<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="LA042790-0205">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>Her movies now are few and far between, but when she is ill, the world still stands at attention.</content>
      <tokens>
        <token id="1" string="Her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="movies" lemma="movie" stem="movi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="few" lemma="few" stem="few" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="far" lemma="far" stem="far" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="between" lemma="between" stem="between" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="ill" lemma="ill" stem="ill" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="still" lemma="still" stem="still" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="stands" lemma="stand" stem="stand" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="attention" lemma="attention" stem="attent" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP$ Her) (NNS movies)) (ADVP (RB now)) (VP (VBP are) (ADJP (JJ few)) (ADVP (CC and) (RB far) (IN between)))) (, ,) (CC but) (S (SBAR (WHADVP (WRB when)) (S (NP (PRP she)) (VP (VBZ is) (ADJP (RB ill))))) (, ,) (NP (DT the) (NN world)) (ADVP (RB still)) (VP (VBZ stands) (PP (IN at) (NP (NN attention))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is ill" type="VP">
          <tokens>
            <token id="13" string="is" />
            <token id="14" string="ill" />
          </tokens>
        </chunking>
        <chunking id="2" string="Her movies" type="NP">
          <tokens>
            <token id="1" string="Her" />
            <token id="2" string="movies" />
          </tokens>
        </chunking>
        <chunking id="3" string="few" type="ADJP">
          <tokens>
            <token id="5" string="few" />
          </tokens>
        </chunking>
        <chunking id="4" string="when she is ill" type="SBAR">
          <tokens>
            <token id="11" string="when" />
            <token id="12" string="she" />
            <token id="13" string="is" />
            <token id="14" string="ill" />
          </tokens>
        </chunking>
        <chunking id="5" string="ill" type="ADJP">
          <tokens>
            <token id="14" string="ill" />
          </tokens>
        </chunking>
        <chunking id="6" string="attention" type="NP">
          <tokens>
            <token id="21" string="attention" />
          </tokens>
        </chunking>
        <chunking id="7" string="are few and far between" type="VP">
          <tokens>
            <token id="4" string="are" />
            <token id="5" string="few" />
            <token id="6" string="and" />
            <token id="7" string="far" />
            <token id="8" string="between" />
          </tokens>
        </chunking>
        <chunking id="8" string="the world" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="world" />
          </tokens>
        </chunking>
        <chunking id="9" string="when" type="WHADVP">
          <tokens>
            <token id="11" string="when" />
          </tokens>
        </chunking>
        <chunking id="10" string="she" type="NP">
          <tokens>
            <token id="12" string="she" />
          </tokens>
        </chunking>
        <chunking id="11" string="stands at attention" type="VP">
          <tokens>
            <token id="19" string="stands" />
            <token id="20" string="at" />
            <token id="21" string="attention" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="2">movies</governor>
          <dependent id="1">Her</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">few</governor>
          <dependent id="2">movies</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">few</governor>
          <dependent id="3">now</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">few</governor>
          <dependent id="4">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">few</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">far</governor>
          <dependent id="6">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">few</governor>
          <dependent id="7">far</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">far</governor>
          <dependent id="8">between</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">few</governor>
          <dependent id="10">but</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">ill</governor>
          <dependent id="11">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">ill</governor>
          <dependent id="12">she</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">ill</governor>
          <dependent id="13">is</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="19">stands</governor>
          <dependent id="14">ill</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">world</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">stands</governor>
          <dependent id="17">world</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">stands</governor>
          <dependent id="18">still</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">few</governor>
          <dependent id="19">stands</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">attention</governor>
          <dependent id="20">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">stands</governor>
          <dependent id="21">attention</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="3" string="now" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>Liz Taylor&amp;apost;s latest bout with pneumonia has drawn the kind of intense scrutiny normally accorded presidential polyps.</content>
      <tokens>
        <token id="1" string="Liz" lemma="Liz" stem="liz" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Taylor" lemma="Taylor" stem="taylor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="latest" lemma="latest" stem="latest" pos="JJS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="bout" lemma="bout" stem="bout" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="pneumonia" lemma="pneumonia" stem="pneumonia" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="false" />
        <token id="8" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="drawn" lemma="draw" stem="drawn" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="kind" lemma="kind" stem="kind" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="intense" lemma="intense" stem="intens" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="scrutiny" lemma="scrutiny" stem="scrutini" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="normally" lemma="normally" stem="normal" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="accorded" lemma="accord" stem="accord" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="presidential" lemma="presidential" stem="presidenti" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="polyps" lemma="polyp" stem="polyp" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NP (NNP Liz) (NNP Taylor) (POS 's)) (JJS latest) (NN bout)) (PP (IN with) (NP (NN pneumonia)))) (VP (VBZ has) (VP (VBN drawn) (NP (NP (DT the) (NN kind)) (PP (IN of) (NP (NP (JJ intense) (NN scrutiny)) (VP (ADVP (RB normally)) (VBN accorded) (NP (JJ presidential) (NNS polyps)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="intense scrutiny normally accorded presidential polyps" type="NP">
          <tokens>
            <token id="13" string="intense" />
            <token id="14" string="scrutiny" />
            <token id="15" string="normally" />
            <token id="16" string="accorded" />
            <token id="17" string="presidential" />
            <token id="18" string="polyps" />
          </tokens>
        </chunking>
        <chunking id="2" string="the kind of intense scrutiny normally accorded presidential polyps" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="kind" />
            <token id="12" string="of" />
            <token id="13" string="intense" />
            <token id="14" string="scrutiny" />
            <token id="15" string="normally" />
            <token id="16" string="accorded" />
            <token id="17" string="presidential" />
            <token id="18" string="polyps" />
          </tokens>
        </chunking>
        <chunking id="3" string="has drawn the kind of intense scrutiny normally accorded presidential polyps" type="VP">
          <tokens>
            <token id="8" string="has" />
            <token id="9" string="drawn" />
            <token id="10" string="the" />
            <token id="11" string="kind" />
            <token id="12" string="of" />
            <token id="13" string="intense" />
            <token id="14" string="scrutiny" />
            <token id="15" string="normally" />
            <token id="16" string="accorded" />
            <token id="17" string="presidential" />
            <token id="18" string="polyps" />
          </tokens>
        </chunking>
        <chunking id="4" string="Liz Taylor 's latest bout with pneumonia" type="NP">
          <tokens>
            <token id="1" string="Liz" />
            <token id="2" string="Taylor" />
            <token id="3" string="'s" />
            <token id="4" string="latest" />
            <token id="5" string="bout" />
            <token id="6" string="with" />
            <token id="7" string="pneumonia" />
          </tokens>
        </chunking>
        <chunking id="5" string="Liz Taylor 's" type="NP">
          <tokens>
            <token id="1" string="Liz" />
            <token id="2" string="Taylor" />
            <token id="3" string="'s" />
          </tokens>
        </chunking>
        <chunking id="6" string="pneumonia" type="NP">
          <tokens>
            <token id="7" string="pneumonia" />
          </tokens>
        </chunking>
        <chunking id="7" string="normally accorded presidential polyps" type="VP">
          <tokens>
            <token id="15" string="normally" />
            <token id="16" string="accorded" />
            <token id="17" string="presidential" />
            <token id="18" string="polyps" />
          </tokens>
        </chunking>
        <chunking id="8" string="Liz Taylor 's latest bout" type="NP">
          <tokens>
            <token id="1" string="Liz" />
            <token id="2" string="Taylor" />
            <token id="3" string="'s" />
            <token id="4" string="latest" />
            <token id="5" string="bout" />
          </tokens>
        </chunking>
        <chunking id="9" string="drawn the kind of intense scrutiny normally accorded presidential polyps" type="VP">
          <tokens>
            <token id="9" string="drawn" />
            <token id="10" string="the" />
            <token id="11" string="kind" />
            <token id="12" string="of" />
            <token id="13" string="intense" />
            <token id="14" string="scrutiny" />
            <token id="15" string="normally" />
            <token id="16" string="accorded" />
            <token id="17" string="presidential" />
            <token id="18" string="polyps" />
          </tokens>
        </chunking>
        <chunking id="10" string="the kind" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="kind" />
          </tokens>
        </chunking>
        <chunking id="11" string="intense scrutiny" type="NP">
          <tokens>
            <token id="13" string="intense" />
            <token id="14" string="scrutiny" />
          </tokens>
        </chunking>
        <chunking id="12" string="presidential polyps" type="NP">
          <tokens>
            <token id="17" string="presidential" />
            <token id="18" string="polyps" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Taylor</governor>
          <dependent id="1">Liz</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">bout</governor>
          <dependent id="2">Taylor</dependent>
        </dependency>
        <dependency type="case">
          <governor id="2">Taylor</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">bout</governor>
          <dependent id="4">latest</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">drawn</governor>
          <dependent id="5">bout</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">pneumonia</governor>
          <dependent id="6">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">bout</governor>
          <dependent id="7">pneumonia</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">drawn</governor>
          <dependent id="8">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">drawn</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">kind</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">drawn</governor>
          <dependent id="11">kind</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">scrutiny</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">scrutiny</governor>
          <dependent id="13">intense</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">kind</governor>
          <dependent id="14">scrutiny</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">accorded</governor>
          <dependent id="15">normally</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="14">scrutiny</governor>
          <dependent id="16">accorded</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">polyps</governor>
          <dependent id="17">presidential</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">accorded</governor>
          <dependent id="18">polyps</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="pneumonia" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="7" string="pneumonia" />
          </tokens>
        </entity>
        <entity id="2" string="Liz Taylor" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Liz" />
            <token id="2" string="Taylor" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>It has inspired a raft of rumors and handed up a field day for the giddy tabloids.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="inspired" lemma="inspire" stem="inspir" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="raft" lemma="raft" stem="raft" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="rumors" lemma="rumor" stem="rumor" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="handed" lemma="hand" stem="hand" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="field" lemma="field" stem="field" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="day" lemma="day" stem="dai" pos="NN" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="14" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="giddy" lemma="giddy" stem="giddi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="tabloids" lemma="tabloid" stem="tabloid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBZ has) (VP (VP (VBN inspired) (NP (NP (DT a) (NN raft)) (PP (IN of) (NP (NNS rumors))))) (CC and) (VP (VBN handed) (PRT (RP up)) (NP (DT a) (NN field) (NN day)) (PP (IN for) (NP (DT the) (JJ giddy) (NNS tabloids)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a raft of rumors" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="raft" />
            <token id="6" string="of" />
            <token id="7" string="rumors" />
          </tokens>
        </chunking>
        <chunking id="2" string="has inspired a raft of rumors and handed up a field day for the giddy tabloids" type="VP">
          <tokens>
            <token id="2" string="has" />
            <token id="3" string="inspired" />
            <token id="4" string="a" />
            <token id="5" string="raft" />
            <token id="6" string="of" />
            <token id="7" string="rumors" />
            <token id="8" string="and" />
            <token id="9" string="handed" />
            <token id="10" string="up" />
            <token id="11" string="a" />
            <token id="12" string="field" />
            <token id="13" string="day" />
            <token id="14" string="for" />
            <token id="15" string="the" />
            <token id="16" string="giddy" />
            <token id="17" string="tabloids" />
          </tokens>
        </chunking>
        <chunking id="3" string="handed up a field day for the giddy tabloids" type="VP">
          <tokens>
            <token id="9" string="handed" />
            <token id="10" string="up" />
            <token id="11" string="a" />
            <token id="12" string="field" />
            <token id="13" string="day" />
            <token id="14" string="for" />
            <token id="15" string="the" />
            <token id="16" string="giddy" />
            <token id="17" string="tabloids" />
          </tokens>
        </chunking>
        <chunking id="4" string="a field day" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="field" />
            <token id="13" string="day" />
          </tokens>
        </chunking>
        <chunking id="5" string="the giddy tabloids" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="giddy" />
            <token id="17" string="tabloids" />
          </tokens>
        </chunking>
        <chunking id="6" string="a raft" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="raft" />
          </tokens>
        </chunking>
        <chunking id="7" string="inspired a raft of rumors and handed up a field day for the giddy tabloids" type="VP">
          <tokens>
            <token id="3" string="inspired" />
            <token id="4" string="a" />
            <token id="5" string="raft" />
            <token id="6" string="of" />
            <token id="7" string="rumors" />
            <token id="8" string="and" />
            <token id="9" string="handed" />
            <token id="10" string="up" />
            <token id="11" string="a" />
            <token id="12" string="field" />
            <token id="13" string="day" />
            <token id="14" string="for" />
            <token id="15" string="the" />
            <token id="16" string="giddy" />
            <token id="17" string="tabloids" />
          </tokens>
        </chunking>
        <chunking id="8" string="rumors" type="NP">
          <tokens>
            <token id="7" string="rumors" />
          </tokens>
        </chunking>
        <chunking id="9" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="10" string="inspired a raft of rumors" type="VP">
          <tokens>
            <token id="3" string="inspired" />
            <token id="4" string="a" />
            <token id="5" string="raft" />
            <token id="6" string="of" />
            <token id="7" string="rumors" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">inspired</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">inspired</governor>
          <dependent id="2">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">inspired</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">raft</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">inspired</governor>
          <dependent id="5">raft</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">rumors</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">raft</governor>
          <dependent id="7">rumors</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">inspired</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">inspired</governor>
          <dependent id="9">handed</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="9">handed</governor>
          <dependent id="10">up</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">day</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">day</governor>
          <dependent id="12">field</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="9">handed</governor>
          <dependent id="13">day</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">tabloids</governor>
          <dependent id="14">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">tabloids</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">tabloids</governor>
          <dependent id="16">giddy</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">handed</governor>
          <dependent id="17">tabloids</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="day" type="DURATION" score="0.0">
          <tokens>
            <token id="13" string="day" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="false">
      <content>And today, yet again, everyone is talking about La Liz.</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="today" lemma="today" stem="todai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="yet" lemma="yet" stem="yet" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="again" lemma="again" stem="again" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="everyone" lemma="everyone" stem="everyon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="talking" lemma="talk" stem="talk" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="La" lemma="La" stem="la" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="12" string="Liz" lemma="Liz" stem="liz" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC And) (ADVP (NN today)) (, ,) (ADVP (RB yet) (RB again)) (, ,) (NP (NN everyone)) (VP (VBZ is) (VP (VBG talking) (PP (IN about) (NP (NNP La) (NNP Liz))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="everyone" type="NP">
          <tokens>
            <token id="7" string="everyone" />
          </tokens>
        </chunking>
        <chunking id="2" string="is talking about La Liz" type="VP">
          <tokens>
            <token id="8" string="is" />
            <token id="9" string="talking" />
            <token id="10" string="about" />
            <token id="11" string="La" />
            <token id="12" string="Liz" />
          </tokens>
        </chunking>
        <chunking id="3" string="talking about La Liz" type="VP">
          <tokens>
            <token id="9" string="talking" />
            <token id="10" string="about" />
            <token id="11" string="La" />
            <token id="12" string="Liz" />
          </tokens>
        </chunking>
        <chunking id="4" string="La Liz" type="NP">
          <tokens>
            <token id="11" string="La" />
            <token id="12" string="Liz" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="9">talking</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">talking</governor>
          <dependent id="2">today</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">again</governor>
          <dependent id="4">yet</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">talking</governor>
          <dependent id="5">again</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">talking</governor>
          <dependent id="7">everyone</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">talking</governor>
          <dependent id="8">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">talking</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Liz</governor>
          <dependent id="10">about</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Liz</governor>
          <dependent id="11">La</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">talking</governor>
          <dependent id="12">Liz</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="today" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="today" />
          </tokens>
        </entity>
        <entity id="2" string="La Liz" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="La" />
            <token id="12" string="Liz" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>But then Liz Taylor, 58, has always lived a life of extremes.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Liz" lemma="Liz" stem="liz" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="Taylor" lemma="Taylor" stem="taylor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="58" lemma="58" stem="58" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="always" lemma="always" stem="alwai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="lived" lemma="live" stem="live" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="life" lemma="life" stem="life" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="extremes" lemma="extreme" stem="extrem" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (ADVP (RB then)) (NP (NP (NNP Liz) (NNP Taylor)) (, ,) (NP (CD 58)) (, ,)) (VP (VBZ has) (ADVP (RB always)) (VP (VBN lived) (NP (NP (DT a) (NN life)) (PP (IN of) (NP (NNS extremes)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="has always lived a life of extremes" type="VP">
          <tokens>
            <token id="8" string="has" />
            <token id="9" string="always" />
            <token id="10" string="lived" />
            <token id="11" string="a" />
            <token id="12" string="life" />
            <token id="13" string="of" />
            <token id="14" string="extremes" />
          </tokens>
        </chunking>
        <chunking id="2" string="a life" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="life" />
          </tokens>
        </chunking>
        <chunking id="3" string="58" type="NP">
          <tokens>
            <token id="6" string="58" />
          </tokens>
        </chunking>
        <chunking id="4" string="Liz Taylor , 58 ," type="NP">
          <tokens>
            <token id="3" string="Liz" />
            <token id="4" string="Taylor" />
            <token id="5" string="," />
            <token id="6" string="58" />
            <token id="7" string="," />
          </tokens>
        </chunking>
        <chunking id="5" string="lived a life of extremes" type="VP">
          <tokens>
            <token id="10" string="lived" />
            <token id="11" string="a" />
            <token id="12" string="life" />
            <token id="13" string="of" />
            <token id="14" string="extremes" />
          </tokens>
        </chunking>
        <chunking id="6" string="Liz Taylor" type="NP">
          <tokens>
            <token id="3" string="Liz" />
            <token id="4" string="Taylor" />
          </tokens>
        </chunking>
        <chunking id="7" string="extremes" type="NP">
          <tokens>
            <token id="14" string="extremes" />
          </tokens>
        </chunking>
        <chunking id="8" string="a life of extremes" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="life" />
            <token id="13" string="of" />
            <token id="14" string="extremes" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="10">lived</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">lived</governor>
          <dependent id="2">then</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Taylor</governor>
          <dependent id="3">Liz</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">lived</governor>
          <dependent id="4">Taylor</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">Taylor</governor>
          <dependent id="6">58</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">lived</governor>
          <dependent id="8">has</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">lived</governor>
          <dependent id="9">always</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">lived</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">life</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">lived</governor>
          <dependent id="12">life</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">extremes</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">life</governor>
          <dependent id="14">extremes</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="58" type="NUMBER" score="0.0">
          <tokens>
            <token id="6" string="58" />
          </tokens>
        </entity>
        <entity id="2" string="Liz Taylor" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Liz" />
            <token id="4" string="Taylor" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>If she has enjoyed the most brilliant career and the glare of fame, she has also survived seven rocky marriages to six men, the frailest health and the most frightening bouts with addiction to booze, drugs and food.</content>
      <tokens>
        <token id="1" string="If" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="enjoyed" lemma="enjoy" stem="enjoi" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="most" lemma="most" stem="most" pos="RBS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="brilliant" lemma="brilliant" stem="brilliant" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="career" lemma="career" stem="career" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="glare" lemma="glare" stem="glare" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="fame" lemma="fame" stem="fame" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="survived" lemma="survive" stem="surviv" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="seven" lemma="seven" stem="seven" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="20" string="rocky" lemma="rocky" stem="rocki" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="marriages" lemma="marriage" stem="marriag" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="six" lemma="six" stem="six" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="24" string="men" lemma="man" stem="men" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="frailest" lemma="frailest" stem="frailest" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="health" lemma="health" stem="health" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="most" lemma="most" stem="most" pos="RBS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="frightening" lemma="frightening" stem="frighten" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="bouts" lemma="bout" stem="bout" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="addiction" lemma="addiction" stem="addict" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="booze" lemma="booze" stem="booz" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="drugs" lemma="drug" stem="drug" pos="NNS" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="false" />
        <token id="40" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="food" lemma="food" stem="food" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN If) (S (NP (PRP she)) (VP (VBZ has) (VP (VBN enjoyed) (NP (NP (DT the) (ADJP (RBS most) (JJ brilliant)) (NN career)) (CC and) (NP (NP (DT the) (NN glare)) (PP (IN of) (NP (NN fame))))))))) (, ,) (NP (PRP she)) (VP (VBZ has) (ADVP (RB also)) (VP (VBN survived) (NP (CD seven) (JJ rocky) (NNS marriages)) (PP (TO to) (NP (NP (CD six) (NNS men)) (, ,) (NP (DT the) (JJS frailest) (NN health)) (CC and) (NP (NP (DT the) (ADJP (RBS most) (JJ frightening)) (NNS bouts)) (PP (IN with) (NP (NN addiction)))))) (PP (TO to) (NP (NN booze) (, ,) (NNS drugs) (CC and) (NN food))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="has also survived seven rocky marriages to six men , the frailest health and the most frightening bouts with addiction to booze , drugs and food" type="VP">
          <tokens>
            <token id="16" string="has" />
            <token id="17" string="also" />
            <token id="18" string="survived" />
            <token id="19" string="seven" />
            <token id="20" string="rocky" />
            <token id="21" string="marriages" />
            <token id="22" string="to" />
            <token id="23" string="six" />
            <token id="24" string="men" />
            <token id="25" string="," />
            <token id="26" string="the" />
            <token id="27" string="frailest" />
            <token id="28" string="health" />
            <token id="29" string="and" />
            <token id="30" string="the" />
            <token id="31" string="most" />
            <token id="32" string="frightening" />
            <token id="33" string="bouts" />
            <token id="34" string="with" />
            <token id="35" string="addiction" />
            <token id="36" string="to" />
            <token id="37" string="booze" />
            <token id="38" string="," />
            <token id="39" string="drugs" />
            <token id="40" string="and" />
            <token id="41" string="food" />
          </tokens>
        </chunking>
        <chunking id="2" string="seven rocky marriages" type="NP">
          <tokens>
            <token id="19" string="seven" />
            <token id="20" string="rocky" />
            <token id="21" string="marriages" />
          </tokens>
        </chunking>
        <chunking id="3" string="the most frightening bouts" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="most" />
            <token id="32" string="frightening" />
            <token id="33" string="bouts" />
          </tokens>
        </chunking>
        <chunking id="4" string="six men , the frailest health and the most frightening bouts with addiction" type="NP">
          <tokens>
            <token id="23" string="six" />
            <token id="24" string="men" />
            <token id="25" string="," />
            <token id="26" string="the" />
            <token id="27" string="frailest" />
            <token id="28" string="health" />
            <token id="29" string="and" />
            <token id="30" string="the" />
            <token id="31" string="most" />
            <token id="32" string="frightening" />
            <token id="33" string="bouts" />
            <token id="34" string="with" />
            <token id="35" string="addiction" />
          </tokens>
        </chunking>
        <chunking id="5" string="booze , drugs and food" type="NP">
          <tokens>
            <token id="37" string="booze" />
            <token id="38" string="," />
            <token id="39" string="drugs" />
            <token id="40" string="and" />
            <token id="41" string="food" />
          </tokens>
        </chunking>
        <chunking id="6" string="addiction" type="NP">
          <tokens>
            <token id="35" string="addiction" />
          </tokens>
        </chunking>
        <chunking id="7" string="most brilliant" type="ADJP">
          <tokens>
            <token id="6" string="most" />
            <token id="7" string="brilliant" />
          </tokens>
        </chunking>
        <chunking id="8" string="enjoyed the most brilliant career and the glare of fame" type="VP">
          <tokens>
            <token id="4" string="enjoyed" />
            <token id="5" string="the" />
            <token id="6" string="most" />
            <token id="7" string="brilliant" />
            <token id="8" string="career" />
            <token id="9" string="and" />
            <token id="10" string="the" />
            <token id="11" string="glare" />
            <token id="12" string="of" />
            <token id="13" string="fame" />
          </tokens>
        </chunking>
        <chunking id="9" string="most frightening" type="ADJP">
          <tokens>
            <token id="31" string="most" />
            <token id="32" string="frightening" />
          </tokens>
        </chunking>
        <chunking id="10" string="she" type="NP">
          <tokens>
            <token id="2" string="she" />
          </tokens>
        </chunking>
        <chunking id="11" string="the most brilliant career and the glare of fame" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="most" />
            <token id="7" string="brilliant" />
            <token id="8" string="career" />
            <token id="9" string="and" />
            <token id="10" string="the" />
            <token id="11" string="glare" />
            <token id="12" string="of" />
            <token id="13" string="fame" />
          </tokens>
        </chunking>
        <chunking id="12" string="six men" type="NP">
          <tokens>
            <token id="23" string="six" />
            <token id="24" string="men" />
          </tokens>
        </chunking>
        <chunking id="13" string="the glare" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="glare" />
          </tokens>
        </chunking>
        <chunking id="14" string="the most frightening bouts with addiction" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="most" />
            <token id="32" string="frightening" />
            <token id="33" string="bouts" />
            <token id="34" string="with" />
            <token id="35" string="addiction" />
          </tokens>
        </chunking>
        <chunking id="15" string="the frailest health" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="frailest" />
            <token id="28" string="health" />
          </tokens>
        </chunking>
        <chunking id="16" string="has enjoyed the most brilliant career and the glare of fame" type="VP">
          <tokens>
            <token id="3" string="has" />
            <token id="4" string="enjoyed" />
            <token id="5" string="the" />
            <token id="6" string="most" />
            <token id="7" string="brilliant" />
            <token id="8" string="career" />
            <token id="9" string="and" />
            <token id="10" string="the" />
            <token id="11" string="glare" />
            <token id="12" string="of" />
            <token id="13" string="fame" />
          </tokens>
        </chunking>
        <chunking id="17" string="fame" type="NP">
          <tokens>
            <token id="13" string="fame" />
          </tokens>
        </chunking>
        <chunking id="18" string="If she has enjoyed the most brilliant career and the glare of fame" type="SBAR">
          <tokens>
            <token id="1" string="If" />
            <token id="2" string="she" />
            <token id="3" string="has" />
            <token id="4" string="enjoyed" />
            <token id="5" string="the" />
            <token id="6" string="most" />
            <token id="7" string="brilliant" />
            <token id="8" string="career" />
            <token id="9" string="and" />
            <token id="10" string="the" />
            <token id="11" string="glare" />
            <token id="12" string="of" />
            <token id="13" string="fame" />
          </tokens>
        </chunking>
        <chunking id="19" string="the most brilliant career" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="most" />
            <token id="7" string="brilliant" />
            <token id="8" string="career" />
          </tokens>
        </chunking>
        <chunking id="20" string="the glare of fame" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="glare" />
            <token id="12" string="of" />
            <token id="13" string="fame" />
          </tokens>
        </chunking>
        <chunking id="21" string="survived seven rocky marriages to six men , the frailest health and the most frightening bouts with addiction to booze , drugs and food" type="VP">
          <tokens>
            <token id="18" string="survived" />
            <token id="19" string="seven" />
            <token id="20" string="rocky" />
            <token id="21" string="marriages" />
            <token id="22" string="to" />
            <token id="23" string="six" />
            <token id="24" string="men" />
            <token id="25" string="," />
            <token id="26" string="the" />
            <token id="27" string="frailest" />
            <token id="28" string="health" />
            <token id="29" string="and" />
            <token id="30" string="the" />
            <token id="31" string="most" />
            <token id="32" string="frightening" />
            <token id="33" string="bouts" />
            <token id="34" string="with" />
            <token id="35" string="addiction" />
            <token id="36" string="to" />
            <token id="37" string="booze" />
            <token id="38" string="," />
            <token id="39" string="drugs" />
            <token id="40" string="and" />
            <token id="41" string="food" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="4">enjoyed</governor>
          <dependent id="1">If</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">enjoyed</governor>
          <dependent id="2">she</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">enjoyed</governor>
          <dependent id="3">has</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="18">survived</governor>
          <dependent id="4">enjoyed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">career</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">brilliant</governor>
          <dependent id="6">most</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">career</governor>
          <dependent id="7">brilliant</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">enjoyed</governor>
          <dependent id="8">career</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">career</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">glare</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">career</governor>
          <dependent id="11">glare</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">fame</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">glare</governor>
          <dependent id="13">fame</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">survived</governor>
          <dependent id="15">she</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">survived</governor>
          <dependent id="16">has</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">survived</governor>
          <dependent id="17">also</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">survived</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="21">marriages</governor>
          <dependent id="19">seven</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">marriages</governor>
          <dependent id="20">rocky</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">survived</governor>
          <dependent id="21">marriages</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">men</governor>
          <dependent id="22">to</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="24">men</governor>
          <dependent id="23">six</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">survived</governor>
          <dependent id="24">men</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">health</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">health</governor>
          <dependent id="27">frailest</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="24">men</governor>
          <dependent id="28">health</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="24">men</governor>
          <dependent id="29">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">bouts</governor>
          <dependent id="30">the</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="32">frightening</governor>
          <dependent id="31">most</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="33">bouts</governor>
          <dependent id="32">frightening</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="24">men</governor>
          <dependent id="33">bouts</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">addiction</governor>
          <dependent id="34">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">bouts</governor>
          <dependent id="35">addiction</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">booze</governor>
          <dependent id="36">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">survived</governor>
          <dependent id="37">booze</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="37">booze</governor>
          <dependent id="39">drugs</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="37">booze</governor>
          <dependent id="40">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="37">booze</governor>
          <dependent id="41">food</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="six" type="NUMBER" score="0.0">
          <tokens>
            <token id="23" string="six" />
          </tokens>
        </entity>
        <entity id="2" string="drugs" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="39" string="drugs" />
          </tokens>
        </entity>
        <entity id="3" string="seven" type="NUMBER" score="0.0">
          <tokens>
            <token id="19" string="seven" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>And through it all, there have been armies of press recording each divorce, each hospital stay.</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="armies" lemma="army" stem="armi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="press" lemma="press" stem="press" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="recording" lemma="recording" stem="record" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="each" lemma="each" stem="each" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="divorce" lemma="divorce" stem="divorc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="each" lemma="each" stem="each" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="hospital" lemma="hospital" stem="hospit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="stay" lemma="stay" stem="stai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC And) (PP (IN through) (NP (PRP it) (DT all))) (, ,) (NP (EX there)) (VP (VBP have) (VP (VBN been) (NP (NP (NNS armies)) (PP (IN of) (NP (NN press) (NN recording))) (NP-TMP (NP (DT each) (NN divorce)) (, ,) (NP (DT each) (NN hospital) (NN stay)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="there" type="NP">
          <tokens>
            <token id="6" string="there" />
          </tokens>
        </chunking>
        <chunking id="2" string="armies of press recording each divorce , each hospital stay" type="NP">
          <tokens>
            <token id="9" string="armies" />
            <token id="10" string="of" />
            <token id="11" string="press" />
            <token id="12" string="recording" />
            <token id="13" string="each" />
            <token id="14" string="divorce" />
            <token id="15" string="," />
            <token id="16" string="each" />
            <token id="17" string="hospital" />
            <token id="18" string="stay" />
          </tokens>
        </chunking>
        <chunking id="3" string="each divorce" type="NP">
          <tokens>
            <token id="13" string="each" />
            <token id="14" string="divorce" />
          </tokens>
        </chunking>
        <chunking id="4" string="have been armies of press recording each divorce , each hospital stay" type="VP">
          <tokens>
            <token id="7" string="have" />
            <token id="8" string="been" />
            <token id="9" string="armies" />
            <token id="10" string="of" />
            <token id="11" string="press" />
            <token id="12" string="recording" />
            <token id="13" string="each" />
            <token id="14" string="divorce" />
            <token id="15" string="," />
            <token id="16" string="each" />
            <token id="17" string="hospital" />
            <token id="18" string="stay" />
          </tokens>
        </chunking>
        <chunking id="5" string="it all" type="NP">
          <tokens>
            <token id="3" string="it" />
            <token id="4" string="all" />
          </tokens>
        </chunking>
        <chunking id="6" string="armies" type="NP">
          <tokens>
            <token id="9" string="armies" />
          </tokens>
        </chunking>
        <chunking id="7" string="each hospital stay" type="NP">
          <tokens>
            <token id="16" string="each" />
            <token id="17" string="hospital" />
            <token id="18" string="stay" />
          </tokens>
        </chunking>
        <chunking id="8" string="press recording" type="NP">
          <tokens>
            <token id="11" string="press" />
            <token id="12" string="recording" />
          </tokens>
        </chunking>
        <chunking id="9" string="been armies of press recording each divorce , each hospital stay" type="VP">
          <tokens>
            <token id="8" string="been" />
            <token id="9" string="armies" />
            <token id="10" string="of" />
            <token id="11" string="press" />
            <token id="12" string="recording" />
            <token id="13" string="each" />
            <token id="14" string="divorce" />
            <token id="15" string="," />
            <token id="16" string="each" />
            <token id="17" string="hospital" />
            <token id="18" string="stay" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="9">armies</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">it</governor>
          <dependent id="2">through</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">armies</governor>
          <dependent id="3">it</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">it</governor>
          <dependent id="4">all</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="9">armies</governor>
          <dependent id="6">there</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">armies</governor>
          <dependent id="7">have</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="9">armies</governor>
          <dependent id="8">been</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">armies</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">recording</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">recording</governor>
          <dependent id="11">press</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">armies</governor>
          <dependent id="12">recording</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">divorce</governor>
          <dependent id="13">each</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="9">armies</governor>
          <dependent id="14">divorce</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">stay</governor>
          <dependent id="16">each</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">stay</governor>
          <dependent id="17">hospital</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="14">divorce</governor>
          <dependent id="18">stay</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>It was partly to still the gossips that Taylor&amp;apost;s doctors called a press conference Wednesday at St. John&amp;apost;s Hospital and Medical Center in Santa Monica.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="partly" lemma="partly" stem="partli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="still" lemma="still" stem="still" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="gossips" lemma="gossip" stem="gossip" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Taylor" lemma="Taylor" stem="taylor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="10" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="doctors" lemma="doctor" stem="doctor" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="called" lemma="call" stem="call" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="press" lemma="press" stem="press" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="conference" lemma="conference" stem="confer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="Wednesday" lemma="Wednesday" stem="wednesdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="17" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="St." lemma="St." stem="st." pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="19" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="20" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="21" string="Hospital" lemma="Hospital" stem="hospit" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="22" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="23" string="Medical" lemma="Medical" stem="medic" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="24" string="Center" lemma="Center" stem="center" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="25" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="Santa" lemma="Santa" stem="santa" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="27" string="Monica" lemma="Monica" stem="monica" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBD was) (ADVP (RB partly)) (PP (TO to) (NP (ADVP (RB still)) (DT the) (NNS gossips))) (SBAR (WHNP (WDT that)) (S (NP (NP (NNP Taylor) (POS 's)) (NNS doctors)) (VP (VBD called) (NP (DT a) (NN press) (NN conference)) (NP-TMP (NNP Wednesday)) (PP (IN at) (NP (NP (NNP St.) (NNP John) (POS 's)) (NNP Hospital) (CC and) (NNP Medical) (NNP Center))) (PP (IN in) (NP (NNP Santa) (NNP Monica))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="St. John 's Hospital and Medical Center" type="NP">
          <tokens>
            <token id="18" string="St." />
            <token id="19" string="John" />
            <token id="20" string="'s" />
            <token id="21" string="Hospital" />
            <token id="22" string="and" />
            <token id="23" string="Medical" />
            <token id="24" string="Center" />
          </tokens>
        </chunking>
        <chunking id="2" string="Santa Monica" type="NP">
          <tokens>
            <token id="26" string="Santa" />
            <token id="27" string="Monica" />
          </tokens>
        </chunking>
        <chunking id="3" string="was partly to still the gossips that Taylor 's doctors called a press conference Wednesday at St. John 's Hospital and Medical Center in Santa Monica" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="partly" />
            <token id="4" string="to" />
            <token id="5" string="still" />
            <token id="6" string="the" />
            <token id="7" string="gossips" />
            <token id="8" string="that" />
            <token id="9" string="Taylor" />
            <token id="10" string="'s" />
            <token id="11" string="doctors" />
            <token id="12" string="called" />
            <token id="13" string="a" />
            <token id="14" string="press" />
            <token id="15" string="conference" />
            <token id="16" string="Wednesday" />
            <token id="17" string="at" />
            <token id="18" string="St." />
            <token id="19" string="John" />
            <token id="20" string="'s" />
            <token id="21" string="Hospital" />
            <token id="22" string="and" />
            <token id="23" string="Medical" />
            <token id="24" string="Center" />
            <token id="25" string="in" />
            <token id="26" string="Santa" />
            <token id="27" string="Monica" />
          </tokens>
        </chunking>
        <chunking id="4" string="still the gossips" type="NP">
          <tokens>
            <token id="5" string="still" />
            <token id="6" string="the" />
            <token id="7" string="gossips" />
          </tokens>
        </chunking>
        <chunking id="5" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="6" string="that Taylor 's doctors called a press conference Wednesday at St. John 's Hospital and Medical Center in Santa Monica" type="SBAR">
          <tokens>
            <token id="8" string="that" />
            <token id="9" string="Taylor" />
            <token id="10" string="'s" />
            <token id="11" string="doctors" />
            <token id="12" string="called" />
            <token id="13" string="a" />
            <token id="14" string="press" />
            <token id="15" string="conference" />
            <token id="16" string="Wednesday" />
            <token id="17" string="at" />
            <token id="18" string="St." />
            <token id="19" string="John" />
            <token id="20" string="'s" />
            <token id="21" string="Hospital" />
            <token id="22" string="and" />
            <token id="23" string="Medical" />
            <token id="24" string="Center" />
            <token id="25" string="in" />
            <token id="26" string="Santa" />
            <token id="27" string="Monica" />
          </tokens>
        </chunking>
        <chunking id="7" string="Taylor 's doctors" type="NP">
          <tokens>
            <token id="9" string="Taylor" />
            <token id="10" string="'s" />
            <token id="11" string="doctors" />
          </tokens>
        </chunking>
        <chunking id="8" string="Taylor 's" type="NP">
          <tokens>
            <token id="9" string="Taylor" />
            <token id="10" string="'s" />
          </tokens>
        </chunking>
        <chunking id="9" string="called a press conference Wednesday at St. John 's Hospital and Medical Center in Santa Monica" type="VP">
          <tokens>
            <token id="12" string="called" />
            <token id="13" string="a" />
            <token id="14" string="press" />
            <token id="15" string="conference" />
            <token id="16" string="Wednesday" />
            <token id="17" string="at" />
            <token id="18" string="St." />
            <token id="19" string="John" />
            <token id="20" string="'s" />
            <token id="21" string="Hospital" />
            <token id="22" string="and" />
            <token id="23" string="Medical" />
            <token id="24" string="Center" />
            <token id="25" string="in" />
            <token id="26" string="Santa" />
            <token id="27" string="Monica" />
          </tokens>
        </chunking>
        <chunking id="10" string="St. John 's" type="NP">
          <tokens>
            <token id="18" string="St." />
            <token id="19" string="John" />
            <token id="20" string="'s" />
          </tokens>
        </chunking>
        <chunking id="11" string="a press conference" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="press" />
            <token id="15" string="conference" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="7">gossips</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">gossips</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">gossips</governor>
          <dependent id="3">partly</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">gossips</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">gossips</governor>
          <dependent id="5">still</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">gossips</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">gossips</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">called</governor>
          <dependent id="8">that</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">doctors</governor>
          <dependent id="9">Taylor</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Taylor</governor>
          <dependent id="10">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">called</governor>
          <dependent id="11">doctors</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">gossips</governor>
          <dependent id="12">called</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">conference</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">conference</governor>
          <dependent id="14">press</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">called</governor>
          <dependent id="15">conference</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="12">called</governor>
          <dependent id="16">Wednesday</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">Hospital</governor>
          <dependent id="17">at</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">John</governor>
          <dependent id="18">St.</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="21">Hospital</governor>
          <dependent id="19">John</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">John</governor>
          <dependent id="20">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">called</governor>
          <dependent id="21">Hospital</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="21">Hospital</governor>
          <dependent id="22">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">Center</governor>
          <dependent id="23">Medical</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="21">Hospital</governor>
          <dependent id="24">Center</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">Monica</governor>
          <dependent id="25">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">Monica</governor>
          <dependent id="26">Santa</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">called</governor>
          <dependent id="27">Monica</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="St. John 's Hospital and Medical Center" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="18" string="St." />
            <token id="19" string="John" />
            <token id="20" string="'s" />
            <token id="21" string="Hospital" />
            <token id="22" string="and" />
            <token id="23" string="Medical" />
            <token id="24" string="Center" />
          </tokens>
        </entity>
        <entity id="2" string="Santa Monica" type="LOCATION" score="0.0">
          <tokens>
            <token id="26" string="Santa" />
            <token id="27" string="Monica" />
          </tokens>
        </entity>
        <entity id="3" string="Taylor" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Taylor" />
          </tokens>
        </entity>
        <entity id="4" string="Wednesday" type="DATE" score="0.0">
          <tokens>
            <token id="16" string="Wednesday" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>No AIDS, they said.</content>
      <tokens>
        <token id="1" string="No" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="2" string="AIDS" lemma="aids" stem="aids" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (DT No) (NN AIDS)) (, ,) (NP (PRP they)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="they" type="NP">
          <tokens>
            <token id="4" string="they" />
          </tokens>
        </chunking>
        <chunking id="2" string="said" type="VP">
          <tokens>
            <token id="5" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="neg">
          <governor id="2">AIDS</governor>
          <dependent id="1">No</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">said</governor>
          <dependent id="2">AIDS</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">said</governor>
          <dependent id="4">they</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="No" type="MISC" score="0.0">
          <tokens>
            <token id="1" string="No" />
          </tokens>
        </entity>
        <entity id="2" string="AIDS" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="2" string="AIDS" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="false">
      <content>No cancer.</content>
      <tokens>
        <token id="1" string="No" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="cancer" lemma="cancer" stem="cancer" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="3" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (DT No) (NN cancer) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="No cancer ." type="NP">
          <tokens>
            <token id="1" string="No" />
            <token id="2" string="cancer" />
            <token id="3" string="." />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="neg">
          <governor id="2">cancer</governor>
          <dependent id="1">No</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">cancer</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="cancer" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="2" string="cancer" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>For the tabloid press had been humming with rumors that Liz Taylor had AIDS virtually since she was checked into Daniel Freeman Hospital in Marina del Rey April 9 with a high fever and sinus infection.</content>
      <tokens>
        <token id="1" string="For" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="tabloid" lemma="tabloid" stem="tabloid" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="press" lemma="press" stem="press" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="humming" lemma="hum" stem="hum" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="rumors" lemma="rumor" stem="rumor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Liz" lemma="Liz" stem="liz" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="12" string="Taylor" lemma="Taylor" stem="taylor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="13" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="AIDS" lemma="AIDS" stem="aids" pos="NNP" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="false" />
        <token id="15" string="virtually" lemma="virtually" stem="virtual" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="checked" lemma="check" stem="check" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="Daniel" lemma="Daniel" stem="daniel" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="22" string="Freeman" lemma="Freeman" stem="freeman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="23" string="Hospital" lemma="Hospital" stem="hospit" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="Marina" lemma="Marina" stem="marina" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="26" string="del" lemma="del" stem="del" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="27" string="Rey" lemma="Rey" stem="rei" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="28" string="April" lemma="April" stem="april" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="29" string="9" lemma="9" stem="9" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="30" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="high" lemma="high" stem="high" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="fever" lemma="fever" stem="fever" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="sinus" lemma="sinus" stem="sinu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="infection" lemma="infection" stem="infect" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="37" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (IN For) (NP (DT the) (JJ tabloid) (NN press)) (VP (VBD had) (VP (VBN been) (VP (VBG humming) (PP (IN with) (NP (NNS rumors))) (SBAR (IN that) (S (NP (NNP Liz) (NNP Taylor)) (VP (VBD had) (NP (NNP AIDS)) (ADVP (RB virtually)) (SBAR (IN since) (S (NP (PRP she)) (VP (VBD was) (VP (VBN checked) (PP (IN into) (NP (NP (NNP Daniel) (NNP Freeman) (NNP Hospital)) (PP (IN in) (NP (NNP Marina) (NNP del) (NNP Rey))))) (NP-TMP (NNP April) (CD 9)) (PP (IN with) (NP (DT a) (JJ high) (NN fever) (CC and) (NN sinus) (NN infection))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that Liz Taylor had AIDS virtually since she was checked into Daniel Freeman Hospital in Marina del Rey April 9 with a high fever and sinus infection" type="SBAR">
          <tokens>
            <token id="10" string="that" />
            <token id="11" string="Liz" />
            <token id="12" string="Taylor" />
            <token id="13" string="had" />
            <token id="14" string="AIDS" />
            <token id="15" string="virtually" />
            <token id="16" string="since" />
            <token id="17" string="she" />
            <token id="18" string="was" />
            <token id="19" string="checked" />
            <token id="20" string="into" />
            <token id="21" string="Daniel" />
            <token id="22" string="Freeman" />
            <token id="23" string="Hospital" />
            <token id="24" string="in" />
            <token id="25" string="Marina" />
            <token id="26" string="del" />
            <token id="27" string="Rey" />
            <token id="28" string="April" />
            <token id="29" string="9" />
            <token id="30" string="with" />
            <token id="31" string="a" />
            <token id="32" string="high" />
            <token id="33" string="fever" />
            <token id="34" string="and" />
            <token id="35" string="sinus" />
            <token id="36" string="infection" />
          </tokens>
        </chunking>
        <chunking id="2" string="had AIDS virtually since she was checked into Daniel Freeman Hospital in Marina del Rey April 9 with a high fever and sinus infection" type="VP">
          <tokens>
            <token id="13" string="had" />
            <token id="14" string="AIDS" />
            <token id="15" string="virtually" />
            <token id="16" string="since" />
            <token id="17" string="she" />
            <token id="18" string="was" />
            <token id="19" string="checked" />
            <token id="20" string="into" />
            <token id="21" string="Daniel" />
            <token id="22" string="Freeman" />
            <token id="23" string="Hospital" />
            <token id="24" string="in" />
            <token id="25" string="Marina" />
            <token id="26" string="del" />
            <token id="27" string="Rey" />
            <token id="28" string="April" />
            <token id="29" string="9" />
            <token id="30" string="with" />
            <token id="31" string="a" />
            <token id="32" string="high" />
            <token id="33" string="fever" />
            <token id="34" string="and" />
            <token id="35" string="sinus" />
            <token id="36" string="infection" />
          </tokens>
        </chunking>
        <chunking id="3" string="since she was checked into Daniel Freeman Hospital in Marina del Rey April 9 with a high fever and sinus infection" type="SBAR">
          <tokens>
            <token id="16" string="since" />
            <token id="17" string="she" />
            <token id="18" string="was" />
            <token id="19" string="checked" />
            <token id="20" string="into" />
            <token id="21" string="Daniel" />
            <token id="22" string="Freeman" />
            <token id="23" string="Hospital" />
            <token id="24" string="in" />
            <token id="25" string="Marina" />
            <token id="26" string="del" />
            <token id="27" string="Rey" />
            <token id="28" string="April" />
            <token id="29" string="9" />
            <token id="30" string="with" />
            <token id="31" string="a" />
            <token id="32" string="high" />
            <token id="33" string="fever" />
            <token id="34" string="and" />
            <token id="35" string="sinus" />
            <token id="36" string="infection" />
          </tokens>
        </chunking>
        <chunking id="4" string="Daniel Freeman Hospital in Marina del Rey" type="NP">
          <tokens>
            <token id="21" string="Daniel" />
            <token id="22" string="Freeman" />
            <token id="23" string="Hospital" />
            <token id="24" string="in" />
            <token id="25" string="Marina" />
            <token id="26" string="del" />
            <token id="27" string="Rey" />
          </tokens>
        </chunking>
        <chunking id="5" string="been humming with rumors that Liz Taylor had AIDS virtually since she was checked into Daniel Freeman Hospital in Marina del Rey April 9 with a high fever and sinus infection" type="VP">
          <tokens>
            <token id="6" string="been" />
            <token id="7" string="humming" />
            <token id="8" string="with" />
            <token id="9" string="rumors" />
            <token id="10" string="that" />
            <token id="11" string="Liz" />
            <token id="12" string="Taylor" />
            <token id="13" string="had" />
            <token id="14" string="AIDS" />
            <token id="15" string="virtually" />
            <token id="16" string="since" />
            <token id="17" string="she" />
            <token id="18" string="was" />
            <token id="19" string="checked" />
            <token id="20" string="into" />
            <token id="21" string="Daniel" />
            <token id="22" string="Freeman" />
            <token id="23" string="Hospital" />
            <token id="24" string="in" />
            <token id="25" string="Marina" />
            <token id="26" string="del" />
            <token id="27" string="Rey" />
            <token id="28" string="April" />
            <token id="29" string="9" />
            <token id="30" string="with" />
            <token id="31" string="a" />
            <token id="32" string="high" />
            <token id="33" string="fever" />
            <token id="34" string="and" />
            <token id="35" string="sinus" />
            <token id="36" string="infection" />
          </tokens>
        </chunking>
        <chunking id="6" string="AIDS" type="NP">
          <tokens>
            <token id="14" string="AIDS" />
          </tokens>
        </chunking>
        <chunking id="7" string="rumors" type="NP">
          <tokens>
            <token id="9" string="rumors" />
          </tokens>
        </chunking>
        <chunking id="8" string="Daniel Freeman Hospital" type="NP">
          <tokens>
            <token id="21" string="Daniel" />
            <token id="22" string="Freeman" />
            <token id="23" string="Hospital" />
          </tokens>
        </chunking>
        <chunking id="9" string="the tabloid press" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="tabloid" />
            <token id="4" string="press" />
          </tokens>
        </chunking>
        <chunking id="10" string="a high fever and sinus infection" type="NP">
          <tokens>
            <token id="31" string="a" />
            <token id="32" string="high" />
            <token id="33" string="fever" />
            <token id="34" string="and" />
            <token id="35" string="sinus" />
            <token id="36" string="infection" />
          </tokens>
        </chunking>
        <chunking id="11" string="she" type="NP">
          <tokens>
            <token id="17" string="she" />
          </tokens>
        </chunking>
        <chunking id="12" string="checked into Daniel Freeman Hospital in Marina del Rey April 9 with a high fever and sinus infection" type="VP">
          <tokens>
            <token id="19" string="checked" />
            <token id="20" string="into" />
            <token id="21" string="Daniel" />
            <token id="22" string="Freeman" />
            <token id="23" string="Hospital" />
            <token id="24" string="in" />
            <token id="25" string="Marina" />
            <token id="26" string="del" />
            <token id="27" string="Rey" />
            <token id="28" string="April" />
            <token id="29" string="9" />
            <token id="30" string="with" />
            <token id="31" string="a" />
            <token id="32" string="high" />
            <token id="33" string="fever" />
            <token id="34" string="and" />
            <token id="35" string="sinus" />
            <token id="36" string="infection" />
          </tokens>
        </chunking>
        <chunking id="13" string="had been humming with rumors that Liz Taylor had AIDS virtually since she was checked into Daniel Freeman Hospital in Marina del Rey April 9 with a high fever and sinus infection" type="VP">
          <tokens>
            <token id="5" string="had" />
            <token id="6" string="been" />
            <token id="7" string="humming" />
            <token id="8" string="with" />
            <token id="9" string="rumors" />
            <token id="10" string="that" />
            <token id="11" string="Liz" />
            <token id="12" string="Taylor" />
            <token id="13" string="had" />
            <token id="14" string="AIDS" />
            <token id="15" string="virtually" />
            <token id="16" string="since" />
            <token id="17" string="she" />
            <token id="18" string="was" />
            <token id="19" string="checked" />
            <token id="20" string="into" />
            <token id="21" string="Daniel" />
            <token id="22" string="Freeman" />
            <token id="23" string="Hospital" />
            <token id="24" string="in" />
            <token id="25" string="Marina" />
            <token id="26" string="del" />
            <token id="27" string="Rey" />
            <token id="28" string="April" />
            <token id="29" string="9" />
            <token id="30" string="with" />
            <token id="31" string="a" />
            <token id="32" string="high" />
            <token id="33" string="fever" />
            <token id="34" string="and" />
            <token id="35" string="sinus" />
            <token id="36" string="infection" />
          </tokens>
        </chunking>
        <chunking id="14" string="humming with rumors that Liz Taylor had AIDS virtually since she was checked into Daniel Freeman Hospital in Marina del Rey April 9 with a high fever and sinus infection" type="VP">
          <tokens>
            <token id="7" string="humming" />
            <token id="8" string="with" />
            <token id="9" string="rumors" />
            <token id="10" string="that" />
            <token id="11" string="Liz" />
            <token id="12" string="Taylor" />
            <token id="13" string="had" />
            <token id="14" string="AIDS" />
            <token id="15" string="virtually" />
            <token id="16" string="since" />
            <token id="17" string="she" />
            <token id="18" string="was" />
            <token id="19" string="checked" />
            <token id="20" string="into" />
            <token id="21" string="Daniel" />
            <token id="22" string="Freeman" />
            <token id="23" string="Hospital" />
            <token id="24" string="in" />
            <token id="25" string="Marina" />
            <token id="26" string="del" />
            <token id="27" string="Rey" />
            <token id="28" string="April" />
            <token id="29" string="9" />
            <token id="30" string="with" />
            <token id="31" string="a" />
            <token id="32" string="high" />
            <token id="33" string="fever" />
            <token id="34" string="and" />
            <token id="35" string="sinus" />
            <token id="36" string="infection" />
          </tokens>
        </chunking>
        <chunking id="15" string="Liz Taylor" type="NP">
          <tokens>
            <token id="11" string="Liz" />
            <token id="12" string="Taylor" />
          </tokens>
        </chunking>
        <chunking id="16" string="Marina del Rey" type="NP">
          <tokens>
            <token id="25" string="Marina" />
            <token id="26" string="del" />
            <token id="27" string="Rey" />
          </tokens>
        </chunking>
        <chunking id="17" string="was checked into Daniel Freeman Hospital in Marina del Rey April 9 with a high fever and sinus infection" type="VP">
          <tokens>
            <token id="18" string="was" />
            <token id="19" string="checked" />
            <token id="20" string="into" />
            <token id="21" string="Daniel" />
            <token id="22" string="Freeman" />
            <token id="23" string="Hospital" />
            <token id="24" string="in" />
            <token id="25" string="Marina" />
            <token id="26" string="del" />
            <token id="27" string="Rey" />
            <token id="28" string="April" />
            <token id="29" string="9" />
            <token id="30" string="with" />
            <token id="31" string="a" />
            <token id="32" string="high" />
            <token id="33" string="fever" />
            <token id="34" string="and" />
            <token id="35" string="sinus" />
            <token id="36" string="infection" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="dep">
          <governor id="7">humming</governor>
          <dependent id="1">For</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">press</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">press</governor>
          <dependent id="3">tabloid</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">humming</governor>
          <dependent id="4">press</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">humming</governor>
          <dependent id="5">had</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">humming</governor>
          <dependent id="6">been</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">humming</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">rumors</governor>
          <dependent id="8">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">humming</governor>
          <dependent id="9">rumors</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">had</governor>
          <dependent id="10">that</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Taylor</governor>
          <dependent id="11">Liz</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">had</governor>
          <dependent id="12">Taylor</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">humming</governor>
          <dependent id="13">had</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">had</governor>
          <dependent id="14">AIDS</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">had</governor>
          <dependent id="15">virtually</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">checked</governor>
          <dependent id="16">since</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="19">checked</governor>
          <dependent id="17">she</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="19">checked</governor>
          <dependent id="18">was</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="13">had</governor>
          <dependent id="19">checked</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">Hospital</governor>
          <dependent id="20">into</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">Hospital</governor>
          <dependent id="21">Daniel</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">Hospital</governor>
          <dependent id="22">Freeman</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">checked</governor>
          <dependent id="23">Hospital</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">Rey</governor>
          <dependent id="24">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">Rey</governor>
          <dependent id="25">Marina</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">Rey</governor>
          <dependent id="26">del</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">Hospital</governor>
          <dependent id="27">Rey</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="19">checked</governor>
          <dependent id="28">April</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="28">April</governor>
          <dependent id="29">9</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">fever</governor>
          <dependent id="30">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">fever</governor>
          <dependent id="31">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="33">fever</governor>
          <dependent id="32">high</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">checked</governor>
          <dependent id="33">fever</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="33">fever</governor>
          <dependent id="34">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="36">infection</governor>
          <dependent id="35">sinus</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="33">fever</governor>
          <dependent id="36">infection</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="infection" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="36" string="infection" />
          </tokens>
        </entity>
        <entity id="2" string="April 9" type="DATE" score="0.0">
          <tokens>
            <token id="28" string="April" />
            <token id="29" string="9" />
          </tokens>
        </entity>
        <entity id="3" string="Daniel Freeman" type="PERSON" score="0.0">
          <tokens>
            <token id="21" string="Daniel" />
            <token id="22" string="Freeman" />
          </tokens>
        </entity>
        <entity id="4" string="AIDS" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="14" string="AIDS" />
          </tokens>
        </entity>
        <entity id="5" string="Liz Taylor" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Liz" />
            <token id="12" string="Taylor" />
          </tokens>
        </entity>
        <entity id="6" string="Marina del Rey" type="LOCATION" score="0.0">
          <tokens>
            <token id="25" string="Marina" />
            <token id="26" string="del" />
            <token id="27" string="Rey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>And when Taylor&amp;apost;s publicists first issued flat denials, the press went on to speculate about the speculation.</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Taylor" lemma="Taylor" stem="taylor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="4" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="publicists" lemma="publicist" stem="publicist" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="first" lemma="first" stem="first" pos="RB" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="true" is_refers="false" />
        <token id="7" string="issued" lemma="issue" stem="issu" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="flat" lemma="flat" stem="flat" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="denials" lemma="denial" stem="denial" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="press" lemma="press" stem="press" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="went" lemma="go" stem="went" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="speculate" lemma="speculate" stem="specul" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="speculation" lemma="speculation" stem="specul" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC And) (SBAR (WHADVP (WRB when)) (S (NP (NP (NNP Taylor) (POS 's)) (NNS publicists)) (ADVP (RB first)) (VP (VBD issued) (NP (JJ flat) (NNS denials))))) (, ,) (NP (DT the) (NN press)) (VP (VBD went) (PP (IN on)) (S (VP (TO to) (VP (VB speculate) (PP (IN about) (NP (DT the) (NN speculation))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="flat denials" type="NP">
          <tokens>
            <token id="8" string="flat" />
            <token id="9" string="denials" />
          </tokens>
        </chunking>
        <chunking id="2" string="Taylor 's publicists" type="NP">
          <tokens>
            <token id="3" string="Taylor" />
            <token id="4" string="'s" />
            <token id="5" string="publicists" />
          </tokens>
        </chunking>
        <chunking id="3" string="went on to speculate about the speculation" type="VP">
          <tokens>
            <token id="13" string="went" />
            <token id="14" string="on" />
            <token id="15" string="to" />
            <token id="16" string="speculate" />
            <token id="17" string="about" />
            <token id="18" string="the" />
            <token id="19" string="speculation" />
          </tokens>
        </chunking>
        <chunking id="4" string="to speculate about the speculation" type="VP">
          <tokens>
            <token id="15" string="to" />
            <token id="16" string="speculate" />
            <token id="17" string="about" />
            <token id="18" string="the" />
            <token id="19" string="speculation" />
          </tokens>
        </chunking>
        <chunking id="5" string="when Taylor 's publicists first issued flat denials" type="SBAR">
          <tokens>
            <token id="2" string="when" />
            <token id="3" string="Taylor" />
            <token id="4" string="'s" />
            <token id="5" string="publicists" />
            <token id="6" string="first" />
            <token id="7" string="issued" />
            <token id="8" string="flat" />
            <token id="9" string="denials" />
          </tokens>
        </chunking>
        <chunking id="6" string="issued flat denials" type="VP">
          <tokens>
            <token id="7" string="issued" />
            <token id="8" string="flat" />
            <token id="9" string="denials" />
          </tokens>
        </chunking>
        <chunking id="7" string="speculate about the speculation" type="VP">
          <tokens>
            <token id="16" string="speculate" />
            <token id="17" string="about" />
            <token id="18" string="the" />
            <token id="19" string="speculation" />
          </tokens>
        </chunking>
        <chunking id="8" string="Taylor 's" type="NP">
          <tokens>
            <token id="3" string="Taylor" />
            <token id="4" string="'s" />
          </tokens>
        </chunking>
        <chunking id="9" string="the speculation" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="speculation" />
          </tokens>
        </chunking>
        <chunking id="10" string="when" type="WHADVP">
          <tokens>
            <token id="2" string="when" />
          </tokens>
        </chunking>
        <chunking id="11" string="the press" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="press" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="13">went</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">issued</governor>
          <dependent id="2">when</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">publicists</governor>
          <dependent id="3">Taylor</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">Taylor</governor>
          <dependent id="4">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">issued</governor>
          <dependent id="5">publicists</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">issued</governor>
          <dependent id="6">first</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="13">went</governor>
          <dependent id="7">issued</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">denials</governor>
          <dependent id="8">flat</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">issued</governor>
          <dependent id="9">denials</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">press</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">went</governor>
          <dependent id="12">press</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">went</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">went</governor>
          <dependent id="14">on</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">speculate</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="13">went</governor>
          <dependent id="16">speculate</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">speculation</governor>
          <dependent id="17">about</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">speculation</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">speculate</governor>
          <dependent id="19">speculation</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="6" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="Taylor" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Taylor" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>Did the AIDS rumors start because of Taylor&amp;apost;s ballyhooed friendship with publishing titan Malcolm Forbes, whose recent death touched off reports about his alleged homosexuality?</content>
      <tokens>
        <token id="1" string="Did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="AIDS" lemma="AIDS" stem="aids" pos="NNP" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="4" string="rumors" lemma="rumor" stem="rumor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="start" lemma="start" stem="start" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Taylor" lemma="Taylor" stem="taylor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="9" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="ballyhooed" lemma="ballyhoo" stem="ballyhoo" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="friendship" lemma="friendship" stem="friendship" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="publishing" lemma="publishing" stem="publish" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="titan" lemma="titan" stem="titan" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="Malcolm" lemma="Malcolm" stem="malcolm" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="16" string="Forbes" lemma="Forbes" stem="forb" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="whose" lemma="whose" stem="whose" pos="WP$" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="recent" lemma="recent" stem="recent" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="death" lemma="death" stem="death" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="touched" lemma="touch" stem="touch" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="off" lemma="off" stem="off" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="reports" lemma="report" stem="report" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="alleged" lemma="alleged" stem="alleg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="homosexuality" lemma="homosexuality" stem="homosexu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (VP (VBD Did) (SBAR (S (NP (DT the) (NNP AIDS) (NNS rumors)) (VP (VBP start) (PP (IN because) (IN of) (NP (NP (NP (NNP Taylor) (POS 's)) (VBN ballyhooed) (NN friendship)) (PP (IN with) (NP (NP (NN publishing) (NN titan) (NNP Malcolm) (NNP Forbes)) (, ,) (SBAR (WP$ whose) (S (NP (JJ recent) (NN death)) (VP (VBD touched) (PRT (RP off)) (NP (NP (NNS reports)) (PP (IN about) (NP (PRP$ his) (JJ alleged) (NN homosexuality))))))))))))))) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Did the AIDS rumors start because of Taylor 's ballyhooed friendship with publishing titan Malcolm Forbes , whose recent death touched off reports about his alleged homosexuality" type="VP">
          <tokens>
            <token id="1" string="Did" />
            <token id="2" string="the" />
            <token id="3" string="AIDS" />
            <token id="4" string="rumors" />
            <token id="5" string="start" />
            <token id="6" string="because" />
            <token id="7" string="of" />
            <token id="8" string="Taylor" />
            <token id="9" string="'s" />
            <token id="10" string="ballyhooed" />
            <token id="11" string="friendship" />
            <token id="12" string="with" />
            <token id="13" string="publishing" />
            <token id="14" string="titan" />
            <token id="15" string="Malcolm" />
            <token id="16" string="Forbes" />
            <token id="17" string="," />
            <token id="18" string="whose" />
            <token id="19" string="recent" />
            <token id="20" string="death" />
            <token id="21" string="touched" />
            <token id="22" string="off" />
            <token id="23" string="reports" />
            <token id="24" string="about" />
            <token id="25" string="his" />
            <token id="26" string="alleged" />
            <token id="27" string="homosexuality" />
          </tokens>
        </chunking>
        <chunking id="2" string="start because of Taylor 's ballyhooed friendship with publishing titan Malcolm Forbes , whose recent death touched off reports about his alleged homosexuality" type="VP">
          <tokens>
            <token id="5" string="start" />
            <token id="6" string="because" />
            <token id="7" string="of" />
            <token id="8" string="Taylor" />
            <token id="9" string="'s" />
            <token id="10" string="ballyhooed" />
            <token id="11" string="friendship" />
            <token id="12" string="with" />
            <token id="13" string="publishing" />
            <token id="14" string="titan" />
            <token id="15" string="Malcolm" />
            <token id="16" string="Forbes" />
            <token id="17" string="," />
            <token id="18" string="whose" />
            <token id="19" string="recent" />
            <token id="20" string="death" />
            <token id="21" string="touched" />
            <token id="22" string="off" />
            <token id="23" string="reports" />
            <token id="24" string="about" />
            <token id="25" string="his" />
            <token id="26" string="alleged" />
            <token id="27" string="homosexuality" />
          </tokens>
        </chunking>
        <chunking id="3" string="whose recent death touched off reports about his alleged homosexuality" type="SBAR">
          <tokens>
            <token id="18" string="whose" />
            <token id="19" string="recent" />
            <token id="20" string="death" />
            <token id="21" string="touched" />
            <token id="22" string="off" />
            <token id="23" string="reports" />
            <token id="24" string="about" />
            <token id="25" string="his" />
            <token id="26" string="alleged" />
            <token id="27" string="homosexuality" />
          </tokens>
        </chunking>
        <chunking id="4" string="reports" type="NP">
          <tokens>
            <token id="23" string="reports" />
          </tokens>
        </chunking>
        <chunking id="5" string="Taylor 's ballyhooed friendship with publishing titan Malcolm Forbes , whose recent death touched off reports about his alleged homosexuality" type="NP">
          <tokens>
            <token id="8" string="Taylor" />
            <token id="9" string="'s" />
            <token id="10" string="ballyhooed" />
            <token id="11" string="friendship" />
            <token id="12" string="with" />
            <token id="13" string="publishing" />
            <token id="14" string="titan" />
            <token id="15" string="Malcolm" />
            <token id="16" string="Forbes" />
            <token id="17" string="," />
            <token id="18" string="whose" />
            <token id="19" string="recent" />
            <token id="20" string="death" />
            <token id="21" string="touched" />
            <token id="22" string="off" />
            <token id="23" string="reports" />
            <token id="24" string="about" />
            <token id="25" string="his" />
            <token id="26" string="alleged" />
            <token id="27" string="homosexuality" />
          </tokens>
        </chunking>
        <chunking id="6" string="reports about his alleged homosexuality" type="NP">
          <tokens>
            <token id="23" string="reports" />
            <token id="24" string="about" />
            <token id="25" string="his" />
            <token id="26" string="alleged" />
            <token id="27" string="homosexuality" />
          </tokens>
        </chunking>
        <chunking id="7" string="the AIDS rumors" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="AIDS" />
            <token id="4" string="rumors" />
          </tokens>
        </chunking>
        <chunking id="8" string="publishing titan Malcolm Forbes" type="NP">
          <tokens>
            <token id="13" string="publishing" />
            <token id="14" string="titan" />
            <token id="15" string="Malcolm" />
            <token id="16" string="Forbes" />
          </tokens>
        </chunking>
        <chunking id="9" string="recent death" type="NP">
          <tokens>
            <token id="19" string="recent" />
            <token id="20" string="death" />
          </tokens>
        </chunking>
        <chunking id="10" string="his alleged homosexuality" type="NP">
          <tokens>
            <token id="25" string="his" />
            <token id="26" string="alleged" />
            <token id="27" string="homosexuality" />
          </tokens>
        </chunking>
        <chunking id="11" string="Taylor 's ballyhooed friendship" type="NP">
          <tokens>
            <token id="8" string="Taylor" />
            <token id="9" string="'s" />
            <token id="10" string="ballyhooed" />
            <token id="11" string="friendship" />
          </tokens>
        </chunking>
        <chunking id="12" string="publishing titan Malcolm Forbes , whose recent death touched off reports about his alleged homosexuality" type="NP">
          <tokens>
            <token id="13" string="publishing" />
            <token id="14" string="titan" />
            <token id="15" string="Malcolm" />
            <token id="16" string="Forbes" />
            <token id="17" string="," />
            <token id="18" string="whose" />
            <token id="19" string="recent" />
            <token id="20" string="death" />
            <token id="21" string="touched" />
            <token id="22" string="off" />
            <token id="23" string="reports" />
            <token id="24" string="about" />
            <token id="25" string="his" />
            <token id="26" string="alleged" />
            <token id="27" string="homosexuality" />
          </tokens>
        </chunking>
        <chunking id="13" string="touched off reports about his alleged homosexuality" type="VP">
          <tokens>
            <token id="21" string="touched" />
            <token id="22" string="off" />
            <token id="23" string="reports" />
            <token id="24" string="about" />
            <token id="25" string="his" />
            <token id="26" string="alleged" />
            <token id="27" string="homosexuality" />
          </tokens>
        </chunking>
        <chunking id="14" string="Taylor 's" type="NP">
          <tokens>
            <token id="8" string="Taylor" />
            <token id="9" string="'s" />
          </tokens>
        </chunking>
        <chunking id="15" string="the AIDS rumors start because of Taylor 's ballyhooed friendship with publishing titan Malcolm Forbes , whose recent death touched off reports about his alleged homosexuality" type="SBAR">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="AIDS" />
            <token id="4" string="rumors" />
            <token id="5" string="start" />
            <token id="6" string="because" />
            <token id="7" string="of" />
            <token id="8" string="Taylor" />
            <token id="9" string="'s" />
            <token id="10" string="ballyhooed" />
            <token id="11" string="friendship" />
            <token id="12" string="with" />
            <token id="13" string="publishing" />
            <token id="14" string="titan" />
            <token id="15" string="Malcolm" />
            <token id="16" string="Forbes" />
            <token id="17" string="," />
            <token id="18" string="whose" />
            <token id="19" string="recent" />
            <token id="20" string="death" />
            <token id="21" string="touched" />
            <token id="22" string="off" />
            <token id="23" string="reports" />
            <token id="24" string="about" />
            <token id="25" string="his" />
            <token id="26" string="alleged" />
            <token id="27" string="homosexuality" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">Did</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">rumors</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">rumors</governor>
          <dependent id="3">AIDS</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">start</governor>
          <dependent id="4">rumors</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="1">Did</governor>
          <dependent id="5">start</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">friendship</governor>
          <dependent id="6">because</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="6">because</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">friendship</governor>
          <dependent id="8">Taylor</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">Taylor</governor>
          <dependent id="9">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">friendship</governor>
          <dependent id="10">ballyhooed</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">start</governor>
          <dependent id="11">friendship</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">Forbes</governor>
          <dependent id="12">with</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Forbes</governor>
          <dependent id="13">publishing</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Forbes</governor>
          <dependent id="14">titan</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Forbes</governor>
          <dependent id="15">Malcolm</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">friendship</governor>
          <dependent id="16">Forbes</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="21">touched</governor>
          <dependent id="18">whose</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">death</governor>
          <dependent id="19">recent</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">touched</governor>
          <dependent id="20">death</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="16">Forbes</governor>
          <dependent id="21">touched</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="21">touched</governor>
          <dependent id="22">off</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">touched</governor>
          <dependent id="23">reports</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">homosexuality</governor>
          <dependent id="24">about</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="27">homosexuality</governor>
          <dependent id="25">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">homosexuality</governor>
          <dependent id="26">alleged</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">reports</governor>
          <dependent id="27">homosexuality</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Malcolm Forbes" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="Malcolm" />
            <token id="16" string="Forbes" />
          </tokens>
        </entity>
        <entity id="2" string="Taylor" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Taylor" />
          </tokens>
        </entity>
        <entity id="3" string="AIDS" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="3" string="AIDS" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>Or was it because of her reputation as a major fund-raiser for the disease?</content>
      <tokens>
        <token id="1" string="Or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="reputation" lemma="reputation" stem="reput" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="major" lemma="major" stem="major" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="fund-raiser" lemma="fund-raiser" stem="fund-rais" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="15" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC Or) (VP (VBD was) (NP (PRP it)) (PP (IN because) (IN of) (NP (NP (PRP$ her) (NN reputation)) (PP (IN as) (NP (NP (DT a) (JJ major) (NN fund-raiser)) (PP (IN for) (NP (DT the) (NN disease)))))))) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the disease" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="disease" />
          </tokens>
        </chunking>
        <chunking id="2" string="it" type="NP">
          <tokens>
            <token id="3" string="it" />
          </tokens>
        </chunking>
        <chunking id="3" string="her reputation as a major fund-raiser for the disease" type="NP">
          <tokens>
            <token id="6" string="her" />
            <token id="7" string="reputation" />
            <token id="8" string="as" />
            <token id="9" string="a" />
            <token id="10" string="major" />
            <token id="11" string="fund-raiser" />
            <token id="12" string="for" />
            <token id="13" string="the" />
            <token id="14" string="disease" />
          </tokens>
        </chunking>
        <chunking id="4" string="was it because of her reputation as a major fund-raiser for the disease" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="it" />
            <token id="4" string="because" />
            <token id="5" string="of" />
            <token id="6" string="her" />
            <token id="7" string="reputation" />
            <token id="8" string="as" />
            <token id="9" string="a" />
            <token id="10" string="major" />
            <token id="11" string="fund-raiser" />
            <token id="12" string="for" />
            <token id="13" string="the" />
            <token id="14" string="disease" />
          </tokens>
        </chunking>
        <chunking id="5" string="a major fund-raiser" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="major" />
            <token id="11" string="fund-raiser" />
          </tokens>
        </chunking>
        <chunking id="6" string="her reputation" type="NP">
          <tokens>
            <token id="6" string="her" />
            <token id="7" string="reputation" />
          </tokens>
        </chunking>
        <chunking id="7" string="a major fund-raiser for the disease" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="major" />
            <token id="11" string="fund-raiser" />
            <token id="12" string="for" />
            <token id="13" string="the" />
            <token id="14" string="disease" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="3">it</governor>
          <dependent id="1">Or</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="3">it</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">it</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">reputation</governor>
          <dependent id="4">because</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="4">because</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">reputation</governor>
          <dependent id="6">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">it</governor>
          <dependent id="7">reputation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">fund-raiser</governor>
          <dependent id="8">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">fund-raiser</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">fund-raiser</governor>
          <dependent id="10">major</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">reputation</governor>
          <dependent id="11">fund-raiser</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">disease</governor>
          <dependent id="12">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">disease</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">fund-raiser</governor>
          <dependent id="14">disease</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="14" string="disease" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>Or because one of her doctors, Michael Roth, was a renowned AIDS specialist -- even though Roth was supervising her treatment for drug and alcohol addiction as early as 1983?</content>
      <tokens>
        <token id="1" string="Or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="doctors" lemma="doctor" stem="doctor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Michael" lemma="Michael" stem="michael" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="9" string="Roth" lemma="Roth" stem="roth" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="renowned" lemma="renowned" stem="renown" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="AIDS" lemma="aids" stem="aids" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="15" string="specialist" lemma="specialist" stem="specialist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="though" lemma="though" stem="though" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="Roth" lemma="Roth" stem="roth" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="20" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="supervising" lemma="supervise" stem="supervis" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="treatment" lemma="treatment" stem="treatment" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="drug" lemma="drug" stem="drug" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="alcohol" lemma="alcohol" stem="alcohol" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="addiction" lemma="addiction" stem="addict" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="early" lemma="early" stem="earli" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="1983" lemma="1983" stem="1983" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="33" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (FRAG (CC Or) (SBAR (IN because) (S (NP (NP (CD one)) (PP (IN of) (NP (NP (PRP$ her) (NNS doctors)) (, ,) (NP (NNP Michael) (NNP Roth)) (, ,)))) (VP (VBD was) (NP (NP (DT a) (JJ renowned) (NN AIDS) (NN specialist)) (PRN (: --) (SBAR (RB even) (IN though) (S (NP (NNP Roth)) (VP (VBD was) (VP (VBG supervising) (NP (PRP$ her) (NN treatment)) (PP (IN for) (NP (UCP (NN drug) (CC and) (NN alcohol)) (NN addiction)))))))) (PP (IN as) (NP (NP (JJ early)) (PP (IN as) (NP (CD 1983))))))))) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="because one of her doctors , Michael Roth , was a renowned AIDS specialist -- even though Roth was supervising her treatment for drug and alcohol addiction as early as 1983" type="SBAR">
          <tokens>
            <token id="2" string="because" />
            <token id="3" string="one" />
            <token id="4" string="of" />
            <token id="5" string="her" />
            <token id="6" string="doctors" />
            <token id="7" string="," />
            <token id="8" string="Michael" />
            <token id="9" string="Roth" />
            <token id="10" string="," />
            <token id="11" string="was" />
            <token id="12" string="a" />
            <token id="13" string="renowned" />
            <token id="14" string="AIDS" />
            <token id="15" string="specialist" />
            <token id="16" string="--" />
            <token id="17" string="even" />
            <token id="18" string="though" />
            <token id="19" string="Roth" />
            <token id="20" string="was" />
            <token id="21" string="supervising" />
            <token id="22" string="her" />
            <token id="23" string="treatment" />
            <token id="24" string="for" />
            <token id="25" string="drug" />
            <token id="26" string="and" />
            <token id="27" string="alcohol" />
            <token id="28" string="addiction" />
            <token id="29" string="as" />
            <token id="30" string="early" />
            <token id="31" string="as" />
            <token id="32" string="1983" />
          </tokens>
        </chunking>
        <chunking id="2" string="supervising her treatment for drug and alcohol addiction" type="VP">
          <tokens>
            <token id="21" string="supervising" />
            <token id="22" string="her" />
            <token id="23" string="treatment" />
            <token id="24" string="for" />
            <token id="25" string="drug" />
            <token id="26" string="and" />
            <token id="27" string="alcohol" />
            <token id="28" string="addiction" />
          </tokens>
        </chunking>
        <chunking id="3" string="drug and alcohol addiction" type="NP">
          <tokens>
            <token id="25" string="drug" />
            <token id="26" string="and" />
            <token id="27" string="alcohol" />
            <token id="28" string="addiction" />
          </tokens>
        </chunking>
        <chunking id="4" string="even though Roth was supervising her treatment for drug and alcohol addiction" type="SBAR">
          <tokens>
            <token id="17" string="even" />
            <token id="18" string="though" />
            <token id="19" string="Roth" />
            <token id="20" string="was" />
            <token id="21" string="supervising" />
            <token id="22" string="her" />
            <token id="23" string="treatment" />
            <token id="24" string="for" />
            <token id="25" string="drug" />
            <token id="26" string="and" />
            <token id="27" string="alcohol" />
            <token id="28" string="addiction" />
          </tokens>
        </chunking>
        <chunking id="5" string="one" type="NP">
          <tokens>
            <token id="3" string="one" />
          </tokens>
        </chunking>
        <chunking id="6" string="Michael Roth" type="NP">
          <tokens>
            <token id="8" string="Michael" />
            <token id="9" string="Roth" />
          </tokens>
        </chunking>
        <chunking id="7" string="was a renowned AIDS specialist -- even though Roth was supervising her treatment for drug and alcohol addiction as early as 1983" type="VP">
          <tokens>
            <token id="11" string="was" />
            <token id="12" string="a" />
            <token id="13" string="renowned" />
            <token id="14" string="AIDS" />
            <token id="15" string="specialist" />
            <token id="16" string="--" />
            <token id="17" string="even" />
            <token id="18" string="though" />
            <token id="19" string="Roth" />
            <token id="20" string="was" />
            <token id="21" string="supervising" />
            <token id="22" string="her" />
            <token id="23" string="treatment" />
            <token id="24" string="for" />
            <token id="25" string="drug" />
            <token id="26" string="and" />
            <token id="27" string="alcohol" />
            <token id="28" string="addiction" />
            <token id="29" string="as" />
            <token id="30" string="early" />
            <token id="31" string="as" />
            <token id="32" string="1983" />
          </tokens>
        </chunking>
        <chunking id="8" string="her doctors" type="NP">
          <tokens>
            <token id="5" string="her" />
            <token id="6" string="doctors" />
          </tokens>
        </chunking>
        <chunking id="9" string="her doctors , Michael Roth ," type="NP">
          <tokens>
            <token id="5" string="her" />
            <token id="6" string="doctors" />
            <token id="7" string="," />
            <token id="8" string="Michael" />
            <token id="9" string="Roth" />
            <token id="10" string="," />
          </tokens>
        </chunking>
        <chunking id="10" string="early as 1983" type="NP">
          <tokens>
            <token id="30" string="early" />
            <token id="31" string="as" />
            <token id="32" string="1983" />
          </tokens>
        </chunking>
        <chunking id="11" string="1983" type="NP">
          <tokens>
            <token id="32" string="1983" />
          </tokens>
        </chunking>
        <chunking id="12" string="Roth" type="NP">
          <tokens>
            <token id="19" string="Roth" />
          </tokens>
        </chunking>
        <chunking id="13" string="a renowned AIDS specialist" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="renowned" />
            <token id="14" string="AIDS" />
            <token id="15" string="specialist" />
          </tokens>
        </chunking>
        <chunking id="14" string="her treatment" type="NP">
          <tokens>
            <token id="22" string="her" />
            <token id="23" string="treatment" />
          </tokens>
        </chunking>
        <chunking id="15" string="one of her doctors , Michael Roth ," type="NP">
          <tokens>
            <token id="3" string="one" />
            <token id="4" string="of" />
            <token id="5" string="her" />
            <token id="6" string="doctors" />
            <token id="7" string="," />
            <token id="8" string="Michael" />
            <token id="9" string="Roth" />
            <token id="10" string="," />
          </tokens>
        </chunking>
        <chunking id="16" string="a renowned AIDS specialist -- even though Roth was supervising her treatment for drug and alcohol addiction as early as 1983" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="renowned" />
            <token id="14" string="AIDS" />
            <token id="15" string="specialist" />
            <token id="16" string="--" />
            <token id="17" string="even" />
            <token id="18" string="though" />
            <token id="19" string="Roth" />
            <token id="20" string="was" />
            <token id="21" string="supervising" />
            <token id="22" string="her" />
            <token id="23" string="treatment" />
            <token id="24" string="for" />
            <token id="25" string="drug" />
            <token id="26" string="and" />
            <token id="27" string="alcohol" />
            <token id="28" string="addiction" />
            <token id="29" string="as" />
            <token id="30" string="early" />
            <token id="31" string="as" />
            <token id="32" string="1983" />
          </tokens>
        </chunking>
        <chunking id="17" string="was supervising her treatment for drug and alcohol addiction" type="VP">
          <tokens>
            <token id="20" string="was" />
            <token id="21" string="supervising" />
            <token id="22" string="her" />
            <token id="23" string="treatment" />
            <token id="24" string="for" />
            <token id="25" string="drug" />
            <token id="26" string="and" />
            <token id="27" string="alcohol" />
            <token id="28" string="addiction" />
          </tokens>
        </chunking>
        <chunking id="18" string="early" type="NP">
          <tokens>
            <token id="30" string="early" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="15">specialist</governor>
          <dependent id="1">Or</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">specialist</governor>
          <dependent id="2">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">specialist</governor>
          <dependent id="3">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">doctors</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">doctors</governor>
          <dependent id="5">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">one</governor>
          <dependent id="6">doctors</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Roth</governor>
          <dependent id="8">Michael</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="6">doctors</governor>
          <dependent id="9">Roth</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="15">specialist</governor>
          <dependent id="11">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">specialist</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">specialist</governor>
          <dependent id="13">renowned</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">specialist</governor>
          <dependent id="14">AIDS</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">specialist</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="21">supervising</governor>
          <dependent id="17">even</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">supervising</governor>
          <dependent id="18">though</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">supervising</governor>
          <dependent id="19">Roth</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">supervising</governor>
          <dependent id="20">was</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="15">specialist</governor>
          <dependent id="21">supervising</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="23">treatment</governor>
          <dependent id="22">her</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">supervising</governor>
          <dependent id="23">treatment</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">addiction</governor>
          <dependent id="24">for</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">addiction</governor>
          <dependent id="25">drug</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="25">drug</governor>
          <dependent id="26">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="25">drug</governor>
          <dependent id="27">alcohol</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">supervising</governor>
          <dependent id="28">addiction</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">early</governor>
          <dependent id="29">as</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">specialist</governor>
          <dependent id="30">early</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">1983</governor>
          <dependent id="31">as</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">early</governor>
          <dependent id="32">1983</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="Michael Roth" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Michael" />
            <token id="9" string="Roth" />
          </tokens>
        </entity>
        <entity id="3" string="1983" type="DATE" score="0.0">
          <tokens>
            <token id="32" string="1983" />
          </tokens>
        </entity>
        <entity id="4" string="Roth" type="PERSON" score="0.0">
          <tokens>
            <token id="19" string="Roth" />
          </tokens>
        </entity>
        <entity id="5" string="AIDS" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="14" string="AIDS" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>&amp;quot;Liz is a national treasure and when she entered the hospital, I thought it was as important as the President of the U.S. going in and we treated it as such.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Liz" lemma="Liz" stem="liz" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="national" lemma="national" stem="nation" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="treasure" lemma="treasure" stem="treasur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="entered" lemma="enter" stem="enter" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="hospital" lemma="hospital" stem="hospit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="thought" lemma="think" stem="thought" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="as" lemma="as" stem="a" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="important" lemma="important" stem="import" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="President" lemma="President" stem="presid" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="true" is_refers="false" />
        <token id="23" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="U.S." lemma="U.S." stem="u.s." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="26" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="28" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="30" string="treated" lemma="treat" stem="treat" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="32" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (NNP Liz)) (VP (VBZ is) (NP (DT a) (JJ national) (NN treasure)))) (CC and) (S (SBAR (WHADVP (WRB when)) (S (NP (PRP she)) (VP (VBD entered) (NP (DT the) (NN hospital))))) (, ,) (NP (PRP I)) (VP (VBD thought) (SBAR (S (S (NP (PRP it)) (VP (VBD was) (ADJP (RB as) (JJ important) (PP (IN as) (NP (NP (DT the) (NNP President)) (PP (IN of) (NP (NP (DT the) (NNP U.S.)) (VP (VBG going) (PP (IN in)))))))))) (CC and) (S (NP (PRP we)) (VP (VBD treated) (NP (PRP it)) (PP (IN as) (NP (JJ such))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is a national treasure" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="a" />
            <token id="5" string="national" />
            <token id="6" string="treasure" />
          </tokens>
        </chunking>
        <chunking id="2" string="a national treasure" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="national" />
            <token id="6" string="treasure" />
          </tokens>
        </chunking>
        <chunking id="3" string="thought it was as important as the President of the U.S. going in and we treated it as such" type="VP">
          <tokens>
            <token id="15" string="thought" />
            <token id="16" string="it" />
            <token id="17" string="was" />
            <token id="18" string="as" />
            <token id="19" string="important" />
            <token id="20" string="as" />
            <token id="21" string="the" />
            <token id="22" string="President" />
            <token id="23" string="of" />
            <token id="24" string="the" />
            <token id="25" string="U.S." />
            <token id="26" string="going" />
            <token id="27" string="in" />
            <token id="28" string="and" />
            <token id="29" string="we" />
            <token id="30" string="treated" />
            <token id="31" string="it" />
            <token id="32" string="as" />
            <token id="33" string="such" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="14" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="the U.S. going in" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="U.S." />
            <token id="26" string="going" />
            <token id="27" string="in" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="16" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="it was as important as the President of the U.S. going in and we treated it as such" type="SBAR">
          <tokens>
            <token id="16" string="it" />
            <token id="17" string="was" />
            <token id="18" string="as" />
            <token id="19" string="important" />
            <token id="20" string="as" />
            <token id="21" string="the" />
            <token id="22" string="President" />
            <token id="23" string="of" />
            <token id="24" string="the" />
            <token id="25" string="U.S." />
            <token id="26" string="going" />
            <token id="27" string="in" />
            <token id="28" string="and" />
            <token id="29" string="we" />
            <token id="30" string="treated" />
            <token id="31" string="it" />
            <token id="32" string="as" />
            <token id="33" string="such" />
          </tokens>
        </chunking>
        <chunking id="8" string="we" type="NP">
          <tokens>
            <token id="29" string="we" />
          </tokens>
        </chunking>
        <chunking id="9" string="when" type="WHADVP">
          <tokens>
            <token id="8" string="when" />
          </tokens>
        </chunking>
        <chunking id="10" string="she" type="NP">
          <tokens>
            <token id="9" string="she" />
          </tokens>
        </chunking>
        <chunking id="11" string="as important as the President of the U.S. going in" type="ADJP">
          <tokens>
            <token id="18" string="as" />
            <token id="19" string="important" />
            <token id="20" string="as" />
            <token id="21" string="the" />
            <token id="22" string="President" />
            <token id="23" string="of" />
            <token id="24" string="the" />
            <token id="25" string="U.S." />
            <token id="26" string="going" />
            <token id="27" string="in" />
          </tokens>
        </chunking>
        <chunking id="12" string="such" type="NP">
          <tokens>
            <token id="33" string="such" />
          </tokens>
        </chunking>
        <chunking id="13" string="was as important as the President of the U.S. going in" type="VP">
          <tokens>
            <token id="17" string="was" />
            <token id="18" string="as" />
            <token id="19" string="important" />
            <token id="20" string="as" />
            <token id="21" string="the" />
            <token id="22" string="President" />
            <token id="23" string="of" />
            <token id="24" string="the" />
            <token id="25" string="U.S." />
            <token id="26" string="going" />
            <token id="27" string="in" />
          </tokens>
        </chunking>
        <chunking id="14" string="treated it as such" type="VP">
          <tokens>
            <token id="30" string="treated" />
            <token id="31" string="it" />
            <token id="32" string="as" />
            <token id="33" string="such" />
          </tokens>
        </chunking>
        <chunking id="15" string="the President" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="President" />
          </tokens>
        </chunking>
        <chunking id="16" string="the U.S." type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="U.S." />
          </tokens>
        </chunking>
        <chunking id="17" string="when she entered the hospital" type="SBAR">
          <tokens>
            <token id="8" string="when" />
            <token id="9" string="she" />
            <token id="10" string="entered" />
            <token id="11" string="the" />
            <token id="12" string="hospital" />
          </tokens>
        </chunking>
        <chunking id="18" string="the President of the U.S. going in" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="President" />
            <token id="23" string="of" />
            <token id="24" string="the" />
            <token id="25" string="U.S." />
            <token id="26" string="going" />
            <token id="27" string="in" />
          </tokens>
        </chunking>
        <chunking id="19" string="entered the hospital" type="VP">
          <tokens>
            <token id="10" string="entered" />
            <token id="11" string="the" />
            <token id="12" string="hospital" />
          </tokens>
        </chunking>
        <chunking id="20" string="Liz" type="NP">
          <tokens>
            <token id="2" string="Liz" />
          </tokens>
        </chunking>
        <chunking id="21" string="going in" type="VP">
          <tokens>
            <token id="26" string="going" />
            <token id="27" string="in" />
          </tokens>
        </chunking>
        <chunking id="22" string="the hospital" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="hospital" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">treasure</governor>
          <dependent id="2">Liz</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">treasure</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">treasure</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">treasure</governor>
          <dependent id="5">national</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">treasure</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">treasure</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">entered</governor>
          <dependent id="8">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">entered</governor>
          <dependent id="9">she</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="15">thought</governor>
          <dependent id="10">entered</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">hospital</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">entered</governor>
          <dependent id="12">hospital</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">thought</governor>
          <dependent id="14">I</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">treasure</governor>
          <dependent id="15">thought</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">important</governor>
          <dependent id="16">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="19">important</governor>
          <dependent id="17">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">important</governor>
          <dependent id="18">as</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="15">thought</governor>
          <dependent id="19">important</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">President</governor>
          <dependent id="20">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">President</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">important</governor>
          <dependent id="22">President</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">U.S.</governor>
          <dependent id="23">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">U.S.</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">President</governor>
          <dependent id="25">U.S.</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="25">U.S.</governor>
          <dependent id="26">going</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">going</governor>
          <dependent id="27">in</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="19">important</governor>
          <dependent id="28">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="30">treated</governor>
          <dependent id="29">we</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">important</governor>
          <dependent id="30">treated</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="30">treated</governor>
          <dependent id="31">it</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">such</governor>
          <dependent id="32">as</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">treated</governor>
          <dependent id="33">such</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="U.S." type="LOCATION" score="0.0">
          <tokens>
            <token id="25" string="U.S." />
          </tokens>
        </entity>
        <entity id="2" string="Liz" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Liz" />
          </tokens>
        </entity>
        <entity id="3" string="President" type="TITLE" score="0.0">
          <tokens>
            <token id="22" string="President" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>Liz is as close to American royalty as you can have, and our readers . . . in the heartland . . . they&amp;apost;re living and dying with her,&amp;quot; said Barry Levine, Hollywood bureau chief of the Star, which featured a cover photograph of Liz, hooked up to an intravenous tube and oxygen mask, being transferred from the Marina del Rey hospital to St. John&amp;apost;s.</content>
      <tokens>
        <token id="1" string="Liz" lemma="Liz" stem="liz" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="as" lemma="as" stem="a" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="close" lemma="close" stem="close" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="American" lemma="american" stem="american" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="7" string="royalty" lemma="royalty" stem="royalti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="our" lemma="we" stem="our" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="readers" lemma="reader" stem="reader" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string=". . ." lemma="..." stem=". . ." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="heartland" lemma="heartland" stem="heartland" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string=". . ." lemma="..." stem=". . ." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="'re" lemma="be" stem="'re" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="living" lemma="live" stem="live" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="dying" lemma="die" stem="dy" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="her" lemma="she" stem="her" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="28" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="Barry" lemma="Barry" stem="barri" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="32" string="Levine" lemma="Levine" stem="levin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="33" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="34" string="Hollywood" lemma="Hollywood" stem="hollywood" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="35" string="bureau" lemma="bureau" stem="bureau" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="36" string="chief" lemma="chief" stem="chief" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="37" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="38" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="39" string="Star" lemma="Star" stem="star" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="40" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="41" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="42" string="featured" lemma="feature" stem="featur" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="43" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="44" string="cover" lemma="cover" stem="cover" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="45" string="photograph" lemma="photograph" stem="photograph" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="46" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="47" string="Liz" lemma="Liz" stem="liz" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="48" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="49" string="hooked" lemma="hook" stem="hook" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="50" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="51" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="52" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="53" string="intravenous" lemma="intravenous" stem="intraven" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="54" string="tube" lemma="tube" stem="tube" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="55" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="56" string="oxygen" lemma="oxygen" stem="oxygen" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="57" string="mask" lemma="mask" stem="mask" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="58" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="59" string="being" lemma="be" stem="be" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="60" string="transferred" lemma="transfer" stem="transfer" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="61" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="62" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="63" string="Marina" lemma="Marina" stem="marina" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="64" string="del" lemma="del" stem="del" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="65" string="Rey" lemma="Rey" stem="rei" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="66" string="hospital" lemma="hospital" stem="hospit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="67" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="68" string="St." lemma="St." stem="st." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="69" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="70" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="71" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (S (NP (NNP Liz)) (VP (VBZ is) (ADJP (RB as) (JJ close) (PP (TO to) (NP (NP (NP (JJ American) (NN royalty)) (SBAR (IN as) (S (NP (PRP you)) (VP (MD can) (VP (VB have)))))) (, ,) (CC and) (NP (NP (PRP$ our) (NNS readers)) (SBAR (S (: ...) (PP (IN in) (NP (DT the) (NN heartland))) (: ...) (NP (PRP they)) (VP (VBP 're) (VP (VBG living) (CC and) (VBG dying) (PP (IN with) (NP (PRP her))))))))))))) (, ,) ('' '') (VP (VBD said)) (NP (NP (NNP Barry) (NNP Levine)) (, ,) (NP (NP (NNP Hollywood) (NN bureau) (NN chief)) (PP (IN of) (NP (DT the) (NNP Star)))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VP (VBD featured) (NP (NP (DT a) (NN cover) (NN photograph)) (PP (IN of) (NP (NNP Liz))))) (, ,) (VP (VBD hooked) (PRT (RP up)) (PP (TO to) (NP (DT an) (JJ intravenous) (NN tube) (CC and) (NN oxygen) (NN mask)))) (, ,) (S (VP (VBG being) (VP (VBN transferred) (PP (IN from) (NP (NP (DT the) (NNP Marina) (NNP del) (NNP Rey) (NN hospital)) (PP (TO to) (NP (NNP St.) (NNP John) (POS 's)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="living and dying with her" type="VP">
          <tokens>
            <token id="23" string="living" />
            <token id="24" string="and" />
            <token id="25" string="dying" />
            <token id="26" string="with" />
            <token id="27" string="her" />
          </tokens>
        </chunking>
        <chunking id="2" string="Barry Levine" type="NP">
          <tokens>
            <token id="31" string="Barry" />
            <token id="32" string="Levine" />
          </tokens>
        </chunking>
        <chunking id="3" string="American royalty as you can have , and our readers ... in the heartland ... they 're living and dying with her" type="NP">
          <tokens>
            <token id="6" string="American" />
            <token id="7" string="royalty" />
            <token id="8" string="as" />
            <token id="9" string="you" />
            <token id="10" string="can" />
            <token id="11" string="have" />
            <token id="12" string="," />
            <token id="13" string="and" />
            <token id="14" string="our" />
            <token id="15" string="readers" />
            <token id="16" string=". . ." />
            <token id="17" string="in" />
            <token id="18" string="the" />
            <token id="19" string="heartland" />
            <token id="20" string=". . ." />
            <token id="21" string="they" />
            <token id="22" string="'re" />
            <token id="23" string="living" />
            <token id="24" string="and" />
            <token id="25" string="dying" />
            <token id="26" string="with" />
            <token id="27" string="her" />
          </tokens>
        </chunking>
        <chunking id="4" string="St. John 's" type="NP">
          <tokens>
            <token id="68" string="St." />
            <token id="69" string="John" />
            <token id="70" string="'s" />
          </tokens>
        </chunking>
        <chunking id="5" string="American royalty" type="NP">
          <tokens>
            <token id="6" string="American" />
            <token id="7" string="royalty" />
          </tokens>
        </chunking>
        <chunking id="6" string="the Marina del Rey hospital to St. John 's" type="NP">
          <tokens>
            <token id="62" string="the" />
            <token id="63" string="Marina" />
            <token id="64" string="del" />
            <token id="65" string="Rey" />
            <token id="66" string="hospital" />
            <token id="67" string="to" />
            <token id="68" string="St." />
            <token id="69" string="John" />
            <token id="70" string="'s" />
          </tokens>
        </chunking>
        <chunking id="7" string="Barry Levine , Hollywood bureau chief of the Star , which featured a cover photograph of Liz , hooked up to an intravenous tube and oxygen mask , being transferred from the Marina del Rey hospital to St. John 's" type="NP">
          <tokens>
            <token id="31" string="Barry" />
            <token id="32" string="Levine" />
            <token id="33" string="," />
            <token id="34" string="Hollywood" />
            <token id="35" string="bureau" />
            <token id="36" string="chief" />
            <token id="37" string="of" />
            <token id="38" string="the" />
            <token id="39" string="Star" />
            <token id="40" string="," />
            <token id="41" string="which" />
            <token id="42" string="featured" />
            <token id="43" string="a" />
            <token id="44" string="cover" />
            <token id="45" string="photograph" />
            <token id="46" string="of" />
            <token id="47" string="Liz" />
            <token id="48" string="," />
            <token id="49" string="hooked" />
            <token id="50" string="up" />
            <token id="51" string="to" />
            <token id="52" string="an" />
            <token id="53" string="intravenous" />
            <token id="54" string="tube" />
            <token id="55" string="and" />
            <token id="56" string="oxygen" />
            <token id="57" string="mask" />
            <token id="58" string="," />
            <token id="59" string="being" />
            <token id="60" string="transferred" />
            <token id="61" string="from" />
            <token id="62" string="the" />
            <token id="63" string="Marina" />
            <token id="64" string="del" />
            <token id="65" string="Rey" />
            <token id="66" string="hospital" />
            <token id="67" string="to" />
            <token id="68" string="St." />
            <token id="69" string="John" />
            <token id="70" string="'s" />
          </tokens>
        </chunking>
        <chunking id="8" string="an intravenous tube and oxygen mask" type="NP">
          <tokens>
            <token id="52" string="an" />
            <token id="53" string="intravenous" />
            <token id="54" string="tube" />
            <token id="55" string="and" />
            <token id="56" string="oxygen" />
            <token id="57" string="mask" />
          </tokens>
        </chunking>
        <chunking id="9" string="the heartland" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="heartland" />
          </tokens>
        </chunking>
        <chunking id="10" string="being transferred from the Marina del Rey hospital to St. John 's" type="VP">
          <tokens>
            <token id="59" string="being" />
            <token id="60" string="transferred" />
            <token id="61" string="from" />
            <token id="62" string="the" />
            <token id="63" string="Marina" />
            <token id="64" string="del" />
            <token id="65" string="Rey" />
            <token id="66" string="hospital" />
            <token id="67" string="to" />
            <token id="68" string="St." />
            <token id="69" string="John" />
            <token id="70" string="'s" />
          </tokens>
        </chunking>
        <chunking id="11" string="featured a cover photograph of Liz" type="VP">
          <tokens>
            <token id="42" string="featured" />
            <token id="43" string="a" />
            <token id="44" string="cover" />
            <token id="45" string="photograph" />
            <token id="46" string="of" />
            <token id="47" string="Liz" />
          </tokens>
        </chunking>
        <chunking id="12" string="Liz" type="NP">
          <tokens>
            <token id="1" string="Liz" />
          </tokens>
        </chunking>
        <chunking id="13" string="our readers" type="NP">
          <tokens>
            <token id="14" string="our" />
            <token id="15" string="readers" />
          </tokens>
        </chunking>
        <chunking id="14" string="the Marina del Rey hospital" type="NP">
          <tokens>
            <token id="62" string="the" />
            <token id="63" string="Marina" />
            <token id="64" string="del" />
            <token id="65" string="Rey" />
            <token id="66" string="hospital" />
          </tokens>
        </chunking>
        <chunking id="15" string="Hollywood bureau chief of the Star" type="NP">
          <tokens>
            <token id="34" string="Hollywood" />
            <token id="35" string="bureau" />
            <token id="36" string="chief" />
            <token id="37" string="of" />
            <token id="38" string="the" />
            <token id="39" string="Star" />
          </tokens>
        </chunking>
        <chunking id="16" string="our readers ... in the heartland ... they 're living and dying with her" type="NP">
          <tokens>
            <token id="14" string="our" />
            <token id="15" string="readers" />
            <token id="16" string=". . ." />
            <token id="17" string="in" />
            <token id="18" string="the" />
            <token id="19" string="heartland" />
            <token id="20" string=". . ." />
            <token id="21" string="they" />
            <token id="22" string="'re" />
            <token id="23" string="living" />
            <token id="24" string="and" />
            <token id="25" string="dying" />
            <token id="26" string="with" />
            <token id="27" string="her" />
          </tokens>
        </chunking>
        <chunking id="17" string="transferred from the Marina del Rey hospital to St. John 's" type="VP">
          <tokens>
            <token id="60" string="transferred" />
            <token id="61" string="from" />
            <token id="62" string="the" />
            <token id="63" string="Marina" />
            <token id="64" string="del" />
            <token id="65" string="Rey" />
            <token id="66" string="hospital" />
            <token id="67" string="to" />
            <token id="68" string="St." />
            <token id="69" string="John" />
            <token id="70" string="'s" />
          </tokens>
        </chunking>
        <chunking id="18" string="which featured a cover photograph of Liz , hooked up to an intravenous tube and oxygen mask , being transferred from the Marina del Rey hospital to St. John 's" type="SBAR">
          <tokens>
            <token id="41" string="which" />
            <token id="42" string="featured" />
            <token id="43" string="a" />
            <token id="44" string="cover" />
            <token id="45" string="photograph" />
            <token id="46" string="of" />
            <token id="47" string="Liz" />
            <token id="48" string="," />
            <token id="49" string="hooked" />
            <token id="50" string="up" />
            <token id="51" string="to" />
            <token id="52" string="an" />
            <token id="53" string="intravenous" />
            <token id="54" string="tube" />
            <token id="55" string="and" />
            <token id="56" string="oxygen" />
            <token id="57" string="mask" />
            <token id="58" string="," />
            <token id="59" string="being" />
            <token id="60" string="transferred" />
            <token id="61" string="from" />
            <token id="62" string="the" />
            <token id="63" string="Marina" />
            <token id="64" string="del" />
            <token id="65" string="Rey" />
            <token id="66" string="hospital" />
            <token id="67" string="to" />
            <token id="68" string="St." />
            <token id="69" string="John" />
            <token id="70" string="'s" />
          </tokens>
        </chunking>
        <chunking id="19" string="... in the heartland ... they 're living and dying with her" type="SBAR">
          <tokens>
            <token id="16" string=". . ." />
            <token id="17" string="in" />
            <token id="18" string="the" />
            <token id="19" string="heartland" />
            <token id="20" string=". . ." />
            <token id="21" string="they" />
            <token id="22" string="'re" />
            <token id="23" string="living" />
            <token id="24" string="and" />
            <token id="25" string="dying" />
            <token id="26" string="with" />
            <token id="27" string="her" />
          </tokens>
        </chunking>
        <chunking id="20" string="can have" type="VP">
          <tokens>
            <token id="10" string="can" />
            <token id="11" string="have" />
          </tokens>
        </chunking>
        <chunking id="21" string="American royalty as you can have" type="NP">
          <tokens>
            <token id="6" string="American" />
            <token id="7" string="royalty" />
            <token id="8" string="as" />
            <token id="9" string="you" />
            <token id="10" string="can" />
            <token id="11" string="have" />
          </tokens>
        </chunking>
        <chunking id="22" string="they" type="NP">
          <tokens>
            <token id="21" string="they" />
          </tokens>
        </chunking>
        <chunking id="23" string="'re living and dying with her" type="VP">
          <tokens>
            <token id="22" string="'re" />
            <token id="23" string="living" />
            <token id="24" string="and" />
            <token id="25" string="dying" />
            <token id="26" string="with" />
            <token id="27" string="her" />
          </tokens>
        </chunking>
        <chunking id="24" string="Hollywood bureau chief" type="NP">
          <tokens>
            <token id="34" string="Hollywood" />
            <token id="35" string="bureau" />
            <token id="36" string="chief" />
          </tokens>
        </chunking>
        <chunking id="25" string="the Star" type="NP">
          <tokens>
            <token id="38" string="the" />
            <token id="39" string="Star" />
          </tokens>
        </chunking>
        <chunking id="26" string="her" type="NP">
          <tokens>
            <token id="27" string="her" />
          </tokens>
        </chunking>
        <chunking id="27" string="have" type="VP">
          <tokens>
            <token id="11" string="have" />
          </tokens>
        </chunking>
        <chunking id="28" string="as you can have" type="SBAR">
          <tokens>
            <token id="8" string="as" />
            <token id="9" string="you" />
            <token id="10" string="can" />
            <token id="11" string="have" />
          </tokens>
        </chunking>
        <chunking id="29" string="a cover photograph" type="NP">
          <tokens>
            <token id="43" string="a" />
            <token id="44" string="cover" />
            <token id="45" string="photograph" />
          </tokens>
        </chunking>
        <chunking id="30" string="hooked up to an intravenous tube and oxygen mask" type="VP">
          <tokens>
            <token id="49" string="hooked" />
            <token id="50" string="up" />
            <token id="51" string="to" />
            <token id="52" string="an" />
            <token id="53" string="intravenous" />
            <token id="54" string="tube" />
            <token id="55" string="and" />
            <token id="56" string="oxygen" />
            <token id="57" string="mask" />
          </tokens>
        </chunking>
        <chunking id="31" string="a cover photograph of Liz" type="NP">
          <tokens>
            <token id="43" string="a" />
            <token id="44" string="cover" />
            <token id="45" string="photograph" />
            <token id="46" string="of" />
            <token id="47" string="Liz" />
          </tokens>
        </chunking>
        <chunking id="32" string="is as close to American royalty as you can have , and our readers ... in the heartland ... they 're living and dying with her" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="as" />
            <token id="4" string="close" />
            <token id="5" string="to" />
            <token id="6" string="American" />
            <token id="7" string="royalty" />
            <token id="8" string="as" />
            <token id="9" string="you" />
            <token id="10" string="can" />
            <token id="11" string="have" />
            <token id="12" string="," />
            <token id="13" string="and" />
            <token id="14" string="our" />
            <token id="15" string="readers" />
            <token id="16" string=". . ." />
            <token id="17" string="in" />
            <token id="18" string="the" />
            <token id="19" string="heartland" />
            <token id="20" string=". . ." />
            <token id="21" string="they" />
            <token id="22" string="'re" />
            <token id="23" string="living" />
            <token id="24" string="and" />
            <token id="25" string="dying" />
            <token id="26" string="with" />
            <token id="27" string="her" />
          </tokens>
        </chunking>
        <chunking id="33" string="said" type="VP">
          <tokens>
            <token id="30" string="said" />
          </tokens>
        </chunking>
        <chunking id="34" string="featured a cover photograph of Liz , hooked up to an intravenous tube and oxygen mask , being transferred from the Marina del Rey hospital to St. John 's" type="VP">
          <tokens>
            <token id="42" string="featured" />
            <token id="43" string="a" />
            <token id="44" string="cover" />
            <token id="45" string="photograph" />
            <token id="46" string="of" />
            <token id="47" string="Liz" />
            <token id="48" string="," />
            <token id="49" string="hooked" />
            <token id="50" string="up" />
            <token id="51" string="to" />
            <token id="52" string="an" />
            <token id="53" string="intravenous" />
            <token id="54" string="tube" />
            <token id="55" string="and" />
            <token id="56" string="oxygen" />
            <token id="57" string="mask" />
            <token id="58" string="," />
            <token id="59" string="being" />
            <token id="60" string="transferred" />
            <token id="61" string="from" />
            <token id="62" string="the" />
            <token id="63" string="Marina" />
            <token id="64" string="del" />
            <token id="65" string="Rey" />
            <token id="66" string="hospital" />
            <token id="67" string="to" />
            <token id="68" string="St." />
            <token id="69" string="John" />
            <token id="70" string="'s" />
          </tokens>
        </chunking>
        <chunking id="35" string="as close to American royalty as you can have , and our readers ... in the heartland ... they 're living and dying with her" type="ADJP">
          <tokens>
            <token id="3" string="as" />
            <token id="4" string="close" />
            <token id="5" string="to" />
            <token id="6" string="American" />
            <token id="7" string="royalty" />
            <token id="8" string="as" />
            <token id="9" string="you" />
            <token id="10" string="can" />
            <token id="11" string="have" />
            <token id="12" string="," />
            <token id="13" string="and" />
            <token id="14" string="our" />
            <token id="15" string="readers" />
            <token id="16" string=". . ." />
            <token id="17" string="in" />
            <token id="18" string="the" />
            <token id="19" string="heartland" />
            <token id="20" string=". . ." />
            <token id="21" string="they" />
            <token id="22" string="'re" />
            <token id="23" string="living" />
            <token id="24" string="and" />
            <token id="25" string="dying" />
            <token id="26" string="with" />
            <token id="27" string="her" />
          </tokens>
        </chunking>
        <chunking id="36" string="you" type="NP">
          <tokens>
            <token id="9" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="7">royalty</governor>
          <dependent id="1">Liz</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">royalty</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">royalty</governor>
          <dependent id="3">as</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">royalty</governor>
          <dependent id="4">close</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="4">close</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">royalty</governor>
          <dependent id="6">American</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="30">said</governor>
          <dependent id="7">royalty</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">have</governor>
          <dependent id="8">as</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">have</governor>
          <dependent id="9">you</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">have</governor>
          <dependent id="10">can</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="7">royalty</governor>
          <dependent id="11">have</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">royalty</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">readers</governor>
          <dependent id="14">our</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">royalty</governor>
          <dependent id="15">readers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">heartland</governor>
          <dependent id="17">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">heartland</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">living</governor>
          <dependent id="19">heartland</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">living</governor>
          <dependent id="21">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="23">living</governor>
          <dependent id="22">'re</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="15">readers</governor>
          <dependent id="23">living</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="23">living</governor>
          <dependent id="24">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="23">living</governor>
          <dependent id="25">dying</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">her</governor>
          <dependent id="26">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">living</governor>
          <dependent id="27">her</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="30">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="32">Levine</governor>
          <dependent id="31">Barry</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="30">said</governor>
          <dependent id="32">Levine</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="36">chief</governor>
          <dependent id="34">Hollywood</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="36">chief</governor>
          <dependent id="35">bureau</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="32">Levine</governor>
          <dependent id="36">chief</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">Star</governor>
          <dependent id="37">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="39">Star</governor>
          <dependent id="38">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="36">chief</governor>
          <dependent id="39">Star</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="42">featured</governor>
          <dependent id="41">which</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="32">Levine</governor>
          <dependent id="42">featured</dependent>
        </dependency>
        <dependency type="det">
          <governor id="45">photograph</governor>
          <dependent id="43">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="45">photograph</governor>
          <dependent id="44">cover</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="42">featured</governor>
          <dependent id="45">photograph</dependent>
        </dependency>
        <dependency type="case">
          <governor id="47">Liz</governor>
          <dependent id="46">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="45">photograph</governor>
          <dependent id="47">Liz</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="42">featured</governor>
          <dependent id="49">hooked</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="49">hooked</governor>
          <dependent id="50">up</dependent>
        </dependency>
        <dependency type="case">
          <governor id="54">tube</governor>
          <dependent id="51">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="54">tube</governor>
          <dependent id="52">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="54">tube</governor>
          <dependent id="53">intravenous</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="49">hooked</governor>
          <dependent id="54">tube</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="54">tube</governor>
          <dependent id="55">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="57">mask</governor>
          <dependent id="56">oxygen</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="54">tube</governor>
          <dependent id="57">mask</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="60">transferred</governor>
          <dependent id="59">being</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="42">featured</governor>
          <dependent id="60">transferred</dependent>
        </dependency>
        <dependency type="case">
          <governor id="66">hospital</governor>
          <dependent id="61">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="66">hospital</governor>
          <dependent id="62">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="66">hospital</governor>
          <dependent id="63">Marina</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="66">hospital</governor>
          <dependent id="64">del</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="66">hospital</governor>
          <dependent id="65">Rey</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="60">transferred</governor>
          <dependent id="66">hospital</dependent>
        </dependency>
        <dependency type="case">
          <governor id="69">John</governor>
          <dependent id="67">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="69">John</governor>
          <dependent id="68">St.</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="66">hospital</governor>
          <dependent id="69">John</dependent>
        </dependency>
        <dependency type="case">
          <governor id="69">John</governor>
          <dependent id="70">'s</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Hollywood" type="LOCATION" score="0.0">
          <tokens>
            <token id="34" string="Hollywood" />
          </tokens>
        </entity>
        <entity id="2" string="St. John" type="PERSON" score="0.0">
          <tokens>
            <token id="68" string="St." />
            <token id="69" string="John" />
          </tokens>
        </entity>
        <entity id="3" string="Barry Levine" type="PERSON" score="0.0">
          <tokens>
            <token id="31" string="Barry" />
            <token id="32" string="Levine" />
          </tokens>
        </entity>
        <entity id="4" string="American" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="6" string="American" />
          </tokens>
        </entity>
        <entity id="5" string="Marina" type="LOCATION" score="0.0">
          <tokens>
            <token id="63" string="Marina" />
          </tokens>
        </entity>
        <entity id="6" string="Liz" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Liz" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>Levine declined comment on a rumor circulating among reporters that the tabloid had paid $50,000 for the pictures.</content>
      <tokens>
        <token id="1" string="Levine" lemma="Levine" stem="levin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="declined" lemma="decline" stem="declin" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="comment" lemma="comment" stem="comment" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="rumor" lemma="rumor" stem="rumor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="circulating" lemma="circulate" stem="circul" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="among" lemma="among" stem="among" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="reporters" lemma="reporter" stem="report" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="tabloid" lemma="tabloid" stem="tabloid" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="paid" lemma="pay" stem="paid" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="16" string="50,000" lemma="50,000" stem="50,000" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="17" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="pictures" lemma="picture" stem="pictur" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Levine)) (VP (VBD declined) (NP (NN comment)) (PP (IN on) (NP (NP (DT a) (NN rumor)) (VP (VBG circulating) (PP (IN among) (NP (NNS reporters))) (SBAR (IN that) (S (NP (DT the) (NN tabloid)) (VP (VBD had) (VP (VBN paid) (NP (NP ($ $) (CD 50,000)) (PP (IN for) (NP (DT the) (NNS pictures)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="reporters" type="NP">
          <tokens>
            <token id="9" string="reporters" />
          </tokens>
        </chunking>
        <chunking id="2" string="$ 50,000" type="NP">
          <tokens>
            <token id="15" string="$" />
            <token id="16" string="50,000" />
          </tokens>
        </chunking>
        <chunking id="3" string="declined comment on a rumor circulating among reporters that the tabloid had paid $ 50,000 for the pictures" type="VP">
          <tokens>
            <token id="2" string="declined" />
            <token id="3" string="comment" />
            <token id="4" string="on" />
            <token id="5" string="a" />
            <token id="6" string="rumor" />
            <token id="7" string="circulating" />
            <token id="8" string="among" />
            <token id="9" string="reporters" />
            <token id="10" string="that" />
            <token id="11" string="the" />
            <token id="12" string="tabloid" />
            <token id="13" string="had" />
            <token id="14" string="paid" />
            <token id="15" string="$" />
            <token id="16" string="50,000" />
            <token id="17" string="for" />
            <token id="18" string="the" />
            <token id="19" string="pictures" />
          </tokens>
        </chunking>
        <chunking id="4" string="had paid $ 50,000 for the pictures" type="VP">
          <tokens>
            <token id="13" string="had" />
            <token id="14" string="paid" />
            <token id="15" string="$" />
            <token id="16" string="50,000" />
            <token id="17" string="for" />
            <token id="18" string="the" />
            <token id="19" string="pictures" />
          </tokens>
        </chunking>
        <chunking id="5" string="the pictures" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="pictures" />
          </tokens>
        </chunking>
        <chunking id="6" string="the tabloid" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="tabloid" />
          </tokens>
        </chunking>
        <chunking id="7" string="$ 50,000 for the pictures" type="NP">
          <tokens>
            <token id="15" string="$" />
            <token id="16" string="50,000" />
            <token id="17" string="for" />
            <token id="18" string="the" />
            <token id="19" string="pictures" />
          </tokens>
        </chunking>
        <chunking id="8" string="a rumor circulating among reporters that the tabloid had paid $ 50,000 for the pictures" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="rumor" />
            <token id="7" string="circulating" />
            <token id="8" string="among" />
            <token id="9" string="reporters" />
            <token id="10" string="that" />
            <token id="11" string="the" />
            <token id="12" string="tabloid" />
            <token id="13" string="had" />
            <token id="14" string="paid" />
            <token id="15" string="$" />
            <token id="16" string="50,000" />
            <token id="17" string="for" />
            <token id="18" string="the" />
            <token id="19" string="pictures" />
          </tokens>
        </chunking>
        <chunking id="9" string="Levine" type="NP">
          <tokens>
            <token id="1" string="Levine" />
          </tokens>
        </chunking>
        <chunking id="10" string="circulating among reporters that the tabloid had paid $ 50,000 for the pictures" type="VP">
          <tokens>
            <token id="7" string="circulating" />
            <token id="8" string="among" />
            <token id="9" string="reporters" />
            <token id="10" string="that" />
            <token id="11" string="the" />
            <token id="12" string="tabloid" />
            <token id="13" string="had" />
            <token id="14" string="paid" />
            <token id="15" string="$" />
            <token id="16" string="50,000" />
            <token id="17" string="for" />
            <token id="18" string="the" />
            <token id="19" string="pictures" />
          </tokens>
        </chunking>
        <chunking id="11" string="that the tabloid had paid $ 50,000 for the pictures" type="SBAR">
          <tokens>
            <token id="10" string="that" />
            <token id="11" string="the" />
            <token id="12" string="tabloid" />
            <token id="13" string="had" />
            <token id="14" string="paid" />
            <token id="15" string="$" />
            <token id="16" string="50,000" />
            <token id="17" string="for" />
            <token id="18" string="the" />
            <token id="19" string="pictures" />
          </tokens>
        </chunking>
        <chunking id="12" string="a rumor" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="rumor" />
          </tokens>
        </chunking>
        <chunking id="13" string="paid $ 50,000 for the pictures" type="VP">
          <tokens>
            <token id="14" string="paid" />
            <token id="15" string="$" />
            <token id="16" string="50,000" />
            <token id="17" string="for" />
            <token id="18" string="the" />
            <token id="19" string="pictures" />
          </tokens>
        </chunking>
        <chunking id="14" string="comment" type="NP">
          <tokens>
            <token id="3" string="comment" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">declined</governor>
          <dependent id="1">Levine</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">declined</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">declined</governor>
          <dependent id="3">comment</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">rumor</governor>
          <dependent id="4">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">rumor</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">declined</governor>
          <dependent id="6">rumor</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="6">rumor</governor>
          <dependent id="7">circulating</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">reporters</governor>
          <dependent id="8">among</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">circulating</governor>
          <dependent id="9">reporters</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">paid</governor>
          <dependent id="10">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">tabloid</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">paid</governor>
          <dependent id="12">tabloid</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">paid</governor>
          <dependent id="13">had</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">circulating</governor>
          <dependent id="14">paid</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="16">50,000</governor>
          <dependent id="15">$</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">paid</governor>
          <dependent id="16">50,000</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">pictures</governor>
          <dependent id="17">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">pictures</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">50,000</governor>
          <dependent id="19">pictures</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="$ 50,000" type="MONEY" score="0.0">
          <tokens>
            <token id="15" string="$" />
            <token id="16" string="50,000" />
          </tokens>
        </entity>
        <entity id="2" string="Levine" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Levine" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>Some press coverage has bent over backwards to tug at the bounds of credibility; the National Enquirer has Liz communing with the ghosts of Forbes and one-time husband Richard Burton.</content>
      <tokens>
        <token id="1" string="Some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="press" lemma="press" stem="press" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="coverage" lemma="coverage" stem="coverag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="bent" lemma="bent" stem="bent" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="backwards" lemma="backwards" stem="backward" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="tug" lemma="tug" stem="tug" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="bounds" lemma="bound" stem="bound" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="credibility" lemma="credibility" stem="credibl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="National" lemma="National" stem="nation" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="18" string="Enquirer" lemma="Enquirer" stem="enquirer" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="19" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Liz" lemma="Liz" stem="liz" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="21" string="communing" lemma="commune" stem="commun" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="ghosts" lemma="ghost" stem="ghost" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="Forbes" lemma="Forbes" stem="forb" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="27" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="one-time" lemma="one-time" stem="one-tim" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="husband" lemma="husband" stem="husband" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="Richard" lemma="Richard" stem="richard" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="31" string="Burton" lemma="Burton" stem="burton" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT Some) (NN press) (NN coverage)) (VP (VBZ has) (S (ADJP (JJ bent) (PP (IN over) (ADVP (RB backwards) (PP (TO to) (NP (NN tug))))))) (PP (IN at) (NP (NP (DT the) (NNS bounds)) (PP (IN of) (NP (NN credibility))))))) (: ;) (S (NP (DT the) (NNP National) (NNP Enquirer)) (VP (VBZ has) (NP (NP (NNP Liz)) (VP (VBG communing) (PP (IN with) (NP (NP (DT the) (NNS ghosts)) (PP (IN of) (NP (NNP Forbes) (CC and) (JJ one-time) (NN husband) (NNP Richard) (NNP Burton))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the bounds of credibility" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="bounds" />
            <token id="13" string="of" />
            <token id="14" string="credibility" />
          </tokens>
        </chunking>
        <chunking id="2" string="the ghosts of Forbes and one-time husband Richard Burton" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="ghosts" />
            <token id="25" string="of" />
            <token id="26" string="Forbes" />
            <token id="27" string="and" />
            <token id="28" string="one-time" />
            <token id="29" string="husband" />
            <token id="30" string="Richard" />
            <token id="31" string="Burton" />
          </tokens>
        </chunking>
        <chunking id="3" string="Some press coverage" type="NP">
          <tokens>
            <token id="1" string="Some" />
            <token id="2" string="press" />
            <token id="3" string="coverage" />
          </tokens>
        </chunking>
        <chunking id="4" string="the bounds" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="bounds" />
          </tokens>
        </chunking>
        <chunking id="5" string="tug" type="NP">
          <tokens>
            <token id="9" string="tug" />
          </tokens>
        </chunking>
        <chunking id="6" string="bent over backwards to tug" type="ADJP">
          <tokens>
            <token id="5" string="bent" />
            <token id="6" string="over" />
            <token id="7" string="backwards" />
            <token id="8" string="to" />
            <token id="9" string="tug" />
          </tokens>
        </chunking>
        <chunking id="7" string="communing with the ghosts of Forbes and one-time husband Richard Burton" type="VP">
          <tokens>
            <token id="21" string="communing" />
            <token id="22" string="with" />
            <token id="23" string="the" />
            <token id="24" string="ghosts" />
            <token id="25" string="of" />
            <token id="26" string="Forbes" />
            <token id="27" string="and" />
            <token id="28" string="one-time" />
            <token id="29" string="husband" />
            <token id="30" string="Richard" />
            <token id="31" string="Burton" />
          </tokens>
        </chunking>
        <chunking id="8" string="has Liz communing with the ghosts of Forbes and one-time husband Richard Burton" type="VP">
          <tokens>
            <token id="19" string="has" />
            <token id="20" string="Liz" />
            <token id="21" string="communing" />
            <token id="22" string="with" />
            <token id="23" string="the" />
            <token id="24" string="ghosts" />
            <token id="25" string="of" />
            <token id="26" string="Forbes" />
            <token id="27" string="and" />
            <token id="28" string="one-time" />
            <token id="29" string="husband" />
            <token id="30" string="Richard" />
            <token id="31" string="Burton" />
          </tokens>
        </chunking>
        <chunking id="9" string="the ghosts" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="ghosts" />
          </tokens>
        </chunking>
        <chunking id="10" string="the National Enquirer" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="National" />
            <token id="18" string="Enquirer" />
          </tokens>
        </chunking>
        <chunking id="11" string="Liz communing with the ghosts of Forbes and one-time husband Richard Burton" type="NP">
          <tokens>
            <token id="20" string="Liz" />
            <token id="21" string="communing" />
            <token id="22" string="with" />
            <token id="23" string="the" />
            <token id="24" string="ghosts" />
            <token id="25" string="of" />
            <token id="26" string="Forbes" />
            <token id="27" string="and" />
            <token id="28" string="one-time" />
            <token id="29" string="husband" />
            <token id="30" string="Richard" />
            <token id="31" string="Burton" />
          </tokens>
        </chunking>
        <chunking id="12" string="Forbes and one-time husband Richard Burton" type="NP">
          <tokens>
            <token id="26" string="Forbes" />
            <token id="27" string="and" />
            <token id="28" string="one-time" />
            <token id="29" string="husband" />
            <token id="30" string="Richard" />
            <token id="31" string="Burton" />
          </tokens>
        </chunking>
        <chunking id="13" string="credibility" type="NP">
          <tokens>
            <token id="14" string="credibility" />
          </tokens>
        </chunking>
        <chunking id="14" string="Liz" type="NP">
          <tokens>
            <token id="20" string="Liz" />
          </tokens>
        </chunking>
        <chunking id="15" string="has bent over backwards to tug at the bounds of credibility" type="VP">
          <tokens>
            <token id="4" string="has" />
            <token id="5" string="bent" />
            <token id="6" string="over" />
            <token id="7" string="backwards" />
            <token id="8" string="to" />
            <token id="9" string="tug" />
            <token id="10" string="at" />
            <token id="11" string="the" />
            <token id="12" string="bounds" />
            <token id="13" string="of" />
            <token id="14" string="credibility" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">coverage</governor>
          <dependent id="1">Some</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">coverage</governor>
          <dependent id="2">press</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">has</governor>
          <dependent id="3">coverage</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">has</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">has</governor>
          <dependent id="5">bent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">backwards</governor>
          <dependent id="6">over</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">bent</governor>
          <dependent id="7">backwards</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">tug</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">backwards</governor>
          <dependent id="9">tug</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">bounds</governor>
          <dependent id="10">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">bounds</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">has</governor>
          <dependent id="12">bounds</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">credibility</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">bounds</governor>
          <dependent id="14">credibility</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">Enquirer</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Enquirer</governor>
          <dependent id="17">National</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">has</governor>
          <dependent id="18">Enquirer</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="4">has</governor>
          <dependent id="19">has</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">has</governor>
          <dependent id="20">Liz</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="20">Liz</governor>
          <dependent id="21">communing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">ghosts</governor>
          <dependent id="22">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">ghosts</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">communing</governor>
          <dependent id="24">ghosts</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">Burton</governor>
          <dependent id="25">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">Burton</governor>
          <dependent id="26">Forbes</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="26">Forbes</governor>
          <dependent id="27">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="26">Forbes</governor>
          <dependent id="28">one-time</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">Burton</governor>
          <dependent id="29">husband</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">Burton</governor>
          <dependent id="30">Richard</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">ghosts</governor>
          <dependent id="31">Burton</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Forbes" type="PERSON" score="0.0">
          <tokens>
            <token id="26" string="Forbes" />
          </tokens>
        </entity>
        <entity id="2" string="National Enquirer" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="17" string="National" />
            <token id="18" string="Enquirer" />
          </tokens>
        </entity>
        <entity id="3" string="Richard Burton" type="PERSON" score="0.0">
          <tokens>
            <token id="30" string="Richard" />
            <token id="31" string="Burton" />
          </tokens>
        </entity>
        <entity id="4" string="Liz" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="Liz" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>In all, Liz&amp;apost;s current illness has drawn the most attention yet, according to her publicist, Chen Sam.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Liz" lemma="Liz" stem="liz" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="5" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="current" lemma="current" stem="current" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="7" string="illness" lemma="illness" stem="ill" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="drawn" lemma="draw" stem="drawn" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="most" lemma="most" stem="most" pos="RBS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="attention" lemma="attention" stem="attent" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="yet" lemma="yet" stem="yet" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="according" lemma="accord" stem="accord" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="publicist" lemma="publicist" stem="publicist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Chen" lemma="Chen" stem="chen" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="21" string="Sam" lemma="Sam" stem="sam" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (DT all))) (, ,) (NP (NP (NNP Liz) (POS 's)) (JJ current) (NN illness)) (VP (VBZ has) (VP (VBN drawn) (NP (NP (DT the) (RBS most)) (NN attention)) (ADVP (RB yet)) (, ,) (PP (VBG according) (PP (TO to) (NP (NP (PRP$ her) (NN publicist)) (, ,) (NP (NNP Chen) (NNP Sam))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="her publicist" type="NP">
          <tokens>
            <token id="17" string="her" />
            <token id="18" string="publicist" />
          </tokens>
        </chunking>
        <chunking id="2" string="all" type="NP">
          <tokens>
            <token id="2" string="all" />
          </tokens>
        </chunking>
        <chunking id="3" string="Liz 's" type="NP">
          <tokens>
            <token id="4" string="Liz" />
            <token id="5" string="'s" />
          </tokens>
        </chunking>
        <chunking id="4" string="the most" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="most" />
          </tokens>
        </chunking>
        <chunking id="5" string="Chen Sam" type="NP">
          <tokens>
            <token id="20" string="Chen" />
            <token id="21" string="Sam" />
          </tokens>
        </chunking>
        <chunking id="6" string="drawn the most attention yet , according to her publicist , Chen Sam" type="VP">
          <tokens>
            <token id="9" string="drawn" />
            <token id="10" string="the" />
            <token id="11" string="most" />
            <token id="12" string="attention" />
            <token id="13" string="yet" />
            <token id="14" string="," />
            <token id="15" string="according" />
            <token id="16" string="to" />
            <token id="17" string="her" />
            <token id="18" string="publicist" />
            <token id="19" string="," />
            <token id="20" string="Chen" />
            <token id="21" string="Sam" />
          </tokens>
        </chunking>
        <chunking id="7" string="the most attention" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="most" />
            <token id="12" string="attention" />
          </tokens>
        </chunking>
        <chunking id="8" string="her publicist , Chen Sam" type="NP">
          <tokens>
            <token id="17" string="her" />
            <token id="18" string="publicist" />
            <token id="19" string="," />
            <token id="20" string="Chen" />
            <token id="21" string="Sam" />
          </tokens>
        </chunking>
        <chunking id="9" string="Liz 's current illness" type="NP">
          <tokens>
            <token id="4" string="Liz" />
            <token id="5" string="'s" />
            <token id="6" string="current" />
            <token id="7" string="illness" />
          </tokens>
        </chunking>
        <chunking id="10" string="has drawn the most attention yet , according to her publicist , Chen Sam" type="VP">
          <tokens>
            <token id="8" string="has" />
            <token id="9" string="drawn" />
            <token id="10" string="the" />
            <token id="11" string="most" />
            <token id="12" string="attention" />
            <token id="13" string="yet" />
            <token id="14" string="," />
            <token id="15" string="according" />
            <token id="16" string="to" />
            <token id="17" string="her" />
            <token id="18" string="publicist" />
            <token id="19" string="," />
            <token id="20" string="Chen" />
            <token id="21" string="Sam" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">all</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">drawn</governor>
          <dependent id="2">all</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">illness</governor>
          <dependent id="4">Liz</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">Liz</governor>
          <dependent id="5">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">illness</governor>
          <dependent id="6">current</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">drawn</governor>
          <dependent id="7">illness</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">drawn</governor>
          <dependent id="8">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">drawn</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">attention</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">the</governor>
          <dependent id="11">most</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">drawn</governor>
          <dependent id="12">attention</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">drawn</governor>
          <dependent id="13">yet</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">publicist</governor>
          <dependent id="15">according</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="15">according</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="18">publicist</governor>
          <dependent id="17">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">drawn</governor>
          <dependent id="18">publicist</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">Sam</governor>
          <dependent id="20">Chen</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="18">publicist</governor>
          <dependent id="21">Sam</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Chen Sam" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="Chen" />
            <token id="21" string="Sam" />
          </tokens>
        </entity>
        <entity id="2" string="current" type="DATE" score="0.0">
          <tokens>
            <token id="6" string="current" />
          </tokens>
        </entity>
        <entity id="3" string="Liz" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Liz" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>More than 100 reporters, photographers and cameramen converged on St. John&amp;apost;s, many of whom had flown in from around the country for the 15-minute press conference.</content>
      <tokens>
        <token id="1" string="More" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="100" lemma="100" stem="100" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="4" string="reporters" lemma="reporter" stem="report" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="photographers" lemma="photographer" stem="photograph" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="cameramen" lemma="cameraman" stem="cameramen" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="converged" lemma="converge" stem="converg" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="St." lemma="St." stem="st." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="12" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="13" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="whom" lemma="whom" stem="whom" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="flown" lemma="fly" stem="flown" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="around" lemma="around" stem="around" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="24" string="country" lemma="country" stem="countri" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="25" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="27" string="15-minute" lemma="15-minute" stem="15-minut" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="true" />
        <token id="28" string="press" lemma="press" stem="press" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="29" string="conference" lemma="conference" stem="confer" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (QP (JJR More) (IN than) (CD 100)) (NNS reporters)) (, ,) (NP (NNS photographers)) (CC and) (NP (NNS cameramen))) (VP (VBN converged) (PP (IN on) (NP (NP (NNP St.) (NNP John) (POS 's)) (, ,) (SBAR (WHNP (WHNP (JJ many)) (WHPP (IN of) (WHNP (WP whom)))) (S (VP (VBD had) (VP (VBN flown) (PP (IN in) (PP (IN from) (PP (IN around) (NP (NP (DT the) (NN country)) (PP (IN for) (NP (DT the) (JJ 15-minute) (NN press) (NN conference)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="converged on St. John 's , many of whom had flown in from around the country for the 15-minute press conference" type="VP">
          <tokens>
            <token id="9" string="converged" />
            <token id="10" string="on" />
            <token id="11" string="St." />
            <token id="12" string="John" />
            <token id="13" string="'s" />
            <token id="14" string="," />
            <token id="15" string="many" />
            <token id="16" string="of" />
            <token id="17" string="whom" />
            <token id="18" string="had" />
            <token id="19" string="flown" />
            <token id="20" string="in" />
            <token id="21" string="from" />
            <token id="22" string="around" />
            <token id="23" string="the" />
            <token id="24" string="country" />
            <token id="25" string="for" />
            <token id="26" string="the" />
            <token id="27" string="15-minute" />
            <token id="28" string="press" />
            <token id="29" string="conference" />
          </tokens>
        </chunking>
        <chunking id="2" string="St. John 's , many of whom had flown in from around the country for the 15-minute press conference" type="NP">
          <tokens>
            <token id="11" string="St." />
            <token id="12" string="John" />
            <token id="13" string="'s" />
            <token id="14" string="," />
            <token id="15" string="many" />
            <token id="16" string="of" />
            <token id="17" string="whom" />
            <token id="18" string="had" />
            <token id="19" string="flown" />
            <token id="20" string="in" />
            <token id="21" string="from" />
            <token id="22" string="around" />
            <token id="23" string="the" />
            <token id="24" string="country" />
            <token id="25" string="for" />
            <token id="26" string="the" />
            <token id="27" string="15-minute" />
            <token id="28" string="press" />
            <token id="29" string="conference" />
          </tokens>
        </chunking>
        <chunking id="3" string="had flown in from around the country for the 15-minute press conference" type="VP">
          <tokens>
            <token id="18" string="had" />
            <token id="19" string="flown" />
            <token id="20" string="in" />
            <token id="21" string="from" />
            <token id="22" string="around" />
            <token id="23" string="the" />
            <token id="24" string="country" />
            <token id="25" string="for" />
            <token id="26" string="the" />
            <token id="27" string="15-minute" />
            <token id="28" string="press" />
            <token id="29" string="conference" />
          </tokens>
        </chunking>
        <chunking id="4" string="flown in from around the country for the 15-minute press conference" type="VP">
          <tokens>
            <token id="19" string="flown" />
            <token id="20" string="in" />
            <token id="21" string="from" />
            <token id="22" string="around" />
            <token id="23" string="the" />
            <token id="24" string="country" />
            <token id="25" string="for" />
            <token id="26" string="the" />
            <token id="27" string="15-minute" />
            <token id="28" string="press" />
            <token id="29" string="conference" />
          </tokens>
        </chunking>
        <chunking id="5" string="St. John 's" type="NP">
          <tokens>
            <token id="11" string="St." />
            <token id="12" string="John" />
            <token id="13" string="'s" />
          </tokens>
        </chunking>
        <chunking id="6" string="cameramen" type="NP">
          <tokens>
            <token id="8" string="cameramen" />
          </tokens>
        </chunking>
        <chunking id="7" string="More than 100 reporters , photographers and cameramen" type="NP">
          <tokens>
            <token id="1" string="More" />
            <token id="2" string="than" />
            <token id="3" string="100" />
            <token id="4" string="reporters" />
            <token id="5" string="," />
            <token id="6" string="photographers" />
            <token id="7" string="and" />
            <token id="8" string="cameramen" />
          </tokens>
        </chunking>
        <chunking id="8" string="photographers" type="NP">
          <tokens>
            <token id="6" string="photographers" />
          </tokens>
        </chunking>
        <chunking id="9" string="many of whom had flown in from around the country for the 15-minute press conference" type="SBAR">
          <tokens>
            <token id="15" string="many" />
            <token id="16" string="of" />
            <token id="17" string="whom" />
            <token id="18" string="had" />
            <token id="19" string="flown" />
            <token id="20" string="in" />
            <token id="21" string="from" />
            <token id="22" string="around" />
            <token id="23" string="the" />
            <token id="24" string="country" />
            <token id="25" string="for" />
            <token id="26" string="the" />
            <token id="27" string="15-minute" />
            <token id="28" string="press" />
            <token id="29" string="conference" />
          </tokens>
        </chunking>
        <chunking id="10" string="the country" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="country" />
          </tokens>
        </chunking>
        <chunking id="11" string="the country for the 15-minute press conference" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="country" />
            <token id="25" string="for" />
            <token id="26" string="the" />
            <token id="27" string="15-minute" />
            <token id="28" string="press" />
            <token id="29" string="conference" />
          </tokens>
        </chunking>
        <chunking id="12" string="the 15-minute press conference" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="15-minute" />
            <token id="28" string="press" />
            <token id="29" string="conference" />
          </tokens>
        </chunking>
        <chunking id="13" string="More than 100 reporters" type="NP">
          <tokens>
            <token id="1" string="More" />
            <token id="2" string="than" />
            <token id="3" string="100" />
            <token id="4" string="reporters" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="3">100</governor>
          <dependent id="1">More</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="1">More</governor>
          <dependent id="2">than</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="4">reporters</governor>
          <dependent id="3">100</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">converged</governor>
          <dependent id="4">reporters</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">reporters</governor>
          <dependent id="6">photographers</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">reporters</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">reporters</governor>
          <dependent id="8">cameramen</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">converged</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">John</governor>
          <dependent id="10">on</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">John</governor>
          <dependent id="11">St.</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">converged</governor>
          <dependent id="12">John</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">John</governor>
          <dependent id="13">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">flown</governor>
          <dependent id="15">many</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">whom</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">many</governor>
          <dependent id="17">whom</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="19">flown</governor>
          <dependent id="18">had</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="12">John</governor>
          <dependent id="19">flown</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">country</governor>
          <dependent id="20">in</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">country</governor>
          <dependent id="21">from</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">country</governor>
          <dependent id="22">around</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">country</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="19">flown</governor>
          <dependent id="24">country</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">conference</governor>
          <dependent id="25">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">conference</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">conference</governor>
          <dependent id="27">15-minute</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">conference</governor>
          <dependent id="28">press</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">country</governor>
          <dependent id="29">conference</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="100" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="100" />
          </tokens>
        </entity>
        <entity id="2" string="St. John" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="St." />
            <token id="12" string="John" />
          </tokens>
        </entity>
        <entity id="3" string="15-minute" type="DURATION" score="0.0">
          <tokens>
            <token id="27" string="15-minute" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>Behind a chorus line of video cameras -- representing the major networks, the local stations, CNN and the tabloid shows -- reporters peppered the doctors with pointed and sometimes testy questions about Taylor&amp;apost;s treatment and drug use.</content>
      <tokens>
        <token id="1" string="Behind" lemma="behind" stem="behind" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="chorus" lemma="chorus" stem="choru" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="line" lemma="line" stem="line" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="video" lemma="video" stem="video" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="cameras" lemma="camera" stem="camera" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="representing" lemma="represent" stem="repres" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="major" lemma="major" stem="major" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="networks" lemma="network" stem="network" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="local" lemma="local" stem="local" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="stations" lemma="station" stem="station" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="CNN" lemma="CNN" stem="cnn" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="tabloid" lemma="tabloid" stem="tabloid" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="shows" lemma="show" stem="show" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="reporters" lemma="reporter" stem="report" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="peppered" lemma="pepper" stem="pepper" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="doctors" lemma="doctor" stem="doctor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="28" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="pointed" lemma="pointed" stem="point" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="sometimes" lemma="sometimes" stem="sometim" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="testy" lemma="testy" stem="testi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="questions" lemma="question" stem="question" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="Taylor" lemma="Taylor" stem="taylor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="36" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="treatment" lemma="treatment" stem="treatment" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="drug" lemma="drug" stem="drug" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="use" lemma="use" stem="us" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN Behind) (NP (NP (DT a) (NN chorus) (NN line)) (PP (IN of) (NP (NN video) (NNS cameras))))) (PRN (: --) (S (VP (VBG representing) (SBAR (S (NP (NP (DT the) (JJ major) (NNS networks)) (, ,) (NP (DT the) (JJ local) (NNS stations)) (, ,) (NP (NNP CNN)) (CC and) (NP (DT the) (NN tabloid))) (VP (VBZ shows)))))) (: --)) (NP (NNS reporters)) (VP (VBD peppered) (NP (DT the) (NNS doctors)) (PP (IN with) (NP (ADJP (ADJP (JJ pointed)) (CC and) (ADJP (RB sometimes) (JJ testy))) (NNS questions))) (PP (IN about) (NP (NP (NNP Taylor) (POS 's)) (NN treatment) (CC and) (NN drug) (NN use)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="reporters" type="NP">
          <tokens>
            <token id="24" string="reporters" />
          </tokens>
        </chunking>
        <chunking id="2" string="CNN" type="NP">
          <tokens>
            <token id="18" string="CNN" />
          </tokens>
        </chunking>
        <chunking id="3" string="video cameras" type="NP">
          <tokens>
            <token id="6" string="video" />
            <token id="7" string="cameras" />
          </tokens>
        </chunking>
        <chunking id="4" string="peppered the doctors with pointed and sometimes testy questions about Taylor 's treatment and drug use" type="VP">
          <tokens>
            <token id="25" string="peppered" />
            <token id="26" string="the" />
            <token id="27" string="doctors" />
            <token id="28" string="with" />
            <token id="29" string="pointed" />
            <token id="30" string="and" />
            <token id="31" string="sometimes" />
            <token id="32" string="testy" />
            <token id="33" string="questions" />
            <token id="34" string="about" />
            <token id="35" string="Taylor" />
            <token id="36" string="'s" />
            <token id="37" string="treatment" />
            <token id="38" string="and" />
            <token id="39" string="drug" />
            <token id="40" string="use" />
          </tokens>
        </chunking>
        <chunking id="5" string="the local stations" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="local" />
            <token id="16" string="stations" />
          </tokens>
        </chunking>
        <chunking id="6" string="the tabloid" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="tabloid" />
          </tokens>
        </chunking>
        <chunking id="7" string="pointed and sometimes testy questions" type="NP">
          <tokens>
            <token id="29" string="pointed" />
            <token id="30" string="and" />
            <token id="31" string="sometimes" />
            <token id="32" string="testy" />
            <token id="33" string="questions" />
          </tokens>
        </chunking>
        <chunking id="8" string="the major networks , the local stations , CNN and the tabloid shows" type="SBAR">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="major" />
            <token id="12" string="networks" />
            <token id="13" string="," />
            <token id="14" string="the" />
            <token id="15" string="local" />
            <token id="16" string="stations" />
            <token id="17" string="," />
            <token id="18" string="CNN" />
            <token id="19" string="and" />
            <token id="20" string="the" />
            <token id="21" string="tabloid" />
            <token id="22" string="shows" />
          </tokens>
        </chunking>
        <chunking id="9" string="shows" type="VP">
          <tokens>
            <token id="22" string="shows" />
          </tokens>
        </chunking>
        <chunking id="10" string="a chorus line" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="chorus" />
            <token id="4" string="line" />
          </tokens>
        </chunking>
        <chunking id="11" string="pointed" type="ADJP">
          <tokens>
            <token id="29" string="pointed" />
          </tokens>
        </chunking>
        <chunking id="12" string="the major networks" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="major" />
            <token id="12" string="networks" />
          </tokens>
        </chunking>
        <chunking id="13" string="pointed and sometimes testy" type="ADJP">
          <tokens>
            <token id="29" string="pointed" />
            <token id="30" string="and" />
            <token id="31" string="sometimes" />
            <token id="32" string="testy" />
          </tokens>
        </chunking>
        <chunking id="14" string="sometimes testy" type="ADJP">
          <tokens>
            <token id="31" string="sometimes" />
            <token id="32" string="testy" />
          </tokens>
        </chunking>
        <chunking id="15" string="the doctors" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="doctors" />
          </tokens>
        </chunking>
        <chunking id="16" string="Taylor 's treatment and drug use" type="NP">
          <tokens>
            <token id="35" string="Taylor" />
            <token id="36" string="'s" />
            <token id="37" string="treatment" />
            <token id="38" string="and" />
            <token id="39" string="drug" />
            <token id="40" string="use" />
          </tokens>
        </chunking>
        <chunking id="17" string="the major networks , the local stations , CNN and the tabloid" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="major" />
            <token id="12" string="networks" />
            <token id="13" string="," />
            <token id="14" string="the" />
            <token id="15" string="local" />
            <token id="16" string="stations" />
            <token id="17" string="," />
            <token id="18" string="CNN" />
            <token id="19" string="and" />
            <token id="20" string="the" />
            <token id="21" string="tabloid" />
          </tokens>
        </chunking>
        <chunking id="18" string="Taylor 's" type="NP">
          <tokens>
            <token id="35" string="Taylor" />
            <token id="36" string="'s" />
          </tokens>
        </chunking>
        <chunking id="19" string="a chorus line of video cameras" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="chorus" />
            <token id="4" string="line" />
            <token id="5" string="of" />
            <token id="6" string="video" />
            <token id="7" string="cameras" />
          </tokens>
        </chunking>
        <chunking id="20" string="representing the major networks , the local stations , CNN and the tabloid shows" type="VP">
          <tokens>
            <token id="9" string="representing" />
            <token id="10" string="the" />
            <token id="11" string="major" />
            <token id="12" string="networks" />
            <token id="13" string="," />
            <token id="14" string="the" />
            <token id="15" string="local" />
            <token id="16" string="stations" />
            <token id="17" string="," />
            <token id="18" string="CNN" />
            <token id="19" string="and" />
            <token id="20" string="the" />
            <token id="21" string="tabloid" />
            <token id="22" string="shows" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">line</governor>
          <dependent id="1">Behind</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">line</governor>
          <dependent id="2">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">line</governor>
          <dependent id="3">chorus</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">peppered</governor>
          <dependent id="4">line</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">cameras</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">cameras</governor>
          <dependent id="6">video</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">line</governor>
          <dependent id="7">cameras</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="25">peppered</governor>
          <dependent id="9">representing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">networks</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">networks</governor>
          <dependent id="11">major</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">shows</governor>
          <dependent id="12">networks</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">stations</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">stations</governor>
          <dependent id="15">local</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">networks</governor>
          <dependent id="16">stations</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">networks</governor>
          <dependent id="18">CNN</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">networks</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">tabloid</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">networks</governor>
          <dependent id="21">tabloid</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">representing</governor>
          <dependent id="22">shows</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">peppered</governor>
          <dependent id="24">reporters</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="25">peppered</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">doctors</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">peppered</governor>
          <dependent id="27">doctors</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">questions</governor>
          <dependent id="28">with</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="33">questions</governor>
          <dependent id="29">pointed</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="29">pointed</governor>
          <dependent id="30">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="32">testy</governor>
          <dependent id="31">sometimes</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="29">pointed</governor>
          <dependent id="32">testy</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">peppered</governor>
          <dependent id="33">questions</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">treatment</governor>
          <dependent id="34">about</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="37">treatment</governor>
          <dependent id="35">Taylor</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">Taylor</governor>
          <dependent id="36">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">peppered</governor>
          <dependent id="37">treatment</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="37">treatment</governor>
          <dependent id="38">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="40">use</governor>
          <dependent id="39">drug</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="37">treatment</governor>
          <dependent id="40">use</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="CNN" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="18" string="CNN" />
          </tokens>
        </entity>
        <entity id="2" string="Taylor" type="PERSON" score="0.0">
          <tokens>
            <token id="35" string="Taylor" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>&amp;quot;I heard some guys talking behind me, saying, &amp;apost;I can&amp;apost;t believe they&amp;apost;re hounding her like this.&amp;apost;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="heard" lemma="hear" stem="heard" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="guys" lemma="guy" stem="gui" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="talking" lemma="talk" stem="talk" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="behind" lemma="behind" stem="behind" pos="IN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="saying" lemma="say" stem="sai" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="ca" lemma="can" stem="ca" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="believe" lemma="believe" stem="believ" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="'re" lemma="be" stem="'re" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="hounding" lemma="hound" stem="hound" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP I)) (VP (VBD heard) (NP (NP (DT some) (NNS guys)) (VP (VBG talking) (PP (IN behind) (NP (PRP me))))) (, ,) (S (VP (VBG saying))))) (, ,) ('' ') (NP (PRP I)) (VP (MD ca) (RB n't) (VP (VB believe) (SBAR (S (NP (PRP they)) (VP (VBP 're) (VP (VBG hounding) (NP (PRP$ her)) (PP (IN like) (NP (DT this))))))))) (. .) ('' ')))</syntactictree>
      <chunkings>
        <chunking id="1" string="believe they 're hounding her like this" type="VP">
          <tokens>
            <token id="16" string="believe" />
            <token id="17" string="they" />
            <token id="18" string="'re" />
            <token id="19" string="hounding" />
            <token id="20" string="her" />
            <token id="21" string="like" />
            <token id="22" string="this" />
          </tokens>
        </chunking>
        <chunking id="2" string="some guys talking behind me" type="NP">
          <tokens>
            <token id="4" string="some" />
            <token id="5" string="guys" />
            <token id="6" string="talking" />
            <token id="7" string="behind" />
            <token id="8" string="me" />
          </tokens>
        </chunking>
        <chunking id="3" string="some guys" type="NP">
          <tokens>
            <token id="4" string="some" />
            <token id="5" string="guys" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="heard some guys talking behind me , saying" type="VP">
          <tokens>
            <token id="3" string="heard" />
            <token id="4" string="some" />
            <token id="5" string="guys" />
            <token id="6" string="talking" />
            <token id="7" string="behind" />
            <token id="8" string="me" />
            <token id="9" string="," />
            <token id="10" string="saying" />
          </tokens>
        </chunking>
        <chunking id="6" string="'re hounding her like this" type="VP">
          <tokens>
            <token id="18" string="'re" />
            <token id="19" string="hounding" />
            <token id="20" string="her" />
            <token id="21" string="like" />
            <token id="22" string="this" />
          </tokens>
        </chunking>
        <chunking id="7" string="this" type="NP">
          <tokens>
            <token id="22" string="this" />
          </tokens>
        </chunking>
        <chunking id="8" string="they" type="NP">
          <tokens>
            <token id="17" string="they" />
          </tokens>
        </chunking>
        <chunking id="9" string="hounding her like this" type="VP">
          <tokens>
            <token id="19" string="hounding" />
            <token id="20" string="her" />
            <token id="21" string="like" />
            <token id="22" string="this" />
          </tokens>
        </chunking>
        <chunking id="10" string="ca n't believe they 're hounding her like this" type="VP">
          <tokens>
            <token id="14" string="ca" />
            <token id="15" string="n't" />
            <token id="16" string="believe" />
            <token id="17" string="they" />
            <token id="18" string="'re" />
            <token id="19" string="hounding" />
            <token id="20" string="her" />
            <token id="21" string="like" />
            <token id="22" string="this" />
          </tokens>
        </chunking>
        <chunking id="11" string="talking behind me" type="VP">
          <tokens>
            <token id="6" string="talking" />
            <token id="7" string="behind" />
            <token id="8" string="me" />
          </tokens>
        </chunking>
        <chunking id="12" string="her" type="NP">
          <tokens>
            <token id="20" string="her" />
          </tokens>
        </chunking>
        <chunking id="13" string="me" type="NP">
          <tokens>
            <token id="8" string="me" />
          </tokens>
        </chunking>
        <chunking id="14" string="saying" type="VP">
          <tokens>
            <token id="10" string="saying" />
          </tokens>
        </chunking>
        <chunking id="15" string="they 're hounding her like this" type="SBAR">
          <tokens>
            <token id="17" string="they" />
            <token id="18" string="'re" />
            <token id="19" string="hounding" />
            <token id="20" string="her" />
            <token id="21" string="like" />
            <token id="22" string="this" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">heard</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">believe</governor>
          <dependent id="3">heard</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">guys</governor>
          <dependent id="4">some</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">heard</governor>
          <dependent id="5">guys</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="5">guys</governor>
          <dependent id="6">talking</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">me</governor>
          <dependent id="7">behind</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">talking</governor>
          <dependent id="8">me</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">heard</governor>
          <dependent id="10">saying</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">believe</governor>
          <dependent id="13">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">believe</governor>
          <dependent id="14">ca</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="16">believe</governor>
          <dependent id="15">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">believe</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">hounding</governor>
          <dependent id="17">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="19">hounding</governor>
          <dependent id="18">'re</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">believe</governor>
          <dependent id="19">hounding</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">hounding</governor>
          <dependent id="20">her</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">this</governor>
          <dependent id="21">like</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">hounding</governor>
          <dependent id="22">this</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>I felt like saying, &amp;apost;Are you offended reading about her?&amp;apost; &amp;quot;</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="felt" lemma="feel" stem="felt" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="saying" lemma="say" stem="sai" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="'" lemma="`" stem="'" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Are" lemma="be" stem="are" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="offended" lemma="offended" stem="offend" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="reading" lemma="reading" stem="read" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBD felt) (PP (IN like) (VP (VBG saying) (, ,) (`` `) (SQ (VBP Are) (NP (PRP you)) (NP (JJ offended) (NN reading)) (PP (IN about) (NP (PRP$ her)) (. ?) ('' '))) ('' ''))))))</syntactictree>
      <chunkings>
        <chunking id="1" string="offended reading" type="NP">
          <tokens>
            <token id="9" string="offended" />
            <token id="10" string="reading" />
          </tokens>
        </chunking>
        <chunking id="2" string="her" type="NP">
          <tokens>
            <token id="12" string="her" />
          </tokens>
        </chunking>
        <chunking id="3" string="felt like saying , ` Are you offended reading about her ? ' ''" type="VP">
          <tokens>
            <token id="2" string="felt" />
            <token id="3" string="like" />
            <token id="4" string="saying" />
            <token id="5" string="," />
            <token id="6" string="'" />
            <token id="7" string="Are" />
            <token id="8" string="you" />
            <token id="9" string="offended" />
            <token id="10" string="reading" />
            <token id="11" string="about" />
            <token id="12" string="her" />
            <token id="13" string="?" />
            <token id="14" string="'" />
            <token id="15" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="saying , ` Are you offended reading about her ? ' ''" type="VP">
          <tokens>
            <token id="4" string="saying" />
            <token id="5" string="," />
            <token id="6" string="'" />
            <token id="7" string="Are" />
            <token id="8" string="you" />
            <token id="9" string="offended" />
            <token id="10" string="reading" />
            <token id="11" string="about" />
            <token id="12" string="her" />
            <token id="13" string="?" />
            <token id="14" string="'" />
            <token id="15" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="6" string="you" type="NP">
          <tokens>
            <token id="8" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">felt</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">felt</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">saying</governor>
          <dependent id="3">like</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="2">felt</governor>
          <dependent id="4">saying</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="10">reading</governor>
          <dependent id="7">Are</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">reading</governor>
          <dependent id="8">you</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">reading</governor>
          <dependent id="9">offended</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">saying</governor>
          <dependent id="10">reading</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">her</governor>
          <dependent id="11">about</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">reading</governor>
          <dependent id="12">her</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>sniffed Val Richardson, a reporter from the Washington Times who&amp;apost;d flown in that morning.</content>
      <tokens>
        <token id="1" string="sniffed" lemma="sniff" stem="snif" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="Val" lemma="val" stem="val" pos="NN" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="Richardson" lemma="Richardson" stem="richardson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="reporter" lemma="reporter" stem="report" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="Washington" lemma="Washington" stem="washington" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="10" string="Times" lemma="Times" stem="time" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="'d" lemma="have" stem="'d" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="flown" lemma="fly" stem="flown" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="morning" lemma="morning" stem="morn" pos="NN" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (VP (VBD sniffed) (NP (NN Val))) (NP (NP (NNP Richardson)) (, ,) (NP (NP (DT a) (NN reporter)) (PP (IN from) (NP (DT the) (NNP Washington) (NNP Times))) (SBAR (WHNP (WP who)) (S (VP (VBD 'd) (VP (VBN flown) (PP (IN in) (NP (DT that) (NN morning))) (. .)))))))))</syntactictree>
      <chunkings>
        <chunking id="1" string="Val" type="NP">
          <tokens>
            <token id="2" string="Val" />
          </tokens>
        </chunking>
        <chunking id="2" string="the Washington Times" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="Washington" />
            <token id="10" string="Times" />
          </tokens>
        </chunking>
        <chunking id="3" string="a reporter" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="reporter" />
          </tokens>
        </chunking>
        <chunking id="4" string="Richardson , a reporter from the Washington Times who 'd flown in that morning ." type="NP">
          <tokens>
            <token id="3" string="Richardson" />
            <token id="4" string="," />
            <token id="5" string="a" />
            <token id="6" string="reporter" />
            <token id="7" string="from" />
            <token id="8" string="the" />
            <token id="9" string="Washington" />
            <token id="10" string="Times" />
            <token id="11" string="who" />
            <token id="12" string="'d" />
            <token id="13" string="flown" />
            <token id="14" string="in" />
            <token id="15" string="that" />
            <token id="16" string="morning" />
            <token id="17" string="." />
          </tokens>
        </chunking>
        <chunking id="5" string="who 'd flown in that morning ." type="SBAR">
          <tokens>
            <token id="11" string="who" />
            <token id="12" string="'d" />
            <token id="13" string="flown" />
            <token id="14" string="in" />
            <token id="15" string="that" />
            <token id="16" string="morning" />
            <token id="17" string="." />
          </tokens>
        </chunking>
        <chunking id="6" string="'d flown in that morning ." type="VP">
          <tokens>
            <token id="12" string="'d" />
            <token id="13" string="flown" />
            <token id="14" string="in" />
            <token id="15" string="that" />
            <token id="16" string="morning" />
            <token id="17" string="." />
          </tokens>
        </chunking>
        <chunking id="7" string="that morning" type="NP">
          <tokens>
            <token id="15" string="that" />
            <token id="16" string="morning" />
          </tokens>
        </chunking>
        <chunking id="8" string="Richardson" type="NP">
          <tokens>
            <token id="3" string="Richardson" />
          </tokens>
        </chunking>
        <chunking id="9" string="sniffed Val" type="VP">
          <tokens>
            <token id="1" string="sniffed" />
            <token id="2" string="Val" />
          </tokens>
        </chunking>
        <chunking id="10" string="a reporter from the Washington Times who 'd flown in that morning ." type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="reporter" />
            <token id="7" string="from" />
            <token id="8" string="the" />
            <token id="9" string="Washington" />
            <token id="10" string="Times" />
            <token id="11" string="who" />
            <token id="12" string="'d" />
            <token id="13" string="flown" />
            <token id="14" string="in" />
            <token id="15" string="that" />
            <token id="16" string="morning" />
            <token id="17" string="." />
          </tokens>
        </chunking>
        <chunking id="11" string="flown in that morning ." type="VP">
          <tokens>
            <token id="13" string="flown" />
            <token id="14" string="in" />
            <token id="15" string="that" />
            <token id="16" string="morning" />
            <token id="17" string="." />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">sniffed</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="1">sniffed</governor>
          <dependent id="2">Val</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="1">sniffed</governor>
          <dependent id="3">Richardson</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">reporter</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="3">Richardson</governor>
          <dependent id="6">reporter</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Times</governor>
          <dependent id="7">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">Times</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Times</governor>
          <dependent id="9">Washington</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">reporter</governor>
          <dependent id="10">Times</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">flown</governor>
          <dependent id="11">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">flown</governor>
          <dependent id="12">'d</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="6">reporter</governor>
          <dependent id="13">flown</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">morning</governor>
          <dependent id="14">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">morning</governor>
          <dependent id="15">that</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">flown</governor>
          <dependent id="16">morning</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Washington" type="LOCATION" score="0.0">
          <tokens>
            <token id="9" string="Washington" />
          </tokens>
        </entity>
        <entity id="2" string="Val Richardson" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Val" />
            <token id="3" string="Richardson" />
          </tokens>
        </entity>
        <entity id="3" string="morning" type="TIME" score="0.0">
          <tokens>
            <token id="16" string="morning" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="26" has_coreference="false">
      <content>At any rate, the news was good.</content>
      <tokens>
        <token id="1" string="At" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="rate" lemma="rate" stem="rate" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="news" lemma="news" stem="new" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="good" lemma="good" stem="good" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN At) (NP (DT any) (NN rate))) (, ,) (NP (DT the) (NN news)) (VP (VBD was) (ADJP (JJ good))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="any rate" type="NP">
          <tokens>
            <token id="2" string="any" />
            <token id="3" string="rate" />
          </tokens>
        </chunking>
        <chunking id="2" string="the news" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="news" />
          </tokens>
        </chunking>
        <chunking id="3" string="was good" type="VP">
          <tokens>
            <token id="7" string="was" />
            <token id="8" string="good" />
          </tokens>
        </chunking>
        <chunking id="4" string="good" type="ADJP">
          <tokens>
            <token id="8" string="good" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">rate</governor>
          <dependent id="1">At</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">rate</governor>
          <dependent id="2">any</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">good</governor>
          <dependent id="3">rate</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">news</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">good</governor>
          <dependent id="6">news</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">good</governor>
          <dependent id="7">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">good</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>Taylor was off a respirator and breathing with the help of an oxygen mask.</content>
      <tokens>
        <token id="1" string="Taylor" lemma="Taylor" stem="taylor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="off" lemma="off" stem="off" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="respirator" lemma="respirator" stem="respir" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="breathing" lemma="breathing" stem="breath" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="help" lemma="help" stem="help" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="oxygen" lemma="oxygen" stem="oxygen" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="mask" lemma="mask" stem="mask" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Taylor)) (VP (VBD was) (PP (IN off) (NP (NP (DT a) (NN respirator) (CC and) (NN breathing)) (PP (IN with) (NP (NP (DT the) (NN help)) (PP (IN of) (NP (DT an) (NN oxygen) (NN mask)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a respirator and breathing" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="respirator" />
            <token id="6" string="and" />
            <token id="7" string="breathing" />
          </tokens>
        </chunking>
        <chunking id="2" string="the help" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="help" />
          </tokens>
        </chunking>
        <chunking id="3" string="Taylor" type="NP">
          <tokens>
            <token id="1" string="Taylor" />
          </tokens>
        </chunking>
        <chunking id="4" string="was off a respirator and breathing with the help of an oxygen mask" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="off" />
            <token id="4" string="a" />
            <token id="5" string="respirator" />
            <token id="6" string="and" />
            <token id="7" string="breathing" />
            <token id="8" string="with" />
            <token id="9" string="the" />
            <token id="10" string="help" />
            <token id="11" string="of" />
            <token id="12" string="an" />
            <token id="13" string="oxygen" />
            <token id="14" string="mask" />
          </tokens>
        </chunking>
        <chunking id="5" string="the help of an oxygen mask" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="help" />
            <token id="11" string="of" />
            <token id="12" string="an" />
            <token id="13" string="oxygen" />
            <token id="14" string="mask" />
          </tokens>
        </chunking>
        <chunking id="6" string="a respirator and breathing with the help of an oxygen mask" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="respirator" />
            <token id="6" string="and" />
            <token id="7" string="breathing" />
            <token id="8" string="with" />
            <token id="9" string="the" />
            <token id="10" string="help" />
            <token id="11" string="of" />
            <token id="12" string="an" />
            <token id="13" string="oxygen" />
            <token id="14" string="mask" />
          </tokens>
        </chunking>
        <chunking id="7" string="an oxygen mask" type="NP">
          <tokens>
            <token id="12" string="an" />
            <token id="13" string="oxygen" />
            <token id="14" string="mask" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">respirator</governor>
          <dependent id="1">Taylor</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">respirator</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">respirator</governor>
          <dependent id="3">off</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">respirator</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">respirator</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">respirator</governor>
          <dependent id="6">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">respirator</governor>
          <dependent id="7">breathing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">help</governor>
          <dependent id="8">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">help</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">respirator</governor>
          <dependent id="10">help</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">mask</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">mask</governor>
          <dependent id="12">an</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">mask</governor>
          <dependent id="13">oxygen</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">help</governor>
          <dependent id="14">mask</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Taylor" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Taylor" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="28" has_coreference="true">
      <content>She had apparently rebounded from a bad weekend, when doctors feared she might die.</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="apparently" lemma="apparently" stem="appar" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="rebounded" lemma="rebound" stem="rebound" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="bad" lemma="bad" stem="bad" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="weekend" lemma="weekend" stem="weekend" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="doctors" lemma="doctor" stem="doctor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="feared" lemma="fear" stem="fear" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="might" lemma="might" stem="might" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="die" lemma="die" stem="die" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP She)) (VP (VBD had) (ADVP (RB apparently)) (VP (VBN rebounded) (PP (IN from) (NP (NP (DT a) (JJ bad) (NN weekend)) (, ,) (SBAR (WHADVP (WRB when)) (S (NP (NNS doctors)) (VP (VBD feared) (SBAR (S (NP (PRP she)) (VP (MD might) (VP (VB die)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="feared she might die" type="VP">
          <tokens>
            <token id="12" string="feared" />
            <token id="13" string="she" />
            <token id="14" string="might" />
            <token id="15" string="die" />
          </tokens>
        </chunking>
        <chunking id="2" string="a bad weekend , when doctors feared she might die" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="bad" />
            <token id="8" string="weekend" />
            <token id="9" string="," />
            <token id="10" string="when" />
            <token id="11" string="doctors" />
            <token id="12" string="feared" />
            <token id="13" string="she" />
            <token id="14" string="might" />
            <token id="15" string="die" />
          </tokens>
        </chunking>
        <chunking id="3" string="when doctors feared she might die" type="SBAR">
          <tokens>
            <token id="10" string="when" />
            <token id="11" string="doctors" />
            <token id="12" string="feared" />
            <token id="13" string="she" />
            <token id="14" string="might" />
            <token id="15" string="die" />
          </tokens>
        </chunking>
        <chunking id="4" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
        <chunking id="5" string="when" type="WHADVP">
          <tokens>
            <token id="10" string="when" />
          </tokens>
        </chunking>
        <chunking id="6" string="she" type="NP">
          <tokens>
            <token id="13" string="she" />
          </tokens>
        </chunking>
        <chunking id="7" string="doctors" type="NP">
          <tokens>
            <token id="11" string="doctors" />
          </tokens>
        </chunking>
        <chunking id="8" string="had apparently rebounded from a bad weekend , when doctors feared she might die" type="VP">
          <tokens>
            <token id="2" string="had" />
            <token id="3" string="apparently" />
            <token id="4" string="rebounded" />
            <token id="5" string="from" />
            <token id="6" string="a" />
            <token id="7" string="bad" />
            <token id="8" string="weekend" />
            <token id="9" string="," />
            <token id="10" string="when" />
            <token id="11" string="doctors" />
            <token id="12" string="feared" />
            <token id="13" string="she" />
            <token id="14" string="might" />
            <token id="15" string="die" />
          </tokens>
        </chunking>
        <chunking id="9" string="a bad weekend" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="bad" />
            <token id="8" string="weekend" />
          </tokens>
        </chunking>
        <chunking id="10" string="rebounded from a bad weekend , when doctors feared she might die" type="VP">
          <tokens>
            <token id="4" string="rebounded" />
            <token id="5" string="from" />
            <token id="6" string="a" />
            <token id="7" string="bad" />
            <token id="8" string="weekend" />
            <token id="9" string="," />
            <token id="10" string="when" />
            <token id="11" string="doctors" />
            <token id="12" string="feared" />
            <token id="13" string="she" />
            <token id="14" string="might" />
            <token id="15" string="die" />
          </tokens>
        </chunking>
        <chunking id="11" string="she might die" type="SBAR">
          <tokens>
            <token id="13" string="she" />
            <token id="14" string="might" />
            <token id="15" string="die" />
          </tokens>
        </chunking>
        <chunking id="12" string="might die" type="VP">
          <tokens>
            <token id="14" string="might" />
            <token id="15" string="die" />
          </tokens>
        </chunking>
        <chunking id="13" string="die" type="VP">
          <tokens>
            <token id="15" string="die" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">rebounded</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">rebounded</governor>
          <dependent id="2">had</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">rebounded</governor>
          <dependent id="3">apparently</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">rebounded</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">weekend</governor>
          <dependent id="5">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">weekend</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">weekend</governor>
          <dependent id="7">bad</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">rebounded</governor>
          <dependent id="8">weekend</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">feared</governor>
          <dependent id="10">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">feared</governor>
          <dependent id="11">doctors</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="8">weekend</governor>
          <dependent id="12">feared</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">die</governor>
          <dependent id="13">she</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">die</governor>
          <dependent id="14">might</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">feared</governor>
          <dependent id="15">die</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="weekend" type="DATE" score="0.0">
          <tokens>
            <token id="8" string="weekend" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="29" has_coreference="true">
      <content>Although Taylor&amp;apost;s physicians are still trying to identify the virus, they are treating her for pneumonia with antibiotics.</content>
      <tokens>
        <token id="1" string="Although" lemma="although" stem="although" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="Taylor" lemma="Taylor" stem="taylor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="physicians" lemma="physician" stem="physician" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="still" lemma="still" stem="still" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="trying" lemma="try" stem="try" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="identify" lemma="identify" stem="identifi" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="virus" lemma="virus" stem="viru" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="treating" lemma="treat" stem="treat" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="pneumonia" lemma="pneumonia" stem="pneumonia" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="19" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="antibiotics" lemma="antibiotic" stem="antibiot" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN Although) (S (NP (NP (NNP Taylor) (POS 's)) (NNS physicians)) (VP (VBP are) (ADVP (RB still)) (VP (VBG trying) (S (VP (TO to) (VP (VB identify) (NP (DT the) (NN virus))))))))) (, ,) (NP (PRP they)) (VP (VBP are) (VP (VBG treating) (NP (PRP$ her)) (PP (IN for) (NP (NP (NN pneumonia)) (PP (IN with) (NP (NNS antibiotics))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="trying to identify the virus" type="VP">
          <tokens>
            <token id="7" string="trying" />
            <token id="8" string="to" />
            <token id="9" string="identify" />
            <token id="10" string="the" />
            <token id="11" string="virus" />
          </tokens>
        </chunking>
        <chunking id="2" string="to identify the virus" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="identify" />
            <token id="10" string="the" />
            <token id="11" string="virus" />
          </tokens>
        </chunking>
        <chunking id="3" string="treating her for pneumonia with antibiotics" type="VP">
          <tokens>
            <token id="15" string="treating" />
            <token id="16" string="her" />
            <token id="17" string="for" />
            <token id="18" string="pneumonia" />
            <token id="19" string="with" />
            <token id="20" string="antibiotics" />
          </tokens>
        </chunking>
        <chunking id="4" string="the virus" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="virus" />
          </tokens>
        </chunking>
        <chunking id="5" string="they" type="NP">
          <tokens>
            <token id="13" string="they" />
          </tokens>
        </chunking>
        <chunking id="6" string="are treating her for pneumonia with antibiotics" type="VP">
          <tokens>
            <token id="14" string="are" />
            <token id="15" string="treating" />
            <token id="16" string="her" />
            <token id="17" string="for" />
            <token id="18" string="pneumonia" />
            <token id="19" string="with" />
            <token id="20" string="antibiotics" />
          </tokens>
        </chunking>
        <chunking id="7" string="identify the virus" type="VP">
          <tokens>
            <token id="9" string="identify" />
            <token id="10" string="the" />
            <token id="11" string="virus" />
          </tokens>
        </chunking>
        <chunking id="8" string="her" type="NP">
          <tokens>
            <token id="16" string="her" />
          </tokens>
        </chunking>
        <chunking id="9" string="Although Taylor 's physicians are still trying to identify the virus" type="SBAR">
          <tokens>
            <token id="1" string="Although" />
            <token id="2" string="Taylor" />
            <token id="3" string="'s" />
            <token id="4" string="physicians" />
            <token id="5" string="are" />
            <token id="6" string="still" />
            <token id="7" string="trying" />
            <token id="8" string="to" />
            <token id="9" string="identify" />
            <token id="10" string="the" />
            <token id="11" string="virus" />
          </tokens>
        </chunking>
        <chunking id="10" string="Taylor 's physicians" type="NP">
          <tokens>
            <token id="2" string="Taylor" />
            <token id="3" string="'s" />
            <token id="4" string="physicians" />
          </tokens>
        </chunking>
        <chunking id="11" string="pneumonia" type="NP">
          <tokens>
            <token id="18" string="pneumonia" />
          </tokens>
        </chunking>
        <chunking id="12" string="are still trying to identify the virus" type="VP">
          <tokens>
            <token id="5" string="are" />
            <token id="6" string="still" />
            <token id="7" string="trying" />
            <token id="8" string="to" />
            <token id="9" string="identify" />
            <token id="10" string="the" />
            <token id="11" string="virus" />
          </tokens>
        </chunking>
        <chunking id="13" string="pneumonia with antibiotics" type="NP">
          <tokens>
            <token id="18" string="pneumonia" />
            <token id="19" string="with" />
            <token id="20" string="antibiotics" />
          </tokens>
        </chunking>
        <chunking id="14" string="Taylor 's" type="NP">
          <tokens>
            <token id="2" string="Taylor" />
            <token id="3" string="'s" />
          </tokens>
        </chunking>
        <chunking id="15" string="antibiotics" type="NP">
          <tokens>
            <token id="20" string="antibiotics" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="7">trying</governor>
          <dependent id="1">Although</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">physicians</governor>
          <dependent id="2">Taylor</dependent>
        </dependency>
        <dependency type="case">
          <governor id="2">Taylor</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">trying</governor>
          <dependent id="4">physicians</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">trying</governor>
          <dependent id="5">are</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">trying</governor>
          <dependent id="6">still</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="15">treating</governor>
          <dependent id="7">trying</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">identify</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">trying</governor>
          <dependent id="9">identify</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">virus</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">identify</governor>
          <dependent id="11">virus</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">treating</governor>
          <dependent id="13">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">treating</governor>
          <dependent id="14">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">treating</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">treating</governor>
          <dependent id="16">her</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">pneumonia</governor>
          <dependent id="17">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">treating</governor>
          <dependent id="18">pneumonia</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">antibiotics</governor>
          <dependent id="19">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">pneumonia</governor>
          <dependent id="20">antibiotics</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Taylor" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Taylor" />
          </tokens>
        </entity>
        <entity id="2" string="pneumonia" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="18" string="pneumonia" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="30" has_coreference="true">
      <content>And she remains in the intensive-care unit, but she continues to improve and is expected to move to a regular room this weekend, Sam said Thursday.</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="remains" lemma="remain" stem="remain" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="intensive-care" lemma="intensive-care" stem="intensive-car" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="unit" lemma="unit" stem="unit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="continues" lemma="continue" stem="continu" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="improve" lemma="improve" stem="improv" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="expected" lemma="expect" stem="expect" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="move" lemma="move" stem="move" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="regular" lemma="regular" stem="regular" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="room" lemma="room" stem="room" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="24" string="weekend" lemma="weekend" stem="weekend" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="Sam" lemma="Sam" stem="sam" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="27" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="Thursday" lemma="Thursday" stem="thursdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (S (CC And) (NP (PRP she)) (VP (VBZ remains) (PP (IN in) (NP (DT the) (JJ intensive-care) (NN unit))))) (, ,) (CC but) (S (NP (PRP she)) (VP (VP (VBZ continues) (S (VP (TO to) (VP (VB improve))))) (CC and) (VP (VBZ is) (VP (VBN expected) (S (VP (TO to) (VP (VB move) (PP (TO to) (NP (DT a) (JJ regular) (NN room))) (NP-TMP (DT this) (NN weekend)))))))))) (, ,) (NP (NNP Sam)) (VP (VBD said) (NP-TMP (NNP Thursday))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="to move to a regular room this weekend" type="VP">
          <tokens>
            <token id="17" string="to" />
            <token id="18" string="move" />
            <token id="19" string="to" />
            <token id="20" string="a" />
            <token id="21" string="regular" />
            <token id="22" string="room" />
            <token id="23" string="this" />
            <token id="24" string="weekend" />
          </tokens>
        </chunking>
        <chunking id="2" string="move to a regular room this weekend" type="VP">
          <tokens>
            <token id="18" string="move" />
            <token id="19" string="to" />
            <token id="20" string="a" />
            <token id="21" string="regular" />
            <token id="22" string="room" />
            <token id="23" string="this" />
            <token id="24" string="weekend" />
          </tokens>
        </chunking>
        <chunking id="3" string="she" type="NP">
          <tokens>
            <token id="2" string="she" />
          </tokens>
        </chunking>
        <chunking id="4" string="a regular room" type="NP">
          <tokens>
            <token id="20" string="a" />
            <token id="21" string="regular" />
            <token id="22" string="room" />
          </tokens>
        </chunking>
        <chunking id="5" string="the intensive-care unit" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="intensive-care" />
            <token id="7" string="unit" />
          </tokens>
        </chunking>
        <chunking id="6" string="continues to improve and is expected to move to a regular room this weekend" type="VP">
          <tokens>
            <token id="11" string="continues" />
            <token id="12" string="to" />
            <token id="13" string="improve" />
            <token id="14" string="and" />
            <token id="15" string="is" />
            <token id="16" string="expected" />
            <token id="17" string="to" />
            <token id="18" string="move" />
            <token id="19" string="to" />
            <token id="20" string="a" />
            <token id="21" string="regular" />
            <token id="22" string="room" />
            <token id="23" string="this" />
            <token id="24" string="weekend" />
          </tokens>
        </chunking>
        <chunking id="7" string="continues to improve" type="VP">
          <tokens>
            <token id="11" string="continues" />
            <token id="12" string="to" />
            <token id="13" string="improve" />
          </tokens>
        </chunking>
        <chunking id="8" string="to improve" type="VP">
          <tokens>
            <token id="12" string="to" />
            <token id="13" string="improve" />
          </tokens>
        </chunking>
        <chunking id="9" string="said Thursday" type="VP">
          <tokens>
            <token id="27" string="said" />
            <token id="28" string="Thursday" />
          </tokens>
        </chunking>
        <chunking id="10" string="improve" type="VP">
          <tokens>
            <token id="13" string="improve" />
          </tokens>
        </chunking>
        <chunking id="11" string="is expected to move to a regular room this weekend" type="VP">
          <tokens>
            <token id="15" string="is" />
            <token id="16" string="expected" />
            <token id="17" string="to" />
            <token id="18" string="move" />
            <token id="19" string="to" />
            <token id="20" string="a" />
            <token id="21" string="regular" />
            <token id="22" string="room" />
            <token id="23" string="this" />
            <token id="24" string="weekend" />
          </tokens>
        </chunking>
        <chunking id="12" string="remains in the intensive-care unit" type="VP">
          <tokens>
            <token id="3" string="remains" />
            <token id="4" string="in" />
            <token id="5" string="the" />
            <token id="6" string="intensive-care" />
            <token id="7" string="unit" />
          </tokens>
        </chunking>
        <chunking id="13" string="expected to move to a regular room this weekend" type="VP">
          <tokens>
            <token id="16" string="expected" />
            <token id="17" string="to" />
            <token id="18" string="move" />
            <token id="19" string="to" />
            <token id="20" string="a" />
            <token id="21" string="regular" />
            <token id="22" string="room" />
            <token id="23" string="this" />
            <token id="24" string="weekend" />
          </tokens>
        </chunking>
        <chunking id="14" string="Sam" type="NP">
          <tokens>
            <token id="26" string="Sam" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="3">remains</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">remains</governor>
          <dependent id="2">she</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="27">said</governor>
          <dependent id="3">remains</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">unit</governor>
          <dependent id="4">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">unit</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">unit</governor>
          <dependent id="6">intensive-care</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">remains</governor>
          <dependent id="7">unit</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">remains</governor>
          <dependent id="9">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">continues</governor>
          <dependent id="10">she</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">remains</governor>
          <dependent id="11">continues</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">improve</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="11">continues</governor>
          <dependent id="13">improve</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">continues</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="16">expected</governor>
          <dependent id="15">is</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">continues</governor>
          <dependent id="16">expected</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">move</governor>
          <dependent id="17">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="16">expected</governor>
          <dependent id="18">move</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">room</governor>
          <dependent id="19">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">room</governor>
          <dependent id="20">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">room</governor>
          <dependent id="21">regular</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">move</governor>
          <dependent id="22">room</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">weekend</governor>
          <dependent id="23">this</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="18">move</governor>
          <dependent id="24">weekend</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">said</governor>
          <dependent id="26">Sam</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="27">said</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="27">said</governor>
          <dependent id="28">Thursday</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Thursday" type="DATE" score="0.0">
          <tokens>
            <token id="28" string="Thursday" />
          </tokens>
        </entity>
        <entity id="2" string="this weekend" type="DATE" score="0.0">
          <tokens>
            <token id="23" string="this" />
            <token id="24" string="weekend" />
          </tokens>
        </entity>
        <entity id="3" string="Sam" type="PERSON" score="0.0">
          <tokens>
            <token id="26" string="Sam" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="31" has_coreference="true">
      <content>Meanwhile, her own security guards keep watch over her private room in intensive care.</content>
      <tokens>
        <token id="1" string="Meanwhile" lemma="meanwhile" stem="meanwhil" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="own" lemma="own" stem="own" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="security" lemma="security" stem="secur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="guards" lemma="guard" stem="guard" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="keep" lemma="keep" stem="keep" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="watch" lemma="watch" stem="watch" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="11" string="private" lemma="private" stem="privat" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="room" lemma="room" stem="room" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="intensive" lemma="intensive" stem="intens" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="care" lemma="care" stem="care" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Meanwhile)) (, ,) (NP (PRP$ her) (JJ own) (NN security) (NNS guards)) (VP (VBP keep) (NP (NN watch)) (PP (IN over) (NP (NP (PRP$ her) (JJ private) (NN room)) (PP (IN in) (NP (JJ intensive) (NN care)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="her own security guards" type="NP">
          <tokens>
            <token id="3" string="her" />
            <token id="4" string="own" />
            <token id="5" string="security" />
            <token id="6" string="guards" />
          </tokens>
        </chunking>
        <chunking id="2" string="intensive care" type="NP">
          <tokens>
            <token id="14" string="intensive" />
            <token id="15" string="care" />
          </tokens>
        </chunking>
        <chunking id="3" string="watch" type="NP">
          <tokens>
            <token id="8" string="watch" />
          </tokens>
        </chunking>
        <chunking id="4" string="her private room in intensive care" type="NP">
          <tokens>
            <token id="10" string="her" />
            <token id="11" string="private" />
            <token id="12" string="room" />
            <token id="13" string="in" />
            <token id="14" string="intensive" />
            <token id="15" string="care" />
          </tokens>
        </chunking>
        <chunking id="5" string="keep watch over her private room in intensive care" type="VP">
          <tokens>
            <token id="7" string="keep" />
            <token id="8" string="watch" />
            <token id="9" string="over" />
            <token id="10" string="her" />
            <token id="11" string="private" />
            <token id="12" string="room" />
            <token id="13" string="in" />
            <token id="14" string="intensive" />
            <token id="15" string="care" />
          </tokens>
        </chunking>
        <chunking id="6" string="her private room" type="NP">
          <tokens>
            <token id="10" string="her" />
            <token id="11" string="private" />
            <token id="12" string="room" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="7">keep</governor>
          <dependent id="1">Meanwhile</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">guards</governor>
          <dependent id="3">her</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">guards</governor>
          <dependent id="4">own</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">guards</governor>
          <dependent id="5">security</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">keep</governor>
          <dependent id="6">guards</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">keep</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">keep</governor>
          <dependent id="8">watch</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">room</governor>
          <dependent id="9">over</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">room</governor>
          <dependent id="10">her</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">room</governor>
          <dependent id="11">private</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">keep</governor>
          <dependent id="12">room</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">care</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">care</governor>
          <dependent id="14">intensive</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">room</governor>
          <dependent id="15">care</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="32" has_coreference="true">
      <content>She has received her four children -- Christopher and Michael Wilding, Maria Burton-Carson and Liza Todd-Tivey -- friends Roddy McDowall and Carole Bayer Sager and Liz&amp;apost;s younger, ex-trucker boyfriend, Larry Lee Fortensky, 38.</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="received" lemma="receive" stem="receiv" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="four" lemma="four" stem="four" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="6" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Christopher" lemma="Christopher" stem="christoph" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Michael" lemma="Michael" stem="michael" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="11" string="Wilding" lemma="Wilding" stem="wild" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Maria" lemma="Maria" stem="maria" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="14" string="Burton-Carson" lemma="Burton-Carson" stem="burton-carson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="Liza" lemma="Liza" stem="liza" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="17" string="Todd-Tivey" lemma="Todd-Tivey" stem="todd-tivei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="18" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="friends" lemma="friend" stem="friend" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="Roddy" lemma="Roddy" stem="roddi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="21" string="McDowall" lemma="McDowall" stem="mcdowal" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="22" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="Carole" lemma="Carole" stem="carol" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="24" string="Bayer" lemma="Bayer" stem="bayer" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="25" string="Sager" lemma="Sager" stem="sager" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="26" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="Liz" lemma="Liz" stem="liz" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="28" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="29" string="younger" lemma="younger" stem="younger" pos="JJR" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="30" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="31" string="ex-trucker" lemma="ex-trucker" stem="ex-truck" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string="boyfriend" lemma="boyfriend" stem="boyfriend" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="33" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="Larry" lemma="Larry" stem="larri" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="35" string="Lee" lemma="Lee" stem="lee" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="36" string="Fortensky" lemma="Fortensky" stem="fortenski" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="37" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="38" lemma="38" stem="38" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="39" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP She)) (VP (VBZ has) (VP (VBN received) (NP (NP (NP (PRP$ her) (CD four) (NNS children)) (PRN (: --) (NP (NP (NNP Christopher) (CC and) (NNP Michael) (NNP Wilding)) (, ,) (NP (NNP Maria) (NNP Burton-Carson)) (CC and) (NP (NNP Liza) (NNP Todd-Tivey))) (: --)) (NP (NNS friends) (NNP Roddy) (NNP McDowall) (CC and) (NNP Carole) (NNP Bayer) (NNP Sager))) (CC and) (NP (NP (NP (NP (NNP Liz) (POS 's)) (JJR younger) (, ,) (JJ ex-trucker) (NN boyfriend)) (, ,) (NP (NNP Larry) (NNP Lee) (NNP Fortensky)) (, ,)) (NP (CD 38)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Larry Lee Fortensky" type="NP">
          <tokens>
            <token id="34" string="Larry" />
            <token id="35" string="Lee" />
            <token id="36" string="Fortensky" />
          </tokens>
        </chunking>
        <chunking id="2" string="Liz 's" type="NP">
          <tokens>
            <token id="27" string="Liz" />
            <token id="28" string="'s" />
          </tokens>
        </chunking>
        <chunking id="3" string="38" type="NP">
          <tokens>
            <token id="38" string="38" />
          </tokens>
        </chunking>
        <chunking id="4" string="her four children" type="NP">
          <tokens>
            <token id="4" string="her" />
            <token id="5" string="four" />
            <token id="6" string="children" />
          </tokens>
        </chunking>
        <chunking id="5" string="Christopher and Michael Wilding , Maria Burton-Carson and Liza Todd-Tivey" type="NP">
          <tokens>
            <token id="8" string="Christopher" />
            <token id="9" string="and" />
            <token id="10" string="Michael" />
            <token id="11" string="Wilding" />
            <token id="12" string="," />
            <token id="13" string="Maria" />
            <token id="14" string="Burton-Carson" />
            <token id="15" string="and" />
            <token id="16" string="Liza" />
            <token id="17" string="Todd-Tivey" />
          </tokens>
        </chunking>
        <chunking id="6" string="Liza Todd-Tivey" type="NP">
          <tokens>
            <token id="16" string="Liza" />
            <token id="17" string="Todd-Tivey" />
          </tokens>
        </chunking>
        <chunking id="7" string="friends Roddy McDowall and Carole Bayer Sager" type="NP">
          <tokens>
            <token id="19" string="friends" />
            <token id="20" string="Roddy" />
            <token id="21" string="McDowall" />
            <token id="22" string="and" />
            <token id="23" string="Carole" />
            <token id="24" string="Bayer" />
            <token id="25" string="Sager" />
          </tokens>
        </chunking>
        <chunking id="8" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
        <chunking id="9" string="Liz 's younger , ex-trucker boyfriend , Larry Lee Fortensky , 38" type="NP">
          <tokens>
            <token id="27" string="Liz" />
            <token id="28" string="'s" />
            <token id="29" string="younger" />
            <token id="30" string="," />
            <token id="31" string="ex-trucker" />
            <token id="32" string="boyfriend" />
            <token id="33" string="," />
            <token id="34" string="Larry" />
            <token id="35" string="Lee" />
            <token id="36" string="Fortensky" />
            <token id="37" string="," />
            <token id="38" string="38" />
          </tokens>
        </chunking>
        <chunking id="10" string="her four children -- Christopher and Michael Wilding , Maria Burton-Carson and Liza Todd-Tivey -- friends Roddy McDowall and Carole Bayer Sager" type="NP">
          <tokens>
            <token id="4" string="her" />
            <token id="5" string="four" />
            <token id="6" string="children" />
            <token id="7" string="--" />
            <token id="8" string="Christopher" />
            <token id="9" string="and" />
            <token id="10" string="Michael" />
            <token id="11" string="Wilding" />
            <token id="12" string="," />
            <token id="13" string="Maria" />
            <token id="14" string="Burton-Carson" />
            <token id="15" string="and" />
            <token id="16" string="Liza" />
            <token id="17" string="Todd-Tivey" />
            <token id="18" string="--" />
            <token id="19" string="friends" />
            <token id="20" string="Roddy" />
            <token id="21" string="McDowall" />
            <token id="22" string="and" />
            <token id="23" string="Carole" />
            <token id="24" string="Bayer" />
            <token id="25" string="Sager" />
          </tokens>
        </chunking>
        <chunking id="11" string="Liz 's younger , ex-trucker boyfriend" type="NP">
          <tokens>
            <token id="27" string="Liz" />
            <token id="28" string="'s" />
            <token id="29" string="younger" />
            <token id="30" string="," />
            <token id="31" string="ex-trucker" />
            <token id="32" string="boyfriend" />
          </tokens>
        </chunking>
        <chunking id="12" string="her four children -- Christopher and Michael Wilding , Maria Burton-Carson and Liza Todd-Tivey -- friends Roddy McDowall and Carole Bayer Sager and Liz 's younger , ex-trucker boyfriend , Larry Lee Fortensky , 38" type="NP">
          <tokens>
            <token id="4" string="her" />
            <token id="5" string="four" />
            <token id="6" string="children" />
            <token id="7" string="--" />
            <token id="8" string="Christopher" />
            <token id="9" string="and" />
            <token id="10" string="Michael" />
            <token id="11" string="Wilding" />
            <token id="12" string="," />
            <token id="13" string="Maria" />
            <token id="14" string="Burton-Carson" />
            <token id="15" string="and" />
            <token id="16" string="Liza" />
            <token id="17" string="Todd-Tivey" />
            <token id="18" string="--" />
            <token id="19" string="friends" />
            <token id="20" string="Roddy" />
            <token id="21" string="McDowall" />
            <token id="22" string="and" />
            <token id="23" string="Carole" />
            <token id="24" string="Bayer" />
            <token id="25" string="Sager" />
            <token id="26" string="and" />
            <token id="27" string="Liz" />
            <token id="28" string="'s" />
            <token id="29" string="younger" />
            <token id="30" string="," />
            <token id="31" string="ex-trucker" />
            <token id="32" string="boyfriend" />
            <token id="33" string="," />
            <token id="34" string="Larry" />
            <token id="35" string="Lee" />
            <token id="36" string="Fortensky" />
            <token id="37" string="," />
            <token id="38" string="38" />
          </tokens>
        </chunking>
        <chunking id="13" string="Maria Burton-Carson" type="NP">
          <tokens>
            <token id="13" string="Maria" />
            <token id="14" string="Burton-Carson" />
          </tokens>
        </chunking>
        <chunking id="14" string="Christopher and Michael Wilding" type="NP">
          <tokens>
            <token id="8" string="Christopher" />
            <token id="9" string="and" />
            <token id="10" string="Michael" />
            <token id="11" string="Wilding" />
          </tokens>
        </chunking>
        <chunking id="15" string="Liz 's younger , ex-trucker boyfriend , Larry Lee Fortensky ," type="NP">
          <tokens>
            <token id="27" string="Liz" />
            <token id="28" string="'s" />
            <token id="29" string="younger" />
            <token id="30" string="," />
            <token id="31" string="ex-trucker" />
            <token id="32" string="boyfriend" />
            <token id="33" string="," />
            <token id="34" string="Larry" />
            <token id="35" string="Lee" />
            <token id="36" string="Fortensky" />
            <token id="37" string="," />
          </tokens>
        </chunking>
        <chunking id="16" string="received her four children -- Christopher and Michael Wilding , Maria Burton-Carson and Liza Todd-Tivey -- friends Roddy McDowall and Carole Bayer Sager and Liz 's younger , ex-trucker boyfriend , Larry Lee Fortensky , 38" type="VP">
          <tokens>
            <token id="3" string="received" />
            <token id="4" string="her" />
            <token id="5" string="four" />
            <token id="6" string="children" />
            <token id="7" string="--" />
            <token id="8" string="Christopher" />
            <token id="9" string="and" />
            <token id="10" string="Michael" />
            <token id="11" string="Wilding" />
            <token id="12" string="," />
            <token id="13" string="Maria" />
            <token id="14" string="Burton-Carson" />
            <token id="15" string="and" />
            <token id="16" string="Liza" />
            <token id="17" string="Todd-Tivey" />
            <token id="18" string="--" />
            <token id="19" string="friends" />
            <token id="20" string="Roddy" />
            <token id="21" string="McDowall" />
            <token id="22" string="and" />
            <token id="23" string="Carole" />
            <token id="24" string="Bayer" />
            <token id="25" string="Sager" />
            <token id="26" string="and" />
            <token id="27" string="Liz" />
            <token id="28" string="'s" />
            <token id="29" string="younger" />
            <token id="30" string="," />
            <token id="31" string="ex-trucker" />
            <token id="32" string="boyfriend" />
            <token id="33" string="," />
            <token id="34" string="Larry" />
            <token id="35" string="Lee" />
            <token id="36" string="Fortensky" />
            <token id="37" string="," />
            <token id="38" string="38" />
          </tokens>
        </chunking>
        <chunking id="17" string="has received her four children -- Christopher and Michael Wilding , Maria Burton-Carson and Liza Todd-Tivey -- friends Roddy McDowall and Carole Bayer Sager and Liz 's younger , ex-trucker boyfriend , Larry Lee Fortensky , 38" type="VP">
          <tokens>
            <token id="2" string="has" />
            <token id="3" string="received" />
            <token id="4" string="her" />
            <token id="5" string="four" />
            <token id="6" string="children" />
            <token id="7" string="--" />
            <token id="8" string="Christopher" />
            <token id="9" string="and" />
            <token id="10" string="Michael" />
            <token id="11" string="Wilding" />
            <token id="12" string="," />
            <token id="13" string="Maria" />
            <token id="14" string="Burton-Carson" />
            <token id="15" string="and" />
            <token id="16" string="Liza" />
            <token id="17" string="Todd-Tivey" />
            <token id="18" string="--" />
            <token id="19" string="friends" />
            <token id="20" string="Roddy" />
            <token id="21" string="McDowall" />
            <token id="22" string="and" />
            <token id="23" string="Carole" />
            <token id="24" string="Bayer" />
            <token id="25" string="Sager" />
            <token id="26" string="and" />
            <token id="27" string="Liz" />
            <token id="28" string="'s" />
            <token id="29" string="younger" />
            <token id="30" string="," />
            <token id="31" string="ex-trucker" />
            <token id="32" string="boyfriend" />
            <token id="33" string="," />
            <token id="34" string="Larry" />
            <token id="35" string="Lee" />
            <token id="36" string="Fortensky" />
            <token id="37" string="," />
            <token id="38" string="38" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">received</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">received</governor>
          <dependent id="2">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">received</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">children</governor>
          <dependent id="4">her</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="6">children</governor>
          <dependent id="5">four</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">received</governor>
          <dependent id="6">children</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Wilding</governor>
          <dependent id="8">Christopher</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">Christopher</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">Christopher</governor>
          <dependent id="10">Michael</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="6">children</governor>
          <dependent id="11">Wilding</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Burton-Carson</governor>
          <dependent id="13">Maria</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">Wilding</governor>
          <dependent id="14">Burton-Carson</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">Wilding</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Todd-Tivey</governor>
          <dependent id="16">Liza</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">Wilding</governor>
          <dependent id="17">Todd-Tivey</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">McDowall</governor>
          <dependent id="19">friends</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">McDowall</governor>
          <dependent id="20">Roddy</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="6">children</governor>
          <dependent id="21">McDowall</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="21">McDowall</governor>
          <dependent id="22">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">Sager</governor>
          <dependent id="23">Carole</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">Sager</governor>
          <dependent id="24">Bayer</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="21">McDowall</governor>
          <dependent id="25">Sager</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">children</governor>
          <dependent id="26">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="32">boyfriend</governor>
          <dependent id="27">Liz</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">Liz</governor>
          <dependent id="28">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="32">boyfriend</governor>
          <dependent id="29">younger</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="32">boyfriend</governor>
          <dependent id="31">ex-trucker</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">children</governor>
          <dependent id="32">boyfriend</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="36">Fortensky</governor>
          <dependent id="34">Larry</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="36">Fortensky</governor>
          <dependent id="35">Lee</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="32">boyfriend</governor>
          <dependent id="36">Fortensky</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="32">boyfriend</governor>
          <dependent id="38">38</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Larry Lee Fortensky" type="PERSON" score="0.0">
          <tokens>
            <token id="34" string="Larry" />
            <token id="35" string="Lee" />
            <token id="36" string="Fortensky" />
          </tokens>
        </entity>
        <entity id="2" string="Michael Wilding" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Michael" />
            <token id="11" string="Wilding" />
          </tokens>
        </entity>
        <entity id="3" string="Christopher" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Christopher" />
          </tokens>
        </entity>
        <entity id="4" string="Carole Bayer Sager" type="PERSON" score="0.0">
          <tokens>
            <token id="23" string="Carole" />
            <token id="24" string="Bayer" />
            <token id="25" string="Sager" />
          </tokens>
        </entity>
        <entity id="5" string="38" type="NUMBER" score="0.0">
          <tokens>
            <token id="38" string="38" />
          </tokens>
        </entity>
        <entity id="6" string="four" type="NUMBER" score="0.0">
          <tokens>
            <token id="5" string="four" />
          </tokens>
        </entity>
        <entity id="7" string="Maria Burton-Carson" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Maria" />
            <token id="14" string="Burton-Carson" />
          </tokens>
        </entity>
        <entity id="8" string="Roddy McDowall" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="Roddy" />
            <token id="21" string="McDowall" />
          </tokens>
        </entity>
        <entity id="9" string="Liza Todd-Tivey" type="PERSON" score="0.0">
          <tokens>
            <token id="16" string="Liza" />
            <token id="17" string="Todd-Tivey" />
          </tokens>
        </entity>
        <entity id="10" string="Liz" type="PERSON" score="0.0">
          <tokens>
            <token id="27" string="Liz" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="33" has_coreference="true">
      <content>&amp;quot;I saw her yesterday and I was really pleased,&amp;quot; Sager said Wednesday.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="saw" lemma="see" stem="saw" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="yesterday" lemma="yesterday" stem="yesterdai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="really" lemma="really" stem="realli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="pleased" lemma="pleased" stem="pleas" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Sager" lemma="Sager" stem="sager" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="14" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="Wednesday" lemma="Wednesday" stem="wednesdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (S (NP (PRP I)) (VP (VBD saw) (NP (PRP$ her) (NN yesterday)))) (CC and) (S (NP (PRP I)) (VP (VBD was) (ADJP (RB really) (JJ pleased))))) (, ,) ('' '') (NP (NNP Sager)) (VP (VBD said) (NP-TMP (NNP Wednesday))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was really pleased" type="VP">
          <tokens>
            <token id="8" string="was" />
            <token id="9" string="really" />
            <token id="10" string="pleased" />
          </tokens>
        </chunking>
        <chunking id="2" string="said Wednesday" type="VP">
          <tokens>
            <token id="14" string="said" />
            <token id="15" string="Wednesday" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="really pleased" type="ADJP">
          <tokens>
            <token id="9" string="really" />
            <token id="10" string="pleased" />
          </tokens>
        </chunking>
        <chunking id="5" string="Sager" type="NP">
          <tokens>
            <token id="13" string="Sager" />
          </tokens>
        </chunking>
        <chunking id="6" string="saw her yesterday" type="VP">
          <tokens>
            <token id="3" string="saw" />
            <token id="4" string="her" />
            <token id="5" string="yesterday" />
          </tokens>
        </chunking>
        <chunking id="7" string="her yesterday" type="NP">
          <tokens>
            <token id="4" string="her" />
            <token id="5" string="yesterday" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">saw</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">said</governor>
          <dependent id="3">saw</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">yesterday</governor>
          <dependent id="4">her</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="3">saw</governor>
          <dependent id="5">yesterday</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">saw</governor>
          <dependent id="6">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">pleased</governor>
          <dependent id="7">I</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="10">pleased</governor>
          <dependent id="8">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">pleased</governor>
          <dependent id="9">really</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">saw</governor>
          <dependent id="10">pleased</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">said</governor>
          <dependent id="13">Sager</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">said</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="14">said</governor>
          <dependent id="15">Wednesday</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="yesterday" type="DATE" score="0.0">
          <tokens>
            <token id="5" string="yesterday" />
          </tokens>
        </entity>
        <entity id="2" string="Wednesday" type="DATE" score="0.0">
          <tokens>
            <token id="15" string="Wednesday" />
          </tokens>
        </entity>
        <entity id="3" string="Sager" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Sager" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="34" has_coreference="true">
      <content>&amp;quot;I thought her color was good.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="thought" lemma="think" stem="thought" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="color" lemma="color" stem="color" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="good" lemma="good" stem="good" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (VBD thought) (SBAR (S (NP (PRP$ her) (NN color)) (VP (VBD was) (ADJP (JJ good)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="2" string="thought her color was good" type="VP">
          <tokens>
            <token id="3" string="thought" />
            <token id="4" string="her" />
            <token id="5" string="color" />
            <token id="6" string="was" />
            <token id="7" string="good" />
          </tokens>
        </chunking>
        <chunking id="3" string="was good" type="VP">
          <tokens>
            <token id="6" string="was" />
            <token id="7" string="good" />
          </tokens>
        </chunking>
        <chunking id="4" string="her color" type="NP">
          <tokens>
            <token id="4" string="her" />
            <token id="5" string="color" />
          </tokens>
        </chunking>
        <chunking id="5" string="good" type="ADJP">
          <tokens>
            <token id="7" string="good" />
          </tokens>
        </chunking>
        <chunking id="6" string="her color was good" type="SBAR">
          <tokens>
            <token id="4" string="her" />
            <token id="5" string="color" />
            <token id="6" string="was" />
            <token id="7" string="good" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">thought</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">thought</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">color</governor>
          <dependent id="4">her</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">good</governor>
          <dependent id="5">color</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">good</governor>
          <dependent id="6">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">thought</governor>
          <dependent id="7">good</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="35" has_coreference="true">
      <content>She couldn&amp;apost;t speak because she had the respirator.</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="speak" lemma="speak" stem="speak" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="respirator" lemma="respirator" stem="respir" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP She)) (VP (MD could) (RB n't) (VP (VB speak) (SBAR (IN because) (S (NP (PRP she)) (VP (VBD had) (NP (DT the) (NN respirator))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the respirator" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="respirator" />
          </tokens>
        </chunking>
        <chunking id="2" string="speak because she had the respirator" type="VP">
          <tokens>
            <token id="4" string="speak" />
            <token id="5" string="because" />
            <token id="6" string="she" />
            <token id="7" string="had" />
            <token id="8" string="the" />
            <token id="9" string="respirator" />
          </tokens>
        </chunking>
        <chunking id="3" string="could n't speak because she had the respirator" type="VP">
          <tokens>
            <token id="2" string="could" />
            <token id="3" string="n't" />
            <token id="4" string="speak" />
            <token id="5" string="because" />
            <token id="6" string="she" />
            <token id="7" string="had" />
            <token id="8" string="the" />
            <token id="9" string="respirator" />
          </tokens>
        </chunking>
        <chunking id="4" string="had the respirator" type="VP">
          <tokens>
            <token id="7" string="had" />
            <token id="8" string="the" />
            <token id="9" string="respirator" />
          </tokens>
        </chunking>
        <chunking id="5" string="because she had the respirator" type="SBAR">
          <tokens>
            <token id="5" string="because" />
            <token id="6" string="she" />
            <token id="7" string="had" />
            <token id="8" string="the" />
            <token id="9" string="respirator" />
          </tokens>
        </chunking>
        <chunking id="6" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
        <chunking id="7" string="she" type="NP">
          <tokens>
            <token id="6" string="she" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">speak</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">speak</governor>
          <dependent id="2">could</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">speak</governor>
          <dependent id="3">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">speak</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">had</governor>
          <dependent id="5">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">had</governor>
          <dependent id="6">she</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">speak</governor>
          <dependent id="7">had</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">respirator</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">had</governor>
          <dependent id="9">respirator</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="36" has_coreference="true">
      <content>Her eyes were clear and she definitely understood what I said and motioned, made me know she understood.&amp;quot;</content>
      <tokens>
        <token id="1" string="Her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="eyes" lemma="eye" stem="ey" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="clear" lemma="clear" stem="clear" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="definitely" lemma="definitely" stem="definit" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="understood" lemma="understand" stem="understood" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="motioned" lemma="motion" stem="motion" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="made" lemma="make" stem="made" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="know" lemma="know" stem="know" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="understood" lemma="understand" stem="understood" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP$ Her) (NNS eyes)) (VP (VBD were) (ADJP (JJ clear)))) (CC and) (S (NP (PRP she)) (ADVP (RB definitely)) (VP (VBD understood) (SBAR (WHNP (WP what)) (S (NP (PRP I)) (VP (VP (VBD said)) (CC and) (VP (VBD motioned)) (, ,) (VP (VBD made) (S (NP (PRP me)) (VP (VB know) (S (NP (PRP she)) (VP (VBN understood))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="understood what I said and motioned , made me know she understood" type="VP">
          <tokens>
            <token id="8" string="understood" />
            <token id="9" string="what" />
            <token id="10" string="I" />
            <token id="11" string="said" />
            <token id="12" string="and" />
            <token id="13" string="motioned" />
            <token id="14" string="," />
            <token id="15" string="made" />
            <token id="16" string="me" />
            <token id="17" string="know" />
            <token id="18" string="she" />
            <token id="19" string="understood" />
          </tokens>
        </chunking>
        <chunking id="2" string="said and motioned , made me know she understood" type="VP">
          <tokens>
            <token id="11" string="said" />
            <token id="12" string="and" />
            <token id="13" string="motioned" />
            <token id="14" string="," />
            <token id="15" string="made" />
            <token id="16" string="me" />
            <token id="17" string="know" />
            <token id="18" string="she" />
            <token id="19" string="understood" />
          </tokens>
        </chunking>
        <chunking id="3" string="made me know she understood" type="VP">
          <tokens>
            <token id="15" string="made" />
            <token id="16" string="me" />
            <token id="17" string="know" />
            <token id="18" string="she" />
            <token id="19" string="understood" />
          </tokens>
        </chunking>
        <chunking id="4" string="know she understood" type="VP">
          <tokens>
            <token id="17" string="know" />
            <token id="18" string="she" />
            <token id="19" string="understood" />
          </tokens>
        </chunking>
        <chunking id="5" string="I" type="NP">
          <tokens>
            <token id="10" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="Her eyes" type="NP">
          <tokens>
            <token id="1" string="Her" />
            <token id="2" string="eyes" />
          </tokens>
        </chunking>
        <chunking id="7" string="clear" type="ADJP">
          <tokens>
            <token id="4" string="clear" />
          </tokens>
        </chunking>
        <chunking id="8" string="she" type="NP">
          <tokens>
            <token id="6" string="she" />
          </tokens>
        </chunking>
        <chunking id="9" string="were clear" type="VP">
          <tokens>
            <token id="3" string="were" />
            <token id="4" string="clear" />
          </tokens>
        </chunking>
        <chunking id="10" string="motioned" type="VP">
          <tokens>
            <token id="13" string="motioned" />
          </tokens>
        </chunking>
        <chunking id="11" string="me" type="NP">
          <tokens>
            <token id="16" string="me" />
          </tokens>
        </chunking>
        <chunking id="12" string="what I said and motioned , made me know she understood" type="SBAR">
          <tokens>
            <token id="9" string="what" />
            <token id="10" string="I" />
            <token id="11" string="said" />
            <token id="12" string="and" />
            <token id="13" string="motioned" />
            <token id="14" string="," />
            <token id="15" string="made" />
            <token id="16" string="me" />
            <token id="17" string="know" />
            <token id="18" string="she" />
            <token id="19" string="understood" />
          </tokens>
        </chunking>
        <chunking id="13" string="understood" type="VP">
          <tokens>
            <token id="19" string="understood" />
          </tokens>
        </chunking>
        <chunking id="14" string="said" type="VP">
          <tokens>
            <token id="11" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="2">eyes</governor>
          <dependent id="1">Her</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">clear</governor>
          <dependent id="2">eyes</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">clear</governor>
          <dependent id="3">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">clear</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">clear</governor>
          <dependent id="5">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">understood</governor>
          <dependent id="6">she</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">understood</governor>
          <dependent id="7">definitely</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">clear</governor>
          <dependent id="8">understood</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">said</governor>
          <dependent id="9">what</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">said</governor>
          <dependent id="10">I</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">understood</governor>
          <dependent id="11">said</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">said</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">said</governor>
          <dependent id="13">motioned</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="11">said</governor>
          <dependent id="15">made</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">know</governor>
          <dependent id="16">me</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">made</governor>
          <dependent id="17">know</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">understood</governor>
          <dependent id="18">she</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="17">know</governor>
          <dependent id="19">understood</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="37" has_coreference="true">
      <content>If Liz&amp;apost;s public is fascinated by her frailties, perhaps reassured somehow by the knowledge that even the gods are vulnerable, their interest is also piqued by the public face she puts on her relentless brushes with illness and addiction.</content>
      <tokens>
        <token id="1" string="If" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Liz" lemma="Liz" stem="liz" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="public" lemma="public" stem="public" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="fascinated" lemma="fascinate" stem="fascin" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="frailties" lemma="frailty" stem="frailti" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="perhaps" lemma="perhaps" stem="perhap" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="reassured" lemma="reassure" stem="reassur" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="somehow" lemma="somehow" stem="somehow" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="knowledge" lemma="knowledge" stem="knowledg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="gods" lemma="god" stem="god" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="vulnerable" lemma="vulnerable" stem="vulner" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="interest" lemma="interest" stem="interest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="piqued" lemma="pique" stem="piqu" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="public" lemma="public" stem="public" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="face" lemma="face" stem="face" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="34" string="puts" lemma="put" stem="put" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="37" string="relentless" lemma="relentless" stem="relentless" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="brushes" lemma="brush" stem="brush" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="illness" lemma="illness" stem="ill" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="addiction" lemma="addiction" stem="addict" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN If) (S (NP (NP (NNP Liz) (POS 's)) (NN public)) (VP (VBZ is) (VP (VBN fascinated) (PP (IN by) (NP (PRP$ her) (NNS frailties))))))) (, ,) (ADVP (RB perhaps)) (VP (VBD reassured) (ADVP (RB somehow)) (PP (IN by) (NP (NP (DT the) (NN knowledge)) (SBAR (WHNP (WDT that)) (S (SBAR (RB even) (S (NP (DT the) (NNS gods)) (VP (VBP are) (ADJP (JJ vulnerable))))) (, ,) (NP (PRP$ their) (NN interest)) (VP (VBZ is) (ADVP (RB also)) (VP (VBN piqued) (PP (IN by) (NP (NP (DT the) (JJ public) (NN face)) (SBAR (S (NP (PRP she)) (VP (VBZ puts) (PP (IN on) (NP (PRP$ her) (JJ relentless) (NNS brushes))) (PP (IN with) (NP (NN illness) (CC and) (NN addiction))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Liz 's" type="NP">
          <tokens>
            <token id="2" string="Liz" />
            <token id="3" string="'s" />
          </tokens>
        </chunking>
        <chunking id="2" string="reassured somehow by the knowledge that even the gods are vulnerable , their interest is also piqued by the public face she puts on her relentless brushes with illness and addiction" type="VP">
          <tokens>
            <token id="12" string="reassured" />
            <token id="13" string="somehow" />
            <token id="14" string="by" />
            <token id="15" string="the" />
            <token id="16" string="knowledge" />
            <token id="17" string="that" />
            <token id="18" string="even" />
            <token id="19" string="the" />
            <token id="20" string="gods" />
            <token id="21" string="are" />
            <token id="22" string="vulnerable" />
            <token id="23" string="," />
            <token id="24" string="their" />
            <token id="25" string="interest" />
            <token id="26" string="is" />
            <token id="27" string="also" />
            <token id="28" string="piqued" />
            <token id="29" string="by" />
            <token id="30" string="the" />
            <token id="31" string="public" />
            <token id="32" string="face" />
            <token id="33" string="she" />
            <token id="34" string="puts" />
            <token id="35" string="on" />
            <token id="36" string="her" />
            <token id="37" string="relentless" />
            <token id="38" string="brushes" />
            <token id="39" string="with" />
            <token id="40" string="illness" />
            <token id="41" string="and" />
            <token id="42" string="addiction" />
          </tokens>
        </chunking>
        <chunking id="3" string="piqued by the public face she puts on her relentless brushes with illness and addiction" type="VP">
          <tokens>
            <token id="28" string="piqued" />
            <token id="29" string="by" />
            <token id="30" string="the" />
            <token id="31" string="public" />
            <token id="32" string="face" />
            <token id="33" string="she" />
            <token id="34" string="puts" />
            <token id="35" string="on" />
            <token id="36" string="her" />
            <token id="37" string="relentless" />
            <token id="38" string="brushes" />
            <token id="39" string="with" />
            <token id="40" string="illness" />
            <token id="41" string="and" />
            <token id="42" string="addiction" />
          </tokens>
        </chunking>
        <chunking id="4" string="that even the gods are vulnerable , their interest is also piqued by the public face she puts on her relentless brushes with illness and addiction" type="SBAR">
          <tokens>
            <token id="17" string="that" />
            <token id="18" string="even" />
            <token id="19" string="the" />
            <token id="20" string="gods" />
            <token id="21" string="are" />
            <token id="22" string="vulnerable" />
            <token id="23" string="," />
            <token id="24" string="their" />
            <token id="25" string="interest" />
            <token id="26" string="is" />
            <token id="27" string="also" />
            <token id="28" string="piqued" />
            <token id="29" string="by" />
            <token id="30" string="the" />
            <token id="31" string="public" />
            <token id="32" string="face" />
            <token id="33" string="she" />
            <token id="34" string="puts" />
            <token id="35" string="on" />
            <token id="36" string="her" />
            <token id="37" string="relentless" />
            <token id="38" string="brushes" />
            <token id="39" string="with" />
            <token id="40" string="illness" />
            <token id="41" string="and" />
            <token id="42" string="addiction" />
          </tokens>
        </chunking>
        <chunking id="5" string="is fascinated by her frailties" type="VP">
          <tokens>
            <token id="5" string="is" />
            <token id="6" string="fascinated" />
            <token id="7" string="by" />
            <token id="8" string="her" />
            <token id="9" string="frailties" />
          </tokens>
        </chunking>
        <chunking id="6" string="the public face" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="public" />
            <token id="32" string="face" />
          </tokens>
        </chunking>
        <chunking id="7" string="even the gods are vulnerable" type="SBAR">
          <tokens>
            <token id="18" string="even" />
            <token id="19" string="the" />
            <token id="20" string="gods" />
            <token id="21" string="are" />
            <token id="22" string="vulnerable" />
          </tokens>
        </chunking>
        <chunking id="8" string="puts on her relentless brushes with illness and addiction" type="VP">
          <tokens>
            <token id="34" string="puts" />
            <token id="35" string="on" />
            <token id="36" string="her" />
            <token id="37" string="relentless" />
            <token id="38" string="brushes" />
            <token id="39" string="with" />
            <token id="40" string="illness" />
            <token id="41" string="and" />
            <token id="42" string="addiction" />
          </tokens>
        </chunking>
        <chunking id="9" string="she" type="NP">
          <tokens>
            <token id="33" string="she" />
          </tokens>
        </chunking>
        <chunking id="10" string="their interest" type="NP">
          <tokens>
            <token id="24" string="their" />
            <token id="25" string="interest" />
          </tokens>
        </chunking>
        <chunking id="11" string="the knowledge that even the gods are vulnerable , their interest is also piqued by the public face she puts on her relentless brushes with illness and addiction" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="knowledge" />
            <token id="17" string="that" />
            <token id="18" string="even" />
            <token id="19" string="the" />
            <token id="20" string="gods" />
            <token id="21" string="are" />
            <token id="22" string="vulnerable" />
            <token id="23" string="," />
            <token id="24" string="their" />
            <token id="25" string="interest" />
            <token id="26" string="is" />
            <token id="27" string="also" />
            <token id="28" string="piqued" />
            <token id="29" string="by" />
            <token id="30" string="the" />
            <token id="31" string="public" />
            <token id="32" string="face" />
            <token id="33" string="she" />
            <token id="34" string="puts" />
            <token id="35" string="on" />
            <token id="36" string="her" />
            <token id="37" string="relentless" />
            <token id="38" string="brushes" />
            <token id="39" string="with" />
            <token id="40" string="illness" />
            <token id="41" string="and" />
            <token id="42" string="addiction" />
          </tokens>
        </chunking>
        <chunking id="12" string="illness and addiction" type="NP">
          <tokens>
            <token id="40" string="illness" />
            <token id="41" string="and" />
            <token id="42" string="addiction" />
          </tokens>
        </chunking>
        <chunking id="13" string="If Liz 's public is fascinated by her frailties" type="SBAR">
          <tokens>
            <token id="1" string="If" />
            <token id="2" string="Liz" />
            <token id="3" string="'s" />
            <token id="4" string="public" />
            <token id="5" string="is" />
            <token id="6" string="fascinated" />
            <token id="7" string="by" />
            <token id="8" string="her" />
            <token id="9" string="frailties" />
          </tokens>
        </chunking>
        <chunking id="14" string="fascinated by her frailties" type="VP">
          <tokens>
            <token id="6" string="fascinated" />
            <token id="7" string="by" />
            <token id="8" string="her" />
            <token id="9" string="frailties" />
          </tokens>
        </chunking>
        <chunking id="15" string="the public face she puts on her relentless brushes with illness and addiction" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="public" />
            <token id="32" string="face" />
            <token id="33" string="she" />
            <token id="34" string="puts" />
            <token id="35" string="on" />
            <token id="36" string="her" />
            <token id="37" string="relentless" />
            <token id="38" string="brushes" />
            <token id="39" string="with" />
            <token id="40" string="illness" />
            <token id="41" string="and" />
            <token id="42" string="addiction" />
          </tokens>
        </chunking>
        <chunking id="16" string="her relentless brushes" type="NP">
          <tokens>
            <token id="36" string="her" />
            <token id="37" string="relentless" />
            <token id="38" string="brushes" />
          </tokens>
        </chunking>
        <chunking id="17" string="the gods" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="gods" />
          </tokens>
        </chunking>
        <chunking id="18" string="is also piqued by the public face she puts on her relentless brushes with illness and addiction" type="VP">
          <tokens>
            <token id="26" string="is" />
            <token id="27" string="also" />
            <token id="28" string="piqued" />
            <token id="29" string="by" />
            <token id="30" string="the" />
            <token id="31" string="public" />
            <token id="32" string="face" />
            <token id="33" string="she" />
            <token id="34" string="puts" />
            <token id="35" string="on" />
            <token id="36" string="her" />
            <token id="37" string="relentless" />
            <token id="38" string="brushes" />
            <token id="39" string="with" />
            <token id="40" string="illness" />
            <token id="41" string="and" />
            <token id="42" string="addiction" />
          </tokens>
        </chunking>
        <chunking id="19" string="the knowledge" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="knowledge" />
          </tokens>
        </chunking>
        <chunking id="20" string="are vulnerable" type="VP">
          <tokens>
            <token id="21" string="are" />
            <token id="22" string="vulnerable" />
          </tokens>
        </chunking>
        <chunking id="21" string="she puts on her relentless brushes with illness and addiction" type="SBAR">
          <tokens>
            <token id="33" string="she" />
            <token id="34" string="puts" />
            <token id="35" string="on" />
            <token id="36" string="her" />
            <token id="37" string="relentless" />
            <token id="38" string="brushes" />
            <token id="39" string="with" />
            <token id="40" string="illness" />
            <token id="41" string="and" />
            <token id="42" string="addiction" />
          </tokens>
        </chunking>
        <chunking id="22" string="her frailties" type="NP">
          <tokens>
            <token id="8" string="her" />
            <token id="9" string="frailties" />
          </tokens>
        </chunking>
        <chunking id="23" string="vulnerable" type="ADJP">
          <tokens>
            <token id="22" string="vulnerable" />
          </tokens>
        </chunking>
        <chunking id="24" string="Liz 's public" type="NP">
          <tokens>
            <token id="2" string="Liz" />
            <token id="3" string="'s" />
            <token id="4" string="public" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="6">fascinated</governor>
          <dependent id="1">If</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">public</governor>
          <dependent id="2">Liz</dependent>
        </dependency>
        <dependency type="case">
          <governor id="2">Liz</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="6">fascinated</governor>
          <dependent id="4">public</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">fascinated</governor>
          <dependent id="5">is</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">reassured</governor>
          <dependent id="6">fascinated</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">frailties</governor>
          <dependent id="7">by</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">frailties</governor>
          <dependent id="8">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">fascinated</governor>
          <dependent id="9">frailties</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">reassured</governor>
          <dependent id="11">perhaps</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">reassured</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">reassured</governor>
          <dependent id="13">somehow</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">knowledge</governor>
          <dependent id="14">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">knowledge</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">reassured</governor>
          <dependent id="16">knowledge</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="28">piqued</governor>
          <dependent id="17">that</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="22">vulnerable</governor>
          <dependent id="18">even</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">gods</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">vulnerable</governor>
          <dependent id="20">gods</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="22">vulnerable</governor>
          <dependent id="21">are</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="28">piqued</governor>
          <dependent id="22">vulnerable</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="25">interest</governor>
          <dependent id="24">their</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="28">piqued</governor>
          <dependent id="25">interest</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="28">piqued</governor>
          <dependent id="26">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="28">piqued</governor>
          <dependent id="27">also</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="16">knowledge</governor>
          <dependent id="28">piqued</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">face</governor>
          <dependent id="29">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">face</governor>
          <dependent id="30">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="32">face</governor>
          <dependent id="31">public</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">piqued</governor>
          <dependent id="32">face</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="34">puts</governor>
          <dependent id="33">she</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="32">face</governor>
          <dependent id="34">puts</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">brushes</governor>
          <dependent id="35">on</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="38">brushes</governor>
          <dependent id="36">her</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="38">brushes</governor>
          <dependent id="37">relentless</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="34">puts</governor>
          <dependent id="38">brushes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="40">illness</governor>
          <dependent id="39">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="34">puts</governor>
          <dependent id="40">illness</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="40">illness</governor>
          <dependent id="41">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="40">illness</governor>
          <dependent id="42">addiction</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Liz" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Liz" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="38" has_coreference="true">
      <content>The Taylor wit shone through even Wednesday&amp;apost;s press conference, when doctors passed on the actress&amp;apost; desire to &amp;quot;come out and wave at you, but she wasn&amp;apost;t in her balcony attire.&amp;quot;</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Taylor" lemma="Taylor" stem="taylor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="wit" lemma="wit" stem="wit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="shone" lemma="shine" stem="shone" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="Wednesday" lemma="Wednesday" stem="wednesdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="8" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="press" lemma="press" stem="press" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="conference" lemma="conference" stem="confer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="doctors" lemma="doctor" stem="doctor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="passed" lemma="pass" stem="pass" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="actress" lemma="actress" stem="actress" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="desire" lemma="desire" stem="desir" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="come" lemma="come" stem="come" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="wave" lemma="wave" stem="wave" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="28" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="35" string="balcony" lemma="balcony" stem="balconi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="attire" lemma="attire" stem="attir" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT The) (NNP Taylor) (NN wit)) (VP (VBD shone) (PP (IN through) (NP (NP (RB even) (NP (NNP Wednesday) (POS 's)) (NN press) (NN conference)) (, ,) (SBAR (WHADVP (WRB when)) (S (NP (NNS doctors)) (VP (VP (VBN passed) (PP (IN on) (NP (DT the) (NN actress) ('' ') (NN desire))) (S (VP (TO to) (`` ``) (VP (VB come) (PRT (RP out)))))) (CC and) (VP (NP (NN wave)) (PP (IN at) (NP (PRP you))))))))))) (, ,) (CC but) (S (NP (PRP she)) (VP (VBD was) (RB n't) (PP (IN in) (NP (PRP$ her) (NN balcony) (NN attire))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="passed on the actress ' desire to `` come out" type="VP">
          <tokens>
            <token id="14" string="passed" />
            <token id="15" string="on" />
            <token id="16" string="the" />
            <token id="17" string="actress" />
            <token id="18" string="'" />
            <token id="19" string="desire" />
            <token id="20" string="to" />
            <token id="21" string="&quot;" />
            <token id="22" string="come" />
            <token id="23" string="out" />
          </tokens>
        </chunking>
        <chunking id="2" string="even Wednesday 's press conference" type="NP">
          <tokens>
            <token id="6" string="even" />
            <token id="7" string="Wednesday" />
            <token id="8" string="'s" />
            <token id="9" string="press" />
            <token id="10" string="conference" />
          </tokens>
        </chunking>
        <chunking id="3" string="the actress ' desire" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="actress" />
            <token id="18" string="'" />
            <token id="19" string="desire" />
          </tokens>
        </chunking>
        <chunking id="4" string="to `` come out" type="VP">
          <tokens>
            <token id="20" string="to" />
            <token id="21" string="&quot;" />
            <token id="22" string="come" />
            <token id="23" string="out" />
          </tokens>
        </chunking>
        <chunking id="5" string="even Wednesday 's press conference , when doctors passed on the actress ' desire to `` come out and wave at you" type="NP">
          <tokens>
            <token id="6" string="even" />
            <token id="7" string="Wednesday" />
            <token id="8" string="'s" />
            <token id="9" string="press" />
            <token id="10" string="conference" />
            <token id="11" string="," />
            <token id="12" string="when" />
            <token id="13" string="doctors" />
            <token id="14" string="passed" />
            <token id="15" string="on" />
            <token id="16" string="the" />
            <token id="17" string="actress" />
            <token id="18" string="'" />
            <token id="19" string="desire" />
            <token id="20" string="to" />
            <token id="21" string="&quot;" />
            <token id="22" string="come" />
            <token id="23" string="out" />
            <token id="24" string="and" />
            <token id="25" string="wave" />
            <token id="26" string="at" />
            <token id="27" string="you" />
          </tokens>
        </chunking>
        <chunking id="6" string="when" type="WHADVP">
          <tokens>
            <token id="12" string="when" />
          </tokens>
        </chunking>
        <chunking id="7" string="she" type="NP">
          <tokens>
            <token id="30" string="she" />
          </tokens>
        </chunking>
        <chunking id="8" string="wave" type="NP">
          <tokens>
            <token id="25" string="wave" />
          </tokens>
        </chunking>
        <chunking id="9" string="her balcony attire" type="NP">
          <tokens>
            <token id="34" string="her" />
            <token id="35" string="balcony" />
            <token id="36" string="attire" />
          </tokens>
        </chunking>
        <chunking id="10" string="doctors" type="NP">
          <tokens>
            <token id="13" string="doctors" />
          </tokens>
        </chunking>
        <chunking id="11" string="Wednesday 's" type="NP">
          <tokens>
            <token id="7" string="Wednesday" />
            <token id="8" string="'s" />
          </tokens>
        </chunking>
        <chunking id="12" string="shone through even Wednesday 's press conference , when doctors passed on the actress ' desire to `` come out and wave at you" type="VP">
          <tokens>
            <token id="4" string="shone" />
            <token id="5" string="through" />
            <token id="6" string="even" />
            <token id="7" string="Wednesday" />
            <token id="8" string="'s" />
            <token id="9" string="press" />
            <token id="10" string="conference" />
            <token id="11" string="," />
            <token id="12" string="when" />
            <token id="13" string="doctors" />
            <token id="14" string="passed" />
            <token id="15" string="on" />
            <token id="16" string="the" />
            <token id="17" string="actress" />
            <token id="18" string="'" />
            <token id="19" string="desire" />
            <token id="20" string="to" />
            <token id="21" string="&quot;" />
            <token id="22" string="come" />
            <token id="23" string="out" />
            <token id="24" string="and" />
            <token id="25" string="wave" />
            <token id="26" string="at" />
            <token id="27" string="you" />
          </tokens>
        </chunking>
        <chunking id="13" string="come out" type="VP">
          <tokens>
            <token id="22" string="come" />
            <token id="23" string="out" />
          </tokens>
        </chunking>
        <chunking id="14" string="The Taylor wit" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Taylor" />
            <token id="3" string="wit" />
          </tokens>
        </chunking>
        <chunking id="15" string="when doctors passed on the actress ' desire to `` come out and wave at you" type="SBAR">
          <tokens>
            <token id="12" string="when" />
            <token id="13" string="doctors" />
            <token id="14" string="passed" />
            <token id="15" string="on" />
            <token id="16" string="the" />
            <token id="17" string="actress" />
            <token id="18" string="'" />
            <token id="19" string="desire" />
            <token id="20" string="to" />
            <token id="21" string="&quot;" />
            <token id="22" string="come" />
            <token id="23" string="out" />
            <token id="24" string="and" />
            <token id="25" string="wave" />
            <token id="26" string="at" />
            <token id="27" string="you" />
          </tokens>
        </chunking>
        <chunking id="16" string="was n't in her balcony attire" type="VP">
          <tokens>
            <token id="31" string="was" />
            <token id="32" string="n't" />
            <token id="33" string="in" />
            <token id="34" string="her" />
            <token id="35" string="balcony" />
            <token id="36" string="attire" />
          </tokens>
        </chunking>
        <chunking id="17" string="wave at you" type="VP">
          <tokens>
            <token id="25" string="wave" />
            <token id="26" string="at" />
            <token id="27" string="you" />
          </tokens>
        </chunking>
        <chunking id="18" string="passed on the actress ' desire to `` come out and wave at you" type="VP">
          <tokens>
            <token id="14" string="passed" />
            <token id="15" string="on" />
            <token id="16" string="the" />
            <token id="17" string="actress" />
            <token id="18" string="'" />
            <token id="19" string="desire" />
            <token id="20" string="to" />
            <token id="21" string="&quot;" />
            <token id="22" string="come" />
            <token id="23" string="out" />
            <token id="24" string="and" />
            <token id="25" string="wave" />
            <token id="26" string="at" />
            <token id="27" string="you" />
          </tokens>
        </chunking>
        <chunking id="19" string="you" type="NP">
          <tokens>
            <token id="27" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">wit</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">wit</governor>
          <dependent id="2">Taylor</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">shone</governor>
          <dependent id="3">wit</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">shone</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">conference</governor>
          <dependent id="5">through</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">conference</governor>
          <dependent id="6">even</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">conference</governor>
          <dependent id="7">Wednesday</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Wednesday</governor>
          <dependent id="8">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">conference</governor>
          <dependent id="9">press</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">shone</governor>
          <dependent id="10">conference</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">passed</governor>
          <dependent id="12">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">passed</governor>
          <dependent id="13">doctors</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="10">conference</governor>
          <dependent id="14">passed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">desire</governor>
          <dependent id="15">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">desire</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">desire</governor>
          <dependent id="17">actress</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">passed</governor>
          <dependent id="19">desire</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">come</governor>
          <dependent id="20">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="14">passed</governor>
          <dependent id="22">come</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="22">come</governor>
          <dependent id="23">out</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">passed</governor>
          <dependent id="24">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">passed</governor>
          <dependent id="25">wave</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">you</governor>
          <dependent id="26">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">wave</governor>
          <dependent id="27">you</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">shone</governor>
          <dependent id="29">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="36">attire</governor>
          <dependent id="30">she</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="36">attire</governor>
          <dependent id="31">was</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="36">attire</governor>
          <dependent id="32">n't</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">attire</governor>
          <dependent id="33">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="36">attire</governor>
          <dependent id="34">her</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="36">attire</governor>
          <dependent id="35">balcony</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">shone</governor>
          <dependent id="36">attire</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Taylor" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Taylor" />
          </tokens>
        </entity>
        <entity id="2" string="Wednesday" type="DATE" score="0.0">
          <tokens>
            <token id="7" string="Wednesday" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="39" has_coreference="true">
      <content>&amp;quot;I think she&amp;apost;s extraordinarily brave,&amp;quot; Sager said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="think" lemma="think" stem="think" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="extraordinarily" lemma="extraordinarily" stem="extraordinarili" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="brave" lemma="brave" stem="brave" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Sager" lemma="Sager" stem="sager" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP I)) (VP (VBP think) (SBAR (S (NP (PRP she)) (VP (VBZ 's) (ADJP (RB extraordinarily) (SBAR (S (VP (VB brave)))))))))) (, ,) ('' '') (NP (NNP Sager)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="extraordinarily brave" type="ADJP">
          <tokens>
            <token id="6" string="extraordinarily" />
            <token id="7" string="brave" />
          </tokens>
        </chunking>
        <chunking id="2" string="brave" type="SBAR">
          <tokens>
            <token id="7" string="brave" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="she 's extraordinarily brave" type="SBAR">
          <tokens>
            <token id="4" string="she" />
            <token id="5" string="'s" />
            <token id="6" string="extraordinarily" />
            <token id="7" string="brave" />
          </tokens>
        </chunking>
        <chunking id="5" string="Sager" type="NP">
          <tokens>
            <token id="10" string="Sager" />
          </tokens>
        </chunking>
        <chunking id="6" string="think she 's extraordinarily brave" type="VP">
          <tokens>
            <token id="3" string="think" />
            <token id="4" string="she" />
            <token id="5" string="'s" />
            <token id="6" string="extraordinarily" />
            <token id="7" string="brave" />
          </tokens>
        </chunking>
        <chunking id="7" string="'s extraordinarily brave" type="VP">
          <tokens>
            <token id="5" string="'s" />
            <token id="6" string="extraordinarily" />
            <token id="7" string="brave" />
          </tokens>
        </chunking>
        <chunking id="8" string="said" type="VP">
          <tokens>
            <token id="11" string="said" />
          </tokens>
        </chunking>
        <chunking id="9" string="she" type="NP">
          <tokens>
            <token id="4" string="she" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">think</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">said</governor>
          <dependent id="3">think</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">extraordinarily</governor>
          <dependent id="4">she</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">extraordinarily</governor>
          <dependent id="5">'s</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">think</governor>
          <dependent id="6">extraordinarily</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">extraordinarily</governor>
          <dependent id="7">brave</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">said</governor>
          <dependent id="10">Sager</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Sager" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Sager" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="40" has_coreference="true">
      <content>&amp;quot;She just has an enormous reservoir of inner strength that she calls on when she has to.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="enormous" lemma="enormous" stem="enorm" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="reservoir" lemma="reservoir" stem="reservoir" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="inner" lemma="inner" stem="inner" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="strength" lemma="strength" stem="strength" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="calls" lemma="call" stem="call" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP She)) (ADVP (RB just)) (VP (VBZ has) (NP (NP (DT an) (JJ enormous) (NN reservoir)) (PP (IN of) (NP (JJ inner) (NN strength)))) (SBAR (IN that) (S (NP (PRP she)) (VP (VBZ calls) (PP (IN on) (SBAR (WHADVP (WRB when)) (S (NP (PRP she)) (VP (VBZ has) (VP (PP (TO to))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that she calls on when she has to" type="SBAR">
          <tokens>
            <token id="11" string="that" />
            <token id="12" string="she" />
            <token id="13" string="calls" />
            <token id="14" string="on" />
            <token id="15" string="when" />
            <token id="16" string="she" />
            <token id="17" string="has" />
            <token id="18" string="to" />
          </tokens>
        </chunking>
        <chunking id="2" string="inner strength" type="NP">
          <tokens>
            <token id="9" string="inner" />
            <token id="10" string="strength" />
          </tokens>
        </chunking>
        <chunking id="3" string="calls on when she has to" type="VP">
          <tokens>
            <token id="13" string="calls" />
            <token id="14" string="on" />
            <token id="15" string="when" />
            <token id="16" string="she" />
            <token id="17" string="has" />
            <token id="18" string="to" />
          </tokens>
        </chunking>
        <chunking id="4" string="has to" type="VP">
          <tokens>
            <token id="17" string="has" />
            <token id="18" string="to" />
          </tokens>
        </chunking>
        <chunking id="5" string="has an enormous reservoir of inner strength that she calls on when she has to" type="VP">
          <tokens>
            <token id="4" string="has" />
            <token id="5" string="an" />
            <token id="6" string="enormous" />
            <token id="7" string="reservoir" />
            <token id="8" string="of" />
            <token id="9" string="inner" />
            <token id="10" string="strength" />
            <token id="11" string="that" />
            <token id="12" string="she" />
            <token id="13" string="calls" />
            <token id="14" string="on" />
            <token id="15" string="when" />
            <token id="16" string="she" />
            <token id="17" string="has" />
            <token id="18" string="to" />
          </tokens>
        </chunking>
        <chunking id="6" string="an enormous reservoir" type="NP">
          <tokens>
            <token id="5" string="an" />
            <token id="6" string="enormous" />
            <token id="7" string="reservoir" />
          </tokens>
        </chunking>
        <chunking id="7" string="when she has to" type="SBAR">
          <tokens>
            <token id="15" string="when" />
            <token id="16" string="she" />
            <token id="17" string="has" />
            <token id="18" string="to" />
          </tokens>
        </chunking>
        <chunking id="8" string="an enormous reservoir of inner strength" type="NP">
          <tokens>
            <token id="5" string="an" />
            <token id="6" string="enormous" />
            <token id="7" string="reservoir" />
            <token id="8" string="of" />
            <token id="9" string="inner" />
            <token id="10" string="strength" />
          </tokens>
        </chunking>
        <chunking id="9" string="to" type="VP">
          <tokens>
            <token id="18" string="to" />
          </tokens>
        </chunking>
        <chunking id="10" string="She" type="NP">
          <tokens>
            <token id="2" string="She" />
          </tokens>
        </chunking>
        <chunking id="11" string="she" type="NP">
          <tokens>
            <token id="12" string="she" />
          </tokens>
        </chunking>
        <chunking id="12" string="when" type="WHADVP">
          <tokens>
            <token id="15" string="when" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">has</governor>
          <dependent id="2">She</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">has</governor>
          <dependent id="3">just</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">has</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">reservoir</governor>
          <dependent id="5">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">reservoir</governor>
          <dependent id="6">enormous</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">has</governor>
          <dependent id="7">reservoir</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">strength</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">strength</governor>
          <dependent id="9">inner</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">reservoir</governor>
          <dependent id="10">strength</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">calls</governor>
          <dependent id="11">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">calls</governor>
          <dependent id="12">she</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">has</governor>
          <dependent id="13">calls</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">to</governor>
          <dependent id="14">on</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">to</governor>
          <dependent id="15">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">to</governor>
          <dependent id="16">she</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">to</governor>
          <dependent id="17">has</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="13">calls</governor>
          <dependent id="18">to</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="41" has_coreference="false">
      <content>All of us were encouraged and optimistic.&amp;quot;</content>
      <tokens>
        <token id="1" string="All" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="us" lemma="we" stem="u" pos="PRP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="encouraged" lemma="encouraged" stem="encourag" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="optimistic" lemma="optimistic" stem="optimist" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT All)) (PP (IN of) (NP (PRP us)))) (VP (VBD were) (ADJP (JJ encouraged) (CC and) (JJ optimistic))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="All of us" type="NP">
          <tokens>
            <token id="1" string="All" />
            <token id="2" string="of" />
            <token id="3" string="us" />
          </tokens>
        </chunking>
        <chunking id="2" string="All" type="NP">
          <tokens>
            <token id="1" string="All" />
          </tokens>
        </chunking>
        <chunking id="3" string="were encouraged and optimistic" type="VP">
          <tokens>
            <token id="4" string="were" />
            <token id="5" string="encouraged" />
            <token id="6" string="and" />
            <token id="7" string="optimistic" />
          </tokens>
        </chunking>
        <chunking id="4" string="encouraged and optimistic" type="ADJP">
          <tokens>
            <token id="5" string="encouraged" />
            <token id="6" string="and" />
            <token id="7" string="optimistic" />
          </tokens>
        </chunking>
        <chunking id="5" string="us" type="NP">
          <tokens>
            <token id="3" string="us" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">encouraged</governor>
          <dependent id="1">All</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">us</governor>
          <dependent id="2">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">All</governor>
          <dependent id="3">us</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">encouraged</governor>
          <dependent id="4">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">encouraged</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">encouraged</governor>
          <dependent id="6">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">encouraged</governor>
          <dependent id="7">optimistic</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="42" has_coreference="true">
      <content>She has needed it.</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="needed" lemma="need" stem="need" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP She)) (VP (VBZ has) (VP (VBN needed) (NP (PRP it)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="needed it" type="VP">
          <tokens>
            <token id="3" string="needed" />
            <token id="4" string="it" />
          </tokens>
        </chunking>
        <chunking id="2" string="has needed it" type="VP">
          <tokens>
            <token id="2" string="has" />
            <token id="3" string="needed" />
            <token id="4" string="it" />
          </tokens>
        </chunking>
        <chunking id="3" string="it" type="NP">
          <tokens>
            <token id="4" string="it" />
          </tokens>
        </chunking>
        <chunking id="4" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">needed</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">needed</governor>
          <dependent id="2">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">needed</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">needed</governor>
          <dependent id="4">it</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="43" has_coreference="false">
      <content>Taylor&amp;apost;s respiratory ailments alone have been a recurring problem.</content>
      <tokens>
        <token id="1" string="Taylor" lemma="Taylor" stem="taylor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="2" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="respiratory" lemma="respiratory" stem="respiratori" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="ailments" lemma="ailment" stem="ailment" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="alone" lemma="alone" stem="alon" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="recurring" lemma="recur" stem="recur" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="problem" lemma="problem" stem="problem" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Taylor) (POS 's)) (JJ respiratory) (NNS ailments)) (ADVP (RB alone)) (VP (VBP have) (VP (VBN been) (S (NP (DT a) (VBG recurring) (NN problem))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Taylor 's respiratory ailments" type="NP">
          <tokens>
            <token id="1" string="Taylor" />
            <token id="2" string="'s" />
            <token id="3" string="respiratory" />
            <token id="4" string="ailments" />
          </tokens>
        </chunking>
        <chunking id="2" string="a recurring problem" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="recurring" />
            <token id="10" string="problem" />
          </tokens>
        </chunking>
        <chunking id="3" string="been a recurring problem" type="VP">
          <tokens>
            <token id="7" string="been" />
            <token id="8" string="a" />
            <token id="9" string="recurring" />
            <token id="10" string="problem" />
          </tokens>
        </chunking>
        <chunking id="4" string="Taylor 's" type="NP">
          <tokens>
            <token id="1" string="Taylor" />
            <token id="2" string="'s" />
          </tokens>
        </chunking>
        <chunking id="5" string="have been a recurring problem" type="VP">
          <tokens>
            <token id="6" string="have" />
            <token id="7" string="been" />
            <token id="8" string="a" />
            <token id="9" string="recurring" />
            <token id="10" string="problem" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="4">ailments</governor>
          <dependent id="1">Taylor</dependent>
        </dependency>
        <dependency type="case">
          <governor id="1">Taylor</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">ailments</governor>
          <dependent id="3">respiratory</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">been</governor>
          <dependent id="4">ailments</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">been</governor>
          <dependent id="5">alone</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">been</governor>
          <dependent id="6">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">been</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">problem</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">problem</governor>
          <dependent id="9">recurring</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">been</governor>
          <dependent id="10">problem</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Taylor" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Taylor" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="44" has_coreference="true">
      <content>Bronchitis and laryngitis brought down the curtain on numerous performances of &amp;quot;The Little Foxes,&amp;quot; which Taylor starred in on Broadway in 1981, and Noel Coward&amp;apost;s &amp;quot;Private Lives,&amp;quot; which toured the country in 1983.</content>
      <tokens>
        <token id="1" string="Bronchitis" lemma="bronchitis" stem="bronchiti" pos="NN" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="2" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="laryngitis" lemma="laryngitis" stem="laryng" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="brought" lemma="bring" stem="brought" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="down" lemma="down" stem="down" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="curtain" lemma="curtain" stem="curtain" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="numerous" lemma="numerous" stem="numer" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="performances" lemma="performance" stem="perform" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Little" lemma="little" stem="littl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="Foxes" lemma="fox" stem="fox" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Taylor" lemma="Taylor" stem="taylor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="20" string="starred" lemma="star" stem="star" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="Broadway" lemma="Broadway" stem="broadwai" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="24" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="1981" lemma="1981" stem="1981" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="Noel" lemma="Noel" stem="noel" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="29" string="Coward" lemma="Coward" stem="coward" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="30" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="Private" lemma="private" stem="privat" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="Lives" lemma="life" stem="live" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="toured" lemma="tour" stem="tour" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="39" string="country" lemma="country" stem="countri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="40" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="1983" lemma="1983" stem="1983" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="42" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NN Bronchitis) (CC and) (NN laryngitis)) (VP (VBD brought) (PRT (RP down)) (NP (NP (DT the) (NN curtain)) (PP (IN on) (NP (NP (JJ numerous) (NNS performances)) (PP (IN of) (NP (`` ``) (NP (DT The) (JJ Little) (NNS Foxes)) (, ,) ('' '') (SBAR (WHNP (WDT which)) (S (NP (NNP Taylor)) (VP (VBD starred) (PP (IN in) (IN on) (NP (NP (NP (NNP Broadway)) (PP (IN in) (NP (CD 1981)))) (, ,) (CC and) (NP (NNP Noel) (NP (NNP Coward) (POS 's))))) (NP (`` ``) (NP (JJ Private) (NNS Lives)) (, ,) ('' '') (SBAR (WHNP (WDT which)) (S (VP (VBD toured) (NP (DT the) (NN country)) (PP (IN in) (NP (CD 1983)))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="`` The Little Foxes , '' which Taylor starred in on Broadway in 1981 , and Noel Coward 's `` Private Lives , '' which toured the country in 1983" type="NP">
          <tokens>
            <token id="12" string="&quot;" />
            <token id="13" string="The" />
            <token id="14" string="Little" />
            <token id="15" string="Foxes" />
            <token id="16" string="," />
            <token id="17" string="&quot;" />
            <token id="18" string="which" />
            <token id="19" string="Taylor" />
            <token id="20" string="starred" />
            <token id="21" string="in" />
            <token id="22" string="on" />
            <token id="23" string="Broadway" />
            <token id="24" string="in" />
            <token id="25" string="1981" />
            <token id="26" string="," />
            <token id="27" string="and" />
            <token id="28" string="Noel" />
            <token id="29" string="Coward" />
            <token id="30" string="'s" />
            <token id="31" string="&quot;" />
            <token id="32" string="Private" />
            <token id="33" string="Lives" />
            <token id="34" string="," />
            <token id="35" string="&quot;" />
            <token id="36" string="which" />
            <token id="37" string="toured" />
            <token id="38" string="the" />
            <token id="39" string="country" />
            <token id="40" string="in" />
            <token id="41" string="1983" />
          </tokens>
        </chunking>
        <chunking id="2" string="starred in on Broadway in 1981 , and Noel Coward 's `` Private Lives , '' which toured the country in 1983" type="VP">
          <tokens>
            <token id="20" string="starred" />
            <token id="21" string="in" />
            <token id="22" string="on" />
            <token id="23" string="Broadway" />
            <token id="24" string="in" />
            <token id="25" string="1981" />
            <token id="26" string="," />
            <token id="27" string="and" />
            <token id="28" string="Noel" />
            <token id="29" string="Coward" />
            <token id="30" string="'s" />
            <token id="31" string="&quot;" />
            <token id="32" string="Private" />
            <token id="33" string="Lives" />
            <token id="34" string="," />
            <token id="35" string="&quot;" />
            <token id="36" string="which" />
            <token id="37" string="toured" />
            <token id="38" string="the" />
            <token id="39" string="country" />
            <token id="40" string="in" />
            <token id="41" string="1983" />
          </tokens>
        </chunking>
        <chunking id="3" string="`` Private Lives , '' which toured the country in 1983" type="NP">
          <tokens>
            <token id="31" string="&quot;" />
            <token id="32" string="Private" />
            <token id="33" string="Lives" />
            <token id="34" string="," />
            <token id="35" string="&quot;" />
            <token id="36" string="which" />
            <token id="37" string="toured" />
            <token id="38" string="the" />
            <token id="39" string="country" />
            <token id="40" string="in" />
            <token id="41" string="1983" />
          </tokens>
        </chunking>
        <chunking id="4" string="toured the country in 1983" type="VP">
          <tokens>
            <token id="37" string="toured" />
            <token id="38" string="the" />
            <token id="39" string="country" />
            <token id="40" string="in" />
            <token id="41" string="1983" />
          </tokens>
        </chunking>
        <chunking id="5" string="numerous performances of `` The Little Foxes , '' which Taylor starred in on Broadway in 1981 , and Noel Coward 's `` Private Lives , '' which toured the country in 1983" type="NP">
          <tokens>
            <token id="9" string="numerous" />
            <token id="10" string="performances" />
            <token id="11" string="of" />
            <token id="12" string="&quot;" />
            <token id="13" string="The" />
            <token id="14" string="Little" />
            <token id="15" string="Foxes" />
            <token id="16" string="," />
            <token id="17" string="&quot;" />
            <token id="18" string="which" />
            <token id="19" string="Taylor" />
            <token id="20" string="starred" />
            <token id="21" string="in" />
            <token id="22" string="on" />
            <token id="23" string="Broadway" />
            <token id="24" string="in" />
            <token id="25" string="1981" />
            <token id="26" string="," />
            <token id="27" string="and" />
            <token id="28" string="Noel" />
            <token id="29" string="Coward" />
            <token id="30" string="'s" />
            <token id="31" string="&quot;" />
            <token id="32" string="Private" />
            <token id="33" string="Lives" />
            <token id="34" string="," />
            <token id="35" string="&quot;" />
            <token id="36" string="which" />
            <token id="37" string="toured" />
            <token id="38" string="the" />
            <token id="39" string="country" />
            <token id="40" string="in" />
            <token id="41" string="1983" />
          </tokens>
        </chunking>
        <chunking id="6" string="which toured the country in 1983" type="SBAR">
          <tokens>
            <token id="36" string="which" />
            <token id="37" string="toured" />
            <token id="38" string="the" />
            <token id="39" string="country" />
            <token id="40" string="in" />
            <token id="41" string="1983" />
          </tokens>
        </chunking>
        <chunking id="7" string="Taylor" type="NP">
          <tokens>
            <token id="19" string="Taylor" />
          </tokens>
        </chunking>
        <chunking id="8" string="Noel Coward 's" type="NP">
          <tokens>
            <token id="28" string="Noel" />
            <token id="29" string="Coward" />
            <token id="30" string="'s" />
          </tokens>
        </chunking>
        <chunking id="9" string="brought down the curtain on numerous performances of `` The Little Foxes , '' which Taylor starred in on Broadway in 1981 , and Noel Coward 's `` Private Lives , '' which toured the country in 1983" type="VP">
          <tokens>
            <token id="4" string="brought" />
            <token id="5" string="down" />
            <token id="6" string="the" />
            <token id="7" string="curtain" />
            <token id="8" string="on" />
            <token id="9" string="numerous" />
            <token id="10" string="performances" />
            <token id="11" string="of" />
            <token id="12" string="&quot;" />
            <token id="13" string="The" />
            <token id="14" string="Little" />
            <token id="15" string="Foxes" />
            <token id="16" string="," />
            <token id="17" string="&quot;" />
            <token id="18" string="which" />
            <token id="19" string="Taylor" />
            <token id="20" string="starred" />
            <token id="21" string="in" />
            <token id="22" string="on" />
            <token id="23" string="Broadway" />
            <token id="24" string="in" />
            <token id="25" string="1981" />
            <token id="26" string="," />
            <token id="27" string="and" />
            <token id="28" string="Noel" />
            <token id="29" string="Coward" />
            <token id="30" string="'s" />
            <token id="31" string="&quot;" />
            <token id="32" string="Private" />
            <token id="33" string="Lives" />
            <token id="34" string="," />
            <token id="35" string="&quot;" />
            <token id="36" string="which" />
            <token id="37" string="toured" />
            <token id="38" string="the" />
            <token id="39" string="country" />
            <token id="40" string="in" />
            <token id="41" string="1983" />
          </tokens>
        </chunking>
        <chunking id="10" string="Broadway" type="NP">
          <tokens>
            <token id="23" string="Broadway" />
          </tokens>
        </chunking>
        <chunking id="11" string="Coward 's" type="NP">
          <tokens>
            <token id="29" string="Coward" />
            <token id="30" string="'s" />
          </tokens>
        </chunking>
        <chunking id="12" string="the curtain" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="curtain" />
          </tokens>
        </chunking>
        <chunking id="13" string="Broadway in 1981" type="NP">
          <tokens>
            <token id="23" string="Broadway" />
            <token id="24" string="in" />
            <token id="25" string="1981" />
          </tokens>
        </chunking>
        <chunking id="14" string="Bronchitis and laryngitis" type="NP">
          <tokens>
            <token id="1" string="Bronchitis" />
            <token id="2" string="and" />
            <token id="3" string="laryngitis" />
          </tokens>
        </chunking>
        <chunking id="15" string="the curtain on numerous performances of `` The Little Foxes , '' which Taylor starred in on Broadway in 1981 , and Noel Coward 's `` Private Lives , '' which toured the country in 1983" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="curtain" />
            <token id="8" string="on" />
            <token id="9" string="numerous" />
            <token id="10" string="performances" />
            <token id="11" string="of" />
            <token id="12" string="&quot;" />
            <token id="13" string="The" />
            <token id="14" string="Little" />
            <token id="15" string="Foxes" />
            <token id="16" string="," />
            <token id="17" string="&quot;" />
            <token id="18" string="which" />
            <token id="19" string="Taylor" />
            <token id="20" string="starred" />
            <token id="21" string="in" />
            <token id="22" string="on" />
            <token id="23" string="Broadway" />
            <token id="24" string="in" />
            <token id="25" string="1981" />
            <token id="26" string="," />
            <token id="27" string="and" />
            <token id="28" string="Noel" />
            <token id="29" string="Coward" />
            <token id="30" string="'s" />
            <token id="31" string="&quot;" />
            <token id="32" string="Private" />
            <token id="33" string="Lives" />
            <token id="34" string="," />
            <token id="35" string="&quot;" />
            <token id="36" string="which" />
            <token id="37" string="toured" />
            <token id="38" string="the" />
            <token id="39" string="country" />
            <token id="40" string="in" />
            <token id="41" string="1983" />
          </tokens>
        </chunking>
        <chunking id="16" string="The Little Foxes" type="NP">
          <tokens>
            <token id="13" string="The" />
            <token id="14" string="Little" />
            <token id="15" string="Foxes" />
          </tokens>
        </chunking>
        <chunking id="17" string="Broadway in 1981 , and Noel Coward 's" type="NP">
          <tokens>
            <token id="23" string="Broadway" />
            <token id="24" string="in" />
            <token id="25" string="1981" />
            <token id="26" string="," />
            <token id="27" string="and" />
            <token id="28" string="Noel" />
            <token id="29" string="Coward" />
            <token id="30" string="'s" />
          </tokens>
        </chunking>
        <chunking id="18" string="Private Lives" type="NP">
          <tokens>
            <token id="32" string="Private" />
            <token id="33" string="Lives" />
          </tokens>
        </chunking>
        <chunking id="19" string="the country" type="NP">
          <tokens>
            <token id="38" string="the" />
            <token id="39" string="country" />
          </tokens>
        </chunking>
        <chunking id="20" string="1983" type="NP">
          <tokens>
            <token id="41" string="1983" />
          </tokens>
        </chunking>
        <chunking id="21" string="1981" type="NP">
          <tokens>
            <token id="25" string="1981" />
          </tokens>
        </chunking>
        <chunking id="22" string="numerous performances" type="NP">
          <tokens>
            <token id="9" string="numerous" />
            <token id="10" string="performances" />
          </tokens>
        </chunking>
        <chunking id="23" string="which Taylor starred in on Broadway in 1981 , and Noel Coward 's `` Private Lives , '' which toured the country in 1983" type="SBAR">
          <tokens>
            <token id="18" string="which" />
            <token id="19" string="Taylor" />
            <token id="20" string="starred" />
            <token id="21" string="in" />
            <token id="22" string="on" />
            <token id="23" string="Broadway" />
            <token id="24" string="in" />
            <token id="25" string="1981" />
            <token id="26" string="," />
            <token id="27" string="and" />
            <token id="28" string="Noel" />
            <token id="29" string="Coward" />
            <token id="30" string="'s" />
            <token id="31" string="&quot;" />
            <token id="32" string="Private" />
            <token id="33" string="Lives" />
            <token id="34" string="," />
            <token id="35" string="&quot;" />
            <token id="36" string="which" />
            <token id="37" string="toured" />
            <token id="38" string="the" />
            <token id="39" string="country" />
            <token id="40" string="in" />
            <token id="41" string="1983" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">brought</governor>
          <dependent id="1">Bronchitis</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="1">Bronchitis</governor>
          <dependent id="2">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="1">Bronchitis</governor>
          <dependent id="3">laryngitis</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">brought</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="4">brought</governor>
          <dependent id="5">down</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">curtain</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">brought</governor>
          <dependent id="7">curtain</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">performances</governor>
          <dependent id="8">on</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">performances</governor>
          <dependent id="9">numerous</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">curtain</governor>
          <dependent id="10">performances</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">Foxes</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">Foxes</governor>
          <dependent id="13">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">Foxes</governor>
          <dependent id="14">Little</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">performances</governor>
          <dependent id="15">Foxes</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">starred</governor>
          <dependent id="18">which</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">starred</governor>
          <dependent id="19">Taylor</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="15">Foxes</governor>
          <dependent id="20">starred</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">Broadway</governor>
          <dependent id="21">in</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">Broadway</governor>
          <dependent id="22">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">starred</governor>
          <dependent id="23">Broadway</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">1981</governor>
          <dependent id="24">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">Broadway</governor>
          <dependent id="25">1981</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="23">Broadway</governor>
          <dependent id="27">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="23">Broadway</governor>
          <dependent id="28">Noel</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="28">Noel</governor>
          <dependent id="29">Coward</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">Coward</governor>
          <dependent id="30">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="33">Lives</governor>
          <dependent id="32">Private</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">starred</governor>
          <dependent id="33">Lives</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="37">toured</governor>
          <dependent id="36">which</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="33">Lives</governor>
          <dependent id="37">toured</dependent>
        </dependency>
        <dependency type="det">
          <governor id="39">country</governor>
          <dependent id="38">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="37">toured</governor>
          <dependent id="39">country</dependent>
        </dependency>
        <dependency type="case">
          <governor id="41">1983</governor>
          <dependent id="40">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="37">toured</governor>
          <dependent id="41">1983</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Taylor" type="PERSON" score="0.0">
          <tokens>
            <token id="19" string="Taylor" />
          </tokens>
        </entity>
        <entity id="2" string="1983" type="DATE" score="0.0">
          <tokens>
            <token id="41" string="1983" />
          </tokens>
        </entity>
        <entity id="3" string="1981" type="DATE" score="0.0">
          <tokens>
            <token id="25" string="1981" />
          </tokens>
        </entity>
        <entity id="4" string="Broadway" type="LOCATION" score="0.0">
          <tokens>
            <token id="23" string="Broadway" />
          </tokens>
        </entity>
        <entity id="5" string="Noel Coward" type="PERSON" score="0.0">
          <tokens>
            <token id="28" string="Noel" />
            <token id="29" string="Coward" />
          </tokens>
        </entity>
        <entity id="6" string="Bronchitis" type="MISC" score="0.0">
          <tokens>
            <token id="1" string="Bronchitis" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="45" has_coreference="true">
      <content>The cancellations prompted the play&amp;apost;s co-producer, Zev Bufman, to declare, &amp;quot;Bronchitis has plagued Elizabeth all her life.&amp;quot;</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="cancellations" lemma="cancellation" stem="cancel" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="prompted" lemma="prompt" stem="prompt" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="play" lemma="play" stem="plai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="co-producer" lemma="co-producer" stem="co-produc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Zev" lemma="Zev" stem="zev" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="10" string="Bufman" lemma="Bufman" stem="bufman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="declare" lemma="declare" stem="declar" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="Bronchitis" lemma="bronchitis" stem="bronchiti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="plagued" lemma="plague" stem="plagu" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="Elizabeth" lemma="Elizabeth" stem="elizabeth" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="20" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="life" lemma="life" stem="life" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNS cancellations)) (VP (VBD prompted) (S (NP (NP (NP (DT the) (NN play) (POS 's)) (NN co-producer)) (, ,) (NP (NNP Zev) (NNP Bufman)) (, ,)) (VP (TO to) (VP (VB declare) (, ,) (`` ``) (S (NP (NN Bronchitis)) (VP (VBZ has) (VP (VBN plagued) (S (NP (NNP Elizabeth)) (NP (NP (DT all)) (NP (PRP$ her) (NN life))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="all" type="NP">
          <tokens>
            <token id="20" string="all" />
          </tokens>
        </chunking>
        <chunking id="2" string="the play 's co-producer , Zev Bufman ," type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="play" />
            <token id="6" string="'s" />
            <token id="7" string="co-producer" />
            <token id="8" string="," />
            <token id="9" string="Zev" />
            <token id="10" string="Bufman" />
            <token id="11" string="," />
          </tokens>
        </chunking>
        <chunking id="3" string="all her life" type="NP">
          <tokens>
            <token id="20" string="all" />
            <token id="21" string="her" />
            <token id="22" string="life" />
          </tokens>
        </chunking>
        <chunking id="4" string="The cancellations" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="cancellations" />
          </tokens>
        </chunking>
        <chunking id="5" string="her life" type="NP">
          <tokens>
            <token id="21" string="her" />
            <token id="22" string="life" />
          </tokens>
        </chunking>
        <chunking id="6" string="to declare , `` Bronchitis has plagued Elizabeth all her life" type="VP">
          <tokens>
            <token id="12" string="to" />
            <token id="13" string="declare" />
            <token id="14" string="," />
            <token id="15" string="&quot;" />
            <token id="16" string="Bronchitis" />
            <token id="17" string="has" />
            <token id="18" string="plagued" />
            <token id="19" string="Elizabeth" />
            <token id="20" string="all" />
            <token id="21" string="her" />
            <token id="22" string="life" />
          </tokens>
        </chunking>
        <chunking id="7" string="Elizabeth" type="NP">
          <tokens>
            <token id="19" string="Elizabeth" />
          </tokens>
        </chunking>
        <chunking id="8" string="has plagued Elizabeth all her life" type="VP">
          <tokens>
            <token id="17" string="has" />
            <token id="18" string="plagued" />
            <token id="19" string="Elizabeth" />
            <token id="20" string="all" />
            <token id="21" string="her" />
            <token id="22" string="life" />
          </tokens>
        </chunking>
        <chunking id="9" string="the play 's co-producer" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="play" />
            <token id="6" string="'s" />
            <token id="7" string="co-producer" />
          </tokens>
        </chunking>
        <chunking id="10" string="declare , `` Bronchitis has plagued Elizabeth all her life" type="VP">
          <tokens>
            <token id="13" string="declare" />
            <token id="14" string="," />
            <token id="15" string="&quot;" />
            <token id="16" string="Bronchitis" />
            <token id="17" string="has" />
            <token id="18" string="plagued" />
            <token id="19" string="Elizabeth" />
            <token id="20" string="all" />
            <token id="21" string="her" />
            <token id="22" string="life" />
          </tokens>
        </chunking>
        <chunking id="11" string="prompted the play 's co-producer , Zev Bufman , to declare , `` Bronchitis has plagued Elizabeth all her life" type="VP">
          <tokens>
            <token id="3" string="prompted" />
            <token id="4" string="the" />
            <token id="5" string="play" />
            <token id="6" string="'s" />
            <token id="7" string="co-producer" />
            <token id="8" string="," />
            <token id="9" string="Zev" />
            <token id="10" string="Bufman" />
            <token id="11" string="," />
            <token id="12" string="to" />
            <token id="13" string="declare" />
            <token id="14" string="," />
            <token id="15" string="&quot;" />
            <token id="16" string="Bronchitis" />
            <token id="17" string="has" />
            <token id="18" string="plagued" />
            <token id="19" string="Elizabeth" />
            <token id="20" string="all" />
            <token id="21" string="her" />
            <token id="22" string="life" />
          </tokens>
        </chunking>
        <chunking id="12" string="the play 's" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="play" />
            <token id="6" string="'s" />
          </tokens>
        </chunking>
        <chunking id="13" string="plagued Elizabeth all her life" type="VP">
          <tokens>
            <token id="18" string="plagued" />
            <token id="19" string="Elizabeth" />
            <token id="20" string="all" />
            <token id="21" string="her" />
            <token id="22" string="life" />
          </tokens>
        </chunking>
        <chunking id="14" string="Bronchitis" type="NP">
          <tokens>
            <token id="16" string="Bronchitis" />
          </tokens>
        </chunking>
        <chunking id="15" string="Zev Bufman" type="NP">
          <tokens>
            <token id="9" string="Zev" />
            <token id="10" string="Bufman" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">cancellations</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">prompted</governor>
          <dependent id="2">cancellations</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">prompted</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">play</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">co-producer</governor>
          <dependent id="5">play</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">play</governor>
          <dependent id="6">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">prompted</governor>
          <dependent id="7">co-producer</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Bufman</governor>
          <dependent id="9">Zev</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="7">co-producer</governor>
          <dependent id="10">Bufman</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">declare</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">prompted</governor>
          <dependent id="13">declare</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">plagued</governor>
          <dependent id="16">Bronchitis</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">plagued</governor>
          <dependent id="17">has</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">declare</governor>
          <dependent id="18">plagued</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">all</governor>
          <dependent id="19">Elizabeth</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="18">plagued</governor>
          <dependent id="20">all</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="22">life</governor>
          <dependent id="21">her</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="20">all</governor>
          <dependent id="22">life</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Elizabeth" type="PERSON" score="0.0">
          <tokens>
            <token id="19" string="Elizabeth" />
          </tokens>
        </entity>
        <entity id="2" string="Zev Bufman" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Zev" />
            <token id="10" string="Bufman" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="46" has_coreference="true">
      <content>In fact, Taylor has been plagued by health woes ever since her 1945 film debut in &amp;quot;National Velvet&amp;quot;; her fall from a horse triggered a lifetime of back trouble.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="fact" lemma="fact" stem="fact" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Taylor" lemma="Taylor" stem="taylor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="5" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="plagued" lemma="plague" stem="plagu" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="health" lemma="health" stem="health" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="woes" lemma="woe" stem="woe" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="ever" lemma="ever" stem="ever" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="1945" lemma="1945" stem="1945" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="15" string="film" lemma="film" stem="film" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="debut" lemma="debut" stem="debut" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="National" lemma="National" stem="nation" pos="NNP" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="20" string="Velvet" lemma="Velvet" stem="velvet" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="21" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="fall" lemma="fall" stem="fall" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="25" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="horse" lemma="horse" stem="hors" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="triggered" lemma="trigger" stem="trigger" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="lifetime" lemma="lifetime" stem="lifetim" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="back" lemma="back" stem="back" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="trouble" lemma="trouble" stem="troubl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (PP (IN In) (NP (NN fact))) (, ,) (NP (NNP Taylor)) (VP (VBZ has) (VP (VBN been) (VP (VBN plagued) (PP (IN by) (NP (NN health) (NNS woes))) (PP (ADVP (RB ever)) (IN since) (NP (PRP$ her) (CD 1945) (NN film) (NN debut))) (PP (IN in) (`` ``) (NP (NNP National) (NNP Velvet)) ('' '')))))) (: ;) (S (NP (NP (PRP$ her) (NN fall)) (PP (IN from) (NP (DT a) (NN horse)))) (VP (VBD triggered) (NP (NP (DT a) (NN lifetime)) (PP (IN of) (NP (RB back) (NN trouble)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="plagued by health woes ever since her 1945 film debut in `` National Velvet ''" type="VP">
          <tokens>
            <token id="7" string="plagued" />
            <token id="8" string="by" />
            <token id="9" string="health" />
            <token id="10" string="woes" />
            <token id="11" string="ever" />
            <token id="12" string="since" />
            <token id="13" string="her" />
            <token id="14" string="1945" />
            <token id="15" string="film" />
            <token id="16" string="debut" />
            <token id="17" string="in" />
            <token id="18" string="&quot;" />
            <token id="19" string="National" />
            <token id="20" string="Velvet" />
            <token id="21" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="2" string="back trouble" type="NP">
          <tokens>
            <token id="32" string="back" />
            <token id="33" string="trouble" />
          </tokens>
        </chunking>
        <chunking id="3" string="fact" type="NP">
          <tokens>
            <token id="2" string="fact" />
          </tokens>
        </chunking>
        <chunking id="4" string="Taylor" type="NP">
          <tokens>
            <token id="4" string="Taylor" />
          </tokens>
        </chunking>
        <chunking id="5" string="a lifetime" type="NP">
          <tokens>
            <token id="29" string="a" />
            <token id="30" string="lifetime" />
          </tokens>
        </chunking>
        <chunking id="6" string="been plagued by health woes ever since her 1945 film debut in `` National Velvet ''" type="VP">
          <tokens>
            <token id="6" string="been" />
            <token id="7" string="plagued" />
            <token id="8" string="by" />
            <token id="9" string="health" />
            <token id="10" string="woes" />
            <token id="11" string="ever" />
            <token id="12" string="since" />
            <token id="13" string="her" />
            <token id="14" string="1945" />
            <token id="15" string="film" />
            <token id="16" string="debut" />
            <token id="17" string="in" />
            <token id="18" string="&quot;" />
            <token id="19" string="National" />
            <token id="20" string="Velvet" />
            <token id="21" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="7" string="her 1945 film debut" type="NP">
          <tokens>
            <token id="13" string="her" />
            <token id="14" string="1945" />
            <token id="15" string="film" />
            <token id="16" string="debut" />
          </tokens>
        </chunking>
        <chunking id="8" string="has been plagued by health woes ever since her 1945 film debut in `` National Velvet ''" type="VP">
          <tokens>
            <token id="5" string="has" />
            <token id="6" string="been" />
            <token id="7" string="plagued" />
            <token id="8" string="by" />
            <token id="9" string="health" />
            <token id="10" string="woes" />
            <token id="11" string="ever" />
            <token id="12" string="since" />
            <token id="13" string="her" />
            <token id="14" string="1945" />
            <token id="15" string="film" />
            <token id="16" string="debut" />
            <token id="17" string="in" />
            <token id="18" string="&quot;" />
            <token id="19" string="National" />
            <token id="20" string="Velvet" />
            <token id="21" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="9" string="her fall" type="NP">
          <tokens>
            <token id="23" string="her" />
            <token id="24" string="fall" />
          </tokens>
        </chunking>
        <chunking id="10" string="her fall from a horse" type="NP">
          <tokens>
            <token id="23" string="her" />
            <token id="24" string="fall" />
            <token id="25" string="from" />
            <token id="26" string="a" />
            <token id="27" string="horse" />
          </tokens>
        </chunking>
        <chunking id="11" string="a lifetime of back trouble" type="NP">
          <tokens>
            <token id="29" string="a" />
            <token id="30" string="lifetime" />
            <token id="31" string="of" />
            <token id="32" string="back" />
            <token id="33" string="trouble" />
          </tokens>
        </chunking>
        <chunking id="12" string="a horse" type="NP">
          <tokens>
            <token id="26" string="a" />
            <token id="27" string="horse" />
          </tokens>
        </chunking>
        <chunking id="13" string="National Velvet" type="NP">
          <tokens>
            <token id="19" string="National" />
            <token id="20" string="Velvet" />
          </tokens>
        </chunking>
        <chunking id="14" string="health woes" type="NP">
          <tokens>
            <token id="9" string="health" />
            <token id="10" string="woes" />
          </tokens>
        </chunking>
        <chunking id="15" string="triggered a lifetime of back trouble" type="VP">
          <tokens>
            <token id="28" string="triggered" />
            <token id="29" string="a" />
            <token id="30" string="lifetime" />
            <token id="31" string="of" />
            <token id="32" string="back" />
            <token id="33" string="trouble" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">fact</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">plagued</governor>
          <dependent id="2">fact</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="7">plagued</governor>
          <dependent id="4">Taylor</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">plagued</governor>
          <dependent id="5">has</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="7">plagued</governor>
          <dependent id="6">been</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">plagued</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">woes</governor>
          <dependent id="8">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">woes</governor>
          <dependent id="9">health</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">plagued</governor>
          <dependent id="10">woes</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">debut</governor>
          <dependent id="11">ever</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">debut</governor>
          <dependent id="12">since</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">debut</governor>
          <dependent id="13">her</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="16">debut</governor>
          <dependent id="14">1945</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">debut</governor>
          <dependent id="15">film</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">plagued</governor>
          <dependent id="16">debut</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">Velvet</governor>
          <dependent id="17">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Velvet</governor>
          <dependent id="19">National</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">plagued</governor>
          <dependent id="20">Velvet</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="24">fall</governor>
          <dependent id="23">her</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">triggered</governor>
          <dependent id="24">fall</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">horse</governor>
          <dependent id="25">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">horse</governor>
          <dependent id="26">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">fall</governor>
          <dependent id="27">horse</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="7">plagued</governor>
          <dependent id="28">triggered</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">lifetime</governor>
          <dependent id="29">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="28">triggered</governor>
          <dependent id="30">lifetime</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">trouble</governor>
          <dependent id="31">of</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="33">trouble</governor>
          <dependent id="32">back</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">lifetime</governor>
          <dependent id="33">trouble</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Taylor" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Taylor" />
          </tokens>
        </entity>
        <entity id="2" string="Velvet" type="MISC" score="0.0">
          <tokens>
            <token id="20" string="Velvet" />
          </tokens>
        </entity>
        <entity id="3" string="fall" type="DATE" score="0.0">
          <tokens>
            <token id="24" string="fall" />
          </tokens>
        </entity>
        <entity id="4" string="National" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="19" string="National" />
          </tokens>
        </entity>
        <entity id="5" string="1945" type="DATE" score="0.0">
          <tokens>
            <token id="14" string="1945" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="47" has_coreference="true">
      <content>And when Taylor retired from films to marry the Republican senator from Virginia, John Warner, her well-being continued to make headlines; she choked on a chicken bone and wrenched her back after slipping on a carpet at a reception honoring former President Gerald R. Ford.</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Taylor" lemma="Taylor" stem="taylor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="retired" lemma="retire" stem="retir" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="films" lemma="film" stem="film" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="marry" lemma="marry" stem="marri" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Republican" lemma="republican" stem="republican" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="11" string="senator" lemma="senator" stem="senat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Virginia" lemma="Virginia" stem="virginia" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="16" string="Warner" lemma="Warner" stem="warner" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="well-being" lemma="well-being" stem="well-b" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="continued" lemma="continue" stem="continu" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="make" lemma="make" stem="make" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="headlines" lemma="headline" stem="headlin" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="choked" lemma="choke" stem="choke" pos="VBD" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="27" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="chicken" lemma="chicken" stem="chicken" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="bone" lemma="bone" stem="bone" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="wrenched" lemma="wrench" stem="wrench" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="34" string="back" lemma="back" stem="back" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="slipping" lemma="slip" stem="slip" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="carpet" lemma="carpet" stem="carpet" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="reception" lemma="reception" stem="recept" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="honoring" lemma="honor" stem="honor" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="former" lemma="former" stem="former" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="President" lemma="President" stem="presid" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="false" is_refers="true" />
        <token id="46" string="Gerald" lemma="Gerald" stem="gerald" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="47" string="R." lemma="R." stem="r." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="48" string="Ford" lemma="Ford" stem="ford" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="49" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (CC And) (SBAR (WHADVP (WRB when)) (S (NP (NNP Taylor)) (VP (VBD retired) (PP (IN from) (NP (NNS films))) (S (VP (TO to) (VP (VB marry) (NP (DT the) (JJ Republican) (NN senator)) (PP (IN from) (NP (NP (NNP Virginia)) (, ,) (NP (NNP John) (NNP Warner)))))))))) (, ,) (NP (PRP$ her) (NN well-being)) (VP (VBD continued) (S (VP (TO to) (VP (VB make) (NP (NNS headlines))))))) (: ;) (S (NP (PRP she)) (VP (VP (VBD choked) (PP (IN on) (NP (DT a) (NN chicken) (NN bone)))) (CC and) (VP (VBD wrenched) (NP (PRP$ her) (NN back)) (PP (IN after) (S (VP (VBG slipping) (PP (IN on) (NP (DT a) (NN carpet))) (PP (IN at) (NP (NP (DT a) (NN reception)) (VP (VBG honoring) (NP (JJ former) (NNP President) (NNP Gerald) (NNP R.) (NNP Ford))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="films" type="NP">
          <tokens>
            <token id="6" string="films" />
          </tokens>
        </chunking>
        <chunking id="2" string="a reception honoring former President Gerald R. Ford" type="NP">
          <tokens>
            <token id="41" string="a" />
            <token id="42" string="reception" />
            <token id="43" string="honoring" />
            <token id="44" string="former" />
            <token id="45" string="President" />
            <token id="46" string="Gerald" />
            <token id="47" string="R." />
            <token id="48" string="Ford" />
          </tokens>
        </chunking>
        <chunking id="3" string="marry the Republican senator from Virginia , John Warner" type="VP">
          <tokens>
            <token id="8" string="marry" />
            <token id="9" string="the" />
            <token id="10" string="Republican" />
            <token id="11" string="senator" />
            <token id="12" string="from" />
            <token id="13" string="Virginia" />
            <token id="14" string="," />
            <token id="15" string="John" />
            <token id="16" string="Warner" />
          </tokens>
        </chunking>
        <chunking id="4" string="Taylor" type="NP">
          <tokens>
            <token id="3" string="Taylor" />
          </tokens>
        </chunking>
        <chunking id="5" string="a reception" type="NP">
          <tokens>
            <token id="41" string="a" />
            <token id="42" string="reception" />
          </tokens>
        </chunking>
        <chunking id="6" string="slipping on a carpet at a reception honoring former President Gerald R. Ford" type="VP">
          <tokens>
            <token id="36" string="slipping" />
            <token id="37" string="on" />
            <token id="38" string="a" />
            <token id="39" string="carpet" />
            <token id="40" string="at" />
            <token id="41" string="a" />
            <token id="42" string="reception" />
            <token id="43" string="honoring" />
            <token id="44" string="former" />
            <token id="45" string="President" />
            <token id="46" string="Gerald" />
            <token id="47" string="R." />
            <token id="48" string="Ford" />
          </tokens>
        </chunking>
        <chunking id="7" string="honoring former President Gerald R. Ford" type="VP">
          <tokens>
            <token id="43" string="honoring" />
            <token id="44" string="former" />
            <token id="45" string="President" />
            <token id="46" string="Gerald" />
            <token id="47" string="R." />
            <token id="48" string="Ford" />
          </tokens>
        </chunking>
        <chunking id="8" string="John Warner" type="NP">
          <tokens>
            <token id="15" string="John" />
            <token id="16" string="Warner" />
          </tokens>
        </chunking>
        <chunking id="9" string="she" type="NP">
          <tokens>
            <token id="25" string="she" />
          </tokens>
        </chunking>
        <chunking id="10" string="former President Gerald R. Ford" type="NP">
          <tokens>
            <token id="44" string="former" />
            <token id="45" string="President" />
            <token id="46" string="Gerald" />
            <token id="47" string="R." />
            <token id="48" string="Ford" />
          </tokens>
        </chunking>
        <chunking id="11" string="her well-being" type="NP">
          <tokens>
            <token id="18" string="her" />
            <token id="19" string="well-being" />
          </tokens>
        </chunking>
        <chunking id="12" string="headlines" type="NP">
          <tokens>
            <token id="23" string="headlines" />
          </tokens>
        </chunking>
        <chunking id="13" string="to marry the Republican senator from Virginia , John Warner" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="marry" />
            <token id="9" string="the" />
            <token id="10" string="Republican" />
            <token id="11" string="senator" />
            <token id="12" string="from" />
            <token id="13" string="Virginia" />
            <token id="14" string="," />
            <token id="15" string="John" />
            <token id="16" string="Warner" />
          </tokens>
        </chunking>
        <chunking id="14" string="choked on a chicken bone and wrenched her back after slipping on a carpet at a reception honoring former President Gerald R. Ford" type="VP">
          <tokens>
            <token id="26" string="choked" />
            <token id="27" string="on" />
            <token id="28" string="a" />
            <token id="29" string="chicken" />
            <token id="30" string="bone" />
            <token id="31" string="and" />
            <token id="32" string="wrenched" />
            <token id="33" string="her" />
            <token id="34" string="back" />
            <token id="35" string="after" />
            <token id="36" string="slipping" />
            <token id="37" string="on" />
            <token id="38" string="a" />
            <token id="39" string="carpet" />
            <token id="40" string="at" />
            <token id="41" string="a" />
            <token id="42" string="reception" />
            <token id="43" string="honoring" />
            <token id="44" string="former" />
            <token id="45" string="President" />
            <token id="46" string="Gerald" />
            <token id="47" string="R." />
            <token id="48" string="Ford" />
          </tokens>
        </chunking>
        <chunking id="15" string="to make headlines" type="VP">
          <tokens>
            <token id="21" string="to" />
            <token id="22" string="make" />
            <token id="23" string="headlines" />
          </tokens>
        </chunking>
        <chunking id="16" string="Virginia" type="NP">
          <tokens>
            <token id="13" string="Virginia" />
          </tokens>
        </chunking>
        <chunking id="17" string="a carpet" type="NP">
          <tokens>
            <token id="38" string="a" />
            <token id="39" string="carpet" />
          </tokens>
        </chunking>
        <chunking id="18" string="continued to make headlines" type="VP">
          <tokens>
            <token id="20" string="continued" />
            <token id="21" string="to" />
            <token id="22" string="make" />
            <token id="23" string="headlines" />
          </tokens>
        </chunking>
        <chunking id="19" string="when Taylor retired from films to marry the Republican senator from Virginia , John Warner" type="SBAR">
          <tokens>
            <token id="2" string="when" />
            <token id="3" string="Taylor" />
            <token id="4" string="retired" />
            <token id="5" string="from" />
            <token id="6" string="films" />
            <token id="7" string="to" />
            <token id="8" string="marry" />
            <token id="9" string="the" />
            <token id="10" string="Republican" />
            <token id="11" string="senator" />
            <token id="12" string="from" />
            <token id="13" string="Virginia" />
            <token id="14" string="," />
            <token id="15" string="John" />
            <token id="16" string="Warner" />
          </tokens>
        </chunking>
        <chunking id="20" string="choked on a chicken bone" type="VP">
          <tokens>
            <token id="26" string="choked" />
            <token id="27" string="on" />
            <token id="28" string="a" />
            <token id="29" string="chicken" />
            <token id="30" string="bone" />
          </tokens>
        </chunking>
        <chunking id="21" string="Virginia , John Warner" type="NP">
          <tokens>
            <token id="13" string="Virginia" />
            <token id="14" string="," />
            <token id="15" string="John" />
            <token id="16" string="Warner" />
          </tokens>
        </chunking>
        <chunking id="22" string="make headlines" type="VP">
          <tokens>
            <token id="22" string="make" />
            <token id="23" string="headlines" />
          </tokens>
        </chunking>
        <chunking id="23" string="wrenched her back after slipping on a carpet at a reception honoring former President Gerald R. Ford" type="VP">
          <tokens>
            <token id="32" string="wrenched" />
            <token id="33" string="her" />
            <token id="34" string="back" />
            <token id="35" string="after" />
            <token id="36" string="slipping" />
            <token id="37" string="on" />
            <token id="38" string="a" />
            <token id="39" string="carpet" />
            <token id="40" string="at" />
            <token id="41" string="a" />
            <token id="42" string="reception" />
            <token id="43" string="honoring" />
            <token id="44" string="former" />
            <token id="45" string="President" />
            <token id="46" string="Gerald" />
            <token id="47" string="R." />
            <token id="48" string="Ford" />
          </tokens>
        </chunking>
        <chunking id="24" string="when" type="WHADVP">
          <tokens>
            <token id="2" string="when" />
          </tokens>
        </chunking>
        <chunking id="25" string="retired from films to marry the Republican senator from Virginia , John Warner" type="VP">
          <tokens>
            <token id="4" string="retired" />
            <token id="5" string="from" />
            <token id="6" string="films" />
            <token id="7" string="to" />
            <token id="8" string="marry" />
            <token id="9" string="the" />
            <token id="10" string="Republican" />
            <token id="11" string="senator" />
            <token id="12" string="from" />
            <token id="13" string="Virginia" />
            <token id="14" string="," />
            <token id="15" string="John" />
            <token id="16" string="Warner" />
          </tokens>
        </chunking>
        <chunking id="26" string="the Republican senator" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="Republican" />
            <token id="11" string="senator" />
          </tokens>
        </chunking>
        <chunking id="27" string="a chicken bone" type="NP">
          <tokens>
            <token id="28" string="a" />
            <token id="29" string="chicken" />
            <token id="30" string="bone" />
          </tokens>
        </chunking>
        <chunking id="28" string="her back" type="NP">
          <tokens>
            <token id="33" string="her" />
            <token id="34" string="back" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="20">continued</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">retired</governor>
          <dependent id="2">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">retired</governor>
          <dependent id="3">Taylor</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="20">continued</governor>
          <dependent id="4">retired</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">films</governor>
          <dependent id="5">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">retired</governor>
          <dependent id="6">films</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">marry</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">retired</governor>
          <dependent id="8">marry</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">senator</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">senator</governor>
          <dependent id="10">Republican</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">marry</governor>
          <dependent id="11">senator</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Virginia</governor>
          <dependent id="12">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">marry</governor>
          <dependent id="13">Virginia</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Warner</governor>
          <dependent id="15">John</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="13">Virginia</governor>
          <dependent id="16">Warner</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">well-being</governor>
          <dependent id="18">her</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">continued</governor>
          <dependent id="19">well-being</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="20">continued</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">make</governor>
          <dependent id="21">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="20">continued</governor>
          <dependent id="22">make</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">make</governor>
          <dependent id="23">headlines</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">choked</governor>
          <dependent id="25">she</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="20">continued</governor>
          <dependent id="26">choked</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">bone</governor>
          <dependent id="27">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">bone</governor>
          <dependent id="28">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">bone</governor>
          <dependent id="29">chicken</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">choked</governor>
          <dependent id="30">bone</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="26">choked</governor>
          <dependent id="31">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="26">choked</governor>
          <dependent id="32">wrenched</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="34">back</governor>
          <dependent id="33">her</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="32">wrenched</governor>
          <dependent id="34">back</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="36">slipping</governor>
          <dependent id="35">after</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="32">wrenched</governor>
          <dependent id="36">slipping</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">carpet</governor>
          <dependent id="37">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="39">carpet</governor>
          <dependent id="38">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="36">slipping</governor>
          <dependent id="39">carpet</dependent>
        </dependency>
        <dependency type="case">
          <governor id="42">reception</governor>
          <dependent id="40">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="42">reception</governor>
          <dependent id="41">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="36">slipping</governor>
          <dependent id="42">reception</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="42">reception</governor>
          <dependent id="43">honoring</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="48">Ford</governor>
          <dependent id="44">former</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="48">Ford</governor>
          <dependent id="45">President</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="48">Ford</governor>
          <dependent id="46">Gerald</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="48">Ford</governor>
          <dependent id="47">R.</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="43">honoring</governor>
          <dependent id="48">Ford</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="choked" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="26" string="choked" />
          </tokens>
        </entity>
        <entity id="2" string="Taylor" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Taylor" />
          </tokens>
        </entity>
        <entity id="3" string="Gerald R. Ford" type="PERSON" score="0.0">
          <tokens>
            <token id="46" string="Gerald" />
            <token id="47" string="R." />
            <token id="48" string="Ford" />
          </tokens>
        </entity>
        <entity id="4" string="Republican" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="10" string="Republican" />
          </tokens>
        </entity>
        <entity id="5" string="Virginia" type="LOCATION" score="0.0">
          <tokens>
            <token id="13" string="Virginia" />
          </tokens>
        </entity>
        <entity id="6" string="John Warner" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="John" />
            <token id="16" string="Warner" />
          </tokens>
        </entity>
        <entity id="7" string="President" type="TITLE" score="0.0">
          <tokens>
            <token id="45" string="President" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="48" has_coreference="true">
      <content>Over the years she has endured about 20 major operations on her back, appendix, eyes and teeth; when the Asian flu threatened Taylor&amp;apost;s life, doctors made a hole in her throat so she could breathe.</content>
      <tokens>
        <token id="1" string="Over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="3" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="4" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="endured" lemma="endure" stem="endur" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="20" lemma="20" stem="20" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="9" string="major" lemma="major" stem="major" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="operations" lemma="operation" stem="oper" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="back" lemma="back" stem="back" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="appendix" lemma="appendix" stem="appendix" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="eyes" lemma="eye" stem="ey" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="teeth" lemma="tooth" stem="teeth" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="Asian" lemma="asian" stem="asian" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="24" string="flu" lemma="flu" stem="flu" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="25" string="threatened" lemma="threaten" stem="threaten" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="Taylor" lemma="Taylor" stem="taylor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="27" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="life" lemma="life" stem="life" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="doctors" lemma="doctor" stem="doctor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="31" string="made" lemma="make" stem="made" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="hole" lemma="hole" stem="hole" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="36" string="throat" lemma="throat" stem="throat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="so" lemma="so" stem="so" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="39" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="breathe" lemma="breathe" stem="breath" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (PP (IN Over) (NP (DT the) (NNS years))) (NP (PRP she)) (VP (VBZ has) (VP (VBN endured) (PP (IN about) (NP (NP (CD 20) (JJ major) (NNS operations)) (PP (IN on) (NP (PRP$ her) (NN back) (, ,) (NN appendix) (, ,) (NNS eyes) (CC and) (NNS teeth)))))))) (: ;) (S (SBAR (WHADVP (WRB when)) (S (NP (DT the) (JJ Asian) (NN flu)) (VP (VBD threatened) (NP (NP (NNP Taylor) (POS 's)) (NN life))))) (, ,) (NP (NNS doctors)) (VP (VBD made) (NP (DT a) (NN hole)) (PP (IN in) (NP (PRP$ her) (NN throat))) (SBAR (IN so) (S (NP (PRP she)) (VP (MD could) (VP (VB breathe))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the years" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="years" />
          </tokens>
        </chunking>
        <chunking id="2" string="20 major operations" type="NP">
          <tokens>
            <token id="8" string="20" />
            <token id="9" string="major" />
            <token id="10" string="operations" />
          </tokens>
        </chunking>
        <chunking id="3" string="threatened Taylor 's life" type="VP">
          <tokens>
            <token id="25" string="threatened" />
            <token id="26" string="Taylor" />
            <token id="27" string="'s" />
            <token id="28" string="life" />
          </tokens>
        </chunking>
        <chunking id="4" string="a hole" type="NP">
          <tokens>
            <token id="32" string="a" />
            <token id="33" string="hole" />
          </tokens>
        </chunking>
        <chunking id="5" string="Taylor 's life" type="NP">
          <tokens>
            <token id="26" string="Taylor" />
            <token id="27" string="'s" />
            <token id="28" string="life" />
          </tokens>
        </chunking>
        <chunking id="6" string="her throat" type="NP">
          <tokens>
            <token id="35" string="her" />
            <token id="36" string="throat" />
          </tokens>
        </chunking>
        <chunking id="7" string="breathe" type="VP">
          <tokens>
            <token id="40" string="breathe" />
          </tokens>
        </chunking>
        <chunking id="8" string="she" type="NP">
          <tokens>
            <token id="4" string="she" />
          </tokens>
        </chunking>
        <chunking id="9" string="when" type="WHADVP">
          <tokens>
            <token id="21" string="when" />
          </tokens>
        </chunking>
        <chunking id="10" string="the Asian flu" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="Asian" />
            <token id="24" string="flu" />
          </tokens>
        </chunking>
        <chunking id="11" string="doctors" type="NP">
          <tokens>
            <token id="30" string="doctors" />
          </tokens>
        </chunking>
        <chunking id="12" string="her back , appendix , eyes and teeth" type="NP">
          <tokens>
            <token id="12" string="her" />
            <token id="13" string="back" />
            <token id="14" string="," />
            <token id="15" string="appendix" />
            <token id="16" string="," />
            <token id="17" string="eyes" />
            <token id="18" string="and" />
            <token id="19" string="teeth" />
          </tokens>
        </chunking>
        <chunking id="13" string="so she could breathe" type="SBAR">
          <tokens>
            <token id="37" string="so" />
            <token id="38" string="she" />
            <token id="39" string="could" />
            <token id="40" string="breathe" />
          </tokens>
        </chunking>
        <chunking id="14" string="could breathe" type="VP">
          <tokens>
            <token id="39" string="could" />
            <token id="40" string="breathe" />
          </tokens>
        </chunking>
        <chunking id="15" string="has endured about 20 major operations on her back , appendix , eyes and teeth" type="VP">
          <tokens>
            <token id="5" string="has" />
            <token id="6" string="endured" />
            <token id="7" string="about" />
            <token id="8" string="20" />
            <token id="9" string="major" />
            <token id="10" string="operations" />
            <token id="11" string="on" />
            <token id="12" string="her" />
            <token id="13" string="back" />
            <token id="14" string="," />
            <token id="15" string="appendix" />
            <token id="16" string="," />
            <token id="17" string="eyes" />
            <token id="18" string="and" />
            <token id="19" string="teeth" />
          </tokens>
        </chunking>
        <chunking id="16" string="when the Asian flu threatened Taylor 's life" type="SBAR">
          <tokens>
            <token id="21" string="when" />
            <token id="22" string="the" />
            <token id="23" string="Asian" />
            <token id="24" string="flu" />
            <token id="25" string="threatened" />
            <token id="26" string="Taylor" />
            <token id="27" string="'s" />
            <token id="28" string="life" />
          </tokens>
        </chunking>
        <chunking id="17" string="endured about 20 major operations on her back , appendix , eyes and teeth" type="VP">
          <tokens>
            <token id="6" string="endured" />
            <token id="7" string="about" />
            <token id="8" string="20" />
            <token id="9" string="major" />
            <token id="10" string="operations" />
            <token id="11" string="on" />
            <token id="12" string="her" />
            <token id="13" string="back" />
            <token id="14" string="," />
            <token id="15" string="appendix" />
            <token id="16" string="," />
            <token id="17" string="eyes" />
            <token id="18" string="and" />
            <token id="19" string="teeth" />
          </tokens>
        </chunking>
        <chunking id="18" string="Taylor 's" type="NP">
          <tokens>
            <token id="26" string="Taylor" />
            <token id="27" string="'s" />
          </tokens>
        </chunking>
        <chunking id="19" string="made a hole in her throat so she could breathe" type="VP">
          <tokens>
            <token id="31" string="made" />
            <token id="32" string="a" />
            <token id="33" string="hole" />
            <token id="34" string="in" />
            <token id="35" string="her" />
            <token id="36" string="throat" />
            <token id="37" string="so" />
            <token id="38" string="she" />
            <token id="39" string="could" />
            <token id="40" string="breathe" />
          </tokens>
        </chunking>
        <chunking id="20" string="20 major operations on her back , appendix , eyes and teeth" type="NP">
          <tokens>
            <token id="8" string="20" />
            <token id="9" string="major" />
            <token id="10" string="operations" />
            <token id="11" string="on" />
            <token id="12" string="her" />
            <token id="13" string="back" />
            <token id="14" string="," />
            <token id="15" string="appendix" />
            <token id="16" string="," />
            <token id="17" string="eyes" />
            <token id="18" string="and" />
            <token id="19" string="teeth" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">years</governor>
          <dependent id="1">Over</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">years</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">endured</governor>
          <dependent id="3">years</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">endured</governor>
          <dependent id="4">she</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">endured</governor>
          <dependent id="5">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">endured</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">operations</governor>
          <dependent id="7">about</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="10">operations</governor>
          <dependent id="8">20</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">operations</governor>
          <dependent id="9">major</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">endured</governor>
          <dependent id="10">operations</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">back</governor>
          <dependent id="11">on</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">back</governor>
          <dependent id="12">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">operations</governor>
          <dependent id="13">back</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">back</governor>
          <dependent id="15">appendix</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">back</governor>
          <dependent id="17">eyes</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">back</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">back</governor>
          <dependent id="19">teeth</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="25">threatened</governor>
          <dependent id="21">when</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">flu</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">flu</governor>
          <dependent id="23">Asian</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">threatened</governor>
          <dependent id="24">flu</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="31">made</governor>
          <dependent id="25">threatened</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="28">life</governor>
          <dependent id="26">Taylor</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">Taylor</governor>
          <dependent id="27">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">threatened</governor>
          <dependent id="28">life</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">made</governor>
          <dependent id="30">doctors</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="6">endured</governor>
          <dependent id="31">made</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">hole</governor>
          <dependent id="32">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="31">made</governor>
          <dependent id="33">hole</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">throat</governor>
          <dependent id="34">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="36">throat</governor>
          <dependent id="35">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">made</governor>
          <dependent id="36">throat</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="40">breathe</governor>
          <dependent id="37">so</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="40">breathe</governor>
          <dependent id="38">she</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="40">breathe</governor>
          <dependent id="39">could</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="31">made</governor>
          <dependent id="40">breathe</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="the years" type="DURATION" score="0.0">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="years" />
          </tokens>
        </entity>
        <entity id="2" string="Taylor" type="PERSON" score="0.0">
          <tokens>
            <token id="26" string="Taylor" />
          </tokens>
        </entity>
        <entity id="3" string="Asian" type="MISC" score="0.0">
          <tokens>
            <token id="23" string="Asian" />
          </tokens>
        </entity>
        <entity id="4" string="20" type="NUMBER" score="0.0">
          <tokens>
            <token id="8" string="20" />
          </tokens>
        </entity>
        <entity id="5" string="flu" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="24" string="flu" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="49" has_coreference="true">
      <content>But it has been her wrestling matches with weight and addiction that have consistently lured the world&amp;apost;s curiosity and, at times, admiration.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="wrestling" lemma="wrestling" stem="wrestl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="matches" lemma="match" stem="match" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="weight" lemma="weight" stem="weight" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="addiction" lemma="addiction" stem="addict" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="consistently" lemma="consistently" stem="consist" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="lured" lemma="lure" stem="lure" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="curiosity" lemma="curiosity" stem="curios" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="times" lemma="time" stem="time" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="admiration" lemma="admiration" stem="admir" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (PRP it)) (VP (VBZ has) (VP (VBN been) (NP (NP (PRP$ her) (NN wrestling)) (SBAR (S (VP (VBZ matches) (PP (IN with) (NP (NP (NN weight) (CC and) (NN addiction)) (SBAR (WHNP (WDT that)) (S (VP (VBP have) (ADVP (RB consistently)) (VP (VBN lured) (NP (NP (NP (DT the) (NN world) (POS 's)) (NN curiosity)) (CC and) (, ,) (PP (IN at) (NP (NP (NNS times)) (, ,) (NP (NN admiration))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="her wrestling" type="NP">
          <tokens>
            <token id="5" string="her" />
            <token id="6" string="wrestling" />
          </tokens>
        </chunking>
        <chunking id="2" string="times , admiration" type="NP">
          <tokens>
            <token id="23" string="times" />
            <token id="24" string="," />
            <token id="25" string="admiration" />
          </tokens>
        </chunking>
        <chunking id="3" string="it" type="NP">
          <tokens>
            <token id="2" string="it" />
          </tokens>
        </chunking>
        <chunking id="4" string="the world 's curiosity" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="world" />
            <token id="18" string="'s" />
            <token id="19" string="curiosity" />
          </tokens>
        </chunking>
        <chunking id="5" string="matches with weight and addiction that have consistently lured the world 's curiosity and , at times , admiration" type="SBAR">
          <tokens>
            <token id="7" string="matches" />
            <token id="8" string="with" />
            <token id="9" string="weight" />
            <token id="10" string="and" />
            <token id="11" string="addiction" />
            <token id="12" string="that" />
            <token id="13" string="have" />
            <token id="14" string="consistently" />
            <token id="15" string="lured" />
            <token id="16" string="the" />
            <token id="17" string="world" />
            <token id="18" string="'s" />
            <token id="19" string="curiosity" />
            <token id="20" string="and" />
            <token id="21" string="," />
            <token id="22" string="at" />
            <token id="23" string="times" />
            <token id="24" string="," />
            <token id="25" string="admiration" />
          </tokens>
        </chunking>
        <chunking id="6" string="weight and addiction" type="NP">
          <tokens>
            <token id="9" string="weight" />
            <token id="10" string="and" />
            <token id="11" string="addiction" />
          </tokens>
        </chunking>
        <chunking id="7" string="that have consistently lured the world 's curiosity and , at times , admiration" type="SBAR">
          <tokens>
            <token id="12" string="that" />
            <token id="13" string="have" />
            <token id="14" string="consistently" />
            <token id="15" string="lured" />
            <token id="16" string="the" />
            <token id="17" string="world" />
            <token id="18" string="'s" />
            <token id="19" string="curiosity" />
            <token id="20" string="and" />
            <token id="21" string="," />
            <token id="22" string="at" />
            <token id="23" string="times" />
            <token id="24" string="," />
            <token id="25" string="admiration" />
          </tokens>
        </chunking>
        <chunking id="8" string="lured the world 's curiosity and , at times , admiration" type="VP">
          <tokens>
            <token id="15" string="lured" />
            <token id="16" string="the" />
            <token id="17" string="world" />
            <token id="18" string="'s" />
            <token id="19" string="curiosity" />
            <token id="20" string="and" />
            <token id="21" string="," />
            <token id="22" string="at" />
            <token id="23" string="times" />
            <token id="24" string="," />
            <token id="25" string="admiration" />
          </tokens>
        </chunking>
        <chunking id="9" string="times" type="NP">
          <tokens>
            <token id="23" string="times" />
          </tokens>
        </chunking>
        <chunking id="10" string="have consistently lured the world 's curiosity and , at times , admiration" type="VP">
          <tokens>
            <token id="13" string="have" />
            <token id="14" string="consistently" />
            <token id="15" string="lured" />
            <token id="16" string="the" />
            <token id="17" string="world" />
            <token id="18" string="'s" />
            <token id="19" string="curiosity" />
            <token id="20" string="and" />
            <token id="21" string="," />
            <token id="22" string="at" />
            <token id="23" string="times" />
            <token id="24" string="," />
            <token id="25" string="admiration" />
          </tokens>
        </chunking>
        <chunking id="11" string="admiration" type="NP">
          <tokens>
            <token id="25" string="admiration" />
          </tokens>
        </chunking>
        <chunking id="12" string="has been her wrestling matches with weight and addiction that have consistently lured the world 's curiosity and , at times , admiration" type="VP">
          <tokens>
            <token id="3" string="has" />
            <token id="4" string="been" />
            <token id="5" string="her" />
            <token id="6" string="wrestling" />
            <token id="7" string="matches" />
            <token id="8" string="with" />
            <token id="9" string="weight" />
            <token id="10" string="and" />
            <token id="11" string="addiction" />
            <token id="12" string="that" />
            <token id="13" string="have" />
            <token id="14" string="consistently" />
            <token id="15" string="lured" />
            <token id="16" string="the" />
            <token id="17" string="world" />
            <token id="18" string="'s" />
            <token id="19" string="curiosity" />
            <token id="20" string="and" />
            <token id="21" string="," />
            <token id="22" string="at" />
            <token id="23" string="times" />
            <token id="24" string="," />
            <token id="25" string="admiration" />
          </tokens>
        </chunking>
        <chunking id="13" string="weight and addiction that have consistently lured the world 's curiosity and , at times , admiration" type="NP">
          <tokens>
            <token id="9" string="weight" />
            <token id="10" string="and" />
            <token id="11" string="addiction" />
            <token id="12" string="that" />
            <token id="13" string="have" />
            <token id="14" string="consistently" />
            <token id="15" string="lured" />
            <token id="16" string="the" />
            <token id="17" string="world" />
            <token id="18" string="'s" />
            <token id="19" string="curiosity" />
            <token id="20" string="and" />
            <token id="21" string="," />
            <token id="22" string="at" />
            <token id="23" string="times" />
            <token id="24" string="," />
            <token id="25" string="admiration" />
          </tokens>
        </chunking>
        <chunking id="14" string="been her wrestling matches with weight and addiction that have consistently lured the world 's curiosity and , at times , admiration" type="VP">
          <tokens>
            <token id="4" string="been" />
            <token id="5" string="her" />
            <token id="6" string="wrestling" />
            <token id="7" string="matches" />
            <token id="8" string="with" />
            <token id="9" string="weight" />
            <token id="10" string="and" />
            <token id="11" string="addiction" />
            <token id="12" string="that" />
            <token id="13" string="have" />
            <token id="14" string="consistently" />
            <token id="15" string="lured" />
            <token id="16" string="the" />
            <token id="17" string="world" />
            <token id="18" string="'s" />
            <token id="19" string="curiosity" />
            <token id="20" string="and" />
            <token id="21" string="," />
            <token id="22" string="at" />
            <token id="23" string="times" />
            <token id="24" string="," />
            <token id="25" string="admiration" />
          </tokens>
        </chunking>
        <chunking id="15" string="the world 's curiosity and , at times , admiration" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="world" />
            <token id="18" string="'s" />
            <token id="19" string="curiosity" />
            <token id="20" string="and" />
            <token id="21" string="," />
            <token id="22" string="at" />
            <token id="23" string="times" />
            <token id="24" string="," />
            <token id="25" string="admiration" />
          </tokens>
        </chunking>
        <chunking id="16" string="her wrestling matches with weight and addiction that have consistently lured the world 's curiosity and , at times , admiration" type="NP">
          <tokens>
            <token id="5" string="her" />
            <token id="6" string="wrestling" />
            <token id="7" string="matches" />
            <token id="8" string="with" />
            <token id="9" string="weight" />
            <token id="10" string="and" />
            <token id="11" string="addiction" />
            <token id="12" string="that" />
            <token id="13" string="have" />
            <token id="14" string="consistently" />
            <token id="15" string="lured" />
            <token id="16" string="the" />
            <token id="17" string="world" />
            <token id="18" string="'s" />
            <token id="19" string="curiosity" />
            <token id="20" string="and" />
            <token id="21" string="," />
            <token id="22" string="at" />
            <token id="23" string="times" />
            <token id="24" string="," />
            <token id="25" string="admiration" />
          </tokens>
        </chunking>
        <chunking id="17" string="the world 's" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="world" />
            <token id="18" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="6">wrestling</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">wrestling</governor>
          <dependent id="2">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">wrestling</governor>
          <dependent id="3">has</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">wrestling</governor>
          <dependent id="4">been</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">wrestling</governor>
          <dependent id="5">her</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">wrestling</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="6">wrestling</governor>
          <dependent id="7">matches</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">weight</governor>
          <dependent id="8">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">matches</governor>
          <dependent id="9">weight</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">weight</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">weight</governor>
          <dependent id="11">addiction</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">lured</governor>
          <dependent id="12">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">lured</governor>
          <dependent id="13">have</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">lured</governor>
          <dependent id="14">consistently</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="9">weight</governor>
          <dependent id="15">lured</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">world</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">curiosity</governor>
          <dependent id="17">world</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">world</governor>
          <dependent id="18">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">lured</governor>
          <dependent id="19">curiosity</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="19">curiosity</governor>
          <dependent id="20">and</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">times</governor>
          <dependent id="22">at</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">curiosity</governor>
          <dependent id="23">times</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="23">times</governor>
          <dependent id="25">admiration</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="50" has_coreference="true">
      <content>Taylor&amp;apost;s unhappy stint as a politician&amp;apost;s wife prompted her weight to balloon to 180 pounds.</content>
      <tokens>
        <token id="1" string="Taylor" lemma="Taylor" stem="taylor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="2" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="unhappy" lemma="unhappy" stem="unhappi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="stint" lemma="stint" stem="stint" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="politician" lemma="politician" stem="politician" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="wife" lemma="wife" stem="wife" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="prompted" lemma="prompt" stem="prompt" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="weight" lemma="weight" stem="weight" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="balloon" lemma="balloon" stem="balloon" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="180" lemma="180" stem="180" pos="CD" type="Number" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="17" string="pounds" lemma="pound" stem="pound" pos="NNS" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NP (NNP Taylor) (POS 's)) (ADJP (JJ unhappy)) (NN stint)) (PP (IN as) (NP (NP (DT a) (NN politician) (POS 's)) (NN wife)))) (VP (VBD prompted) (NP (PRP$ her) (NN weight) (S (VP (TO to) (VP (VB balloon) (PP (TO to) (NP (CD 180) (NNS pounds)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="her weight to balloon to 180 pounds" type="NP">
          <tokens>
            <token id="11" string="her" />
            <token id="12" string="weight" />
            <token id="13" string="to" />
            <token id="14" string="balloon" />
            <token id="15" string="to" />
            <token id="16" string="180" />
            <token id="17" string="pounds" />
          </tokens>
        </chunking>
        <chunking id="2" string="unhappy" type="ADJP">
          <tokens>
            <token id="3" string="unhappy" />
          </tokens>
        </chunking>
        <chunking id="3" string="Taylor 's unhappy stint" type="NP">
          <tokens>
            <token id="1" string="Taylor" />
            <token id="2" string="'s" />
            <token id="3" string="unhappy" />
            <token id="4" string="stint" />
          </tokens>
        </chunking>
        <chunking id="4" string="prompted her weight to balloon to 180 pounds" type="VP">
          <tokens>
            <token id="10" string="prompted" />
            <token id="11" string="her" />
            <token id="12" string="weight" />
            <token id="13" string="to" />
            <token id="14" string="balloon" />
            <token id="15" string="to" />
            <token id="16" string="180" />
            <token id="17" string="pounds" />
          </tokens>
        </chunking>
        <chunking id="5" string="a politician 's" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="politician" />
            <token id="8" string="'s" />
          </tokens>
        </chunking>
        <chunking id="6" string="180 pounds" type="NP">
          <tokens>
            <token id="16" string="180" />
            <token id="17" string="pounds" />
          </tokens>
        </chunking>
        <chunking id="7" string="balloon to 180 pounds" type="VP">
          <tokens>
            <token id="14" string="balloon" />
            <token id="15" string="to" />
            <token id="16" string="180" />
            <token id="17" string="pounds" />
          </tokens>
        </chunking>
        <chunking id="8" string="Taylor 's unhappy stint as a politician 's wife" type="NP">
          <tokens>
            <token id="1" string="Taylor" />
            <token id="2" string="'s" />
            <token id="3" string="unhappy" />
            <token id="4" string="stint" />
            <token id="5" string="as" />
            <token id="6" string="a" />
            <token id="7" string="politician" />
            <token id="8" string="'s" />
            <token id="9" string="wife" />
          </tokens>
        </chunking>
        <chunking id="9" string="to balloon to 180 pounds" type="VP">
          <tokens>
            <token id="13" string="to" />
            <token id="14" string="balloon" />
            <token id="15" string="to" />
            <token id="16" string="180" />
            <token id="17" string="pounds" />
          </tokens>
        </chunking>
        <chunking id="10" string="Taylor 's" type="NP">
          <tokens>
            <token id="1" string="Taylor" />
            <token id="2" string="'s" />
          </tokens>
        </chunking>
        <chunking id="11" string="a politician 's wife" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="politician" />
            <token id="8" string="'s" />
            <token id="9" string="wife" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="4">stint</governor>
          <dependent id="1">Taylor</dependent>
        </dependency>
        <dependency type="case">
          <governor id="1">Taylor</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">stint</governor>
          <dependent id="3">unhappy</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">prompted</governor>
          <dependent id="4">stint</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">wife</governor>
          <dependent id="5">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">politician</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">wife</governor>
          <dependent id="7">politician</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">politician</governor>
          <dependent id="8">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">stint</governor>
          <dependent id="9">wife</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">prompted</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">weight</governor>
          <dependent id="11">her</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">prompted</governor>
          <dependent id="12">weight</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">balloon</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="12">weight</governor>
          <dependent id="14">balloon</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">pounds</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="17">pounds</governor>
          <dependent id="16">180</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">balloon</governor>
          <dependent id="17">pounds</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Taylor" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Taylor" />
          </tokens>
        </entity>
        <entity id="2" string="180 pounds" type="MONEY" score="0.0">
          <tokens>
            <token id="16" string="180" />
            <token id="17" string="pounds" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="51" has_coreference="true">
      <content>When she emerged a born-again beauty in 1985 after shedding 60 pounds, and wrote a beauty book to boot, she was applauded by many -- including comedian Joan Rivers, who had made fat-Liz jokes the mainstay of her act.</content>
      <tokens>
        <token id="1" string="When" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="emerged" lemma="emerge" stem="emerg" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="born-again" lemma="born-again" stem="born-again" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="beauty" lemma="beauty" stem="beauti" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="1985" lemma="1985" stem="1985" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="9" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="shedding" lemma="shed" stem="shed" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="60" lemma="60" stem="60" pos="CD" type="Number" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="12" string="pounds" lemma="pound" stem="pound" pos="NNS" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="wrote" lemma="write" stem="wrote" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="beauty" lemma="beauty" stem="beauti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="book" lemma="book" stem="book" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="boot" lemma="boot" stem="boot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="applauded" lemma="applaud" stem="applaud" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="including" lemma="include" stem="includ" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="comedian" lemma="comedian" stem="comedian" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="Joan" lemma="Joan" stem="joan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="31" string="Rivers" lemma="Rivers" stem="river" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="32" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="made" lemma="make" stem="made" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="fat-Liz" lemma="fat-liz" stem="fat-liz" pos="NN" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="37" string="jokes" lemma="joke" stem="joke" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="mainstay" lemma="mainstay" stem="mainstai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="42" string="act" lemma="act" stem="act" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (WHADVP (WRB When)) (S (NP (PRP she)) (VP (VP (VBD emerged) (NP (DT a) (JJ born-again) (NN beauty)) (PP (IN in) (NP (CD 1985))) (PP (IN after) (S (VP (VBG shedding) (NP (CD 60) (NNS pounds)))))) (, ,) (CC and) (VP (VBD wrote) (NP (DT a) (NN beauty) (NN book)) (PP (TO to) (NP (NN boot))))))) (, ,) (NP (PRP she)) (VP (VBD was) (VP (VBN applauded) (PP (IN by) (NP (NP (JJ many)) (: --) (PP (VBG including) (NP (NN comedian) (NNP Joan) (NNP Rivers))) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD had) (VP (VBN made) (SBAR (S (NP (NN fat-Liz)) (VP (VBZ jokes) (NP (NP (DT the) (NN mainstay)) (PP (IN of) (NP (PRP$ her) (NN act))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="many -- including comedian Joan Rivers , who had made fat-Liz jokes the mainstay of her act" type="NP">
          <tokens>
            <token id="26" string="many" />
            <token id="27" string="--" />
            <token id="28" string="including" />
            <token id="29" string="comedian" />
            <token id="30" string="Joan" />
            <token id="31" string="Rivers" />
            <token id="32" string="," />
            <token id="33" string="who" />
            <token id="34" string="had" />
            <token id="35" string="made" />
            <token id="36" string="fat-Liz" />
            <token id="37" string="jokes" />
            <token id="38" string="the" />
            <token id="39" string="mainstay" />
            <token id="40" string="of" />
            <token id="41" string="her" />
            <token id="42" string="act" />
          </tokens>
        </chunking>
        <chunking id="2" string="made fat-Liz jokes the mainstay of her act" type="VP">
          <tokens>
            <token id="35" string="made" />
            <token id="36" string="fat-Liz" />
            <token id="37" string="jokes" />
            <token id="38" string="the" />
            <token id="39" string="mainstay" />
            <token id="40" string="of" />
            <token id="41" string="her" />
            <token id="42" string="act" />
          </tokens>
        </chunking>
        <chunking id="3" string="fat-Liz jokes the mainstay of her act" type="SBAR">
          <tokens>
            <token id="36" string="fat-Liz" />
            <token id="37" string="jokes" />
            <token id="38" string="the" />
            <token id="39" string="mainstay" />
            <token id="40" string="of" />
            <token id="41" string="her" />
            <token id="42" string="act" />
          </tokens>
        </chunking>
        <chunking id="4" string="emerged a born-again beauty in 1985 after shedding 60 pounds , and wrote a beauty book to boot" type="VP">
          <tokens>
            <token id="3" string="emerged" />
            <token id="4" string="a" />
            <token id="5" string="born-again" />
            <token id="6" string="beauty" />
            <token id="7" string="in" />
            <token id="8" string="1985" />
            <token id="9" string="after" />
            <token id="10" string="shedding" />
            <token id="11" string="60" />
            <token id="12" string="pounds" />
            <token id="13" string="," />
            <token id="14" string="and" />
            <token id="15" string="wrote" />
            <token id="16" string="a" />
            <token id="17" string="beauty" />
            <token id="18" string="book" />
            <token id="19" string="to" />
            <token id="20" string="boot" />
          </tokens>
        </chunking>
        <chunking id="5" string="had made fat-Liz jokes the mainstay of her act" type="VP">
          <tokens>
            <token id="34" string="had" />
            <token id="35" string="made" />
            <token id="36" string="fat-Liz" />
            <token id="37" string="jokes" />
            <token id="38" string="the" />
            <token id="39" string="mainstay" />
            <token id="40" string="of" />
            <token id="41" string="her" />
            <token id="42" string="act" />
          </tokens>
        </chunking>
        <chunking id="6" string="60 pounds" type="NP">
          <tokens>
            <token id="11" string="60" />
            <token id="12" string="pounds" />
          </tokens>
        </chunking>
        <chunking id="7" string="many" type="NP">
          <tokens>
            <token id="26" string="many" />
          </tokens>
        </chunking>
        <chunking id="8" string="she" type="NP">
          <tokens>
            <token id="2" string="she" />
          </tokens>
        </chunking>
        <chunking id="9" string="When" type="WHADVP">
          <tokens>
            <token id="1" string="When" />
          </tokens>
        </chunking>
        <chunking id="10" string="fat-Liz" type="NP">
          <tokens>
            <token id="36" string="fat-Liz" />
          </tokens>
        </chunking>
        <chunking id="11" string="1985" type="NP">
          <tokens>
            <token id="8" string="1985" />
          </tokens>
        </chunking>
        <chunking id="12" string="jokes the mainstay of her act" type="VP">
          <tokens>
            <token id="37" string="jokes" />
            <token id="38" string="the" />
            <token id="39" string="mainstay" />
            <token id="40" string="of" />
            <token id="41" string="her" />
            <token id="42" string="act" />
          </tokens>
        </chunking>
        <chunking id="13" string="who had made fat-Liz jokes the mainstay of her act" type="SBAR">
          <tokens>
            <token id="33" string="who" />
            <token id="34" string="had" />
            <token id="35" string="made" />
            <token id="36" string="fat-Liz" />
            <token id="37" string="jokes" />
            <token id="38" string="the" />
            <token id="39" string="mainstay" />
            <token id="40" string="of" />
            <token id="41" string="her" />
            <token id="42" string="act" />
          </tokens>
        </chunking>
        <chunking id="14" string="When she emerged a born-again beauty in 1985 after shedding 60 pounds , and wrote a beauty book to boot" type="SBAR">
          <tokens>
            <token id="1" string="When" />
            <token id="2" string="she" />
            <token id="3" string="emerged" />
            <token id="4" string="a" />
            <token id="5" string="born-again" />
            <token id="6" string="beauty" />
            <token id="7" string="in" />
            <token id="8" string="1985" />
            <token id="9" string="after" />
            <token id="10" string="shedding" />
            <token id="11" string="60" />
            <token id="12" string="pounds" />
            <token id="13" string="," />
            <token id="14" string="and" />
            <token id="15" string="wrote" />
            <token id="16" string="a" />
            <token id="17" string="beauty" />
            <token id="18" string="book" />
            <token id="19" string="to" />
            <token id="20" string="boot" />
          </tokens>
        </chunking>
        <chunking id="15" string="was applauded by many -- including comedian Joan Rivers , who had made fat-Liz jokes the mainstay of her act" type="VP">
          <tokens>
            <token id="23" string="was" />
            <token id="24" string="applauded" />
            <token id="25" string="by" />
            <token id="26" string="many" />
            <token id="27" string="--" />
            <token id="28" string="including" />
            <token id="29" string="comedian" />
            <token id="30" string="Joan" />
            <token id="31" string="Rivers" />
            <token id="32" string="," />
            <token id="33" string="who" />
            <token id="34" string="had" />
            <token id="35" string="made" />
            <token id="36" string="fat-Liz" />
            <token id="37" string="jokes" />
            <token id="38" string="the" />
            <token id="39" string="mainstay" />
            <token id="40" string="of" />
            <token id="41" string="her" />
            <token id="42" string="act" />
          </tokens>
        </chunking>
        <chunking id="16" string="a beauty book" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="beauty" />
            <token id="18" string="book" />
          </tokens>
        </chunking>
        <chunking id="17" string="her act" type="NP">
          <tokens>
            <token id="41" string="her" />
            <token id="42" string="act" />
          </tokens>
        </chunking>
        <chunking id="18" string="shedding 60 pounds" type="VP">
          <tokens>
            <token id="10" string="shedding" />
            <token id="11" string="60" />
            <token id="12" string="pounds" />
          </tokens>
        </chunking>
        <chunking id="19" string="a born-again beauty" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="born-again" />
            <token id="6" string="beauty" />
          </tokens>
        </chunking>
        <chunking id="20" string="the mainstay of her act" type="NP">
          <tokens>
            <token id="38" string="the" />
            <token id="39" string="mainstay" />
            <token id="40" string="of" />
            <token id="41" string="her" />
            <token id="42" string="act" />
          </tokens>
        </chunking>
        <chunking id="21" string="emerged a born-again beauty in 1985 after shedding 60 pounds" type="VP">
          <tokens>
            <token id="3" string="emerged" />
            <token id="4" string="a" />
            <token id="5" string="born-again" />
            <token id="6" string="beauty" />
            <token id="7" string="in" />
            <token id="8" string="1985" />
            <token id="9" string="after" />
            <token id="10" string="shedding" />
            <token id="11" string="60" />
            <token id="12" string="pounds" />
          </tokens>
        </chunking>
        <chunking id="22" string="comedian Joan Rivers" type="NP">
          <tokens>
            <token id="29" string="comedian" />
            <token id="30" string="Joan" />
            <token id="31" string="Rivers" />
          </tokens>
        </chunking>
        <chunking id="23" string="applauded by many -- including comedian Joan Rivers , who had made fat-Liz jokes the mainstay of her act" type="VP">
          <tokens>
            <token id="24" string="applauded" />
            <token id="25" string="by" />
            <token id="26" string="many" />
            <token id="27" string="--" />
            <token id="28" string="including" />
            <token id="29" string="comedian" />
            <token id="30" string="Joan" />
            <token id="31" string="Rivers" />
            <token id="32" string="," />
            <token id="33" string="who" />
            <token id="34" string="had" />
            <token id="35" string="made" />
            <token id="36" string="fat-Liz" />
            <token id="37" string="jokes" />
            <token id="38" string="the" />
            <token id="39" string="mainstay" />
            <token id="40" string="of" />
            <token id="41" string="her" />
            <token id="42" string="act" />
          </tokens>
        </chunking>
        <chunking id="24" string="wrote a beauty book to boot" type="VP">
          <tokens>
            <token id="15" string="wrote" />
            <token id="16" string="a" />
            <token id="17" string="beauty" />
            <token id="18" string="book" />
            <token id="19" string="to" />
            <token id="20" string="boot" />
          </tokens>
        </chunking>
        <chunking id="25" string="the mainstay" type="NP">
          <tokens>
            <token id="38" string="the" />
            <token id="39" string="mainstay" />
          </tokens>
        </chunking>
        <chunking id="26" string="boot" type="NP">
          <tokens>
            <token id="20" string="boot" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="3">emerged</governor>
          <dependent id="1">When</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">emerged</governor>
          <dependent id="2">she</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="24">applauded</governor>
          <dependent id="3">emerged</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">beauty</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">beauty</governor>
          <dependent id="5">born-again</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">emerged</governor>
          <dependent id="6">beauty</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">1985</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">emerged</governor>
          <dependent id="8">1985</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">shedding</governor>
          <dependent id="9">after</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">emerged</governor>
          <dependent id="10">shedding</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="12">pounds</governor>
          <dependent id="11">60</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">shedding</governor>
          <dependent id="12">pounds</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">emerged</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">emerged</governor>
          <dependent id="15">wrote</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">book</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">book</governor>
          <dependent id="17">beauty</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">wrote</governor>
          <dependent id="18">book</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">boot</governor>
          <dependent id="19">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">wrote</governor>
          <dependent id="20">boot</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="24">applauded</governor>
          <dependent id="22">she</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="24">applauded</governor>
          <dependent id="23">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="24">applauded</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">many</governor>
          <dependent id="25">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">applauded</governor>
          <dependent id="26">many</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">Rivers</governor>
          <dependent id="28">including</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">Rivers</governor>
          <dependent id="29">comedian</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">Rivers</governor>
          <dependent id="30">Joan</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">many</governor>
          <dependent id="31">Rivers</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="35">made</governor>
          <dependent id="33">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="35">made</governor>
          <dependent id="34">had</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="26">many</governor>
          <dependent id="35">made</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="37">jokes</governor>
          <dependent id="36">fat-Liz</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="35">made</governor>
          <dependent id="37">jokes</dependent>
        </dependency>
        <dependency type="det">
          <governor id="39">mainstay</governor>
          <dependent id="38">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="37">jokes</governor>
          <dependent id="39">mainstay</dependent>
        </dependency>
        <dependency type="case">
          <governor id="42">act</governor>
          <dependent id="40">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="42">act</governor>
          <dependent id="41">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="39">mainstay</governor>
          <dependent id="42">act</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="fat-Liz" type="MISC" score="0.0">
          <tokens>
            <token id="36" string="fat-Liz" />
          </tokens>
        </entity>
        <entity id="2" string="Joan Rivers" type="PERSON" score="0.0">
          <tokens>
            <token id="30" string="Joan" />
            <token id="31" string="Rivers" />
          </tokens>
        </entity>
        <entity id="3" string="1985" type="DATE" score="0.0">
          <tokens>
            <token id="8" string="1985" />
          </tokens>
        </entity>
        <entity id="4" string="60 pounds" type="MONEY" score="0.0">
          <tokens>
            <token id="11" string="60" />
            <token id="12" string="pounds" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="52" has_coreference="true">
      <content>&amp;quot;For somebody like me who is obsessive, it&amp;apost;s amazing I was never a gambler,&amp;quot; she said at the time.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="For" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="somebody" lemma="somebody" stem="somebodi" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="obsessive" lemma="obsessive" stem="obsess" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="amazing" lemma="amazing" stem="amaz" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="gambler" lemma="gambler" stem="gambler" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (PP (IN For) (NP (NP (NN somebody)) (PP (IN like) (NP (PRP me))) (SBAR (WHNP (WP who)) (S (VP (VBZ is) (ADJP (JJ obsessive))))))) (, ,) (NP (PRP it)) (VP (VBZ 's) (ADJP (JJ amazing) (SBAR (S (NP (PRP I)) (VP (VBD was) (ADVP (RB never)) (NP (DT a) (NN gambler)))))))) (, ,) ('' '') (NP (PRP she)) (VP (VBD said) (PP (IN at) (NP (DT the) (NN time)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="amazing I was never a gambler" type="ADJP">
          <tokens>
            <token id="12" string="amazing" />
            <token id="13" string="I" />
            <token id="14" string="was" />
            <token id="15" string="never" />
            <token id="16" string="a" />
            <token id="17" string="gambler" />
          </tokens>
        </chunking>
        <chunking id="2" string="a gambler" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="gambler" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="13" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="was never a gambler" type="VP">
          <tokens>
            <token id="14" string="was" />
            <token id="15" string="never" />
            <token id="16" string="a" />
            <token id="17" string="gambler" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="10" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="is obsessive" type="VP">
          <tokens>
            <token id="7" string="is" />
            <token id="8" string="obsessive" />
          </tokens>
        </chunking>
        <chunking id="7" string="somebody" type="NP">
          <tokens>
            <token id="3" string="somebody" />
          </tokens>
        </chunking>
        <chunking id="8" string="who is obsessive" type="SBAR">
          <tokens>
            <token id="6" string="who" />
            <token id="7" string="is" />
            <token id="8" string="obsessive" />
          </tokens>
        </chunking>
        <chunking id="9" string="she" type="NP">
          <tokens>
            <token id="20" string="she" />
          </tokens>
        </chunking>
        <chunking id="10" string="said at the time" type="VP">
          <tokens>
            <token id="21" string="said" />
            <token id="22" string="at" />
            <token id="23" string="the" />
            <token id="24" string="time" />
          </tokens>
        </chunking>
        <chunking id="11" string="'s amazing I was never a gambler" type="VP">
          <tokens>
            <token id="11" string="'s" />
            <token id="12" string="amazing" />
            <token id="13" string="I" />
            <token id="14" string="was" />
            <token id="15" string="never" />
            <token id="16" string="a" />
            <token id="17" string="gambler" />
          </tokens>
        </chunking>
        <chunking id="12" string="me" type="NP">
          <tokens>
            <token id="5" string="me" />
          </tokens>
        </chunking>
        <chunking id="13" string="I was never a gambler" type="SBAR">
          <tokens>
            <token id="13" string="I" />
            <token id="14" string="was" />
            <token id="15" string="never" />
            <token id="16" string="a" />
            <token id="17" string="gambler" />
          </tokens>
        </chunking>
        <chunking id="14" string="the time" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="time" />
          </tokens>
        </chunking>
        <chunking id="15" string="obsessive" type="ADJP">
          <tokens>
            <token id="8" string="obsessive" />
          </tokens>
        </chunking>
        <chunking id="16" string="somebody like me who is obsessive" type="NP">
          <tokens>
            <token id="3" string="somebody" />
            <token id="4" string="like" />
            <token id="5" string="me" />
            <token id="6" string="who" />
            <token id="7" string="is" />
            <token id="8" string="obsessive" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">somebody</governor>
          <dependent id="2">For</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">amazing</governor>
          <dependent id="3">somebody</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">me</governor>
          <dependent id="4">like</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">somebody</governor>
          <dependent id="5">me</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">obsessive</governor>
          <dependent id="6">who</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">obsessive</governor>
          <dependent id="7">is</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="3">somebody</governor>
          <dependent id="8">obsessive</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">amazing</governor>
          <dependent id="10">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">amazing</governor>
          <dependent id="11">'s</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="21">said</governor>
          <dependent id="12">amazing</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">gambler</governor>
          <dependent id="13">I</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="17">gambler</governor>
          <dependent id="14">was</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="17">gambler</governor>
          <dependent id="15">never</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">gambler</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">amazing</governor>
          <dependent id="17">gambler</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">said</governor>
          <dependent id="20">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="21">said</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">time</governor>
          <dependent id="22">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">time</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">said</governor>
          <dependent id="24">time</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="time" type="DATE" score="0.0">
          <tokens>
            <token id="24" string="time" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="53" has_coreference="true">
      <content>&amp;quot;I could have become anorexic.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="become" lemma="become" stem="becom" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="anorexic" lemma="anorexic" stem="anorex" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (MD could) (VP (VB have) (VP (VBN become) (S (ADJP (JJ anorexic)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="anorexic" type="ADJP">
          <tokens>
            <token id="6" string="anorexic" />
          </tokens>
        </chunking>
        <chunking id="2" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="3" string="have become anorexic" type="VP">
          <tokens>
            <token id="4" string="have" />
            <token id="5" string="become" />
            <token id="6" string="anorexic" />
          </tokens>
        </chunking>
        <chunking id="4" string="could have become anorexic" type="VP">
          <tokens>
            <token id="3" string="could" />
            <token id="4" string="have" />
            <token id="5" string="become" />
            <token id="6" string="anorexic" />
          </tokens>
        </chunking>
        <chunking id="5" string="become anorexic" type="VP">
          <tokens>
            <token id="5" string="become" />
            <token id="6" string="anorexic" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">become</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">become</governor>
          <dependent id="3">could</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">become</governor>
          <dependent id="4">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">become</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">become</governor>
          <dependent id="6">anorexic</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="54" has_coreference="true">
      <content>I got to a size 4 and said, &amp;apost;Why not a size 2?&amp;apost;</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="got" lemma="get" stem="got" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="size" lemma="size" stem="size" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="4" lemma="4" stem="4" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="'" lemma="`" stem="'" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Why" lemma="why" stem="why" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="size" lemma="size" stem="size" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="2" lemma="2" stem="2" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="16" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBD got) (PP (TO to) (NP (NP (DT a) (NN size)) (UCP (NP (CD 4)) (CC and) (S (VP (VBD said) (, ,) (`` `) (INTJ (WRB Why))))))) (PP (RB not) (NP (DT a) (NN size) (CD 2)))) (. ?) ('' ')))</syntactictree>
      <chunkings>
        <chunking id="1" string="a size" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="size" />
          </tokens>
        </chunking>
        <chunking id="2" string="4" type="NP">
          <tokens>
            <token id="6" string="4" />
          </tokens>
        </chunking>
        <chunking id="3" string="a size 4 and said , ` Why" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="size" />
            <token id="6" string="4" />
            <token id="7" string="and" />
            <token id="8" string="said" />
            <token id="9" string="," />
            <token id="10" string="'" />
            <token id="11" string="Why" />
          </tokens>
        </chunking>
        <chunking id="4" string="a size 2" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="size" />
            <token id="15" string="2" />
          </tokens>
        </chunking>
        <chunking id="5" string="said , ` Why" type="VP">
          <tokens>
            <token id="8" string="said" />
            <token id="9" string="," />
            <token id="10" string="'" />
            <token id="11" string="Why" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="got to a size 4 and said , ` Why not a size 2" type="VP">
          <tokens>
            <token id="2" string="got" />
            <token id="3" string="to" />
            <token id="4" string="a" />
            <token id="5" string="size" />
            <token id="6" string="4" />
            <token id="7" string="and" />
            <token id="8" string="said" />
            <token id="9" string="," />
            <token id="10" string="'" />
            <token id="11" string="Why" />
            <token id="12" string="not" />
            <token id="13" string="a" />
            <token id="14" string="size" />
            <token id="15" string="2" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">got</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">got</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">size</governor>
          <dependent id="3">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">size</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">got</governor>
          <dependent id="5">size</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="5">size</governor>
          <dependent id="6">4</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">4</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">4</governor>
          <dependent id="8">said</dependent>
        </dependency>
        <dependency type="discourse">
          <governor id="8">said</governor>
          <dependent id="11">Why</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="14">size</governor>
          <dependent id="12">not</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">size</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">got</governor>
          <dependent id="14">size</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="14">size</governor>
          <dependent id="15">2</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="2" type="NUMBER" score="0.0">
          <tokens>
            <token id="15" string="2" />
          </tokens>
        </entity>
        <entity id="2" string="4" type="NUMBER" score="0.0">
          <tokens>
            <token id="6" string="4" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="55" has_coreference="true">
      <content>Then I slapped myself and went from 118 to 122, which is the right weight for me.&amp;quot;</content>
      <tokens>
        <token id="1" string="Then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="slapped" lemma="slap" stem="slap" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="myself" lemma="myself" stem="myself" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="went" lemma="go" stem="went" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="118" lemma="118" stem="118" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="10" string="122" lemma="122" stem="122" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="right" lemma="right" stem="right" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="true" is_refers="false" />
        <token id="16" string="weight" lemma="weight" stem="weight" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (RB Then) (NP (PRP I)) (VP (VP (VBD slapped) (NP (PRP myself))) (CC and) (VP (VBD went) (PP (IN from) (NP (NP (QP (CD 118) (TO to) (CD 122))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (NP (NP (DT the) (JJ right) (NN weight)) (PP (IN for) (NP (PRP me))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="slapped myself" type="VP">
          <tokens>
            <token id="3" string="slapped" />
            <token id="4" string="myself" />
          </tokens>
        </chunking>
        <chunking id="2" string="went from 118 to 122 , which is the right weight for me" type="VP">
          <tokens>
            <token id="6" string="went" />
            <token id="7" string="from" />
            <token id="8" string="118" />
            <token id="9" string="to" />
            <token id="10" string="122" />
            <token id="11" string="," />
            <token id="12" string="which" />
            <token id="13" string="is" />
            <token id="14" string="the" />
            <token id="15" string="right" />
            <token id="16" string="weight" />
            <token id="17" string="for" />
            <token id="18" string="me" />
          </tokens>
        </chunking>
        <chunking id="3" string="118 to 122 , which is the right weight for me" type="NP">
          <tokens>
            <token id="8" string="118" />
            <token id="9" string="to" />
            <token id="10" string="122" />
            <token id="11" string="," />
            <token id="12" string="which" />
            <token id="13" string="is" />
            <token id="14" string="the" />
            <token id="15" string="right" />
            <token id="16" string="weight" />
            <token id="17" string="for" />
            <token id="18" string="me" />
          </tokens>
        </chunking>
        <chunking id="4" string="which is the right weight for me" type="SBAR">
          <tokens>
            <token id="12" string="which" />
            <token id="13" string="is" />
            <token id="14" string="the" />
            <token id="15" string="right" />
            <token id="16" string="weight" />
            <token id="17" string="for" />
            <token id="18" string="me" />
          </tokens>
        </chunking>
        <chunking id="5" string="me" type="NP">
          <tokens>
            <token id="18" string="me" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="myself" type="NP">
          <tokens>
            <token id="4" string="myself" />
          </tokens>
        </chunking>
        <chunking id="8" string="the right weight for me" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="right" />
            <token id="16" string="weight" />
            <token id="17" string="for" />
            <token id="18" string="me" />
          </tokens>
        </chunking>
        <chunking id="9" string="the right weight" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="right" />
            <token id="16" string="weight" />
          </tokens>
        </chunking>
        <chunking id="10" string="is the right weight for me" type="VP">
          <tokens>
            <token id="13" string="is" />
            <token id="14" string="the" />
            <token id="15" string="right" />
            <token id="16" string="weight" />
            <token id="17" string="for" />
            <token id="18" string="me" />
          </tokens>
        </chunking>
        <chunking id="11" string="118 to 122" type="NP">
          <tokens>
            <token id="8" string="118" />
            <token id="9" string="to" />
            <token id="10" string="122" />
          </tokens>
        </chunking>
        <chunking id="12" string="slapped myself and went from 118 to 122 , which is the right weight for me" type="VP">
          <tokens>
            <token id="3" string="slapped" />
            <token id="4" string="myself" />
            <token id="5" string="and" />
            <token id="6" string="went" />
            <token id="7" string="from" />
            <token id="8" string="118" />
            <token id="9" string="to" />
            <token id="10" string="122" />
            <token id="11" string="," />
            <token id="12" string="which" />
            <token id="13" string="is" />
            <token id="14" string="the" />
            <token id="15" string="right" />
            <token id="16" string="weight" />
            <token id="17" string="for" />
            <token id="18" string="me" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="3">slapped</governor>
          <dependent id="1">Then</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">slapped</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">slapped</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">slapped</governor>
          <dependent id="4">myself</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">slapped</governor>
          <dependent id="5">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">slapped</governor>
          <dependent id="6">went</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">122</governor>
          <dependent id="7">from</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">122</governor>
          <dependent id="8">118</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="10">122</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">went</governor>
          <dependent id="10">122</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">weight</governor>
          <dependent id="12">which</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="16">weight</governor>
          <dependent id="13">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">weight</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">weight</governor>
          <dependent id="15">right</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="10">122</governor>
          <dependent id="16">weight</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">me</governor>
          <dependent id="17">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">weight</governor>
          <dependent id="18">me</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="right" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="15" string="right" />
          </tokens>
        </entity>
        <entity id="2" string="118 to 122" type="NUMBER" score="0.0">
          <tokens>
            <token id="8" string="118" />
            <token id="9" string="to" />
            <token id="10" string="122" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="56" has_coreference="false">
      <content>But her battles against addiction have played havoc with her fight against the bulge.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="battles" lemma="battle" stem="battl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="addiction" lemma="addiction" stem="addict" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="played" lemma="play" stem="plai" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="havoc" lemma="havoc" stem="havoc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="fight" lemma="fight" stem="fight" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="bulge" lemma="bulge" stem="bulg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (NP (PRP$ her) (NNS battles)) (PP (IN against) (NP (NN addiction)))) (VP (VBP have) (VP (VBN played) (NP (NN havoc)) (PP (IN with) (NP (NP (PRP$ her) (NN fight)) (PP (IN against) (NP (DT the) (NN bulge))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="her battles against addiction" type="NP">
          <tokens>
            <token id="2" string="her" />
            <token id="3" string="battles" />
            <token id="4" string="against" />
            <token id="5" string="addiction" />
          </tokens>
        </chunking>
        <chunking id="2" string="addiction" type="NP">
          <tokens>
            <token id="5" string="addiction" />
          </tokens>
        </chunking>
        <chunking id="3" string="have played havoc with her fight against the bulge" type="VP">
          <tokens>
            <token id="6" string="have" />
            <token id="7" string="played" />
            <token id="8" string="havoc" />
            <token id="9" string="with" />
            <token id="10" string="her" />
            <token id="11" string="fight" />
            <token id="12" string="against" />
            <token id="13" string="the" />
            <token id="14" string="bulge" />
          </tokens>
        </chunking>
        <chunking id="4" string="played havoc with her fight against the bulge" type="VP">
          <tokens>
            <token id="7" string="played" />
            <token id="8" string="havoc" />
            <token id="9" string="with" />
            <token id="10" string="her" />
            <token id="11" string="fight" />
            <token id="12" string="against" />
            <token id="13" string="the" />
            <token id="14" string="bulge" />
          </tokens>
        </chunking>
        <chunking id="5" string="havoc" type="NP">
          <tokens>
            <token id="8" string="havoc" />
          </tokens>
        </chunking>
        <chunking id="6" string="her fight" type="NP">
          <tokens>
            <token id="10" string="her" />
            <token id="11" string="fight" />
          </tokens>
        </chunking>
        <chunking id="7" string="her battles" type="NP">
          <tokens>
            <token id="2" string="her" />
            <token id="3" string="battles" />
          </tokens>
        </chunking>
        <chunking id="8" string="her fight against the bulge" type="NP">
          <tokens>
            <token id="10" string="her" />
            <token id="11" string="fight" />
            <token id="12" string="against" />
            <token id="13" string="the" />
            <token id="14" string="bulge" />
          </tokens>
        </chunking>
        <chunking id="9" string="the bulge" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="bulge" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="7">played</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="3">battles</governor>
          <dependent id="2">her</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">played</governor>
          <dependent id="3">battles</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">addiction</governor>
          <dependent id="4">against</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">battles</governor>
          <dependent id="5">addiction</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">played</governor>
          <dependent id="6">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">played</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">played</governor>
          <dependent id="8">havoc</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">fight</governor>
          <dependent id="9">with</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">fight</governor>
          <dependent id="10">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">played</governor>
          <dependent id="11">fight</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">bulge</governor>
          <dependent id="12">against</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">bulge</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">fight</governor>
          <dependent id="14">bulge</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="57" has_coreference="false">
      <content>And her persistent back problems have nurtured her dependence on pills.</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="persistent" lemma="persistent" stem="persist" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="back" lemma="back" stem="back" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="problems" lemma="problem" stem="problem" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="nurtured" lemma="nurture" stem="nurtur" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="dependence" lemma="dependence" stem="depend" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="pills" lemma="pill" stem="pill" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC And) (NP (PRP$ her) (JJ persistent) (NN back) (NNS problems)) (VP (VBP have) (VP (VBN nurtured) (NP (PRP$ her) (NN dependence)) (PP (IN on) (NP (NNS pills))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="her persistent back problems" type="NP">
          <tokens>
            <token id="2" string="her" />
            <token id="3" string="persistent" />
            <token id="4" string="back" />
            <token id="5" string="problems" />
          </tokens>
        </chunking>
        <chunking id="2" string="pills" type="NP">
          <tokens>
            <token id="11" string="pills" />
          </tokens>
        </chunking>
        <chunking id="3" string="nurtured her dependence on pills" type="VP">
          <tokens>
            <token id="7" string="nurtured" />
            <token id="8" string="her" />
            <token id="9" string="dependence" />
            <token id="10" string="on" />
            <token id="11" string="pills" />
          </tokens>
        </chunking>
        <chunking id="4" string="her dependence" type="NP">
          <tokens>
            <token id="8" string="her" />
            <token id="9" string="dependence" />
          </tokens>
        </chunking>
        <chunking id="5" string="have nurtured her dependence on pills" type="VP">
          <tokens>
            <token id="6" string="have" />
            <token id="7" string="nurtured" />
            <token id="8" string="her" />
            <token id="9" string="dependence" />
            <token id="10" string="on" />
            <token id="11" string="pills" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="7">nurtured</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">problems</governor>
          <dependent id="2">her</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">problems</governor>
          <dependent id="3">persistent</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">problems</governor>
          <dependent id="4">back</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">nurtured</governor>
          <dependent id="5">problems</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">nurtured</governor>
          <dependent id="6">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">nurtured</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">dependence</governor>
          <dependent id="8">her</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">nurtured</governor>
          <dependent id="9">dependence</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">pills</governor>
          <dependent id="10">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">nurtured</governor>
          <dependent id="11">pills</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="58" has_coreference="true">
      <content>Her addictions have even been linked to a criminal investigation by the Los Angeles County district attorney&amp;apost;s office; last week, prosecutors announced that no charges would be filed against Taylor&amp;apost;s doctors, who had been accused of over-prescribing dependence-forming drugs.</content>
      <tokens>
        <token id="1" string="Her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="addictions" lemma="addiction" stem="addict" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="linked" lemma="link" stem="link" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="criminal" lemma="criminal" stem="crimin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="investigation" lemma="investigation" stem="investig" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Los" lemma="Los" stem="lo" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="14" string="Angeles" lemma="Angeles" stem="angele" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="15" string="County" lemma="County" stem="counti" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="16" string="district" lemma="district" stem="district" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="attorney" lemma="attorney" stem="attornei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="office" lemma="office" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="22" string="week" lemma="week" stem="week" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="prosecutors" lemma="prosecutor" stem="prosecutor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="announced" lemma="announce" stem="announc" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="charges" lemma="charge" stem="charg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="filed" lemma="file" stem="file" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="Taylor" lemma="Taylor" stem="taylor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="34" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="35" string="doctors" lemma="doctor" stem="doctor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="36" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="37" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="38" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="39" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="40" string="accused" lemma="accuse" stem="accus" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="41" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="42" string="over-prescribing" lemma="over-prescribing" stem="over-prescrib" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="43" string="dependence-forming" lemma="dependence-forming" stem="dependence-form" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="44" string="drugs" lemma="drug" stem="drug" pos="NNS" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="true" />
        <token id="45" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP$ Her) (NNS addictions)) (VP (VBP have) (ADVP (RB even)) (VP (VBN been) (VP (VBN linked) (PP (TO to) (NP (DT a) (JJ criminal) (NN investigation))) (PP (IN by) (NP (NP (DT the) (NNP Los) (NNP Angeles) (NNP County) (NN district) (NN attorney) (POS 's)) (NN office))))))) (: ;) (S (NP-TMP (JJ last) (NN week)) (, ,) (NP (NNS prosecutors)) (VP (VBD announced) (SBAR (IN that) (S (NP (DT no) (NNS charges)) (VP (MD would) (VP (VB be) (VP (VBN filed) (PP (IN against) (NP (NP (NP (NNP Taylor) (POS 's)) (NNS doctors)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD had) (VP (VBN been) (VP (VBN accused) (PP (IN of) (NP (JJ over-prescribing) (JJ dependence-forming) (NNS drugs))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="announced that no charges would be filed against Taylor 's doctors , who had been accused of over-prescribing dependence-forming drugs" type="VP">
          <tokens>
            <token id="25" string="announced" />
            <token id="26" string="that" />
            <token id="27" string="no" />
            <token id="28" string="charges" />
            <token id="29" string="would" />
            <token id="30" string="be" />
            <token id="31" string="filed" />
            <token id="32" string="against" />
            <token id="33" string="Taylor" />
            <token id="34" string="'s" />
            <token id="35" string="doctors" />
            <token id="36" string="," />
            <token id="37" string="who" />
            <token id="38" string="had" />
            <token id="39" string="been" />
            <token id="40" string="accused" />
            <token id="41" string="of" />
            <token id="42" string="over-prescribing" />
            <token id="43" string="dependence-forming" />
            <token id="44" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="2" string="been accused of over-prescribing dependence-forming drugs" type="VP">
          <tokens>
            <token id="39" string="been" />
            <token id="40" string="accused" />
            <token id="41" string="of" />
            <token id="42" string="over-prescribing" />
            <token id="43" string="dependence-forming" />
            <token id="44" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="3" string="accused of over-prescribing dependence-forming drugs" type="VP">
          <tokens>
            <token id="40" string="accused" />
            <token id="41" string="of" />
            <token id="42" string="over-prescribing" />
            <token id="43" string="dependence-forming" />
            <token id="44" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="4" string="a criminal investigation" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="criminal" />
            <token id="10" string="investigation" />
          </tokens>
        </chunking>
        <chunking id="5" string="be filed against Taylor 's doctors , who had been accused of over-prescribing dependence-forming drugs" type="VP">
          <tokens>
            <token id="30" string="be" />
            <token id="31" string="filed" />
            <token id="32" string="against" />
            <token id="33" string="Taylor" />
            <token id="34" string="'s" />
            <token id="35" string="doctors" />
            <token id="36" string="," />
            <token id="37" string="who" />
            <token id="38" string="had" />
            <token id="39" string="been" />
            <token id="40" string="accused" />
            <token id="41" string="of" />
            <token id="42" string="over-prescribing" />
            <token id="43" string="dependence-forming" />
            <token id="44" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="6" string="Taylor 's doctors , who had been accused of over-prescribing dependence-forming drugs" type="NP">
          <tokens>
            <token id="33" string="Taylor" />
            <token id="34" string="'s" />
            <token id="35" string="doctors" />
            <token id="36" string="," />
            <token id="37" string="who" />
            <token id="38" string="had" />
            <token id="39" string="been" />
            <token id="40" string="accused" />
            <token id="41" string="of" />
            <token id="42" string="over-prescribing" />
            <token id="43" string="dependence-forming" />
            <token id="44" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="7" string="would be filed against Taylor 's doctors , who had been accused of over-prescribing dependence-forming drugs" type="VP">
          <tokens>
            <token id="29" string="would" />
            <token id="30" string="be" />
            <token id="31" string="filed" />
            <token id="32" string="against" />
            <token id="33" string="Taylor" />
            <token id="34" string="'s" />
            <token id="35" string="doctors" />
            <token id="36" string="," />
            <token id="37" string="who" />
            <token id="38" string="had" />
            <token id="39" string="been" />
            <token id="40" string="accused" />
            <token id="41" string="of" />
            <token id="42" string="over-prescribing" />
            <token id="43" string="dependence-forming" />
            <token id="44" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="8" string="prosecutors" type="NP">
          <tokens>
            <token id="24" string="prosecutors" />
          </tokens>
        </chunking>
        <chunking id="9" string="the Los Angeles County district attorney 's office" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="Los" />
            <token id="14" string="Angeles" />
            <token id="15" string="County" />
            <token id="16" string="district" />
            <token id="17" string="attorney" />
            <token id="18" string="'s" />
            <token id="19" string="office" />
          </tokens>
        </chunking>
        <chunking id="10" string="linked to a criminal investigation by the Los Angeles County district attorney 's office" type="VP">
          <tokens>
            <token id="6" string="linked" />
            <token id="7" string="to" />
            <token id="8" string="a" />
            <token id="9" string="criminal" />
            <token id="10" string="investigation" />
            <token id="11" string="by" />
            <token id="12" string="the" />
            <token id="13" string="Los" />
            <token id="14" string="Angeles" />
            <token id="15" string="County" />
            <token id="16" string="district" />
            <token id="17" string="attorney" />
            <token id="18" string="'s" />
            <token id="19" string="office" />
          </tokens>
        </chunking>
        <chunking id="11" string="that no charges would be filed against Taylor 's doctors , who had been accused of over-prescribing dependence-forming drugs" type="SBAR">
          <tokens>
            <token id="26" string="that" />
            <token id="27" string="no" />
            <token id="28" string="charges" />
            <token id="29" string="would" />
            <token id="30" string="be" />
            <token id="31" string="filed" />
            <token id="32" string="against" />
            <token id="33" string="Taylor" />
            <token id="34" string="'s" />
            <token id="35" string="doctors" />
            <token id="36" string="," />
            <token id="37" string="who" />
            <token id="38" string="had" />
            <token id="39" string="been" />
            <token id="40" string="accused" />
            <token id="41" string="of" />
            <token id="42" string="over-prescribing" />
            <token id="43" string="dependence-forming" />
            <token id="44" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="12" string="no charges" type="NP">
          <tokens>
            <token id="27" string="no" />
            <token id="28" string="charges" />
          </tokens>
        </chunking>
        <chunking id="13" string="the Los Angeles County district attorney 's" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="Los" />
            <token id="14" string="Angeles" />
            <token id="15" string="County" />
            <token id="16" string="district" />
            <token id="17" string="attorney" />
            <token id="18" string="'s" />
          </tokens>
        </chunking>
        <chunking id="14" string="had been accused of over-prescribing dependence-forming drugs" type="VP">
          <tokens>
            <token id="38" string="had" />
            <token id="39" string="been" />
            <token id="40" string="accused" />
            <token id="41" string="of" />
            <token id="42" string="over-prescribing" />
            <token id="43" string="dependence-forming" />
            <token id="44" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="15" string="Her addictions" type="NP">
          <tokens>
            <token id="1" string="Her" />
            <token id="2" string="addictions" />
          </tokens>
        </chunking>
        <chunking id="16" string="filed against Taylor 's doctors , who had been accused of over-prescribing dependence-forming drugs" type="VP">
          <tokens>
            <token id="31" string="filed" />
            <token id="32" string="against" />
            <token id="33" string="Taylor" />
            <token id="34" string="'s" />
            <token id="35" string="doctors" />
            <token id="36" string="," />
            <token id="37" string="who" />
            <token id="38" string="had" />
            <token id="39" string="been" />
            <token id="40" string="accused" />
            <token id="41" string="of" />
            <token id="42" string="over-prescribing" />
            <token id="43" string="dependence-forming" />
            <token id="44" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="17" string="over-prescribing dependence-forming drugs" type="NP">
          <tokens>
            <token id="42" string="over-prescribing" />
            <token id="43" string="dependence-forming" />
            <token id="44" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="18" string="who had been accused of over-prescribing dependence-forming drugs" type="SBAR">
          <tokens>
            <token id="37" string="who" />
            <token id="38" string="had" />
            <token id="39" string="been" />
            <token id="40" string="accused" />
            <token id="41" string="of" />
            <token id="42" string="over-prescribing" />
            <token id="43" string="dependence-forming" />
            <token id="44" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="19" string="been linked to a criminal investigation by the Los Angeles County district attorney 's office" type="VP">
          <tokens>
            <token id="5" string="been" />
            <token id="6" string="linked" />
            <token id="7" string="to" />
            <token id="8" string="a" />
            <token id="9" string="criminal" />
            <token id="10" string="investigation" />
            <token id="11" string="by" />
            <token id="12" string="the" />
            <token id="13" string="Los" />
            <token id="14" string="Angeles" />
            <token id="15" string="County" />
            <token id="16" string="district" />
            <token id="17" string="attorney" />
            <token id="18" string="'s" />
            <token id="19" string="office" />
          </tokens>
        </chunking>
        <chunking id="20" string="Taylor 's doctors" type="NP">
          <tokens>
            <token id="33" string="Taylor" />
            <token id="34" string="'s" />
            <token id="35" string="doctors" />
          </tokens>
        </chunking>
        <chunking id="21" string="Taylor 's" type="NP">
          <tokens>
            <token id="33" string="Taylor" />
            <token id="34" string="'s" />
          </tokens>
        </chunking>
        <chunking id="22" string="have even been linked to a criminal investigation by the Los Angeles County district attorney 's office" type="VP">
          <tokens>
            <token id="3" string="have" />
            <token id="4" string="even" />
            <token id="5" string="been" />
            <token id="6" string="linked" />
            <token id="7" string="to" />
            <token id="8" string="a" />
            <token id="9" string="criminal" />
            <token id="10" string="investigation" />
            <token id="11" string="by" />
            <token id="12" string="the" />
            <token id="13" string="Los" />
            <token id="14" string="Angeles" />
            <token id="15" string="County" />
            <token id="16" string="district" />
            <token id="17" string="attorney" />
            <token id="18" string="'s" />
            <token id="19" string="office" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="2">addictions</governor>
          <dependent id="1">Her</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="6">linked</governor>
          <dependent id="2">addictions</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">linked</governor>
          <dependent id="3">have</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">linked</governor>
          <dependent id="4">even</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">linked</governor>
          <dependent id="5">been</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">linked</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">investigation</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">investigation</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">investigation</governor>
          <dependent id="9">criminal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">linked</governor>
          <dependent id="10">investigation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">office</governor>
          <dependent id="11">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">attorney</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">attorney</governor>
          <dependent id="13">Los</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">attorney</governor>
          <dependent id="14">Angeles</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">attorney</governor>
          <dependent id="15">County</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">attorney</governor>
          <dependent id="16">district</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">office</governor>
          <dependent id="17">attorney</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">attorney</governor>
          <dependent id="18">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">linked</governor>
          <dependent id="19">office</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">week</governor>
          <dependent id="21">last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="25">announced</governor>
          <dependent id="22">week</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">announced</governor>
          <dependent id="24">prosecutors</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="6">linked</governor>
          <dependent id="25">announced</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="31">filed</governor>
          <dependent id="26">that</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="28">charges</governor>
          <dependent id="27">no</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="31">filed</governor>
          <dependent id="28">charges</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="31">filed</governor>
          <dependent id="29">would</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="31">filed</governor>
          <dependent id="30">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="25">announced</governor>
          <dependent id="31">filed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">doctors</governor>
          <dependent id="32">against</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="35">doctors</governor>
          <dependent id="33">Taylor</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">Taylor</governor>
          <dependent id="34">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">filed</governor>
          <dependent id="35">doctors</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="40">accused</governor>
          <dependent id="37">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="40">accused</governor>
          <dependent id="38">had</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="40">accused</governor>
          <dependent id="39">been</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="35">doctors</governor>
          <dependent id="40">accused</dependent>
        </dependency>
        <dependency type="case">
          <governor id="44">drugs</governor>
          <dependent id="41">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="44">drugs</governor>
          <dependent id="42">over-prescribing</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="44">drugs</governor>
          <dependent id="43">dependence-forming</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="40">accused</governor>
          <dependent id="44">drugs</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Taylor" type="PERSON" score="0.0">
          <tokens>
            <token id="33" string="Taylor" />
          </tokens>
        </entity>
        <entity id="2" string="drugs" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="44" string="drugs" />
          </tokens>
        </entity>
        <entity id="3" string="Los Angeles County" type="LOCATION" score="0.0">
          <tokens>
            <token id="13" string="Los" />
            <token id="14" string="Angeles" />
            <token id="15" string="County" />
          </tokens>
        </entity>
        <entity id="4" string="last week" type="DATE" score="0.0">
          <tokens>
            <token id="21" string="last" />
            <token id="22" string="week" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="59" has_coreference="true">
      <content>Taylor, the first celebrity known to enter the Betty Ford clinic in Rancho Mirage, made a public example of her willingness to take on her addictions in two heavily publicized stays there.</content>
      <tokens>
        <token id="1" string="Taylor" lemma="Taylor" stem="taylor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="true" />
        <token id="5" string="celebrity" lemma="celebrity" stem="celebr" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="known" lemma="know" stem="known" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="enter" lemma="enter" stem="enter" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="10" string="Betty" lemma="Betty" stem="betti" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="11" string="Ford" lemma="Ford" stem="ford" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="12" string="clinic" lemma="clinic" stem="clinic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="14" string="Rancho" lemma="Rancho" stem="rancho" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="true" />
        <token id="15" string="Mirage" lemma="Mirage" stem="mirag" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="true" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="made" lemma="make" stem="made" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="public" lemma="public" stem="public" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="example" lemma="example" stem="exampl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="willingness" lemma="willingness" stem="willing" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="take" lemma="take" stem="take" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="on" lemma="on" stem="on" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="addictions" lemma="addiction" stem="addict" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="31" string="heavily" lemma="heavily" stem="heavili" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="publicized" lemma="publicize" stem="public" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="stays" lemma="stay" stem="stai" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="there" lemma="there" stem="there" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Taylor)) (, ,) (NP (NP (DT the) (JJ first) (NN celebrity)) (VP (VBN known) (S (VP (TO to) (VP (VB enter) (NP (NP (DT the) (NNP Betty) (NNP Ford) (NN clinic)) (PP (IN in) (NP (NNP Rancho) (NNP Mirage))))))))) (, ,)) (VP (VBD made) (NP (NP (DT a) (JJ public) (NN example)) (PP (IN of) (NP (PRP$ her) (NN willingness) (S (VP (TO to) (VP (VB take) (PRT (RP on)) (NP (PRP$ her) (NNS addictions)) (PP (IN in) (NP (CD two)) (NP (NP (ADJP (RB heavily) (VBN publicized)) (NNS stays)) (ADVP (RB there))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the Betty Ford clinic" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="Betty" />
            <token id="11" string="Ford" />
            <token id="12" string="clinic" />
          </tokens>
        </chunking>
        <chunking id="2" string="heavily publicized stays" type="NP">
          <tokens>
            <token id="31" string="heavily" />
            <token id="32" string="publicized" />
            <token id="33" string="stays" />
          </tokens>
        </chunking>
        <chunking id="3" string="known to enter the Betty Ford clinic in Rancho Mirage" type="VP">
          <tokens>
            <token id="6" string="known" />
            <token id="7" string="to" />
            <token id="8" string="enter" />
            <token id="9" string="the" />
            <token id="10" string="Betty" />
            <token id="11" string="Ford" />
            <token id="12" string="clinic" />
            <token id="13" string="in" />
            <token id="14" string="Rancho" />
            <token id="15" string="Mirage" />
          </tokens>
        </chunking>
        <chunking id="4" string="a public example of her willingness to take on her addictions in two heavily publicized stays there" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="public" />
            <token id="20" string="example" />
            <token id="21" string="of" />
            <token id="22" string="her" />
            <token id="23" string="willingness" />
            <token id="24" string="to" />
            <token id="25" string="take" />
            <token id="26" string="on" />
            <token id="27" string="her" />
            <token id="28" string="addictions" />
            <token id="29" string="in" />
            <token id="30" string="two" />
            <token id="31" string="heavily" />
            <token id="32" string="publicized" />
            <token id="33" string="stays" />
            <token id="34" string="there" />
          </tokens>
        </chunking>
        <chunking id="5" string="Taylor" type="NP">
          <tokens>
            <token id="1" string="Taylor" />
          </tokens>
        </chunking>
        <chunking id="6" string="to take on her addictions in two heavily publicized stays there" type="VP">
          <tokens>
            <token id="24" string="to" />
            <token id="25" string="take" />
            <token id="26" string="on" />
            <token id="27" string="her" />
            <token id="28" string="addictions" />
            <token id="29" string="in" />
            <token id="30" string="two" />
            <token id="31" string="heavily" />
            <token id="32" string="publicized" />
            <token id="33" string="stays" />
            <token id="34" string="there" />
          </tokens>
        </chunking>
        <chunking id="7" string="two" type="NP">
          <tokens>
            <token id="30" string="two" />
          </tokens>
        </chunking>
        <chunking id="8" string="heavily publicized stays there" type="NP">
          <tokens>
            <token id="31" string="heavily" />
            <token id="32" string="publicized" />
            <token id="33" string="stays" />
            <token id="34" string="there" />
          </tokens>
        </chunking>
        <chunking id="9" string="a public example" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="public" />
            <token id="20" string="example" />
          </tokens>
        </chunking>
        <chunking id="10" string="enter the Betty Ford clinic in Rancho Mirage" type="VP">
          <tokens>
            <token id="8" string="enter" />
            <token id="9" string="the" />
            <token id="10" string="Betty" />
            <token id="11" string="Ford" />
            <token id="12" string="clinic" />
            <token id="13" string="in" />
            <token id="14" string="Rancho" />
            <token id="15" string="Mirage" />
          </tokens>
        </chunking>
        <chunking id="11" string="Rancho Mirage" type="NP">
          <tokens>
            <token id="14" string="Rancho" />
            <token id="15" string="Mirage" />
          </tokens>
        </chunking>
        <chunking id="12" string="take on her addictions in two heavily publicized stays there" type="VP">
          <tokens>
            <token id="25" string="take" />
            <token id="26" string="on" />
            <token id="27" string="her" />
            <token id="28" string="addictions" />
            <token id="29" string="in" />
            <token id="30" string="two" />
            <token id="31" string="heavily" />
            <token id="32" string="publicized" />
            <token id="33" string="stays" />
            <token id="34" string="there" />
          </tokens>
        </chunking>
        <chunking id="13" string="Taylor , the first celebrity known to enter the Betty Ford clinic in Rancho Mirage ," type="NP">
          <tokens>
            <token id="1" string="Taylor" />
            <token id="2" string="," />
            <token id="3" string="the" />
            <token id="4" string="first" />
            <token id="5" string="celebrity" />
            <token id="6" string="known" />
            <token id="7" string="to" />
            <token id="8" string="enter" />
            <token id="9" string="the" />
            <token id="10" string="Betty" />
            <token id="11" string="Ford" />
            <token id="12" string="clinic" />
            <token id="13" string="in" />
            <token id="14" string="Rancho" />
            <token id="15" string="Mirage" />
            <token id="16" string="," />
          </tokens>
        </chunking>
        <chunking id="14" string="the first celebrity known to enter the Betty Ford clinic in Rancho Mirage" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="first" />
            <token id="5" string="celebrity" />
            <token id="6" string="known" />
            <token id="7" string="to" />
            <token id="8" string="enter" />
            <token id="9" string="the" />
            <token id="10" string="Betty" />
            <token id="11" string="Ford" />
            <token id="12" string="clinic" />
            <token id="13" string="in" />
            <token id="14" string="Rancho" />
            <token id="15" string="Mirage" />
          </tokens>
        </chunking>
        <chunking id="15" string="the first celebrity" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="first" />
            <token id="5" string="celebrity" />
          </tokens>
        </chunking>
        <chunking id="16" string="her addictions" type="NP">
          <tokens>
            <token id="27" string="her" />
            <token id="28" string="addictions" />
          </tokens>
        </chunking>
        <chunking id="17" string="to enter the Betty Ford clinic in Rancho Mirage" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="enter" />
            <token id="9" string="the" />
            <token id="10" string="Betty" />
            <token id="11" string="Ford" />
            <token id="12" string="clinic" />
            <token id="13" string="in" />
            <token id="14" string="Rancho" />
            <token id="15" string="Mirage" />
          </tokens>
        </chunking>
        <chunking id="18" string="made a public example of her willingness to take on her addictions in two heavily publicized stays there" type="VP">
          <tokens>
            <token id="17" string="made" />
            <token id="18" string="a" />
            <token id="19" string="public" />
            <token id="20" string="example" />
            <token id="21" string="of" />
            <token id="22" string="her" />
            <token id="23" string="willingness" />
            <token id="24" string="to" />
            <token id="25" string="take" />
            <token id="26" string="on" />
            <token id="27" string="her" />
            <token id="28" string="addictions" />
            <token id="29" string="in" />
            <token id="30" string="two" />
            <token id="31" string="heavily" />
            <token id="32" string="publicized" />
            <token id="33" string="stays" />
            <token id="34" string="there" />
          </tokens>
        </chunking>
        <chunking id="19" string="the Betty Ford clinic in Rancho Mirage" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="Betty" />
            <token id="11" string="Ford" />
            <token id="12" string="clinic" />
            <token id="13" string="in" />
            <token id="14" string="Rancho" />
            <token id="15" string="Mirage" />
          </tokens>
        </chunking>
        <chunking id="20" string="heavily publicized" type="ADJP">
          <tokens>
            <token id="31" string="heavily" />
            <token id="32" string="publicized" />
          </tokens>
        </chunking>
        <chunking id="21" string="her willingness to take on her addictions in two heavily publicized stays there" type="NP">
          <tokens>
            <token id="22" string="her" />
            <token id="23" string="willingness" />
            <token id="24" string="to" />
            <token id="25" string="take" />
            <token id="26" string="on" />
            <token id="27" string="her" />
            <token id="28" string="addictions" />
            <token id="29" string="in" />
            <token id="30" string="two" />
            <token id="31" string="heavily" />
            <token id="32" string="publicized" />
            <token id="33" string="stays" />
            <token id="34" string="there" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="17">made</governor>
          <dependent id="1">Taylor</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">celebrity</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">celebrity</governor>
          <dependent id="4">first</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="1">Taylor</governor>
          <dependent id="5">celebrity</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="5">celebrity</governor>
          <dependent id="6">known</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">enter</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">known</governor>
          <dependent id="8">enter</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">clinic</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">clinic</governor>
          <dependent id="10">Betty</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">clinic</governor>
          <dependent id="11">Ford</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">enter</governor>
          <dependent id="12">clinic</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">Mirage</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Mirage</governor>
          <dependent id="14">Rancho</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">clinic</governor>
          <dependent id="15">Mirage</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">made</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">example</governor>
          <dependent id="18">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">example</governor>
          <dependent id="19">public</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">made</governor>
          <dependent id="20">example</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">willingness</governor>
          <dependent id="21">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="23">willingness</governor>
          <dependent id="22">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">example</governor>
          <dependent id="23">willingness</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="25">take</governor>
          <dependent id="24">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="23">willingness</governor>
          <dependent id="25">take</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="25">take</governor>
          <dependent id="26">on</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="28">addictions</governor>
          <dependent id="27">her</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">take</governor>
          <dependent id="28">addictions</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">two</governor>
          <dependent id="29">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">take</governor>
          <dependent id="30">two</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="32">publicized</governor>
          <dependent id="31">heavily</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="33">stays</governor>
          <dependent id="32">publicized</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="30">two</governor>
          <dependent id="33">stays</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="33">stays</governor>
          <dependent id="34">there</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="4" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="Rancho Mirage" type="LOCATION" score="0.0">
          <tokens>
            <token id="14" string="Rancho" />
            <token id="15" string="Mirage" />
          </tokens>
        </entity>
        <entity id="3" string="Taylor" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Taylor" />
          </tokens>
        </entity>
        <entity id="4" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="30" string="two" />
          </tokens>
        </entity>
        <entity id="5" string="Betty Ford" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Betty" />
            <token id="11" string="Ford" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="60" has_coreference="true">
      <content>When Taylor first checked in, in 1983, she admitted to 35 years of addiction to pain killers and sleeping pills.</content>
      <tokens>
        <token id="1" string="When" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Taylor" lemma="Taylor" stem="taylor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="first" lemma="first" stem="first" pos="RB" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="4" string="checked" lemma="check" stem="check" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="1983" lemma="1983" stem="1983" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="admitted" lemma="admit" stem="admit" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="35" lemma="35" stem="35" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="14" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="addiction" lemma="addiction" stem="addict" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="pain" lemma="pain" stem="pain" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="killers" lemma="killer" stem="killer" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="sleeping" lemma="sleep" stem="sleep" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="pills" lemma="pill" stem="pill" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (WHADVP (WRB When)) (S (NP (NNP Taylor)) (ADVP (RB first)) (VP (VBD checked) (PP (IN in)) (, ,) (PP (IN in) (NP (CD 1983)))))) (, ,) (NP (PRP she)) (VP (VBD admitted) (PP (TO to) (NP (NP (CD 35) (NNS years)) (PP (IN of) (NP (NN addiction))))) (PP (TO to) (NP (NP (NN pain) (NNS killers)) (CC and) (NP (VBG sleeping) (NNS pills))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="sleeping pills" type="NP">
          <tokens>
            <token id="21" string="sleeping" />
            <token id="22" string="pills" />
          </tokens>
        </chunking>
        <chunking id="2" string="Taylor" type="NP">
          <tokens>
            <token id="2" string="Taylor" />
          </tokens>
        </chunking>
        <chunking id="3" string="pain killers" type="NP">
          <tokens>
            <token id="18" string="pain" />
            <token id="19" string="killers" />
          </tokens>
        </chunking>
        <chunking id="4" string="addiction" type="NP">
          <tokens>
            <token id="16" string="addiction" />
          </tokens>
        </chunking>
        <chunking id="5" string="pain killers and sleeping pills" type="NP">
          <tokens>
            <token id="18" string="pain" />
            <token id="19" string="killers" />
            <token id="20" string="and" />
            <token id="21" string="sleeping" />
            <token id="22" string="pills" />
          </tokens>
        </chunking>
        <chunking id="6" string="checked in , in 1983" type="VP">
          <tokens>
            <token id="4" string="checked" />
            <token id="5" string="in" />
            <token id="6" string="," />
            <token id="7" string="in" />
            <token id="8" string="1983" />
          </tokens>
        </chunking>
        <chunking id="7" string="she" type="NP">
          <tokens>
            <token id="10" string="she" />
          </tokens>
        </chunking>
        <chunking id="8" string="35 years" type="NP">
          <tokens>
            <token id="13" string="35" />
            <token id="14" string="years" />
          </tokens>
        </chunking>
        <chunking id="9" string="When" type="WHADVP">
          <tokens>
            <token id="1" string="When" />
          </tokens>
        </chunking>
        <chunking id="10" string="When Taylor first checked in , in 1983" type="SBAR">
          <tokens>
            <token id="1" string="When" />
            <token id="2" string="Taylor" />
            <token id="3" string="first" />
            <token id="4" string="checked" />
            <token id="5" string="in" />
            <token id="6" string="," />
            <token id="7" string="in" />
            <token id="8" string="1983" />
          </tokens>
        </chunking>
        <chunking id="11" string="admitted to 35 years of addiction to pain killers and sleeping pills" type="VP">
          <tokens>
            <token id="11" string="admitted" />
            <token id="12" string="to" />
            <token id="13" string="35" />
            <token id="14" string="years" />
            <token id="15" string="of" />
            <token id="16" string="addiction" />
            <token id="17" string="to" />
            <token id="18" string="pain" />
            <token id="19" string="killers" />
            <token id="20" string="and" />
            <token id="21" string="sleeping" />
            <token id="22" string="pills" />
          </tokens>
        </chunking>
        <chunking id="12" string="1983" type="NP">
          <tokens>
            <token id="8" string="1983" />
          </tokens>
        </chunking>
        <chunking id="13" string="35 years of addiction" type="NP">
          <tokens>
            <token id="13" string="35" />
            <token id="14" string="years" />
            <token id="15" string="of" />
            <token id="16" string="addiction" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="4">checked</governor>
          <dependent id="1">When</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">checked</governor>
          <dependent id="2">Taylor</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">checked</governor>
          <dependent id="3">first</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">admitted</governor>
          <dependent id="4">checked</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">checked</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">1983</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">checked</governor>
          <dependent id="8">1983</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">admitted</governor>
          <dependent id="10">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">admitted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">years</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="14">years</governor>
          <dependent id="13">35</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">admitted</governor>
          <dependent id="14">years</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">addiction</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">years</governor>
          <dependent id="16">addiction</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">killers</governor>
          <dependent id="17">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">killers</governor>
          <dependent id="18">pain</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">admitted</governor>
          <dependent id="19">killers</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="19">killers</governor>
          <dependent id="20">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">pills</governor>
          <dependent id="21">sleeping</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">killers</governor>
          <dependent id="22">pills</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="3" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="Taylor" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Taylor" />
          </tokens>
        </entity>
        <entity id="3" string="1983" type="DATE" score="0.0">
          <tokens>
            <token id="8" string="1983" />
          </tokens>
        </entity>
        <entity id="4" string="35 years" type="DURATION" score="0.0">
          <tokens>
            <token id="13" string="35" />
            <token id="14" string="years" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="61" has_coreference="true">
      <content>She kept a diary that poignantly described that stay as &amp;quot;probably the first time since I was 9 that nobody&amp;apost;s wanted to exploit me.</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="kept" lemma="keep" stem="kept" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="diary" lemma="diary" stem="diari" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="poignantly" lemma="poignantly" stem="poignantli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="described" lemma="describe" stem="describ" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="stay" lemma="stay" stem="stai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="probably" lemma="probably" stem="probabl" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="true" />
        <token id="15" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="9" lemma="9" stem="9" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="20" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="nobody" lemma="nobody" stem="nobodi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="wanted" lemma="want" stem="want" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="exploit" lemma="exploit" stem="exploit" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP She)) (VP (VBD kept) (NP (NP (DT a) (NN diary)) (SBAR (WHNP (WDT that)) (S (ADVP (RB poignantly)) (VP (VBD described) (SBAR (IN that) (S (NP (NP (NN stay)) (PP (IN as) (`` ``) (NP (NP (RB probably) (DT the) (JJ first) (NN time)) (SBAR (IN since) (S (NP (PRP I)) (VP (VBD was) (ADJP (CD 9) (PP (IN that) (NP (NN nobody) (POS 's)))))))))) (VP (VBD wanted) (S (VP (TO to) (VP (VB exploit) (NP (PRP me))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="wanted to exploit me" type="VP">
          <tokens>
            <token id="23" string="wanted" />
            <token id="24" string="to" />
            <token id="25" string="exploit" />
            <token id="26" string="me" />
          </tokens>
        </chunking>
        <chunking id="2" string="kept a diary that poignantly described that stay as `` probably the first time since I was 9 that nobody 's wanted to exploit me" type="VP">
          <tokens>
            <token id="2" string="kept" />
            <token id="3" string="a" />
            <token id="4" string="diary" />
            <token id="5" string="that" />
            <token id="6" string="poignantly" />
            <token id="7" string="described" />
            <token id="8" string="that" />
            <token id="9" string="stay" />
            <token id="10" string="as" />
            <token id="11" string="&quot;" />
            <token id="12" string="probably" />
            <token id="13" string="the" />
            <token id="14" string="first" />
            <token id="15" string="time" />
            <token id="16" string="since" />
            <token id="17" string="I" />
            <token id="18" string="was" />
            <token id="19" string="9" />
            <token id="20" string="that" />
            <token id="21" string="nobody" />
            <token id="22" string="'s" />
            <token id="23" string="wanted" />
            <token id="24" string="to" />
            <token id="25" string="exploit" />
            <token id="26" string="me" />
          </tokens>
        </chunking>
        <chunking id="3" string="to exploit me" type="VP">
          <tokens>
            <token id="24" string="to" />
            <token id="25" string="exploit" />
            <token id="26" string="me" />
          </tokens>
        </chunking>
        <chunking id="4" string="a diary that poignantly described that stay as `` probably the first time since I was 9 that nobody 's wanted to exploit me" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="diary" />
            <token id="5" string="that" />
            <token id="6" string="poignantly" />
            <token id="7" string="described" />
            <token id="8" string="that" />
            <token id="9" string="stay" />
            <token id="10" string="as" />
            <token id="11" string="&quot;" />
            <token id="12" string="probably" />
            <token id="13" string="the" />
            <token id="14" string="first" />
            <token id="15" string="time" />
            <token id="16" string="since" />
            <token id="17" string="I" />
            <token id="18" string="was" />
            <token id="19" string="9" />
            <token id="20" string="that" />
            <token id="21" string="nobody" />
            <token id="22" string="'s" />
            <token id="23" string="wanted" />
            <token id="24" string="to" />
            <token id="25" string="exploit" />
            <token id="26" string="me" />
          </tokens>
        </chunking>
        <chunking id="5" string="nobody 's" type="NP">
          <tokens>
            <token id="21" string="nobody" />
            <token id="22" string="'s" />
          </tokens>
        </chunking>
        <chunking id="6" string="probably the first time since I was 9 that nobody 's" type="NP">
          <tokens>
            <token id="12" string="probably" />
            <token id="13" string="the" />
            <token id="14" string="first" />
            <token id="15" string="time" />
            <token id="16" string="since" />
            <token id="17" string="I" />
            <token id="18" string="was" />
            <token id="19" string="9" />
            <token id="20" string="that" />
            <token id="21" string="nobody" />
            <token id="22" string="'s" />
          </tokens>
        </chunking>
        <chunking id="7" string="I" type="NP">
          <tokens>
            <token id="17" string="I" />
          </tokens>
        </chunking>
        <chunking id="8" string="a diary" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="diary" />
          </tokens>
        </chunking>
        <chunking id="9" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
        <chunking id="10" string="stay" type="NP">
          <tokens>
            <token id="9" string="stay" />
          </tokens>
        </chunking>
        <chunking id="11" string="described that stay as `` probably the first time since I was 9 that nobody 's wanted to exploit me" type="VP">
          <tokens>
            <token id="7" string="described" />
            <token id="8" string="that" />
            <token id="9" string="stay" />
            <token id="10" string="as" />
            <token id="11" string="&quot;" />
            <token id="12" string="probably" />
            <token id="13" string="the" />
            <token id="14" string="first" />
            <token id="15" string="time" />
            <token id="16" string="since" />
            <token id="17" string="I" />
            <token id="18" string="was" />
            <token id="19" string="9" />
            <token id="20" string="that" />
            <token id="21" string="nobody" />
            <token id="22" string="'s" />
            <token id="23" string="wanted" />
            <token id="24" string="to" />
            <token id="25" string="exploit" />
            <token id="26" string="me" />
          </tokens>
        </chunking>
        <chunking id="12" string="since I was 9 that nobody 's" type="SBAR">
          <tokens>
            <token id="16" string="since" />
            <token id="17" string="I" />
            <token id="18" string="was" />
            <token id="19" string="9" />
            <token id="20" string="that" />
            <token id="21" string="nobody" />
            <token id="22" string="'s" />
          </tokens>
        </chunking>
        <chunking id="13" string="that stay as `` probably the first time since I was 9 that nobody 's wanted to exploit me" type="SBAR">
          <tokens>
            <token id="8" string="that" />
            <token id="9" string="stay" />
            <token id="10" string="as" />
            <token id="11" string="&quot;" />
            <token id="12" string="probably" />
            <token id="13" string="the" />
            <token id="14" string="first" />
            <token id="15" string="time" />
            <token id="16" string="since" />
            <token id="17" string="I" />
            <token id="18" string="was" />
            <token id="19" string="9" />
            <token id="20" string="that" />
            <token id="21" string="nobody" />
            <token id="22" string="'s" />
            <token id="23" string="wanted" />
            <token id="24" string="to" />
            <token id="25" string="exploit" />
            <token id="26" string="me" />
          </tokens>
        </chunking>
        <chunking id="14" string="was 9 that nobody 's" type="VP">
          <tokens>
            <token id="18" string="was" />
            <token id="19" string="9" />
            <token id="20" string="that" />
            <token id="21" string="nobody" />
            <token id="22" string="'s" />
          </tokens>
        </chunking>
        <chunking id="15" string="stay as `` probably the first time since I was 9 that nobody 's" type="NP">
          <tokens>
            <token id="9" string="stay" />
            <token id="10" string="as" />
            <token id="11" string="&quot;" />
            <token id="12" string="probably" />
            <token id="13" string="the" />
            <token id="14" string="first" />
            <token id="15" string="time" />
            <token id="16" string="since" />
            <token id="17" string="I" />
            <token id="18" string="was" />
            <token id="19" string="9" />
            <token id="20" string="that" />
            <token id="21" string="nobody" />
            <token id="22" string="'s" />
          </tokens>
        </chunking>
        <chunking id="16" string="that poignantly described that stay as `` probably the first time since I was 9 that nobody 's wanted to exploit me" type="SBAR">
          <tokens>
            <token id="5" string="that" />
            <token id="6" string="poignantly" />
            <token id="7" string="described" />
            <token id="8" string="that" />
            <token id="9" string="stay" />
            <token id="10" string="as" />
            <token id="11" string="&quot;" />
            <token id="12" string="probably" />
            <token id="13" string="the" />
            <token id="14" string="first" />
            <token id="15" string="time" />
            <token id="16" string="since" />
            <token id="17" string="I" />
            <token id="18" string="was" />
            <token id="19" string="9" />
            <token id="20" string="that" />
            <token id="21" string="nobody" />
            <token id="22" string="'s" />
            <token id="23" string="wanted" />
            <token id="24" string="to" />
            <token id="25" string="exploit" />
            <token id="26" string="me" />
          </tokens>
        </chunking>
        <chunking id="17" string="exploit me" type="VP">
          <tokens>
            <token id="25" string="exploit" />
            <token id="26" string="me" />
          </tokens>
        </chunking>
        <chunking id="18" string="me" type="NP">
          <tokens>
            <token id="26" string="me" />
          </tokens>
        </chunking>
        <chunking id="19" string="probably the first time" type="NP">
          <tokens>
            <token id="12" string="probably" />
            <token id="13" string="the" />
            <token id="14" string="first" />
            <token id="15" string="time" />
          </tokens>
        </chunking>
        <chunking id="20" string="9 that nobody 's" type="ADJP">
          <tokens>
            <token id="19" string="9" />
            <token id="20" string="that" />
            <token id="21" string="nobody" />
            <token id="22" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">kept</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">kept</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">diary</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">kept</governor>
          <dependent id="4">diary</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">described</governor>
          <dependent id="5">that</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">described</governor>
          <dependent id="6">poignantly</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="4">diary</governor>
          <dependent id="7">described</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">wanted</governor>
          <dependent id="8">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">wanted</governor>
          <dependent id="9">stay</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">time</governor>
          <dependent id="10">as</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">time</governor>
          <dependent id="12">probably</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">time</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">time</governor>
          <dependent id="14">first</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">stay</governor>
          <dependent id="15">time</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">9</governor>
          <dependent id="16">since</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">9</governor>
          <dependent id="17">I</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="19">9</governor>
          <dependent id="18">was</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="15">time</governor>
          <dependent id="19">9</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">nobody</governor>
          <dependent id="20">that</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">9</governor>
          <dependent id="21">nobody</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">nobody</governor>
          <dependent id="22">'s</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">described</governor>
          <dependent id="23">wanted</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="25">exploit</governor>
          <dependent id="24">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="23">wanted</governor>
          <dependent id="25">exploit</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">exploit</governor>
          <dependent id="26">me</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="14" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="9" type="NUMBER" score="0.0">
          <tokens>
            <token id="19" string="9" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="62" has_coreference="false">
      <content>Now the bad news.</content>
      <tokens>
        <token id="1" string="Now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="bad" lemma="bad" stem="bad" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="news" lemma="news" stem="new" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (FRAG (ADVP (RB Now)) (NP (DT the) (JJ bad) (NN news)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the bad news" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="bad" />
            <token id="4" string="news" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="dep">
          <governor id="4">news</governor>
          <dependent id="1">Now</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">news</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">news</governor>
          <dependent id="3">bad</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">news</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Now" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="Now" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="63" has_coreference="true">
      <content>I feel like hell.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="feel" lemma="feel" stem="feel" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="hell" lemma="hell" stem="hell" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBP feel) (PP (IN like) (NP (NN hell)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="2" string="feel like hell" type="VP">
          <tokens>
            <token id="2" string="feel" />
            <token id="3" string="like" />
            <token id="4" string="hell" />
          </tokens>
        </chunking>
        <chunking id="3" string="hell" type="NP">
          <tokens>
            <token id="4" string="hell" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">feel</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">feel</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">hell</governor>
          <dependent id="3">like</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">feel</governor>
          <dependent id="4">hell</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="64" has_coreference="true">
      <content>I&amp;apost;m going through withdrawal.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="'m" lemma="be" stem="'m" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="withdrawal" lemma="withdrawal" stem="withdraw" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBP 'm) (VP (VBG going) (PP (IN through) (NP (NN withdrawal))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="going through withdrawal" type="VP">
          <tokens>
            <token id="3" string="going" />
            <token id="4" string="through" />
            <token id="5" string="withdrawal" />
          </tokens>
        </chunking>
        <chunking id="2" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="3" string="withdrawal" type="NP">
          <tokens>
            <token id="5" string="withdrawal" />
          </tokens>
        </chunking>
        <chunking id="4" string="'m going through withdrawal" type="VP">
          <tokens>
            <token id="2" string="'m" />
            <token id="3" string="going" />
            <token id="4" string="through" />
            <token id="5" string="withdrawal" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">going</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">going</governor>
          <dependent id="2">'m</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">going</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">withdrawal</governor>
          <dependent id="4">through</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">going</governor>
          <dependent id="5">withdrawal</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="65" has_coreference="true">
      <content>My heart feels big and pounding.</content>
      <tokens>
        <token id="1" string="My" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="heart" lemma="heart" stem="heart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="feels" lemma="feel" stem="feel" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="big" lemma="big" stem="big" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="pounding" lemma="pound" stem="pound" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP$ My) (NN heart)) (VP (VBZ feels) (NP (NP (JJ big)) (CC and) (NP (VBG pounding)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="My heart" type="NP">
          <tokens>
            <token id="1" string="My" />
            <token id="2" string="heart" />
          </tokens>
        </chunking>
        <chunking id="2" string="feels big and pounding" type="VP">
          <tokens>
            <token id="3" string="feels" />
            <token id="4" string="big" />
            <token id="5" string="and" />
            <token id="6" string="pounding" />
          </tokens>
        </chunking>
        <chunking id="3" string="big and pounding" type="NP">
          <tokens>
            <token id="4" string="big" />
            <token id="5" string="and" />
            <token id="6" string="pounding" />
          </tokens>
        </chunking>
        <chunking id="4" string="big" type="NP">
          <tokens>
            <token id="4" string="big" />
          </tokens>
        </chunking>
        <chunking id="5" string="pounding" type="NP">
          <tokens>
            <token id="6" string="pounding" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="2">heart</governor>
          <dependent id="1">My</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">feels</governor>
          <dependent id="2">heart</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">feels</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">feels</governor>
          <dependent id="4">big</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">big</governor>
          <dependent id="5">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">big</governor>
          <dependent id="6">pounding</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="66" has_coreference="true">
      <content>I can feel the blood rush through my body.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="feel" lemma="feel" stem="feel" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="blood" lemma="blood" stem="blood" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="rush" lemma="rush" stem="rush" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="body" lemma="body" stem="bodi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (MD can) (VP (VB feel) (NP (DT the) (NN blood) (NN rush)) (PP (IN through) (NP (PRP$ my) (NN body))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="can feel the blood rush through my body" type="VP">
          <tokens>
            <token id="2" string="can" />
            <token id="3" string="feel" />
            <token id="4" string="the" />
            <token id="5" string="blood" />
            <token id="6" string="rush" />
            <token id="7" string="through" />
            <token id="8" string="my" />
            <token id="9" string="body" />
          </tokens>
        </chunking>
        <chunking id="2" string="feel the blood rush through my body" type="VP">
          <tokens>
            <token id="3" string="feel" />
            <token id="4" string="the" />
            <token id="5" string="blood" />
            <token id="6" string="rush" />
            <token id="7" string="through" />
            <token id="8" string="my" />
            <token id="9" string="body" />
          </tokens>
        </chunking>
        <chunking id="3" string="my body" type="NP">
          <tokens>
            <token id="8" string="my" />
            <token id="9" string="body" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="the blood rush" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="blood" />
            <token id="6" string="rush" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">feel</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">feel</governor>
          <dependent id="2">can</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">feel</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">rush</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">rush</governor>
          <dependent id="5">blood</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">feel</governor>
          <dependent id="6">rush</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">body</governor>
          <dependent id="7">through</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">body</governor>
          <dependent id="8">my</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">feel</governor>
          <dependent id="9">body</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="67" has_coreference="true">
      <content>I can almost see it, running like red water over the boulders in my pain-filled neck and shoulders, then through my ears and into my pounding head.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="almost" lemma="almost" stem="almost" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="see" lemma="see" stem="see" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="running" lemma="run" stem="run" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="red" lemma="red" stem="red" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="water" lemma="water" stem="water" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="boulders" lemma="boulder" stem="boulder" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="pain-filled" lemma="pain-filled" stem="pain-fil" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="neck" lemma="neck" stem="neck" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="shoulders" lemma="shoulder" stem="shoulder" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="ears" lemma="ear" stem="ear" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="28" string="pounding" lemma="pound" stem="pound" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="head" lemma="head" stem="head" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (MD can) (ADVP (RB almost)) (VP (VB see) (NP (PRP it)) (, ,) (S (VP (VBG running) (PP (IN like) (NP (NP (JJ red) (NN water)) (PP (IN over) (NP (DT the) (NNS boulders))))) (PP (IN in) (NP (NP (PRP$ my) (JJ pain-filled) (NN neck)) (CC and) (NP (NNS shoulders))) (, ,) (ADVP (RB then))) (PP (PP (IN through) (NP (PRP$ my) (NNS ears))) (CC and) (PP (IN into) (NP (PRP$ my) (VBG pounding) (NN head)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="shoulders" type="NP">
          <tokens>
            <token id="19" string="shoulders" />
          </tokens>
        </chunking>
        <chunking id="2" string="my pain-filled neck" type="NP">
          <tokens>
            <token id="15" string="my" />
            <token id="16" string="pain-filled" />
            <token id="17" string="neck" />
          </tokens>
        </chunking>
        <chunking id="3" string="my ears" type="NP">
          <tokens>
            <token id="23" string="my" />
            <token id="24" string="ears" />
          </tokens>
        </chunking>
        <chunking id="4" string="running like red water over the boulders in my pain-filled neck and shoulders , then through my ears and into my pounding head" type="VP">
          <tokens>
            <token id="7" string="running" />
            <token id="8" string="like" />
            <token id="9" string="red" />
            <token id="10" string="water" />
            <token id="11" string="over" />
            <token id="12" string="the" />
            <token id="13" string="boulders" />
            <token id="14" string="in" />
            <token id="15" string="my" />
            <token id="16" string="pain-filled" />
            <token id="17" string="neck" />
            <token id="18" string="and" />
            <token id="19" string="shoulders" />
            <token id="20" string="," />
            <token id="21" string="then" />
            <token id="22" string="through" />
            <token id="23" string="my" />
            <token id="24" string="ears" />
            <token id="25" string="and" />
            <token id="26" string="into" />
            <token id="27" string="my" />
            <token id="28" string="pounding" />
            <token id="29" string="head" />
          </tokens>
        </chunking>
        <chunking id="5" string="my pounding head" type="NP">
          <tokens>
            <token id="27" string="my" />
            <token id="28" string="pounding" />
            <token id="29" string="head" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="my pain-filled neck and shoulders" type="NP">
          <tokens>
            <token id="15" string="my" />
            <token id="16" string="pain-filled" />
            <token id="17" string="neck" />
            <token id="18" string="and" />
            <token id="19" string="shoulders" />
          </tokens>
        </chunking>
        <chunking id="8" string="the boulders" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="boulders" />
          </tokens>
        </chunking>
        <chunking id="9" string="it" type="NP">
          <tokens>
            <token id="5" string="it" />
          </tokens>
        </chunking>
        <chunking id="10" string="see it , running like red water over the boulders in my pain-filled neck and shoulders , then through my ears and into my pounding head" type="VP">
          <tokens>
            <token id="4" string="see" />
            <token id="5" string="it" />
            <token id="6" string="," />
            <token id="7" string="running" />
            <token id="8" string="like" />
            <token id="9" string="red" />
            <token id="10" string="water" />
            <token id="11" string="over" />
            <token id="12" string="the" />
            <token id="13" string="boulders" />
            <token id="14" string="in" />
            <token id="15" string="my" />
            <token id="16" string="pain-filled" />
            <token id="17" string="neck" />
            <token id="18" string="and" />
            <token id="19" string="shoulders" />
            <token id="20" string="," />
            <token id="21" string="then" />
            <token id="22" string="through" />
            <token id="23" string="my" />
            <token id="24" string="ears" />
            <token id="25" string="and" />
            <token id="26" string="into" />
            <token id="27" string="my" />
            <token id="28" string="pounding" />
            <token id="29" string="head" />
          </tokens>
        </chunking>
        <chunking id="11" string="can almost see it , running like red water over the boulders in my pain-filled neck and shoulders , then through my ears and into my pounding head" type="VP">
          <tokens>
            <token id="2" string="can" />
            <token id="3" string="almost" />
            <token id="4" string="see" />
            <token id="5" string="it" />
            <token id="6" string="," />
            <token id="7" string="running" />
            <token id="8" string="like" />
            <token id="9" string="red" />
            <token id="10" string="water" />
            <token id="11" string="over" />
            <token id="12" string="the" />
            <token id="13" string="boulders" />
            <token id="14" string="in" />
            <token id="15" string="my" />
            <token id="16" string="pain-filled" />
            <token id="17" string="neck" />
            <token id="18" string="and" />
            <token id="19" string="shoulders" />
            <token id="20" string="," />
            <token id="21" string="then" />
            <token id="22" string="through" />
            <token id="23" string="my" />
            <token id="24" string="ears" />
            <token id="25" string="and" />
            <token id="26" string="into" />
            <token id="27" string="my" />
            <token id="28" string="pounding" />
            <token id="29" string="head" />
          </tokens>
        </chunking>
        <chunking id="12" string="red water" type="NP">
          <tokens>
            <token id="9" string="red" />
            <token id="10" string="water" />
          </tokens>
        </chunking>
        <chunking id="13" string="red water over the boulders" type="NP">
          <tokens>
            <token id="9" string="red" />
            <token id="10" string="water" />
            <token id="11" string="over" />
            <token id="12" string="the" />
            <token id="13" string="boulders" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">see</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">see</governor>
          <dependent id="2">can</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">see</governor>
          <dependent id="3">almost</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">see</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">see</governor>
          <dependent id="5">it</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">see</governor>
          <dependent id="7">running</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">running</governor>
          <dependent id="7">running</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">water</governor>
          <dependent id="8">like</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">water</governor>
          <dependent id="9">red</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">running</governor>
          <dependent id="10">water</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">boulders</governor>
          <dependent id="11">over</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">boulders</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">water</governor>
          <dependent id="13">boulders</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">neck</governor>
          <dependent id="14">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="17">neck</governor>
          <dependent id="15">my</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">neck</governor>
          <dependent id="16">pain-filled</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">running</governor>
          <dependent id="17">neck</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">neck</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">neck</governor>
          <dependent id="19">shoulders</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">neck</governor>
          <dependent id="21">then</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">ears</governor>
          <dependent id="22">through</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="24">ears</governor>
          <dependent id="23">my</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">running</governor>
          <dependent id="24">ears</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">running</governor>
          <dependent id="25">and</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">head</governor>
          <dependent id="26">into</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="29">head</governor>
          <dependent id="27">my</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">head</governor>
          <dependent id="28">pounding</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">running</governor>
          <dependent id="29">head</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="68" has_coreference="true">
      <content>My eyelids flutter.</content>
      <tokens>
        <token id="1" string="My" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="eyelids" lemma="eyelid" stem="eyelid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="flutter" lemma="flutter" stem="flutter" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP$ My) (NNS eyelids)) (VP (VB flutter)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="flutter" type="VP">
          <tokens>
            <token id="3" string="flutter" />
          </tokens>
        </chunking>
        <chunking id="2" string="My eyelids" type="NP">
          <tokens>
            <token id="1" string="My" />
            <token id="2" string="eyelids" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="2">eyelids</governor>
          <dependent id="1">My</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">flutter</governor>
          <dependent id="2">eyelids</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">flutter</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="69" has_coreference="true">
      <content>Oh God, I am so, so tired.&amp;quot;</content>
      <tokens>
        <token id="1" string="Oh" lemma="oh" stem="oh" pos="UH" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="God" lemma="God" stem="god" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="am" lemma="be" stem="am" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="tired" lemma="tired" stem="tire" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (INTJ (UH Oh)) (NP (NNP God) (, ,)) (VP (ADVP (PRP I)) (VP (VBP am)))) (RB so) (, ,) (S (ADJP (RB so) (JJ tired))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="I am" type="VP">
          <tokens>
            <token id="4" string="I" />
            <token id="5" string="am" />
          </tokens>
        </chunking>
        <chunking id="2" string="God ," type="NP">
          <tokens>
            <token id="2" string="God" />
            <token id="3" string="," />
          </tokens>
        </chunking>
        <chunking id="3" string="am" type="VP">
          <tokens>
            <token id="5" string="am" />
          </tokens>
        </chunking>
        <chunking id="4" string="so tired" type="ADJP">
          <tokens>
            <token id="8" string="so" />
            <token id="9" string="tired" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="discourse">
          <governor id="5">am</governor>
          <dependent id="1">Oh</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">am</governor>
          <dependent id="2">God</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">am</governor>
          <dependent id="4">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">am</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">am</governor>
          <dependent id="6">so</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">tired</governor>
          <dependent id="8">so</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="5">am</governor>
          <dependent id="9">tired</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="70" has_coreference="true">
      <content>But the Betty Ford clinic encouraged Taylor only to fight the good fights that had brought her there, rather than take on all addictions -- to drugs and food -- at once.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="Betty" lemma="Betty" stem="betti" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="Ford" lemma="Ford" stem="ford" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="5" string="clinic" lemma="clinic" stem="clinic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="encouraged" lemma="encourage" stem="encourag" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="Taylor" lemma="Taylor" stem="taylor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="8" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="fight" lemma="fight" stem="fight" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="good" lemma="good" stem="good" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="fights" lemma="fight" stem="fight" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="brought" lemma="bring" stem="brought" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="rather" lemma="rather" stem="rather" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="take" lemma="take" stem="take" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="on" lemma="on" stem="on" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="addictions" lemma="addiction" stem="addict" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="drugs" lemma="drug" stem="drug" pos="NNS" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="29" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="food" lemma="food" stem="food" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="once" lemma="once" stem="onc" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="34" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (DT the) (NNP Betty) (NNP Ford) (NN clinic)) (VP (VBD encouraged) (S (NP (NNP Taylor)) (ADVP (RB only)) (VP (TO to) (VP (VP (VB fight) (NP (NP (DT the) (JJ good) (NNS fights)) (SBAR (WHNP (WDT that)) (S (VP (VBD had) (VP (VBN brought) (S (NP (PRP$ her)) (NP (EX there))))))))) (, ,) (CONJP (RB rather) (IN than)) (VP (VB take) (PRT (RP on)) (NP (NP (NP (DT all) (NNS addictions)) (PRN (: --) (PP (TO to) (NP (NNS drugs) (CC and) (NN food))) (: --))) (PP (IN at) (NP (RB once))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the Betty Ford clinic" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="Betty" />
            <token id="4" string="Ford" />
            <token id="5" string="clinic" />
          </tokens>
        </chunking>
        <chunking id="2" string="that had brought her there" type="SBAR">
          <tokens>
            <token id="14" string="that" />
            <token id="15" string="had" />
            <token id="16" string="brought" />
            <token id="17" string="her" />
            <token id="18" string="there" />
          </tokens>
        </chunking>
        <chunking id="3" string="the good fights" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="good" />
            <token id="13" string="fights" />
          </tokens>
        </chunking>
        <chunking id="4" string="drugs and food" type="NP">
          <tokens>
            <token id="28" string="drugs" />
            <token id="29" string="and" />
            <token id="30" string="food" />
          </tokens>
        </chunking>
        <chunking id="5" string="to fight the good fights that had brought her there , rather than take on all addictions -- to drugs and food -- at once" type="VP">
          <tokens>
            <token id="9" string="to" />
            <token id="10" string="fight" />
            <token id="11" string="the" />
            <token id="12" string="good" />
            <token id="13" string="fights" />
            <token id="14" string="that" />
            <token id="15" string="had" />
            <token id="16" string="brought" />
            <token id="17" string="her" />
            <token id="18" string="there" />
            <token id="19" string="," />
            <token id="20" string="rather" />
            <token id="21" string="than" />
            <token id="22" string="take" />
            <token id="23" string="on" />
            <token id="24" string="all" />
            <token id="25" string="addictions" />
            <token id="26" string="--" />
            <token id="27" string="to" />
            <token id="28" string="drugs" />
            <token id="29" string="and" />
            <token id="30" string="food" />
            <token id="31" string="--" />
            <token id="32" string="at" />
            <token id="33" string="once" />
          </tokens>
        </chunking>
        <chunking id="6" string="Taylor" type="NP">
          <tokens>
            <token id="7" string="Taylor" />
          </tokens>
        </chunking>
        <chunking id="7" string="had brought her there" type="VP">
          <tokens>
            <token id="15" string="had" />
            <token id="16" string="brought" />
            <token id="17" string="her" />
            <token id="18" string="there" />
          </tokens>
        </chunking>
        <chunking id="8" string="all addictions -- to drugs and food -- at once" type="NP">
          <tokens>
            <token id="24" string="all" />
            <token id="25" string="addictions" />
            <token id="26" string="--" />
            <token id="27" string="to" />
            <token id="28" string="drugs" />
            <token id="29" string="and" />
            <token id="30" string="food" />
            <token id="31" string="--" />
            <token id="32" string="at" />
            <token id="33" string="once" />
          </tokens>
        </chunking>
        <chunking id="9" string="fight the good fights that had brought her there" type="VP">
          <tokens>
            <token id="10" string="fight" />
            <token id="11" string="the" />
            <token id="12" string="good" />
            <token id="13" string="fights" />
            <token id="14" string="that" />
            <token id="15" string="had" />
            <token id="16" string="brought" />
            <token id="17" string="her" />
            <token id="18" string="there" />
          </tokens>
        </chunking>
        <chunking id="10" string="the good fights that had brought her there" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="good" />
            <token id="13" string="fights" />
            <token id="14" string="that" />
            <token id="15" string="had" />
            <token id="16" string="brought" />
            <token id="17" string="her" />
            <token id="18" string="there" />
          </tokens>
        </chunking>
        <chunking id="11" string="take on all addictions -- to drugs and food -- at once" type="VP">
          <tokens>
            <token id="22" string="take" />
            <token id="23" string="on" />
            <token id="24" string="all" />
            <token id="25" string="addictions" />
            <token id="26" string="--" />
            <token id="27" string="to" />
            <token id="28" string="drugs" />
            <token id="29" string="and" />
            <token id="30" string="food" />
            <token id="31" string="--" />
            <token id="32" string="at" />
            <token id="33" string="once" />
          </tokens>
        </chunking>
        <chunking id="12" string="all addictions" type="NP">
          <tokens>
            <token id="24" string="all" />
            <token id="25" string="addictions" />
          </tokens>
        </chunking>
        <chunking id="13" string="fight the good fights that had brought her there , rather than take on all addictions -- to drugs and food -- at once" type="VP">
          <tokens>
            <token id="10" string="fight" />
            <token id="11" string="the" />
            <token id="12" string="good" />
            <token id="13" string="fights" />
            <token id="14" string="that" />
            <token id="15" string="had" />
            <token id="16" string="brought" />
            <token id="17" string="her" />
            <token id="18" string="there" />
            <token id="19" string="," />
            <token id="20" string="rather" />
            <token id="21" string="than" />
            <token id="22" string="take" />
            <token id="23" string="on" />
            <token id="24" string="all" />
            <token id="25" string="addictions" />
            <token id="26" string="--" />
            <token id="27" string="to" />
            <token id="28" string="drugs" />
            <token id="29" string="and" />
            <token id="30" string="food" />
            <token id="31" string="--" />
            <token id="32" string="at" />
            <token id="33" string="once" />
          </tokens>
        </chunking>
        <chunking id="14" string="encouraged Taylor only to fight the good fights that had brought her there , rather than take on all addictions -- to drugs and food -- at once" type="VP">
          <tokens>
            <token id="6" string="encouraged" />
            <token id="7" string="Taylor" />
            <token id="8" string="only" />
            <token id="9" string="to" />
            <token id="10" string="fight" />
            <token id="11" string="the" />
            <token id="12" string="good" />
            <token id="13" string="fights" />
            <token id="14" string="that" />
            <token id="15" string="had" />
            <token id="16" string="brought" />
            <token id="17" string="her" />
            <token id="18" string="there" />
            <token id="19" string="," />
            <token id="20" string="rather" />
            <token id="21" string="than" />
            <token id="22" string="take" />
            <token id="23" string="on" />
            <token id="24" string="all" />
            <token id="25" string="addictions" />
            <token id="26" string="--" />
            <token id="27" string="to" />
            <token id="28" string="drugs" />
            <token id="29" string="and" />
            <token id="30" string="food" />
            <token id="31" string="--" />
            <token id="32" string="at" />
            <token id="33" string="once" />
          </tokens>
        </chunking>
        <chunking id="15" string="there" type="NP">
          <tokens>
            <token id="18" string="there" />
          </tokens>
        </chunking>
        <chunking id="16" string="brought her there" type="VP">
          <tokens>
            <token id="16" string="brought" />
            <token id="17" string="her" />
            <token id="18" string="there" />
          </tokens>
        </chunking>
        <chunking id="17" string="once" type="NP">
          <tokens>
            <token id="33" string="once" />
          </tokens>
        </chunking>
        <chunking id="18" string="her" type="NP">
          <tokens>
            <token id="17" string="her" />
          </tokens>
        </chunking>
        <chunking id="19" string="all addictions -- to drugs and food --" type="NP">
          <tokens>
            <token id="24" string="all" />
            <token id="25" string="addictions" />
            <token id="26" string="--" />
            <token id="27" string="to" />
            <token id="28" string="drugs" />
            <token id="29" string="and" />
            <token id="30" string="food" />
            <token id="31" string="--" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="6">encouraged</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">clinic</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">clinic</governor>
          <dependent id="3">Betty</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">clinic</governor>
          <dependent id="4">Ford</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">encouraged</governor>
          <dependent id="5">clinic</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">encouraged</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">encouraged</governor>
          <dependent id="7">Taylor</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">fight</governor>
          <dependent id="8">only</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">fight</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">encouraged</governor>
          <dependent id="10">fight</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">fights</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">fights</governor>
          <dependent id="12">good</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">fight</governor>
          <dependent id="13">fights</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">brought</governor>
          <dependent id="14">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">brought</governor>
          <dependent id="15">had</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="13">fights</governor>
          <dependent id="16">brought</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">there</governor>
          <dependent id="17">her</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="16">brought</governor>
          <dependent id="18">there</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">fight</governor>
          <dependent id="20">rather</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="20">rather</governor>
          <dependent id="21">than</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">fight</governor>
          <dependent id="22">take</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="22">take</governor>
          <dependent id="23">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">addictions</governor>
          <dependent id="24">all</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">take</governor>
          <dependent id="25">addictions</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">drugs</governor>
          <dependent id="27">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">addictions</governor>
          <dependent id="28">drugs</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="28">drugs</governor>
          <dependent id="29">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="28">drugs</governor>
          <dependent id="30">food</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">once</governor>
          <dependent id="32">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">addictions</governor>
          <dependent id="33">once</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Taylor" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Taylor" />
          </tokens>
        </entity>
        <entity id="2" string="drugs" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="28" string="drugs" />
          </tokens>
        </entity>
        <entity id="3" string="once" type="DATE" score="0.0">
          <tokens>
            <token id="33" string="once" />
          </tokens>
        </entity>
        <entity id="4" string="Betty Ford" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Betty" />
            <token id="4" string="Ford" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="71" has_coreference="true">
      <content>And the late &amp;apost;80s had found Liz, hobbled by back pain, returning to those two sources of comfort.</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="late" lemma="late" stem="late" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="'80s" lemma="'80" stem="'80" pos="NNS" type="Word" isStopWord="false" ner="SET" is_referenced="true" is_refers="false" />
        <token id="5" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="found" lemma="find" stem="found" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="Liz" lemma="Liz" stem="liz" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="hobbled" lemma="hobble" stem="hobbl" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="back" lemma="back" stem="back" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="pain" lemma="pain" stem="pain" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="returning" lemma="return" stem="return" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="18" string="sources" lemma="source" stem="sourc" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="comfort" lemma="comfort" stem="comfort" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC And) (NP (DT the) (JJ late) (NNS '80s)) (VP (VBD had) (VP (VBN found) (NP (NP (NNP Liz)) (, ,) (VP (VBN hobbled) (PP (IN by) (NP (RB back) (NN pain)))) (, ,) (VP (VBG returning) (PP (TO to) (NP (NP (DT those) (CD two) (NNS sources)) (PP (IN of) (NP (NN comfort))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="hobbled by back pain" type="VP">
          <tokens>
            <token id="9" string="hobbled" />
            <token id="10" string="by" />
            <token id="11" string="back" />
            <token id="12" string="pain" />
          </tokens>
        </chunking>
        <chunking id="2" string="back pain" type="NP">
          <tokens>
            <token id="11" string="back" />
            <token id="12" string="pain" />
          </tokens>
        </chunking>
        <chunking id="3" string="returning to those two sources of comfort" type="VP">
          <tokens>
            <token id="14" string="returning" />
            <token id="15" string="to" />
            <token id="16" string="those" />
            <token id="17" string="two" />
            <token id="18" string="sources" />
            <token id="19" string="of" />
            <token id="20" string="comfort" />
          </tokens>
        </chunking>
        <chunking id="4" string="those two sources" type="NP">
          <tokens>
            <token id="16" string="those" />
            <token id="17" string="two" />
            <token id="18" string="sources" />
          </tokens>
        </chunking>
        <chunking id="5" string="had found Liz , hobbled by back pain , returning to those two sources of comfort" type="VP">
          <tokens>
            <token id="5" string="had" />
            <token id="6" string="found" />
            <token id="7" string="Liz" />
            <token id="8" string="," />
            <token id="9" string="hobbled" />
            <token id="10" string="by" />
            <token id="11" string="back" />
            <token id="12" string="pain" />
            <token id="13" string="," />
            <token id="14" string="returning" />
            <token id="15" string="to" />
            <token id="16" string="those" />
            <token id="17" string="two" />
            <token id="18" string="sources" />
            <token id="19" string="of" />
            <token id="20" string="comfort" />
          </tokens>
        </chunking>
        <chunking id="6" string="comfort" type="NP">
          <tokens>
            <token id="20" string="comfort" />
          </tokens>
        </chunking>
        <chunking id="7" string="the late '80s" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="late" />
            <token id="4" string="'80s" />
          </tokens>
        </chunking>
        <chunking id="8" string="Liz , hobbled by back pain , returning to those two sources of comfort" type="NP">
          <tokens>
            <token id="7" string="Liz" />
            <token id="8" string="," />
            <token id="9" string="hobbled" />
            <token id="10" string="by" />
            <token id="11" string="back" />
            <token id="12" string="pain" />
            <token id="13" string="," />
            <token id="14" string="returning" />
            <token id="15" string="to" />
            <token id="16" string="those" />
            <token id="17" string="two" />
            <token id="18" string="sources" />
            <token id="19" string="of" />
            <token id="20" string="comfort" />
          </tokens>
        </chunking>
        <chunking id="9" string="those two sources of comfort" type="NP">
          <tokens>
            <token id="16" string="those" />
            <token id="17" string="two" />
            <token id="18" string="sources" />
            <token id="19" string="of" />
            <token id="20" string="comfort" />
          </tokens>
        </chunking>
        <chunking id="10" string="found Liz , hobbled by back pain , returning to those two sources of comfort" type="VP">
          <tokens>
            <token id="6" string="found" />
            <token id="7" string="Liz" />
            <token id="8" string="," />
            <token id="9" string="hobbled" />
            <token id="10" string="by" />
            <token id="11" string="back" />
            <token id="12" string="pain" />
            <token id="13" string="," />
            <token id="14" string="returning" />
            <token id="15" string="to" />
            <token id="16" string="those" />
            <token id="17" string="two" />
            <token id="18" string="sources" />
            <token id="19" string="of" />
            <token id="20" string="comfort" />
          </tokens>
        </chunking>
        <chunking id="11" string="Liz" type="NP">
          <tokens>
            <token id="7" string="Liz" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="6">found</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">'80s</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">'80s</governor>
          <dependent id="3">late</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">found</governor>
          <dependent id="4">'80s</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">found</governor>
          <dependent id="5">had</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">found</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">found</governor>
          <dependent id="7">Liz</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="7">Liz</governor>
          <dependent id="9">hobbled</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">pain</governor>
          <dependent id="10">by</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">pain</governor>
          <dependent id="11">back</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">hobbled</governor>
          <dependent id="12">pain</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="7">Liz</governor>
          <dependent id="14">returning</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">sources</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">sources</governor>
          <dependent id="16">those</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="18">sources</governor>
          <dependent id="17">two</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">returning</governor>
          <dependent id="18">sources</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">comfort</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">sources</governor>
          <dependent id="20">comfort</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="'80s" type="SET" score="0.0">
          <tokens>
            <token id="4" string="'80s" />
          </tokens>
        </entity>
        <entity id="2" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="17" string="two" />
          </tokens>
        </entity>
        <entity id="3" string="Liz" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Liz" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="72" has_coreference="true">
      <content>Taylor regained much of the weight, even though she took her drug problems in hand once again in a second stay at the Betty Ford clinic in 1988.</content>
      <tokens>
        <token id="1" string="Taylor" lemma="Taylor" stem="taylor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="regained" lemma="regain" stem="regain" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="much" lemma="much" stem="much" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="weight" lemma="weight" stem="weight" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="though" lemma="though" stem="though" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="took" lemma="take" stem="took" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="drug" lemma="drug" stem="drug" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="problems" lemma="problem" stem="problem" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="hand" lemma="hand" stem="hand" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="once" lemma="once" stem="onc" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="18" string="again" lemma="again" stem="again" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="21" string="second" lemma="second" stem="second" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="22" string="stay" lemma="stay" stem="stai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="Betty" lemma="Betty" stem="betti" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="26" string="Ford" lemma="Ford" stem="ford" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="27" string="clinic" lemma="clinic" stem="clinic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="1988" lemma="1988" stem="1988" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Taylor)) (VP (VBD regained) (NP (NP (RB much)) (PP (IN of) (NP (DT the) (NN weight)))) (, ,) (SBAR (RB even) (IN though) (S (NP (PRP she)) (VP (VBD took) (NP (PRP$ her) (NN drug) (NNS problems)) (PP (IN in) (NP (NN hand))) (PP (ADVP (RB once) (RB again)) (IN in) (NP (NP (DT a) (JJ second) (NN stay)) (PP (IN at) (NP (NP (DT the) (NNP Betty) (NNP Ford) (NN clinic)) (PP (IN in) (NP (CD 1988))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the Betty Ford clinic" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="Betty" />
            <token id="26" string="Ford" />
            <token id="27" string="clinic" />
          </tokens>
        </chunking>
        <chunking id="2" string="Taylor" type="NP">
          <tokens>
            <token id="1" string="Taylor" />
          </tokens>
        </chunking>
        <chunking id="3" string="the weight" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="weight" />
          </tokens>
        </chunking>
        <chunking id="4" string="regained much of the weight , even though she took her drug problems in hand once again in a second stay at the Betty Ford clinic in 1988" type="VP">
          <tokens>
            <token id="2" string="regained" />
            <token id="3" string="much" />
            <token id="4" string="of" />
            <token id="5" string="the" />
            <token id="6" string="weight" />
            <token id="7" string="," />
            <token id="8" string="even" />
            <token id="9" string="though" />
            <token id="10" string="she" />
            <token id="11" string="took" />
            <token id="12" string="her" />
            <token id="13" string="drug" />
            <token id="14" string="problems" />
            <token id="15" string="in" />
            <token id="16" string="hand" />
            <token id="17" string="once" />
            <token id="18" string="again" />
            <token id="19" string="in" />
            <token id="20" string="a" />
            <token id="21" string="second" />
            <token id="22" string="stay" />
            <token id="23" string="at" />
            <token id="24" string="the" />
            <token id="25" string="Betty" />
            <token id="26" string="Ford" />
            <token id="27" string="clinic" />
            <token id="28" string="in" />
            <token id="29" string="1988" />
          </tokens>
        </chunking>
        <chunking id="5" string="much of the weight" type="NP">
          <tokens>
            <token id="3" string="much" />
            <token id="4" string="of" />
            <token id="5" string="the" />
            <token id="6" string="weight" />
          </tokens>
        </chunking>
        <chunking id="6" string="a second stay at the Betty Ford clinic in 1988" type="NP">
          <tokens>
            <token id="20" string="a" />
            <token id="21" string="second" />
            <token id="22" string="stay" />
            <token id="23" string="at" />
            <token id="24" string="the" />
            <token id="25" string="Betty" />
            <token id="26" string="Ford" />
            <token id="27" string="clinic" />
            <token id="28" string="in" />
            <token id="29" string="1988" />
          </tokens>
        </chunking>
        <chunking id="7" string="she" type="NP">
          <tokens>
            <token id="10" string="she" />
          </tokens>
        </chunking>
        <chunking id="8" string="the Betty Ford clinic in 1988" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="Betty" />
            <token id="26" string="Ford" />
            <token id="27" string="clinic" />
            <token id="28" string="in" />
            <token id="29" string="1988" />
          </tokens>
        </chunking>
        <chunking id="9" string="even though she took her drug problems in hand once again in a second stay at the Betty Ford clinic in 1988" type="SBAR">
          <tokens>
            <token id="8" string="even" />
            <token id="9" string="though" />
            <token id="10" string="she" />
            <token id="11" string="took" />
            <token id="12" string="her" />
            <token id="13" string="drug" />
            <token id="14" string="problems" />
            <token id="15" string="in" />
            <token id="16" string="hand" />
            <token id="17" string="once" />
            <token id="18" string="again" />
            <token id="19" string="in" />
            <token id="20" string="a" />
            <token id="21" string="second" />
            <token id="22" string="stay" />
            <token id="23" string="at" />
            <token id="24" string="the" />
            <token id="25" string="Betty" />
            <token id="26" string="Ford" />
            <token id="27" string="clinic" />
            <token id="28" string="in" />
            <token id="29" string="1988" />
          </tokens>
        </chunking>
        <chunking id="10" string="1988" type="NP">
          <tokens>
            <token id="29" string="1988" />
          </tokens>
        </chunking>
        <chunking id="11" string="a second stay" type="NP">
          <tokens>
            <token id="20" string="a" />
            <token id="21" string="second" />
            <token id="22" string="stay" />
          </tokens>
        </chunking>
        <chunking id="12" string="took her drug problems in hand once again in a second stay at the Betty Ford clinic in 1988" type="VP">
          <tokens>
            <token id="11" string="took" />
            <token id="12" string="her" />
            <token id="13" string="drug" />
            <token id="14" string="problems" />
            <token id="15" string="in" />
            <token id="16" string="hand" />
            <token id="17" string="once" />
            <token id="18" string="again" />
            <token id="19" string="in" />
            <token id="20" string="a" />
            <token id="21" string="second" />
            <token id="22" string="stay" />
            <token id="23" string="at" />
            <token id="24" string="the" />
            <token id="25" string="Betty" />
            <token id="26" string="Ford" />
            <token id="27" string="clinic" />
            <token id="28" string="in" />
            <token id="29" string="1988" />
          </tokens>
        </chunking>
        <chunking id="13" string="her drug problems" type="NP">
          <tokens>
            <token id="12" string="her" />
            <token id="13" string="drug" />
            <token id="14" string="problems" />
          </tokens>
        </chunking>
        <chunking id="14" string="hand" type="NP">
          <tokens>
            <token id="16" string="hand" />
          </tokens>
        </chunking>
        <chunking id="15" string="much" type="NP">
          <tokens>
            <token id="3" string="much" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">regained</governor>
          <dependent id="1">Taylor</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">regained</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">regained</governor>
          <dependent id="3">much</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">weight</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">weight</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">much</governor>
          <dependent id="6">weight</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">took</governor>
          <dependent id="8">even</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">took</governor>
          <dependent id="9">though</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">took</governor>
          <dependent id="10">she</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="2">regained</governor>
          <dependent id="11">took</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">problems</governor>
          <dependent id="12">her</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">problems</governor>
          <dependent id="13">drug</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">took</governor>
          <dependent id="14">problems</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">hand</governor>
          <dependent id="15">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">took</governor>
          <dependent id="16">hand</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">again</governor>
          <dependent id="17">once</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="22">stay</governor>
          <dependent id="18">again</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">stay</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">stay</governor>
          <dependent id="20">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">stay</governor>
          <dependent id="21">second</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">took</governor>
          <dependent id="22">stay</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">clinic</governor>
          <dependent id="23">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">clinic</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">clinic</governor>
          <dependent id="25">Betty</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">clinic</governor>
          <dependent id="26">Ford</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">stay</governor>
          <dependent id="27">clinic</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">1988</governor>
          <dependent id="28">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">clinic</governor>
          <dependent id="29">1988</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1988" type="DATE" score="0.0">
          <tokens>
            <token id="29" string="1988" />
          </tokens>
        </entity>
        <entity id="2" string="Taylor" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Taylor" />
          </tokens>
        </entity>
        <entity id="3" string="once" type="DATE" score="0.0">
          <tokens>
            <token id="17" string="once" />
          </tokens>
        </entity>
        <entity id="4" string="a second" type="DURATION" score="0.0">
          <tokens>
            <token id="20" string="a" />
            <token id="21" string="second" />
          </tokens>
        </entity>
        <entity id="5" string="Betty Ford" type="PERSON" score="0.0">
          <tokens>
            <token id="25" string="Betty" />
            <token id="26" string="Ford" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="73" has_coreference="true">
      <content>But through her ordeals, she has remained the same charmingly vain Liz who once declared her hobbies to be clothes and jewels.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="ordeals" lemma="ordeal" stem="ordeal" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="remained" lemma="remain" stem="remain" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="same" lemma="same" stem="same" pos="JJ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="charmingly" lemma="charmingly" stem="charmingli" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="vain" lemma="vain" stem="vain" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="Liz" lemma="Liz" stem="liz" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="14" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="once" lemma="once" stem="onc" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="16" string="declared" lemma="declare" stem="declar" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="18" string="hobbies" lemma="hobby" stem="hobbi" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="clothes" lemma="clothes" stem="cloth" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="jewels" lemma="jewel" stem="jewel" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (PP (IN through) (NP (PRP$ her) (NNS ordeals))) (, ,) (NP (PRP she)) (VP (VBZ has) (VP (VBN remained) (NP (ADVP (NP (DT the) (JJ same)) (RB charmingly)) (NP (JJ vain) (NNP Liz)) (SBAR (WHNP (WP who)) (S (ADVP (RB once)) (VP (VBD declared) (NP (PRP$ her) (NNS hobbies)) (S (VP (TO to) (VP (VB be) (NP (NNS clothes) (CC and) (NNS jewels))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the same charmingly vain Liz who once declared her hobbies to be clothes and jewels" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="same" />
            <token id="11" string="charmingly" />
            <token id="12" string="vain" />
            <token id="13" string="Liz" />
            <token id="14" string="who" />
            <token id="15" string="once" />
            <token id="16" string="declared" />
            <token id="17" string="her" />
            <token id="18" string="hobbies" />
            <token id="19" string="to" />
            <token id="20" string="be" />
            <token id="21" string="clothes" />
            <token id="22" string="and" />
            <token id="23" string="jewels" />
          </tokens>
        </chunking>
        <chunking id="2" string="her hobbies" type="NP">
          <tokens>
            <token id="17" string="her" />
            <token id="18" string="hobbies" />
          </tokens>
        </chunking>
        <chunking id="3" string="who once declared her hobbies to be clothes and jewels" type="SBAR">
          <tokens>
            <token id="14" string="who" />
            <token id="15" string="once" />
            <token id="16" string="declared" />
            <token id="17" string="her" />
            <token id="18" string="hobbies" />
            <token id="19" string="to" />
            <token id="20" string="be" />
            <token id="21" string="clothes" />
            <token id="22" string="and" />
            <token id="23" string="jewels" />
          </tokens>
        </chunking>
        <chunking id="4" string="has remained the same charmingly vain Liz who once declared her hobbies to be clothes and jewels" type="VP">
          <tokens>
            <token id="7" string="has" />
            <token id="8" string="remained" />
            <token id="9" string="the" />
            <token id="10" string="same" />
            <token id="11" string="charmingly" />
            <token id="12" string="vain" />
            <token id="13" string="Liz" />
            <token id="14" string="who" />
            <token id="15" string="once" />
            <token id="16" string="declared" />
            <token id="17" string="her" />
            <token id="18" string="hobbies" />
            <token id="19" string="to" />
            <token id="20" string="be" />
            <token id="21" string="clothes" />
            <token id="22" string="and" />
            <token id="23" string="jewels" />
          </tokens>
        </chunking>
        <chunking id="5" string="remained the same charmingly vain Liz who once declared her hobbies to be clothes and jewels" type="VP">
          <tokens>
            <token id="8" string="remained" />
            <token id="9" string="the" />
            <token id="10" string="same" />
            <token id="11" string="charmingly" />
            <token id="12" string="vain" />
            <token id="13" string="Liz" />
            <token id="14" string="who" />
            <token id="15" string="once" />
            <token id="16" string="declared" />
            <token id="17" string="her" />
            <token id="18" string="hobbies" />
            <token id="19" string="to" />
            <token id="20" string="be" />
            <token id="21" string="clothes" />
            <token id="22" string="and" />
            <token id="23" string="jewels" />
          </tokens>
        </chunking>
        <chunking id="6" string="she" type="NP">
          <tokens>
            <token id="6" string="she" />
          </tokens>
        </chunking>
        <chunking id="7" string="be clothes and jewels" type="VP">
          <tokens>
            <token id="20" string="be" />
            <token id="21" string="clothes" />
            <token id="22" string="and" />
            <token id="23" string="jewels" />
          </tokens>
        </chunking>
        <chunking id="8" string="her ordeals" type="NP">
          <tokens>
            <token id="3" string="her" />
            <token id="4" string="ordeals" />
          </tokens>
        </chunking>
        <chunking id="9" string="the same" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="same" />
          </tokens>
        </chunking>
        <chunking id="10" string="to be clothes and jewels" type="VP">
          <tokens>
            <token id="19" string="to" />
            <token id="20" string="be" />
            <token id="21" string="clothes" />
            <token id="22" string="and" />
            <token id="23" string="jewels" />
          </tokens>
        </chunking>
        <chunking id="11" string="declared her hobbies to be clothes and jewels" type="VP">
          <tokens>
            <token id="16" string="declared" />
            <token id="17" string="her" />
            <token id="18" string="hobbies" />
            <token id="19" string="to" />
            <token id="20" string="be" />
            <token id="21" string="clothes" />
            <token id="22" string="and" />
            <token id="23" string="jewels" />
          </tokens>
        </chunking>
        <chunking id="12" string="vain Liz" type="NP">
          <tokens>
            <token id="12" string="vain" />
            <token id="13" string="Liz" />
          </tokens>
        </chunking>
        <chunking id="13" string="clothes and jewels" type="NP">
          <tokens>
            <token id="21" string="clothes" />
            <token id="22" string="and" />
            <token id="23" string="jewels" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="8">remained</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">ordeals</governor>
          <dependent id="2">through</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">ordeals</governor>
          <dependent id="3">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">remained</governor>
          <dependent id="4">ordeals</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">remained</governor>
          <dependent id="6">she</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">remained</governor>
          <dependent id="7">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">remained</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">same</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="11">charmingly</governor>
          <dependent id="10">same</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">Liz</governor>
          <dependent id="11">charmingly</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">Liz</governor>
          <dependent id="12">vain</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">remained</governor>
          <dependent id="13">Liz</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">declared</governor>
          <dependent id="14">who</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">declared</governor>
          <dependent id="15">once</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="13">Liz</governor>
          <dependent id="16">declared</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="18">hobbies</governor>
          <dependent id="17">her</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">declared</governor>
          <dependent id="18">hobbies</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">clothes</governor>
          <dependent id="19">to</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="21">clothes</governor>
          <dependent id="20">be</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="16">declared</governor>
          <dependent id="21">clothes</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="21">clothes</governor>
          <dependent id="22">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="21">clothes</governor>
          <dependent id="23">jewels</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="once" type="DATE" score="0.0">
          <tokens>
            <token id="15" string="once" />
          </tokens>
        </entity>
        <entity id="2" string="Liz" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Liz" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="74" has_coreference="true">
      <content>She never budged from her room at Betty Ford without her trademark darkened eyebrows.</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="budged" lemma="budge" stem="budg" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="room" lemma="room" stem="room" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Betty" lemma="Betty" stem="betti" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="9" string="Ford" lemma="Ford" stem="ford" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="10" string="without" lemma="without" stem="without" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="trademark" lemma="trademark" stem="trademark" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="darkened" lemma="darkened" stem="darken" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="eyebrows" lemma="eyebrow" stem="eyebrow" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP She)) (ADVP (RB never)) (VP (VBD budged) (PP (IN from) (NP (PRP$ her) (NN room))) (PP (IN at) (NP (NNP Betty) (NNP Ford))) (PP (IN without) (NP (PRP$ her) (NN trademark) (JJ darkened) (NNS eyebrows)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="her trademark darkened eyebrows" type="NP">
          <tokens>
            <token id="11" string="her" />
            <token id="12" string="trademark" />
            <token id="13" string="darkened" />
            <token id="14" string="eyebrows" />
          </tokens>
        </chunking>
        <chunking id="2" string="her room" type="NP">
          <tokens>
            <token id="5" string="her" />
            <token id="6" string="room" />
          </tokens>
        </chunking>
        <chunking id="3" string="budged from her room at Betty Ford without her trademark darkened eyebrows" type="VP">
          <tokens>
            <token id="3" string="budged" />
            <token id="4" string="from" />
            <token id="5" string="her" />
            <token id="6" string="room" />
            <token id="7" string="at" />
            <token id="8" string="Betty" />
            <token id="9" string="Ford" />
            <token id="10" string="without" />
            <token id="11" string="her" />
            <token id="12" string="trademark" />
            <token id="13" string="darkened" />
            <token id="14" string="eyebrows" />
          </tokens>
        </chunking>
        <chunking id="4" string="Betty Ford" type="NP">
          <tokens>
            <token id="8" string="Betty" />
            <token id="9" string="Ford" />
          </tokens>
        </chunking>
        <chunking id="5" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">budged</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="3">budged</governor>
          <dependent id="2">never</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">budged</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">room</governor>
          <dependent id="4">from</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">room</governor>
          <dependent id="5">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">budged</governor>
          <dependent id="6">room</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Ford</governor>
          <dependent id="7">at</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Ford</governor>
          <dependent id="8">Betty</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">budged</governor>
          <dependent id="9">Ford</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">eyebrows</governor>
          <dependent id="10">without</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">eyebrows</governor>
          <dependent id="11">her</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">eyebrows</governor>
          <dependent id="12">trademark</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">eyebrows</governor>
          <dependent id="13">darkened</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">budged</governor>
          <dependent id="14">eyebrows</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Betty Ford" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Betty" />
            <token id="9" string="Ford" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="75" has_coreference="true">
      <content>And even when she was ambushed recently by a Star photographer, Liz couldn&amp;apost;t help being, well, Liz.</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="ambushed" lemma="ambush" stem="ambush" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="recently" lemma="recently" stem="recent" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="8" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Star" lemma="Star" stem="star" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="11" string="photographer" lemma="photographer" stem="photograph" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Liz" lemma="Liz" stem="liz" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="14" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="help" lemma="help" stem="help" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="being" lemma="be" stem="be" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="well" lemma="well" stem="well" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="Liz" lemma="Liz" stem="liz" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC And) (SBAR (RB even) (WHADVP (WRB when)) (S (NP (PRP she)) (VP (VBD was) (VP (VBN ambushed) (ADVP (RB recently)) (PP (IN by) (NP (DT a) (NNP Star) (NNP photographer))))))) (, ,) (NP (NNP Liz)) (VP (MD could) (RB n't) (VP (VP (VB help) (VP (VBG being))) (, ,) (FRAG (INTJ (RB well)) (, ,) (NP (NNP Liz))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="help being" type="VP">
          <tokens>
            <token id="16" string="help" />
            <token id="17" string="being" />
          </tokens>
        </chunking>
        <chunking id="2" string="help being , well , Liz" type="VP">
          <tokens>
            <token id="16" string="help" />
            <token id="17" string="being" />
            <token id="18" string="," />
            <token id="19" string="well" />
            <token id="20" string="," />
            <token id="21" string="Liz" />
          </tokens>
        </chunking>
        <chunking id="3" string="a Star photographer" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="Star" />
            <token id="11" string="photographer" />
          </tokens>
        </chunking>
        <chunking id="4" string="ambushed recently by a Star photographer" type="VP">
          <tokens>
            <token id="6" string="ambushed" />
            <token id="7" string="recently" />
            <token id="8" string="by" />
            <token id="9" string="a" />
            <token id="10" string="Star" />
            <token id="11" string="photographer" />
          </tokens>
        </chunking>
        <chunking id="5" string="even when she was ambushed recently by a Star photographer" type="SBAR">
          <tokens>
            <token id="2" string="even" />
            <token id="3" string="when" />
            <token id="4" string="she" />
            <token id="5" string="was" />
            <token id="6" string="ambushed" />
            <token id="7" string="recently" />
            <token id="8" string="by" />
            <token id="9" string="a" />
            <token id="10" string="Star" />
            <token id="11" string="photographer" />
          </tokens>
        </chunking>
        <chunking id="6" string="was ambushed recently by a Star photographer" type="VP">
          <tokens>
            <token id="5" string="was" />
            <token id="6" string="ambushed" />
            <token id="7" string="recently" />
            <token id="8" string="by" />
            <token id="9" string="a" />
            <token id="10" string="Star" />
            <token id="11" string="photographer" />
          </tokens>
        </chunking>
        <chunking id="7" string="being" type="VP">
          <tokens>
            <token id="17" string="being" />
          </tokens>
        </chunking>
        <chunking id="8" string="could n't help being , well , Liz" type="VP">
          <tokens>
            <token id="14" string="could" />
            <token id="15" string="n't" />
            <token id="16" string="help" />
            <token id="17" string="being" />
            <token id="18" string="," />
            <token id="19" string="well" />
            <token id="20" string="," />
            <token id="21" string="Liz" />
          </tokens>
        </chunking>
        <chunking id="9" string="Liz" type="NP">
          <tokens>
            <token id="13" string="Liz" />
          </tokens>
        </chunking>
        <chunking id="10" string="when" type="WHADVP">
          <tokens>
            <token id="3" string="when" />
          </tokens>
        </chunking>
        <chunking id="11" string="she" type="NP">
          <tokens>
            <token id="4" string="she" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="16">help</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">ambushed</governor>
          <dependent id="2">even</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">ambushed</governor>
          <dependent id="3">when</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="6">ambushed</governor>
          <dependent id="4">she</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">ambushed</governor>
          <dependent id="5">was</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="16">help</governor>
          <dependent id="6">ambushed</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">ambushed</governor>
          <dependent id="7">recently</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">photographer</governor>
          <dependent id="8">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">photographer</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">photographer</governor>
          <dependent id="10">Star</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">ambushed</governor>
          <dependent id="11">photographer</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">help</governor>
          <dependent id="13">Liz</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">help</governor>
          <dependent id="14">could</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="16">help</governor>
          <dependent id="15">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">help</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="16">help</governor>
          <dependent id="17">being</dependent>
        </dependency>
        <dependency type="discourse">
          <governor id="21">Liz</governor>
          <dependent id="19">well</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="16">help</governor>
          <dependent id="21">Liz</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Star" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="10" string="Star" />
          </tokens>
        </entity>
        <entity id="2" string="recently" type="DATE" score="0.0">
          <tokens>
            <token id="7" string="recently" />
          </tokens>
        </entity>
        <entity id="3" string="Liz" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Liz" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="76" has_coreference="true">
      <content>Says the Star&amp;apost;s Levine: &amp;quot;No matter how sick she was, when someone down on the ground told her she was being photographed, she put on sunglasses, even though she had an IV in her arm, as if to cover herself up.</content>
      <tokens>
        <token id="1" string="Says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="Star" lemma="Star" stem="star" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="4" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="5" string="Levine" lemma="Levine" stem="levin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="No" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="matter" lemma="matter" stem="matter" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="how" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="sick" lemma="sick" stem="sick" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="someone" lemma="someone" stem="someon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="down" lemma="down" stem="down" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="ground" lemma="ground" stem="ground" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="told" lemma="tell" stem="told" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="her" lemma="she" stem="her" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="being" lemma="be" stem="be" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="photographed" lemma="photograph" stem="photograph" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="29" string="put" lemma="put" stem="put" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="on" lemma="on" stem="on" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="sunglasses" lemma="sunglass" stem="sunglass" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="though" lemma="though" stem="though" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="36" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="IV" lemma="iv" stem="iv" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="39" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="41" string="arm" lemma="arm" stem="arm" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="cover" lemma="cover" stem="cover" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="47" string="herself" lemma="herself" stem="herself" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="48" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="49" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VBZ Says) (NP (DT the) (NP (NNP Star) (POS 's)) (NNP Levine)))) (: :) (`` ``) (S (ADVP (DT No) (NN matter) (SBAR (WHADVP (WRB how) (ADJP (JJ sick))) (S (NP (PRP she)) (VP (VP (VBD was)) (, ,) (SBAR (WHADVP (WRB when)) (S (NP (NN someone)) (ADVP (RB down) (PP (IN on) (NP (DT the) (NN ground)))) (VP (VBD told) (NP (PRP her)) (SBAR (S (NP (PRP she)) (VP (VBD was) (VP (VBG being) (VP (VBN photographed))))))))))))) (, ,) (NP (PRP she)) (VP (VBD put) (PRT (RP on)) (NP (NNS sunglasses)) (, ,) (SBAR (RB even) (IN though) (S (NP (PRP she)) (VP (VBD had) (NP (NP (DT an) (CD IV)) (PP (IN in) (NP (PRP$ her) (NN arm)))) (, ,) (PP (IN as) (SBAR (IN if) (S (VP (TO to) (VP (VB cover) (NP (PRP herself)) (PRT (RP up)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was , when someone down on the ground told her she was being photographed" type="VP">
          <tokens>
            <token id="13" string="was" />
            <token id="14" string="," />
            <token id="15" string="when" />
            <token id="16" string="someone" />
            <token id="17" string="down" />
            <token id="18" string="on" />
            <token id="19" string="the" />
            <token id="20" string="ground" />
            <token id="21" string="told" />
            <token id="22" string="her" />
            <token id="23" string="she" />
            <token id="24" string="was" />
            <token id="25" string="being" />
            <token id="26" string="photographed" />
          </tokens>
        </chunking>
        <chunking id="2" string="if to cover herself up" type="SBAR">
          <tokens>
            <token id="44" string="if" />
            <token id="45" string="to" />
            <token id="46" string="cover" />
            <token id="47" string="herself" />
            <token id="48" string="up" />
          </tokens>
        </chunking>
        <chunking id="3" string="sunglasses" type="NP">
          <tokens>
            <token id="31" string="sunglasses" />
          </tokens>
        </chunking>
        <chunking id="4" string="the ground" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="ground" />
          </tokens>
        </chunking>
        <chunking id="5" string="put on sunglasses , even though she had an IV in her arm , as if to cover herself up" type="VP">
          <tokens>
            <token id="29" string="put" />
            <token id="30" string="on" />
            <token id="31" string="sunglasses" />
            <token id="32" string="," />
            <token id="33" string="even" />
            <token id="34" string="though" />
            <token id="35" string="she" />
            <token id="36" string="had" />
            <token id="37" string="an" />
            <token id="38" string="IV" />
            <token id="39" string="in" />
            <token id="40" string="her" />
            <token id="41" string="arm" />
            <token id="42" string="," />
            <token id="43" string="as" />
            <token id="44" string="if" />
            <token id="45" string="to" />
            <token id="46" string="cover" />
            <token id="47" string="herself" />
            <token id="48" string="up" />
          </tokens>
        </chunking>
        <chunking id="6" string="her arm" type="NP">
          <tokens>
            <token id="40" string="her" />
            <token id="41" string="arm" />
          </tokens>
        </chunking>
        <chunking id="7" string="was" type="VP">
          <tokens>
            <token id="13" string="was" />
          </tokens>
        </chunking>
        <chunking id="8" string="photographed" type="VP">
          <tokens>
            <token id="26" string="photographed" />
          </tokens>
        </chunking>
        <chunking id="9" string="she" type="NP">
          <tokens>
            <token id="12" string="she" />
          </tokens>
        </chunking>
        <chunking id="10" string="cover herself up" type="VP">
          <tokens>
            <token id="46" string="cover" />
            <token id="47" string="herself" />
            <token id="48" string="up" />
          </tokens>
        </chunking>
        <chunking id="11" string="even though she had an IV in her arm , as if to cover herself up" type="SBAR">
          <tokens>
            <token id="33" string="even" />
            <token id="34" string="though" />
            <token id="35" string="she" />
            <token id="36" string="had" />
            <token id="37" string="an" />
            <token id="38" string="IV" />
            <token id="39" string="in" />
            <token id="40" string="her" />
            <token id="41" string="arm" />
            <token id="42" string="," />
            <token id="43" string="as" />
            <token id="44" string="if" />
            <token id="45" string="to" />
            <token id="46" string="cover" />
            <token id="47" string="herself" />
            <token id="48" string="up" />
          </tokens>
        </chunking>
        <chunking id="12" string="when someone down on the ground told her she was being photographed" type="SBAR">
          <tokens>
            <token id="15" string="when" />
            <token id="16" string="someone" />
            <token id="17" string="down" />
            <token id="18" string="on" />
            <token id="19" string="the" />
            <token id="20" string="ground" />
            <token id="21" string="told" />
            <token id="22" string="her" />
            <token id="23" string="she" />
            <token id="24" string="was" />
            <token id="25" string="being" />
            <token id="26" string="photographed" />
          </tokens>
        </chunking>
        <chunking id="13" string="an IV" type="NP">
          <tokens>
            <token id="37" string="an" />
            <token id="38" string="IV" />
          </tokens>
        </chunking>
        <chunking id="14" string="someone" type="NP">
          <tokens>
            <token id="16" string="someone" />
          </tokens>
        </chunking>
        <chunking id="15" string="Star 's" type="NP">
          <tokens>
            <token id="3" string="Star" />
            <token id="4" string="'s" />
          </tokens>
        </chunking>
        <chunking id="16" string="herself" type="NP">
          <tokens>
            <token id="47" string="herself" />
          </tokens>
        </chunking>
        <chunking id="17" string="Says the Star 's Levine" type="VP">
          <tokens>
            <token id="1" string="Says" />
            <token id="2" string="the" />
            <token id="3" string="Star" />
            <token id="4" string="'s" />
            <token id="5" string="Levine" />
          </tokens>
        </chunking>
        <chunking id="18" string="an IV in her arm" type="NP">
          <tokens>
            <token id="37" string="an" />
            <token id="38" string="IV" />
            <token id="39" string="in" />
            <token id="40" string="her" />
            <token id="41" string="arm" />
          </tokens>
        </chunking>
        <chunking id="19" string="sick" type="ADJP">
          <tokens>
            <token id="11" string="sick" />
          </tokens>
        </chunking>
        <chunking id="20" string="when" type="WHADVP">
          <tokens>
            <token id="15" string="when" />
          </tokens>
        </chunking>
        <chunking id="21" string="the Star 's Levine" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="Star" />
            <token id="4" string="'s" />
            <token id="5" string="Levine" />
          </tokens>
        </chunking>
        <chunking id="22" string="being photographed" type="VP">
          <tokens>
            <token id="25" string="being" />
            <token id="26" string="photographed" />
          </tokens>
        </chunking>
        <chunking id="23" string="how sick she was , when someone down on the ground told her she was being photographed" type="SBAR">
          <tokens>
            <token id="10" string="how" />
            <token id="11" string="sick" />
            <token id="12" string="she" />
            <token id="13" string="was" />
            <token id="14" string="," />
            <token id="15" string="when" />
            <token id="16" string="someone" />
            <token id="17" string="down" />
            <token id="18" string="on" />
            <token id="19" string="the" />
            <token id="20" string="ground" />
            <token id="21" string="told" />
            <token id="22" string="her" />
            <token id="23" string="she" />
            <token id="24" string="was" />
            <token id="25" string="being" />
            <token id="26" string="photographed" />
          </tokens>
        </chunking>
        <chunking id="24" string="her" type="NP">
          <tokens>
            <token id="22" string="her" />
          </tokens>
        </chunking>
        <chunking id="25" string="she was being photographed" type="SBAR">
          <tokens>
            <token id="23" string="she" />
            <token id="24" string="was" />
            <token id="25" string="being" />
            <token id="26" string="photographed" />
          </tokens>
        </chunking>
        <chunking id="26" string="was being photographed" type="VP">
          <tokens>
            <token id="24" string="was" />
            <token id="25" string="being" />
            <token id="26" string="photographed" />
          </tokens>
        </chunking>
        <chunking id="27" string="had an IV in her arm , as if to cover herself up" type="VP">
          <tokens>
            <token id="36" string="had" />
            <token id="37" string="an" />
            <token id="38" string="IV" />
            <token id="39" string="in" />
            <token id="40" string="her" />
            <token id="41" string="arm" />
            <token id="42" string="," />
            <token id="43" string="as" />
            <token id="44" string="if" />
            <token id="45" string="to" />
            <token id="46" string="cover" />
            <token id="47" string="herself" />
            <token id="48" string="up" />
          </tokens>
        </chunking>
        <chunking id="28" string="told her she was being photographed" type="VP">
          <tokens>
            <token id="21" string="told" />
            <token id="22" string="her" />
            <token id="23" string="she" />
            <token id="24" string="was" />
            <token id="25" string="being" />
            <token id="26" string="photographed" />
          </tokens>
        </chunking>
        <chunking id="29" string="to cover herself up" type="VP">
          <tokens>
            <token id="45" string="to" />
            <token id="46" string="cover" />
            <token id="47" string="herself" />
            <token id="48" string="up" />
          </tokens>
        </chunking>
        <chunking id="30" string="how sick" type="WHADVP">
          <tokens>
            <token id="10" string="how" />
            <token id="11" string="sick" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">Says</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">Levine</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">Levine</governor>
          <dependent id="3">Star</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">Star</governor>
          <dependent id="4">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="1">Says</governor>
          <dependent id="5">Levine</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="9">matter</governor>
          <dependent id="8">No</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="29">put</governor>
          <dependent id="9">matter</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">was</governor>
          <dependent id="10">how</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="10">how</governor>
          <dependent id="11">sick</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">was</governor>
          <dependent id="12">she</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="9">matter</governor>
          <dependent id="13">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="21">told</governor>
          <dependent id="15">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">told</governor>
          <dependent id="16">someone</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="21">told</governor>
          <dependent id="17">down</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">ground</governor>
          <dependent id="18">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">ground</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">down</governor>
          <dependent id="20">ground</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="13">was</governor>
          <dependent id="21">told</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">told</governor>
          <dependent id="22">her</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="26">photographed</governor>
          <dependent id="23">she</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="26">photographed</governor>
          <dependent id="24">was</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="26">photographed</governor>
          <dependent id="25">being</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="21">told</governor>
          <dependent id="26">photographed</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">put</governor>
          <dependent id="28">she</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="1">Says</governor>
          <dependent id="29">put</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="29">put</governor>
          <dependent id="30">on</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="29">put</governor>
          <dependent id="31">sunglasses</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="36">had</governor>
          <dependent id="33">even</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="36">had</governor>
          <dependent id="34">though</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="36">had</governor>
          <dependent id="35">she</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="29">put</governor>
          <dependent id="36">had</dependent>
        </dependency>
        <dependency type="det">
          <governor id="38">IV</governor>
          <dependent id="37">an</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="36">had</governor>
          <dependent id="38">IV</dependent>
        </dependency>
        <dependency type="case">
          <governor id="41">arm</governor>
          <dependent id="39">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="41">arm</governor>
          <dependent id="40">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="38">IV</governor>
          <dependent id="41">arm</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="46">cover</governor>
          <dependent id="43">as</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="46">cover</governor>
          <dependent id="44">if</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="46">cover</governor>
          <dependent id="45">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="36">had</governor>
          <dependent id="46">cover</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="46">cover</governor>
          <dependent id="47">herself</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="46">cover</governor>
          <dependent id="48">up</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Levine" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Levine" />
          </tokens>
        </entity>
        <entity id="2" string="IV" type="NUMBER" score="0.0">
          <tokens>
            <token id="38" string="IV" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="77" has_coreference="true">
      <content>Typical Liz Taylor.</content>
      <tokens>
        <token id="1" string="Typical" lemma="typical" stem="typic" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="Liz" lemma="Liz" stem="liz" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="3" string="Taylor" lemma="Taylor" stem="taylor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="4" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (JJ Typical)) (NP (NNP Liz) (NNP Taylor)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Typical Liz Taylor ." type="NP">
          <tokens>
            <token id="1" string="Typical" />
            <token id="2" string="Liz" />
            <token id="3" string="Taylor" />
            <token id="4" string="." />
          </tokens>
        </chunking>
        <chunking id="2" string="Liz Taylor" type="NP">
          <tokens>
            <token id="2" string="Liz" />
            <token id="3" string="Taylor" />
          </tokens>
        </chunking>
        <chunking id="3" string="Typical" type="NP">
          <tokens>
            <token id="1" string="Typical" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">Typical</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Taylor</governor>
          <dependent id="2">Liz</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="1">Typical</governor>
          <dependent id="3">Taylor</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Liz Taylor" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Liz" />
            <token id="3" string="Taylor" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="78" has_coreference="true">
      <content>It was sad and sweet, at the same time.&amp;quot;</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="sad" lemma="sad" stem="sad" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="sweet" lemma="sweet" stem="sweet" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="same" lemma="same" stem="same" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBD was) (ADJP (JJ sad) (CC and) (JJ sweet) (, ,) (PP (IN at) (NP (DT the) (JJ same) (NN time))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="was sad and sweet , at the same time" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="sad" />
            <token id="4" string="and" />
            <token id="5" string="sweet" />
            <token id="6" string="," />
            <token id="7" string="at" />
            <token id="8" string="the" />
            <token id="9" string="same" />
            <token id="10" string="time" />
          </tokens>
        </chunking>
        <chunking id="2" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="3" string="sad and sweet , at the same time" type="ADJP">
          <tokens>
            <token id="3" string="sad" />
            <token id="4" string="and" />
            <token id="5" string="sweet" />
            <token id="6" string="," />
            <token id="7" string="at" />
            <token id="8" string="the" />
            <token id="9" string="same" />
            <token id="10" string="time" />
          </tokens>
        </chunking>
        <chunking id="4" string="the same time" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="same" />
            <token id="10" string="time" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">sad</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="3">sad</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">sad</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">sad</governor>
          <dependent id="4">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">sad</governor>
          <dependent id="5">sweet</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">time</governor>
          <dependent id="7">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">time</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">time</governor>
          <dependent id="9">same</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">sad</governor>
          <dependent id="10">time</dependent>
        </dependency>
      </dependencies>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="2" type="NOMINAL">
      <referenced ids_tokens="16-17" string="the world" id_sentence="1" />
      <mentions>
        <mention ids_tokens="16-18" string="the world's" id_sentence="49" />
      </mentions>
    </coreference>
    <coreference id="3" type="PROPER">
      <referenced ids_tokens="1-2-3" string="Liz Taylor 's" id_sentence="2" />
      <mentions>
        <mention ids_tokens="3-6" string="Liz Taylor , 58" id_sentence="5" />
        <mention ids_tokens="3-4" string="Liz Taylor" id_sentence="5" />
        <mention ids_tokens="2" string="she" id_sentence="6" />
        <mention ids_tokens="15" string="she" id_sentence="6" />
        <mention ids_tokens="11-12" string="Liz Taylor" id_sentence="11" />
        <mention ids_tokens="17" string="she" id_sentence="11" />
        <mention ids_tokens="6" string="her" id_sentence="14" />
        <mention ids_tokens="22" string="her" id_sentence="15" />
        <mention ids_tokens="2-3" string="Liz Taylor" id_sentence="77" />
      </mentions>
    </coreference>
    <coreference id="4" type="NOMINAL">
      <referenced ids_tokens="1-2-3-4-5-6-7" string="Liz Taylor 's latest bout with pneumonia" id_sentence="2" />
      <mentions>
        <mention ids_tokens="1" string="It" id_sentence="3" />
      </mentions>
    </coreference>
    <coreference id="6" type="NOMINAL">
      <referenced ids_tokens="1-2-3-4" string="Typical Liz Taylor ." id_sentence="77" />
      <mentions>
        <mention ids_tokens="1" string="It" id_sentence="78" />
      </mentions>
    </coreference>
    <coreference id="7" type="NOMINAL">
      <referenced ids_tokens="11-12-13-14" string="a life of extremes" id_sentence="5" />
      <mentions>
        <mention ids_tokens="21-22" string="her life" id_sentence="45" />
      </mentions>
    </coreference>
    <coreference id="9" type="NOMINAL">
      <referenced ids_tokens="5-6-7-8" string="the most brilliant career" id_sentence="6" />
      <mentions>
        <mention ids_tokens="3-4" string="it all" id_sentence="7" />
        <mention ids_tokens="1" string="It" id_sentence="8" />
      </mentions>
    </coreference>
    <coreference id="10" type="PROPER">
      <referenced ids_tokens="9-10" string="Taylor 's" id_sentence="8" />
      <mentions>
        <mention ids_tokens="25" string="his" id_sentence="13" />
        <mention ids_tokens="1" string="Taylor" id_sentence="27" />
        <mention ids_tokens="2" string="Taylor" id_sentence="38" />
        <mention ids_tokens="19" string="Taylor" id_sentence="44" />
        <mention ids_tokens="4" string="Taylor" id_sentence="46" />
        <mention ids_tokens="3" string="Taylor" id_sentence="47" />
        <mention ids_tokens="1-15" string="Taylor , the first celebrity known to enter the Betty Ford clinic in Rancho Mirage" id_sentence="59" />
        <mention ids_tokens="1" string="Taylor" id_sentence="59" />
        <mention ids_tokens="3-15" string="the first celebrity known to enter the Betty Ford clinic in Rancho Mirage" id_sentence="59" />
        <mention ids_tokens="2" string="Taylor" id_sentence="60" />
        <mention ids_tokens="7" string="Taylor" id_sentence="70" />
        <mention ids_tokens="1" string="Taylor" id_sentence="72" />
      </mentions>
    </coreference>
    <coreference id="11" type="NOMINAL">
      <referenced ids_tokens="5-6-7" string="still the gossips" id_sentence="8" />
      <mentions>
        <mention ids_tokens="4" string="they" id_sentence="9" />
      </mentions>
    </coreference>
    <coreference id="12" type="NOMINAL">
      <referenced ids_tokens="9-10-11" string="Taylor 's doctors" id_sentence="8" />
      <mentions>
        <mention ids_tokens="26-27" string="the doctors" id_sentence="22" />
        <mention ids_tokens="11" string="doctors" id_sentence="28" />
        <mention ids_tokens="13" string="doctors" id_sentence="38" />
        <mention ids_tokens="30" string="doctors" id_sentence="48" />
        <mention ids_tokens="33-44" string="Taylor's doctors , who had been accused of over-prescribing dependence-forming drugs" id_sentence="58" />
      </mentions>
    </coreference>
    <coreference id="13" type="PROPER">
      <referenced ids_tokens="16" string="Wednesday" id_sentence="8" />
      <mentions>
        <mention ids_tokens="7-8" string="Wednesday's" id_sentence="38" />
      </mentions>
    </coreference>
    <coreference id="14" type="PROPER">
      <referenced ids_tokens="14" string="AIDS" id_sentence="11" />
      <mentions>
        <mention ids_tokens="3" string="it" id_sentence="14" />
      </mentions>
    </coreference>
    <coreference id="15" type="PROPER">
      <referenced ids_tokens="25-26-27" string="Marina del Rey" id_sentence="11" />
      <mentions>
        <mention ids_tokens="63" string="Marina" id_sentence="17" />
      </mentions>
    </coreference>
    <coreference id="16" type="NOMINAL">
      <referenced ids_tokens="2-3-4" string="the tabloid press" id_sentence="11" />
      <mentions>
        <mention ids_tokens="11-12" string="the press" id_sentence="12" />
      </mentions>
    </coreference>
    <coreference id="17" type="PROPER">
      <referenced ids_tokens="21-22-23-24-25-26-27" string="Daniel Freeman Hospital in Marina del Rey" id_sentence="11" />
      <mentions>
        <mention ids_tokens="11-12" string="the hospital" id_sentence="16" />
        <mention ids_tokens="16" string="it" id_sentence="16" />
        <mention ids_tokens="31" string="it" id_sentence="16" />
      </mentions>
    </coreference>
    <coreference id="19" type="PROPER">
      <referenced ids_tokens="15-16" string="Malcolm Forbes" id_sentence="13" />
      <mentions>
        <mention ids_tokens="26" string="Forbes" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="20" type="PROPER">
      <referenced ids_tokens="8-9" string="Michael Roth" id_sentence="15" />
      <mentions>
        <mention ids_tokens="14" string="I" id_sentence="16" />
      </mentions>
    </coreference>
    <coreference id="22" type="PROPER">
      <referenced ids_tokens="9-10-11-12-13-14-15-16-17-18-19-20-21-22-23" string="the same charmingly vain Liz who once declared her hobbies to be clothes and jewels" id_sentence="73" />
      <mentions>
        <mention ids_tokens="2" string="Liz" id_sentence="16" />
        <mention ids_tokens="9" string="she" id_sentence="16" />
        <mention ids_tokens="1" string="Liz" id_sentence="17" />
        <mention ids_tokens="27" string="her" id_sentence="17" />
        <mention ids_tokens="47" string="Liz" id_sentence="17" />
        <mention ids_tokens="4-5" string="Liz's" id_sentence="20" />
        <mention ids_tokens="17" string="her" id_sentence="20" />
        <mention ids_tokens="20" string="her" id_sentence="23" />
        <mention ids_tokens="12" string="her" id_sentence="24" />
        <mention ids_tokens="27-28" string="Liz's" id_sentence="32" />
        <mention ids_tokens="2-3" string="Liz's" id_sentence="37" />
        <mention ids_tokens="8" string="her" id_sentence="37" />
        <mention ids_tokens="33" string="she" id_sentence="37" />
        <mention ids_tokens="36" string="her" id_sentence="37" />
        <mention ids_tokens="30" string="she" id_sentence="38" />
        <mention ids_tokens="4" string="she" id_sentence="39" />
        <mention ids_tokens="2" string="She" id_sentence="40" />
        <mention ids_tokens="12" string="she" id_sentence="40" />
        <mention ids_tokens="16" string="she" id_sentence="40" />
        <mention ids_tokens="1" string="She" id_sentence="42" />
        <mention ids_tokens="7-20" string="Liz , hobbled by back pain , returning to those two sources of comfort" id_sentence="71" />
        <mention ids_tokens="7" string="Liz" id_sentence="71" />
        <mention ids_tokens="13" string="Liz" id_sentence="75" />
        <mention ids_tokens="21" string="Liz" id_sentence="75" />
      </mentions>
    </coreference>
    <coreference id="23" type="PROPER">
      <referenced ids_tokens="21-22-23-24-25-26-27" string="the President of the U.S. going in" id_sentence="16" />
      <mentions>
        <mention ids_tokens="45" string="President" id_sentence="47" />
      </mentions>
    </coreference>
    <coreference id="24" type="PRONOMINAL">
      <referenced ids_tokens="29" string="we" id_sentence="16" />
      <mentions>
        <mention ids_tokens="14" string="our" id_sentence="17" />
      </mentions>
    </coreference>
    <coreference id="25" type="PROPER">
      <referenced ids_tokens="31-32" string="Barry Levine" id_sentence="17" />
      <mentions>
        <mention ids_tokens="1" string="Levine" id_sentence="18" />
      </mentions>
    </coreference>
    <coreference id="26" type="PROPER">
      <referenced ids_tokens="68-69-70" string="St. John 's" id_sentence="17" />
      <mentions>
        <mention ids_tokens="11-29" string="St. John's , many of whom had flown in from around the country for the 15-minute press conference" id_sentence="21" />
      </mentions>
    </coreference>
    <coreference id="27" type="PROPER">
      <referenced ids_tokens="2-3-4-5" string="the Star 's Levine" id_sentence="76" />
      <mentions>
        <mention ids_tokens="31-70" string="Barry Levine , Hollywood bureau chief of the Star , which featured a cover photograph of Liz , hooked up to an intravenous tube and oxygen mask , being transferred from the Marina del Rey hospital to St. John's" id_sentence="17" />
      </mentions>
    </coreference>
    <coreference id="28" type="PROPER">
      <referenced ids_tokens="10" string="Star" id_sentence="75" />
      <mentions>
        <mention ids_tokens="38-39" string="the Star" id_sentence="17" />
        <mention ids_tokens="3-4" string="Star's" id_sentence="76" />
      </mentions>
    </coreference>
    <coreference id="31" type="PROPER">
      <referenced ids_tokens="20-21" string="Chen Sam" id_sentence="20" />
      <mentions>
        <mention ids_tokens="26" string="Sam" id_sentence="30" />
      </mentions>
    </coreference>
    <coreference id="32" type="NOMINAL">
      <referenced ids_tokens="23-24-25-26-27-28-29" string="the country for the 15-minute press conference" id_sentence="21" />
      <mentions>
        <mention ids_tokens="38-39" string="the country" id_sentence="44" />
      </mentions>
    </coreference>
    <coreference id="33" type="LIST">
      <referenced ids_tokens="10-11-12-13-14-15-16-17-18-19-20-21" string="the major networks , the local stations , CNN and the tabloid" id_sentence="22" />
      <mentions>
        <mention ids_tokens="2" string="I" id_sentence="23" />
        <mention ids_tokens="8" string="me" id_sentence="23" />
        <mention ids_tokens="13" string="I" id_sentence="23" />
        <mention ids_tokens="1" string="I" id_sentence="24" />
      </mentions>
    </coreference>
    <coreference id="36" type="PROPER">
      <referenced ids_tokens="8-9-10" string="the Washington Times" id_sentence="25" />
      <mentions>
        <mention ids_tokens="23" string="times" id_sentence="49" />
      </mentions>
    </coreference>
    <coreference id="37" type="NOMINAL">
      <referenced ids_tokens="8-9" string="the respirator" id_sentence="35" />
      <mentions>
        <mention ids_tokens="4-14" string="a respirator and breathing with the help of an oxygen mask" id_sentence="27" />
      </mentions>
    </coreference>
    <coreference id="38" type="PRONOMINAL">
      <referenced ids_tokens="1" string="She" id_sentence="28" />
      <mentions>
        <mention ids_tokens="16" string="her" id_sentence="29" />
        <mention ids_tokens="3" string="her" id_sentence="31" />
        <mention ids_tokens="10" string="her" id_sentence="31" />
        <mention ids_tokens="4" string="her" id_sentence="32" />
        <mention ids_tokens="4" string="her" id_sentence="33" />
        <mention ids_tokens="4" string="her" id_sentence="34" />
        <mention ids_tokens="1" string="Her" id_sentence="36" />
        <mention ids_tokens="34" string="her" id_sentence="38" />
        <mention ids_tokens="2" string="I" id_sentence="39" />
      </mentions>
    </coreference>
    <coreference id="39" type="PROPER">
      <referenced ids_tokens="6-7-8" string="a bad weekend" id_sentence="28" />
      <mentions>
        <mention ids_tokens="23-24" string="this weekend" id_sentence="30" />
      </mentions>
    </coreference>
    <coreference id="41" type="NOMINAL">
      <referenced ids_tokens="10-11-12-13-14-15" string="her private room in intensive care" id_sentence="31" />
      <mentions>
        <mention ids_tokens="5-6" string="her room" id_sentence="74" />
      </mentions>
    </coreference>
    <coreference id="42" type="PROPER">
      <referenced ids_tokens="23-24-25" string="Carole Bayer Sager" id_sentence="32" />
      <mentions>
        <mention ids_tokens="13" string="Sager" id_sentence="33" />
        <mention ids_tokens="10" string="Sager" id_sentence="39" />
      </mentions>
    </coreference>
    <coreference id="43" type="NOMINAL">
      <referenced ids_tokens="27-28-29-30-31-32" string="Liz 's younger , ex-trucker boyfriend" id_sentence="32" />
      <mentions>
        <mention ids_tokens="2" string="I" id_sentence="33" />
        <mention ids_tokens="7" string="I" id_sentence="33" />
        <mention ids_tokens="2" string="I" id_sentence="34" />
        <mention ids_tokens="10" string="I" id_sentence="36" />
        <mention ids_tokens="16" string="me" id_sentence="36" />
        <mention ids_tokens="27" string="you" id_sentence="38" />
      </mentions>
    </coreference>
    <coreference id="44" type="NOMINAL">
      <referenced ids_tokens="5-6-7-8-9-10" string="an enormous reservoir of inner strength" id_sentence="40" />
      <mentions>
        <mention ids_tokens="4" string="it" id_sentence="42" />
      </mentions>
    </coreference>
    <coreference id="45" type="PROPER">
      <referenced ids_tokens="19" string="Elizabeth" id_sentence="45" />
      <mentions>
        <mention ids_tokens="13" string="her" id_sentence="46" />
        <mention ids_tokens="23" string="her" id_sentence="46" />
        <mention ids_tokens="18" string="her" id_sentence="47" />
        <mention ids_tokens="25" string="she" id_sentence="47" />
        <mention ids_tokens="33" string="her" id_sentence="47" />
        <mention ids_tokens="4" string="she" id_sentence="48" />
        <mention ids_tokens="12" string="her" id_sentence="48" />
        <mention ids_tokens="35" string="her" id_sentence="48" />
        <mention ids_tokens="38" string="she" id_sentence="48" />
        <mention ids_tokens="5" string="her" id_sentence="49" />
      </mentions>
    </coreference>
    <coreference id="47" type="PROPER">
      <referenced ids_tokens="2-3" string="the years" id_sentence="48" />
      <mentions>
        <mention ids_tokens="2" string="it" id_sentence="49" />
        <mention ids_tokens="5-25" string="her wrestling matches with weight and addiction that have consistently lured the world's curiosity and , at times , admiration" id_sentence="49" />
      </mentions>
    </coreference>
    <coreference id="48" type="NOMINAL">
      <referenced ids_tokens="6-7-8-9" string="a politician 's wife" id_sentence="50" />
      <mentions>
        <mention ids_tokens="2" string="she" id_sentence="51" />
        <mention ids_tokens="22" string="she" id_sentence="51" />
        <mention ids_tokens="41" string="her" id_sentence="51" />
      </mentions>
    </coreference>
    <coreference id="49" type="NOMINAL">
      <referenced ids_tokens="4-5-6" string="a born-again beauty" id_sentence="51" />
      <mentions>
        <mention ids_tokens="10" string="it" id_sentence="52" />
      </mentions>
    </coreference>
    <coreference id="51" type="PROPER">
      <referenced ids_tokens="23-24" string="the time" id_sentence="52" />
      <mentions>
        <mention ids_tokens="2" string="I" id_sentence="53" />
        <mention ids_tokens="1" string="I" id_sentence="54" />
        <mention ids_tokens="2" string="I" id_sentence="55" />
        <mention ids_tokens="4" string="myself" id_sentence="55" />
        <mention ids_tokens="18" string="me" id_sentence="55" />
        <mention ids_tokens="12-22" string="probably the first time since I was 9 that nobody's" id_sentence="61" />
        <mention ids_tokens="8-10" string="the same time" id_sentence="78" />
      </mentions>
    </coreference>
    <coreference id="52" type="NOMINAL">
      <referenced ids_tokens="14-15-16-17-18" string="the right weight for me" id_sentence="55" />
      <mentions>
        <mention ids_tokens="5-6" string="the weight" id_sentence="72" />
      </mentions>
    </coreference>
    <coreference id="55" type="PROPER">
      <referenced ids_tokens="10-11" string="Betty Ford" id_sentence="59" />
      <mentions>
        <mention ids_tokens="10" string="she" id_sentence="60" />
        <mention ids_tokens="1" string="She" id_sentence="61" />
        <mention ids_tokens="17" string="I" id_sentence="61" />
        <mention ids_tokens="26" string="me" id_sentence="61" />
        <mention ids_tokens="1" string="I" id_sentence="63" />
        <mention ids_tokens="1" string="I" id_sentence="64" />
        <mention ids_tokens="1" string="My" id_sentence="65" />
        <mention ids_tokens="1" string="I" id_sentence="66" />
        <mention ids_tokens="8" string="my" id_sentence="66" />
        <mention ids_tokens="1" string="I" id_sentence="67" />
        <mention ids_tokens="15" string="my" id_sentence="67" />
        <mention ids_tokens="23" string="my" id_sentence="67" />
        <mention ids_tokens="27" string="my" id_sentence="67" />
        <mention ids_tokens="1" string="My" id_sentence="68" />
        <mention ids_tokens="4" string="I" id_sentence="69" />
        <mention ids_tokens="17" string="her" id_sentence="70" />
      </mentions>
    </coreference>
    <coreference id="57" type="NOMINAL">
      <referenced ids_tokens="9-10-11-12-13-14-15" string="the Betty Ford clinic in Rancho Mirage" id_sentence="59" />
      <mentions>
        <mention ids_tokens="2-5" string="the Betty Ford clinic" id_sentence="70" />
      </mentions>
    </coreference>
    <coreference id="58" type="NOMINAL">
      <referenced ids_tokens="4-5-6" string="the blood rush" id_sentence="66" />
      <mentions>
        <mention ids_tokens="5" string="it" id_sentence="67" />
      </mentions>
    </coreference>
    <coreference id="59" type="PROPER">
      <referenced ids_tokens="2-3-4" string="the late '80s" id_sentence="71" />
      <mentions>
        <mention ids_tokens="10" string="she" id_sentence="72" />
        <mention ids_tokens="12" string="her" id_sentence="72" />
        <mention ids_tokens="3" string="her" id_sentence="73" />
        <mention ids_tokens="6" string="she" id_sentence="73" />
        <mention ids_tokens="17" string="her" id_sentence="73" />
        <mention ids_tokens="1" string="She" id_sentence="74" />
        <mention ids_tokens="5" string="her" id_sentence="74" />
        <mention ids_tokens="11" string="her" id_sentence="74" />
        <mention ids_tokens="4" string="she" id_sentence="75" />
        <mention ids_tokens="12" string="she" id_sentence="76" />
        <mention ids_tokens="22" string="her" id_sentence="76" />
        <mention ids_tokens="23" string="she" id_sentence="76" />
        <mention ids_tokens="28" string="she" id_sentence="76" />
        <mention ids_tokens="35" string="she" id_sentence="76" />
        <mention ids_tokens="40" string="her" id_sentence="76" />
        <mention ids_tokens="47" string="herself" id_sentence="76" />
      </mentions>
    </coreference>
  </coreferences>
</document>
