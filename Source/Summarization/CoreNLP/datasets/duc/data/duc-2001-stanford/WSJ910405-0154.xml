<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="WSJ910405-0154">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>A police chief plays an essential role in setting the climate in which his department operates.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="chief" lemma="chief" stem="chief" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="plays" lemma="play" stem="plai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="essential" lemma="essential" stem="essenti" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="role" lemma="role" stem="role" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="setting" lemma="set" stem="set" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="climate" lemma="climate" stem="climat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="15" string="department" lemma="department" stem="depart" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="operates" lemma="operate" stem="oper" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT A) (NN police) (NN chief)) (VP (VBZ plays) (NP (DT an) (JJ essential) (NN role)) (PP (IN in) (S (VP (VBG setting) (NP (NP (DT the) (NN climate)) (SBAR (WHPP (IN in) (WHNP (WDT which))) (S (NP (PRP$ his) (NN department)) (VP (VBZ operates))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="an essential role" type="NP">
          <tokens>
            <token id="5" string="an" />
            <token id="6" string="essential" />
            <token id="7" string="role" />
          </tokens>
        </chunking>
        <chunking id="2" string="operates" type="VP">
          <tokens>
            <token id="16" string="operates" />
          </tokens>
        </chunking>
        <chunking id="3" string="his department" type="NP">
          <tokens>
            <token id="14" string="his" />
            <token id="15" string="department" />
          </tokens>
        </chunking>
        <chunking id="4" string="A police chief" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="police" />
            <token id="3" string="chief" />
          </tokens>
        </chunking>
        <chunking id="5" string="the climate in which his department operates" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="climate" />
            <token id="12" string="in" />
            <token id="13" string="which" />
            <token id="14" string="his" />
            <token id="15" string="department" />
            <token id="16" string="operates" />
          </tokens>
        </chunking>
        <chunking id="6" string="in which his department operates" type="SBAR">
          <tokens>
            <token id="12" string="in" />
            <token id="13" string="which" />
            <token id="14" string="his" />
            <token id="15" string="department" />
            <token id="16" string="operates" />
          </tokens>
        </chunking>
        <chunking id="7" string="setting the climate in which his department operates" type="VP">
          <tokens>
            <token id="9" string="setting" />
            <token id="10" string="the" />
            <token id="11" string="climate" />
            <token id="12" string="in" />
            <token id="13" string="which" />
            <token id="14" string="his" />
            <token id="15" string="department" />
            <token id="16" string="operates" />
          </tokens>
        </chunking>
        <chunking id="8" string="plays an essential role in setting the climate in which his department operates" type="VP">
          <tokens>
            <token id="4" string="plays" />
            <token id="5" string="an" />
            <token id="6" string="essential" />
            <token id="7" string="role" />
            <token id="8" string="in" />
            <token id="9" string="setting" />
            <token id="10" string="the" />
            <token id="11" string="climate" />
            <token id="12" string="in" />
            <token id="13" string="which" />
            <token id="14" string="his" />
            <token id="15" string="department" />
            <token id="16" string="operates" />
          </tokens>
        </chunking>
        <chunking id="9" string="the climate" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="climate" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">chief</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">chief</governor>
          <dependent id="2">police</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">plays</governor>
          <dependent id="3">chief</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">plays</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">role</governor>
          <dependent id="5">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">role</governor>
          <dependent id="6">essential</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">plays</governor>
          <dependent id="7">role</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">setting</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">plays</governor>
          <dependent id="9">setting</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">climate</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">setting</governor>
          <dependent id="11">climate</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">which</governor>
          <dependent id="12">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">operates</governor>
          <dependent id="13">which</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">department</governor>
          <dependent id="14">his</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">operates</governor>
          <dependent id="15">department</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="11">climate</governor>
          <dependent id="16">operates</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>Through the years Mr. Gates has made public statements clearly at odds with the new concept of community policing, in which officers work with citizens to improve neighborhoods and prevent crime.</content>
      <tokens>
        <token id="1" string="Through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="3" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="4" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="Gates" lemma="Gates" stem="gate" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="made" lemma="make" stem="made" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="public" lemma="public" stem="public" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="statements" lemma="statement" stem="statement" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="clearly" lemma="clearly" stem="clearli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="odds" lemma="odds" stem="odd" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="new" lemma="new" stem="new" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="concept" lemma="concept" stem="concept" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="community" lemma="community" stem="commun" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="policing" lemma="police" stem="polic" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="24" string="work" lemma="work" stem="work" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="25" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="citizens" lemma="citizen" stem="citizen" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="27" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="28" string="improve" lemma="improve" stem="improv" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="29" string="neighborhoods" lemma="neighborhood" stem="neighborhood" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="30" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="prevent" lemma="prevent" stem="prevent" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="32" string="crime" lemma="crime" stem="crime" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN Through) (NP (DT the) (NNS years))) (NP (NNP Mr.) (NNP Gates)) (VP (VBZ has) (VP (VBN made) (NP (JJ public) (NNS statements)) (ADVP (RB clearly)) (PP (IN at) (NP (NP (NNS odds)) (PP (IN with) (NP (NP (DT the) (JJ new) (NN concept)) (PP (IN of) (NP (NP (NN community)) (VP (VBG policing)) (, ,) (SBAR (WHPP (IN in) (WHNP (WDT which))) (S (NP (NNS officers)) (VP (VP (VBP work) (PP (IN with) (NP (NNS citizens))) (S (VP (TO to) (VP (VB improve) (NP (NNS neighborhoods)))))) (CC and) (VP (VBP prevent) (NP (NN crime)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="community policing , in which officers work with citizens to improve neighborhoods and prevent crime" type="NP">
          <tokens>
            <token id="18" string="community" />
            <token id="19" string="policing" />
            <token id="20" string="," />
            <token id="21" string="in" />
            <token id="22" string="which" />
            <token id="23" string="officers" />
            <token id="24" string="work" />
            <token id="25" string="with" />
            <token id="26" string="citizens" />
            <token id="27" string="to" />
            <token id="28" string="improve" />
            <token id="29" string="neighborhoods" />
            <token id="30" string="and" />
            <token id="31" string="prevent" />
            <token id="32" string="crime" />
          </tokens>
        </chunking>
        <chunking id="2" string="policing" type="VP">
          <tokens>
            <token id="19" string="policing" />
          </tokens>
        </chunking>
        <chunking id="3" string="neighborhoods" type="NP">
          <tokens>
            <token id="29" string="neighborhoods" />
          </tokens>
        </chunking>
        <chunking id="4" string="the years" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="years" />
          </tokens>
        </chunking>
        <chunking id="5" string="work with citizens to improve neighborhoods" type="VP">
          <tokens>
            <token id="24" string="work" />
            <token id="25" string="with" />
            <token id="26" string="citizens" />
            <token id="27" string="to" />
            <token id="28" string="improve" />
            <token id="29" string="neighborhoods" />
          </tokens>
        </chunking>
        <chunking id="6" string="in which officers work with citizens to improve neighborhoods and prevent crime" type="SBAR">
          <tokens>
            <token id="21" string="in" />
            <token id="22" string="which" />
            <token id="23" string="officers" />
            <token id="24" string="work" />
            <token id="25" string="with" />
            <token id="26" string="citizens" />
            <token id="27" string="to" />
            <token id="28" string="improve" />
            <token id="29" string="neighborhoods" />
            <token id="30" string="and" />
            <token id="31" string="prevent" />
            <token id="32" string="crime" />
          </tokens>
        </chunking>
        <chunking id="7" string="improve neighborhoods" type="VP">
          <tokens>
            <token id="28" string="improve" />
            <token id="29" string="neighborhoods" />
          </tokens>
        </chunking>
        <chunking id="8" string="community" type="NP">
          <tokens>
            <token id="18" string="community" />
          </tokens>
        </chunking>
        <chunking id="9" string="made public statements clearly at odds with the new concept of community policing , in which officers work with citizens to improve neighborhoods and prevent crime" type="VP">
          <tokens>
            <token id="7" string="made" />
            <token id="8" string="public" />
            <token id="9" string="statements" />
            <token id="10" string="clearly" />
            <token id="11" string="at" />
            <token id="12" string="odds" />
            <token id="13" string="with" />
            <token id="14" string="the" />
            <token id="15" string="new" />
            <token id="16" string="concept" />
            <token id="17" string="of" />
            <token id="18" string="community" />
            <token id="19" string="policing" />
            <token id="20" string="," />
            <token id="21" string="in" />
            <token id="22" string="which" />
            <token id="23" string="officers" />
            <token id="24" string="work" />
            <token id="25" string="with" />
            <token id="26" string="citizens" />
            <token id="27" string="to" />
            <token id="28" string="improve" />
            <token id="29" string="neighborhoods" />
            <token id="30" string="and" />
            <token id="31" string="prevent" />
            <token id="32" string="crime" />
          </tokens>
        </chunking>
        <chunking id="10" string="the new concept of community policing , in which officers work with citizens to improve neighborhoods and prevent crime" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="new" />
            <token id="16" string="concept" />
            <token id="17" string="of" />
            <token id="18" string="community" />
            <token id="19" string="policing" />
            <token id="20" string="," />
            <token id="21" string="in" />
            <token id="22" string="which" />
            <token id="23" string="officers" />
            <token id="24" string="work" />
            <token id="25" string="with" />
            <token id="26" string="citizens" />
            <token id="27" string="to" />
            <token id="28" string="improve" />
            <token id="29" string="neighborhoods" />
            <token id="30" string="and" />
            <token id="31" string="prevent" />
            <token id="32" string="crime" />
          </tokens>
        </chunking>
        <chunking id="11" string="work with citizens to improve neighborhoods and prevent crime" type="VP">
          <tokens>
            <token id="24" string="work" />
            <token id="25" string="with" />
            <token id="26" string="citizens" />
            <token id="27" string="to" />
            <token id="28" string="improve" />
            <token id="29" string="neighborhoods" />
            <token id="30" string="and" />
            <token id="31" string="prevent" />
            <token id="32" string="crime" />
          </tokens>
        </chunking>
        <chunking id="12" string="has made public statements clearly at odds with the new concept of community policing , in which officers work with citizens to improve neighborhoods and prevent crime" type="VP">
          <tokens>
            <token id="6" string="has" />
            <token id="7" string="made" />
            <token id="8" string="public" />
            <token id="9" string="statements" />
            <token id="10" string="clearly" />
            <token id="11" string="at" />
            <token id="12" string="odds" />
            <token id="13" string="with" />
            <token id="14" string="the" />
            <token id="15" string="new" />
            <token id="16" string="concept" />
            <token id="17" string="of" />
            <token id="18" string="community" />
            <token id="19" string="policing" />
            <token id="20" string="," />
            <token id="21" string="in" />
            <token id="22" string="which" />
            <token id="23" string="officers" />
            <token id="24" string="work" />
            <token id="25" string="with" />
            <token id="26" string="citizens" />
            <token id="27" string="to" />
            <token id="28" string="improve" />
            <token id="29" string="neighborhoods" />
            <token id="30" string="and" />
            <token id="31" string="prevent" />
            <token id="32" string="crime" />
          </tokens>
        </chunking>
        <chunking id="13" string="odds" type="NP">
          <tokens>
            <token id="12" string="odds" />
          </tokens>
        </chunking>
        <chunking id="14" string="odds with the new concept of community policing , in which officers work with citizens to improve neighborhoods and prevent crime" type="NP">
          <tokens>
            <token id="12" string="odds" />
            <token id="13" string="with" />
            <token id="14" string="the" />
            <token id="15" string="new" />
            <token id="16" string="concept" />
            <token id="17" string="of" />
            <token id="18" string="community" />
            <token id="19" string="policing" />
            <token id="20" string="," />
            <token id="21" string="in" />
            <token id="22" string="which" />
            <token id="23" string="officers" />
            <token id="24" string="work" />
            <token id="25" string="with" />
            <token id="26" string="citizens" />
            <token id="27" string="to" />
            <token id="28" string="improve" />
            <token id="29" string="neighborhoods" />
            <token id="30" string="and" />
            <token id="31" string="prevent" />
            <token id="32" string="crime" />
          </tokens>
        </chunking>
        <chunking id="15" string="prevent crime" type="VP">
          <tokens>
            <token id="31" string="prevent" />
            <token id="32" string="crime" />
          </tokens>
        </chunking>
        <chunking id="16" string="the new concept" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="new" />
            <token id="16" string="concept" />
          </tokens>
        </chunking>
        <chunking id="17" string="crime" type="NP">
          <tokens>
            <token id="32" string="crime" />
          </tokens>
        </chunking>
        <chunking id="18" string="public statements" type="NP">
          <tokens>
            <token id="8" string="public" />
            <token id="9" string="statements" />
          </tokens>
        </chunking>
        <chunking id="19" string="Mr. Gates" type="NP">
          <tokens>
            <token id="4" string="Mr." />
            <token id="5" string="Gates" />
          </tokens>
        </chunking>
        <chunking id="20" string="officers" type="NP">
          <tokens>
            <token id="23" string="officers" />
          </tokens>
        </chunking>
        <chunking id="21" string="citizens" type="NP">
          <tokens>
            <token id="26" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="22" string="to improve neighborhoods" type="VP">
          <tokens>
            <token id="27" string="to" />
            <token id="28" string="improve" />
            <token id="29" string="neighborhoods" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">years</governor>
          <dependent id="1">Through</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">years</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">made</governor>
          <dependent id="3">years</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Gates</governor>
          <dependent id="4">Mr.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">made</governor>
          <dependent id="5">Gates</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">made</governor>
          <dependent id="6">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">made</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">statements</governor>
          <dependent id="8">public</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">made</governor>
          <dependent id="9">statements</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">made</governor>
          <dependent id="10">clearly</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">odds</governor>
          <dependent id="11">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">made</governor>
          <dependent id="12">odds</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">concept</governor>
          <dependent id="13">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">concept</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">concept</governor>
          <dependent id="15">new</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">odds</governor>
          <dependent id="16">concept</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">community</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">concept</governor>
          <dependent id="18">community</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="18">community</governor>
          <dependent id="19">policing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">which</governor>
          <dependent id="21">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">work</governor>
          <dependent id="22">which</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">work</governor>
          <dependent id="23">officers</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="18">community</governor>
          <dependent id="24">work</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">citizens</governor>
          <dependent id="25">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">work</governor>
          <dependent id="26">citizens</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="28">improve</governor>
          <dependent id="27">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="24">work</governor>
          <dependent id="28">improve</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="28">improve</governor>
          <dependent id="29">neighborhoods</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="24">work</governor>
          <dependent id="30">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="24">work</governor>
          <dependent id="31">prevent</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="31">prevent</governor>
          <dependent id="32">crime</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Gates" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Gates" />
          </tokens>
        </entity>
        <entity id="2" string="the years" type="DURATION" score="0.0">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="years" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>A few years ago Chief Gates referred to gang members as &amp;quot;dirty little cowards,&amp;quot; and warned them that &amp;quot;there is resounding applause to every fall of the hammer.&amp;quot;</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="2" string="few" lemma="few" stem="few" pos="JJ" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="ago" lemma="ago" stem="ago" pos="IN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="Chief" lemma="Chief" stem="chief" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="true" is_refers="false" />
        <token id="6" string="Gates" lemma="Gates" stem="gate" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="referred" lemma="refer" stem="refer" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="gang" lemma="gang" stem="gang" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="members" lemma="member" stem="member" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="dirty" lemma="dirty" stem="dirti" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="little" lemma="little" stem="littl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="cowards" lemma="coward" stem="coward" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="warned" lemma="warn" stem="warn" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="resounding" lemma="resounding" stem="resound" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="applause" lemma="applause" stem="applaus" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="every" lemma="every" stem="everi" pos="DT" type="Word" isStopWord="false" ner="SET" is_referenced="false" is_refers="false" />
        <token id="29" string="fall" lemma="fall" stem="fall" pos="NN" type="Word" isStopWord="false" ner="SET" is_referenced="false" is_refers="false" />
        <token id="30" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="hammer" lemma="hammer" stem="hammer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (NP (DT A) (JJ few) (NNS years)) (IN ago)) (NP (NNP Chief) (NNP Gates)) (VP (VP (VBD referred) (PP (TO to) (NP (NN gang) (NNS members))) (PP (IN as) (`` ``) (NP (JJ dirty) (JJ little) (NNS cowards)))) (, ,) ('' '') (CC and) (VP (VBD warned) (NP (PRP them)) (SBAR (IN that) (`` ``) (S (NP (EX there)) (VP (VBZ is) (NP (NP (JJ resounding) (NN applause)) (PP (TO to) (NP (NP (DT every) (NN fall)) (PP (IN of) (NP (DT the) (NN hammer))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="the hammer" type="NP">
          <tokens>
            <token id="31" string="the" />
            <token id="32" string="hammer" />
          </tokens>
        </chunking>
        <chunking id="2" string="gang members" type="NP">
          <tokens>
            <token id="9" string="gang" />
            <token id="10" string="members" />
          </tokens>
        </chunking>
        <chunking id="3" string="Chief Gates" type="NP">
          <tokens>
            <token id="5" string="Chief" />
            <token id="6" string="Gates" />
          </tokens>
        </chunking>
        <chunking id="4" string="every fall of the hammer" type="NP">
          <tokens>
            <token id="28" string="every" />
            <token id="29" string="fall" />
            <token id="30" string="of" />
            <token id="31" string="the" />
            <token id="32" string="hammer" />
          </tokens>
        </chunking>
        <chunking id="5" string="dirty little cowards" type="NP">
          <tokens>
            <token id="13" string="dirty" />
            <token id="14" string="little" />
            <token id="15" string="cowards" />
          </tokens>
        </chunking>
        <chunking id="6" string="them" type="NP">
          <tokens>
            <token id="20" string="them" />
          </tokens>
        </chunking>
        <chunking id="7" string="resounding applause" type="NP">
          <tokens>
            <token id="25" string="resounding" />
            <token id="26" string="applause" />
          </tokens>
        </chunking>
        <chunking id="8" string="there" type="NP">
          <tokens>
            <token id="23" string="there" />
          </tokens>
        </chunking>
        <chunking id="9" string="every fall" type="NP">
          <tokens>
            <token id="28" string="every" />
            <token id="29" string="fall" />
          </tokens>
        </chunking>
        <chunking id="10" string="that `` there is resounding applause to every fall of the hammer" type="SBAR">
          <tokens>
            <token id="21" string="that" />
            <token id="22" string="&quot;" />
            <token id="23" string="there" />
            <token id="24" string="is" />
            <token id="25" string="resounding" />
            <token id="26" string="applause" />
            <token id="27" string="to" />
            <token id="28" string="every" />
            <token id="29" string="fall" />
            <token id="30" string="of" />
            <token id="31" string="the" />
            <token id="32" string="hammer" />
          </tokens>
        </chunking>
        <chunking id="11" string="referred to gang members as `` dirty little cowards , '' and warned them that `` there is resounding applause to every fall of the hammer" type="VP">
          <tokens>
            <token id="7" string="referred" />
            <token id="8" string="to" />
            <token id="9" string="gang" />
            <token id="10" string="members" />
            <token id="11" string="as" />
            <token id="12" string="&quot;" />
            <token id="13" string="dirty" />
            <token id="14" string="little" />
            <token id="15" string="cowards" />
            <token id="16" string="," />
            <token id="17" string="&quot;" />
            <token id="18" string="and" />
            <token id="19" string="warned" />
            <token id="20" string="them" />
            <token id="21" string="that" />
            <token id="22" string="&quot;" />
            <token id="23" string="there" />
            <token id="24" string="is" />
            <token id="25" string="resounding" />
            <token id="26" string="applause" />
            <token id="27" string="to" />
            <token id="28" string="every" />
            <token id="29" string="fall" />
            <token id="30" string="of" />
            <token id="31" string="the" />
            <token id="32" string="hammer" />
          </tokens>
        </chunking>
        <chunking id="12" string="referred to gang members as `` dirty little cowards" type="VP">
          <tokens>
            <token id="7" string="referred" />
            <token id="8" string="to" />
            <token id="9" string="gang" />
            <token id="10" string="members" />
            <token id="11" string="as" />
            <token id="12" string="&quot;" />
            <token id="13" string="dirty" />
            <token id="14" string="little" />
            <token id="15" string="cowards" />
          </tokens>
        </chunking>
        <chunking id="13" string="resounding applause to every fall of the hammer" type="NP">
          <tokens>
            <token id="25" string="resounding" />
            <token id="26" string="applause" />
            <token id="27" string="to" />
            <token id="28" string="every" />
            <token id="29" string="fall" />
            <token id="30" string="of" />
            <token id="31" string="the" />
            <token id="32" string="hammer" />
          </tokens>
        </chunking>
        <chunking id="14" string="is resounding applause to every fall of the hammer" type="VP">
          <tokens>
            <token id="24" string="is" />
            <token id="25" string="resounding" />
            <token id="26" string="applause" />
            <token id="27" string="to" />
            <token id="28" string="every" />
            <token id="29" string="fall" />
            <token id="30" string="of" />
            <token id="31" string="the" />
            <token id="32" string="hammer" />
          </tokens>
        </chunking>
        <chunking id="15" string="warned them that `` there is resounding applause to every fall of the hammer" type="VP">
          <tokens>
            <token id="19" string="warned" />
            <token id="20" string="them" />
            <token id="21" string="that" />
            <token id="22" string="&quot;" />
            <token id="23" string="there" />
            <token id="24" string="is" />
            <token id="25" string="resounding" />
            <token id="26" string="applause" />
            <token id="27" string="to" />
            <token id="28" string="every" />
            <token id="29" string="fall" />
            <token id="30" string="of" />
            <token id="31" string="the" />
            <token id="32" string="hammer" />
          </tokens>
        </chunking>
        <chunking id="16" string="A few years" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="few" />
            <token id="3" string="years" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">years</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">years</governor>
          <dependent id="2">few</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">referred</governor>
          <dependent id="3">years</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">years</governor>
          <dependent id="4">ago</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Gates</governor>
          <dependent id="5">Chief</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">referred</governor>
          <dependent id="6">Gates</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">referred</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">members</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">members</governor>
          <dependent id="9">gang</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">referred</governor>
          <dependent id="10">members</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">cowards</governor>
          <dependent id="11">as</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">cowards</governor>
          <dependent id="13">dirty</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">cowards</governor>
          <dependent id="14">little</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">referred</governor>
          <dependent id="15">cowards</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">referred</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">referred</governor>
          <dependent id="19">warned</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">warned</governor>
          <dependent id="20">them</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">is</governor>
          <dependent id="21">that</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="24">is</governor>
          <dependent id="23">there</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">warned</governor>
          <dependent id="24">is</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">applause</governor>
          <dependent id="25">resounding</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">is</governor>
          <dependent id="26">applause</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">fall</governor>
          <dependent id="27">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">fall</governor>
          <dependent id="28">every</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">applause</governor>
          <dependent id="29">fall</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">hammer</governor>
          <dependent id="30">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">hammer</governor>
          <dependent id="31">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">fall</governor>
          <dependent id="32">hammer</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="every fall" type="SET" score="0.0">
          <tokens>
            <token id="28" string="every" />
            <token id="29" string="fall" />
          </tokens>
        </entity>
        <entity id="2" string="Chief" type="TITLE" score="0.0">
          <tokens>
            <token id="5" string="Chief" />
          </tokens>
        </entity>
        <entity id="3" string="A few years ago" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="few" />
            <token id="3" string="years" />
            <token id="4" string="ago" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>The exchange sounded more like one gang challenging another than a police chief seeking to reduce conflict in the community.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="exchange" lemma="exchange" stem="exchang" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="sounded" lemma="sound" stem="sound" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="7" string="gang" lemma="gang" stem="gang" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="challenging" lemma="challenging" stem="challeng" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="another" lemma="another" stem="anoth" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="chief" lemma="chief" stem="chief" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="seeking" lemma="seek" stem="seek" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="reduce" lemma="reduce" stem="reduc" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="conflict" lemma="conflict" stem="conflict" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="community" lemma="community" stem="commun" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN exchange)) (VP (VBD sounded) (NP (NP (QP (JJR more) (IN like) (CD one)) (NN gang)) (ADJP (JJ challenging) (DT another))) (PP (IN than) (NP (NP (DT a) (NN police) (NN chief)) (VP (VBG seeking) (S (VP (TO to) (VP (VB reduce) (NP (NN conflict)) (PP (IN in) (NP (DT the) (NN community)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The exchange" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="exchange" />
          </tokens>
        </chunking>
        <chunking id="2" string="sounded more like one gang challenging another than a police chief seeking to reduce conflict in the community" type="VP">
          <tokens>
            <token id="3" string="sounded" />
            <token id="4" string="more" />
            <token id="5" string="like" />
            <token id="6" string="one" />
            <token id="7" string="gang" />
            <token id="8" string="challenging" />
            <token id="9" string="another" />
            <token id="10" string="than" />
            <token id="11" string="a" />
            <token id="12" string="police" />
            <token id="13" string="chief" />
            <token id="14" string="seeking" />
            <token id="15" string="to" />
            <token id="16" string="reduce" />
            <token id="17" string="conflict" />
            <token id="18" string="in" />
            <token id="19" string="the" />
            <token id="20" string="community" />
          </tokens>
        </chunking>
        <chunking id="3" string="a police chief seeking to reduce conflict in the community" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="police" />
            <token id="13" string="chief" />
            <token id="14" string="seeking" />
            <token id="15" string="to" />
            <token id="16" string="reduce" />
            <token id="17" string="conflict" />
            <token id="18" string="in" />
            <token id="19" string="the" />
            <token id="20" string="community" />
          </tokens>
        </chunking>
        <chunking id="4" string="a police chief" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="police" />
            <token id="13" string="chief" />
          </tokens>
        </chunking>
        <chunking id="5" string="seeking to reduce conflict in the community" type="VP">
          <tokens>
            <token id="14" string="seeking" />
            <token id="15" string="to" />
            <token id="16" string="reduce" />
            <token id="17" string="conflict" />
            <token id="18" string="in" />
            <token id="19" string="the" />
            <token id="20" string="community" />
          </tokens>
        </chunking>
        <chunking id="6" string="challenging another" type="ADJP">
          <tokens>
            <token id="8" string="challenging" />
            <token id="9" string="another" />
          </tokens>
        </chunking>
        <chunking id="7" string="more like one gang challenging another" type="NP">
          <tokens>
            <token id="4" string="more" />
            <token id="5" string="like" />
            <token id="6" string="one" />
            <token id="7" string="gang" />
            <token id="8" string="challenging" />
            <token id="9" string="another" />
          </tokens>
        </chunking>
        <chunking id="8" string="reduce conflict in the community" type="VP">
          <tokens>
            <token id="16" string="reduce" />
            <token id="17" string="conflict" />
            <token id="18" string="in" />
            <token id="19" string="the" />
            <token id="20" string="community" />
          </tokens>
        </chunking>
        <chunking id="9" string="more like one gang" type="NP">
          <tokens>
            <token id="4" string="more" />
            <token id="5" string="like" />
            <token id="6" string="one" />
            <token id="7" string="gang" />
          </tokens>
        </chunking>
        <chunking id="10" string="to reduce conflict in the community" type="VP">
          <tokens>
            <token id="15" string="to" />
            <token id="16" string="reduce" />
            <token id="17" string="conflict" />
            <token id="18" string="in" />
            <token id="19" string="the" />
            <token id="20" string="community" />
          </tokens>
        </chunking>
        <chunking id="11" string="conflict" type="NP">
          <tokens>
            <token id="17" string="conflict" />
          </tokens>
        </chunking>
        <chunking id="12" string="the community" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="community" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">exchange</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">sounded</governor>
          <dependent id="2">exchange</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">sounded</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">one</governor>
          <dependent id="4">more</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">one</governor>
          <dependent id="5">like</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="7">gang</governor>
          <dependent id="6">one</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">sounded</governor>
          <dependent id="7">gang</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">gang</governor>
          <dependent id="8">challenging</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="8">challenging</governor>
          <dependent id="9">another</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">chief</governor>
          <dependent id="10">than</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">chief</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">chief</governor>
          <dependent id="12">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">sounded</governor>
          <dependent id="13">chief</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="13">chief</governor>
          <dependent id="14">seeking</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">reduce</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="14">seeking</governor>
          <dependent id="16">reduce</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">reduce</governor>
          <dependent id="17">conflict</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">community</governor>
          <dependent id="18">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">community</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">reduce</governor>
          <dependent id="20">community</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="6" string="one" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="false">
      <content>Indeed the Rambo-like challenge did not lower violence, and may have increased it.</content>
      <tokens>
        <token id="1" string="Indeed" lemma="indeed" stem="indeed" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="Rambo-like" lemma="rambo-like" stem="rambo-lik" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="4" string="challenge" lemma="challenge" stem="challeng" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="lower" lemma="lower" stem="lower" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="violence" lemma="violence" stem="violenc" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="increased" lemma="increase" stem="increas" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Indeed)) (NP (DT the) (JJ Rambo-like) (NN challenge)) (VP (VP (VBD did) (NP (ADJP (RB not) (JJR lower)) (NN violence))) (, ,) (CC and) (VP (MD may) (VP (VB have) (VP (VBN increased) (NP (PRP it)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="did not lower violence , and may have increased it" type="VP">
          <tokens>
            <token id="5" string="did" />
            <token id="6" string="not" />
            <token id="7" string="lower" />
            <token id="8" string="violence" />
            <token id="9" string="," />
            <token id="10" string="and" />
            <token id="11" string="may" />
            <token id="12" string="have" />
            <token id="13" string="increased" />
            <token id="14" string="it" />
          </tokens>
        </chunking>
        <chunking id="2" string="the Rambo-like challenge" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="Rambo-like" />
            <token id="4" string="challenge" />
          </tokens>
        </chunking>
        <chunking id="3" string="not lower violence" type="NP">
          <tokens>
            <token id="6" string="not" />
            <token id="7" string="lower" />
            <token id="8" string="violence" />
          </tokens>
        </chunking>
        <chunking id="4" string="may have increased it" type="VP">
          <tokens>
            <token id="11" string="may" />
            <token id="12" string="have" />
            <token id="13" string="increased" />
            <token id="14" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="increased it" type="VP">
          <tokens>
            <token id="13" string="increased" />
            <token id="14" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="did not lower violence" type="VP">
          <tokens>
            <token id="5" string="did" />
            <token id="6" string="not" />
            <token id="7" string="lower" />
            <token id="8" string="violence" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="14" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="have increased it" type="VP">
          <tokens>
            <token id="12" string="have" />
            <token id="13" string="increased" />
            <token id="14" string="it" />
          </tokens>
        </chunking>
        <chunking id="9" string="not lower" type="ADJP">
          <tokens>
            <token id="6" string="not" />
            <token id="7" string="lower" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="5">did</governor>
          <dependent id="1">Indeed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">challenge</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">challenge</governor>
          <dependent id="3">Rambo-like</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">did</governor>
          <dependent id="4">challenge</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="7">lower</governor>
          <dependent id="6">not</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">violence</governor>
          <dependent id="7">lower</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">did</governor>
          <dependent id="8">violence</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">did</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">increased</governor>
          <dependent id="11">may</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">increased</governor>
          <dependent id="12">have</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">did</governor>
          <dependent id="13">increased</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">increased</governor>
          <dependent id="14">it</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Rambo-like" type="MISC" score="0.0">
          <tokens>
            <token id="3" string="Rambo-like" />
          </tokens>
        </entity>
        <entity id="2" string="violence" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="8" string="violence" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>Hundreds of gang homicides occur every year in Los Angeles despite sweeps by the city&amp;apost;s police.</content>
      <tokens>
        <token id="1" string="Hundreds" lemma="hundred" stem="hundr" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="gang" lemma="gang" stem="gang" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="homicides" lemma="homicide" stem="homicid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="occur" lemma="occur" stem="occur" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="every" lemma="every" stem="everi" pos="DT" type="Word" isStopWord="false" ner="SET" is_referenced="false" is_refers="false" />
        <token id="7" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="SET" is_referenced="false" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Los" lemma="Los" stem="lo" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="10" string="Angeles" lemma="Angeles" stem="angele" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="11" string="despite" lemma="despite" stem="despit" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="sweeps" lemma="sweep" stem="sweep" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="city" lemma="city" stem="citi" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNS Hundreds)) (PP (IN of) (NP (NN gang) (NNS homicides)))) (VP (VBP occur) (NP (NP (DT every) (NN year)) (PP (IN in) (NP (NNP Los) (NNP Angeles)))) (PP (IN despite) (NP (NP (NNS sweeps)) (PP (IN by) (NP (NP (DT the) (NN city) (POS 's)) (NN police)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="every year in Los Angeles" type="NP">
          <tokens>
            <token id="6" string="every" />
            <token id="7" string="year" />
            <token id="8" string="in" />
            <token id="9" string="Los" />
            <token id="10" string="Angeles" />
          </tokens>
        </chunking>
        <chunking id="2" string="sweeps by the city 's police" type="NP">
          <tokens>
            <token id="12" string="sweeps" />
            <token id="13" string="by" />
            <token id="14" string="the" />
            <token id="15" string="city" />
            <token id="16" string="'s" />
            <token id="17" string="police" />
          </tokens>
        </chunking>
        <chunking id="3" string="occur every year in Los Angeles despite sweeps by the city 's police" type="VP">
          <tokens>
            <token id="5" string="occur" />
            <token id="6" string="every" />
            <token id="7" string="year" />
            <token id="8" string="in" />
            <token id="9" string="Los" />
            <token id="10" string="Angeles" />
            <token id="11" string="despite" />
            <token id="12" string="sweeps" />
            <token id="13" string="by" />
            <token id="14" string="the" />
            <token id="15" string="city" />
            <token id="16" string="'s" />
            <token id="17" string="police" />
          </tokens>
        </chunking>
        <chunking id="4" string="every year" type="NP">
          <tokens>
            <token id="6" string="every" />
            <token id="7" string="year" />
          </tokens>
        </chunking>
        <chunking id="5" string="gang homicides" type="NP">
          <tokens>
            <token id="3" string="gang" />
            <token id="4" string="homicides" />
          </tokens>
        </chunking>
        <chunking id="6" string="Los Angeles" type="NP">
          <tokens>
            <token id="9" string="Los" />
            <token id="10" string="Angeles" />
          </tokens>
        </chunking>
        <chunking id="7" string="Hundreds of gang homicides" type="NP">
          <tokens>
            <token id="1" string="Hundreds" />
            <token id="2" string="of" />
            <token id="3" string="gang" />
            <token id="4" string="homicides" />
          </tokens>
        </chunking>
        <chunking id="8" string="the city 's police" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="city" />
            <token id="16" string="'s" />
            <token id="17" string="police" />
          </tokens>
        </chunking>
        <chunking id="9" string="Hundreds" type="NP">
          <tokens>
            <token id="1" string="Hundreds" />
          </tokens>
        </chunking>
        <chunking id="10" string="the city 's" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="city" />
            <token id="16" string="'s" />
          </tokens>
        </chunking>
        <chunking id="11" string="sweeps" type="NP">
          <tokens>
            <token id="12" string="sweeps" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">occur</governor>
          <dependent id="1">Hundreds</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">homicides</governor>
          <dependent id="2">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">homicides</governor>
          <dependent id="3">gang</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Hundreds</governor>
          <dependent id="4">homicides</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">occur</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">year</governor>
          <dependent id="6">every</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">occur</governor>
          <dependent id="7">year</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Angeles</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Angeles</governor>
          <dependent id="9">Los</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">year</governor>
          <dependent id="10">Angeles</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">sweeps</governor>
          <dependent id="11">despite</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">occur</governor>
          <dependent id="12">sweeps</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">police</governor>
          <dependent id="13">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">city</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="17">police</governor>
          <dependent id="15">city</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">city</governor>
          <dependent id="16">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">sweeps</governor>
          <dependent id="17">police</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="every year" type="SET" score="0.0">
          <tokens>
            <token id="6" string="every" />
            <token id="7" string="year" />
          </tokens>
        </entity>
        <entity id="2" string="Los Angeles" type="LOCATION" score="0.0">
          <tokens>
            <token id="9" string="Los" />
            <token id="10" string="Angeles" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="false">
      <content>Mr. Gates would have been better advised to seek community programs for jobs, education, elimination of prejudice and improvement of neighborhoods.</content>
      <tokens>
        <token id="1" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="Gates" lemma="Gates" stem="gate" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="3" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="better" lemma="better" stem="better" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="advised" lemma="advise" stem="advis" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="seek" lemma="seek" stem="seek" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="community" lemma="community" stem="commun" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="programs" lemma="program" stem="program" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="jobs" lemma="job" stem="job" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="education" lemma="education" stem="educ" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="elimination" lemma="elimination" stem="elimin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="prejudice" lemma="prejudice" stem="prejudic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="improvement" lemma="improvement" stem="improv" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="neighborhoods" lemma="neighborhood" stem="neighborhood" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (S (NP (NNP Mr.) (NNP Gates)) (VP (MD would) (VP (VB have) (VP (VBN been) (ADJP (JJR better)))))) (VP (VBD advised) (S (VP (TO to) (VP (VB seek) (NP (NN community) (NNS programs)) (PP (IN for) (NP (NP (NNS jobs)) (, ,) (NP (NN education)) (, ,))))))) (NP (NP (NN elimination)) (PP (IN of) (NP (NP (NN prejudice) (CC and) (NN improvement)) (PP (IN of) (NP (NNS neighborhoods)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="to seek community programs for jobs , education ," type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="seek" />
            <token id="10" string="community" />
            <token id="11" string="programs" />
            <token id="12" string="for" />
            <token id="13" string="jobs" />
            <token id="14" string="," />
            <token id="15" string="education" />
            <token id="16" string="," />
          </tokens>
        </chunking>
        <chunking id="2" string="neighborhoods" type="NP">
          <tokens>
            <token id="23" string="neighborhoods" />
          </tokens>
        </chunking>
        <chunking id="3" string="jobs" type="NP">
          <tokens>
            <token id="13" string="jobs" />
          </tokens>
        </chunking>
        <chunking id="4" string="advised to seek community programs for jobs , education ," type="VP">
          <tokens>
            <token id="7" string="advised" />
            <token id="8" string="to" />
            <token id="9" string="seek" />
            <token id="10" string="community" />
            <token id="11" string="programs" />
            <token id="12" string="for" />
            <token id="13" string="jobs" />
            <token id="14" string="," />
            <token id="15" string="education" />
            <token id="16" string="," />
          </tokens>
        </chunking>
        <chunking id="5" string="been better" type="VP">
          <tokens>
            <token id="5" string="been" />
            <token id="6" string="better" />
          </tokens>
        </chunking>
        <chunking id="6" string="jobs , education ," type="NP">
          <tokens>
            <token id="13" string="jobs" />
            <token id="14" string="," />
            <token id="15" string="education" />
            <token id="16" string="," />
          </tokens>
        </chunking>
        <chunking id="7" string="education" type="NP">
          <tokens>
            <token id="15" string="education" />
          </tokens>
        </chunking>
        <chunking id="8" string="prejudice and improvement of neighborhoods" type="NP">
          <tokens>
            <token id="19" string="prejudice" />
            <token id="20" string="and" />
            <token id="21" string="improvement" />
            <token id="22" string="of" />
            <token id="23" string="neighborhoods" />
          </tokens>
        </chunking>
        <chunking id="9" string="better" type="ADJP">
          <tokens>
            <token id="6" string="better" />
          </tokens>
        </chunking>
        <chunking id="10" string="would have been better" type="VP">
          <tokens>
            <token id="3" string="would" />
            <token id="4" string="have" />
            <token id="5" string="been" />
            <token id="6" string="better" />
          </tokens>
        </chunking>
        <chunking id="11" string="seek community programs for jobs , education ," type="VP">
          <tokens>
            <token id="9" string="seek" />
            <token id="10" string="community" />
            <token id="11" string="programs" />
            <token id="12" string="for" />
            <token id="13" string="jobs" />
            <token id="14" string="," />
            <token id="15" string="education" />
            <token id="16" string="," />
          </tokens>
        </chunking>
        <chunking id="12" string="Mr. Gates" type="NP">
          <tokens>
            <token id="1" string="Mr." />
            <token id="2" string="Gates" />
          </tokens>
        </chunking>
        <chunking id="13" string="elimination of prejudice and improvement of neighborhoods" type="NP">
          <tokens>
            <token id="17" string="elimination" />
            <token id="18" string="of" />
            <token id="19" string="prejudice" />
            <token id="20" string="and" />
            <token id="21" string="improvement" />
            <token id="22" string="of" />
            <token id="23" string="neighborhoods" />
          </tokens>
        </chunking>
        <chunking id="14" string="elimination" type="NP">
          <tokens>
            <token id="17" string="elimination" />
          </tokens>
        </chunking>
        <chunking id="15" string="have been better" type="VP">
          <tokens>
            <token id="4" string="have" />
            <token id="5" string="been" />
            <token id="6" string="better" />
          </tokens>
        </chunking>
        <chunking id="16" string="community programs" type="NP">
          <tokens>
            <token id="10" string="community" />
            <token id="11" string="programs" />
          </tokens>
        </chunking>
        <chunking id="17" string="prejudice and improvement" type="NP">
          <tokens>
            <token id="19" string="prejudice" />
            <token id="20" string="and" />
            <token id="21" string="improvement" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Gates</governor>
          <dependent id="1">Mr.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">better</governor>
          <dependent id="2">Gates</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">better</governor>
          <dependent id="3">would</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">better</governor>
          <dependent id="4">have</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">better</governor>
          <dependent id="5">been</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">advised</governor>
          <dependent id="6">better</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">advised</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">seek</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">advised</governor>
          <dependent id="9">seek</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">programs</governor>
          <dependent id="10">community</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">seek</governor>
          <dependent id="11">programs</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">jobs</governor>
          <dependent id="12">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">seek</governor>
          <dependent id="13">jobs</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="13">jobs</governor>
          <dependent id="15">education</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">advised</governor>
          <dependent id="17">elimination</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">prejudice</governor>
          <dependent id="18">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">elimination</governor>
          <dependent id="19">prejudice</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="19">prejudice</governor>
          <dependent id="20">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">prejudice</governor>
          <dependent id="21">improvement</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">neighborhoods</governor>
          <dependent id="22">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">prejudice</governor>
          <dependent id="23">neighborhoods</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Gates" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Gates" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>But this kind of reasoning is foreign to a man who publicly claimed that his SWAT team could free the Iranian hostages.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="kind" lemma="kind" stem="kind" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="reasoning" lemma="reasoning" stem="reason" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="foreign" lemma="foreign" stem="foreign" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="man" lemma="man" stem="man" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="publicly" lemma="publicly" stem="publicli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="claimed" lemma="claim" stem="claim" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="SWAT" lemma="SWAT" stem="swat" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="team" lemma="team" stem="team" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="free" lemma="free" stem="free" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="Iranian" lemma="iranian" stem="iranian" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="22" string="hostages" lemma="hostage" stem="hostag" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (NP (DT this) (NN kind)) (PP (IN of) (NP (NN reasoning)))) (VP (VBZ is) (ADJP (JJ foreign) (PP (TO to) (NP (NP (DT a) (NN man)) (SBAR (WHNP (WP who)) (S (ADVP (RB publicly)) (VP (VBD claimed) (SBAR (IN that) (S (NP (PRP$ his) (NNP SWAT) (NN team)) (VP (MD could) (VP (VB free) (NP (DT the) (JJ Iranian) (NNS hostages))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="claimed that his SWAT team could free the Iranian hostages" type="VP">
          <tokens>
            <token id="13" string="claimed" />
            <token id="14" string="that" />
            <token id="15" string="his" />
            <token id="16" string="SWAT" />
            <token id="17" string="team" />
            <token id="18" string="could" />
            <token id="19" string="free" />
            <token id="20" string="the" />
            <token id="21" string="Iranian" />
            <token id="22" string="hostages" />
          </tokens>
        </chunking>
        <chunking id="2" string="reasoning" type="NP">
          <tokens>
            <token id="5" string="reasoning" />
          </tokens>
        </chunking>
        <chunking id="3" string="free the Iranian hostages" type="VP">
          <tokens>
            <token id="19" string="free" />
            <token id="20" string="the" />
            <token id="21" string="Iranian" />
            <token id="22" string="hostages" />
          </tokens>
        </chunking>
        <chunking id="4" string="a man who publicly claimed that his SWAT team could free the Iranian hostages" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="man" />
            <token id="11" string="who" />
            <token id="12" string="publicly" />
            <token id="13" string="claimed" />
            <token id="14" string="that" />
            <token id="15" string="his" />
            <token id="16" string="SWAT" />
            <token id="17" string="team" />
            <token id="18" string="could" />
            <token id="19" string="free" />
            <token id="20" string="the" />
            <token id="21" string="Iranian" />
            <token id="22" string="hostages" />
          </tokens>
        </chunking>
        <chunking id="5" string="this kind" type="NP">
          <tokens>
            <token id="2" string="this" />
            <token id="3" string="kind" />
          </tokens>
        </chunking>
        <chunking id="6" string="that his SWAT team could free the Iranian hostages" type="SBAR">
          <tokens>
            <token id="14" string="that" />
            <token id="15" string="his" />
            <token id="16" string="SWAT" />
            <token id="17" string="team" />
            <token id="18" string="could" />
            <token id="19" string="free" />
            <token id="20" string="the" />
            <token id="21" string="Iranian" />
            <token id="22" string="hostages" />
          </tokens>
        </chunking>
        <chunking id="7" string="his SWAT team" type="NP">
          <tokens>
            <token id="15" string="his" />
            <token id="16" string="SWAT" />
            <token id="17" string="team" />
          </tokens>
        </chunking>
        <chunking id="8" string="this kind of reasoning" type="NP">
          <tokens>
            <token id="2" string="this" />
            <token id="3" string="kind" />
            <token id="4" string="of" />
            <token id="5" string="reasoning" />
          </tokens>
        </chunking>
        <chunking id="9" string="foreign to a man who publicly claimed that his SWAT team could free the Iranian hostages" type="ADJP">
          <tokens>
            <token id="7" string="foreign" />
            <token id="8" string="to" />
            <token id="9" string="a" />
            <token id="10" string="man" />
            <token id="11" string="who" />
            <token id="12" string="publicly" />
            <token id="13" string="claimed" />
            <token id="14" string="that" />
            <token id="15" string="his" />
            <token id="16" string="SWAT" />
            <token id="17" string="team" />
            <token id="18" string="could" />
            <token id="19" string="free" />
            <token id="20" string="the" />
            <token id="21" string="Iranian" />
            <token id="22" string="hostages" />
          </tokens>
        </chunking>
        <chunking id="10" string="is foreign to a man who publicly claimed that his SWAT team could free the Iranian hostages" type="VP">
          <tokens>
            <token id="6" string="is" />
            <token id="7" string="foreign" />
            <token id="8" string="to" />
            <token id="9" string="a" />
            <token id="10" string="man" />
            <token id="11" string="who" />
            <token id="12" string="publicly" />
            <token id="13" string="claimed" />
            <token id="14" string="that" />
            <token id="15" string="his" />
            <token id="16" string="SWAT" />
            <token id="17" string="team" />
            <token id="18" string="could" />
            <token id="19" string="free" />
            <token id="20" string="the" />
            <token id="21" string="Iranian" />
            <token id="22" string="hostages" />
          </tokens>
        </chunking>
        <chunking id="11" string="could free the Iranian hostages" type="VP">
          <tokens>
            <token id="18" string="could" />
            <token id="19" string="free" />
            <token id="20" string="the" />
            <token id="21" string="Iranian" />
            <token id="22" string="hostages" />
          </tokens>
        </chunking>
        <chunking id="12" string="a man" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="man" />
          </tokens>
        </chunking>
        <chunking id="13" string="the Iranian hostages" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="Iranian" />
            <token id="22" string="hostages" />
          </tokens>
        </chunking>
        <chunking id="14" string="who publicly claimed that his SWAT team could free the Iranian hostages" type="SBAR">
          <tokens>
            <token id="11" string="who" />
            <token id="12" string="publicly" />
            <token id="13" string="claimed" />
            <token id="14" string="that" />
            <token id="15" string="his" />
            <token id="16" string="SWAT" />
            <token id="17" string="team" />
            <token id="18" string="could" />
            <token id="19" string="free" />
            <token id="20" string="the" />
            <token id="21" string="Iranian" />
            <token id="22" string="hostages" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="7">foreign</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">kind</governor>
          <dependent id="2">this</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">foreign</governor>
          <dependent id="3">kind</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">reasoning</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">kind</governor>
          <dependent id="5">reasoning</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">foreign</governor>
          <dependent id="6">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">foreign</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">man</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">man</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">foreign</governor>
          <dependent id="10">man</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">claimed</governor>
          <dependent id="11">who</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">claimed</governor>
          <dependent id="12">publicly</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="10">man</governor>
          <dependent id="13">claimed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">free</governor>
          <dependent id="14">that</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="17">team</governor>
          <dependent id="15">his</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">team</governor>
          <dependent id="16">SWAT</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">free</governor>
          <dependent id="17">team</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="19">free</governor>
          <dependent id="18">could</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">claimed</governor>
          <dependent id="19">free</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">hostages</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">hostages</governor>
          <dependent id="21">Iranian</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">free</governor>
          <dependent id="22">hostages</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Iranian" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="21" string="Iranian" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>Similarly, Mr. Gates vehemently opposed the Police Corps Program backed by other police chiefs.</content>
      <tokens>
        <token id="1" string="Similarly" lemma="similarly" stem="similarli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="Gates" lemma="Gates" stem="gate" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="5" string="vehemently" lemma="vehemently" stem="vehement" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="opposed" lemma="oppose" stem="oppos" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="Police" lemma="Police" stem="polic" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="9" string="Corps" lemma="Corps" stem="corp" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="10" string="Program" lemma="Program" stem="program" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="11" string="backed" lemma="back" stem="back" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="police" lemma="police" stem="polic" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="chiefs" lemma="chief" stem="chief" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Similarly)) (, ,) (NP (NNP Mr.) (NNP Gates)) (ADVP (RB vehemently)) (VP (VBD opposed) (SBAR (S (NP (DT the) (NNP Police) (NNP Corps) (NNP Program)) (VP (VBD backed) (PP (IN by) (NP (JJ other) (NNS police) (NNS chiefs))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="other police chiefs" type="NP">
          <tokens>
            <token id="13" string="other" />
            <token id="14" string="police" />
            <token id="15" string="chiefs" />
          </tokens>
        </chunking>
        <chunking id="2" string="the Police Corps Program" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="Police" />
            <token id="9" string="Corps" />
            <token id="10" string="Program" />
          </tokens>
        </chunking>
        <chunking id="3" string="the Police Corps Program backed by other police chiefs" type="SBAR">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="Police" />
            <token id="9" string="Corps" />
            <token id="10" string="Program" />
            <token id="11" string="backed" />
            <token id="12" string="by" />
            <token id="13" string="other" />
            <token id="14" string="police" />
            <token id="15" string="chiefs" />
          </tokens>
        </chunking>
        <chunking id="4" string="backed by other police chiefs" type="VP">
          <tokens>
            <token id="11" string="backed" />
            <token id="12" string="by" />
            <token id="13" string="other" />
            <token id="14" string="police" />
            <token id="15" string="chiefs" />
          </tokens>
        </chunking>
        <chunking id="5" string="Mr. Gates" type="NP">
          <tokens>
            <token id="3" string="Mr." />
            <token id="4" string="Gates" />
          </tokens>
        </chunking>
        <chunking id="6" string="opposed the Police Corps Program backed by other police chiefs" type="VP">
          <tokens>
            <token id="6" string="opposed" />
            <token id="7" string="the" />
            <token id="8" string="Police" />
            <token id="9" string="Corps" />
            <token id="10" string="Program" />
            <token id="11" string="backed" />
            <token id="12" string="by" />
            <token id="13" string="other" />
            <token id="14" string="police" />
            <token id="15" string="chiefs" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="6">opposed</governor>
          <dependent id="1">Similarly</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Gates</governor>
          <dependent id="3">Mr.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">opposed</governor>
          <dependent id="4">Gates</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">opposed</governor>
          <dependent id="5">vehemently</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">opposed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">Program</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Program</governor>
          <dependent id="8">Police</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Program</governor>
          <dependent id="9">Corps</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">backed</governor>
          <dependent id="10">Program</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">opposed</governor>
          <dependent id="11">backed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">chiefs</governor>
          <dependent id="12">by</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">chiefs</governor>
          <dependent id="13">other</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">chiefs</governor>
          <dependent id="14">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">backed</governor>
          <dependent id="15">chiefs</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Gates" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Gates" />
          </tokens>
        </entity>
        <entity id="2" string="Police Corps Program" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="8" string="Police" />
            <token id="9" string="Corps" />
            <token id="10" string="Program" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>The Police Corps would send idealistic young people, including minorities, to serve a three -- or four -- year tour of duty after college graduation in return for federal funding of their educations.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="Police" lemma="Police" stem="polic" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="3" string="Corps" lemma="Corps" stem="corp" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="4" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="send" lemma="send" stem="send" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="idealistic" lemma="idealistic" stem="idealist" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="young" lemma="young" stem="young" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="including" lemma="include" stem="includ" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="minorities" lemma="minority" stem="minor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="serve" lemma="serve" stem="serv" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="three" lemma="three" stem="three" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="17" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="four" lemma="four" stem="four" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="20" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="22" string="tour" lemma="tour" stem="tour" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="duty" lemma="duty" stem="duti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="college" lemma="college" stem="colleg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="graduation" lemma="graduation" stem="graduat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="return" lemma="return" stem="return" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="federal" lemma="federal" stem="feder" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="funding" lemma="funding" stem="fund" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="educations" lemma="education" stem="educ" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNP Police) (NNP Corps)) (VP (MD would) (VP (VB send) (S (NP (NP (JJ idealistic) (JJ young) (NNS people)) (, ,) (PP (VBG including) (NP (NNS minorities))) (, ,)) (VP (TO to) (VP (VB serve) (NP (NP (DT a) (NP (NP (CD three)) (PRN (: --) (CC or) (NP (CD four)) (: --))) (NN year) (NN tour)) (PP (IN of) (NP (NN duty)))) (PP (IN after) (NP (NP (NN college) (NN graduation)) (PP (IN in) (NP (NN return))))) (PP (IN for) (NP (NP (JJ federal) (NN funding)) (PP (IN of) (NP (PRP$ their) (NNS educations)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="return" type="NP">
          <tokens>
            <token id="29" string="return" />
          </tokens>
        </chunking>
        <chunking id="2" string="a three -- or four -- year tour of duty" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="three" />
            <token id="17" string="--" />
            <token id="18" string="or" />
            <token id="19" string="four" />
            <token id="20" string="--" />
            <token id="21" string="year" />
            <token id="22" string="tour" />
            <token id="23" string="of" />
            <token id="24" string="duty" />
          </tokens>
        </chunking>
        <chunking id="3" string="minorities" type="NP">
          <tokens>
            <token id="11" string="minorities" />
          </tokens>
        </chunking>
        <chunking id="4" string="college graduation in return" type="NP">
          <tokens>
            <token id="26" string="college" />
            <token id="27" string="graduation" />
            <token id="28" string="in" />
            <token id="29" string="return" />
          </tokens>
        </chunking>
        <chunking id="5" string="federal funding of their educations" type="NP">
          <tokens>
            <token id="31" string="federal" />
            <token id="32" string="funding" />
            <token id="33" string="of" />
            <token id="34" string="their" />
            <token id="35" string="educations" />
          </tokens>
        </chunking>
        <chunking id="6" string="three" type="NP">
          <tokens>
            <token id="16" string="three" />
          </tokens>
        </chunking>
        <chunking id="7" string="The Police Corps" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Police" />
            <token id="3" string="Corps" />
          </tokens>
        </chunking>
        <chunking id="8" string="idealistic young people , including minorities ," type="NP">
          <tokens>
            <token id="6" string="idealistic" />
            <token id="7" string="young" />
            <token id="8" string="people" />
            <token id="9" string="," />
            <token id="10" string="including" />
            <token id="11" string="minorities" />
            <token id="12" string="," />
          </tokens>
        </chunking>
        <chunking id="9" string="a three -- or four -- year tour" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="three" />
            <token id="17" string="--" />
            <token id="18" string="or" />
            <token id="19" string="four" />
            <token id="20" string="--" />
            <token id="21" string="year" />
            <token id="22" string="tour" />
          </tokens>
        </chunking>
        <chunking id="10" string="four" type="NP">
          <tokens>
            <token id="19" string="four" />
          </tokens>
        </chunking>
        <chunking id="11" string="send idealistic young people , including minorities , to serve a three -- or four -- year tour of duty after college graduation in return for federal funding of their educations" type="VP">
          <tokens>
            <token id="5" string="send" />
            <token id="6" string="idealistic" />
            <token id="7" string="young" />
            <token id="8" string="people" />
            <token id="9" string="," />
            <token id="10" string="including" />
            <token id="11" string="minorities" />
            <token id="12" string="," />
            <token id="13" string="to" />
            <token id="14" string="serve" />
            <token id="15" string="a" />
            <token id="16" string="three" />
            <token id="17" string="--" />
            <token id="18" string="or" />
            <token id="19" string="four" />
            <token id="20" string="--" />
            <token id="21" string="year" />
            <token id="22" string="tour" />
            <token id="23" string="of" />
            <token id="24" string="duty" />
            <token id="25" string="after" />
            <token id="26" string="college" />
            <token id="27" string="graduation" />
            <token id="28" string="in" />
            <token id="29" string="return" />
            <token id="30" string="for" />
            <token id="31" string="federal" />
            <token id="32" string="funding" />
            <token id="33" string="of" />
            <token id="34" string="their" />
            <token id="35" string="educations" />
          </tokens>
        </chunking>
        <chunking id="12" string="three -- or four --" type="NP">
          <tokens>
            <token id="16" string="three" />
            <token id="17" string="--" />
            <token id="18" string="or" />
            <token id="19" string="four" />
            <token id="20" string="--" />
          </tokens>
        </chunking>
        <chunking id="13" string="federal funding" type="NP">
          <tokens>
            <token id="31" string="federal" />
            <token id="32" string="funding" />
          </tokens>
        </chunking>
        <chunking id="14" string="idealistic young people" type="NP">
          <tokens>
            <token id="6" string="idealistic" />
            <token id="7" string="young" />
            <token id="8" string="people" />
          </tokens>
        </chunking>
        <chunking id="15" string="duty" type="NP">
          <tokens>
            <token id="24" string="duty" />
          </tokens>
        </chunking>
        <chunking id="16" string="college graduation" type="NP">
          <tokens>
            <token id="26" string="college" />
            <token id="27" string="graduation" />
          </tokens>
        </chunking>
        <chunking id="17" string="to serve a three -- or four -- year tour of duty after college graduation in return for federal funding of their educations" type="VP">
          <tokens>
            <token id="13" string="to" />
            <token id="14" string="serve" />
            <token id="15" string="a" />
            <token id="16" string="three" />
            <token id="17" string="--" />
            <token id="18" string="or" />
            <token id="19" string="four" />
            <token id="20" string="--" />
            <token id="21" string="year" />
            <token id="22" string="tour" />
            <token id="23" string="of" />
            <token id="24" string="duty" />
            <token id="25" string="after" />
            <token id="26" string="college" />
            <token id="27" string="graduation" />
            <token id="28" string="in" />
            <token id="29" string="return" />
            <token id="30" string="for" />
            <token id="31" string="federal" />
            <token id="32" string="funding" />
            <token id="33" string="of" />
            <token id="34" string="their" />
            <token id="35" string="educations" />
          </tokens>
        </chunking>
        <chunking id="18" string="serve a three -- or four -- year tour of duty after college graduation in return for federal funding of their educations" type="VP">
          <tokens>
            <token id="14" string="serve" />
            <token id="15" string="a" />
            <token id="16" string="three" />
            <token id="17" string="--" />
            <token id="18" string="or" />
            <token id="19" string="four" />
            <token id="20" string="--" />
            <token id="21" string="year" />
            <token id="22" string="tour" />
            <token id="23" string="of" />
            <token id="24" string="duty" />
            <token id="25" string="after" />
            <token id="26" string="college" />
            <token id="27" string="graduation" />
            <token id="28" string="in" />
            <token id="29" string="return" />
            <token id="30" string="for" />
            <token id="31" string="federal" />
            <token id="32" string="funding" />
            <token id="33" string="of" />
            <token id="34" string="their" />
            <token id="35" string="educations" />
          </tokens>
        </chunking>
        <chunking id="19" string="their educations" type="NP">
          <tokens>
            <token id="34" string="their" />
            <token id="35" string="educations" />
          </tokens>
        </chunking>
        <chunking id="20" string="would send idealistic young people , including minorities , to serve a three -- or four -- year tour of duty after college graduation in return for federal funding of their educations" type="VP">
          <tokens>
            <token id="4" string="would" />
            <token id="5" string="send" />
            <token id="6" string="idealistic" />
            <token id="7" string="young" />
            <token id="8" string="people" />
            <token id="9" string="," />
            <token id="10" string="including" />
            <token id="11" string="minorities" />
            <token id="12" string="," />
            <token id="13" string="to" />
            <token id="14" string="serve" />
            <token id="15" string="a" />
            <token id="16" string="three" />
            <token id="17" string="--" />
            <token id="18" string="or" />
            <token id="19" string="four" />
            <token id="20" string="--" />
            <token id="21" string="year" />
            <token id="22" string="tour" />
            <token id="23" string="of" />
            <token id="24" string="duty" />
            <token id="25" string="after" />
            <token id="26" string="college" />
            <token id="27" string="graduation" />
            <token id="28" string="in" />
            <token id="29" string="return" />
            <token id="30" string="for" />
            <token id="31" string="federal" />
            <token id="32" string="funding" />
            <token id="33" string="of" />
            <token id="34" string="their" />
            <token id="35" string="educations" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">Corps</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Corps</governor>
          <dependent id="2">Police</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">send</governor>
          <dependent id="3">Corps</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">send</governor>
          <dependent id="4">would</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">send</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">people</governor>
          <dependent id="6">idealistic</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">people</governor>
          <dependent id="7">young</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">send</governor>
          <dependent id="8">people</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">minorities</governor>
          <dependent id="10">including</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">people</governor>
          <dependent id="11">minorities</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">serve</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">send</governor>
          <dependent id="14">serve</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">tour</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">tour</governor>
          <dependent id="16">three</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="19">four</governor>
          <dependent id="18">or</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="16">three</governor>
          <dependent id="19">four</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">tour</governor>
          <dependent id="21">year</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">serve</governor>
          <dependent id="22">tour</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">duty</governor>
          <dependent id="23">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">tour</governor>
          <dependent id="24">duty</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">graduation</governor>
          <dependent id="25">after</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">graduation</governor>
          <dependent id="26">college</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">serve</governor>
          <dependent id="27">graduation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">return</governor>
          <dependent id="28">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">graduation</governor>
          <dependent id="29">return</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">funding</governor>
          <dependent id="30">for</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="32">funding</governor>
          <dependent id="31">federal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">serve</governor>
          <dependent id="32">funding</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">educations</governor>
          <dependent id="33">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="35">educations</governor>
          <dependent id="34">their</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">funding</governor>
          <dependent id="35">educations</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="year" type="DURATION" score="0.0">
          <tokens>
            <token id="21" string="year" />
          </tokens>
        </entity>
        <entity id="2" string="Police Corps" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="2" string="Police" />
            <token id="3" string="Corps" />
          </tokens>
        </entity>
        <entity id="3" string="four" type="NUMBER" score="0.0">
          <tokens>
            <token id="19" string="four" />
          </tokens>
        </entity>
        <entity id="4" string="three" type="NUMBER" score="0.0">
          <tokens>
            <token id="16" string="three" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>Mr. Gates opposed the Police Corps because its members would not be professionals.</content>
      <tokens>
        <token id="1" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="Gates" lemma="Gates" stem="gate" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="3" string="opposed" lemma="oppose" stem="oppos" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="Police" lemma="Police" stem="polic" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="6" string="Corps" lemma="Corps" stem="corp" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="7" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="members" lemma="member" stem="member" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="professionals" lemma="professional" stem="profession" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Mr.) (NNP Gates)) (VP (VBD opposed) (NP (DT the) (NNP Police) (NNP Corps)) (SBAR (IN because) (S (NP (PRP$ its) (NNS members)) (VP (MD would) (RB not) (VP (VB be) (NP (NNS professionals))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="professionals" type="NP">
          <tokens>
            <token id="13" string="professionals" />
          </tokens>
        </chunking>
        <chunking id="2" string="be professionals" type="VP">
          <tokens>
            <token id="12" string="be" />
            <token id="13" string="professionals" />
          </tokens>
        </chunking>
        <chunking id="3" string="would not be professionals" type="VP">
          <tokens>
            <token id="10" string="would" />
            <token id="11" string="not" />
            <token id="12" string="be" />
            <token id="13" string="professionals" />
          </tokens>
        </chunking>
        <chunking id="4" string="opposed the Police Corps because its members would not be professionals" type="VP">
          <tokens>
            <token id="3" string="opposed" />
            <token id="4" string="the" />
            <token id="5" string="Police" />
            <token id="6" string="Corps" />
            <token id="7" string="because" />
            <token id="8" string="its" />
            <token id="9" string="members" />
            <token id="10" string="would" />
            <token id="11" string="not" />
            <token id="12" string="be" />
            <token id="13" string="professionals" />
          </tokens>
        </chunking>
        <chunking id="5" string="the Police Corps" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="Police" />
            <token id="6" string="Corps" />
          </tokens>
        </chunking>
        <chunking id="6" string="its members" type="NP">
          <tokens>
            <token id="8" string="its" />
            <token id="9" string="members" />
          </tokens>
        </chunking>
        <chunking id="7" string="Mr. Gates" type="NP">
          <tokens>
            <token id="1" string="Mr." />
            <token id="2" string="Gates" />
          </tokens>
        </chunking>
        <chunking id="8" string="because its members would not be professionals" type="SBAR">
          <tokens>
            <token id="7" string="because" />
            <token id="8" string="its" />
            <token id="9" string="members" />
            <token id="10" string="would" />
            <token id="11" string="not" />
            <token id="12" string="be" />
            <token id="13" string="professionals" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Gates</governor>
          <dependent id="1">Mr.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">opposed</governor>
          <dependent id="2">Gates</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">opposed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">Corps</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Corps</governor>
          <dependent id="5">Police</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">opposed</governor>
          <dependent id="6">Corps</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">professionals</governor>
          <dependent id="7">because</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">members</governor>
          <dependent id="8">its</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">professionals</governor>
          <dependent id="9">members</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">professionals</governor>
          <dependent id="10">would</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="13">professionals</governor>
          <dependent id="11">not</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="13">professionals</governor>
          <dependent id="12">be</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">opposed</governor>
          <dependent id="13">professionals</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Gates" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Gates" />
          </tokens>
        </entity>
        <entity id="2" string="Police Corps" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="5" string="Police" />
            <token id="6" string="Corps" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>Yet the presence of such &amp;quot;non-professionals&amp;quot; would discourage the racism and brutality exposed by the Rodney King beating.</content>
      <tokens>
        <token id="1" string="Yet" lemma="yet" stem="yet" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="presence" lemma="presence" stem="presenc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="non-professionals" lemma="non-professional" stem="non-profession" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="discourage" lemma="discourage" stem="discourag" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="racism" lemma="racism" stem="racism" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="brutality" lemma="brutality" stem="brutal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="exposed" lemma="expose" stem="expos" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="Rodney" lemma="Rodney" stem="rodnei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="19" string="King" lemma="King" stem="king" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="20" string="beating" lemma="beating" stem="beat" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Yet)) (NP (NP (DT the) (NN presence)) (PP (IN of) (NP (JJ such) (`` ``) (NNS non-professionals) ('' '')))) (VP (MD would) (VP (VB discourage) (NP (NP (DT the) (NN racism) (CC and) (NN brutality)) (VP (VBN exposed) (PP (IN by) (NP (DT the) (NNP Rodney) (NNP King) (NN beating))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the racism and brutality" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="racism" />
            <token id="13" string="and" />
            <token id="14" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="2" string="exposed by the Rodney King beating" type="VP">
          <tokens>
            <token id="15" string="exposed" />
            <token id="16" string="by" />
            <token id="17" string="the" />
            <token id="18" string="Rodney" />
            <token id="19" string="King" />
            <token id="20" string="beating" />
          </tokens>
        </chunking>
        <chunking id="3" string="the presence of such `` non-professionals ''" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="presence" />
            <token id="4" string="of" />
            <token id="5" string="such" />
            <token id="6" string="&quot;" />
            <token id="7" string="non-professionals" />
            <token id="8" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="4" string="discourage the racism and brutality exposed by the Rodney King beating" type="VP">
          <tokens>
            <token id="10" string="discourage" />
            <token id="11" string="the" />
            <token id="12" string="racism" />
            <token id="13" string="and" />
            <token id="14" string="brutality" />
            <token id="15" string="exposed" />
            <token id="16" string="by" />
            <token id="17" string="the" />
            <token id="18" string="Rodney" />
            <token id="19" string="King" />
            <token id="20" string="beating" />
          </tokens>
        </chunking>
        <chunking id="5" string="the racism and brutality exposed by the Rodney King beating" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="racism" />
            <token id="13" string="and" />
            <token id="14" string="brutality" />
            <token id="15" string="exposed" />
            <token id="16" string="by" />
            <token id="17" string="the" />
            <token id="18" string="Rodney" />
            <token id="19" string="King" />
            <token id="20" string="beating" />
          </tokens>
        </chunking>
        <chunking id="6" string="would discourage the racism and brutality exposed by the Rodney King beating" type="VP">
          <tokens>
            <token id="9" string="would" />
            <token id="10" string="discourage" />
            <token id="11" string="the" />
            <token id="12" string="racism" />
            <token id="13" string="and" />
            <token id="14" string="brutality" />
            <token id="15" string="exposed" />
            <token id="16" string="by" />
            <token id="17" string="the" />
            <token id="18" string="Rodney" />
            <token id="19" string="King" />
            <token id="20" string="beating" />
          </tokens>
        </chunking>
        <chunking id="7" string="the Rodney King beating" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="Rodney" />
            <token id="19" string="King" />
            <token id="20" string="beating" />
          </tokens>
        </chunking>
        <chunking id="8" string="such `` non-professionals ''" type="NP">
          <tokens>
            <token id="5" string="such" />
            <token id="6" string="&quot;" />
            <token id="7" string="non-professionals" />
            <token id="8" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="9" string="the presence" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="presence" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="10">discourage</governor>
          <dependent id="1">Yet</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">presence</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">discourage</governor>
          <dependent id="3">presence</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">non-professionals</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">non-professionals</governor>
          <dependent id="5">such</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">presence</governor>
          <dependent id="7">non-professionals</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">discourage</governor>
          <dependent id="9">would</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">discourage</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">racism</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">discourage</governor>
          <dependent id="12">racism</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">racism</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">racism</governor>
          <dependent id="14">brutality</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="12">racism</governor>
          <dependent id="15">exposed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">beating</governor>
          <dependent id="16">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">beating</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">beating</governor>
          <dependent id="18">Rodney</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">beating</governor>
          <dependent id="19">King</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">exposed</governor>
          <dependent id="20">beating</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Rodney King" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Rodney" />
            <token id="19" string="King" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="false">
      <content>Such attitudes survive only in a closed police culture.</content>
      <tokens>
        <token id="1" string="Such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="attitudes" lemma="attitude" stem="attitud" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="survive" lemma="survive" stem="surviv" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="closed" lemma="closed" stem="close" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="culture" lemma="culture" stem="cultur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (JJ Such) (NNS attitudes)) (VP (VBP survive) (ADVP (RB only)) (PP (IN in) (NP (DT a) (JJ closed) (NN police) (NN culture)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="survive only in a closed police culture" type="VP">
          <tokens>
            <token id="3" string="survive" />
            <token id="4" string="only" />
            <token id="5" string="in" />
            <token id="6" string="a" />
            <token id="7" string="closed" />
            <token id="8" string="police" />
            <token id="9" string="culture" />
          </tokens>
        </chunking>
        <chunking id="2" string="a closed police culture" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="closed" />
            <token id="8" string="police" />
            <token id="9" string="culture" />
          </tokens>
        </chunking>
        <chunking id="3" string="Such attitudes" type="NP">
          <tokens>
            <token id="1" string="Such" />
            <token id="2" string="attitudes" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">attitudes</governor>
          <dependent id="1">Such</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">survive</governor>
          <dependent id="2">attitudes</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">survive</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">survive</governor>
          <dependent id="4">only</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">culture</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">culture</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">culture</governor>
          <dependent id="7">closed</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">culture</governor>
          <dependent id="8">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">survive</governor>
          <dependent id="9">culture</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="14" has_coreference="false">
      <content>The presence of even one police corps officer witness would have deterred the criminal cops.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="presence" lemma="presence" stem="presenc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="6" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="corps" lemma="corps" stem="corp" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="witness" lemma="witness" stem="wit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="deterred" lemma="deter" stem="deter" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="criminal" lemma="criminal" stem="crimin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="cops" lemma="cop" stem="cop" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NN presence)) (PP (IN of) (NP (ADJP (RB even) (NP-TMP (CD one))) (NN police) (NN corps) (NN officer) (NN witness)))) (VP (MD would) (VP (VB have) (VP (VBN deterred) (NP (DT the) (JJ criminal) (NNS cops))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="even one" type="ADJP">
          <tokens>
            <token id="4" string="even" />
            <token id="5" string="one" />
          </tokens>
        </chunking>
        <chunking id="2" string="would have deterred the criminal cops" type="VP">
          <tokens>
            <token id="10" string="would" />
            <token id="11" string="have" />
            <token id="12" string="deterred" />
            <token id="13" string="the" />
            <token id="14" string="criminal" />
            <token id="15" string="cops" />
          </tokens>
        </chunking>
        <chunking id="3" string="the criminal cops" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="criminal" />
            <token id="15" string="cops" />
          </tokens>
        </chunking>
        <chunking id="4" string="have deterred the criminal cops" type="VP">
          <tokens>
            <token id="11" string="have" />
            <token id="12" string="deterred" />
            <token id="13" string="the" />
            <token id="14" string="criminal" />
            <token id="15" string="cops" />
          </tokens>
        </chunking>
        <chunking id="5" string="The presence" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="presence" />
          </tokens>
        </chunking>
        <chunking id="6" string="The presence of even one police corps officer witness" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="presence" />
            <token id="3" string="of" />
            <token id="4" string="even" />
            <token id="5" string="one" />
            <token id="6" string="police" />
            <token id="7" string="corps" />
            <token id="8" string="officer" />
            <token id="9" string="witness" />
          </tokens>
        </chunking>
        <chunking id="7" string="even one police corps officer witness" type="NP">
          <tokens>
            <token id="4" string="even" />
            <token id="5" string="one" />
            <token id="6" string="police" />
            <token id="7" string="corps" />
            <token id="8" string="officer" />
            <token id="9" string="witness" />
          </tokens>
        </chunking>
        <chunking id="8" string="deterred the criminal cops" type="VP">
          <tokens>
            <token id="12" string="deterred" />
            <token id="13" string="the" />
            <token id="14" string="criminal" />
            <token id="15" string="cops" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">presence</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">deterred</governor>
          <dependent id="2">presence</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">witness</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">witness</governor>
          <dependent id="4">even</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="4">even</governor>
          <dependent id="5">one</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">witness</governor>
          <dependent id="6">police</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">witness</governor>
          <dependent id="7">corps</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">witness</governor>
          <dependent id="8">officer</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">presence</governor>
          <dependent id="9">witness</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">deterred</governor>
          <dependent id="10">would</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">deterred</governor>
          <dependent id="11">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">deterred</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">cops</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">cops</governor>
          <dependent id="14">criminal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">deterred</governor>
          <dependent id="15">cops</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="5" string="one" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>Many chiefs openly disagreed with Mr. Gates when he opposed the Police Corps Bill in Congress.</content>
      <tokens>
        <token id="1" string="Many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="chiefs" lemma="chief" stem="chief" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="openly" lemma="openly" stem="openli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="disagreed" lemma="disagree" stem="disagre" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="Gates" lemma="Gates" stem="gate" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="8" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="opposed" lemma="oppose" stem="oppos" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Police" lemma="Police" stem="polic" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="Corps" lemma="Corps" stem="corp" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="Bill" lemma="Bill" stem="bill" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="Congress" lemma="Congress" stem="congress" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (JJ Many) (NNS chiefs)) (ADVP (RB openly)) (VP (VBD disagreed) (PP (IN with) (NP (NNP Mr.) (NNP Gates))) (SBAR (WHADVP (WRB when)) (S (NP (PRP he)) (VP (VBD opposed) (NP (NP (DT the) (NNP Police) (NNP Corps) (NNP Bill)) (PP (IN in) (NP (NNP Congress)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the Police Corps Bill in Congress" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="Police" />
            <token id="13" string="Corps" />
            <token id="14" string="Bill" />
            <token id="15" string="in" />
            <token id="16" string="Congress" />
          </tokens>
        </chunking>
        <chunking id="2" string="opposed the Police Corps Bill in Congress" type="VP">
          <tokens>
            <token id="10" string="opposed" />
            <token id="11" string="the" />
            <token id="12" string="Police" />
            <token id="13" string="Corps" />
            <token id="14" string="Bill" />
            <token id="15" string="in" />
            <token id="16" string="Congress" />
          </tokens>
        </chunking>
        <chunking id="3" string="Many chiefs" type="NP">
          <tokens>
            <token id="1" string="Many" />
            <token id="2" string="chiefs" />
          </tokens>
        </chunking>
        <chunking id="4" string="Mr. Gates" type="NP">
          <tokens>
            <token id="6" string="Mr." />
            <token id="7" string="Gates" />
          </tokens>
        </chunking>
        <chunking id="5" string="he" type="NP">
          <tokens>
            <token id="9" string="he" />
          </tokens>
        </chunking>
        <chunking id="6" string="the Police Corps Bill" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="Police" />
            <token id="13" string="Corps" />
            <token id="14" string="Bill" />
          </tokens>
        </chunking>
        <chunking id="7" string="disagreed with Mr. Gates when he opposed the Police Corps Bill in Congress" type="VP">
          <tokens>
            <token id="4" string="disagreed" />
            <token id="5" string="with" />
            <token id="6" string="Mr." />
            <token id="7" string="Gates" />
            <token id="8" string="when" />
            <token id="9" string="he" />
            <token id="10" string="opposed" />
            <token id="11" string="the" />
            <token id="12" string="Police" />
            <token id="13" string="Corps" />
            <token id="14" string="Bill" />
            <token id="15" string="in" />
            <token id="16" string="Congress" />
          </tokens>
        </chunking>
        <chunking id="8" string="when he opposed the Police Corps Bill in Congress" type="SBAR">
          <tokens>
            <token id="8" string="when" />
            <token id="9" string="he" />
            <token id="10" string="opposed" />
            <token id="11" string="the" />
            <token id="12" string="Police" />
            <token id="13" string="Corps" />
            <token id="14" string="Bill" />
            <token id="15" string="in" />
            <token id="16" string="Congress" />
          </tokens>
        </chunking>
        <chunking id="9" string="when" type="WHADVP">
          <tokens>
            <token id="8" string="when" />
          </tokens>
        </chunking>
        <chunking id="10" string="Congress" type="NP">
          <tokens>
            <token id="16" string="Congress" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">chiefs</governor>
          <dependent id="1">Many</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">disagreed</governor>
          <dependent id="2">chiefs</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">disagreed</governor>
          <dependent id="3">openly</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">disagreed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Gates</governor>
          <dependent id="5">with</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Gates</governor>
          <dependent id="6">Mr.</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">disagreed</governor>
          <dependent id="7">Gates</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">opposed</governor>
          <dependent id="8">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">opposed</governor>
          <dependent id="9">he</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">disagreed</governor>
          <dependent id="10">opposed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">Bill</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Bill</governor>
          <dependent id="12">Police</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Bill</governor>
          <dependent id="13">Corps</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">opposed</governor>
          <dependent id="14">Bill</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">Congress</governor>
          <dependent id="15">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">Bill</governor>
          <dependent id="16">Congress</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Gates" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Gates" />
          </tokens>
        </entity>
        <entity id="2" string="Congress" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="16" string="Congress" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>We should be as openly critical of his other statements.</content>
      <tokens>
        <token id="1" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="should" lemma="should" stem="should" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="openly" lemma="openly" stem="openli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="critical" lemma="critical" stem="critic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="statements" lemma="statement" stem="statement" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP We)) (VP (MD should) (VP (VB be) (SBAR (IN as) (S (ADVP (RB openly)) (ADJP (JJ critical) (PP (IN of) (NP (PRP$ his) (JJ other) (NNS statements)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="be as openly critical of his other statements" type="VP">
          <tokens>
            <token id="3" string="be" />
            <token id="4" string="as" />
            <token id="5" string="openly" />
            <token id="6" string="critical" />
            <token id="7" string="of" />
            <token id="8" string="his" />
            <token id="9" string="other" />
            <token id="10" string="statements" />
          </tokens>
        </chunking>
        <chunking id="2" string="as openly critical of his other statements" type="SBAR">
          <tokens>
            <token id="4" string="as" />
            <token id="5" string="openly" />
            <token id="6" string="critical" />
            <token id="7" string="of" />
            <token id="8" string="his" />
            <token id="9" string="other" />
            <token id="10" string="statements" />
          </tokens>
        </chunking>
        <chunking id="3" string="critical of his other statements" type="ADJP">
          <tokens>
            <token id="6" string="critical" />
            <token id="7" string="of" />
            <token id="8" string="his" />
            <token id="9" string="other" />
            <token id="10" string="statements" />
          </tokens>
        </chunking>
        <chunking id="4" string="We" type="NP">
          <tokens>
            <token id="1" string="We" />
          </tokens>
        </chunking>
        <chunking id="5" string="his other statements" type="NP">
          <tokens>
            <token id="8" string="his" />
            <token id="9" string="other" />
            <token id="10" string="statements" />
          </tokens>
        </chunking>
        <chunking id="6" string="should be as openly critical of his other statements" type="VP">
          <tokens>
            <token id="2" string="should" />
            <token id="3" string="be" />
            <token id="4" string="as" />
            <token id="5" string="openly" />
            <token id="6" string="critical" />
            <token id="7" string="of" />
            <token id="8" string="his" />
            <token id="9" string="other" />
            <token id="10" string="statements" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">be</governor>
          <dependent id="1">We</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">be</governor>
          <dependent id="2">should</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">be</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">critical</governor>
          <dependent id="4">as</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">critical</governor>
          <dependent id="5">openly</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">be</governor>
          <dependent id="6">critical</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">statements</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">statements</governor>
          <dependent id="8">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">statements</governor>
          <dependent id="9">other</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">critical</governor>
          <dependent id="10">statements</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>For example, Mr. Gates once said that blacks were more susceptible than &amp;quot;normal people&amp;quot; to chokeholds.</content>
      <tokens>
        <token id="1" string="For" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="example" lemma="example" stem="exampl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="Gates" lemma="Gates" stem="gate" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="6" string="once" lemma="once" stem="onc" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="7" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="blacks" lemma="black" stem="black" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="susceptible" lemma="susceptible" stem="suscept" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="normal" lemma="normal" stem="normal" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="chokeholds" lemma="chokehold" stem="chokehold" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN For) (NP (NN example))) (, ,) (NP (NNP Mr.) (NNP Gates)) (ADVP (RB once)) (VP (VBD said) (SBAR (IN that) (S (NP (NNS blacks)) (VP (VBD were) (ADJP (RBR more) (JJ susceptible) (PP (IN than) (`` ``) (NP (JJ normal) (NNS people)) ('' ''))) (PP (TO to) (NP (NNS chokeholds))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="more susceptible than `` normal people ''" type="ADJP">
          <tokens>
            <token id="11" string="more" />
            <token id="12" string="susceptible" />
            <token id="13" string="than" />
            <token id="14" string="&quot;" />
            <token id="15" string="normal" />
            <token id="16" string="people" />
            <token id="17" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="2" string="normal people" type="NP">
          <tokens>
            <token id="15" string="normal" />
            <token id="16" string="people" />
          </tokens>
        </chunking>
        <chunking id="3" string="that blacks were more susceptible than `` normal people '' to chokeholds" type="SBAR">
          <tokens>
            <token id="8" string="that" />
            <token id="9" string="blacks" />
            <token id="10" string="were" />
            <token id="11" string="more" />
            <token id="12" string="susceptible" />
            <token id="13" string="than" />
            <token id="14" string="&quot;" />
            <token id="15" string="normal" />
            <token id="16" string="people" />
            <token id="17" string="&quot;" />
            <token id="18" string="to" />
            <token id="19" string="chokeholds" />
          </tokens>
        </chunking>
        <chunking id="4" string="were more susceptible than `` normal people '' to chokeholds" type="VP">
          <tokens>
            <token id="10" string="were" />
            <token id="11" string="more" />
            <token id="12" string="susceptible" />
            <token id="13" string="than" />
            <token id="14" string="&quot;" />
            <token id="15" string="normal" />
            <token id="16" string="people" />
            <token id="17" string="&quot;" />
            <token id="18" string="to" />
            <token id="19" string="chokeholds" />
          </tokens>
        </chunking>
        <chunking id="5" string="chokeholds" type="NP">
          <tokens>
            <token id="19" string="chokeholds" />
          </tokens>
        </chunking>
        <chunking id="6" string="blacks" type="NP">
          <tokens>
            <token id="9" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="7" string="said that blacks were more susceptible than `` normal people '' to chokeholds" type="VP">
          <tokens>
            <token id="7" string="said" />
            <token id="8" string="that" />
            <token id="9" string="blacks" />
            <token id="10" string="were" />
            <token id="11" string="more" />
            <token id="12" string="susceptible" />
            <token id="13" string="than" />
            <token id="14" string="&quot;" />
            <token id="15" string="normal" />
            <token id="16" string="people" />
            <token id="17" string="&quot;" />
            <token id="18" string="to" />
            <token id="19" string="chokeholds" />
          </tokens>
        </chunking>
        <chunking id="8" string="Mr. Gates" type="NP">
          <tokens>
            <token id="4" string="Mr." />
            <token id="5" string="Gates" />
          </tokens>
        </chunking>
        <chunking id="9" string="example" type="NP">
          <tokens>
            <token id="2" string="example" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">example</governor>
          <dependent id="1">For</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">said</governor>
          <dependent id="2">example</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Gates</governor>
          <dependent id="4">Mr.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">said</governor>
          <dependent id="5">Gates</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">said</governor>
          <dependent id="6">once</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">said</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">susceptible</governor>
          <dependent id="8">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">susceptible</governor>
          <dependent id="9">blacks</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">susceptible</governor>
          <dependent id="10">were</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">susceptible</governor>
          <dependent id="11">more</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">said</governor>
          <dependent id="12">susceptible</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">people</governor>
          <dependent id="13">than</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">people</governor>
          <dependent id="15">normal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">susceptible</governor>
          <dependent id="16">people</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">chokeholds</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">susceptible</governor>
          <dependent id="19">chokeholds</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Gates" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Gates" />
          </tokens>
        </entity>
        <entity id="2" string="once" type="DATE" score="0.0">
          <tokens>
            <token id="6" string="once" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>More recently, he described the killer of a policewoman as an &amp;quot;El Salvadoran, who shouldn&amp;apost;t have been here.&amp;quot;</content>
      <tokens>
        <token id="1" string="More" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="recently" lemma="recently" stem="recent" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="described" lemma="describe" stem="describ" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="killer" lemma="killer" stem="killer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="policewoman" lemma="policewoman" stem="policewoman" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="El" lemma="El" stem="el" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="Salvadoran" lemma="salvadoran" stem="salvadoran" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="should" lemma="should" stem="should" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="here" lemma="here" stem="here" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RBR More) (RB recently)) (, ,) (NP (PRP he)) (VP (VBD described) (NP (NP (DT the) (NN killer)) (PP (IN of) (NP (DT a) (NN policewoman)))) (PP (IN as) (NP (DT an) (`` ``) (NNP El))) (NP-TMP (NP (JJ Salvadoran)) (, ,) (SBAR (WHNP (WP who)) (S (VP (MD should) (RB n't) (VP (VB have) (VP (VBN been) (ADVP (RB here))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="described the killer of a policewoman as an `` El Salvadoran , who should n't have been here" type="VP">
          <tokens>
            <token id="5" string="described" />
            <token id="6" string="the" />
            <token id="7" string="killer" />
            <token id="8" string="of" />
            <token id="9" string="a" />
            <token id="10" string="policewoman" />
            <token id="11" string="as" />
            <token id="12" string="an" />
            <token id="13" string="&quot;" />
            <token id="14" string="El" />
            <token id="15" string="Salvadoran" />
            <token id="16" string="," />
            <token id="17" string="who" />
            <token id="18" string="should" />
            <token id="19" string="n't" />
            <token id="20" string="have" />
            <token id="21" string="been" />
            <token id="22" string="here" />
          </tokens>
        </chunking>
        <chunking id="2" string="the killer of a policewoman" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="killer" />
            <token id="8" string="of" />
            <token id="9" string="a" />
            <token id="10" string="policewoman" />
          </tokens>
        </chunking>
        <chunking id="3" string="been here" type="VP">
          <tokens>
            <token id="21" string="been" />
            <token id="22" string="here" />
          </tokens>
        </chunking>
        <chunking id="4" string="the killer" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="killer" />
          </tokens>
        </chunking>
        <chunking id="5" string="a policewoman" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="policewoman" />
          </tokens>
        </chunking>
        <chunking id="6" string="should n't have been here" type="VP">
          <tokens>
            <token id="18" string="should" />
            <token id="19" string="n't" />
            <token id="20" string="have" />
            <token id="21" string="been" />
            <token id="22" string="here" />
          </tokens>
        </chunking>
        <chunking id="7" string="have been here" type="VP">
          <tokens>
            <token id="20" string="have" />
            <token id="21" string="been" />
            <token id="22" string="here" />
          </tokens>
        </chunking>
        <chunking id="8" string="he" type="NP">
          <tokens>
            <token id="4" string="he" />
          </tokens>
        </chunking>
        <chunking id="9" string="an `` El" type="NP">
          <tokens>
            <token id="12" string="an" />
            <token id="13" string="&quot;" />
            <token id="14" string="El" />
          </tokens>
        </chunking>
        <chunking id="10" string="Salvadoran" type="NP">
          <tokens>
            <token id="15" string="Salvadoran" />
          </tokens>
        </chunking>
        <chunking id="11" string="who should n't have been here" type="SBAR">
          <tokens>
            <token id="17" string="who" />
            <token id="18" string="should" />
            <token id="19" string="n't" />
            <token id="20" string="have" />
            <token id="21" string="been" />
            <token id="22" string="here" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="2">recently</governor>
          <dependent id="1">More</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">described</governor>
          <dependent id="2">recently</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">described</governor>
          <dependent id="4">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">described</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">killer</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">described</governor>
          <dependent id="7">killer</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">policewoman</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">policewoman</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">killer</governor>
          <dependent id="10">policewoman</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">El</governor>
          <dependent id="11">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">El</governor>
          <dependent id="12">an</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">described</governor>
          <dependent id="14">El</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="5">described</governor>
          <dependent id="15">Salvadoran</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">been</governor>
          <dependent id="17">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">been</governor>
          <dependent id="18">should</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="21">been</governor>
          <dependent id="19">n't</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">been</governor>
          <dependent id="20">have</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="15">Salvadoran</governor>
          <dependent id="21">been</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="21">been</governor>
          <dependent id="22">here</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="recently" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="recently" />
          </tokens>
        </entity>
        <entity id="2" string="Salvadoran" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="15" string="Salvadoran" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="false">
      <content>The nationality of the murderer was irrelevant.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="nationality" lemma="nationality" stem="nation" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="murderer" lemma="murderer" stem="murder" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="irrelevant" lemma="irrelevant" stem="irrelev" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NN nationality)) (PP (IN of) (NP (DT the) (NN murderer)))) (VP (VBD was) (ADJP (JJ irrelevant))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="irrelevant" type="ADJP">
          <tokens>
            <token id="7" string="irrelevant" />
          </tokens>
        </chunking>
        <chunking id="2" string="The nationality of the murderer" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="nationality" />
            <token id="3" string="of" />
            <token id="4" string="the" />
            <token id="5" string="murderer" />
          </tokens>
        </chunking>
        <chunking id="3" string="the murderer" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="murderer" />
          </tokens>
        </chunking>
        <chunking id="4" string="The nationality" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="nationality" />
          </tokens>
        </chunking>
        <chunking id="5" string="was irrelevant" type="VP">
          <tokens>
            <token id="6" string="was" />
            <token id="7" string="irrelevant" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">nationality</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">irrelevant</governor>
          <dependent id="2">nationality</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">murderer</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">murderer</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">nationality</governor>
          <dependent id="5">murderer</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">irrelevant</governor>
          <dependent id="6">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">irrelevant</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>Mr. Gates&amp;apost;s statement did nothing to lessen the tragedy of the fallen officer, but like his statement about blacks, it gave comfort to bigots within and outside the department.</content>
      <tokens>
        <token id="1" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="2" string="Gates" lemma="Gates" stem="gate" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="3" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="4" string="statement" lemma="statement" stem="statement" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="nothing" lemma="nothing" stem="noth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="lessen" lemma="lessen" stem="lessen" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="tragedy" lemma="tragedy" stem="tragedi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="fallen" lemma="fall" stem="fallen" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="19" string="statement" lemma="statement" stem="statement" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="blacks" lemma="black" stem="black" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="gave" lemma="give" stem="gave" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="comfort" lemma="comfort" stem="comfort" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="bigots" lemma="bigot" stem="bigot" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="within" lemma="within" stem="within" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="outside" lemma="outside" stem="outsid" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="32" string="department" lemma="department" stem="depart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (NNP Mr.) (NNP Gates) (POS 's)) (NN statement)) (VP (VBD did) (NP (NN nothing)) (S (VP (TO to) (VP (VB lessen) (NP (NP (DT the) (NN tragedy)) (PP (IN of) (NP (DT the) (VBN fallen) (NN officer))))))))) (, ,) (CC but) (S (PP (IN like) (NP (NP (PRP$ his) (NN statement)) (PP (IN about) (NP (NNS blacks))))) (, ,) (NP (PRP it)) (VP (VBD gave) (NP (NN comfort)) (PP (TO to) (NP (NNS bigots))) (PP (IN within) (CC and) (IN outside) (NP (DT the) (NN department))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="did nothing to lessen the tragedy of the fallen officer" type="VP">
          <tokens>
            <token id="5" string="did" />
            <token id="6" string="nothing" />
            <token id="7" string="to" />
            <token id="8" string="lessen" />
            <token id="9" string="the" />
            <token id="10" string="tragedy" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="fallen" />
            <token id="14" string="officer" />
          </tokens>
        </chunking>
        <chunking id="2" string="nothing" type="NP">
          <tokens>
            <token id="6" string="nothing" />
          </tokens>
        </chunking>
        <chunking id="3" string="his statement about blacks" type="NP">
          <tokens>
            <token id="18" string="his" />
            <token id="19" string="statement" />
            <token id="20" string="about" />
            <token id="21" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="4" string="lessen the tragedy of the fallen officer" type="VP">
          <tokens>
            <token id="8" string="lessen" />
            <token id="9" string="the" />
            <token id="10" string="tragedy" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="fallen" />
            <token id="14" string="officer" />
          </tokens>
        </chunking>
        <chunking id="5" string="blacks" type="NP">
          <tokens>
            <token id="21" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="6" string="comfort" type="NP">
          <tokens>
            <token id="25" string="comfort" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="23" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="Mr. Gates 's statement" type="NP">
          <tokens>
            <token id="1" string="Mr." />
            <token id="2" string="Gates" />
            <token id="3" string="'s" />
            <token id="4" string="statement" />
          </tokens>
        </chunking>
        <chunking id="9" string="the department" type="NP">
          <tokens>
            <token id="31" string="the" />
            <token id="32" string="department" />
          </tokens>
        </chunking>
        <chunking id="10" string="Mr. Gates 's" type="NP">
          <tokens>
            <token id="1" string="Mr." />
            <token id="2" string="Gates" />
            <token id="3" string="'s" />
          </tokens>
        </chunking>
        <chunking id="11" string="the fallen officer" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="fallen" />
            <token id="14" string="officer" />
          </tokens>
        </chunking>
        <chunking id="12" string="the tragedy" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="tragedy" />
          </tokens>
        </chunking>
        <chunking id="13" string="his statement" type="NP">
          <tokens>
            <token id="18" string="his" />
            <token id="19" string="statement" />
          </tokens>
        </chunking>
        <chunking id="14" string="gave comfort to bigots within and outside the department" type="VP">
          <tokens>
            <token id="24" string="gave" />
            <token id="25" string="comfort" />
            <token id="26" string="to" />
            <token id="27" string="bigots" />
            <token id="28" string="within" />
            <token id="29" string="and" />
            <token id="30" string="outside" />
            <token id="31" string="the" />
            <token id="32" string="department" />
          </tokens>
        </chunking>
        <chunking id="15" string="the tragedy of the fallen officer" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="tragedy" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="fallen" />
            <token id="14" string="officer" />
          </tokens>
        </chunking>
        <chunking id="16" string="to lessen the tragedy of the fallen officer" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="lessen" />
            <token id="9" string="the" />
            <token id="10" string="tragedy" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="fallen" />
            <token id="14" string="officer" />
          </tokens>
        </chunking>
        <chunking id="17" string="bigots" type="NP">
          <tokens>
            <token id="27" string="bigots" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Gates</governor>
          <dependent id="1">Mr.</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">statement</governor>
          <dependent id="2">Gates</dependent>
        </dependency>
        <dependency type="case">
          <governor id="2">Gates</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">did</governor>
          <dependent id="4">statement</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">did</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">did</governor>
          <dependent id="6">nothing</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">lessen</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">did</governor>
          <dependent id="8">lessen</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">tragedy</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">lessen</governor>
          <dependent id="10">tragedy</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">officer</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">officer</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">officer</governor>
          <dependent id="13">fallen</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">tragedy</governor>
          <dependent id="14">officer</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">did</governor>
          <dependent id="16">but</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">statement</governor>
          <dependent id="17">like</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">statement</governor>
          <dependent id="18">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">gave</governor>
          <dependent id="19">statement</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">blacks</governor>
          <dependent id="20">about</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">statement</governor>
          <dependent id="21">blacks</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">gave</governor>
          <dependent id="23">it</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">did</governor>
          <dependent id="24">gave</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="24">gave</governor>
          <dependent id="24">gave</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">gave</governor>
          <dependent id="25">comfort</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">bigots</governor>
          <dependent id="26">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">gave</governor>
          <dependent id="27">bigots</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">department</governor>
          <dependent id="28">within</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="28">within</governor>
          <dependent id="29">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="28">within</governor>
          <dependent id="30">outside</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">department</governor>
          <dependent id="31">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">gave</governor>
          <dependent id="32">department</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">gave</governor>
          <dependent id="32">department</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Gates" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Gates" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>And it hardly reduced conflict in a city where the majority of the population is made up of minorities who need and deserve police protection, whether or not they are citizens.</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="hardly" lemma="hardly" stem="hardli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="reduced" lemma="reduce" stem="reduc" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="conflict" lemma="conflict" stem="conflict" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="city" lemma="city" stem="citi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="majority" lemma="majority" stem="major" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="population" lemma="population" stem="popul" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="made" lemma="make" stem="made" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="minorities" lemma="minority" stem="minor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="need" lemma="need" stem="need" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="deserve" lemma="deserve" stem="deserv" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="police" lemma="police" stem="polic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="protection" lemma="protection" stem="protect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="whether" lemma="whether" stem="whether" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="citizens" lemma="citizen" stem="citizen" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC And) (NP (PRP it)) (ADVP (RB hardly)) (VP (VBD reduced) (NP (NN conflict)) (PP (IN in) (NP (DT a) (NN city))) (SBAR (WHADVP (WRB where)) (S (NP (NP (DT the) (NN majority)) (PP (IN of) (NP (DT the) (NN population)))) (VP (VBZ is) (VP (VBN made) (PRT (RP up)) (PP (IN of) (NP (NP (NNS minorities)) (SBAR (WHNP (WP who)) (S (VP (VBP need) (CC and) (VBP deserve) (NP (NNS police) (NN protection)) (, ,) (SBAR (IN whether) (CC or) (RB not) (S (NP (PRP they)) (VP (VBP are) (NP (NNS citizens))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the majority of the population" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="majority" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="population" />
          </tokens>
        </chunking>
        <chunking id="2" string="where the majority of the population is made up of minorities who need and deserve police protection , whether or not they are citizens" type="SBAR">
          <tokens>
            <token id="9" string="where" />
            <token id="10" string="the" />
            <token id="11" string="majority" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="population" />
            <token id="15" string="is" />
            <token id="16" string="made" />
            <token id="17" string="up" />
            <token id="18" string="of" />
            <token id="19" string="minorities" />
            <token id="20" string="who" />
            <token id="21" string="need" />
            <token id="22" string="and" />
            <token id="23" string="deserve" />
            <token id="24" string="police" />
            <token id="25" string="protection" />
            <token id="26" string="," />
            <token id="27" string="whether" />
            <token id="28" string="or" />
            <token id="29" string="not" />
            <token id="30" string="they" />
            <token id="31" string="are" />
            <token id="32" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="3" string="minorities" type="NP">
          <tokens>
            <token id="19" string="minorities" />
          </tokens>
        </chunking>
        <chunking id="4" string="who need and deserve police protection , whether or not they are citizens" type="SBAR">
          <tokens>
            <token id="20" string="who" />
            <token id="21" string="need" />
            <token id="22" string="and" />
            <token id="23" string="deserve" />
            <token id="24" string="police" />
            <token id="25" string="protection" />
            <token id="26" string="," />
            <token id="27" string="whether" />
            <token id="28" string="or" />
            <token id="29" string="not" />
            <token id="30" string="they" />
            <token id="31" string="are" />
            <token id="32" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="2" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="is made up of minorities who need and deserve police protection , whether or not they are citizens" type="VP">
          <tokens>
            <token id="15" string="is" />
            <token id="16" string="made" />
            <token id="17" string="up" />
            <token id="18" string="of" />
            <token id="19" string="minorities" />
            <token id="20" string="who" />
            <token id="21" string="need" />
            <token id="22" string="and" />
            <token id="23" string="deserve" />
            <token id="24" string="police" />
            <token id="25" string="protection" />
            <token id="26" string="," />
            <token id="27" string="whether" />
            <token id="28" string="or" />
            <token id="29" string="not" />
            <token id="30" string="they" />
            <token id="31" string="are" />
            <token id="32" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="7" string="reduced conflict in a city where the majority of the population is made up of minorities who need and deserve police protection , whether or not they are citizens" type="VP">
          <tokens>
            <token id="4" string="reduced" />
            <token id="5" string="conflict" />
            <token id="6" string="in" />
            <token id="7" string="a" />
            <token id="8" string="city" />
            <token id="9" string="where" />
            <token id="10" string="the" />
            <token id="11" string="majority" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="population" />
            <token id="15" string="is" />
            <token id="16" string="made" />
            <token id="17" string="up" />
            <token id="18" string="of" />
            <token id="19" string="minorities" />
            <token id="20" string="who" />
            <token id="21" string="need" />
            <token id="22" string="and" />
            <token id="23" string="deserve" />
            <token id="24" string="police" />
            <token id="25" string="protection" />
            <token id="26" string="," />
            <token id="27" string="whether" />
            <token id="28" string="or" />
            <token id="29" string="not" />
            <token id="30" string="they" />
            <token id="31" string="are" />
            <token id="32" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="8" string="need and deserve police protection , whether or not they are citizens" type="VP">
          <tokens>
            <token id="21" string="need" />
            <token id="22" string="and" />
            <token id="23" string="deserve" />
            <token id="24" string="police" />
            <token id="25" string="protection" />
            <token id="26" string="," />
            <token id="27" string="whether" />
            <token id="28" string="or" />
            <token id="29" string="not" />
            <token id="30" string="they" />
            <token id="31" string="are" />
            <token id="32" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="9" string="whether or not they are citizens" type="SBAR">
          <tokens>
            <token id="27" string="whether" />
            <token id="28" string="or" />
            <token id="29" string="not" />
            <token id="30" string="they" />
            <token id="31" string="are" />
            <token id="32" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="10" string="they" type="NP">
          <tokens>
            <token id="30" string="they" />
          </tokens>
        </chunking>
        <chunking id="11" string="the population" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="population" />
          </tokens>
        </chunking>
        <chunking id="12" string="are citizens" type="VP">
          <tokens>
            <token id="31" string="are" />
            <token id="32" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="13" string="made up of minorities who need and deserve police protection , whether or not they are citizens" type="VP">
          <tokens>
            <token id="16" string="made" />
            <token id="17" string="up" />
            <token id="18" string="of" />
            <token id="19" string="minorities" />
            <token id="20" string="who" />
            <token id="21" string="need" />
            <token id="22" string="and" />
            <token id="23" string="deserve" />
            <token id="24" string="police" />
            <token id="25" string="protection" />
            <token id="26" string="," />
            <token id="27" string="whether" />
            <token id="28" string="or" />
            <token id="29" string="not" />
            <token id="30" string="they" />
            <token id="31" string="are" />
            <token id="32" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="14" string="minorities who need and deserve police protection , whether or not they are citizens" type="NP">
          <tokens>
            <token id="19" string="minorities" />
            <token id="20" string="who" />
            <token id="21" string="need" />
            <token id="22" string="and" />
            <token id="23" string="deserve" />
            <token id="24" string="police" />
            <token id="25" string="protection" />
            <token id="26" string="," />
            <token id="27" string="whether" />
            <token id="28" string="or" />
            <token id="29" string="not" />
            <token id="30" string="they" />
            <token id="31" string="are" />
            <token id="32" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="15" string="where" type="WHADVP">
          <tokens>
            <token id="9" string="where" />
          </tokens>
        </chunking>
        <chunking id="16" string="conflict" type="NP">
          <tokens>
            <token id="5" string="conflict" />
          </tokens>
        </chunking>
        <chunking id="17" string="the majority" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="majority" />
          </tokens>
        </chunking>
        <chunking id="18" string="a city" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="city" />
          </tokens>
        </chunking>
        <chunking id="19" string="police protection" type="NP">
          <tokens>
            <token id="24" string="police" />
            <token id="25" string="protection" />
          </tokens>
        </chunking>
        <chunking id="20" string="citizens" type="NP">
          <tokens>
            <token id="32" string="citizens" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="4">reduced</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">reduced</governor>
          <dependent id="2">it</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">reduced</governor>
          <dependent id="3">hardly</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">reduced</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">reduced</governor>
          <dependent id="5">conflict</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">city</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">city</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">reduced</governor>
          <dependent id="8">city</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">made</governor>
          <dependent id="9">where</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">majority</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="16">made</governor>
          <dependent id="11">majority</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">population</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">population</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">majority</governor>
          <dependent id="14">population</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="16">made</governor>
          <dependent id="15">is</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">reduced</governor>
          <dependent id="16">made</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="16">made</governor>
          <dependent id="17">up</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">minorities</governor>
          <dependent id="18">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">made</governor>
          <dependent id="19">minorities</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">need</governor>
          <dependent id="20">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="19">minorities</governor>
          <dependent id="21">need</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="21">need</governor>
          <dependent id="22">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="21">need</governor>
          <dependent id="23">deserve</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">protection</governor>
          <dependent id="24">police</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">need</governor>
          <dependent id="25">protection</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="32">citizens</governor>
          <dependent id="27">whether</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="27">whether</governor>
          <dependent id="28">or</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="27">whether</governor>
          <dependent id="29">not</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="32">citizens</governor>
          <dependent id="30">they</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="32">citizens</governor>
          <dependent id="31">are</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="21">need</governor>
          <dependent id="32">citizens</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>Two years ago, on a national television documentary, Mr. Gates defended a special unit that had shot many criminals during stakeouts.</content>
      <tokens>
        <token id="1" string="Two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="2" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="ago" lemma="ago" stem="ago" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="national" lemma="national" stem="nation" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="television" lemma="television" stem="televis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="documentary" lemma="documentary" stem="documentari" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="Gates" lemma="Gates" stem="gate" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="13" string="defended" lemma="defend" stem="defend" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="special" lemma="special" stem="special" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="unit" lemma="unit" stem="unit" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="shot" lemma="shoot" stem="shot" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="criminals" lemma="criminal" stem="crimin" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="during" lemma="during" stem="dure" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="stakeouts" lemma="stakeout" stem="stakeout" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (NP (CD Two) (NNS years)) (RB ago)) (, ,) (PP (IN on) (NP (DT a) (JJ national) (NN television) (NN documentary))) (, ,) (NP (NNP Mr.) (NNP Gates)) (VP (VBD defended) (NP (NP (DT a) (JJ special) (NN unit)) (SBAR (WHNP (WDT that)) (S (VP (VBD had) (VP (VBN shot) (NP (JJ many) (NNS criminals)) (PP (IN during) (NP (NNS stakeouts))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that had shot many criminals during stakeouts" type="SBAR">
          <tokens>
            <token id="17" string="that" />
            <token id="18" string="had" />
            <token id="19" string="shot" />
            <token id="20" string="many" />
            <token id="21" string="criminals" />
            <token id="22" string="during" />
            <token id="23" string="stakeouts" />
          </tokens>
        </chunking>
        <chunking id="2" string="stakeouts" type="NP">
          <tokens>
            <token id="23" string="stakeouts" />
          </tokens>
        </chunking>
        <chunking id="3" string="a national television documentary" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="national" />
            <token id="8" string="television" />
            <token id="9" string="documentary" />
          </tokens>
        </chunking>
        <chunking id="4" string="Two years" type="NP">
          <tokens>
            <token id="1" string="Two" />
            <token id="2" string="years" />
          </tokens>
        </chunking>
        <chunking id="5" string="had shot many criminals during stakeouts" type="VP">
          <tokens>
            <token id="18" string="had" />
            <token id="19" string="shot" />
            <token id="20" string="many" />
            <token id="21" string="criminals" />
            <token id="22" string="during" />
            <token id="23" string="stakeouts" />
          </tokens>
        </chunking>
        <chunking id="6" string="shot many criminals during stakeouts" type="VP">
          <tokens>
            <token id="19" string="shot" />
            <token id="20" string="many" />
            <token id="21" string="criminals" />
            <token id="22" string="during" />
            <token id="23" string="stakeouts" />
          </tokens>
        </chunking>
        <chunking id="7" string="many criminals" type="NP">
          <tokens>
            <token id="20" string="many" />
            <token id="21" string="criminals" />
          </tokens>
        </chunking>
        <chunking id="8" string="defended a special unit that had shot many criminals during stakeouts" type="VP">
          <tokens>
            <token id="13" string="defended" />
            <token id="14" string="a" />
            <token id="15" string="special" />
            <token id="16" string="unit" />
            <token id="17" string="that" />
            <token id="18" string="had" />
            <token id="19" string="shot" />
            <token id="20" string="many" />
            <token id="21" string="criminals" />
            <token id="22" string="during" />
            <token id="23" string="stakeouts" />
          </tokens>
        </chunking>
        <chunking id="9" string="a special unit" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="special" />
            <token id="16" string="unit" />
          </tokens>
        </chunking>
        <chunking id="10" string="Mr. Gates" type="NP">
          <tokens>
            <token id="11" string="Mr." />
            <token id="12" string="Gates" />
          </tokens>
        </chunking>
        <chunking id="11" string="a special unit that had shot many criminals during stakeouts" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="special" />
            <token id="16" string="unit" />
            <token id="17" string="that" />
            <token id="18" string="had" />
            <token id="19" string="shot" />
            <token id="20" string="many" />
            <token id="21" string="criminals" />
            <token id="22" string="during" />
            <token id="23" string="stakeouts" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nummod">
          <governor id="2">years</governor>
          <dependent id="1">Two</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="3">ago</governor>
          <dependent id="2">years</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">defended</governor>
          <dependent id="3">ago</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">documentary</governor>
          <dependent id="5">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">documentary</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">documentary</governor>
          <dependent id="7">national</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">documentary</governor>
          <dependent id="8">television</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">defended</governor>
          <dependent id="9">documentary</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Gates</governor>
          <dependent id="11">Mr.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">defended</governor>
          <dependent id="12">Gates</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">defended</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">unit</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">unit</governor>
          <dependent id="15">special</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">defended</governor>
          <dependent id="16">unit</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">shot</governor>
          <dependent id="17">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="19">shot</governor>
          <dependent id="18">had</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="16">unit</governor>
          <dependent id="19">shot</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">criminals</governor>
          <dependent id="20">many</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">shot</governor>
          <dependent id="21">criminals</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">stakeouts</governor>
          <dependent id="22">during</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">shot</governor>
          <dependent id="23">stakeouts</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Gates" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Gates" />
          </tokens>
        </entity>
        <entity id="2" string="Two years ago" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="Two" />
            <token id="2" string="years" />
            <token id="3" string="ago" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>The unit had advance knowledge that crimes were about to occur, but often stayed outside and let robberies occur, even though innocent retailers and customers were put at risk.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="unit" lemma="unit" stem="unit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="advance" lemma="advance" stem="advanc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="knowledge" lemma="knowledge" stem="knowledg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="crimes" lemma="crime" stem="crime" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="about" lemma="about" stem="about" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="occur" lemma="occur" stem="occur" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="often" lemma="often" stem="often" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="stayed" lemma="stay" stem="stai" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="outside" lemma="outside" stem="outsid" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="let" lemma="let" stem="let" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="robberies" lemma="robbery" stem="robberi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="occur" lemma="occur" stem="occur" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="though" lemma="though" stem="though" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="innocent" lemma="innocent" stem="innoc" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="retailers" lemma="retailer" stem="retail" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="customers" lemma="customer" stem="custom" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="put" lemma="put" stem="put" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="risk" lemma="risk" stem="risk" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN unit)) (VP (VBD had) (NP (NP (NN advance) (NN knowledge)) (SBAR (WHNP (WDT that)) (S (NP (NNS crimes)) (VP (VBD were) (VP (RB about) (S (VP (TO to) (VP (VP (VP (VB occur)) (, ,) (CC but) (ADVP (RB often)) (VP (VBD stayed) (ADVP (JJ outside)))) (CC and) (VP (VB let) (S (NP (NNS robberies)) (VP (VB occur))))))) (, ,) (SBAR (RB even) (IN though) (S (NP (JJ innocent) (NNS retailers) (CC and) (NNS customers)) (VP (VBD were) (VP (VBN put) (PP (IN at) (NP (NN risk))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="advance knowledge that crimes were about to occur , but often stayed outside and let robberies occur , even though innocent retailers and customers were put at risk" type="NP">
          <tokens>
            <token id="4" string="advance" />
            <token id="5" string="knowledge" />
            <token id="6" string="that" />
            <token id="7" string="crimes" />
            <token id="8" string="were" />
            <token id="9" string="about" />
            <token id="10" string="to" />
            <token id="11" string="occur" />
            <token id="12" string="," />
            <token id="13" string="but" />
            <token id="14" string="often" />
            <token id="15" string="stayed" />
            <token id="16" string="outside" />
            <token id="17" string="and" />
            <token id="18" string="let" />
            <token id="19" string="robberies" />
            <token id="20" string="occur" />
            <token id="21" string="," />
            <token id="22" string="even" />
            <token id="23" string="though" />
            <token id="24" string="innocent" />
            <token id="25" string="retailers" />
            <token id="26" string="and" />
            <token id="27" string="customers" />
            <token id="28" string="were" />
            <token id="29" string="put" />
            <token id="30" string="at" />
            <token id="31" string="risk" />
          </tokens>
        </chunking>
        <chunking id="2" string="occur" type="VP">
          <tokens>
            <token id="11" string="occur" />
          </tokens>
        </chunking>
        <chunking id="3" string="occur , but often stayed outside and let robberies occur" type="VP">
          <tokens>
            <token id="11" string="occur" />
            <token id="12" string="," />
            <token id="13" string="but" />
            <token id="14" string="often" />
            <token id="15" string="stayed" />
            <token id="16" string="outside" />
            <token id="17" string="and" />
            <token id="18" string="let" />
            <token id="19" string="robberies" />
            <token id="20" string="occur" />
          </tokens>
        </chunking>
        <chunking id="4" string="let robberies occur" type="VP">
          <tokens>
            <token id="18" string="let" />
            <token id="19" string="robberies" />
            <token id="20" string="occur" />
          </tokens>
        </chunking>
        <chunking id="5" string="crimes" type="NP">
          <tokens>
            <token id="7" string="crimes" />
          </tokens>
        </chunking>
        <chunking id="6" string="put at risk" type="VP">
          <tokens>
            <token id="29" string="put" />
            <token id="30" string="at" />
            <token id="31" string="risk" />
          </tokens>
        </chunking>
        <chunking id="7" string="even though innocent retailers and customers were put at risk" type="SBAR">
          <tokens>
            <token id="22" string="even" />
            <token id="23" string="though" />
            <token id="24" string="innocent" />
            <token id="25" string="retailers" />
            <token id="26" string="and" />
            <token id="27" string="customers" />
            <token id="28" string="were" />
            <token id="29" string="put" />
            <token id="30" string="at" />
            <token id="31" string="risk" />
          </tokens>
        </chunking>
        <chunking id="8" string="stayed outside" type="VP">
          <tokens>
            <token id="15" string="stayed" />
            <token id="16" string="outside" />
          </tokens>
        </chunking>
        <chunking id="9" string="The unit" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="unit" />
          </tokens>
        </chunking>
        <chunking id="10" string="that crimes were about to occur , but often stayed outside and let robberies occur , even though innocent retailers and customers were put at risk" type="SBAR">
          <tokens>
            <token id="6" string="that" />
            <token id="7" string="crimes" />
            <token id="8" string="were" />
            <token id="9" string="about" />
            <token id="10" string="to" />
            <token id="11" string="occur" />
            <token id="12" string="," />
            <token id="13" string="but" />
            <token id="14" string="often" />
            <token id="15" string="stayed" />
            <token id="16" string="outside" />
            <token id="17" string="and" />
            <token id="18" string="let" />
            <token id="19" string="robberies" />
            <token id="20" string="occur" />
            <token id="21" string="," />
            <token id="22" string="even" />
            <token id="23" string="though" />
            <token id="24" string="innocent" />
            <token id="25" string="retailers" />
            <token id="26" string="and" />
            <token id="27" string="customers" />
            <token id="28" string="were" />
            <token id="29" string="put" />
            <token id="30" string="at" />
            <token id="31" string="risk" />
          </tokens>
        </chunking>
        <chunking id="11" string="occur , but often stayed outside" type="VP">
          <tokens>
            <token id="11" string="occur" />
            <token id="12" string="," />
            <token id="13" string="but" />
            <token id="14" string="often" />
            <token id="15" string="stayed" />
            <token id="16" string="outside" />
          </tokens>
        </chunking>
        <chunking id="12" string="advance knowledge" type="NP">
          <tokens>
            <token id="4" string="advance" />
            <token id="5" string="knowledge" />
          </tokens>
        </chunking>
        <chunking id="13" string="robberies" type="NP">
          <tokens>
            <token id="19" string="robberies" />
          </tokens>
        </chunking>
        <chunking id="14" string="to occur , but often stayed outside and let robberies occur" type="VP">
          <tokens>
            <token id="10" string="to" />
            <token id="11" string="occur" />
            <token id="12" string="," />
            <token id="13" string="but" />
            <token id="14" string="often" />
            <token id="15" string="stayed" />
            <token id="16" string="outside" />
            <token id="17" string="and" />
            <token id="18" string="let" />
            <token id="19" string="robberies" />
            <token id="20" string="occur" />
          </tokens>
        </chunking>
        <chunking id="15" string="had advance knowledge that crimes were about to occur , but often stayed outside and let robberies occur , even though innocent retailers and customers were put at risk" type="VP">
          <tokens>
            <token id="3" string="had" />
            <token id="4" string="advance" />
            <token id="5" string="knowledge" />
            <token id="6" string="that" />
            <token id="7" string="crimes" />
            <token id="8" string="were" />
            <token id="9" string="about" />
            <token id="10" string="to" />
            <token id="11" string="occur" />
            <token id="12" string="," />
            <token id="13" string="but" />
            <token id="14" string="often" />
            <token id="15" string="stayed" />
            <token id="16" string="outside" />
            <token id="17" string="and" />
            <token id="18" string="let" />
            <token id="19" string="robberies" />
            <token id="20" string="occur" />
            <token id="21" string="," />
            <token id="22" string="even" />
            <token id="23" string="though" />
            <token id="24" string="innocent" />
            <token id="25" string="retailers" />
            <token id="26" string="and" />
            <token id="27" string="customers" />
            <token id="28" string="were" />
            <token id="29" string="put" />
            <token id="30" string="at" />
            <token id="31" string="risk" />
          </tokens>
        </chunking>
        <chunking id="16" string="were about to occur , but often stayed outside and let robberies occur , even though innocent retailers and customers were put at risk" type="VP">
          <tokens>
            <token id="8" string="were" />
            <token id="9" string="about" />
            <token id="10" string="to" />
            <token id="11" string="occur" />
            <token id="12" string="," />
            <token id="13" string="but" />
            <token id="14" string="often" />
            <token id="15" string="stayed" />
            <token id="16" string="outside" />
            <token id="17" string="and" />
            <token id="18" string="let" />
            <token id="19" string="robberies" />
            <token id="20" string="occur" />
            <token id="21" string="," />
            <token id="22" string="even" />
            <token id="23" string="though" />
            <token id="24" string="innocent" />
            <token id="25" string="retailers" />
            <token id="26" string="and" />
            <token id="27" string="customers" />
            <token id="28" string="were" />
            <token id="29" string="put" />
            <token id="30" string="at" />
            <token id="31" string="risk" />
          </tokens>
        </chunking>
        <chunking id="17" string="innocent retailers and customers" type="NP">
          <tokens>
            <token id="24" string="innocent" />
            <token id="25" string="retailers" />
            <token id="26" string="and" />
            <token id="27" string="customers" />
          </tokens>
        </chunking>
        <chunking id="18" string="about to occur , but often stayed outside and let robberies occur , even though innocent retailers and customers were put at risk" type="VP">
          <tokens>
            <token id="9" string="about" />
            <token id="10" string="to" />
            <token id="11" string="occur" />
            <token id="12" string="," />
            <token id="13" string="but" />
            <token id="14" string="often" />
            <token id="15" string="stayed" />
            <token id="16" string="outside" />
            <token id="17" string="and" />
            <token id="18" string="let" />
            <token id="19" string="robberies" />
            <token id="20" string="occur" />
            <token id="21" string="," />
            <token id="22" string="even" />
            <token id="23" string="though" />
            <token id="24" string="innocent" />
            <token id="25" string="retailers" />
            <token id="26" string="and" />
            <token id="27" string="customers" />
            <token id="28" string="were" />
            <token id="29" string="put" />
            <token id="30" string="at" />
            <token id="31" string="risk" />
          </tokens>
        </chunking>
        <chunking id="19" string="risk" type="NP">
          <tokens>
            <token id="31" string="risk" />
          </tokens>
        </chunking>
        <chunking id="20" string="were put at risk" type="VP">
          <tokens>
            <token id="28" string="were" />
            <token id="29" string="put" />
            <token id="30" string="at" />
            <token id="31" string="risk" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">unit</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">had</governor>
          <dependent id="2">unit</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">had</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">knowledge</governor>
          <dependent id="4">advance</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">had</governor>
          <dependent id="5">knowledge</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">occur</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">about</governor>
          <dependent id="7">crimes</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">about</governor>
          <dependent id="8">were</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="5">knowledge</governor>
          <dependent id="9">about</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">occur</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">about</governor>
          <dependent id="11">occur</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">occur</governor>
          <dependent id="13">but</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">stayed</governor>
          <dependent id="14">often</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">occur</governor>
          <dependent id="15">stayed</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">stayed</governor>
          <dependent id="16">outside</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">occur</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">occur</governor>
          <dependent id="18">let</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">occur</governor>
          <dependent id="19">robberies</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="18">let</governor>
          <dependent id="20">occur</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="29">put</governor>
          <dependent id="22">even</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="29">put</governor>
          <dependent id="23">though</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">retailers</governor>
          <dependent id="24">innocent</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="29">put</governor>
          <dependent id="25">retailers</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="25">retailers</governor>
          <dependent id="26">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="25">retailers</governor>
          <dependent id="27">customers</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="29">put</governor>
          <dependent id="28">were</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">about</governor>
          <dependent id="29">put</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">risk</governor>
          <dependent id="30">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">put</governor>
          <dependent id="31">risk</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>The chief said that arresting the criminals before the robberies wasn&amp;apost;t a good idea because the courts were so lenient.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="chief" lemma="chief" stem="chief" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="arresting" lemma="arrest" stem="arrest" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="criminals" lemma="criminal" stem="crimin" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="robberies" lemma="robbery" stem="robberi" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="good" lemma="good" stem="good" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="idea" lemma="idea" stem="idea" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="courts" lemma="court" stem="court" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="lenient" lemma="lenient" stem="lenient" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN chief)) (VP (VBD said) (SBAR (IN that) (S (S (VP (VBG arresting) (NP (DT the) (NNS criminals)) (PP (IN before) (NP (DT the) (NNS robberies))))) (VP (VBD was) (RB n't) (NP (DT a) (JJ good) (NN idea)) (SBAR (IN because) (S (NP (DT the) (NNS courts)) (VP (VBD were) (ADJP (RB so) (JJ lenient))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="said that arresting the criminals before the robberies was n't a good idea because the courts were so lenient" type="VP">
          <tokens>
            <token id="3" string="said" />
            <token id="4" string="that" />
            <token id="5" string="arresting" />
            <token id="6" string="the" />
            <token id="7" string="criminals" />
            <token id="8" string="before" />
            <token id="9" string="the" />
            <token id="10" string="robberies" />
            <token id="11" string="was" />
            <token id="12" string="n't" />
            <token id="13" string="a" />
            <token id="14" string="good" />
            <token id="15" string="idea" />
            <token id="16" string="because" />
            <token id="17" string="the" />
            <token id="18" string="courts" />
            <token id="19" string="were" />
            <token id="20" string="so" />
            <token id="21" string="lenient" />
          </tokens>
        </chunking>
        <chunking id="2" string="was n't a good idea because the courts were so lenient" type="VP">
          <tokens>
            <token id="11" string="was" />
            <token id="12" string="n't" />
            <token id="13" string="a" />
            <token id="14" string="good" />
            <token id="15" string="idea" />
            <token id="16" string="because" />
            <token id="17" string="the" />
            <token id="18" string="courts" />
            <token id="19" string="were" />
            <token id="20" string="so" />
            <token id="21" string="lenient" />
          </tokens>
        </chunking>
        <chunking id="3" string="the courts" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="courts" />
          </tokens>
        </chunking>
        <chunking id="4" string="that arresting the criminals before the robberies was n't a good idea because the courts were so lenient" type="SBAR">
          <tokens>
            <token id="4" string="that" />
            <token id="5" string="arresting" />
            <token id="6" string="the" />
            <token id="7" string="criminals" />
            <token id="8" string="before" />
            <token id="9" string="the" />
            <token id="10" string="robberies" />
            <token id="11" string="was" />
            <token id="12" string="n't" />
            <token id="13" string="a" />
            <token id="14" string="good" />
            <token id="15" string="idea" />
            <token id="16" string="because" />
            <token id="17" string="the" />
            <token id="18" string="courts" />
            <token id="19" string="were" />
            <token id="20" string="so" />
            <token id="21" string="lenient" />
          </tokens>
        </chunking>
        <chunking id="5" string="because the courts were so lenient" type="SBAR">
          <tokens>
            <token id="16" string="because" />
            <token id="17" string="the" />
            <token id="18" string="courts" />
            <token id="19" string="were" />
            <token id="20" string="so" />
            <token id="21" string="lenient" />
          </tokens>
        </chunking>
        <chunking id="6" string="The chief" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="chief" />
          </tokens>
        </chunking>
        <chunking id="7" string="a good idea" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="good" />
            <token id="15" string="idea" />
          </tokens>
        </chunking>
        <chunking id="8" string="arresting the criminals before the robberies" type="VP">
          <tokens>
            <token id="5" string="arresting" />
            <token id="6" string="the" />
            <token id="7" string="criminals" />
            <token id="8" string="before" />
            <token id="9" string="the" />
            <token id="10" string="robberies" />
          </tokens>
        </chunking>
        <chunking id="9" string="the criminals" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="criminals" />
          </tokens>
        </chunking>
        <chunking id="10" string="so lenient" type="ADJP">
          <tokens>
            <token id="20" string="so" />
            <token id="21" string="lenient" />
          </tokens>
        </chunking>
        <chunking id="11" string="were so lenient" type="VP">
          <tokens>
            <token id="19" string="were" />
            <token id="20" string="so" />
            <token id="21" string="lenient" />
          </tokens>
        </chunking>
        <chunking id="12" string="the robberies" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="robberies" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">chief</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">said</governor>
          <dependent id="2">chief</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">said</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">idea</governor>
          <dependent id="4">that</dependent>
        </dependency>
        <dependency type="csubj">
          <governor id="15">idea</governor>
          <dependent id="5">arresting</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">criminals</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">arresting</governor>
          <dependent id="7">criminals</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">robberies</governor>
          <dependent id="8">before</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">robberies</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">arresting</governor>
          <dependent id="10">robberies</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="15">idea</governor>
          <dependent id="11">was</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="15">idea</governor>
          <dependent id="12">n't</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">idea</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">idea</governor>
          <dependent id="14">good</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">said</governor>
          <dependent id="15">idea</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">lenient</governor>
          <dependent id="16">because</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">courts</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">lenient</governor>
          <dependent id="18">courts</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="21">lenient</governor>
          <dependent id="19">were</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="21">lenient</governor>
          <dependent id="20">so</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="15">idea</governor>
          <dependent id="21">lenient</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>The unit has been allowed to continue to operate despite its high shooting rate -- or, worse still, because of the shootings.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="unit" lemma="unit" stem="unit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="allowed" lemma="allow" stem="allow" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="continue" lemma="continue" stem="continu" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="operate" lemma="operate" stem="oper" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="despite" lemma="despite" stem="despit" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="high" lemma="high" stem="high" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="shooting" lemma="shooting" stem="shoot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="rate" lemma="rate" stem="rate" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="worse" lemma="worse" stem="wors" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="still" lemma="still" stem="still" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="shootings" lemma="shooting" stem="shoot" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN unit)) (VP (VBZ has) (VP (VBN been) (VP (VP (VBN allowed) (S (VP (TO to) (VP (VB continue) (S (VP (TO to) (VP (VB operate) (PP (IN despite) (NP (PRP$ its) (JJ high) (NN shooting) (NN rate)))))))))) (: --) (CC or) (, ,) (VP (NP (JJR worse)) (ADVP (RB still))) (, ,) (PP (IN because) (PP (IN of) (NP (DT the) (NNS shootings))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="to continue to operate despite its high shooting rate" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="continue" />
            <token id="8" string="to" />
            <token id="9" string="operate" />
            <token id="10" string="despite" />
            <token id="11" string="its" />
            <token id="12" string="high" />
            <token id="13" string="shooting" />
            <token id="14" string="rate" />
          </tokens>
        </chunking>
        <chunking id="2" string="continue to operate despite its high shooting rate" type="VP">
          <tokens>
            <token id="7" string="continue" />
            <token id="8" string="to" />
            <token id="9" string="operate" />
            <token id="10" string="despite" />
            <token id="11" string="its" />
            <token id="12" string="high" />
            <token id="13" string="shooting" />
            <token id="14" string="rate" />
          </tokens>
        </chunking>
        <chunking id="3" string="its high shooting rate" type="NP">
          <tokens>
            <token id="11" string="its" />
            <token id="12" string="high" />
            <token id="13" string="shooting" />
            <token id="14" string="rate" />
          </tokens>
        </chunking>
        <chunking id="4" string="worse" type="NP">
          <tokens>
            <token id="18" string="worse" />
          </tokens>
        </chunking>
        <chunking id="5" string="to operate despite its high shooting rate" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="operate" />
            <token id="10" string="despite" />
            <token id="11" string="its" />
            <token id="12" string="high" />
            <token id="13" string="shooting" />
            <token id="14" string="rate" />
          </tokens>
        </chunking>
        <chunking id="6" string="The unit" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="unit" />
          </tokens>
        </chunking>
        <chunking id="7" string="worse still" type="VP">
          <tokens>
            <token id="18" string="worse" />
            <token id="19" string="still" />
          </tokens>
        </chunking>
        <chunking id="8" string="operate despite its high shooting rate" type="VP">
          <tokens>
            <token id="9" string="operate" />
            <token id="10" string="despite" />
            <token id="11" string="its" />
            <token id="12" string="high" />
            <token id="13" string="shooting" />
            <token id="14" string="rate" />
          </tokens>
        </chunking>
        <chunking id="9" string="allowed to continue to operate despite its high shooting rate -- or , worse still , because of the shootings" type="VP">
          <tokens>
            <token id="5" string="allowed" />
            <token id="6" string="to" />
            <token id="7" string="continue" />
            <token id="8" string="to" />
            <token id="9" string="operate" />
            <token id="10" string="despite" />
            <token id="11" string="its" />
            <token id="12" string="high" />
            <token id="13" string="shooting" />
            <token id="14" string="rate" />
            <token id="15" string="--" />
            <token id="16" string="or" />
            <token id="17" string="," />
            <token id="18" string="worse" />
            <token id="19" string="still" />
            <token id="20" string="," />
            <token id="21" string="because" />
            <token id="22" string="of" />
            <token id="23" string="the" />
            <token id="24" string="shootings" />
          </tokens>
        </chunking>
        <chunking id="10" string="has been allowed to continue to operate despite its high shooting rate -- or , worse still , because of the shootings" type="VP">
          <tokens>
            <token id="3" string="has" />
            <token id="4" string="been" />
            <token id="5" string="allowed" />
            <token id="6" string="to" />
            <token id="7" string="continue" />
            <token id="8" string="to" />
            <token id="9" string="operate" />
            <token id="10" string="despite" />
            <token id="11" string="its" />
            <token id="12" string="high" />
            <token id="13" string="shooting" />
            <token id="14" string="rate" />
            <token id="15" string="--" />
            <token id="16" string="or" />
            <token id="17" string="," />
            <token id="18" string="worse" />
            <token id="19" string="still" />
            <token id="20" string="," />
            <token id="21" string="because" />
            <token id="22" string="of" />
            <token id="23" string="the" />
            <token id="24" string="shootings" />
          </tokens>
        </chunking>
        <chunking id="11" string="been allowed to continue to operate despite its high shooting rate -- or , worse still , because of the shootings" type="VP">
          <tokens>
            <token id="4" string="been" />
            <token id="5" string="allowed" />
            <token id="6" string="to" />
            <token id="7" string="continue" />
            <token id="8" string="to" />
            <token id="9" string="operate" />
            <token id="10" string="despite" />
            <token id="11" string="its" />
            <token id="12" string="high" />
            <token id="13" string="shooting" />
            <token id="14" string="rate" />
            <token id="15" string="--" />
            <token id="16" string="or" />
            <token id="17" string="," />
            <token id="18" string="worse" />
            <token id="19" string="still" />
            <token id="20" string="," />
            <token id="21" string="because" />
            <token id="22" string="of" />
            <token id="23" string="the" />
            <token id="24" string="shootings" />
          </tokens>
        </chunking>
        <chunking id="12" string="the shootings" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="shootings" />
          </tokens>
        </chunking>
        <chunking id="13" string="allowed to continue to operate despite its high shooting rate" type="VP">
          <tokens>
            <token id="5" string="allowed" />
            <token id="6" string="to" />
            <token id="7" string="continue" />
            <token id="8" string="to" />
            <token id="9" string="operate" />
            <token id="10" string="despite" />
            <token id="11" string="its" />
            <token id="12" string="high" />
            <token id="13" string="shooting" />
            <token id="14" string="rate" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">unit</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="5">allowed</governor>
          <dependent id="2">unit</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">allowed</governor>
          <dependent id="3">has</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">allowed</governor>
          <dependent id="4">been</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">allowed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">continue</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">allowed</governor>
          <dependent id="7">continue</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">operate</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">continue</governor>
          <dependent id="9">operate</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">rate</governor>
          <dependent id="10">despite</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">rate</governor>
          <dependent id="11">its</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">rate</governor>
          <dependent id="12">high</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">rate</governor>
          <dependent id="13">shooting</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">operate</governor>
          <dependent id="14">rate</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">allowed</governor>
          <dependent id="16">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">allowed</governor>
          <dependent id="18">worse</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">worse</governor>
          <dependent id="19">still</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">shootings</governor>
          <dependent id="21">because</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">shootings</governor>
          <dependent id="22">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">shootings</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">allowed</governor>
          <dependent id="24">shootings</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="26" has_coreference="false">
      <content>Last year Los Angeles paid $3 million to 52 residents of an apartment complex ransacked by police.</content>
      <tokens>
        <token id="1" string="Last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="2" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="Los" lemma="Los" stem="lo" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="4" string="Angeles" lemma="Angeles" stem="angele" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="5" string="paid" lemma="pay" stem="paid" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="7" string="3" lemma="3" stem="3" pos="CD" type="Number" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="8" string="million" lemma="million" stem="million" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="52" lemma="52" stem="52" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="11" string="residents" lemma="resident" stem="resid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="apartment" lemma="apartment" stem="apart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="complex" lemma="complex" stem="complex" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="ransacked" lemma="ransack" stem="ransack" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP-TMP (JJ Last) (NN year)) (NP (NNP Los) (NNP Angeles)) (VP (VBD paid) (NP (QP ($ $) (CD 3) (CD million))) (PP (TO to) (NP (NP (CD 52) (NNS residents)) (PP (IN of) (NP (NP (DT an) (NN apartment) (NN complex)) (VP (VBN ransacked) (PP (IN by) (NP (NN police))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="police" type="NP">
          <tokens>
            <token id="18" string="police" />
          </tokens>
        </chunking>
        <chunking id="2" string="52 residents of an apartment complex ransacked by police" type="NP">
          <tokens>
            <token id="10" string="52" />
            <token id="11" string="residents" />
            <token id="12" string="of" />
            <token id="13" string="an" />
            <token id="14" string="apartment" />
            <token id="15" string="complex" />
            <token id="16" string="ransacked" />
            <token id="17" string="by" />
            <token id="18" string="police" />
          </tokens>
        </chunking>
        <chunking id="3" string="paid $ 3 million to 52 residents of an apartment complex ransacked by police" type="VP">
          <tokens>
            <token id="5" string="paid" />
            <token id="6" string="$" />
            <token id="7" string="3" />
            <token id="8" string="million" />
            <token id="9" string="to" />
            <token id="10" string="52" />
            <token id="11" string="residents" />
            <token id="12" string="of" />
            <token id="13" string="an" />
            <token id="14" string="apartment" />
            <token id="15" string="complex" />
            <token id="16" string="ransacked" />
            <token id="17" string="by" />
            <token id="18" string="police" />
          </tokens>
        </chunking>
        <chunking id="4" string="$ 3 million" type="NP">
          <tokens>
            <token id="6" string="$" />
            <token id="7" string="3" />
            <token id="8" string="million" />
          </tokens>
        </chunking>
        <chunking id="5" string="52 residents" type="NP">
          <tokens>
            <token id="10" string="52" />
            <token id="11" string="residents" />
          </tokens>
        </chunking>
        <chunking id="6" string="an apartment complex ransacked by police" type="NP">
          <tokens>
            <token id="13" string="an" />
            <token id="14" string="apartment" />
            <token id="15" string="complex" />
            <token id="16" string="ransacked" />
            <token id="17" string="by" />
            <token id="18" string="police" />
          </tokens>
        </chunking>
        <chunking id="7" string="an apartment complex" type="NP">
          <tokens>
            <token id="13" string="an" />
            <token id="14" string="apartment" />
            <token id="15" string="complex" />
          </tokens>
        </chunking>
        <chunking id="8" string="Los Angeles" type="NP">
          <tokens>
            <token id="3" string="Los" />
            <token id="4" string="Angeles" />
          </tokens>
        </chunking>
        <chunking id="9" string="ransacked by police" type="VP">
          <tokens>
            <token id="16" string="ransacked" />
            <token id="17" string="by" />
            <token id="18" string="police" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">year</governor>
          <dependent id="1">Last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="5">paid</governor>
          <dependent id="2">year</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Angeles</governor>
          <dependent id="3">Los</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">paid</governor>
          <dependent id="4">Angeles</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">paid</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">paid</governor>
          <dependent id="6">$</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">million</governor>
          <dependent id="7">3</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="6">$</governor>
          <dependent id="8">million</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">residents</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="11">residents</governor>
          <dependent id="10">52</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">paid</governor>
          <dependent id="11">residents</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">complex</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">complex</governor>
          <dependent id="13">an</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">complex</governor>
          <dependent id="14">apartment</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">residents</governor>
          <dependent id="15">complex</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="15">complex</governor>
          <dependent id="16">ransacked</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">police</governor>
          <dependent id="17">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">ransacked</governor>
          <dependent id="18">police</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="$ 3 million" type="MONEY" score="0.0">
          <tokens>
            <token id="6" string="$" />
            <token id="7" string="3" />
            <token id="8" string="million" />
          </tokens>
        </entity>
        <entity id="2" string="Last year" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="Last" />
            <token id="2" string="year" />
          </tokens>
        </entity>
        <entity id="3" string="Los Angeles" type="LOCATION" score="0.0">
          <tokens>
            <token id="3" string="Los" />
            <token id="4" string="Angeles" />
          </tokens>
        </entity>
        <entity id="4" string="52" type="NUMBER" score="0.0">
          <tokens>
            <token id="10" string="52" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>Mr. Gates reluctantly admitted that the officers who did the ransacking were wrong, but said he could understand their frustration in trying to fight drugs.</content>
      <tokens>
        <token id="1" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="Gates" lemma="Gates" stem="gate" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="3" string="reluctantly" lemma="reluctantly" stem="reluctantli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="admitted" lemma="admit" stem="admit" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="ransacking" lemma="ransacking" stem="ransack" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="wrong" lemma="wrong" stem="wrong" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="understand" lemma="understand" stem="understand" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="frustration" lemma="frustration" stem="frustrat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="trying" lemma="try" stem="try" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="fight" lemma="fight" stem="fight" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="drugs" lemma="drug" stem="drug" pos="NNS" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Mr.) (NNP Gates)) (ADVP (RB reluctantly)) (VP (VP (VBD admitted) (SBAR (IN that) (S (NP (NP (DT the) (NNS officers)) (SBAR (WHNP (WP who)) (S (VP (VBD did) (NP (DT the) (NN ransacking)))))) (VP (VBD were) (ADJP (JJ wrong)))))) (, ,) (CC but) (VP (VBD said) (SBAR (S (NP (PRP he)) (VP (MD could) (VP (VB understand) (NP (PRP$ their) (NN frustration)) (PP (IN in) (S (VP (VBG trying) (S (VP (TO to) (VP (VB fight) (NP (NNS drugs)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="he could understand their frustration in trying to fight drugs" type="SBAR">
          <tokens>
            <token id="17" string="he" />
            <token id="18" string="could" />
            <token id="19" string="understand" />
            <token id="20" string="their" />
            <token id="21" string="frustration" />
            <token id="22" string="in" />
            <token id="23" string="trying" />
            <token id="24" string="to" />
            <token id="25" string="fight" />
            <token id="26" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="2" string="could understand their frustration in trying to fight drugs" type="VP">
          <tokens>
            <token id="18" string="could" />
            <token id="19" string="understand" />
            <token id="20" string="their" />
            <token id="21" string="frustration" />
            <token id="22" string="in" />
            <token id="23" string="trying" />
            <token id="24" string="to" />
            <token id="25" string="fight" />
            <token id="26" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="3" string="fight drugs" type="VP">
          <tokens>
            <token id="25" string="fight" />
            <token id="26" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="4" string="drugs" type="NP">
          <tokens>
            <token id="26" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="5" string="who did the ransacking" type="SBAR">
          <tokens>
            <token id="8" string="who" />
            <token id="9" string="did" />
            <token id="10" string="the" />
            <token id="11" string="ransacking" />
          </tokens>
        </chunking>
        <chunking id="6" string="said he could understand their frustration in trying to fight drugs" type="VP">
          <tokens>
            <token id="16" string="said" />
            <token id="17" string="he" />
            <token id="18" string="could" />
            <token id="19" string="understand" />
            <token id="20" string="their" />
            <token id="21" string="frustration" />
            <token id="22" string="in" />
            <token id="23" string="trying" />
            <token id="24" string="to" />
            <token id="25" string="fight" />
            <token id="26" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="7" string="that the officers who did the ransacking were wrong" type="SBAR">
          <tokens>
            <token id="5" string="that" />
            <token id="6" string="the" />
            <token id="7" string="officers" />
            <token id="8" string="who" />
            <token id="9" string="did" />
            <token id="10" string="the" />
            <token id="11" string="ransacking" />
            <token id="12" string="were" />
            <token id="13" string="wrong" />
          </tokens>
        </chunking>
        <chunking id="8" string="did the ransacking" type="VP">
          <tokens>
            <token id="9" string="did" />
            <token id="10" string="the" />
            <token id="11" string="ransacking" />
          </tokens>
        </chunking>
        <chunking id="9" string="wrong" type="ADJP">
          <tokens>
            <token id="13" string="wrong" />
          </tokens>
        </chunking>
        <chunking id="10" string="were wrong" type="VP">
          <tokens>
            <token id="12" string="were" />
            <token id="13" string="wrong" />
          </tokens>
        </chunking>
        <chunking id="11" string="understand their frustration in trying to fight drugs" type="VP">
          <tokens>
            <token id="19" string="understand" />
            <token id="20" string="their" />
            <token id="21" string="frustration" />
            <token id="22" string="in" />
            <token id="23" string="trying" />
            <token id="24" string="to" />
            <token id="25" string="fight" />
            <token id="26" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="12" string="trying to fight drugs" type="VP">
          <tokens>
            <token id="23" string="trying" />
            <token id="24" string="to" />
            <token id="25" string="fight" />
            <token id="26" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="13" string="to fight drugs" type="VP">
          <tokens>
            <token id="24" string="to" />
            <token id="25" string="fight" />
            <token id="26" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="14" string="the ransacking" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="ransacking" />
          </tokens>
        </chunking>
        <chunking id="15" string="admitted that the officers who did the ransacking were wrong" type="VP">
          <tokens>
            <token id="4" string="admitted" />
            <token id="5" string="that" />
            <token id="6" string="the" />
            <token id="7" string="officers" />
            <token id="8" string="who" />
            <token id="9" string="did" />
            <token id="10" string="the" />
            <token id="11" string="ransacking" />
            <token id="12" string="were" />
            <token id="13" string="wrong" />
          </tokens>
        </chunking>
        <chunking id="16" string="the officers who did the ransacking" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="officers" />
            <token id="8" string="who" />
            <token id="9" string="did" />
            <token id="10" string="the" />
            <token id="11" string="ransacking" />
          </tokens>
        </chunking>
        <chunking id="17" string="the officers" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="officers" />
          </tokens>
        </chunking>
        <chunking id="18" string="Mr. Gates" type="NP">
          <tokens>
            <token id="1" string="Mr." />
            <token id="2" string="Gates" />
          </tokens>
        </chunking>
        <chunking id="19" string="he" type="NP">
          <tokens>
            <token id="17" string="he" />
          </tokens>
        </chunking>
        <chunking id="20" string="their frustration" type="NP">
          <tokens>
            <token id="20" string="their" />
            <token id="21" string="frustration" />
          </tokens>
        </chunking>
        <chunking id="21" string="admitted that the officers who did the ransacking were wrong , but said he could understand their frustration in trying to fight drugs" type="VP">
          <tokens>
            <token id="4" string="admitted" />
            <token id="5" string="that" />
            <token id="6" string="the" />
            <token id="7" string="officers" />
            <token id="8" string="who" />
            <token id="9" string="did" />
            <token id="10" string="the" />
            <token id="11" string="ransacking" />
            <token id="12" string="were" />
            <token id="13" string="wrong" />
            <token id="14" string="," />
            <token id="15" string="but" />
            <token id="16" string="said" />
            <token id="17" string="he" />
            <token id="18" string="could" />
            <token id="19" string="understand" />
            <token id="20" string="their" />
            <token id="21" string="frustration" />
            <token id="22" string="in" />
            <token id="23" string="trying" />
            <token id="24" string="to" />
            <token id="25" string="fight" />
            <token id="26" string="drugs" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Gates</governor>
          <dependent id="1">Mr.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">admitted</governor>
          <dependent id="2">Gates</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">admitted</governor>
          <dependent id="3">reluctantly</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">admitted</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">wrong</governor>
          <dependent id="5">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">officers</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">wrong</governor>
          <dependent id="7">officers</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">did</governor>
          <dependent id="8">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="7">officers</governor>
          <dependent id="9">did</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">ransacking</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">did</governor>
          <dependent id="11">ransacking</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="13">wrong</governor>
          <dependent id="12">were</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">admitted</governor>
          <dependent id="13">wrong</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">admitted</governor>
          <dependent id="15">but</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">admitted</governor>
          <dependent id="16">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">understand</governor>
          <dependent id="17">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="19">understand</governor>
          <dependent id="18">could</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">said</governor>
          <dependent id="19">understand</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="21">frustration</governor>
          <dependent id="20">their</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">understand</governor>
          <dependent id="21">frustration</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">trying</governor>
          <dependent id="22">in</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="19">understand</governor>
          <dependent id="23">trying</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="25">fight</governor>
          <dependent id="24">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="23">trying</governor>
          <dependent id="25">fight</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">fight</governor>
          <dependent id="26">drugs</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Gates" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Gates" />
          </tokens>
        </entity>
        <entity id="2" string="drugs" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="26" string="drugs" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="28" has_coreference="false">
      <content>Even more recently, Mr. Gates told the Senate that &amp;quot;casual drug users should be taken out and shot.&amp;quot;</content>
      <tokens>
        <token id="1" string="Even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="recently" lemma="recently" stem="recent" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="Gates" lemma="Gates" stem="gate" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="7" string="told" lemma="tell" stem="told" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Senate" lemma="Senate" stem="senat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="10" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="casual" lemma="casual" stem="casual" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="drug" lemma="drug" stem="drug" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="users" lemma="user" stem="user" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="should" lemma="should" stem="should" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="taken" lemma="take" stem="taken" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="shot" lemma="shot" stem="shot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Even) (RBR more) (RB recently)) (, ,) (NP (NNP Mr.) (NNP Gates)) (VP (VBD told) (NP (DT the) (NNP Senate)) (SBAR (SBAR (IN that) (`` ``) (S (NP (JJ casual) (NN drug) (NNS users)) (VP (MD should) (VP (VB be) (VP (VBN taken) (PRT (RP out))))))) (CC and) (FRAG (NP (NN shot))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="should be taken out" type="VP">
          <tokens>
            <token id="15" string="should" />
            <token id="16" string="be" />
            <token id="17" string="taken" />
            <token id="18" string="out" />
          </tokens>
        </chunking>
        <chunking id="2" string="taken out" type="VP">
          <tokens>
            <token id="17" string="taken" />
            <token id="18" string="out" />
          </tokens>
        </chunking>
        <chunking id="3" string="the Senate" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="Senate" />
          </tokens>
        </chunking>
        <chunking id="4" string="that `` casual drug users should be taken out" type="SBAR">
          <tokens>
            <token id="10" string="that" />
            <token id="11" string="&quot;" />
            <token id="12" string="casual" />
            <token id="13" string="drug" />
            <token id="14" string="users" />
            <token id="15" string="should" />
            <token id="16" string="be" />
            <token id="17" string="taken" />
            <token id="18" string="out" />
          </tokens>
        </chunking>
        <chunking id="5" string="be taken out" type="VP">
          <tokens>
            <token id="16" string="be" />
            <token id="17" string="taken" />
            <token id="18" string="out" />
          </tokens>
        </chunking>
        <chunking id="6" string="Mr. Gates" type="NP">
          <tokens>
            <token id="5" string="Mr." />
            <token id="6" string="Gates" />
          </tokens>
        </chunking>
        <chunking id="7" string="casual drug users" type="NP">
          <tokens>
            <token id="12" string="casual" />
            <token id="13" string="drug" />
            <token id="14" string="users" />
          </tokens>
        </chunking>
        <chunking id="8" string="shot" type="NP">
          <tokens>
            <token id="20" string="shot" />
          </tokens>
        </chunking>
        <chunking id="9" string="told the Senate that `` casual drug users should be taken out and shot" type="VP">
          <tokens>
            <token id="7" string="told" />
            <token id="8" string="the" />
            <token id="9" string="Senate" />
            <token id="10" string="that" />
            <token id="11" string="&quot;" />
            <token id="12" string="casual" />
            <token id="13" string="drug" />
            <token id="14" string="users" />
            <token id="15" string="should" />
            <token id="16" string="be" />
            <token id="17" string="taken" />
            <token id="18" string="out" />
            <token id="19" string="and" />
            <token id="20" string="shot" />
          </tokens>
        </chunking>
        <chunking id="10" string="that `` casual drug users should be taken out and shot" type="SBAR">
          <tokens>
            <token id="10" string="that" />
            <token id="11" string="&quot;" />
            <token id="12" string="casual" />
            <token id="13" string="drug" />
            <token id="14" string="users" />
            <token id="15" string="should" />
            <token id="16" string="be" />
            <token id="17" string="taken" />
            <token id="18" string="out" />
            <token id="19" string="and" />
            <token id="20" string="shot" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="3">recently</governor>
          <dependent id="1">Even</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">recently</governor>
          <dependent id="2">more</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">told</governor>
          <dependent id="3">recently</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Gates</governor>
          <dependent id="5">Mr.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">told</governor>
          <dependent id="6">Gates</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">told</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">Senate</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">told</governor>
          <dependent id="9">Senate</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">taken</governor>
          <dependent id="10">that</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">users</governor>
          <dependent id="12">casual</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">users</governor>
          <dependent id="13">drug</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="17">taken</governor>
          <dependent id="14">users</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="17">taken</governor>
          <dependent id="15">should</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="17">taken</governor>
          <dependent id="16">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">told</governor>
          <dependent id="17">taken</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="17">taken</governor>
          <dependent id="18">out</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">taken</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">taken</governor>
          <dependent id="20">shot</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Gates" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Gates" />
          </tokens>
        </entity>
        <entity id="2" string="Senate" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="9" string="Senate" />
          </tokens>
        </entity>
        <entity id="3" string="recently" type="DATE" score="0.0">
          <tokens>
            <token id="3" string="recently" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="29" has_coreference="true">
      <content>He assured the senators that he was not being facetious.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="assured" lemma="assure" stem="assur" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="senators" lemma="senator" stem="senat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="being" lemma="be" stem="be" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="facetious" lemma="facetious" stem="faceti" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD assured) (NP (DT the) (NNS senators)) (SBAR (IN that) (S (NP (PRP he)) (VP (VBD was) (RB not) (VP (VBG being) (ADJP (JJ facetious))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the senators" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="senators" />
          </tokens>
        </chunking>
        <chunking id="2" string="was not being facetious" type="VP">
          <tokens>
            <token id="7" string="was" />
            <token id="8" string="not" />
            <token id="9" string="being" />
            <token id="10" string="facetious" />
          </tokens>
        </chunking>
        <chunking id="3" string="assured the senators that he was not being facetious" type="VP">
          <tokens>
            <token id="2" string="assured" />
            <token id="3" string="the" />
            <token id="4" string="senators" />
            <token id="5" string="that" />
            <token id="6" string="he" />
            <token id="7" string="was" />
            <token id="8" string="not" />
            <token id="9" string="being" />
            <token id="10" string="facetious" />
          </tokens>
        </chunking>
        <chunking id="4" string="facetious" type="ADJP">
          <tokens>
            <token id="10" string="facetious" />
          </tokens>
        </chunking>
        <chunking id="5" string="being facetious" type="VP">
          <tokens>
            <token id="9" string="being" />
            <token id="10" string="facetious" />
          </tokens>
        </chunking>
        <chunking id="6" string="that he was not being facetious" type="SBAR">
          <tokens>
            <token id="5" string="that" />
            <token id="6" string="he" />
            <token id="7" string="was" />
            <token id="8" string="not" />
            <token id="9" string="being" />
            <token id="10" string="facetious" />
          </tokens>
        </chunking>
        <chunking id="7" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="8" string="he" type="NP">
          <tokens>
            <token id="6" string="he" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">assured</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">assured</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">senators</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">assured</governor>
          <dependent id="4">senators</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">facetious</governor>
          <dependent id="5">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">facetious</governor>
          <dependent id="6">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">facetious</governor>
          <dependent id="7">was</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="10">facetious</governor>
          <dependent id="8">not</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="10">facetious</governor>
          <dependent id="9">being</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">assured</governor>
          <dependent id="10">facetious</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="30" has_coreference="true">
      <content>And his initial reaction on television to the Rodney King brutality tapes was defensive.</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="initial" lemma="initial" stem="initi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="reaction" lemma="reaction" stem="reaction" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="television" lemma="television" stem="televis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Rodney" lemma="Rodney" stem="rodnei" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="King" lemma="King" stem="king" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="false" is_refers="true" />
        <token id="11" string="brutality" lemma="brutality" stem="brutal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="tapes" lemma="tape" stem="tape" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="defensive" lemma="defensive" stem="defens" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC And) (NP (NP (PRP$ his) (JJ initial) (NN reaction)) (PP (IN on) (NP (NP (NN television)) (PP (TO to) (NP (DT the) (NNP Rodney) (NNP King) (NN brutality) (NNS tapes)))))) (VP (VBD was) (ADJP (JJ defensive))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="his initial reaction" type="NP">
          <tokens>
            <token id="2" string="his" />
            <token id="3" string="initial" />
            <token id="4" string="reaction" />
          </tokens>
        </chunking>
        <chunking id="2" string="the Rodney King brutality tapes" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="Rodney" />
            <token id="10" string="King" />
            <token id="11" string="brutality" />
            <token id="12" string="tapes" />
          </tokens>
        </chunking>
        <chunking id="3" string="television" type="NP">
          <tokens>
            <token id="6" string="television" />
          </tokens>
        </chunking>
        <chunking id="4" string="was defensive" type="VP">
          <tokens>
            <token id="13" string="was" />
            <token id="14" string="defensive" />
          </tokens>
        </chunking>
        <chunking id="5" string="defensive" type="ADJP">
          <tokens>
            <token id="14" string="defensive" />
          </tokens>
        </chunking>
        <chunking id="6" string="his initial reaction on television to the Rodney King brutality tapes" type="NP">
          <tokens>
            <token id="2" string="his" />
            <token id="3" string="initial" />
            <token id="4" string="reaction" />
            <token id="5" string="on" />
            <token id="6" string="television" />
            <token id="7" string="to" />
            <token id="8" string="the" />
            <token id="9" string="Rodney" />
            <token id="10" string="King" />
            <token id="11" string="brutality" />
            <token id="12" string="tapes" />
          </tokens>
        </chunking>
        <chunking id="7" string="television to the Rodney King brutality tapes" type="NP">
          <tokens>
            <token id="6" string="television" />
            <token id="7" string="to" />
            <token id="8" string="the" />
            <token id="9" string="Rodney" />
            <token id="10" string="King" />
            <token id="11" string="brutality" />
            <token id="12" string="tapes" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="14">defensive</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">reaction</governor>
          <dependent id="2">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">reaction</governor>
          <dependent id="3">initial</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">defensive</governor>
          <dependent id="4">reaction</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">television</governor>
          <dependent id="5">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">reaction</governor>
          <dependent id="6">television</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">tapes</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">tapes</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">tapes</governor>
          <dependent id="9">Rodney</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">tapes</governor>
          <dependent id="10">King</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">tapes</governor>
          <dependent id="11">brutality</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">television</governor>
          <dependent id="12">tapes</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">defensive</governor>
          <dependent id="13">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">defensive</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="King" type="TITLE" score="0.0">
          <tokens>
            <token id="10" string="King" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="31" has_coreference="false">
      <content>Mayor Tom Bradley told the media that such conduct wouldn&amp;apost;t be tolerated, and that the wrongdoers would be sought out for punishment.</content>
      <tokens>
        <token id="1" string="Mayor" lemma="Mayor" stem="mayor" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="false" is_refers="false" />
        <token id="2" string="Tom" lemma="Tom" stem="tom" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="3" string="Bradley" lemma="Bradley" stem="bradlei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="4" string="told" lemma="tell" stem="told" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="media" lemma="media" stem="media" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="conduct" lemma="conduct" stem="conduct" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="tolerated" lemma="tolerate" stem="toler" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="wrongdoers" lemma="wrongdoer" stem="wrongdoer" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="sought" lemma="seek" stem="sought" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="punishment" lemma="punishment" stem="punish" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Mayor) (NNP Tom) (NNP Bradley)) (VP (VBD told) (NP (DT the) (NNS media)) (SBAR (SBAR (IN that) (S (NP (JJ such) (NN conduct)) (VP (MD would) (RB n't) (VP (VB be) (VP (VBN tolerated)))))) (, ,) (CC and) (SBAR (IN that) (S (NP (DT the) (NNS wrongdoers)) (VP (MD would) (VP (VB be) (VP (VBN sought) (PRT (RP out)) (PP (IN for) (NP (NN punishment)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="would n't be tolerated" type="VP">
          <tokens>
            <token id="10" string="would" />
            <token id="11" string="n't" />
            <token id="12" string="be" />
            <token id="13" string="tolerated" />
          </tokens>
        </chunking>
        <chunking id="2" string="that the wrongdoers would be sought out for punishment" type="SBAR">
          <tokens>
            <token id="16" string="that" />
            <token id="17" string="the" />
            <token id="18" string="wrongdoers" />
            <token id="19" string="would" />
            <token id="20" string="be" />
            <token id="21" string="sought" />
            <token id="22" string="out" />
            <token id="23" string="for" />
            <token id="24" string="punishment" />
          </tokens>
        </chunking>
        <chunking id="3" string="the media" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="media" />
          </tokens>
        </chunking>
        <chunking id="4" string="sought out for punishment" type="VP">
          <tokens>
            <token id="21" string="sought" />
            <token id="22" string="out" />
            <token id="23" string="for" />
            <token id="24" string="punishment" />
          </tokens>
        </chunking>
        <chunking id="5" string="that such conduct would n't be tolerated , and that the wrongdoers would be sought out for punishment" type="SBAR">
          <tokens>
            <token id="7" string="that" />
            <token id="8" string="such" />
            <token id="9" string="conduct" />
            <token id="10" string="would" />
            <token id="11" string="n't" />
            <token id="12" string="be" />
            <token id="13" string="tolerated" />
            <token id="14" string="," />
            <token id="15" string="and" />
            <token id="16" string="that" />
            <token id="17" string="the" />
            <token id="18" string="wrongdoers" />
            <token id="19" string="would" />
            <token id="20" string="be" />
            <token id="21" string="sought" />
            <token id="22" string="out" />
            <token id="23" string="for" />
            <token id="24" string="punishment" />
          </tokens>
        </chunking>
        <chunking id="6" string="be tolerated" type="VP">
          <tokens>
            <token id="12" string="be" />
            <token id="13" string="tolerated" />
          </tokens>
        </chunking>
        <chunking id="7" string="that such conduct would n't be tolerated" type="SBAR">
          <tokens>
            <token id="7" string="that" />
            <token id="8" string="such" />
            <token id="9" string="conduct" />
            <token id="10" string="would" />
            <token id="11" string="n't" />
            <token id="12" string="be" />
            <token id="13" string="tolerated" />
          </tokens>
        </chunking>
        <chunking id="8" string="punishment" type="NP">
          <tokens>
            <token id="24" string="punishment" />
          </tokens>
        </chunking>
        <chunking id="9" string="told the media that such conduct would n't be tolerated , and that the wrongdoers would be sought out for punishment" type="VP">
          <tokens>
            <token id="4" string="told" />
            <token id="5" string="the" />
            <token id="6" string="media" />
            <token id="7" string="that" />
            <token id="8" string="such" />
            <token id="9" string="conduct" />
            <token id="10" string="would" />
            <token id="11" string="n't" />
            <token id="12" string="be" />
            <token id="13" string="tolerated" />
            <token id="14" string="," />
            <token id="15" string="and" />
            <token id="16" string="that" />
            <token id="17" string="the" />
            <token id="18" string="wrongdoers" />
            <token id="19" string="would" />
            <token id="20" string="be" />
            <token id="21" string="sought" />
            <token id="22" string="out" />
            <token id="23" string="for" />
            <token id="24" string="punishment" />
          </tokens>
        </chunking>
        <chunking id="10" string="such conduct" type="NP">
          <tokens>
            <token id="8" string="such" />
            <token id="9" string="conduct" />
          </tokens>
        </chunking>
        <chunking id="11" string="the wrongdoers" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="wrongdoers" />
          </tokens>
        </chunking>
        <chunking id="12" string="be sought out for punishment" type="VP">
          <tokens>
            <token id="20" string="be" />
            <token id="21" string="sought" />
            <token id="22" string="out" />
            <token id="23" string="for" />
            <token id="24" string="punishment" />
          </tokens>
        </chunking>
        <chunking id="13" string="Mayor Tom Bradley" type="NP">
          <tokens>
            <token id="1" string="Mayor" />
            <token id="2" string="Tom" />
            <token id="3" string="Bradley" />
          </tokens>
        </chunking>
        <chunking id="14" string="tolerated" type="VP">
          <tokens>
            <token id="13" string="tolerated" />
          </tokens>
        </chunking>
        <chunking id="15" string="would be sought out for punishment" type="VP">
          <tokens>
            <token id="19" string="would" />
            <token id="20" string="be" />
            <token id="21" string="sought" />
            <token id="22" string="out" />
            <token id="23" string="for" />
            <token id="24" string="punishment" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Bradley</governor>
          <dependent id="1">Mayor</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Bradley</governor>
          <dependent id="2">Tom</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">told</governor>
          <dependent id="3">Bradley</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">told</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">media</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">told</governor>
          <dependent id="6">media</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">tolerated</governor>
          <dependent id="7">that</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">conduct</governor>
          <dependent id="8">such</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="13">tolerated</governor>
          <dependent id="9">conduct</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">tolerated</governor>
          <dependent id="10">would</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="13">tolerated</governor>
          <dependent id="11">n't</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="13">tolerated</governor>
          <dependent id="12">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">told</governor>
          <dependent id="13">tolerated</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">tolerated</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">sought</governor>
          <dependent id="16">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">wrongdoers</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="21">sought</governor>
          <dependent id="18">wrongdoers</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">sought</governor>
          <dependent id="19">would</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="21">sought</governor>
          <dependent id="20">be</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">tolerated</governor>
          <dependent id="21">sought</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="21">sought</governor>
          <dependent id="22">out</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">punishment</governor>
          <dependent id="23">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">sought</governor>
          <dependent id="24">punishment</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Tom Bradley" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Tom" />
            <token id="3" string="Bradley" />
          </tokens>
        </entity>
        <entity id="2" string="Mayor" type="TITLE" score="0.0">
          <tokens>
            <token id="1" string="Mayor" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="32" has_coreference="true">
      <content>Mr. Gates said that while he was shocked, he wasn&amp;apost;t drawing conclusions and would look into the &amp;quot;background,&amp;quot; of the incident.</content>
      <tokens>
        <token id="1" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="Gates" lemma="Gates" stem="gate" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="3" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="while" lemma="while" stem="while" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="shocked" lemma="shock" stem="shock" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="drawing" lemma="draw" stem="draw" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="conclusions" lemma="conclusion" stem="conclus" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="look" lemma="look" stem="look" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="background" lemma="background" stem="background" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="26" string="incident" lemma="incident" stem="incid" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Mr.) (NNP Gates)) (VP (VBD said) (SBAR (IN that) (S (SBAR (IN while) (S (NP (PRP he)) (VP (VBD was) (VP (VBN shocked))))) (, ,) (NP (PRP he)) (VP (VP (VBD was) (RB n't) (VP (VBG drawing) (NP (NNS conclusions)))) (CC and) (VP (MD would) (VP (VB look) (PP (IN into) (NP (NP (DT the) (`` ``) (NN background) (, ,) ('' '')) (PP (IN of) (NP (DT the) (NN incident))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="conclusions" type="NP">
          <tokens>
            <token id="14" string="conclusions" />
          </tokens>
        </chunking>
        <chunking id="2" string="look into the `` background , '' of the incident" type="VP">
          <tokens>
            <token id="17" string="look" />
            <token id="18" string="into" />
            <token id="19" string="the" />
            <token id="20" string="&quot;" />
            <token id="21" string="background" />
            <token id="22" string="," />
            <token id="23" string="&quot;" />
            <token id="24" string="of" />
            <token id="25" string="the" />
            <token id="26" string="incident" />
          </tokens>
        </chunking>
        <chunking id="3" string="the `` background , ''" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="&quot;" />
            <token id="21" string="background" />
            <token id="22" string="," />
            <token id="23" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="4" string="the `` background , '' of the incident" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="&quot;" />
            <token id="21" string="background" />
            <token id="22" string="," />
            <token id="23" string="&quot;" />
            <token id="24" string="of" />
            <token id="25" string="the" />
            <token id="26" string="incident" />
          </tokens>
        </chunking>
        <chunking id="5" string="would look into the `` background , '' of the incident" type="VP">
          <tokens>
            <token id="16" string="would" />
            <token id="17" string="look" />
            <token id="18" string="into" />
            <token id="19" string="the" />
            <token id="20" string="&quot;" />
            <token id="21" string="background" />
            <token id="22" string="," />
            <token id="23" string="&quot;" />
            <token id="24" string="of" />
            <token id="25" string="the" />
            <token id="26" string="incident" />
          </tokens>
        </chunking>
        <chunking id="6" string="was n't drawing conclusions" type="VP">
          <tokens>
            <token id="11" string="was" />
            <token id="12" string="n't" />
            <token id="13" string="drawing" />
            <token id="14" string="conclusions" />
          </tokens>
        </chunking>
        <chunking id="7" string="drawing conclusions" type="VP">
          <tokens>
            <token id="13" string="drawing" />
            <token id="14" string="conclusions" />
          </tokens>
        </chunking>
        <chunking id="8" string="shocked" type="VP">
          <tokens>
            <token id="8" string="shocked" />
          </tokens>
        </chunking>
        <chunking id="9" string="said that while he was shocked , he was n't drawing conclusions and would look into the `` background , '' of the incident" type="VP">
          <tokens>
            <token id="3" string="said" />
            <token id="4" string="that" />
            <token id="5" string="while" />
            <token id="6" string="he" />
            <token id="7" string="was" />
            <token id="8" string="shocked" />
            <token id="9" string="," />
            <token id="10" string="he" />
            <token id="11" string="was" />
            <token id="12" string="n't" />
            <token id="13" string="drawing" />
            <token id="14" string="conclusions" />
            <token id="15" string="and" />
            <token id="16" string="would" />
            <token id="17" string="look" />
            <token id="18" string="into" />
            <token id="19" string="the" />
            <token id="20" string="&quot;" />
            <token id="21" string="background" />
            <token id="22" string="," />
            <token id="23" string="&quot;" />
            <token id="24" string="of" />
            <token id="25" string="the" />
            <token id="26" string="incident" />
          </tokens>
        </chunking>
        <chunking id="10" string="that while he was shocked , he was n't drawing conclusions and would look into the `` background , '' of the incident" type="SBAR">
          <tokens>
            <token id="4" string="that" />
            <token id="5" string="while" />
            <token id="6" string="he" />
            <token id="7" string="was" />
            <token id="8" string="shocked" />
            <token id="9" string="," />
            <token id="10" string="he" />
            <token id="11" string="was" />
            <token id="12" string="n't" />
            <token id="13" string="drawing" />
            <token id="14" string="conclusions" />
            <token id="15" string="and" />
            <token id="16" string="would" />
            <token id="17" string="look" />
            <token id="18" string="into" />
            <token id="19" string="the" />
            <token id="20" string="&quot;" />
            <token id="21" string="background" />
            <token id="22" string="," />
            <token id="23" string="&quot;" />
            <token id="24" string="of" />
            <token id="25" string="the" />
            <token id="26" string="incident" />
          </tokens>
        </chunking>
        <chunking id="11" string="while he was shocked" type="SBAR">
          <tokens>
            <token id="5" string="while" />
            <token id="6" string="he" />
            <token id="7" string="was" />
            <token id="8" string="shocked" />
          </tokens>
        </chunking>
        <chunking id="12" string="Mr. Gates" type="NP">
          <tokens>
            <token id="1" string="Mr." />
            <token id="2" string="Gates" />
          </tokens>
        </chunking>
        <chunking id="13" string="he" type="NP">
          <tokens>
            <token id="6" string="he" />
          </tokens>
        </chunking>
        <chunking id="14" string="was shocked" type="VP">
          <tokens>
            <token id="7" string="was" />
            <token id="8" string="shocked" />
          </tokens>
        </chunking>
        <chunking id="15" string="was n't drawing conclusions and would look into the `` background , '' of the incident" type="VP">
          <tokens>
            <token id="11" string="was" />
            <token id="12" string="n't" />
            <token id="13" string="drawing" />
            <token id="14" string="conclusions" />
            <token id="15" string="and" />
            <token id="16" string="would" />
            <token id="17" string="look" />
            <token id="18" string="into" />
            <token id="19" string="the" />
            <token id="20" string="&quot;" />
            <token id="21" string="background" />
            <token id="22" string="," />
            <token id="23" string="&quot;" />
            <token id="24" string="of" />
            <token id="25" string="the" />
            <token id="26" string="incident" />
          </tokens>
        </chunking>
        <chunking id="16" string="the incident" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="incident" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Gates</governor>
          <dependent id="1">Mr.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">said</governor>
          <dependent id="2">Gates</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">said</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">drawing</governor>
          <dependent id="4">that</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">shocked</governor>
          <dependent id="5">while</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="8">shocked</governor>
          <dependent id="6">he</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="8">shocked</governor>
          <dependent id="7">was</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="13">drawing</governor>
          <dependent id="8">shocked</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">drawing</governor>
          <dependent id="10">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">drawing</governor>
          <dependent id="11">was</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="13">drawing</governor>
          <dependent id="12">n't</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">said</governor>
          <dependent id="13">drawing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">drawing</governor>
          <dependent id="14">conclusions</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">drawing</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="17">look</governor>
          <dependent id="16">would</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">drawing</governor>
          <dependent id="17">look</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">background</governor>
          <dependent id="18">into</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">background</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">look</governor>
          <dependent id="21">background</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">incident</governor>
          <dependent id="24">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">incident</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">background</governor>
          <dependent id="26">incident</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Gates" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Gates" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="33" has_coreference="true">
      <content>Presumably, the chief has now received wiser council.</content>
      <tokens>
        <token id="1" string="Presumably" lemma="presumably" stem="presum" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="chief" lemma="chief" stem="chief" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="7" string="received" lemma="receive" stem="receiv" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="wiser" lemma="wiser" stem="wiser" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="council" lemma="council" stem="council" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Presumably)) (, ,) (NP (DT the) (NN chief)) (VP (VBZ has) (ADVP (RB now)) (VP (VBN received) (NP (ADJP (JJR wiser)) (NN council)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="wiser" type="ADJP">
          <tokens>
            <token id="8" string="wiser" />
          </tokens>
        </chunking>
        <chunking id="2" string="the chief" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="chief" />
          </tokens>
        </chunking>
        <chunking id="3" string="has now received wiser council" type="VP">
          <tokens>
            <token id="5" string="has" />
            <token id="6" string="now" />
            <token id="7" string="received" />
            <token id="8" string="wiser" />
            <token id="9" string="council" />
          </tokens>
        </chunking>
        <chunking id="4" string="received wiser council" type="VP">
          <tokens>
            <token id="7" string="received" />
            <token id="8" string="wiser" />
            <token id="9" string="council" />
          </tokens>
        </chunking>
        <chunking id="5" string="wiser council" type="NP">
          <tokens>
            <token id="8" string="wiser" />
            <token id="9" string="council" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="7">received</governor>
          <dependent id="1">Presumably</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">chief</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">received</governor>
          <dependent id="4">chief</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">received</governor>
          <dependent id="5">has</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">received</governor>
          <dependent id="6">now</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">received</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">council</governor>
          <dependent id="8">wiser</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">received</governor>
          <dependent id="9">council</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="6" string="now" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="34" has_coreference="true">
      <content>He has called for prosecution of three of the officers, and has produced a videotape for his troops condemning the beating.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="called" lemma="call" stem="call" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="prosecution" lemma="prosecution" stem="prosecut" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="three" lemma="three" stem="three" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="produced" lemma="produce" stem="produc" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="videotape" lemma="videotape" stem="videotap" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="troops" lemma="troops" stem="troop" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="condemning" lemma="condemn" stem="condemn" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="beating" lemma="beating" stem="beat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VP (VBZ has) (VP (VBN called) (PP (IN for) (NP (NP (NN prosecution)) (PP (IN of) (NP (NP (CD three)) (PP (IN of) (NP (DT the) (NNS officers))))))))) (, ,) (CC and) (VP (VBZ has) (VP (VBN produced) (NP (DT a) (NN videotape)) (PP (IN for) (NP (PRP$ his) (NNS troops))) (S (VP (VBG condemning) (NP (DT the) (NN beating))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="has produced a videotape for his troops condemning the beating" type="VP">
          <tokens>
            <token id="13" string="has" />
            <token id="14" string="produced" />
            <token id="15" string="a" />
            <token id="16" string="videotape" />
            <token id="17" string="for" />
            <token id="18" string="his" />
            <token id="19" string="troops" />
            <token id="20" string="condemning" />
            <token id="21" string="the" />
            <token id="22" string="beating" />
          </tokens>
        </chunking>
        <chunking id="2" string="three of the officers" type="NP">
          <tokens>
            <token id="7" string="three" />
            <token id="8" string="of" />
            <token id="9" string="the" />
            <token id="10" string="officers" />
          </tokens>
        </chunking>
        <chunking id="3" string="prosecution" type="NP">
          <tokens>
            <token id="5" string="prosecution" />
          </tokens>
        </chunking>
        <chunking id="4" string="produced a videotape for his troops condemning the beating" type="VP">
          <tokens>
            <token id="14" string="produced" />
            <token id="15" string="a" />
            <token id="16" string="videotape" />
            <token id="17" string="for" />
            <token id="18" string="his" />
            <token id="19" string="troops" />
            <token id="20" string="condemning" />
            <token id="21" string="the" />
            <token id="22" string="beating" />
          </tokens>
        </chunking>
        <chunking id="5" string="a videotape" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="videotape" />
          </tokens>
        </chunking>
        <chunking id="6" string="has called for prosecution of three of the officers" type="VP">
          <tokens>
            <token id="2" string="has" />
            <token id="3" string="called" />
            <token id="4" string="for" />
            <token id="5" string="prosecution" />
            <token id="6" string="of" />
            <token id="7" string="three" />
            <token id="8" string="of" />
            <token id="9" string="the" />
            <token id="10" string="officers" />
          </tokens>
        </chunking>
        <chunking id="7" string="prosecution of three of the officers" type="NP">
          <tokens>
            <token id="5" string="prosecution" />
            <token id="6" string="of" />
            <token id="7" string="three" />
            <token id="8" string="of" />
            <token id="9" string="the" />
            <token id="10" string="officers" />
          </tokens>
        </chunking>
        <chunking id="8" string="his troops" type="NP">
          <tokens>
            <token id="18" string="his" />
            <token id="19" string="troops" />
          </tokens>
        </chunking>
        <chunking id="9" string="three" type="NP">
          <tokens>
            <token id="7" string="three" />
          </tokens>
        </chunking>
        <chunking id="10" string="condemning the beating" type="VP">
          <tokens>
            <token id="20" string="condemning" />
            <token id="21" string="the" />
            <token id="22" string="beating" />
          </tokens>
        </chunking>
        <chunking id="11" string="has called for prosecution of three of the officers , and has produced a videotape for his troops condemning the beating" type="VP">
          <tokens>
            <token id="2" string="has" />
            <token id="3" string="called" />
            <token id="4" string="for" />
            <token id="5" string="prosecution" />
            <token id="6" string="of" />
            <token id="7" string="three" />
            <token id="8" string="of" />
            <token id="9" string="the" />
            <token id="10" string="officers" />
            <token id="11" string="," />
            <token id="12" string="and" />
            <token id="13" string="has" />
            <token id="14" string="produced" />
            <token id="15" string="a" />
            <token id="16" string="videotape" />
            <token id="17" string="for" />
            <token id="18" string="his" />
            <token id="19" string="troops" />
            <token id="20" string="condemning" />
            <token id="21" string="the" />
            <token id="22" string="beating" />
          </tokens>
        </chunking>
        <chunking id="12" string="the beating" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="beating" />
          </tokens>
        </chunking>
        <chunking id="13" string="the officers" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="officers" />
          </tokens>
        </chunking>
        <chunking id="14" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="15" string="called for prosecution of three of the officers" type="VP">
          <tokens>
            <token id="3" string="called" />
            <token id="4" string="for" />
            <token id="5" string="prosecution" />
            <token id="6" string="of" />
            <token id="7" string="three" />
            <token id="8" string="of" />
            <token id="9" string="the" />
            <token id="10" string="officers" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">called</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">called</governor>
          <dependent id="2">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">called</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">prosecution</governor>
          <dependent id="4">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">called</governor>
          <dependent id="5">prosecution</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">three</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">prosecution</governor>
          <dependent id="7">three</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">officers</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">officers</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">three</governor>
          <dependent id="10">officers</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">called</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">produced</governor>
          <dependent id="13">has</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">called</governor>
          <dependent id="14">produced</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">videotape</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">produced</governor>
          <dependent id="16">videotape</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">troops</governor>
          <dependent id="17">for</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">troops</governor>
          <dependent id="18">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">produced</governor>
          <dependent id="19">troops</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="14">produced</governor>
          <dependent id="20">condemning</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">beating</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">condemning</governor>
          <dependent id="22">beating</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="three" type="NUMBER" score="0.0">
          <tokens>
            <token id="7" string="three" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="35" has_coreference="true">
      <content>But condemnation of misconduct and excessive force should have been a constant message from the command staff before the brutality, and not an afterthought.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="condemnation" lemma="condemnation" stem="condemn" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="misconduct" lemma="misconduct" stem="misconduct" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="excessive" lemma="excessive" stem="excess" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="force" lemma="force" stem="forc" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="should" lemma="should" stem="should" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="constant" lemma="constant" stem="constant" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="message" lemma="message" stem="messag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="command" lemma="command" stem="command" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="staff" lemma="staff" stem="staff" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="brutality" lemma="brutality" stem="brutal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="afterthought" lemma="afterthought" stem="afterthought" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (NP (NN condemnation)) (PP (IN of) (NP (NN misconduct) (CC and) (JJ excessive) (NN force)))) (VP (MD should) (VP (VB have) (VP (VBN been) (NP (NP (DT a) (JJ constant) (NN message)) (PP (IN from) (NP (DT the) (NN command) (NN staff)))) (PP (IN before) (NP (NP (DT the) (NN brutality)) (, ,) (CC and) (RB not) (NP (DT an) (NN afterthought))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="condemnation of misconduct and excessive force" type="NP">
          <tokens>
            <token id="2" string="condemnation" />
            <token id="3" string="of" />
            <token id="4" string="misconduct" />
            <token id="5" string="and" />
            <token id="6" string="excessive" />
            <token id="7" string="force" />
          </tokens>
        </chunking>
        <chunking id="2" string="misconduct and excessive force" type="NP">
          <tokens>
            <token id="4" string="misconduct" />
            <token id="5" string="and" />
            <token id="6" string="excessive" />
            <token id="7" string="force" />
          </tokens>
        </chunking>
        <chunking id="3" string="a constant message from the command staff" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="constant" />
            <token id="13" string="message" />
            <token id="14" string="from" />
            <token id="15" string="the" />
            <token id="16" string="command" />
            <token id="17" string="staff" />
          </tokens>
        </chunking>
        <chunking id="4" string="the brutality" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="5" string="have been a constant message from the command staff before the brutality , and not an afterthought" type="VP">
          <tokens>
            <token id="9" string="have" />
            <token id="10" string="been" />
            <token id="11" string="a" />
            <token id="12" string="constant" />
            <token id="13" string="message" />
            <token id="14" string="from" />
            <token id="15" string="the" />
            <token id="16" string="command" />
            <token id="17" string="staff" />
            <token id="18" string="before" />
            <token id="19" string="the" />
            <token id="20" string="brutality" />
            <token id="21" string="," />
            <token id="22" string="and" />
            <token id="23" string="not" />
            <token id="24" string="an" />
            <token id="25" string="afterthought" />
          </tokens>
        </chunking>
        <chunking id="6" string="an afterthought" type="NP">
          <tokens>
            <token id="24" string="an" />
            <token id="25" string="afterthought" />
          </tokens>
        </chunking>
        <chunking id="7" string="condemnation" type="NP">
          <tokens>
            <token id="2" string="condemnation" />
          </tokens>
        </chunking>
        <chunking id="8" string="a constant message" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="constant" />
            <token id="13" string="message" />
          </tokens>
        </chunking>
        <chunking id="9" string="been a constant message from the command staff before the brutality , and not an afterthought" type="VP">
          <tokens>
            <token id="10" string="been" />
            <token id="11" string="a" />
            <token id="12" string="constant" />
            <token id="13" string="message" />
            <token id="14" string="from" />
            <token id="15" string="the" />
            <token id="16" string="command" />
            <token id="17" string="staff" />
            <token id="18" string="before" />
            <token id="19" string="the" />
            <token id="20" string="brutality" />
            <token id="21" string="," />
            <token id="22" string="and" />
            <token id="23" string="not" />
            <token id="24" string="an" />
            <token id="25" string="afterthought" />
          </tokens>
        </chunking>
        <chunking id="10" string="the command staff" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="command" />
            <token id="17" string="staff" />
          </tokens>
        </chunking>
        <chunking id="11" string="the brutality , and not an afterthought" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="brutality" />
            <token id="21" string="," />
            <token id="22" string="and" />
            <token id="23" string="not" />
            <token id="24" string="an" />
            <token id="25" string="afterthought" />
          </tokens>
        </chunking>
        <chunking id="12" string="should have been a constant message from the command staff before the brutality , and not an afterthought" type="VP">
          <tokens>
            <token id="8" string="should" />
            <token id="9" string="have" />
            <token id="10" string="been" />
            <token id="11" string="a" />
            <token id="12" string="constant" />
            <token id="13" string="message" />
            <token id="14" string="from" />
            <token id="15" string="the" />
            <token id="16" string="command" />
            <token id="17" string="staff" />
            <token id="18" string="before" />
            <token id="19" string="the" />
            <token id="20" string="brutality" />
            <token id="21" string="," />
            <token id="22" string="and" />
            <token id="23" string="not" />
            <token id="24" string="an" />
            <token id="25" string="afterthought" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="13">message</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">message</governor>
          <dependent id="2">condemnation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">force</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">force</governor>
          <dependent id="4">misconduct</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">misconduct</governor>
          <dependent id="5">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">misconduct</governor>
          <dependent id="6">excessive</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">condemnation</governor>
          <dependent id="7">force</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">message</governor>
          <dependent id="8">should</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">message</governor>
          <dependent id="9">have</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="13">message</governor>
          <dependent id="10">been</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">message</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">message</governor>
          <dependent id="12">constant</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">message</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">staff</governor>
          <dependent id="14">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">staff</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">staff</governor>
          <dependent id="16">command</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">message</governor>
          <dependent id="17">staff</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">brutality</governor>
          <dependent id="18">before</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">brutality</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">message</governor>
          <dependent id="20">brutality</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="20">brutality</governor>
          <dependent id="22">and</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="25">afterthought</governor>
          <dependent id="23">not</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">afterthought</governor>
          <dependent id="24">an</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="20">brutality</governor>
          <dependent id="25">afterthought</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="36" has_coreference="true">
      <content>Yet, it&amp;apost;s hard to imagine commanders preaching restraint in light of the chief&amp;apost;s constant belligerent pronouncements.</content>
      <tokens>
        <token id="1" string="Yet" lemma="yet" stem="yet" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="hard" lemma="hard" stem="hard" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="imagine" lemma="imagine" stem="imagin" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="commanders" lemma="commander" stem="command" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="preaching" lemma="preach" stem="preach" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="restraint" lemma="restraint" stem="restraint" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="light" lemma="light" stem="light" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="chief" lemma="chief" stem="chief" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="constant" lemma="constant" stem="constant" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="belligerent" lemma="belligerent" stem="belliger" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="pronouncements" lemma="pronouncement" stem="pronounc" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Yet)) (, ,) (NP (PRP it)) (VP (VBZ 's) (ADJP (JJ hard) (S (VP (TO to) (VP (VB imagine) (NP (NNS commanders)) (S (VP (VBG preaching) (NP (NN restraint)) (PP (IN in) (NP (NP (NN light)) (PP (IN of) (NP (NP (DT the) (NN chief) (POS 's)) (JJ constant) (JJ belligerent) (NNS pronouncements)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="'s hard to imagine commanders preaching restraint in light of the chief 's constant belligerent pronouncements" type="VP">
          <tokens>
            <token id="4" string="'s" />
            <token id="5" string="hard" />
            <token id="6" string="to" />
            <token id="7" string="imagine" />
            <token id="8" string="commanders" />
            <token id="9" string="preaching" />
            <token id="10" string="restraint" />
            <token id="11" string="in" />
            <token id="12" string="light" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="chief" />
            <token id="16" string="'s" />
            <token id="17" string="constant" />
            <token id="18" string="belligerent" />
            <token id="19" string="pronouncements" />
          </tokens>
        </chunking>
        <chunking id="2" string="hard to imagine commanders preaching restraint in light of the chief 's constant belligerent pronouncements" type="ADJP">
          <tokens>
            <token id="5" string="hard" />
            <token id="6" string="to" />
            <token id="7" string="imagine" />
            <token id="8" string="commanders" />
            <token id="9" string="preaching" />
            <token id="10" string="restraint" />
            <token id="11" string="in" />
            <token id="12" string="light" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="chief" />
            <token id="16" string="'s" />
            <token id="17" string="constant" />
            <token id="18" string="belligerent" />
            <token id="19" string="pronouncements" />
          </tokens>
        </chunking>
        <chunking id="3" string="the chief 's" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="chief" />
            <token id="16" string="'s" />
          </tokens>
        </chunking>
        <chunking id="4" string="light" type="NP">
          <tokens>
            <token id="12" string="light" />
          </tokens>
        </chunking>
        <chunking id="5" string="commanders" type="NP">
          <tokens>
            <token id="8" string="commanders" />
          </tokens>
        </chunking>
        <chunking id="6" string="the chief 's constant belligerent pronouncements" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="chief" />
            <token id="16" string="'s" />
            <token id="17" string="constant" />
            <token id="18" string="belligerent" />
            <token id="19" string="pronouncements" />
          </tokens>
        </chunking>
        <chunking id="7" string="restraint" type="NP">
          <tokens>
            <token id="10" string="restraint" />
          </tokens>
        </chunking>
        <chunking id="8" string="imagine commanders preaching restraint in light of the chief 's constant belligerent pronouncements" type="VP">
          <tokens>
            <token id="7" string="imagine" />
            <token id="8" string="commanders" />
            <token id="9" string="preaching" />
            <token id="10" string="restraint" />
            <token id="11" string="in" />
            <token id="12" string="light" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="chief" />
            <token id="16" string="'s" />
            <token id="17" string="constant" />
            <token id="18" string="belligerent" />
            <token id="19" string="pronouncements" />
          </tokens>
        </chunking>
        <chunking id="9" string="it" type="NP">
          <tokens>
            <token id="3" string="it" />
          </tokens>
        </chunking>
        <chunking id="10" string="light of the chief 's constant belligerent pronouncements" type="NP">
          <tokens>
            <token id="12" string="light" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="chief" />
            <token id="16" string="'s" />
            <token id="17" string="constant" />
            <token id="18" string="belligerent" />
            <token id="19" string="pronouncements" />
          </tokens>
        </chunking>
        <chunking id="11" string="preaching restraint in light of the chief 's constant belligerent pronouncements" type="VP">
          <tokens>
            <token id="9" string="preaching" />
            <token id="10" string="restraint" />
            <token id="11" string="in" />
            <token id="12" string="light" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="chief" />
            <token id="16" string="'s" />
            <token id="17" string="constant" />
            <token id="18" string="belligerent" />
            <token id="19" string="pronouncements" />
          </tokens>
        </chunking>
        <chunking id="12" string="to imagine commanders preaching restraint in light of the chief 's constant belligerent pronouncements" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="imagine" />
            <token id="8" string="commanders" />
            <token id="9" string="preaching" />
            <token id="10" string="restraint" />
            <token id="11" string="in" />
            <token id="12" string="light" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="chief" />
            <token id="16" string="'s" />
            <token id="17" string="constant" />
            <token id="18" string="belligerent" />
            <token id="19" string="pronouncements" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="5">hard</governor>
          <dependent id="1">Yet</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">hard</governor>
          <dependent id="3">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">hard</governor>
          <dependent id="4">'s</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">hard</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">imagine</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">hard</governor>
          <dependent id="7">imagine</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">imagine</governor>
          <dependent id="8">commanders</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">imagine</governor>
          <dependent id="9">preaching</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">preaching</governor>
          <dependent id="10">restraint</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">light</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">preaching</governor>
          <dependent id="12">light</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">pronouncements</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">chief</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">pronouncements</governor>
          <dependent id="15">chief</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">chief</governor>
          <dependent id="16">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">pronouncements</governor>
          <dependent id="17">constant</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">pronouncements</governor>
          <dependent id="18">belligerent</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">light</governor>
          <dependent id="19">pronouncements</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="37" has_coreference="true">
      <content>Even Mr. Gates&amp;apost;s apology to Mr. King sent the wrong message.</content>
      <tokens>
        <token id="1" string="Even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="Gates" lemma="Gates" stem="gate" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="apology" lemma="apology" stem="apologi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="King" lemma="King" stem="king" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="9" string="sent" lemma="send" stem="sent" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="wrong" lemma="wrong" stem="wrong" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="message" lemma="message" stem="messag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (RB Even) (NP (NNP Mr.) (NNP Gates) (POS 's)) (NN apology)) (PP (TO to) (NP (NNP Mr.) (NNP King)))) (VP (VBD sent) (NP (DT the) (JJ wrong) (NN message))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Mr. Gates 's" type="NP">
          <tokens>
            <token id="2" string="Mr." />
            <token id="3" string="Gates" />
            <token id="4" string="'s" />
          </tokens>
        </chunking>
        <chunking id="2" string="Even Mr. Gates 's apology" type="NP">
          <tokens>
            <token id="1" string="Even" />
            <token id="2" string="Mr." />
            <token id="3" string="Gates" />
            <token id="4" string="'s" />
            <token id="5" string="apology" />
          </tokens>
        </chunking>
        <chunking id="3" string="Even Mr. Gates 's apology to Mr. King" type="NP">
          <tokens>
            <token id="1" string="Even" />
            <token id="2" string="Mr." />
            <token id="3" string="Gates" />
            <token id="4" string="'s" />
            <token id="5" string="apology" />
            <token id="6" string="to" />
            <token id="7" string="Mr." />
            <token id="8" string="King" />
          </tokens>
        </chunking>
        <chunking id="4" string="Mr. King" type="NP">
          <tokens>
            <token id="7" string="Mr." />
            <token id="8" string="King" />
          </tokens>
        </chunking>
        <chunking id="5" string="sent the wrong message" type="VP">
          <tokens>
            <token id="9" string="sent" />
            <token id="10" string="the" />
            <token id="11" string="wrong" />
            <token id="12" string="message" />
          </tokens>
        </chunking>
        <chunking id="6" string="the wrong message" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="wrong" />
            <token id="12" string="message" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="5">apology</governor>
          <dependent id="1">Even</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Gates</governor>
          <dependent id="2">Mr.</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">apology</governor>
          <dependent id="3">Gates</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">Gates</governor>
          <dependent id="4">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">sent</governor>
          <dependent id="5">apology</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">King</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">King</governor>
          <dependent id="7">Mr.</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">apology</governor>
          <dependent id="8">King</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">sent</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">message</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">message</governor>
          <dependent id="11">wrong</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">sent</governor>
          <dependent id="12">message</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Gates" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Gates" />
          </tokens>
        </entity>
        <entity id="2" string="King" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="King" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="38" has_coreference="true">
      <content>He said that he hoped the incident might help Mr. King to straighten out his life.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="hoped" lemma="hope" stem="hope" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="incident" lemma="incident" stem="incid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="might" lemma="might" stem="might" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="help" lemma="help" stem="help" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="King" lemma="King" stem="king" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="straighten" lemma="straighten" stem="straighten" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="life" lemma="life" stem="life" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD said) (SBAR (IN that) (S (NP (PRP he)) (VP (VBD hoped) (SBAR (S (NP (DT the) (NN incident)) (VP (MD might) (VP (VB help) (S (NP (NNP Mr.) (NNP King)) (VP (TO to) (VP (VB straighten) (PRT (RP out)) (NP (PRP$ his) (NN life))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="hoped the incident might help Mr. King to straighten out his life" type="VP">
          <tokens>
            <token id="5" string="hoped" />
            <token id="6" string="the" />
            <token id="7" string="incident" />
            <token id="8" string="might" />
            <token id="9" string="help" />
            <token id="10" string="Mr." />
            <token id="11" string="King" />
            <token id="12" string="to" />
            <token id="13" string="straighten" />
            <token id="14" string="out" />
            <token id="15" string="his" />
            <token id="16" string="life" />
          </tokens>
        </chunking>
        <chunking id="2" string="straighten out his life" type="VP">
          <tokens>
            <token id="13" string="straighten" />
            <token id="14" string="out" />
            <token id="15" string="his" />
            <token id="16" string="life" />
          </tokens>
        </chunking>
        <chunking id="3" string="said that he hoped the incident might help Mr. King to straighten out his life" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="that" />
            <token id="4" string="he" />
            <token id="5" string="hoped" />
            <token id="6" string="the" />
            <token id="7" string="incident" />
            <token id="8" string="might" />
            <token id="9" string="help" />
            <token id="10" string="Mr." />
            <token id="11" string="King" />
            <token id="12" string="to" />
            <token id="13" string="straighten" />
            <token id="14" string="out" />
            <token id="15" string="his" />
            <token id="16" string="life" />
          </tokens>
        </chunking>
        <chunking id="4" string="to straighten out his life" type="VP">
          <tokens>
            <token id="12" string="to" />
            <token id="13" string="straighten" />
            <token id="14" string="out" />
            <token id="15" string="his" />
            <token id="16" string="life" />
          </tokens>
        </chunking>
        <chunking id="5" string="the incident might help Mr. King to straighten out his life" type="SBAR">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="incident" />
            <token id="8" string="might" />
            <token id="9" string="help" />
            <token id="10" string="Mr." />
            <token id="11" string="King" />
            <token id="12" string="to" />
            <token id="13" string="straighten" />
            <token id="14" string="out" />
            <token id="15" string="his" />
            <token id="16" string="life" />
          </tokens>
        </chunking>
        <chunking id="6" string="Mr. King" type="NP">
          <tokens>
            <token id="10" string="Mr." />
            <token id="11" string="King" />
          </tokens>
        </chunking>
        <chunking id="7" string="help Mr. King to straighten out his life" type="VP">
          <tokens>
            <token id="9" string="help" />
            <token id="10" string="Mr." />
            <token id="11" string="King" />
            <token id="12" string="to" />
            <token id="13" string="straighten" />
            <token id="14" string="out" />
            <token id="15" string="his" />
            <token id="16" string="life" />
          </tokens>
        </chunking>
        <chunking id="8" string="his life" type="NP">
          <tokens>
            <token id="15" string="his" />
            <token id="16" string="life" />
          </tokens>
        </chunking>
        <chunking id="9" string="that he hoped the incident might help Mr. King to straighten out his life" type="SBAR">
          <tokens>
            <token id="3" string="that" />
            <token id="4" string="he" />
            <token id="5" string="hoped" />
            <token id="6" string="the" />
            <token id="7" string="incident" />
            <token id="8" string="might" />
            <token id="9" string="help" />
            <token id="10" string="Mr." />
            <token id="11" string="King" />
            <token id="12" string="to" />
            <token id="13" string="straighten" />
            <token id="14" string="out" />
            <token id="15" string="his" />
            <token id="16" string="life" />
          </tokens>
        </chunking>
        <chunking id="10" string="might help Mr. King to straighten out his life" type="VP">
          <tokens>
            <token id="8" string="might" />
            <token id="9" string="help" />
            <token id="10" string="Mr." />
            <token id="11" string="King" />
            <token id="12" string="to" />
            <token id="13" string="straighten" />
            <token id="14" string="out" />
            <token id="15" string="his" />
            <token id="16" string="life" />
          </tokens>
        </chunking>
        <chunking id="11" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="12" string="he" type="NP">
          <tokens>
            <token id="4" string="he" />
          </tokens>
        </chunking>
        <chunking id="13" string="the incident" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="incident" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">hoped</governor>
          <dependent id="3">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">hoped</governor>
          <dependent id="4">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="5">hoped</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">incident</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">help</governor>
          <dependent id="7">incident</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">help</governor>
          <dependent id="8">might</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">hoped</governor>
          <dependent id="9">help</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">King</governor>
          <dependent id="10">Mr.</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">help</governor>
          <dependent id="11">King</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">straighten</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">help</governor>
          <dependent id="13">straighten</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="13">straighten</governor>
          <dependent id="14">out</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">life</governor>
          <dependent id="15">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">straighten</governor>
          <dependent id="16">life</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="King" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="King" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="39" has_coreference="false">
      <content>It is hard to imagine someone unlawfully beaten by uniformed officers as others looked on being inspired to respect law and order.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="hard" lemma="hard" stem="hard" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="imagine" lemma="imagine" stem="imagin" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="someone" lemma="someone" stem="someon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="unlawfully" lemma="unlawfully" stem="unlawfulli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="beaten" lemma="beat" stem="beaten" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="uniformed" lemma="uniformed" stem="uniform" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="others" lemma="other" stem="other" pos="NNS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="looked" lemma="look" stem="look" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="being" lemma="be" stem="be" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="inspired" lemma="inspire" stem="inspir" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="respect" lemma="respect" stem="respect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="law" lemma="law" stem="law" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="order" lemma="order" stem="order" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBZ is) (ADJP (JJ hard) (S (VP (TO to) (VP (VB imagine) (NP (NP (NN someone)) (VP (ADVP (RB unlawfully)) (VBN beaten) (PP (IN by) (NP (JJ uniformed) (NNS officers))))))))) (SBAR (IN as) (S (NP (NNS others)) (VP (VBD looked) (PP (IN on) (S (VP (VBG being) (VP (VBN inspired) (PP (TO to) (NP (NN respect) (NN law) (CC and) (NN order))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="uniformed officers" type="NP">
          <tokens>
            <token id="10" string="uniformed" />
            <token id="11" string="officers" />
          </tokens>
        </chunking>
        <chunking id="2" string="imagine someone unlawfully beaten by uniformed officers" type="VP">
          <tokens>
            <token id="5" string="imagine" />
            <token id="6" string="someone" />
            <token id="7" string="unlawfully" />
            <token id="8" string="beaten" />
            <token id="9" string="by" />
            <token id="10" string="uniformed" />
            <token id="11" string="officers" />
          </tokens>
        </chunking>
        <chunking id="3" string="respect law and order" type="NP">
          <tokens>
            <token id="19" string="respect" />
            <token id="20" string="law" />
            <token id="21" string="and" />
            <token id="22" string="order" />
          </tokens>
        </chunking>
        <chunking id="4" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="5" string="is hard to imagine someone unlawfully beaten by uniformed officers as others looked on being inspired to respect law and order" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="hard" />
            <token id="4" string="to" />
            <token id="5" string="imagine" />
            <token id="6" string="someone" />
            <token id="7" string="unlawfully" />
            <token id="8" string="beaten" />
            <token id="9" string="by" />
            <token id="10" string="uniformed" />
            <token id="11" string="officers" />
            <token id="12" string="as" />
            <token id="13" string="others" />
            <token id="14" string="looked" />
            <token id="15" string="on" />
            <token id="16" string="being" />
            <token id="17" string="inspired" />
            <token id="18" string="to" />
            <token id="19" string="respect" />
            <token id="20" string="law" />
            <token id="21" string="and" />
            <token id="22" string="order" />
          </tokens>
        </chunking>
        <chunking id="6" string="looked on being inspired to respect law and order" type="VP">
          <tokens>
            <token id="14" string="looked" />
            <token id="15" string="on" />
            <token id="16" string="being" />
            <token id="17" string="inspired" />
            <token id="18" string="to" />
            <token id="19" string="respect" />
            <token id="20" string="law" />
            <token id="21" string="and" />
            <token id="22" string="order" />
          </tokens>
        </chunking>
        <chunking id="7" string="unlawfully beaten by uniformed officers" type="VP">
          <tokens>
            <token id="7" string="unlawfully" />
            <token id="8" string="beaten" />
            <token id="9" string="by" />
            <token id="10" string="uniformed" />
            <token id="11" string="officers" />
          </tokens>
        </chunking>
        <chunking id="8" string="being inspired to respect law and order" type="VP">
          <tokens>
            <token id="16" string="being" />
            <token id="17" string="inspired" />
            <token id="18" string="to" />
            <token id="19" string="respect" />
            <token id="20" string="law" />
            <token id="21" string="and" />
            <token id="22" string="order" />
          </tokens>
        </chunking>
        <chunking id="9" string="to imagine someone unlawfully beaten by uniformed officers" type="VP">
          <tokens>
            <token id="4" string="to" />
            <token id="5" string="imagine" />
            <token id="6" string="someone" />
            <token id="7" string="unlawfully" />
            <token id="8" string="beaten" />
            <token id="9" string="by" />
            <token id="10" string="uniformed" />
            <token id="11" string="officers" />
          </tokens>
        </chunking>
        <chunking id="10" string="inspired to respect law and order" type="VP">
          <tokens>
            <token id="17" string="inspired" />
            <token id="18" string="to" />
            <token id="19" string="respect" />
            <token id="20" string="law" />
            <token id="21" string="and" />
            <token id="22" string="order" />
          </tokens>
        </chunking>
        <chunking id="11" string="someone" type="NP">
          <tokens>
            <token id="6" string="someone" />
          </tokens>
        </chunking>
        <chunking id="12" string="someone unlawfully beaten by uniformed officers" type="NP">
          <tokens>
            <token id="6" string="someone" />
            <token id="7" string="unlawfully" />
            <token id="8" string="beaten" />
            <token id="9" string="by" />
            <token id="10" string="uniformed" />
            <token id="11" string="officers" />
          </tokens>
        </chunking>
        <chunking id="13" string="hard to imagine someone unlawfully beaten by uniformed officers" type="ADJP">
          <tokens>
            <token id="3" string="hard" />
            <token id="4" string="to" />
            <token id="5" string="imagine" />
            <token id="6" string="someone" />
            <token id="7" string="unlawfully" />
            <token id="8" string="beaten" />
            <token id="9" string="by" />
            <token id="10" string="uniformed" />
            <token id="11" string="officers" />
          </tokens>
        </chunking>
        <chunking id="14" string="as others looked on being inspired to respect law and order" type="SBAR">
          <tokens>
            <token id="12" string="as" />
            <token id="13" string="others" />
            <token id="14" string="looked" />
            <token id="15" string="on" />
            <token id="16" string="being" />
            <token id="17" string="inspired" />
            <token id="18" string="to" />
            <token id="19" string="respect" />
            <token id="20" string="law" />
            <token id="21" string="and" />
            <token id="22" string="order" />
          </tokens>
        </chunking>
        <chunking id="15" string="others" type="NP">
          <tokens>
            <token id="13" string="others" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">hard</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="3">hard</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">hard</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">imagine</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">hard</governor>
          <dependent id="5">imagine</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">imagine</governor>
          <dependent id="6">someone</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">beaten</governor>
          <dependent id="7">unlawfully</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="6">someone</governor>
          <dependent id="8">beaten</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">officers</governor>
          <dependent id="9">by</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">officers</governor>
          <dependent id="10">uniformed</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">beaten</governor>
          <dependent id="11">officers</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">looked</governor>
          <dependent id="12">as</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">looked</governor>
          <dependent id="13">others</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">hard</governor>
          <dependent id="14">looked</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">inspired</governor>
          <dependent id="15">on</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="17">inspired</governor>
          <dependent id="16">being</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="14">looked</governor>
          <dependent id="17">inspired</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">law</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">law</governor>
          <dependent id="19">respect</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">inspired</governor>
          <dependent id="20">law</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="20">law</governor>
          <dependent id="21">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="20">law</governor>
          <dependent id="22">order</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="40" has_coreference="true">
      <content>Or was the chief suggesting that the beating was a warning against further run-ins with the police?</content>
      <tokens>
        <token id="1" string="Or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="chief" lemma="chief" stem="chief" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="suggesting" lemma="suggest" stem="suggest" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="beating" lemma="beating" stem="beat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="warning" lemma="warning" stem="warn" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="further" lemma="further" stem="further" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="run-ins" lemma="run-in" stem="run-in" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC Or) (VP (VBD was) (NP (NP (DT the) (JJ chief)) (VP (VBG suggesting) (SBAR (IN that) (S (NP (DT the) (NN beating)) (VP (VBD was) (NP (NP (DT a) (NN warning)) (PP (IN against) (NP (NP (JJ further) (NNS run-ins)) (PP (IN with) (NP (DT the) (NN police)))))))))))) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a warning against further run-ins with the police" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="warning" />
            <token id="12" string="against" />
            <token id="13" string="further" />
            <token id="14" string="run-ins" />
            <token id="15" string="with" />
            <token id="16" string="the" />
            <token id="17" string="police" />
          </tokens>
        </chunking>
        <chunking id="2" string="the chief suggesting that the beating was a warning against further run-ins with the police" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="chief" />
            <token id="5" string="suggesting" />
            <token id="6" string="that" />
            <token id="7" string="the" />
            <token id="8" string="beating" />
            <token id="9" string="was" />
            <token id="10" string="a" />
            <token id="11" string="warning" />
            <token id="12" string="against" />
            <token id="13" string="further" />
            <token id="14" string="run-ins" />
            <token id="15" string="with" />
            <token id="16" string="the" />
            <token id="17" string="police" />
          </tokens>
        </chunking>
        <chunking id="3" string="was the chief suggesting that the beating was a warning against further run-ins with the police" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="the" />
            <token id="4" string="chief" />
            <token id="5" string="suggesting" />
            <token id="6" string="that" />
            <token id="7" string="the" />
            <token id="8" string="beating" />
            <token id="9" string="was" />
            <token id="10" string="a" />
            <token id="11" string="warning" />
            <token id="12" string="against" />
            <token id="13" string="further" />
            <token id="14" string="run-ins" />
            <token id="15" string="with" />
            <token id="16" string="the" />
            <token id="17" string="police" />
          </tokens>
        </chunking>
        <chunking id="4" string="suggesting that the beating was a warning against further run-ins with the police" type="VP">
          <tokens>
            <token id="5" string="suggesting" />
            <token id="6" string="that" />
            <token id="7" string="the" />
            <token id="8" string="beating" />
            <token id="9" string="was" />
            <token id="10" string="a" />
            <token id="11" string="warning" />
            <token id="12" string="against" />
            <token id="13" string="further" />
            <token id="14" string="run-ins" />
            <token id="15" string="with" />
            <token id="16" string="the" />
            <token id="17" string="police" />
          </tokens>
        </chunking>
        <chunking id="5" string="the chief" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="chief" />
          </tokens>
        </chunking>
        <chunking id="6" string="a warning" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="warning" />
          </tokens>
        </chunking>
        <chunking id="7" string="that the beating was a warning against further run-ins with the police" type="SBAR">
          <tokens>
            <token id="6" string="that" />
            <token id="7" string="the" />
            <token id="8" string="beating" />
            <token id="9" string="was" />
            <token id="10" string="a" />
            <token id="11" string="warning" />
            <token id="12" string="against" />
            <token id="13" string="further" />
            <token id="14" string="run-ins" />
            <token id="15" string="with" />
            <token id="16" string="the" />
            <token id="17" string="police" />
          </tokens>
        </chunking>
        <chunking id="8" string="the beating" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="beating" />
          </tokens>
        </chunking>
        <chunking id="9" string="further run-ins" type="NP">
          <tokens>
            <token id="13" string="further" />
            <token id="14" string="run-ins" />
          </tokens>
        </chunking>
        <chunking id="10" string="the police" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="police" />
          </tokens>
        </chunking>
        <chunking id="11" string="was a warning against further run-ins with the police" type="VP">
          <tokens>
            <token id="9" string="was" />
            <token id="10" string="a" />
            <token id="11" string="warning" />
            <token id="12" string="against" />
            <token id="13" string="further" />
            <token id="14" string="run-ins" />
            <token id="15" string="with" />
            <token id="16" string="the" />
            <token id="17" string="police" />
          </tokens>
        </chunking>
        <chunking id="12" string="further run-ins with the police" type="NP">
          <tokens>
            <token id="13" string="further" />
            <token id="14" string="run-ins" />
            <token id="15" string="with" />
            <token id="16" string="the" />
            <token id="17" string="police" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="4">chief</governor>
          <dependent id="1">Or</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">chief</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">chief</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">chief</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="4">chief</governor>
          <dependent id="5">suggesting</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">warning</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">beating</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">warning</governor>
          <dependent id="8">beating</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">warning</governor>
          <dependent id="9">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">warning</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">suggesting</governor>
          <dependent id="11">warning</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">run-ins</governor>
          <dependent id="12">against</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">run-ins</governor>
          <dependent id="13">further</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">warning</governor>
          <dependent id="14">run-ins</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">police</governor>
          <dependent id="15">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">police</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">run-ins</governor>
          <dependent id="17">police</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="41" has_coreference="false">
      <content>Clearly, Daryl Gates&amp;apost;s words and actions create doubt about his claim that the Rodney King incident was an aberration.</content>
      <tokens>
        <token id="1" string="Clearly" lemma="clearly" stem="clearli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Daryl" lemma="Daryl" stem="daryl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="Gates" lemma="Gates" stem="gate" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="5" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="words" lemma="word" stem="word" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="actions" lemma="action" stem="action" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="create" lemma="create" stem="creat" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="doubt" lemma="doubt" stem="doubt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="claim" lemma="claim" stem="claim" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="Rodney" lemma="Rodney" stem="rodnei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="17" string="King" lemma="King" stem="king" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="18" string="incident" lemma="incident" stem="incid" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="aberration" lemma="aberration" stem="aberr" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Clearly)) (, ,) (NP (NP (NNP Daryl) (NNP Gates) (POS 's)) (NNS words) (CC and) (NNS actions)) (VP (VBP create) (ADVP (NN doubt)) (PP (IN about) (NP (PRP$ his) (NN claim))) (SBAR (IN that) (S (NP (DT the) (NNP Rodney) (NNP King) (NN incident)) (VP (VBD was) (NP (DT an) (NN aberration)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the Rodney King incident" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="Rodney" />
            <token id="17" string="King" />
            <token id="18" string="incident" />
          </tokens>
        </chunking>
        <chunking id="2" string="Daryl Gates 's words and actions" type="NP">
          <tokens>
            <token id="3" string="Daryl" />
            <token id="4" string="Gates" />
            <token id="5" string="'s" />
            <token id="6" string="words" />
            <token id="7" string="and" />
            <token id="8" string="actions" />
          </tokens>
        </chunking>
        <chunking id="3" string="create doubt about his claim that the Rodney King incident was an aberration" type="VP">
          <tokens>
            <token id="9" string="create" />
            <token id="10" string="doubt" />
            <token id="11" string="about" />
            <token id="12" string="his" />
            <token id="13" string="claim" />
            <token id="14" string="that" />
            <token id="15" string="the" />
            <token id="16" string="Rodney" />
            <token id="17" string="King" />
            <token id="18" string="incident" />
            <token id="19" string="was" />
            <token id="20" string="an" />
            <token id="21" string="aberration" />
          </tokens>
        </chunking>
        <chunking id="4" string="was an aberration" type="VP">
          <tokens>
            <token id="19" string="was" />
            <token id="20" string="an" />
            <token id="21" string="aberration" />
          </tokens>
        </chunking>
        <chunking id="5" string="his claim" type="NP">
          <tokens>
            <token id="12" string="his" />
            <token id="13" string="claim" />
          </tokens>
        </chunking>
        <chunking id="6" string="Daryl Gates 's" type="NP">
          <tokens>
            <token id="3" string="Daryl" />
            <token id="4" string="Gates" />
            <token id="5" string="'s" />
          </tokens>
        </chunking>
        <chunking id="7" string="an aberration" type="NP">
          <tokens>
            <token id="20" string="an" />
            <token id="21" string="aberration" />
          </tokens>
        </chunking>
        <chunking id="8" string="that the Rodney King incident was an aberration" type="SBAR">
          <tokens>
            <token id="14" string="that" />
            <token id="15" string="the" />
            <token id="16" string="Rodney" />
            <token id="17" string="King" />
            <token id="18" string="incident" />
            <token id="19" string="was" />
            <token id="20" string="an" />
            <token id="21" string="aberration" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="9">create</governor>
          <dependent id="1">Clearly</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Gates</governor>
          <dependent id="3">Daryl</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">words</governor>
          <dependent id="4">Gates</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">Gates</governor>
          <dependent id="5">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">create</governor>
          <dependent id="6">words</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">words</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">words</governor>
          <dependent id="8">actions</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">create</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">create</governor>
          <dependent id="10">doubt</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">claim</governor>
          <dependent id="11">about</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">claim</governor>
          <dependent id="12">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">create</governor>
          <dependent id="13">claim</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">aberration</governor>
          <dependent id="14">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">incident</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">incident</governor>
          <dependent id="16">Rodney</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">incident</governor>
          <dependent id="17">King</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">aberration</governor>
          <dependent id="18">incident</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="21">aberration</governor>
          <dependent id="19">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">aberration</governor>
          <dependent id="20">an</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">create</governor>
          <dependent id="21">aberration</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Daryl Gates" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Daryl" />
            <token id="4" string="Gates" />
          </tokens>
        </entity>
        <entity id="2" string="Rodney King" type="PERSON" score="0.0">
          <tokens>
            <token id="16" string="Rodney" />
            <token id="17" string="King" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="42" has_coreference="true">
      <content>Public opinion polls in Los Angeles show the majority of people believe police brutality is common, and they disapprove of the way Mr. Gates has done his job.</content>
      <tokens>
        <token id="1" string="Public" lemma="Public" stem="public" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="opinion" lemma="opinion" stem="opinion" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="polls" lemma="poll" stem="poll" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Los" lemma="Los" stem="lo" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="6" string="Angeles" lemma="Angeles" stem="angele" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="7" string="show" lemma="show" stem="show" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="majority" lemma="majority" stem="major" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="believe" lemma="believe" stem="believ" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="police" lemma="police" stem="polic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="brutality" lemma="brutality" stem="brutal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="common" lemma="common" stem="common" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="disapprove" lemma="disapprove" stem="disapprov" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="way" lemma="way" stem="wai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="Gates" lemma="Gates" stem="gate" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="26" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="done" lemma="do" stem="done" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="29" string="job" lemma="job" stem="job" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (NNP Public) (NN opinion) (NNS polls)) (PP (IN in) (NP (NNP Los) (NNP Angeles)))) (VP (VBP show) (SBAR (S (NP (NP (DT the) (NN majority)) (PP (IN of) (NP (NNS people)))) (VP (VBP believe) (SBAR (S (NP (NNS police) (NN brutality)) (VP (VBZ is) (ADJP (JJ common)))))))))) (, ,) (CC and) (S (NP (PRP they)) (VP (VBP disapprove) (PP (IN of) (NP (NP (DT the) (NN way)) (SBAR (S (NP (NNP Mr.) (NNP Gates)) (VP (VBZ has) (VP (VBN done) (NP (PRP$ his) (NN job)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="police brutality is common" type="SBAR">
          <tokens>
            <token id="13" string="police" />
            <token id="14" string="brutality" />
            <token id="15" string="is" />
            <token id="16" string="common" />
          </tokens>
        </chunking>
        <chunking id="2" string="the majority of people" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="majority" />
            <token id="10" string="of" />
            <token id="11" string="people" />
          </tokens>
        </chunking>
        <chunking id="3" string="Public opinion polls" type="NP">
          <tokens>
            <token id="1" string="Public" />
            <token id="2" string="opinion" />
            <token id="3" string="polls" />
          </tokens>
        </chunking>
        <chunking id="4" string="believe police brutality is common" type="VP">
          <tokens>
            <token id="12" string="believe" />
            <token id="13" string="police" />
            <token id="14" string="brutality" />
            <token id="15" string="is" />
            <token id="16" string="common" />
          </tokens>
        </chunking>
        <chunking id="5" string="the majority of people believe police brutality is common" type="SBAR">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="majority" />
            <token id="10" string="of" />
            <token id="11" string="people" />
            <token id="12" string="believe" />
            <token id="13" string="police" />
            <token id="14" string="brutality" />
            <token id="15" string="is" />
            <token id="16" string="common" />
          </tokens>
        </chunking>
        <chunking id="6" string="done his job" type="VP">
          <tokens>
            <token id="27" string="done" />
            <token id="28" string="his" />
            <token id="29" string="job" />
          </tokens>
        </chunking>
        <chunking id="7" string="people" type="NP">
          <tokens>
            <token id="11" string="people" />
          </tokens>
        </chunking>
        <chunking id="8" string="disapprove of the way Mr. Gates has done his job" type="VP">
          <tokens>
            <token id="20" string="disapprove" />
            <token id="21" string="of" />
            <token id="22" string="the" />
            <token id="23" string="way" />
            <token id="24" string="Mr." />
            <token id="25" string="Gates" />
            <token id="26" string="has" />
            <token id="27" string="done" />
            <token id="28" string="his" />
            <token id="29" string="job" />
          </tokens>
        </chunking>
        <chunking id="9" string="they" type="NP">
          <tokens>
            <token id="19" string="they" />
          </tokens>
        </chunking>
        <chunking id="10" string="common" type="ADJP">
          <tokens>
            <token id="16" string="common" />
          </tokens>
        </chunking>
        <chunking id="11" string="the way" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="way" />
          </tokens>
        </chunking>
        <chunking id="12" string="has done his job" type="VP">
          <tokens>
            <token id="26" string="has" />
            <token id="27" string="done" />
            <token id="28" string="his" />
            <token id="29" string="job" />
          </tokens>
        </chunking>
        <chunking id="13" string="show the majority of people believe police brutality is common" type="VP">
          <tokens>
            <token id="7" string="show" />
            <token id="8" string="the" />
            <token id="9" string="majority" />
            <token id="10" string="of" />
            <token id="11" string="people" />
            <token id="12" string="believe" />
            <token id="13" string="police" />
            <token id="14" string="brutality" />
            <token id="15" string="is" />
            <token id="16" string="common" />
          </tokens>
        </chunking>
        <chunking id="14" string="his job" type="NP">
          <tokens>
            <token id="28" string="his" />
            <token id="29" string="job" />
          </tokens>
        </chunking>
        <chunking id="15" string="Public opinion polls in Los Angeles" type="NP">
          <tokens>
            <token id="1" string="Public" />
            <token id="2" string="opinion" />
            <token id="3" string="polls" />
            <token id="4" string="in" />
            <token id="5" string="Los" />
            <token id="6" string="Angeles" />
          </tokens>
        </chunking>
        <chunking id="16" string="Mr. Gates has done his job" type="SBAR">
          <tokens>
            <token id="24" string="Mr." />
            <token id="25" string="Gates" />
            <token id="26" string="has" />
            <token id="27" string="done" />
            <token id="28" string="his" />
            <token id="29" string="job" />
          </tokens>
        </chunking>
        <chunking id="17" string="police brutality" type="NP">
          <tokens>
            <token id="13" string="police" />
            <token id="14" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="18" string="the way Mr. Gates has done his job" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="way" />
            <token id="24" string="Mr." />
            <token id="25" string="Gates" />
            <token id="26" string="has" />
            <token id="27" string="done" />
            <token id="28" string="his" />
            <token id="29" string="job" />
          </tokens>
        </chunking>
        <chunking id="19" string="Los Angeles" type="NP">
          <tokens>
            <token id="5" string="Los" />
            <token id="6" string="Angeles" />
          </tokens>
        </chunking>
        <chunking id="20" string="Mr. Gates" type="NP">
          <tokens>
            <token id="24" string="Mr." />
            <token id="25" string="Gates" />
          </tokens>
        </chunking>
        <chunking id="21" string="the majority" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="majority" />
          </tokens>
        </chunking>
        <chunking id="22" string="is common" type="VP">
          <tokens>
            <token id="15" string="is" />
            <token id="16" string="common" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">polls</governor>
          <dependent id="1">Public</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">polls</governor>
          <dependent id="2">opinion</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">show</governor>
          <dependent id="3">polls</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Angeles</governor>
          <dependent id="4">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Angeles</governor>
          <dependent id="5">Los</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">polls</governor>
          <dependent id="6">Angeles</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">show</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">majority</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">believe</governor>
          <dependent id="9">majority</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">people</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">majority</governor>
          <dependent id="11">people</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">show</governor>
          <dependent id="12">believe</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">brutality</governor>
          <dependent id="13">police</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">common</governor>
          <dependent id="14">brutality</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="16">common</governor>
          <dependent id="15">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">believe</governor>
          <dependent id="16">common</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">show</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">disapprove</governor>
          <dependent id="19">they</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">show</governor>
          <dependent id="20">disapprove</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">way</governor>
          <dependent id="21">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">way</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">disapprove</governor>
          <dependent id="23">way</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">Gates</governor>
          <dependent id="24">Mr.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">done</governor>
          <dependent id="25">Gates</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="27">done</governor>
          <dependent id="26">has</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="23">way</governor>
          <dependent id="27">done</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="29">job</governor>
          <dependent id="28">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="27">done</governor>
          <dependent id="29">job</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Gates" type="PERSON" score="0.0">
          <tokens>
            <token id="25" string="Gates" />
          </tokens>
        </entity>
        <entity id="2" string="Los Angeles" type="LOCATION" score="0.0">
          <tokens>
            <token id="5" string="Los" />
            <token id="6" string="Angeles" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="43" has_coreference="true">
      <content>When he characterizes such opposition as cop-haters, he embitters his department and to some extent all police.</content>
      <tokens>
        <token id="1" string="When" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="characterizes" lemma="characterize" stem="character" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="opposition" lemma="opposition" stem="opposit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="cop-haters" lemma="cop-hater" stem="cop-hat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="embitters" lemma="embitter" stem="embitt" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="department" lemma="department" stem="depart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="extent" lemma="extent" stem="extent" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="police" lemma="police" stem="polic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (WHADVP (WRB When)) (S (NP (PRP he)) (VP (VBZ characterizes) (NP (JJ such) (NN opposition)) (PP (IN as) (NP (NNS cop-haters)))))) (, ,) (NP (PRP he)) (VP (VP (VBZ embitters) (NP (PRP$ his) (NN department))) (CC and) (VP (PP (TO to) (NP (NP (DT some) (NN extent)) (NP (DT all) (NNS police)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="When he characterizes such opposition as cop-haters" type="SBAR">
          <tokens>
            <token id="1" string="When" />
            <token id="2" string="he" />
            <token id="3" string="characterizes" />
            <token id="4" string="such" />
            <token id="5" string="opposition" />
            <token id="6" string="as" />
            <token id="7" string="cop-haters" />
          </tokens>
        </chunking>
        <chunking id="2" string="cop-haters" type="NP">
          <tokens>
            <token id="7" string="cop-haters" />
          </tokens>
        </chunking>
        <chunking id="3" string="embitters his department" type="VP">
          <tokens>
            <token id="10" string="embitters" />
            <token id="11" string="his" />
            <token id="12" string="department" />
          </tokens>
        </chunking>
        <chunking id="4" string="When" type="WHADVP">
          <tokens>
            <token id="1" string="When" />
          </tokens>
        </chunking>
        <chunking id="5" string="such opposition" type="NP">
          <tokens>
            <token id="4" string="such" />
            <token id="5" string="opposition" />
          </tokens>
        </chunking>
        <chunking id="6" string="to some extent all police" type="VP">
          <tokens>
            <token id="14" string="to" />
            <token id="15" string="some" />
            <token id="16" string="extent" />
            <token id="17" string="all" />
            <token id="18" string="police" />
          </tokens>
        </chunking>
        <chunking id="7" string="some extent" type="NP">
          <tokens>
            <token id="15" string="some" />
            <token id="16" string="extent" />
          </tokens>
        </chunking>
        <chunking id="8" string="his department" type="NP">
          <tokens>
            <token id="11" string="his" />
            <token id="12" string="department" />
          </tokens>
        </chunking>
        <chunking id="9" string="embitters his department and to some extent all police" type="VP">
          <tokens>
            <token id="10" string="embitters" />
            <token id="11" string="his" />
            <token id="12" string="department" />
            <token id="13" string="and" />
            <token id="14" string="to" />
            <token id="15" string="some" />
            <token id="16" string="extent" />
            <token id="17" string="all" />
            <token id="18" string="police" />
          </tokens>
        </chunking>
        <chunking id="10" string="some extent all police" type="NP">
          <tokens>
            <token id="15" string="some" />
            <token id="16" string="extent" />
            <token id="17" string="all" />
            <token id="18" string="police" />
          </tokens>
        </chunking>
        <chunking id="11" string="all police" type="NP">
          <tokens>
            <token id="17" string="all" />
            <token id="18" string="police" />
          </tokens>
        </chunking>
        <chunking id="12" string="he" type="NP">
          <tokens>
            <token id="2" string="he" />
          </tokens>
        </chunking>
        <chunking id="13" string="characterizes such opposition as cop-haters" type="VP">
          <tokens>
            <token id="3" string="characterizes" />
            <token id="4" string="such" />
            <token id="5" string="opposition" />
            <token id="6" string="as" />
            <token id="7" string="cop-haters" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="3">characterizes</governor>
          <dependent id="1">When</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">characterizes</governor>
          <dependent id="2">he</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="10">embitters</governor>
          <dependent id="3">characterizes</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">opposition</governor>
          <dependent id="4">such</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">characterizes</governor>
          <dependent id="5">opposition</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">cop-haters</governor>
          <dependent id="6">as</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">characterizes</governor>
          <dependent id="7">cop-haters</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">embitters</governor>
          <dependent id="9">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">embitters</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">department</governor>
          <dependent id="11">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">embitters</governor>
          <dependent id="12">department</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">embitters</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">extent</governor>
          <dependent id="14">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">extent</governor>
          <dependent id="15">some</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">embitters</governor>
          <dependent id="16">extent</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">police</governor>
          <dependent id="17">all</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="16">extent</governor>
          <dependent id="18">police</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="44" has_coreference="true">
      <content>Mr. Gates&amp;apost;s military style of policing is at odds with that in the rest of the country, and it&amp;apost;s about time police leaders publicly repudiated it.</content>
      <tokens>
        <token id="1" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="2" string="Gates" lemma="Gates" stem="gate" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="3" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="4" string="military" lemma="military" stem="militari" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="style" lemma="style" stem="style" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="policing" lemma="police" stem="polic" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="odds" lemma="odds" stem="odd" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="rest" lemma="rest" stem="rest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="country" lemma="country" stem="countri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="leaders" lemma="leader" stem="leader" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="publicly" lemma="publicly" stem="publicli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="repudiated" lemma="repudiate" stem="repudi" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (NP (NNP Mr.) (NNP Gates) (POS 's)) (JJ military) (NN style)) (PP (IN of) (S (VP (VBG policing))))) (VP (VBZ is) (PP (IN at) (NP (NP (NNS odds)) (PP (IN with) (NP (NP (DT that)) (PP (IN in) (NP (NP (DT the) (NN rest)) (PP (IN of) (NP (DT the) (NN country))))))))))) (, ,) (CC and) (S (NP (PRP it)) (VP (VBZ 's) (SBAR (IN about) (S (NP (NN time) (NN police) (NNS leaders)) (ADVP (RB publicly)) (VP (VBD repudiated) (NP (PRP it))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the rest" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="rest" />
          </tokens>
        </chunking>
        <chunking id="2" string="time police leaders" type="NP">
          <tokens>
            <token id="24" string="time" />
            <token id="25" string="police" />
            <token id="26" string="leaders" />
          </tokens>
        </chunking>
        <chunking id="3" string="policing" type="VP">
          <tokens>
            <token id="7" string="policing" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="21" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="repudiated it" type="VP">
          <tokens>
            <token id="28" string="repudiated" />
            <token id="29" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="odds with that in the rest of the country" type="NP">
          <tokens>
            <token id="10" string="odds" />
            <token id="11" string="with" />
            <token id="12" string="that" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="rest" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="country" />
          </tokens>
        </chunking>
        <chunking id="7" string="'s about time police leaders publicly repudiated it" type="VP">
          <tokens>
            <token id="22" string="'s" />
            <token id="23" string="about" />
            <token id="24" string="time" />
            <token id="25" string="police" />
            <token id="26" string="leaders" />
            <token id="27" string="publicly" />
            <token id="28" string="repudiated" />
            <token id="29" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="odds" type="NP">
          <tokens>
            <token id="10" string="odds" />
          </tokens>
        </chunking>
        <chunking id="9" string="that" type="NP">
          <tokens>
            <token id="12" string="that" />
          </tokens>
        </chunking>
        <chunking id="10" string="the rest of the country" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="rest" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="country" />
          </tokens>
        </chunking>
        <chunking id="11" string="about time police leaders publicly repudiated it" type="SBAR">
          <tokens>
            <token id="23" string="about" />
            <token id="24" string="time" />
            <token id="25" string="police" />
            <token id="26" string="leaders" />
            <token id="27" string="publicly" />
            <token id="28" string="repudiated" />
            <token id="29" string="it" />
          </tokens>
        </chunking>
        <chunking id="12" string="Mr. Gates 's military style of policing" type="NP">
          <tokens>
            <token id="1" string="Mr." />
            <token id="2" string="Gates" />
            <token id="3" string="'s" />
            <token id="4" string="military" />
            <token id="5" string="style" />
            <token id="6" string="of" />
            <token id="7" string="policing" />
          </tokens>
        </chunking>
        <chunking id="13" string="the country" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="country" />
          </tokens>
        </chunking>
        <chunking id="14" string="Mr. Gates 's" type="NP">
          <tokens>
            <token id="1" string="Mr." />
            <token id="2" string="Gates" />
            <token id="3" string="'s" />
          </tokens>
        </chunking>
        <chunking id="15" string="that in the rest of the country" type="NP">
          <tokens>
            <token id="12" string="that" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="rest" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="country" />
          </tokens>
        </chunking>
        <chunking id="16" string="Mr. Gates 's military style" type="NP">
          <tokens>
            <token id="1" string="Mr." />
            <token id="2" string="Gates" />
            <token id="3" string="'s" />
            <token id="4" string="military" />
            <token id="5" string="style" />
          </tokens>
        </chunking>
        <chunking id="17" string="is at odds with that in the rest of the country" type="VP">
          <tokens>
            <token id="8" string="is" />
            <token id="9" string="at" />
            <token id="10" string="odds" />
            <token id="11" string="with" />
            <token id="12" string="that" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="rest" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="country" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Gates</governor>
          <dependent id="1">Mr.</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">style</governor>
          <dependent id="2">Gates</dependent>
        </dependency>
        <dependency type="case">
          <governor id="2">Gates</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">style</governor>
          <dependent id="4">military</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">odds</governor>
          <dependent id="5">style</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">policing</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="5">style</governor>
          <dependent id="7">policing</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="10">odds</governor>
          <dependent id="8">is</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">odds</governor>
          <dependent id="9">at</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">odds</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">that</governor>
          <dependent id="11">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">odds</governor>
          <dependent id="12">that</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">rest</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">rest</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">that</governor>
          <dependent id="15">rest</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">country</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">country</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">rest</governor>
          <dependent id="18">country</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">odds</governor>
          <dependent id="20">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">'s</governor>
          <dependent id="21">it</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">odds</governor>
          <dependent id="22">'s</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="28">repudiated</governor>
          <dependent id="23">about</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">leaders</governor>
          <dependent id="24">time</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">leaders</governor>
          <dependent id="25">police</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">repudiated</governor>
          <dependent id="26">leaders</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="28">repudiated</governor>
          <dependent id="27">publicly</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="22">'s</governor>
          <dependent id="28">repudiated</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="28">repudiated</governor>
          <dependent id="29">it</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Gates" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Gates" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="45" has_coreference="false">
      <content>It is hard to see how the Los Angeles Police Department can regain credibility unless Daryl Gates&amp;apost;s leave becomes permanent.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="hard" lemma="hard" stem="hard" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="see" lemma="see" stem="see" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="how" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Los" lemma="Los" stem="lo" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="9" string="Angeles" lemma="Angeles" stem="angele" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="10" string="Police" lemma="Police" stem="polic" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="11" string="Department" lemma="Department" stem="depart" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="12" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="regain" lemma="regain" stem="regain" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="credibility" lemma="credibility" stem="credibl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="unless" lemma="unless" stem="unless" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="Daryl" lemma="Daryl" stem="daryl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="17" string="Gates" lemma="Gates" stem="gate" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="18" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="leave" lemma="leave" stem="leav" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="becomes" lemma="become" stem="becom" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="permanent" lemma="permanent" stem="perman" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBZ is) (ADJP (JJ hard) (S (VP (TO to) (VP (VB see) (SBAR (WHADVP (WRB how)) (S (NP (DT the) (NNP Los) (NNP Angeles) (NNP Police) (NNP Department)) (VP (MD can) (VP (VB regain) (NP (NN credibility)) (SBAR (IN unless) (S (NP (NP (NNP Daryl) (NNP Gates) (POS 's)) (NN leave)) (VP (VBZ becomes) (ADJP (JJ permanent)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="becomes permanent" type="VP">
          <tokens>
            <token id="20" string="becomes" />
            <token id="21" string="permanent" />
          </tokens>
        </chunking>
        <chunking id="2" string="to see how the Los Angeles Police Department can regain credibility unless Daryl Gates 's leave becomes permanent" type="VP">
          <tokens>
            <token id="4" string="to" />
            <token id="5" string="see" />
            <token id="6" string="how" />
            <token id="7" string="the" />
            <token id="8" string="Los" />
            <token id="9" string="Angeles" />
            <token id="10" string="Police" />
            <token id="11" string="Department" />
            <token id="12" string="can" />
            <token id="13" string="regain" />
            <token id="14" string="credibility" />
            <token id="15" string="unless" />
            <token id="16" string="Daryl" />
            <token id="17" string="Gates" />
            <token id="18" string="'s" />
            <token id="19" string="leave" />
            <token id="20" string="becomes" />
            <token id="21" string="permanent" />
          </tokens>
        </chunking>
        <chunking id="3" string="Daryl Gates 's" type="NP">
          <tokens>
            <token id="16" string="Daryl" />
            <token id="17" string="Gates" />
            <token id="18" string="'s" />
          </tokens>
        </chunking>
        <chunking id="4" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="5" string="how" type="WHADVP">
          <tokens>
            <token id="6" string="how" />
          </tokens>
        </chunking>
        <chunking id="6" string="regain credibility unless Daryl Gates 's leave becomes permanent" type="VP">
          <tokens>
            <token id="13" string="regain" />
            <token id="14" string="credibility" />
            <token id="15" string="unless" />
            <token id="16" string="Daryl" />
            <token id="17" string="Gates" />
            <token id="18" string="'s" />
            <token id="19" string="leave" />
            <token id="20" string="becomes" />
            <token id="21" string="permanent" />
          </tokens>
        </chunking>
        <chunking id="7" string="unless Daryl Gates 's leave becomes permanent" type="SBAR">
          <tokens>
            <token id="15" string="unless" />
            <token id="16" string="Daryl" />
            <token id="17" string="Gates" />
            <token id="18" string="'s" />
            <token id="19" string="leave" />
            <token id="20" string="becomes" />
            <token id="21" string="permanent" />
          </tokens>
        </chunking>
        <chunking id="8" string="hard to see how the Los Angeles Police Department can regain credibility unless Daryl Gates 's leave becomes permanent" type="ADJP">
          <tokens>
            <token id="3" string="hard" />
            <token id="4" string="to" />
            <token id="5" string="see" />
            <token id="6" string="how" />
            <token id="7" string="the" />
            <token id="8" string="Los" />
            <token id="9" string="Angeles" />
            <token id="10" string="Police" />
            <token id="11" string="Department" />
            <token id="12" string="can" />
            <token id="13" string="regain" />
            <token id="14" string="credibility" />
            <token id="15" string="unless" />
            <token id="16" string="Daryl" />
            <token id="17" string="Gates" />
            <token id="18" string="'s" />
            <token id="19" string="leave" />
            <token id="20" string="becomes" />
            <token id="21" string="permanent" />
          </tokens>
        </chunking>
        <chunking id="9" string="can regain credibility unless Daryl Gates 's leave becomes permanent" type="VP">
          <tokens>
            <token id="12" string="can" />
            <token id="13" string="regain" />
            <token id="14" string="credibility" />
            <token id="15" string="unless" />
            <token id="16" string="Daryl" />
            <token id="17" string="Gates" />
            <token id="18" string="'s" />
            <token id="19" string="leave" />
            <token id="20" string="becomes" />
            <token id="21" string="permanent" />
          </tokens>
        </chunking>
        <chunking id="10" string="is hard to see how the Los Angeles Police Department can regain credibility unless Daryl Gates 's leave becomes permanent" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="hard" />
            <token id="4" string="to" />
            <token id="5" string="see" />
            <token id="6" string="how" />
            <token id="7" string="the" />
            <token id="8" string="Los" />
            <token id="9" string="Angeles" />
            <token id="10" string="Police" />
            <token id="11" string="Department" />
            <token id="12" string="can" />
            <token id="13" string="regain" />
            <token id="14" string="credibility" />
            <token id="15" string="unless" />
            <token id="16" string="Daryl" />
            <token id="17" string="Gates" />
            <token id="18" string="'s" />
            <token id="19" string="leave" />
            <token id="20" string="becomes" />
            <token id="21" string="permanent" />
          </tokens>
        </chunking>
        <chunking id="11" string="Daryl Gates 's leave" type="NP">
          <tokens>
            <token id="16" string="Daryl" />
            <token id="17" string="Gates" />
            <token id="18" string="'s" />
            <token id="19" string="leave" />
          </tokens>
        </chunking>
        <chunking id="12" string="permanent" type="ADJP">
          <tokens>
            <token id="21" string="permanent" />
          </tokens>
        </chunking>
        <chunking id="13" string="see how the Los Angeles Police Department can regain credibility unless Daryl Gates 's leave becomes permanent" type="VP">
          <tokens>
            <token id="5" string="see" />
            <token id="6" string="how" />
            <token id="7" string="the" />
            <token id="8" string="Los" />
            <token id="9" string="Angeles" />
            <token id="10" string="Police" />
            <token id="11" string="Department" />
            <token id="12" string="can" />
            <token id="13" string="regain" />
            <token id="14" string="credibility" />
            <token id="15" string="unless" />
            <token id="16" string="Daryl" />
            <token id="17" string="Gates" />
            <token id="18" string="'s" />
            <token id="19" string="leave" />
            <token id="20" string="becomes" />
            <token id="21" string="permanent" />
          </tokens>
        </chunking>
        <chunking id="14" string="the Los Angeles Police Department" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="Los" />
            <token id="9" string="Angeles" />
            <token id="10" string="Police" />
            <token id="11" string="Department" />
          </tokens>
        </chunking>
        <chunking id="15" string="how the Los Angeles Police Department can regain credibility unless Daryl Gates 's leave becomes permanent" type="SBAR">
          <tokens>
            <token id="6" string="how" />
            <token id="7" string="the" />
            <token id="8" string="Los" />
            <token id="9" string="Angeles" />
            <token id="10" string="Police" />
            <token id="11" string="Department" />
            <token id="12" string="can" />
            <token id="13" string="regain" />
            <token id="14" string="credibility" />
            <token id="15" string="unless" />
            <token id="16" string="Daryl" />
            <token id="17" string="Gates" />
            <token id="18" string="'s" />
            <token id="19" string="leave" />
            <token id="20" string="becomes" />
            <token id="21" string="permanent" />
          </tokens>
        </chunking>
        <chunking id="16" string="credibility" type="NP">
          <tokens>
            <token id="14" string="credibility" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">hard</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="3">hard</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">hard</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">see</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">hard</governor>
          <dependent id="5">see</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">regain</governor>
          <dependent id="6">how</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">Department</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Department</governor>
          <dependent id="8">Los</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Department</governor>
          <dependent id="9">Angeles</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Department</governor>
          <dependent id="10">Police</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">regain</governor>
          <dependent id="11">Department</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">regain</governor>
          <dependent id="12">can</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">see</governor>
          <dependent id="13">regain</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">regain</governor>
          <dependent id="14">credibility</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">becomes</governor>
          <dependent id="15">unless</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Gates</governor>
          <dependent id="16">Daryl</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">leave</governor>
          <dependent id="17">Gates</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">Gates</governor>
          <dependent id="18">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">becomes</governor>
          <dependent id="19">leave</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="13">regain</governor>
          <dependent id="20">becomes</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="20">becomes</governor>
          <dependent id="21">permanent</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Daryl Gates" type="PERSON" score="0.0">
          <tokens>
            <token id="16" string="Daryl" />
            <token id="17" string="Gates" />
          </tokens>
        </entity>
        <entity id="2" string="Los Angeles Police Department" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="8" string="Los" />
            <token id="9" string="Angeles" />
            <token id="10" string="Police" />
            <token id="11" string="Department" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="46" has_coreference="true">
      <content>But the videotape of the LAPD brutality affects the credibility of all police officers.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="videotape" lemma="videotape" stem="videotap" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="LAPD" lemma="lapd" stem="lapd" pos="NN" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="7" string="brutality" lemma="brutality" stem="brutal" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="affects" lemma="affect" stem="affect" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="credibility" lemma="credibility" stem="credibl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="police" lemma="police" stem="polic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (NP (DT the) (NN videotape)) (PP (IN of) (NP (DT the) (NN LAPD) (NN brutality)))) (VP (VBZ affects) (NP (NP (DT the) (NN credibility)) (PP (IN of) (NP (DT all) (NNS police) (NNS officers))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the credibility of all police officers" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="credibility" />
            <token id="11" string="of" />
            <token id="12" string="all" />
            <token id="13" string="police" />
            <token id="14" string="officers" />
          </tokens>
        </chunking>
        <chunking id="2" string="all police officers" type="NP">
          <tokens>
            <token id="12" string="all" />
            <token id="13" string="police" />
            <token id="14" string="officers" />
          </tokens>
        </chunking>
        <chunking id="3" string="the videotape" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="videotape" />
          </tokens>
        </chunking>
        <chunking id="4" string="affects the credibility of all police officers" type="VP">
          <tokens>
            <token id="8" string="affects" />
            <token id="9" string="the" />
            <token id="10" string="credibility" />
            <token id="11" string="of" />
            <token id="12" string="all" />
            <token id="13" string="police" />
            <token id="14" string="officers" />
          </tokens>
        </chunking>
        <chunking id="5" string="the LAPD brutality" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="LAPD" />
            <token id="7" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="6" string="the videotape of the LAPD brutality" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="videotape" />
            <token id="4" string="of" />
            <token id="5" string="the" />
            <token id="6" string="LAPD" />
            <token id="7" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="7" string="the credibility" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="credibility" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="8">affects</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">videotape</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">affects</governor>
          <dependent id="3">videotape</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">brutality</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">brutality</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">brutality</governor>
          <dependent id="6">LAPD</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">videotape</governor>
          <dependent id="7">brutality</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">affects</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">credibility</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">affects</governor>
          <dependent id="10">credibility</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">officers</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">officers</governor>
          <dependent id="12">all</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">officers</governor>
          <dependent id="13">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">credibility</governor>
          <dependent id="14">officers</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="LAPD" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="6" string="LAPD" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="47" has_coreference="true">
      <content>It has cast a cloud over policing that won&amp;apost;t be lifted until police chiefs drop their own code of silence and speak out against one of their own&amp;apost;s peculiar philosophy of policing.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="cast" lemma="cast" stem="cast" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="cloud" lemma="cloud" stem="cloud" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="policing" lemma="police" stem="polic" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="wo" lemma="will" stem="wo" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="lifted" lemma="lift" stem="lift" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="until" lemma="until" stem="until" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="chiefs" lemma="chief" stem="chief" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="drop" lemma="drop" stem="drop" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="own" lemma="own" stem="own" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="code" lemma="code" stem="code" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="silence" lemma="silence" stem="silenc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="speak" lemma="speak" stem="speak" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="out" lemma="out" stem="out" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="27" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="own" lemma="own" stem="own" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="peculiar" lemma="peculiar" stem="peculiar" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="philosophy" lemma="philosophy" stem="philosophi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="policing" lemma="police" stem="polic" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBZ has) (VP (VBN cast) (NP (DT a) (NN cloud)) (PP (IN over) (S (VP (VBG policing) (SBAR (S (NP (DT that)) (VP (MD wo) (RB n't) (VP (VP (VB be) (VP (VBN lifted) (SBAR (IN until) (S (NP (NN police) (NNS chiefs)) (VP (VBP drop) (NP (NP (PRP$ their) (JJ own) (NN code)) (PP (IN of) (NP (NN silence))))))))) (CC and) (VP (VB speak) (PRT (IN out)) (PP (IN against) (NP (NP (NP (NP (CD one)) (PP (IN of) (NP (PRP$ their) (JJ own))) (POS 's)) (JJ peculiar) (NN philosophy)) (PP (IN of) (S (VP (VBG policing)))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="drop their own code of silence" type="VP">
          <tokens>
            <token id="16" string="drop" />
            <token id="17" string="their" />
            <token id="18" string="own" />
            <token id="19" string="code" />
            <token id="20" string="of" />
            <token id="21" string="silence" />
          </tokens>
        </chunking>
        <chunking id="2" string="one of their own 's" type="NP">
          <tokens>
            <token id="26" string="one" />
            <token id="27" string="of" />
            <token id="28" string="their" />
            <token id="29" string="own" />
            <token id="30" string="'s" />
          </tokens>
        </chunking>
        <chunking id="3" string="has cast a cloud over policing that wo n't be lifted until police chiefs drop their own code of silence and speak out against one of their own 's peculiar philosophy of policing" type="VP">
          <tokens>
            <token id="2" string="has" />
            <token id="3" string="cast" />
            <token id="4" string="a" />
            <token id="5" string="cloud" />
            <token id="6" string="over" />
            <token id="7" string="policing" />
            <token id="8" string="that" />
            <token id="9" string="wo" />
            <token id="10" string="n't" />
            <token id="11" string="be" />
            <token id="12" string="lifted" />
            <token id="13" string="until" />
            <token id="14" string="police" />
            <token id="15" string="chiefs" />
            <token id="16" string="drop" />
            <token id="17" string="their" />
            <token id="18" string="own" />
            <token id="19" string="code" />
            <token id="20" string="of" />
            <token id="21" string="silence" />
            <token id="22" string="and" />
            <token id="23" string="speak" />
            <token id="24" string="out" />
            <token id="25" string="against" />
            <token id="26" string="one" />
            <token id="27" string="of" />
            <token id="28" string="their" />
            <token id="29" string="own" />
            <token id="30" string="'s" />
            <token id="31" string="peculiar" />
            <token id="32" string="philosophy" />
            <token id="33" string="of" />
            <token id="34" string="policing" />
          </tokens>
        </chunking>
        <chunking id="4" string="their own code" type="NP">
          <tokens>
            <token id="17" string="their" />
            <token id="18" string="own" />
            <token id="19" string="code" />
          </tokens>
        </chunking>
        <chunking id="5" string="policing" type="VP">
          <tokens>
            <token id="34" string="policing" />
          </tokens>
        </chunking>
        <chunking id="6" string="lifted until police chiefs drop their own code of silence" type="VP">
          <tokens>
            <token id="12" string="lifted" />
            <token id="13" string="until" />
            <token id="14" string="police" />
            <token id="15" string="chiefs" />
            <token id="16" string="drop" />
            <token id="17" string="their" />
            <token id="18" string="own" />
            <token id="19" string="code" />
            <token id="20" string="of" />
            <token id="21" string="silence" />
          </tokens>
        </chunking>
        <chunking id="7" string="that wo n't be lifted until police chiefs drop their own code of silence and speak out against one of their own 's peculiar philosophy of policing" type="SBAR">
          <tokens>
            <token id="8" string="that" />
            <token id="9" string="wo" />
            <token id="10" string="n't" />
            <token id="11" string="be" />
            <token id="12" string="lifted" />
            <token id="13" string="until" />
            <token id="14" string="police" />
            <token id="15" string="chiefs" />
            <token id="16" string="drop" />
            <token id="17" string="their" />
            <token id="18" string="own" />
            <token id="19" string="code" />
            <token id="20" string="of" />
            <token id="21" string="silence" />
            <token id="22" string="and" />
            <token id="23" string="speak" />
            <token id="24" string="out" />
            <token id="25" string="against" />
            <token id="26" string="one" />
            <token id="27" string="of" />
            <token id="28" string="their" />
            <token id="29" string="own" />
            <token id="30" string="'s" />
            <token id="31" string="peculiar" />
            <token id="32" string="philosophy" />
            <token id="33" string="of" />
            <token id="34" string="policing" />
          </tokens>
        </chunking>
        <chunking id="8" string="their own code of silence" type="NP">
          <tokens>
            <token id="17" string="their" />
            <token id="18" string="own" />
            <token id="19" string="code" />
            <token id="20" string="of" />
            <token id="21" string="silence" />
          </tokens>
        </chunking>
        <chunking id="9" string="one" type="NP">
          <tokens>
            <token id="26" string="one" />
          </tokens>
        </chunking>
        <chunking id="10" string="until police chiefs drop their own code of silence" type="SBAR">
          <tokens>
            <token id="13" string="until" />
            <token id="14" string="police" />
            <token id="15" string="chiefs" />
            <token id="16" string="drop" />
            <token id="17" string="their" />
            <token id="18" string="own" />
            <token id="19" string="code" />
            <token id="20" string="of" />
            <token id="21" string="silence" />
          </tokens>
        </chunking>
        <chunking id="11" string="wo n't be lifted until police chiefs drop their own code of silence and speak out against one of their own 's peculiar philosophy of policing" type="VP">
          <tokens>
            <token id="9" string="wo" />
            <token id="10" string="n't" />
            <token id="11" string="be" />
            <token id="12" string="lifted" />
            <token id="13" string="until" />
            <token id="14" string="police" />
            <token id="15" string="chiefs" />
            <token id="16" string="drop" />
            <token id="17" string="their" />
            <token id="18" string="own" />
            <token id="19" string="code" />
            <token id="20" string="of" />
            <token id="21" string="silence" />
            <token id="22" string="and" />
            <token id="23" string="speak" />
            <token id="24" string="out" />
            <token id="25" string="against" />
            <token id="26" string="one" />
            <token id="27" string="of" />
            <token id="28" string="their" />
            <token id="29" string="own" />
            <token id="30" string="'s" />
            <token id="31" string="peculiar" />
            <token id="32" string="philosophy" />
            <token id="33" string="of" />
            <token id="34" string="policing" />
          </tokens>
        </chunking>
        <chunking id="12" string="a cloud" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="cloud" />
          </tokens>
        </chunking>
        <chunking id="13" string="be lifted until police chiefs drop their own code of silence and speak out against one of their own 's peculiar philosophy of policing" type="VP">
          <tokens>
            <token id="11" string="be" />
            <token id="12" string="lifted" />
            <token id="13" string="until" />
            <token id="14" string="police" />
            <token id="15" string="chiefs" />
            <token id="16" string="drop" />
            <token id="17" string="their" />
            <token id="18" string="own" />
            <token id="19" string="code" />
            <token id="20" string="of" />
            <token id="21" string="silence" />
            <token id="22" string="and" />
            <token id="23" string="speak" />
            <token id="24" string="out" />
            <token id="25" string="against" />
            <token id="26" string="one" />
            <token id="27" string="of" />
            <token id="28" string="their" />
            <token id="29" string="own" />
            <token id="30" string="'s" />
            <token id="31" string="peculiar" />
            <token id="32" string="philosophy" />
            <token id="33" string="of" />
            <token id="34" string="policing" />
          </tokens>
        </chunking>
        <chunking id="14" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="15" string="one of their own 's peculiar philosophy" type="NP">
          <tokens>
            <token id="26" string="one" />
            <token id="27" string="of" />
            <token id="28" string="their" />
            <token id="29" string="own" />
            <token id="30" string="'s" />
            <token id="31" string="peculiar" />
            <token id="32" string="philosophy" />
          </tokens>
        </chunking>
        <chunking id="16" string="their own" type="NP">
          <tokens>
            <token id="28" string="their" />
            <token id="29" string="own" />
          </tokens>
        </chunking>
        <chunking id="17" string="police chiefs" type="NP">
          <tokens>
            <token id="14" string="police" />
            <token id="15" string="chiefs" />
          </tokens>
        </chunking>
        <chunking id="18" string="speak out against one of their own 's peculiar philosophy of policing" type="VP">
          <tokens>
            <token id="23" string="speak" />
            <token id="24" string="out" />
            <token id="25" string="against" />
            <token id="26" string="one" />
            <token id="27" string="of" />
            <token id="28" string="their" />
            <token id="29" string="own" />
            <token id="30" string="'s" />
            <token id="31" string="peculiar" />
            <token id="32" string="philosophy" />
            <token id="33" string="of" />
            <token id="34" string="policing" />
          </tokens>
        </chunking>
        <chunking id="19" string="that" type="NP">
          <tokens>
            <token id="8" string="that" />
          </tokens>
        </chunking>
        <chunking id="20" string="be lifted until police chiefs drop their own code of silence" type="VP">
          <tokens>
            <token id="11" string="be" />
            <token id="12" string="lifted" />
            <token id="13" string="until" />
            <token id="14" string="police" />
            <token id="15" string="chiefs" />
            <token id="16" string="drop" />
            <token id="17" string="their" />
            <token id="18" string="own" />
            <token id="19" string="code" />
            <token id="20" string="of" />
            <token id="21" string="silence" />
          </tokens>
        </chunking>
        <chunking id="21" string="cast a cloud over policing that wo n't be lifted until police chiefs drop their own code of silence and speak out against one of their own 's peculiar philosophy of policing" type="VP">
          <tokens>
            <token id="3" string="cast" />
            <token id="4" string="a" />
            <token id="5" string="cloud" />
            <token id="6" string="over" />
            <token id="7" string="policing" />
            <token id="8" string="that" />
            <token id="9" string="wo" />
            <token id="10" string="n't" />
            <token id="11" string="be" />
            <token id="12" string="lifted" />
            <token id="13" string="until" />
            <token id="14" string="police" />
            <token id="15" string="chiefs" />
            <token id="16" string="drop" />
            <token id="17" string="their" />
            <token id="18" string="own" />
            <token id="19" string="code" />
            <token id="20" string="of" />
            <token id="21" string="silence" />
            <token id="22" string="and" />
            <token id="23" string="speak" />
            <token id="24" string="out" />
            <token id="25" string="against" />
            <token id="26" string="one" />
            <token id="27" string="of" />
            <token id="28" string="their" />
            <token id="29" string="own" />
            <token id="30" string="'s" />
            <token id="31" string="peculiar" />
            <token id="32" string="philosophy" />
            <token id="33" string="of" />
            <token id="34" string="policing" />
          </tokens>
        </chunking>
        <chunking id="22" string="silence" type="NP">
          <tokens>
            <token id="21" string="silence" />
          </tokens>
        </chunking>
        <chunking id="23" string="one of their own 's peculiar philosophy of policing" type="NP">
          <tokens>
            <token id="26" string="one" />
            <token id="27" string="of" />
            <token id="28" string="their" />
            <token id="29" string="own" />
            <token id="30" string="'s" />
            <token id="31" string="peculiar" />
            <token id="32" string="philosophy" />
            <token id="33" string="of" />
            <token id="34" string="policing" />
          </tokens>
        </chunking>
        <chunking id="24" string="policing that wo n't be lifted until police chiefs drop their own code of silence and speak out against one of their own 's peculiar philosophy of policing" type="VP">
          <tokens>
            <token id="7" string="policing" />
            <token id="8" string="that" />
            <token id="9" string="wo" />
            <token id="10" string="n't" />
            <token id="11" string="be" />
            <token id="12" string="lifted" />
            <token id="13" string="until" />
            <token id="14" string="police" />
            <token id="15" string="chiefs" />
            <token id="16" string="drop" />
            <token id="17" string="their" />
            <token id="18" string="own" />
            <token id="19" string="code" />
            <token id="20" string="of" />
            <token id="21" string="silence" />
            <token id="22" string="and" />
            <token id="23" string="speak" />
            <token id="24" string="out" />
            <token id="25" string="against" />
            <token id="26" string="one" />
            <token id="27" string="of" />
            <token id="28" string="their" />
            <token id="29" string="own" />
            <token id="30" string="'s" />
            <token id="31" string="peculiar" />
            <token id="32" string="philosophy" />
            <token id="33" string="of" />
            <token id="34" string="policing" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">cast</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">cast</governor>
          <dependent id="2">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">cast</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">cloud</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">cast</governor>
          <dependent id="5">cloud</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">policing</governor>
          <dependent id="6">over</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">cast</governor>
          <dependent id="7">policing</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="12">lifted</governor>
          <dependent id="8">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">lifted</governor>
          <dependent id="9">wo</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="12">lifted</governor>
          <dependent id="10">n't</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="12">lifted</governor>
          <dependent id="11">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">policing</governor>
          <dependent id="12">lifted</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">drop</governor>
          <dependent id="13">until</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">chiefs</governor>
          <dependent id="14">police</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">drop</governor>
          <dependent id="15">chiefs</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">lifted</governor>
          <dependent id="16">drop</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">code</governor>
          <dependent id="17">their</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">code</governor>
          <dependent id="18">own</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">drop</governor>
          <dependent id="19">code</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">silence</governor>
          <dependent id="20">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">code</governor>
          <dependent id="21">silence</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">lifted</governor>
          <dependent id="22">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">lifted</governor>
          <dependent id="23">speak</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="23">speak</governor>
          <dependent id="24">out</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">philosophy</governor>
          <dependent id="25">against</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="32">philosophy</governor>
          <dependent id="26">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">own</governor>
          <dependent id="27">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="29">own</governor>
          <dependent id="28">their</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">one</governor>
          <dependent id="29">own</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">one</governor>
          <dependent id="30">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="32">philosophy</governor>
          <dependent id="31">peculiar</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">speak</governor>
          <dependent id="32">philosophy</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="34">policing</governor>
          <dependent id="33">of</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="32">philosophy</governor>
          <dependent id="34">policing</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="26" string="one" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="48" has_coreference="true">
      <content>--- Mr. McNamara is the police chief in San Jose.</content>
      <tokens>
        <token id="1" string="---" lemma="--" stem="---" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="McNamara" lemma="McNamara" stem="mcnamara" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="chief" lemma="chief" stem="chief" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="San" lemma="San" stem="san" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="10" string="Jose" lemma="Jose" stem="jose" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: --) (NP (NNP Mr.) (NNP McNamara)) (VP (VBZ is) (NP (NP (DT the) (NN police) (NN chief)) (PP (IN in) (NP (NNP San) (NNP Jose))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the police chief" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="police" />
            <token id="7" string="chief" />
          </tokens>
        </chunking>
        <chunking id="2" string="is the police chief in San Jose" type="VP">
          <tokens>
            <token id="4" string="is" />
            <token id="5" string="the" />
            <token id="6" string="police" />
            <token id="7" string="chief" />
            <token id="8" string="in" />
            <token id="9" string="San" />
            <token id="10" string="Jose" />
          </tokens>
        </chunking>
        <chunking id="3" string="the police chief in San Jose" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="police" />
            <token id="7" string="chief" />
            <token id="8" string="in" />
            <token id="9" string="San" />
            <token id="10" string="Jose" />
          </tokens>
        </chunking>
        <chunking id="4" string="Mr. McNamara" type="NP">
          <tokens>
            <token id="2" string="Mr." />
            <token id="3" string="McNamara" />
          </tokens>
        </chunking>
        <chunking id="5" string="San Jose" type="NP">
          <tokens>
            <token id="9" string="San" />
            <token id="10" string="Jose" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">McNamara</governor>
          <dependent id="2">Mr.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">chief</governor>
          <dependent id="3">McNamara</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">chief</governor>
          <dependent id="4">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">chief</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">chief</governor>
          <dependent id="6">police</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">chief</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Jose</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Jose</governor>
          <dependent id="9">San</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">chief</governor>
          <dependent id="10">Jose</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="McNamara" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="McNamara" />
          </tokens>
        </entity>
        <entity id="2" string="San Jose" type="LOCATION" score="0.0">
          <tokens>
            <token id="9" string="San" />
            <token id="10" string="Jose" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="49" has_coreference="true">
      <content>He comes from a family of policemen and has been one for 35 years.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="comes" lemma="come" stem="come" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="family" lemma="family" stem="famili" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="policemen" lemma="policeman" stem="policemen" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="12" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="35" lemma="35" stem="35" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="14" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VP (VBZ comes) (PP (IN from) (NP (NP (DT a) (NN family)) (PP (IN of) (NP (NNS policemen)))))) (CC and) (VP (VBZ has) (VP (VBN been) (NP (NP (CD one)) (PP (IN for) (NP (CD 35) (NNS years))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="has been one for 35 years" type="VP">
          <tokens>
            <token id="9" string="has" />
            <token id="10" string="been" />
            <token id="11" string="one" />
            <token id="12" string="for" />
            <token id="13" string="35" />
            <token id="14" string="years" />
          </tokens>
        </chunking>
        <chunking id="2" string="comes from a family of policemen and has been one for 35 years" type="VP">
          <tokens>
            <token id="2" string="comes" />
            <token id="3" string="from" />
            <token id="4" string="a" />
            <token id="5" string="family" />
            <token id="6" string="of" />
            <token id="7" string="policemen" />
            <token id="8" string="and" />
            <token id="9" string="has" />
            <token id="10" string="been" />
            <token id="11" string="one" />
            <token id="12" string="for" />
            <token id="13" string="35" />
            <token id="14" string="years" />
          </tokens>
        </chunking>
        <chunking id="3" string="comes from a family of policemen" type="VP">
          <tokens>
            <token id="2" string="comes" />
            <token id="3" string="from" />
            <token id="4" string="a" />
            <token id="5" string="family" />
            <token id="6" string="of" />
            <token id="7" string="policemen" />
          </tokens>
        </chunking>
        <chunking id="4" string="a family" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="family" />
          </tokens>
        </chunking>
        <chunking id="5" string="policemen" type="NP">
          <tokens>
            <token id="7" string="policemen" />
          </tokens>
        </chunking>
        <chunking id="6" string="one" type="NP">
          <tokens>
            <token id="11" string="one" />
          </tokens>
        </chunking>
        <chunking id="7" string="a family of policemen" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="family" />
            <token id="6" string="of" />
            <token id="7" string="policemen" />
          </tokens>
        </chunking>
        <chunking id="8" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="9" string="been one for 35 years" type="VP">
          <tokens>
            <token id="10" string="been" />
            <token id="11" string="one" />
            <token id="12" string="for" />
            <token id="13" string="35" />
            <token id="14" string="years" />
          </tokens>
        </chunking>
        <chunking id="10" string="one for 35 years" type="NP">
          <tokens>
            <token id="11" string="one" />
            <token id="12" string="for" />
            <token id="13" string="35" />
            <token id="14" string="years" />
          </tokens>
        </chunking>
        <chunking id="11" string="35 years" type="NP">
          <tokens>
            <token id="13" string="35" />
            <token id="14" string="years" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">comes</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">comes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">family</governor>
          <dependent id="3">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">family</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">comes</governor>
          <dependent id="5">family</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">policemen</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">family</governor>
          <dependent id="7">policemen</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">comes</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">one</governor>
          <dependent id="9">has</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">one</governor>
          <dependent id="10">been</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">comes</governor>
          <dependent id="11">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">years</governor>
          <dependent id="12">for</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="14">years</governor>
          <dependent id="13">35</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">one</governor>
          <dependent id="14">years</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="11" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="35 years" type="DURATION" score="0.0">
          <tokens>
            <token id="13" string="35" />
            <token id="14" string="years" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="5" string="Chief" id_sentence="3" />
      <mentions>
        <mention ids_tokens="1-3" string="A police chief" id_sentence="1" />
        <mention ids_tokens="14" string="his" id_sentence="1" />
      </mentions>
    </coreference>
    <coreference id="2" type="NOMINAL">
      <referenced ids_tokens="14-15" string="his department" id_sentence="1" />
      <mentions>
        <mention ids_tokens="31-32" string="the department" id_sentence="20" />
      </mentions>
    </coreference>
    <coreference id="3" type="PROPER">
      <referenced ids_tokens="4-5" string="Mr. Gates" id_sentence="2" />
      <mentions>
        <mention ids_tokens="15" string="his" id_sentence="8" />
        <mention ids_tokens="9" string="he" id_sentence="15" />
        <mention ids_tokens="8" string="his" id_sentence="16" />
        <mention ids_tokens="4" string="he" id_sentence="18" />
        <mention ids_tokens="1-3" string="Mr. Gates's" id_sentence="20" />
        <mention ids_tokens="18" string="his" id_sentence="20" />
        <mention ids_tokens="17" string="he" id_sentence="27" />
        <mention ids_tokens="1" string="He" id_sentence="29" />
        <mention ids_tokens="6" string="he" id_sentence="29" />
        <mention ids_tokens="2" string="his" id_sentence="30" />
        <mention ids_tokens="6" string="he" id_sentence="32" />
        <mention ids_tokens="10" string="he" id_sentence="32" />
        <mention ids_tokens="2-4" string="Mr. Gates's" id_sentence="37" />
        <mention ids_tokens="1" string="He" id_sentence="38" />
        <mention ids_tokens="4" string="he" id_sentence="38" />
        <mention ids_tokens="28" string="his" id_sentence="42" />
        <mention ids_tokens="2" string="he" id_sentence="43" />
        <mention ids_tokens="9" string="he" id_sentence="43" />
        <mention ids_tokens="11" string="his" id_sentence="43" />
        <mention ids_tokens="1-3" string="Mr. Gates's" id_sentence="44" />
      </mentions>
    </coreference>
    <coreference id="4" type="NOMINAL">
      <referenced ids_tokens="19-20" string="the community" id_sentence="4" />
      <mentions>
        <mention ids_tokens="18-32" string="community policing , in which officers work with citizens to improve neighborhoods and prevent crime" id_sentence="2" />
      </mentions>
    </coreference>
    <coreference id="7" type="NOMINAL">
      <referenced ids_tokens="9-10" string="gang members" id_sentence="3" />
      <mentions>
        <mention ids_tokens="8-9" string="its members" id_sentence="11" />
        <mention ids_tokens="13" string="professionals" id_sentence="11" />
      </mentions>
    </coreference>
    <coreference id="8" type="NOMINAL">
      <referenced ids_tokens="11-12-13-14-15-16-17-18-19-20" string="a police chief seeking to reduce conflict in the community" id_sentence="4" />
      <mentions>
        <mention ids_tokens="1-2" string="The chief" id_sentence="24" />
        <mention ids_tokens="3-4" string="the chief" id_sentence="33" />
        <mention ids_tokens="1" string="He" id_sentence="34" />
        <mention ids_tokens="18" string="his" id_sentence="34" />
        <mention ids_tokens="14-16" string="the chief's" id_sentence="36" />
      </mentions>
    </coreference>
    <coreference id="11" type="NOMINAL">
      <referenced ids_tokens="14-15-16-17" string="the city 's police" id_sentence="6" />
      <mentions>
        <mention ids_tokens="16-17" string="the police" id_sentence="40" />
      </mentions>
    </coreference>
    <coreference id="12" type="PROPER">
      <referenced ids_tokens="7-8-9-10" string="the Police Corps Program" id_sentence="9" />
      <mentions>
        <mention ids_tokens="1-3" string="The Police Corps" id_sentence="10" />
        <mention ids_tokens="4-6" string="the Police Corps" id_sentence="11" />
        <mention ids_tokens="8" string="its" id_sentence="11" />
      </mentions>
    </coreference>
    <coreference id="13" type="NOMINAL">
      <referenced ids_tokens="13-14-15" string="other police chiefs" id_sentence="9" />
      <mentions>
        <mention ids_tokens="14-15" string="police chiefs" id_sentence="47" />
        <mention ids_tokens="17" string="their" id_sentence="47" />
      </mentions>
    </coreference>
    <coreference id="15" type="PROPER">
      <referenced ids_tokens="18-19" string="Rodney King" id_sentence="12" />
      <mentions>
        <mention ids_tokens="10" string="King" id_sentence="30" />
        <mention ids_tokens="7-8" string="Mr. King" id_sentence="37" />
        <mention ids_tokens="10-11" string="Mr. King" id_sentence="38" />
        <mention ids_tokens="15" string="his" id_sentence="38" />
      </mentions>
    </coreference>
    <coreference id="16" type="NOMINAL">
      <referenced ids_tokens="17-18-19-20" string="the Rodney King beating" id_sentence="12" />
      <mentions>
        <mention ids_tokens="21-22" string="the beating" id_sentence="34" />
        <mention ids_tokens="7-8" string="the beating" id_sentence="40" />
        <mention ids_tokens="10-17" string="a warning against further run-ins with the police" id_sentence="40" />
      </mentions>
    </coreference>
    <coreference id="17" type="NOMINAL">
      <referenced ids_tokens="9" string="blacks" id_sentence="17" />
      <mentions>
        <mention ids_tokens="30" string="they" id_sentence="21" />
      </mentions>
    </coreference>
    <coreference id="18" type="NOMINAL">
      <referenced ids_tokens="15-16" string="normal people" id_sentence="17" />
      <mentions>
        <mention ids_tokens="11" string="people" id_sentence="42" />
        <mention ids_tokens="19" string="they" id_sentence="42" />
      </mentions>
    </coreference>
    <coreference id="19" type="NOMINAL">
      <referenced ids_tokens="1-2-3-4" string="Mr. Gates 's statement" id_sentence="20" />
      <mentions>
        <mention ids_tokens="2" string="it" id_sentence="21" />
      </mentions>
    </coreference>
    <coreference id="21" type="NOMINAL">
      <referenced ids_tokens="14-15-16-17-18-19-20-21-22-23" string="a special unit that had shot many criminals during stakeouts" id_sentence="22" />
      <mentions>
        <mention ids_tokens="1-2" string="The unit" id_sentence="23" />
        <mention ids_tokens="1-2" string="The unit" id_sentence="25" />
        <mention ids_tokens="11" string="its" id_sentence="25" />
      </mentions>
    </coreference>
    <coreference id="22" type="NOMINAL">
      <referenced ids_tokens="20-21" string="many criminals" id_sentence="22" />
      <mentions>
        <mention ids_tokens="6-7" string="the criminals" id_sentence="24" />
      </mentions>
    </coreference>
    <coreference id="23" type="NOMINAL">
      <referenced ids_tokens="9-10" string="the robberies" id_sentence="24" />
      <mentions>
        <mention ids_tokens="19" string="robberies" id_sentence="23" />
      </mentions>
    </coreference>
    <coreference id="26" type="NOMINAL">
      <referenced ids_tokens="2-3-4-5-6-7" string="condemnation of misconduct and excessive force" id_sentence="35" />
      <mentions>
        <mention ids_tokens="3" string="it" id_sentence="36" />
      </mentions>
    </coreference>
    <coreference id="30" type="NOMINAL">
      <referenced ids_tokens="2-3-4-5-6-7" string="the videotape of the LAPD brutality" id_sentence="46" />
      <mentions>
        <mention ids_tokens="1" string="It" id_sentence="47" />
      </mentions>
    </coreference>
    <coreference id="32" type="PROPER">
      <referenced ids_tokens="2-3" string="Mr. McNamara" id_sentence="48" />
      <mentions>
        <mention ids_tokens="1" string="He" id_sentence="49" />
      </mentions>
    </coreference>
  </coreferences>
</document>
