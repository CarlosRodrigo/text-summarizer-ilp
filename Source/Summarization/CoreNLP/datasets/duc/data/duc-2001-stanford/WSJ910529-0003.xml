<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="WSJ910529-0003">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>The lawsuit, which has been pending for nine months, arose out of two articles published by the Enquirer in June 1990 reporting on Miss Taylor&amp;apost;s condition and activities at St. John&amp;apost;s Hospital, Santa Monica, Calif., where she was treated last spring for pneumonia.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="lawsuit" lemma="lawsuit" stem="lawsuit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="pending" lemma="pend" stem="pend" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="nine" lemma="nine" stem="nine" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="10" string="months" lemma="month" stem="month" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="arose" lemma="arise" stem="aros" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="out" lemma="out" stem="out" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="16" string="articles" lemma="article" stem="articl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="published" lemma="publish" stem="publish" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Enquirer" lemma="Enquirer" stem="enquirer" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="21" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="June" lemma="June" stem="june" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="23" string="1990" lemma="1990" stem="1990" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="24" string="reporting" lemma="report" stem="report" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="Taylor" lemma="Taylor" stem="taylor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="28" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="29" string="condition" lemma="condition" stem="condit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="activities" lemma="activity" stem="activ" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="St." lemma="St." stem="st." pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="34" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="35" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="36" string="Hospital" lemma="Hospital" stem="hospit" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="37" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="Santa" lemma="Santa" stem="santa" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="39" string="Monica" lemma="Monica" stem="monica" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="40" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="Calif." lemma="Calif." stem="calif." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="42" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="treated" lemma="treat" stem="treat" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="47" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="48" string="spring" lemma="spring" stem="spring" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="49" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="50" string="pneumonia" lemma="pneumonia" stem="pneumonia" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="51" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NN lawsuit)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ has) (VP (VBN been) (VP (VBG pending) (PP (IN for) (NP (CD nine) (NNS months)))))))) (, ,)) (VP (VBD arose) (PRT (IN out)) (PP (IN of) (NP (NP (CD two) (NNS articles)) (VP (VBN published) (PP (IN by) (NP (DT the) (NNP Enquirer))) (PP (IN in) (NP (NP (NNP June) (CD 1990)) (VP (VBG reporting) (PP (IN on) (NP (NP (NNP Miss) (NNP Taylor) (POS 's)) (NN condition) (CC and) (NNS activities))) (PP (IN at) (NP (NP (NNP St.) (NNP John) (POS 's)) (NNP Hospital) (PRN (, ,) (NP (NNP Santa) (NNP Monica)) (, ,)) (NNP Calif.))) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (PRP she)) (VP (VBD was) (VP (VBN treated) (NP-TMP (JJ last) (NN spring)) (PP (IN for) (NP (NN pneumonia)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="two articles" type="NP">
          <tokens>
            <token id="15" string="two" />
            <token id="16" string="articles" />
          </tokens>
        </chunking>
        <chunking id="2" string="has been pending for nine months" type="VP">
          <tokens>
            <token id="5" string="has" />
            <token id="6" string="been" />
            <token id="7" string="pending" />
            <token id="8" string="for" />
            <token id="9" string="nine" />
            <token id="10" string="months" />
          </tokens>
        </chunking>
        <chunking id="3" string="The lawsuit , which has been pending for nine months ," type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="lawsuit" />
            <token id="3" string="," />
            <token id="4" string="which" />
            <token id="5" string="has" />
            <token id="6" string="been" />
            <token id="7" string="pending" />
            <token id="8" string="for" />
            <token id="9" string="nine" />
            <token id="10" string="months" />
            <token id="11" string="," />
          </tokens>
        </chunking>
        <chunking id="4" string="Miss Taylor 's condition and activities" type="NP">
          <tokens>
            <token id="26" string="Miss" />
            <token id="27" string="Taylor" />
            <token id="28" string="'s" />
            <token id="29" string="condition" />
            <token id="30" string="and" />
            <token id="31" string="activities" />
          </tokens>
        </chunking>
        <chunking id="5" string="pending for nine months" type="VP">
          <tokens>
            <token id="7" string="pending" />
            <token id="8" string="for" />
            <token id="9" string="nine" />
            <token id="10" string="months" />
          </tokens>
        </chunking>
        <chunking id="6" string="St. John 's" type="NP">
          <tokens>
            <token id="33" string="St." />
            <token id="34" string="John" />
            <token id="35" string="'s" />
          </tokens>
        </chunking>
        <chunking id="7" string="June 1990" type="NP">
          <tokens>
            <token id="22" string="June" />
            <token id="23" string="1990" />
          </tokens>
        </chunking>
        <chunking id="8" string="she" type="NP">
          <tokens>
            <token id="44" string="she" />
          </tokens>
        </chunking>
        <chunking id="9" string="The lawsuit" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="lawsuit" />
          </tokens>
        </chunking>
        <chunking id="10" string="Santa Monica" type="NP">
          <tokens>
            <token id="38" string="Santa" />
            <token id="39" string="Monica" />
          </tokens>
        </chunking>
        <chunking id="11" string="Miss Taylor 's" type="NP">
          <tokens>
            <token id="26" string="Miss" />
            <token id="27" string="Taylor" />
            <token id="28" string="'s" />
          </tokens>
        </chunking>
        <chunking id="12" string="June 1990 reporting on Miss Taylor 's condition and activities at St. John 's Hospital , Santa Monica , Calif. , where she was treated last spring for pneumonia" type="NP">
          <tokens>
            <token id="22" string="June" />
            <token id="23" string="1990" />
            <token id="24" string="reporting" />
            <token id="25" string="on" />
            <token id="26" string="Miss" />
            <token id="27" string="Taylor" />
            <token id="28" string="'s" />
            <token id="29" string="condition" />
            <token id="30" string="and" />
            <token id="31" string="activities" />
            <token id="32" string="at" />
            <token id="33" string="St." />
            <token id="34" string="John" />
            <token id="35" string="'s" />
            <token id="36" string="Hospital" />
            <token id="37" string="," />
            <token id="38" string="Santa" />
            <token id="39" string="Monica" />
            <token id="40" string="," />
            <token id="41" string="Calif." />
            <token id="42" string="," />
            <token id="43" string="where" />
            <token id="44" string="she" />
            <token id="45" string="was" />
            <token id="46" string="treated" />
            <token id="47" string="last" />
            <token id="48" string="spring" />
            <token id="49" string="for" />
            <token id="50" string="pneumonia" />
          </tokens>
        </chunking>
        <chunking id="13" string="reporting on Miss Taylor 's condition and activities at St. John 's Hospital , Santa Monica , Calif. , where she was treated last spring for pneumonia" type="VP">
          <tokens>
            <token id="24" string="reporting" />
            <token id="25" string="on" />
            <token id="26" string="Miss" />
            <token id="27" string="Taylor" />
            <token id="28" string="'s" />
            <token id="29" string="condition" />
            <token id="30" string="and" />
            <token id="31" string="activities" />
            <token id="32" string="at" />
            <token id="33" string="St." />
            <token id="34" string="John" />
            <token id="35" string="'s" />
            <token id="36" string="Hospital" />
            <token id="37" string="," />
            <token id="38" string="Santa" />
            <token id="39" string="Monica" />
            <token id="40" string="," />
            <token id="41" string="Calif." />
            <token id="42" string="," />
            <token id="43" string="where" />
            <token id="44" string="she" />
            <token id="45" string="was" />
            <token id="46" string="treated" />
            <token id="47" string="last" />
            <token id="48" string="spring" />
            <token id="49" string="for" />
            <token id="50" string="pneumonia" />
          </tokens>
        </chunking>
        <chunking id="14" string="St. John 's Hospital , Santa Monica , Calif." type="NP">
          <tokens>
            <token id="33" string="St." />
            <token id="34" string="John" />
            <token id="35" string="'s" />
            <token id="36" string="Hospital" />
            <token id="37" string="," />
            <token id="38" string="Santa" />
            <token id="39" string="Monica" />
            <token id="40" string="," />
            <token id="41" string="Calif." />
          </tokens>
        </chunking>
        <chunking id="15" string="arose out of two articles published by the Enquirer in June 1990 reporting on Miss Taylor 's condition and activities at St. John 's Hospital , Santa Monica , Calif. , where she was treated last spring for pneumonia" type="VP">
          <tokens>
            <token id="12" string="arose" />
            <token id="13" string="out" />
            <token id="14" string="of" />
            <token id="15" string="two" />
            <token id="16" string="articles" />
            <token id="17" string="published" />
            <token id="18" string="by" />
            <token id="19" string="the" />
            <token id="20" string="Enquirer" />
            <token id="21" string="in" />
            <token id="22" string="June" />
            <token id="23" string="1990" />
            <token id="24" string="reporting" />
            <token id="25" string="on" />
            <token id="26" string="Miss" />
            <token id="27" string="Taylor" />
            <token id="28" string="'s" />
            <token id="29" string="condition" />
            <token id="30" string="and" />
            <token id="31" string="activities" />
            <token id="32" string="at" />
            <token id="33" string="St." />
            <token id="34" string="John" />
            <token id="35" string="'s" />
            <token id="36" string="Hospital" />
            <token id="37" string="," />
            <token id="38" string="Santa" />
            <token id="39" string="Monica" />
            <token id="40" string="," />
            <token id="41" string="Calif." />
            <token id="42" string="," />
            <token id="43" string="where" />
            <token id="44" string="she" />
            <token id="45" string="was" />
            <token id="46" string="treated" />
            <token id="47" string="last" />
            <token id="48" string="spring" />
            <token id="49" string="for" />
            <token id="50" string="pneumonia" />
          </tokens>
        </chunking>
        <chunking id="16" string="treated last spring for pneumonia" type="VP">
          <tokens>
            <token id="46" string="treated" />
            <token id="47" string="last" />
            <token id="48" string="spring" />
            <token id="49" string="for" />
            <token id="50" string="pneumonia" />
          </tokens>
        </chunking>
        <chunking id="17" string="published by the Enquirer in June 1990 reporting on Miss Taylor 's condition and activities at St. John 's Hospital , Santa Monica , Calif. , where she was treated last spring for pneumonia" type="VP">
          <tokens>
            <token id="17" string="published" />
            <token id="18" string="by" />
            <token id="19" string="the" />
            <token id="20" string="Enquirer" />
            <token id="21" string="in" />
            <token id="22" string="June" />
            <token id="23" string="1990" />
            <token id="24" string="reporting" />
            <token id="25" string="on" />
            <token id="26" string="Miss" />
            <token id="27" string="Taylor" />
            <token id="28" string="'s" />
            <token id="29" string="condition" />
            <token id="30" string="and" />
            <token id="31" string="activities" />
            <token id="32" string="at" />
            <token id="33" string="St." />
            <token id="34" string="John" />
            <token id="35" string="'s" />
            <token id="36" string="Hospital" />
            <token id="37" string="," />
            <token id="38" string="Santa" />
            <token id="39" string="Monica" />
            <token id="40" string="," />
            <token id="41" string="Calif." />
            <token id="42" string="," />
            <token id="43" string="where" />
            <token id="44" string="she" />
            <token id="45" string="was" />
            <token id="46" string="treated" />
            <token id="47" string="last" />
            <token id="48" string="spring" />
            <token id="49" string="for" />
            <token id="50" string="pneumonia" />
          </tokens>
        </chunking>
        <chunking id="18" string="was treated last spring for pneumonia" type="VP">
          <tokens>
            <token id="45" string="was" />
            <token id="46" string="treated" />
            <token id="47" string="last" />
            <token id="48" string="spring" />
            <token id="49" string="for" />
            <token id="50" string="pneumonia" />
          </tokens>
        </chunking>
        <chunking id="19" string="two articles published by the Enquirer in June 1990 reporting on Miss Taylor 's condition and activities at St. John 's Hospital , Santa Monica , Calif. , where she was treated last spring for pneumonia" type="NP">
          <tokens>
            <token id="15" string="two" />
            <token id="16" string="articles" />
            <token id="17" string="published" />
            <token id="18" string="by" />
            <token id="19" string="the" />
            <token id="20" string="Enquirer" />
            <token id="21" string="in" />
            <token id="22" string="June" />
            <token id="23" string="1990" />
            <token id="24" string="reporting" />
            <token id="25" string="on" />
            <token id="26" string="Miss" />
            <token id="27" string="Taylor" />
            <token id="28" string="'s" />
            <token id="29" string="condition" />
            <token id="30" string="and" />
            <token id="31" string="activities" />
            <token id="32" string="at" />
            <token id="33" string="St." />
            <token id="34" string="John" />
            <token id="35" string="'s" />
            <token id="36" string="Hospital" />
            <token id="37" string="," />
            <token id="38" string="Santa" />
            <token id="39" string="Monica" />
            <token id="40" string="," />
            <token id="41" string="Calif." />
            <token id="42" string="," />
            <token id="43" string="where" />
            <token id="44" string="she" />
            <token id="45" string="was" />
            <token id="46" string="treated" />
            <token id="47" string="last" />
            <token id="48" string="spring" />
            <token id="49" string="for" />
            <token id="50" string="pneumonia" />
          </tokens>
        </chunking>
        <chunking id="20" string="the Enquirer" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="Enquirer" />
          </tokens>
        </chunking>
        <chunking id="21" string="been pending for nine months" type="VP">
          <tokens>
            <token id="6" string="been" />
            <token id="7" string="pending" />
            <token id="8" string="for" />
            <token id="9" string="nine" />
            <token id="10" string="months" />
          </tokens>
        </chunking>
        <chunking id="22" string="pneumonia" type="NP">
          <tokens>
            <token id="50" string="pneumonia" />
          </tokens>
        </chunking>
        <chunking id="23" string="nine months" type="NP">
          <tokens>
            <token id="9" string="nine" />
            <token id="10" string="months" />
          </tokens>
        </chunking>
        <chunking id="24" string="where" type="WHADVP">
          <tokens>
            <token id="43" string="where" />
          </tokens>
        </chunking>
        <chunking id="25" string="which has been pending for nine months" type="SBAR">
          <tokens>
            <token id="4" string="which" />
            <token id="5" string="has" />
            <token id="6" string="been" />
            <token id="7" string="pending" />
            <token id="8" string="for" />
            <token id="9" string="nine" />
            <token id="10" string="months" />
          </tokens>
        </chunking>
        <chunking id="26" string="where she was treated last spring for pneumonia" type="SBAR">
          <tokens>
            <token id="43" string="where" />
            <token id="44" string="she" />
            <token id="45" string="was" />
            <token id="46" string="treated" />
            <token id="47" string="last" />
            <token id="48" string="spring" />
            <token id="49" string="for" />
            <token id="50" string="pneumonia" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">lawsuit</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">arose</governor>
          <dependent id="2">lawsuit</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">pending</governor>
          <dependent id="4">which</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">pending</governor>
          <dependent id="5">has</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">pending</governor>
          <dependent id="6">been</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="2">lawsuit</governor>
          <dependent id="7">pending</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">months</governor>
          <dependent id="8">for</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="10">months</governor>
          <dependent id="9">nine</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">pending</governor>
          <dependent id="10">months</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">arose</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="12">arose</governor>
          <dependent id="13">out</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">articles</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="16">articles</governor>
          <dependent id="15">two</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">arose</governor>
          <dependent id="16">articles</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="16">articles</governor>
          <dependent id="17">published</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">Enquirer</governor>
          <dependent id="18">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">Enquirer</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">published</governor>
          <dependent id="20">Enquirer</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">June</governor>
          <dependent id="21">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">published</governor>
          <dependent id="22">June</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="22">June</governor>
          <dependent id="23">1990</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="22">June</governor>
          <dependent id="24">reporting</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">condition</governor>
          <dependent id="25">on</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">Taylor</governor>
          <dependent id="26">Miss</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="29">condition</governor>
          <dependent id="27">Taylor</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">Taylor</governor>
          <dependent id="28">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">reporting</governor>
          <dependent id="29">condition</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="29">condition</governor>
          <dependent id="30">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="29">condition</governor>
          <dependent id="31">activities</dependent>
        </dependency>
        <dependency type="case">
          <governor id="41">Calif.</governor>
          <dependent id="32">at</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="34">John</governor>
          <dependent id="33">St.</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="41">Calif.</governor>
          <dependent id="34">John</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">John</governor>
          <dependent id="35">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="41">Calif.</governor>
          <dependent id="36">Hospital</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="39">Monica</governor>
          <dependent id="38">Santa</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="41">Calif.</governor>
          <dependent id="39">Monica</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">reporting</governor>
          <dependent id="41">Calif.</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="46">treated</governor>
          <dependent id="43">where</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="46">treated</governor>
          <dependent id="44">she</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="46">treated</governor>
          <dependent id="45">was</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="24">reporting</governor>
          <dependent id="46">treated</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="48">spring</governor>
          <dependent id="47">last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="46">treated</governor>
          <dependent id="48">spring</dependent>
        </dependency>
        <dependency type="case">
          <governor id="50">pneumonia</governor>
          <dependent id="49">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="46">treated</governor>
          <dependent id="50">pneumonia</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Santa Monica" type="LOCATION" score="0.0">
          <tokens>
            <token id="38" string="Santa" />
            <token id="39" string="Monica" />
          </tokens>
        </entity>
        <entity id="2" string="Taylor" type="PERSON" score="0.0">
          <tokens>
            <token id="27" string="Taylor" />
          </tokens>
        </entity>
        <entity id="3" string="Enquirer" type="MISC" score="0.0">
          <tokens>
            <token id="20" string="Enquirer" />
          </tokens>
        </entity>
        <entity id="4" string="St. John 's Hospital" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="33" string="St." />
            <token id="34" string="John" />
            <token id="35" string="'s" />
            <token id="36" string="Hospital" />
          </tokens>
        </entity>
        <entity id="5" string="pneumonia" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="50" string="pneumonia" />
          </tokens>
        </entity>
        <entity id="6" string="nine months" type="DURATION" score="0.0">
          <tokens>
            <token id="9" string="nine" />
            <token id="10" string="months" />
          </tokens>
        </entity>
        <entity id="7" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="15" string="two" />
          </tokens>
        </entity>
        <entity id="8" string="Calif." type="LOCATION" score="0.0">
          <tokens>
            <token id="41" string="Calif." />
          </tokens>
        </entity>
        <entity id="9" string="June 1990" type="DATE" score="0.0">
          <tokens>
            <token id="22" string="June" />
            <token id="23" string="1990" />
          </tokens>
        </entity>
        <entity id="10" string="last spring" type="DATE" score="0.0">
          <tokens>
            <token id="47" string="last" />
            <token id="48" string="spring" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>The Enquirer said that after gaining access to all of Miss Taylor&amp;apost;s medical records, it is satisfied that the articles reporting on the actress&amp;apost;s medical condition and the report that she was drinking were in error.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="Enquirer" lemma="Enquirer" stem="enquirer" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="3" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="gaining" lemma="gain" stem="gain" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="access" lemma="access" stem="access" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="Taylor" lemma="Taylor" stem="taylor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="13" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="medical" lemma="medical" stem="medic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="records" lemma="record" stem="record" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="satisfied" lemma="satisfied" stem="satisfi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="articles" lemma="article" stem="articl" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="reporting" lemma="report" stem="report" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="26" string="actress" lemma="actress" stem="actress" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="28" string="medical" lemma="medical" stem="medic" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="condition" lemma="condition" stem="condit" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="30" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="31" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="32" string="report" lemma="report" stem="report" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="33" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="34" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="35" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="36" string="drinking" lemma="drinking" stem="drink" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="37" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="error" lemma="error" stem="error" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNP Enquirer)) (VP (VBD said) (SBAR (IN that) (S (PP (IN after) (S (VP (VBG gaining) (NP (NN access)) (PP (TO to) (NP (NP (DT all)) (PP (IN of) (NP (NP (NNP Miss) (NNP Taylor) (POS 's)) (JJ medical) (NNS records)))))))) (, ,) (NP (PRP it)) (VP (VBZ is) (ADJP (JJ satisfied)) (SBAR (IN that) (S (NP (NP (DT the) (NNS articles)) (VP (VBG reporting) (PP (IN on) (NP (NP (NP (DT the) (NN actress) (POS 's)) (JJ medical) (NN condition)) (CC and) (NP (DT the) (NN report)))) (SBAR (IN that) (S (NP (PRP she)) (VP (VBD was) (NP (NN drinking))))))) (VP (VBD were) (PP (IN in) (NP (NN error)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="drinking" type="NP">
          <tokens>
            <token id="36" string="drinking" />
          </tokens>
        </chunking>
        <chunking id="2" string="all" type="NP">
          <tokens>
            <token id="9" string="all" />
          </tokens>
        </chunking>
        <chunking id="3" string="all of Miss Taylor 's medical records" type="NP">
          <tokens>
            <token id="9" string="all" />
            <token id="10" string="of" />
            <token id="11" string="Miss" />
            <token id="12" string="Taylor" />
            <token id="13" string="'s" />
            <token id="14" string="medical" />
            <token id="15" string="records" />
          </tokens>
        </chunking>
        <chunking id="4" string="the articles" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="articles" />
          </tokens>
        </chunking>
        <chunking id="5" string="satisfied" type="ADJP">
          <tokens>
            <token id="19" string="satisfied" />
          </tokens>
        </chunking>
        <chunking id="6" string="that after gaining access to all of Miss Taylor 's medical records , it is satisfied that the articles reporting on the actress 's medical condition and the report that she was drinking were in error" type="SBAR">
          <tokens>
            <token id="4" string="that" />
            <token id="5" string="after" />
            <token id="6" string="gaining" />
            <token id="7" string="access" />
            <token id="8" string="to" />
            <token id="9" string="all" />
            <token id="10" string="of" />
            <token id="11" string="Miss" />
            <token id="12" string="Taylor" />
            <token id="13" string="'s" />
            <token id="14" string="medical" />
            <token id="15" string="records" />
            <token id="16" string="," />
            <token id="17" string="it" />
            <token id="18" string="is" />
            <token id="19" string="satisfied" />
            <token id="20" string="that" />
            <token id="21" string="the" />
            <token id="22" string="articles" />
            <token id="23" string="reporting" />
            <token id="24" string="on" />
            <token id="25" string="the" />
            <token id="26" string="actress" />
            <token id="27" string="'s" />
            <token id="28" string="medical" />
            <token id="29" string="condition" />
            <token id="30" string="and" />
            <token id="31" string="the" />
            <token id="32" string="report" />
            <token id="33" string="that" />
            <token id="34" string="she" />
            <token id="35" string="was" />
            <token id="36" string="drinking" />
            <token id="37" string="were" />
            <token id="38" string="in" />
            <token id="39" string="error" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="17" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="she" type="NP">
          <tokens>
            <token id="34" string="she" />
          </tokens>
        </chunking>
        <chunking id="9" string="the actress 's medical condition" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="actress" />
            <token id="27" string="'s" />
            <token id="28" string="medical" />
            <token id="29" string="condition" />
          </tokens>
        </chunking>
        <chunking id="10" string="said that after gaining access to all of Miss Taylor 's medical records , it is satisfied that the articles reporting on the actress 's medical condition and the report that she was drinking were in error" type="VP">
          <tokens>
            <token id="3" string="said" />
            <token id="4" string="that" />
            <token id="5" string="after" />
            <token id="6" string="gaining" />
            <token id="7" string="access" />
            <token id="8" string="to" />
            <token id="9" string="all" />
            <token id="10" string="of" />
            <token id="11" string="Miss" />
            <token id="12" string="Taylor" />
            <token id="13" string="'s" />
            <token id="14" string="medical" />
            <token id="15" string="records" />
            <token id="16" string="," />
            <token id="17" string="it" />
            <token id="18" string="is" />
            <token id="19" string="satisfied" />
            <token id="20" string="that" />
            <token id="21" string="the" />
            <token id="22" string="articles" />
            <token id="23" string="reporting" />
            <token id="24" string="on" />
            <token id="25" string="the" />
            <token id="26" string="actress" />
            <token id="27" string="'s" />
            <token id="28" string="medical" />
            <token id="29" string="condition" />
            <token id="30" string="and" />
            <token id="31" string="the" />
            <token id="32" string="report" />
            <token id="33" string="that" />
            <token id="34" string="she" />
            <token id="35" string="was" />
            <token id="36" string="drinking" />
            <token id="37" string="were" />
            <token id="38" string="in" />
            <token id="39" string="error" />
          </tokens>
        </chunking>
        <chunking id="11" string="that the articles reporting on the actress 's medical condition and the report that she was drinking were in error" type="SBAR">
          <tokens>
            <token id="20" string="that" />
            <token id="21" string="the" />
            <token id="22" string="articles" />
            <token id="23" string="reporting" />
            <token id="24" string="on" />
            <token id="25" string="the" />
            <token id="26" string="actress" />
            <token id="27" string="'s" />
            <token id="28" string="medical" />
            <token id="29" string="condition" />
            <token id="30" string="and" />
            <token id="31" string="the" />
            <token id="32" string="report" />
            <token id="33" string="that" />
            <token id="34" string="she" />
            <token id="35" string="was" />
            <token id="36" string="drinking" />
            <token id="37" string="were" />
            <token id="38" string="in" />
            <token id="39" string="error" />
          </tokens>
        </chunking>
        <chunking id="12" string="the actress 's" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="actress" />
            <token id="27" string="'s" />
          </tokens>
        </chunking>
        <chunking id="13" string="Miss Taylor 's" type="NP">
          <tokens>
            <token id="11" string="Miss" />
            <token id="12" string="Taylor" />
            <token id="13" string="'s" />
          </tokens>
        </chunking>
        <chunking id="14" string="the actress 's medical condition and the report" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="actress" />
            <token id="27" string="'s" />
            <token id="28" string="medical" />
            <token id="29" string="condition" />
            <token id="30" string="and" />
            <token id="31" string="the" />
            <token id="32" string="report" />
          </tokens>
        </chunking>
        <chunking id="15" string="the report" type="NP">
          <tokens>
            <token id="31" string="the" />
            <token id="32" string="report" />
          </tokens>
        </chunking>
        <chunking id="16" string="The Enquirer" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Enquirer" />
          </tokens>
        </chunking>
        <chunking id="17" string="the articles reporting on the actress 's medical condition and the report that she was drinking" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="articles" />
            <token id="23" string="reporting" />
            <token id="24" string="on" />
            <token id="25" string="the" />
            <token id="26" string="actress" />
            <token id="27" string="'s" />
            <token id="28" string="medical" />
            <token id="29" string="condition" />
            <token id="30" string="and" />
            <token id="31" string="the" />
            <token id="32" string="report" />
            <token id="33" string="that" />
            <token id="34" string="she" />
            <token id="35" string="was" />
            <token id="36" string="drinking" />
          </tokens>
        </chunking>
        <chunking id="18" string="error" type="NP">
          <tokens>
            <token id="39" string="error" />
          </tokens>
        </chunking>
        <chunking id="19" string="access" type="NP">
          <tokens>
            <token id="7" string="access" />
          </tokens>
        </chunking>
        <chunking id="20" string="that she was drinking" type="SBAR">
          <tokens>
            <token id="33" string="that" />
            <token id="34" string="she" />
            <token id="35" string="was" />
            <token id="36" string="drinking" />
          </tokens>
        </chunking>
        <chunking id="21" string="reporting on the actress 's medical condition and the report that she was drinking" type="VP">
          <tokens>
            <token id="23" string="reporting" />
            <token id="24" string="on" />
            <token id="25" string="the" />
            <token id="26" string="actress" />
            <token id="27" string="'s" />
            <token id="28" string="medical" />
            <token id="29" string="condition" />
            <token id="30" string="and" />
            <token id="31" string="the" />
            <token id="32" string="report" />
            <token id="33" string="that" />
            <token id="34" string="she" />
            <token id="35" string="was" />
            <token id="36" string="drinking" />
          </tokens>
        </chunking>
        <chunking id="22" string="is satisfied that the articles reporting on the actress 's medical condition and the report that she was drinking were in error" type="VP">
          <tokens>
            <token id="18" string="is" />
            <token id="19" string="satisfied" />
            <token id="20" string="that" />
            <token id="21" string="the" />
            <token id="22" string="articles" />
            <token id="23" string="reporting" />
            <token id="24" string="on" />
            <token id="25" string="the" />
            <token id="26" string="actress" />
            <token id="27" string="'s" />
            <token id="28" string="medical" />
            <token id="29" string="condition" />
            <token id="30" string="and" />
            <token id="31" string="the" />
            <token id="32" string="report" />
            <token id="33" string="that" />
            <token id="34" string="she" />
            <token id="35" string="was" />
            <token id="36" string="drinking" />
            <token id="37" string="were" />
            <token id="38" string="in" />
            <token id="39" string="error" />
          </tokens>
        </chunking>
        <chunking id="23" string="were in error" type="VP">
          <tokens>
            <token id="37" string="were" />
            <token id="38" string="in" />
            <token id="39" string="error" />
          </tokens>
        </chunking>
        <chunking id="24" string="Miss Taylor 's medical records" type="NP">
          <tokens>
            <token id="11" string="Miss" />
            <token id="12" string="Taylor" />
            <token id="13" string="'s" />
            <token id="14" string="medical" />
            <token id="15" string="records" />
          </tokens>
        </chunking>
        <chunking id="25" string="was drinking" type="VP">
          <tokens>
            <token id="35" string="was" />
            <token id="36" string="drinking" />
          </tokens>
        </chunking>
        <chunking id="26" string="gaining access to all of Miss Taylor 's medical records" type="VP">
          <tokens>
            <token id="6" string="gaining" />
            <token id="7" string="access" />
            <token id="8" string="to" />
            <token id="9" string="all" />
            <token id="10" string="of" />
            <token id="11" string="Miss" />
            <token id="12" string="Taylor" />
            <token id="13" string="'s" />
            <token id="14" string="medical" />
            <token id="15" string="records" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">Enquirer</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">said</governor>
          <dependent id="2">Enquirer</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">said</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">satisfied</governor>
          <dependent id="4">that</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">gaining</governor>
          <dependent id="5">after</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="19">satisfied</governor>
          <dependent id="6">gaining</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">gaining</governor>
          <dependent id="7">access</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">all</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">gaining</governor>
          <dependent id="9">all</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">records</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Taylor</governor>
          <dependent id="11">Miss</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">records</governor>
          <dependent id="12">Taylor</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Taylor</governor>
          <dependent id="13">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">records</governor>
          <dependent id="14">medical</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">all</governor>
          <dependent id="15">records</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">satisfied</governor>
          <dependent id="17">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="19">satisfied</governor>
          <dependent id="18">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">said</governor>
          <dependent id="19">satisfied</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="39">error</governor>
          <dependent id="20">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">articles</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="39">error</governor>
          <dependent id="22">articles</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="22">articles</governor>
          <dependent id="23">reporting</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">condition</governor>
          <dependent id="24">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">actress</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="29">condition</governor>
          <dependent id="26">actress</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">actress</governor>
          <dependent id="27">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">condition</governor>
          <dependent id="28">medical</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">reporting</governor>
          <dependent id="29">condition</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="29">condition</governor>
          <dependent id="30">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">report</governor>
          <dependent id="31">the</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="29">condition</governor>
          <dependent id="32">report</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="36">drinking</governor>
          <dependent id="33">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="36">drinking</governor>
          <dependent id="34">she</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="36">drinking</governor>
          <dependent id="35">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="23">reporting</governor>
          <dependent id="36">drinking</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="39">error</governor>
          <dependent id="37">were</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">error</governor>
          <dependent id="38">in</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">satisfied</governor>
          <dependent id="39">error</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Taylor" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Taylor" />
          </tokens>
        </entity>
        <entity id="2" string="Enquirer" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="2" string="Enquirer" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>The paper said it published the articles in good faith reliance on information provided to it, but the information was inaccurate.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="paper" lemma="paper" stem="paper" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="published" lemma="publish" stem="publish" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="articles" lemma="article" stem="articl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="good" lemma="good" stem="good" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="faith" lemma="faith" stem="faith" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="reliance" lemma="reliance" stem="relianc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="information" lemma="information" stem="inform" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="provided" lemma="provide" stem="provid" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="information" lemma="information" stem="inform" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="inaccurate" lemma="inaccurate" stem="inaccur" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT The) (NN paper)) (VP (VBD said) (SBAR (S (NP (PRP it)) (VP (VBD published) (NP (DT the) (NNS articles)) (PP (IN in) (NP (NP (JJ good) (NN faith) (NN reliance)) (PP (IN on) (NP (NN information))))) (PP (VBN provided) (PP (TO to) (NP (PRP it))))))))) (, ,) (CC but) (S (NP (DT the) (NN information)) (VP (VBD was) (ADJP (JJ inaccurate)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="good faith reliance" type="NP">
          <tokens>
            <token id="9" string="good" />
            <token id="10" string="faith" />
            <token id="11" string="reliance" />
          </tokens>
        </chunking>
        <chunking id="2" string="said it published the articles in good faith reliance on information provided to it" type="VP">
          <tokens>
            <token id="3" string="said" />
            <token id="4" string="it" />
            <token id="5" string="published" />
            <token id="6" string="the" />
            <token id="7" string="articles" />
            <token id="8" string="in" />
            <token id="9" string="good" />
            <token id="10" string="faith" />
            <token id="11" string="reliance" />
            <token id="12" string="on" />
            <token id="13" string="information" />
            <token id="14" string="provided" />
            <token id="15" string="to" />
            <token id="16" string="it" />
          </tokens>
        </chunking>
        <chunking id="3" string="published the articles in good faith reliance on information provided to it" type="VP">
          <tokens>
            <token id="5" string="published" />
            <token id="6" string="the" />
            <token id="7" string="articles" />
            <token id="8" string="in" />
            <token id="9" string="good" />
            <token id="10" string="faith" />
            <token id="11" string="reliance" />
            <token id="12" string="on" />
            <token id="13" string="information" />
            <token id="14" string="provided" />
            <token id="15" string="to" />
            <token id="16" string="it" />
          </tokens>
        </chunking>
        <chunking id="4" string="the articles" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="articles" />
          </tokens>
        </chunking>
        <chunking id="5" string="was inaccurate" type="VP">
          <tokens>
            <token id="21" string="was" />
            <token id="22" string="inaccurate" />
          </tokens>
        </chunking>
        <chunking id="6" string="it published the articles in good faith reliance on information provided to it" type="SBAR">
          <tokens>
            <token id="4" string="it" />
            <token id="5" string="published" />
            <token id="6" string="the" />
            <token id="7" string="articles" />
            <token id="8" string="in" />
            <token id="9" string="good" />
            <token id="10" string="faith" />
            <token id="11" string="reliance" />
            <token id="12" string="on" />
            <token id="13" string="information" />
            <token id="14" string="provided" />
            <token id="15" string="to" />
            <token id="16" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="4" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="The paper" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="paper" />
          </tokens>
        </chunking>
        <chunking id="9" string="good faith reliance on information" type="NP">
          <tokens>
            <token id="9" string="good" />
            <token id="10" string="faith" />
            <token id="11" string="reliance" />
            <token id="12" string="on" />
            <token id="13" string="information" />
          </tokens>
        </chunking>
        <chunking id="10" string="information" type="NP">
          <tokens>
            <token id="13" string="information" />
          </tokens>
        </chunking>
        <chunking id="11" string="the information" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="information" />
          </tokens>
        </chunking>
        <chunking id="12" string="inaccurate" type="ADJP">
          <tokens>
            <token id="22" string="inaccurate" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">paper</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">said</governor>
          <dependent id="2">paper</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">published</governor>
          <dependent id="4">it</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">said</governor>
          <dependent id="5">published</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">articles</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">published</governor>
          <dependent id="7">articles</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">reliance</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">reliance</governor>
          <dependent id="9">good</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">reliance</governor>
          <dependent id="10">faith</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">published</governor>
          <dependent id="11">reliance</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">information</governor>
          <dependent id="12">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">reliance</governor>
          <dependent id="13">information</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">it</governor>
          <dependent id="14">provided</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">it</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">published</governor>
          <dependent id="16">it</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">said</governor>
          <dependent id="18">but</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">information</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">inaccurate</governor>
          <dependent id="20">information</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="22">inaccurate</governor>
          <dependent id="21">was</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">said</governor>
          <dependent id="22">inaccurate</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>Iain Calder, Enquirer editor, said in a statement, &amp;quot;we regret the inaccuracies in the articles but are pleased that this dispute has come to an amicable end.&amp;quot;</content>
      <tokens>
        <token id="1" string="Iain" lemma="Iain" stem="iain" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Calder" lemma="Calder" stem="calder" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Enquirer" lemma="Enquirer" stem="enquirer" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="5" string="editor" lemma="editor" stem="editor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="statement" lemma="statement" stem="statement" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="regret" lemma="regret" stem="regret" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="inaccuracies" lemma="inaccuracy" stem="inaccuraci" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="articles" lemma="article" stem="articl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="pleased" lemma="pleased" stem="pleas" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="dispute" lemma="dispute" stem="disput" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="come" lemma="come" stem="come" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="amicable" lemma="amicable" stem="amic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="end" lemma="end" stem="end" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Iain) (NNP Calder)) (, ,) (NP (NNP Enquirer) (NN editor)) (, ,)) (VP (VBD said) (SBAR (S (PP (IN in) (NP (DT a) (NN statement))) (, ,) (`` ``) (NP (PRP we)) (VP (VP (VBP regret) (NP (DT the) (NNS inaccuracies)) (PP (IN in) (NP (DT the) (NNS articles)))) (CC but) (VP (VBP are) (ADJP (JJ pleased) (SBAR (IN that) (S (NP (DT this) (NN dispute)) (VP (VBZ has) (VP (VBN come) (PP (TO to) (NP (DT an) (JJ amicable) (NN end))))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="come to an amicable end" type="VP">
          <tokens>
            <token id="27" string="come" />
            <token id="28" string="to" />
            <token id="29" string="an" />
            <token id="30" string="amicable" />
            <token id="31" string="end" />
          </tokens>
        </chunking>
        <chunking id="2" string="a statement" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="statement" />
          </tokens>
        </chunking>
        <chunking id="3" string="the articles" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="articles" />
          </tokens>
        </chunking>
        <chunking id="4" string="are pleased that this dispute has come to an amicable end" type="VP">
          <tokens>
            <token id="21" string="are" />
            <token id="22" string="pleased" />
            <token id="23" string="that" />
            <token id="24" string="this" />
            <token id="25" string="dispute" />
            <token id="26" string="has" />
            <token id="27" string="come" />
            <token id="28" string="to" />
            <token id="29" string="an" />
            <token id="30" string="amicable" />
            <token id="31" string="end" />
          </tokens>
        </chunking>
        <chunking id="5" string="Iain Calder" type="NP">
          <tokens>
            <token id="1" string="Iain" />
            <token id="2" string="Calder" />
          </tokens>
        </chunking>
        <chunking id="6" string="we" type="NP">
          <tokens>
            <token id="13" string="we" />
          </tokens>
        </chunking>
        <chunking id="7" string="regret the inaccuracies in the articles" type="VP">
          <tokens>
            <token id="14" string="regret" />
            <token id="15" string="the" />
            <token id="16" string="inaccuracies" />
            <token id="17" string="in" />
            <token id="18" string="the" />
            <token id="19" string="articles" />
          </tokens>
        </chunking>
        <chunking id="8" string="the inaccuracies" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="inaccuracies" />
          </tokens>
        </chunking>
        <chunking id="9" string="this dispute" type="NP">
          <tokens>
            <token id="24" string="this" />
            <token id="25" string="dispute" />
          </tokens>
        </chunking>
        <chunking id="10" string="Iain Calder , Enquirer editor ," type="NP">
          <tokens>
            <token id="1" string="Iain" />
            <token id="2" string="Calder" />
            <token id="3" string="," />
            <token id="4" string="Enquirer" />
            <token id="5" string="editor" />
            <token id="6" string="," />
          </tokens>
        </chunking>
        <chunking id="11" string="has come to an amicable end" type="VP">
          <tokens>
            <token id="26" string="has" />
            <token id="27" string="come" />
            <token id="28" string="to" />
            <token id="29" string="an" />
            <token id="30" string="amicable" />
            <token id="31" string="end" />
          </tokens>
        </chunking>
        <chunking id="12" string="pleased that this dispute has come to an amicable end" type="ADJP">
          <tokens>
            <token id="22" string="pleased" />
            <token id="23" string="that" />
            <token id="24" string="this" />
            <token id="25" string="dispute" />
            <token id="26" string="has" />
            <token id="27" string="come" />
            <token id="28" string="to" />
            <token id="29" string="an" />
            <token id="30" string="amicable" />
            <token id="31" string="end" />
          </tokens>
        </chunking>
        <chunking id="13" string="Enquirer editor" type="NP">
          <tokens>
            <token id="4" string="Enquirer" />
            <token id="5" string="editor" />
          </tokens>
        </chunking>
        <chunking id="14" string="that this dispute has come to an amicable end" type="SBAR">
          <tokens>
            <token id="23" string="that" />
            <token id="24" string="this" />
            <token id="25" string="dispute" />
            <token id="26" string="has" />
            <token id="27" string="come" />
            <token id="28" string="to" />
            <token id="29" string="an" />
            <token id="30" string="amicable" />
            <token id="31" string="end" />
          </tokens>
        </chunking>
        <chunking id="15" string="said in a statement , `` we regret the inaccuracies in the articles but are pleased that this dispute has come to an amicable end" type="VP">
          <tokens>
            <token id="7" string="said" />
            <token id="8" string="in" />
            <token id="9" string="a" />
            <token id="10" string="statement" />
            <token id="11" string="," />
            <token id="12" string="&quot;" />
            <token id="13" string="we" />
            <token id="14" string="regret" />
            <token id="15" string="the" />
            <token id="16" string="inaccuracies" />
            <token id="17" string="in" />
            <token id="18" string="the" />
            <token id="19" string="articles" />
            <token id="20" string="but" />
            <token id="21" string="are" />
            <token id="22" string="pleased" />
            <token id="23" string="that" />
            <token id="24" string="this" />
            <token id="25" string="dispute" />
            <token id="26" string="has" />
            <token id="27" string="come" />
            <token id="28" string="to" />
            <token id="29" string="an" />
            <token id="30" string="amicable" />
            <token id="31" string="end" />
          </tokens>
        </chunking>
        <chunking id="16" string="an amicable end" type="NP">
          <tokens>
            <token id="29" string="an" />
            <token id="30" string="amicable" />
            <token id="31" string="end" />
          </tokens>
        </chunking>
        <chunking id="17" string="in a statement , `` we regret the inaccuracies in the articles but are pleased that this dispute has come to an amicable end" type="SBAR">
          <tokens>
            <token id="8" string="in" />
            <token id="9" string="a" />
            <token id="10" string="statement" />
            <token id="11" string="," />
            <token id="12" string="&quot;" />
            <token id="13" string="we" />
            <token id="14" string="regret" />
            <token id="15" string="the" />
            <token id="16" string="inaccuracies" />
            <token id="17" string="in" />
            <token id="18" string="the" />
            <token id="19" string="articles" />
            <token id="20" string="but" />
            <token id="21" string="are" />
            <token id="22" string="pleased" />
            <token id="23" string="that" />
            <token id="24" string="this" />
            <token id="25" string="dispute" />
            <token id="26" string="has" />
            <token id="27" string="come" />
            <token id="28" string="to" />
            <token id="29" string="an" />
            <token id="30" string="amicable" />
            <token id="31" string="end" />
          </tokens>
        </chunking>
        <chunking id="18" string="regret the inaccuracies in the articles but are pleased that this dispute has come to an amicable end" type="VP">
          <tokens>
            <token id="14" string="regret" />
            <token id="15" string="the" />
            <token id="16" string="inaccuracies" />
            <token id="17" string="in" />
            <token id="18" string="the" />
            <token id="19" string="articles" />
            <token id="20" string="but" />
            <token id="21" string="are" />
            <token id="22" string="pleased" />
            <token id="23" string="that" />
            <token id="24" string="this" />
            <token id="25" string="dispute" />
            <token id="26" string="has" />
            <token id="27" string="come" />
            <token id="28" string="to" />
            <token id="29" string="an" />
            <token id="30" string="amicable" />
            <token id="31" string="end" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Calder</governor>
          <dependent id="1">Iain</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">said</governor>
          <dependent id="2">Calder</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">editor</governor>
          <dependent id="4">Enquirer</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">Calder</governor>
          <dependent id="5">editor</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">said</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">statement</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">statement</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">regret</governor>
          <dependent id="10">statement</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">regret</governor>
          <dependent id="13">we</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">said</governor>
          <dependent id="14">regret</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">inaccuracies</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">regret</governor>
          <dependent id="16">inaccuracies</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">articles</governor>
          <dependent id="17">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">articles</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">regret</governor>
          <dependent id="19">articles</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">regret</governor>
          <dependent id="20">but</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="22">pleased</governor>
          <dependent id="21">are</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">regret</governor>
          <dependent id="22">pleased</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="27">come</governor>
          <dependent id="23">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">dispute</governor>
          <dependent id="24">this</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">come</governor>
          <dependent id="25">dispute</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="27">come</governor>
          <dependent id="26">has</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="22">pleased</governor>
          <dependent id="27">come</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">end</governor>
          <dependent id="28">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">end</governor>
          <dependent id="29">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">end</governor>
          <dependent id="30">amicable</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">come</governor>
          <dependent id="31">end</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Iain Calder" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Iain" />
            <token id="2" string="Calder" />
          </tokens>
        </entity>
        <entity id="2" string="Enquirer" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="4" string="Enquirer" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>Miss Taylor said she feels &amp;quot;completely vindicated,&amp;quot; and that after the newspaper&amp;apost;s management determined the articles were in error, the Enquirer &amp;quot;acted promptly and in good faith.&amp;quot;</content>
      <tokens>
        <token id="1" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="Taylor" lemma="Taylor" stem="taylor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="feels" lemma="feel" stem="feel" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="completely" lemma="completely" stem="complet" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="vindicated" lemma="vindicate" stem="vindic" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="newspaper" lemma="newspaper" stem="newspap" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="management" lemma="management" stem="manag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="determined" lemma="determine" stem="determin" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="articles" lemma="article" stem="articl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="error" lemma="error" stem="error" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="Enquirer" lemma="Enquirer" stem="enquirer" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="27" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="acted" lemma="act" stem="act" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="promptly" lemma="promptly" stem="promptli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="good" lemma="good" stem="good" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="faith" lemma="faith" stem="faith" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Miss) (NNP Taylor)) (VP (VBD said) (SBAR (SBAR (S (NP (PRP she)) (VP (VBZ feels) (`` ``) (ADJP (RB completely) (VBN vindicated))))) (, ,) ('' '') (CC and) (SBAR (IN that) (S (SBAR (IN after) (S (NP (NP (DT the) (NN newspaper) (POS 's)) (NN management)) (VP (VBD determined) (SBAR (S (NP (DT the) (NNS articles)) (VP (VBD were) (PP (IN in) (NP (NN error))))))))) (, ,) (NP (DT the) (NNP Enquirer)) (`` ``) (VP (VBD acted) (UCP (ADVP (RB promptly)) (CC and) (PP (IN in) (NP (JJ good) (NN faith))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="said she feels `` completely vindicated , '' and that after the newspaper 's management determined the articles were in error , the Enquirer `` acted promptly and in good faith" type="VP">
          <tokens>
            <token id="3" string="said" />
            <token id="4" string="she" />
            <token id="5" string="feels" />
            <token id="6" string="&quot;" />
            <token id="7" string="completely" />
            <token id="8" string="vindicated" />
            <token id="9" string="," />
            <token id="10" string="&quot;" />
            <token id="11" string="and" />
            <token id="12" string="that" />
            <token id="13" string="after" />
            <token id="14" string="the" />
            <token id="15" string="newspaper" />
            <token id="16" string="'s" />
            <token id="17" string="management" />
            <token id="18" string="determined" />
            <token id="19" string="the" />
            <token id="20" string="articles" />
            <token id="21" string="were" />
            <token id="22" string="in" />
            <token id="23" string="error" />
            <token id="24" string="," />
            <token id="25" string="the" />
            <token id="26" string="Enquirer" />
            <token id="27" string="&quot;" />
            <token id="28" string="acted" />
            <token id="29" string="promptly" />
            <token id="30" string="and" />
            <token id="31" string="in" />
            <token id="32" string="good" />
            <token id="33" string="faith" />
          </tokens>
        </chunking>
        <chunking id="2" string="error" type="NP">
          <tokens>
            <token id="23" string="error" />
          </tokens>
        </chunking>
        <chunking id="3" string="the articles" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="articles" />
          </tokens>
        </chunking>
        <chunking id="4" string="she feels `` completely vindicated , '' and that after the newspaper 's management determined the articles were in error , the Enquirer `` acted promptly and in good faith" type="SBAR">
          <tokens>
            <token id="4" string="she" />
            <token id="5" string="feels" />
            <token id="6" string="&quot;" />
            <token id="7" string="completely" />
            <token id="8" string="vindicated" />
            <token id="9" string="," />
            <token id="10" string="&quot;" />
            <token id="11" string="and" />
            <token id="12" string="that" />
            <token id="13" string="after" />
            <token id="14" string="the" />
            <token id="15" string="newspaper" />
            <token id="16" string="'s" />
            <token id="17" string="management" />
            <token id="18" string="determined" />
            <token id="19" string="the" />
            <token id="20" string="articles" />
            <token id="21" string="were" />
            <token id="22" string="in" />
            <token id="23" string="error" />
            <token id="24" string="," />
            <token id="25" string="the" />
            <token id="26" string="Enquirer" />
            <token id="27" string="&quot;" />
            <token id="28" string="acted" />
            <token id="29" string="promptly" />
            <token id="30" string="and" />
            <token id="31" string="in" />
            <token id="32" string="good" />
            <token id="33" string="faith" />
          </tokens>
        </chunking>
        <chunking id="5" string="that after the newspaper 's management determined the articles were in error , the Enquirer `` acted promptly and in good faith" type="SBAR">
          <tokens>
            <token id="12" string="that" />
            <token id="13" string="after" />
            <token id="14" string="the" />
            <token id="15" string="newspaper" />
            <token id="16" string="'s" />
            <token id="17" string="management" />
            <token id="18" string="determined" />
            <token id="19" string="the" />
            <token id="20" string="articles" />
            <token id="21" string="were" />
            <token id="22" string="in" />
            <token id="23" string="error" />
            <token id="24" string="," />
            <token id="25" string="the" />
            <token id="26" string="Enquirer" />
            <token id="27" string="&quot;" />
            <token id="28" string="acted" />
            <token id="29" string="promptly" />
            <token id="30" string="and" />
            <token id="31" string="in" />
            <token id="32" string="good" />
            <token id="33" string="faith" />
          </tokens>
        </chunking>
        <chunking id="6" string="the articles were in error" type="SBAR">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="articles" />
            <token id="21" string="were" />
            <token id="22" string="in" />
            <token id="23" string="error" />
          </tokens>
        </chunking>
        <chunking id="7" string="were in error" type="VP">
          <tokens>
            <token id="21" string="were" />
            <token id="22" string="in" />
            <token id="23" string="error" />
          </tokens>
        </chunking>
        <chunking id="8" string="she" type="NP">
          <tokens>
            <token id="4" string="she" />
          </tokens>
        </chunking>
        <chunking id="9" string="good faith" type="NP">
          <tokens>
            <token id="32" string="good" />
            <token id="33" string="faith" />
          </tokens>
        </chunking>
        <chunking id="10" string="the newspaper 's" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="newspaper" />
            <token id="16" string="'s" />
          </tokens>
        </chunking>
        <chunking id="11" string="the Enquirer" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="Enquirer" />
          </tokens>
        </chunking>
        <chunking id="12" string="the newspaper 's management" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="newspaper" />
            <token id="16" string="'s" />
            <token id="17" string="management" />
          </tokens>
        </chunking>
        <chunking id="13" string="determined the articles were in error" type="VP">
          <tokens>
            <token id="18" string="determined" />
            <token id="19" string="the" />
            <token id="20" string="articles" />
            <token id="21" string="were" />
            <token id="22" string="in" />
            <token id="23" string="error" />
          </tokens>
        </chunking>
        <chunking id="14" string="acted promptly and in good faith" type="VP">
          <tokens>
            <token id="28" string="acted" />
            <token id="29" string="promptly" />
            <token id="30" string="and" />
            <token id="31" string="in" />
            <token id="32" string="good" />
            <token id="33" string="faith" />
          </tokens>
        </chunking>
        <chunking id="15" string="Miss Taylor" type="NP">
          <tokens>
            <token id="1" string="Miss" />
            <token id="2" string="Taylor" />
          </tokens>
        </chunking>
        <chunking id="16" string="she feels `` completely vindicated" type="SBAR">
          <tokens>
            <token id="4" string="she" />
            <token id="5" string="feels" />
            <token id="6" string="&quot;" />
            <token id="7" string="completely" />
            <token id="8" string="vindicated" />
          </tokens>
        </chunking>
        <chunking id="17" string="after the newspaper 's management determined the articles were in error" type="SBAR">
          <tokens>
            <token id="13" string="after" />
            <token id="14" string="the" />
            <token id="15" string="newspaper" />
            <token id="16" string="'s" />
            <token id="17" string="management" />
            <token id="18" string="determined" />
            <token id="19" string="the" />
            <token id="20" string="articles" />
            <token id="21" string="were" />
            <token id="22" string="in" />
            <token id="23" string="error" />
          </tokens>
        </chunking>
        <chunking id="18" string="completely vindicated" type="ADJP">
          <tokens>
            <token id="7" string="completely" />
            <token id="8" string="vindicated" />
          </tokens>
        </chunking>
        <chunking id="19" string="feels `` completely vindicated" type="VP">
          <tokens>
            <token id="5" string="feels" />
            <token id="6" string="&quot;" />
            <token id="7" string="completely" />
            <token id="8" string="vindicated" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Taylor</governor>
          <dependent id="1">Miss</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">said</governor>
          <dependent id="2">Taylor</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">feels</governor>
          <dependent id="4">she</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">said</governor>
          <dependent id="5">feels</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">vindicated</governor>
          <dependent id="7">completely</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">feels</governor>
          <dependent id="8">vindicated</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">feels</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="28">acted</governor>
          <dependent id="12">that</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">determined</governor>
          <dependent id="13">after</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">newspaper</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="17">management</governor>
          <dependent id="15">newspaper</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">newspaper</governor>
          <dependent id="16">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">determined</governor>
          <dependent id="17">management</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="28">acted</governor>
          <dependent id="18">determined</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">articles</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">error</governor>
          <dependent id="20">articles</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="23">error</governor>
          <dependent id="21">were</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">error</governor>
          <dependent id="22">in</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="18">determined</governor>
          <dependent id="23">error</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">Enquirer</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">acted</governor>
          <dependent id="26">Enquirer</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">feels</governor>
          <dependent id="28">acted</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="30">and</governor>
          <dependent id="29">promptly</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="28">acted</governor>
          <dependent id="30">and</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">faith</governor>
          <dependent id="31">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="33">faith</governor>
          <dependent id="32">good</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="30">and</governor>
          <dependent id="33">faith</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Taylor" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Taylor" />
          </tokens>
        </entity>
        <entity id="2" string="Enquirer" type="MISC" score="0.0">
          <tokens>
            <token id="26" string="Enquirer" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>Miss Taylor initially sought damages of $20 million in Los Angeles Superior Court, according to Neil Papiano, her attorney.</content>
      <tokens>
        <token id="1" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="Taylor" lemma="Taylor" stem="taylor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="initially" lemma="initially" stem="initi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="sought" lemma="seek" stem="sought" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="damages" lemma="damages" stem="damag" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="8" string="20" lemma="20" stem="20" pos="CD" type="Number" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="9" string="million" lemma="million" stem="million" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="10" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Los" lemma="Los" stem="lo" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="12" string="Angeles" lemma="Angeles" stem="angele" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="13" string="Superior" lemma="Superior" stem="superior" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="14" string="Court" lemma="Court" stem="court" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="according" lemma="accord" stem="accord" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Neil" lemma="Neil" stem="neil" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="19" string="Papiano" lemma="Papiano" stem="papiano" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="attorney" lemma="attorney" stem="attornei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Miss) (NNP Taylor)) (ADVP (RB initially)) (VP (VBD sought) (NP (NP (NNS damages)) (PP (IN of) (NP (QP ($ $) (CD 20) (CD million))))) (PP (IN in) (NP (NNP Los) (NNP Angeles) (NNP Superior) (NNP Court))) (, ,) (PP (VBG according) (PP (TO to) (NP (NP (NNP Neil) (NNP Papiano)) (, ,) (NP (PRP$ her) (NN attorney)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="damages of $ 20 million" type="NP">
          <tokens>
            <token id="5" string="damages" />
            <token id="6" string="of" />
            <token id="7" string="$" />
            <token id="8" string="20" />
            <token id="9" string="million" />
          </tokens>
        </chunking>
        <chunking id="2" string="damages" type="NP">
          <tokens>
            <token id="5" string="damages" />
          </tokens>
        </chunking>
        <chunking id="3" string="Neil Papiano , her attorney" type="NP">
          <tokens>
            <token id="18" string="Neil" />
            <token id="19" string="Papiano" />
            <token id="20" string="," />
            <token id="21" string="her" />
            <token id="22" string="attorney" />
          </tokens>
        </chunking>
        <chunking id="4" string="Los Angeles Superior Court" type="NP">
          <tokens>
            <token id="11" string="Los" />
            <token id="12" string="Angeles" />
            <token id="13" string="Superior" />
            <token id="14" string="Court" />
          </tokens>
        </chunking>
        <chunking id="5" string="Neil Papiano" type="NP">
          <tokens>
            <token id="18" string="Neil" />
            <token id="19" string="Papiano" />
          </tokens>
        </chunking>
        <chunking id="6" string="her attorney" type="NP">
          <tokens>
            <token id="21" string="her" />
            <token id="22" string="attorney" />
          </tokens>
        </chunking>
        <chunking id="7" string="$ 20 million" type="NP">
          <tokens>
            <token id="7" string="$" />
            <token id="8" string="20" />
            <token id="9" string="million" />
          </tokens>
        </chunking>
        <chunking id="8" string="Miss Taylor" type="NP">
          <tokens>
            <token id="1" string="Miss" />
            <token id="2" string="Taylor" />
          </tokens>
        </chunking>
        <chunking id="9" string="sought damages of $ 20 million in Los Angeles Superior Court , according to Neil Papiano , her attorney" type="VP">
          <tokens>
            <token id="4" string="sought" />
            <token id="5" string="damages" />
            <token id="6" string="of" />
            <token id="7" string="$" />
            <token id="8" string="20" />
            <token id="9" string="million" />
            <token id="10" string="in" />
            <token id="11" string="Los" />
            <token id="12" string="Angeles" />
            <token id="13" string="Superior" />
            <token id="14" string="Court" />
            <token id="15" string="," />
            <token id="16" string="according" />
            <token id="17" string="to" />
            <token id="18" string="Neil" />
            <token id="19" string="Papiano" />
            <token id="20" string="," />
            <token id="21" string="her" />
            <token id="22" string="attorney" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Taylor</governor>
          <dependent id="1">Miss</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">sought</governor>
          <dependent id="2">Taylor</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">sought</governor>
          <dependent id="3">initially</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">sought</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">sought</governor>
          <dependent id="5">damages</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">$</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">damages</governor>
          <dependent id="7">$</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">million</governor>
          <dependent id="8">20</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="7">$</governor>
          <dependent id="9">million</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Court</governor>
          <dependent id="10">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Court</governor>
          <dependent id="11">Los</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Court</governor>
          <dependent id="12">Angeles</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Court</governor>
          <dependent id="13">Superior</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">sought</governor>
          <dependent id="14">Court</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">Papiano</governor>
          <dependent id="16">according</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="16">according</governor>
          <dependent id="17">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">Papiano</governor>
          <dependent id="18">Neil</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">sought</governor>
          <dependent id="19">Papiano</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="22">attorney</governor>
          <dependent id="21">her</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="19">Papiano</governor>
          <dependent id="22">attorney</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Los Angeles Superior Court" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="11" string="Los" />
            <token id="12" string="Angeles" />
            <token id="13" string="Superior" />
            <token id="14" string="Court" />
          </tokens>
        </entity>
        <entity id="2" string="Neil Papiano" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Neil" />
            <token id="19" string="Papiano" />
          </tokens>
        </entity>
        <entity id="3" string="Taylor" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Taylor" />
          </tokens>
        </entity>
        <entity id="4" string="$ 20 million" type="MONEY" score="0.0">
          <tokens>
            <token id="7" string="$" />
            <token id="8" string="20" />
            <token id="9" string="million" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>Although Mr. Papiano wouldn&amp;apost;t specify the size of the settlement, he said &amp;quot;we were persuaded that it was certainly large enough that we shouldn&amp;apost;t go to trial.&amp;quot;</content>
      <tokens>
        <token id="1" string="Although" lemma="although" stem="although" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="Papiano" lemma="Papiano" stem="papiano" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="specify" lemma="specify" stem="specifi" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="size" lemma="size" stem="size" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="settlement" lemma="settlement" stem="settlement" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="persuaded" lemma="persuade" stem="persuad" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="certainly" lemma="certainly" stem="certainli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="large" lemma="large" stem="larg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="enough" lemma="enough" stem="enough" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="should" lemma="should" stem="should" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="go" lemma="go" stem="go" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="trial" lemma="trial" stem="trial" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN Although) (S (NP (NNP Mr.) (NNP Papiano)) (VP (MD would) (RB n't) (VP (VB specify) (NP (NP (DT the) (NN size)) (PP (IN of) (NP (DT the) (NN settlement)))))))) (, ,) (NP (PRP he)) (VP (VBD said) (S (`` ``) (NP (PRP we)) (VP (VBD were) (VP (VBN persuaded) (SBAR (IN that) (S (NP (PRP it)) (VP (VBD was) (ADVP (RB certainly)) (ADJP (JJ large) (RB enough) (SBAR (IN that) (S (NP (PRP we)) (VP (MD should) (RB n't) (VP (VB go) (PP (TO to) (NP (NN trial))))))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="Mr. Papiano" type="NP">
          <tokens>
            <token id="2" string="Mr." />
            <token id="3" string="Papiano" />
          </tokens>
        </chunking>
        <chunking id="2" string="large enough that we should n't go to trial" type="ADJP">
          <tokens>
            <token id="23" string="large" />
            <token id="24" string="enough" />
            <token id="25" string="that" />
            <token id="26" string="we" />
            <token id="27" string="should" />
            <token id="28" string="n't" />
            <token id="29" string="go" />
            <token id="30" string="to" />
            <token id="31" string="trial" />
          </tokens>
        </chunking>
        <chunking id="3" string="were persuaded that it was certainly large enough that we should n't go to trial" type="VP">
          <tokens>
            <token id="17" string="were" />
            <token id="18" string="persuaded" />
            <token id="19" string="that" />
            <token id="20" string="it" />
            <token id="21" string="was" />
            <token id="22" string="certainly" />
            <token id="23" string="large" />
            <token id="24" string="enough" />
            <token id="25" string="that" />
            <token id="26" string="we" />
            <token id="27" string="should" />
            <token id="28" string="n't" />
            <token id="29" string="go" />
            <token id="30" string="to" />
            <token id="31" string="trial" />
          </tokens>
        </chunking>
        <chunking id="4" string="that it was certainly large enough that we should n't go to trial" type="SBAR">
          <tokens>
            <token id="19" string="that" />
            <token id="20" string="it" />
            <token id="21" string="was" />
            <token id="22" string="certainly" />
            <token id="23" string="large" />
            <token id="24" string="enough" />
            <token id="25" string="that" />
            <token id="26" string="we" />
            <token id="27" string="should" />
            <token id="28" string="n't" />
            <token id="29" string="go" />
            <token id="30" string="to" />
            <token id="31" string="trial" />
          </tokens>
        </chunking>
        <chunking id="5" string="said `` we were persuaded that it was certainly large enough that we should n't go to trial" type="VP">
          <tokens>
            <token id="14" string="said" />
            <token id="15" string="&quot;" />
            <token id="16" string="we" />
            <token id="17" string="were" />
            <token id="18" string="persuaded" />
            <token id="19" string="that" />
            <token id="20" string="it" />
            <token id="21" string="was" />
            <token id="22" string="certainly" />
            <token id="23" string="large" />
            <token id="24" string="enough" />
            <token id="25" string="that" />
            <token id="26" string="we" />
            <token id="27" string="should" />
            <token id="28" string="n't" />
            <token id="29" string="go" />
            <token id="30" string="to" />
            <token id="31" string="trial" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="20" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="the size" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="size" />
          </tokens>
        </chunking>
        <chunking id="8" string="we" type="NP">
          <tokens>
            <token id="16" string="we" />
          </tokens>
        </chunking>
        <chunking id="9" string="trial" type="NP">
          <tokens>
            <token id="31" string="trial" />
          </tokens>
        </chunking>
        <chunking id="10" string="would n't specify the size of the settlement" type="VP">
          <tokens>
            <token id="4" string="would" />
            <token id="5" string="n't" />
            <token id="6" string="specify" />
            <token id="7" string="the" />
            <token id="8" string="size" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="settlement" />
          </tokens>
        </chunking>
        <chunking id="11" string="go to trial" type="VP">
          <tokens>
            <token id="29" string="go" />
            <token id="30" string="to" />
            <token id="31" string="trial" />
          </tokens>
        </chunking>
        <chunking id="12" string="was certainly large enough that we should n't go to trial" type="VP">
          <tokens>
            <token id="21" string="was" />
            <token id="22" string="certainly" />
            <token id="23" string="large" />
            <token id="24" string="enough" />
            <token id="25" string="that" />
            <token id="26" string="we" />
            <token id="27" string="should" />
            <token id="28" string="n't" />
            <token id="29" string="go" />
            <token id="30" string="to" />
            <token id="31" string="trial" />
          </tokens>
        </chunking>
        <chunking id="13" string="persuaded that it was certainly large enough that we should n't go to trial" type="VP">
          <tokens>
            <token id="18" string="persuaded" />
            <token id="19" string="that" />
            <token id="20" string="it" />
            <token id="21" string="was" />
            <token id="22" string="certainly" />
            <token id="23" string="large" />
            <token id="24" string="enough" />
            <token id="25" string="that" />
            <token id="26" string="we" />
            <token id="27" string="should" />
            <token id="28" string="n't" />
            <token id="29" string="go" />
            <token id="30" string="to" />
            <token id="31" string="trial" />
          </tokens>
        </chunking>
        <chunking id="14" string="specify the size of the settlement" type="VP">
          <tokens>
            <token id="6" string="specify" />
            <token id="7" string="the" />
            <token id="8" string="size" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="settlement" />
          </tokens>
        </chunking>
        <chunking id="15" string="should n't go to trial" type="VP">
          <tokens>
            <token id="27" string="should" />
            <token id="28" string="n't" />
            <token id="29" string="go" />
            <token id="30" string="to" />
            <token id="31" string="trial" />
          </tokens>
        </chunking>
        <chunking id="16" string="the settlement" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="settlement" />
          </tokens>
        </chunking>
        <chunking id="17" string="Although Mr. Papiano would n't specify the size of the settlement" type="SBAR">
          <tokens>
            <token id="1" string="Although" />
            <token id="2" string="Mr." />
            <token id="3" string="Papiano" />
            <token id="4" string="would" />
            <token id="5" string="n't" />
            <token id="6" string="specify" />
            <token id="7" string="the" />
            <token id="8" string="size" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="settlement" />
          </tokens>
        </chunking>
        <chunking id="18" string="he" type="NP">
          <tokens>
            <token id="13" string="he" />
          </tokens>
        </chunking>
        <chunking id="19" string="the size of the settlement" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="size" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="settlement" />
          </tokens>
        </chunking>
        <chunking id="20" string="that we should n't go to trial" type="SBAR">
          <tokens>
            <token id="25" string="that" />
            <token id="26" string="we" />
            <token id="27" string="should" />
            <token id="28" string="n't" />
            <token id="29" string="go" />
            <token id="30" string="to" />
            <token id="31" string="trial" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="6">specify</governor>
          <dependent id="1">Although</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Papiano</governor>
          <dependent id="2">Mr.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">specify</governor>
          <dependent id="3">Papiano</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">specify</governor>
          <dependent id="4">would</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">specify</governor>
          <dependent id="5">n't</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="14">said</governor>
          <dependent id="6">specify</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">size</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">specify</governor>
          <dependent id="8">size</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">settlement</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">settlement</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">size</governor>
          <dependent id="11">settlement</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">said</governor>
          <dependent id="13">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">said</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="18">persuaded</governor>
          <dependent id="16">we</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="18">persuaded</governor>
          <dependent id="17">were</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">said</governor>
          <dependent id="18">persuaded</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">large</governor>
          <dependent id="19">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">large</governor>
          <dependent id="20">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="23">large</governor>
          <dependent id="21">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="23">large</governor>
          <dependent id="22">certainly</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="18">persuaded</governor>
          <dependent id="23">large</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="23">large</governor>
          <dependent id="24">enough</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="29">go</governor>
          <dependent id="25">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">go</governor>
          <dependent id="26">we</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="29">go</governor>
          <dependent id="27">should</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="29">go</governor>
          <dependent id="28">n't</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="23">large</governor>
          <dependent id="29">go</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">trial</governor>
          <dependent id="30">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">go</governor>
          <dependent id="31">trial</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Papiano" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Papiano" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>As previously reported, G.P. Group Inc., the Lantana, Fla., publisher of the Enquirer and Star tabloids, plans to raise $350 million by offering 43% of the firm in an initial public offering.</content>
      <tokens>
        <token id="1" string="As" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="previously" lemma="previously" stem="previous" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="reported" lemma="report" stem="report" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="G.P." lemma="G.P." stem="g.p." pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="6" string="Group" lemma="Group" stem="group" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="7" string="Inc." lemma="Inc." stem="inc." pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Lantana" lemma="Lantana" stem="lantana" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Fla." lemma="Fla." stem="fla." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="publisher" lemma="publisher" stem="publish" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Enquirer" lemma="Enquirer" stem="enquirer" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Star" lemma="Star" stem="star" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="20" string="tabloids" lemma="tabloid" stem="tabloid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="plans" lemma="plan" stem="plan" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="raise" lemma="raise" stem="rais" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="26" string="350" lemma="350" stem="350" pos="CD" type="Number" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="27" string="million" lemma="million" stem="million" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="28" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="offering" lemma="offer" stem="offer" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="43" lemma="43" stem="43" pos="CD" type="Number" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="31" string="%" lemma="%" stem="%" pos="NN" type="Symbol" isStopWord="true" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="32" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="firm" lemma="firm" stem="firm" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="initial" lemma="initial" stem="initi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="public" lemma="public" stem="public" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="offering" lemma="offering" stem="offer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN As) (S (ADVP (RB previously)) (VP (VBN reported)))) (, ,) (NP (NP (NNP G.P.) (NNP Group) (NNP Inc.)) (, ,) (NP (NP (DT the) (NNP Lantana) (, ,) (NNP Fla.) (, ,) (NN publisher)) (PP (IN of) (NP (DT the) (NNP Enquirer) (CC and) (NNP Star) (NNS tabloids)))) (, ,)) (VP (VBZ plans) (S (VP (TO to) (VP (VB raise) (NP (QP ($ $) (CD 350) (CD million))) (PP (IN by) (S (VP (VBG offering) (NP (NP (CD 43) (NN %)) (PP (IN of) (NP (NP (DT the) (NN firm)) (PP (IN in) (NP (DT an) (JJ initial) (JJ public) (NN offering))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="offering 43 % of the firm in an initial public offering" type="VP">
          <tokens>
            <token id="29" string="offering" />
            <token id="30" string="43" />
            <token id="31" string="%" />
            <token id="32" string="of" />
            <token id="33" string="the" />
            <token id="34" string="firm" />
            <token id="35" string="in" />
            <token id="36" string="an" />
            <token id="37" string="initial" />
            <token id="38" string="public" />
            <token id="39" string="offering" />
          </tokens>
        </chunking>
        <chunking id="2" string="G.P. Group Inc. , the Lantana , Fla. , publisher of the Enquirer and Star tabloids ," type="NP">
          <tokens>
            <token id="5" string="G.P." />
            <token id="6" string="Group" />
            <token id="7" string="Inc." />
            <token id="8" string="," />
            <token id="9" string="the" />
            <token id="10" string="Lantana" />
            <token id="11" string="," />
            <token id="12" string="Fla." />
            <token id="13" string="," />
            <token id="14" string="publisher" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="Enquirer" />
            <token id="18" string="and" />
            <token id="19" string="Star" />
            <token id="20" string="tabloids" />
            <token id="21" string="," />
          </tokens>
        </chunking>
        <chunking id="3" string="the Lantana , Fla. , publisher of the Enquirer and Star tabloids" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="Lantana" />
            <token id="11" string="," />
            <token id="12" string="Fla." />
            <token id="13" string="," />
            <token id="14" string="publisher" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="Enquirer" />
            <token id="18" string="and" />
            <token id="19" string="Star" />
            <token id="20" string="tabloids" />
          </tokens>
        </chunking>
        <chunking id="4" string="$ 350 million" type="NP">
          <tokens>
            <token id="25" string="$" />
            <token id="26" string="350" />
            <token id="27" string="million" />
          </tokens>
        </chunking>
        <chunking id="5" string="the firm in an initial public offering" type="NP">
          <tokens>
            <token id="33" string="the" />
            <token id="34" string="firm" />
            <token id="35" string="in" />
            <token id="36" string="an" />
            <token id="37" string="initial" />
            <token id="38" string="public" />
            <token id="39" string="offering" />
          </tokens>
        </chunking>
        <chunking id="6" string="43 % of the firm in an initial public offering" type="NP">
          <tokens>
            <token id="30" string="43" />
            <token id="31" string="%" />
            <token id="32" string="of" />
            <token id="33" string="the" />
            <token id="34" string="firm" />
            <token id="35" string="in" />
            <token id="36" string="an" />
            <token id="37" string="initial" />
            <token id="38" string="public" />
            <token id="39" string="offering" />
          </tokens>
        </chunking>
        <chunking id="7" string="As previously reported" type="SBAR">
          <tokens>
            <token id="1" string="As" />
            <token id="2" string="previously" />
            <token id="3" string="reported" />
          </tokens>
        </chunking>
        <chunking id="8" string="G.P. Group Inc." type="NP">
          <tokens>
            <token id="5" string="G.P." />
            <token id="6" string="Group" />
            <token id="7" string="Inc." />
          </tokens>
        </chunking>
        <chunking id="9" string="plans to raise $ 350 million by offering 43 % of the firm in an initial public offering" type="VP">
          <tokens>
            <token id="22" string="plans" />
            <token id="23" string="to" />
            <token id="24" string="raise" />
            <token id="25" string="$" />
            <token id="26" string="350" />
            <token id="27" string="million" />
            <token id="28" string="by" />
            <token id="29" string="offering" />
            <token id="30" string="43" />
            <token id="31" string="%" />
            <token id="32" string="of" />
            <token id="33" string="the" />
            <token id="34" string="firm" />
            <token id="35" string="in" />
            <token id="36" string="an" />
            <token id="37" string="initial" />
            <token id="38" string="public" />
            <token id="39" string="offering" />
          </tokens>
        </chunking>
        <chunking id="10" string="an initial public offering" type="NP">
          <tokens>
            <token id="36" string="an" />
            <token id="37" string="initial" />
            <token id="38" string="public" />
            <token id="39" string="offering" />
          </tokens>
        </chunking>
        <chunking id="11" string="the Lantana , Fla. , publisher" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="Lantana" />
            <token id="11" string="," />
            <token id="12" string="Fla." />
            <token id="13" string="," />
            <token id="14" string="publisher" />
          </tokens>
        </chunking>
        <chunking id="12" string="the firm" type="NP">
          <tokens>
            <token id="33" string="the" />
            <token id="34" string="firm" />
          </tokens>
        </chunking>
        <chunking id="13" string="reported" type="VP">
          <tokens>
            <token id="3" string="reported" />
          </tokens>
        </chunking>
        <chunking id="14" string="to raise $ 350 million by offering 43 % of the firm in an initial public offering" type="VP">
          <tokens>
            <token id="23" string="to" />
            <token id="24" string="raise" />
            <token id="25" string="$" />
            <token id="26" string="350" />
            <token id="27" string="million" />
            <token id="28" string="by" />
            <token id="29" string="offering" />
            <token id="30" string="43" />
            <token id="31" string="%" />
            <token id="32" string="of" />
            <token id="33" string="the" />
            <token id="34" string="firm" />
            <token id="35" string="in" />
            <token id="36" string="an" />
            <token id="37" string="initial" />
            <token id="38" string="public" />
            <token id="39" string="offering" />
          </tokens>
        </chunking>
        <chunking id="15" string="43 %" type="NP">
          <tokens>
            <token id="30" string="43" />
            <token id="31" string="%" />
          </tokens>
        </chunking>
        <chunking id="16" string="the Enquirer and Star tabloids" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="Enquirer" />
            <token id="18" string="and" />
            <token id="19" string="Star" />
            <token id="20" string="tabloids" />
          </tokens>
        </chunking>
        <chunking id="17" string="raise $ 350 million by offering 43 % of the firm in an initial public offering" type="VP">
          <tokens>
            <token id="24" string="raise" />
            <token id="25" string="$" />
            <token id="26" string="350" />
            <token id="27" string="million" />
            <token id="28" string="by" />
            <token id="29" string="offering" />
            <token id="30" string="43" />
            <token id="31" string="%" />
            <token id="32" string="of" />
            <token id="33" string="the" />
            <token id="34" string="firm" />
            <token id="35" string="in" />
            <token id="36" string="an" />
            <token id="37" string="initial" />
            <token id="38" string="public" />
            <token id="39" string="offering" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="3">reported</governor>
          <dependent id="1">As</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">reported</governor>
          <dependent id="2">previously</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="22">plans</governor>
          <dependent id="3">reported</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Inc.</governor>
          <dependent id="5">G.P.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Inc.</governor>
          <dependent id="6">Group</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">plans</governor>
          <dependent id="7">Inc.</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">publisher</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">publisher</governor>
          <dependent id="10">Lantana</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="14">publisher</governor>
          <dependent id="12">Fla.</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="7">Inc.</governor>
          <dependent id="14">publisher</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">tabloids</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">tabloids</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">tabloids</governor>
          <dependent id="17">Enquirer</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">Enquirer</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">Enquirer</governor>
          <dependent id="19">Star</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">publisher</governor>
          <dependent id="20">tabloids</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="22">plans</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">raise</governor>
          <dependent id="23">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="22">plans</governor>
          <dependent id="24">raise</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">raise</governor>
          <dependent id="25">$</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">million</governor>
          <dependent id="26">350</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="25">$</governor>
          <dependent id="27">million</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="29">offering</governor>
          <dependent id="28">by</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="24">raise</governor>
          <dependent id="29">offering</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="31">%</governor>
          <dependent id="30">43</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="29">offering</governor>
          <dependent id="31">%</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">firm</governor>
          <dependent id="32">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">firm</governor>
          <dependent id="33">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">%</governor>
          <dependent id="34">firm</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">offering</governor>
          <dependent id="35">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="39">offering</governor>
          <dependent id="36">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="39">offering</governor>
          <dependent id="37">initial</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="39">offering</governor>
          <dependent id="38">public</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="34">firm</governor>
          <dependent id="39">offering</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="previously" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="previously" />
          </tokens>
        </entity>
        <entity id="2" string="Fla." type="LOCATION" score="0.0">
          <tokens>
            <token id="12" string="Fla." />
          </tokens>
        </entity>
        <entity id="3" string="$ 350 million" type="MONEY" score="0.0">
          <tokens>
            <token id="25" string="$" />
            <token id="26" string="350" />
            <token id="27" string="million" />
          </tokens>
        </entity>
        <entity id="4" string="Enquirer" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="17" string="Enquirer" />
          </tokens>
        </entity>
        <entity id="5" string="Star" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="19" string="Star" />
          </tokens>
        </entity>
        <entity id="6" string="G.P. Group Inc." type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="5" string="G.P." />
            <token id="6" string="Group" />
            <token id="7" string="Inc." />
          </tokens>
        </entity>
        <entity id="7" string="Lantana" type="LOCATION" score="0.0">
          <tokens>
            <token id="10" string="Lantana" />
          </tokens>
        </entity>
        <entity id="8" string="43 %" type="PERCENT" score="0.0">
          <tokens>
            <token id="30" string="43" />
            <token id="31" string="%" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="1-2" string="The Enquirer" id_sentence="2" />
      <mentions>
        <mention ids_tokens="4" string="Enquirer" id_sentence="4" />
        <mention ids_tokens="17" string="Enquirer" id_sentence="8" />
      </mentions>
    </coreference>
    <coreference id="2" type="PROPER">
      <referenced ids_tokens="26-27-28" string="Miss Taylor 's" id_sentence="1" />
      <mentions>
        <mention ids_tokens="12-13" string="Taylor's" id_sentence="2" />
        <mention ids_tokens="1-2" string="Miss Taylor" id_sentence="5" />
        <mention ids_tokens="4" string="she" id_sentence="5" />
        <mention ids_tokens="1-2" string="Miss Taylor" id_sentence="6" />
        <mention ids_tokens="21" string="her" id_sentence="6" />
      </mentions>
    </coreference>
    <coreference id="3" type="NOMINAL">
      <referenced ids_tokens="21-22-23-24-25-26-27-28-29-30-31-32-33-34-35-36" string="the articles reporting on the actress 's medical condition and the report that she was drinking" id_sentence="2" />
      <mentions>
        <mention ids_tokens="6-7" string="the articles" id_sentence="3" />
        <mention ids_tokens="18-19" string="the articles" id_sentence="4" />
        <mention ids_tokens="19-20" string="the articles" id_sentence="5" />
      </mentions>
    </coreference>
    <coreference id="8" type="PROPER">
      <referenced ids_tokens="18-19" string="Neil Papiano" id_sentence="6" />
      <mentions>
        <mention ids_tokens="2-3" string="Mr. Papiano" id_sentence="7" />
        <mention ids_tokens="13" string="he" id_sentence="7" />
      </mentions>
    </coreference>
  </coreferences>
</document>
