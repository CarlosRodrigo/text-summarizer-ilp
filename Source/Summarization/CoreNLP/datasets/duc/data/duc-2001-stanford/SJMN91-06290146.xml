<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="SJMN91-06290146">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>As the climactic votes that put her son on the Supreme Court were cast hundreds of miles away in Washington, Leola Williams jumped from her chair, hugged a neighbor and then began to sing a spiritual, &amp;quot;Jesus Keep Me Near the Cross.&amp;quot;</content>
      <tokens>
        <token id="1" string="As" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="climactic" lemma="climactic" stem="climact" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="votes" lemma="vote" stem="vote" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="put" lemma="put" stem="put" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="her" lemma="she" stem="her" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="son" lemma="son" stem="son" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Supreme" lemma="Supreme" stem="suprem" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="12" string="Court" lemma="Court" stem="court" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="13" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="cast" lemma="cast" stem="cast" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="hundreds" lemma="hundred" stem="hundr" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="miles" lemma="mile" stem="mile" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="away" lemma="away" stem="awai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Washington" lemma="Washington" stem="washington" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="Leola" lemma="Leola" stem="leola" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="23" string="Williams" lemma="Williams" stem="william" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="24" string="jumped" lemma="jump" stem="jump" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="chair" lemma="chair" stem="chair" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="hugged" lemma="hug" stem="hug" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="neighbor" lemma="neighbor" stem="neighbor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="began" lemma="begin" stem="began" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="sing" lemma="sing" stem="sing" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="spiritual" lemma="spiritual" stem="spiritu" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="Jesus" lemma="Jesus" stem="jesu" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="Keep" lemma="keep" stem="keep" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="Me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="Near" lemma="near" stem="near" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="Cross" lemma="cross" stem="cross" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="47" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="48" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN As) (S (NP (NP (DT the) (JJ climactic) (NNS votes)) (SBAR (WHNP (WDT that)) (S (VP (VBD put) (NP (PRP her)) (NP (NP (NN son)) (PP (IN on) (NP (DT the) (NNP Supreme) (NNP Court)))))))) (VP (VBD were) (VP (VBN cast) (NP (NP (NNS hundreds)) (PP (IN of) (NP (NNS miles)))) (ADVP (RB away) (PP (IN in) (NP (NNP Washington)))))))) (, ,) (PRN (S (NP (NNP Leola) (NNP Williams)) (VP (VP (VBD jumped) (PP (IN from) (NP (PRP$ her) (NN chair)))) (, ,) (VP (VBD hugged) (NP (DT a) (NN neighbor))) (CC and) (VP (ADVP (RB then)) (VBD began) (S (VP (TO to) (VP (VB sing) (NP (DT a) (JJ spiritual)))))))) (, ,)) (`` ``) (NP (NNP Jesus)) (VP (VB Keep) (S (NP (PRP Me)) (PP (IN Near) (NP (DT the) (NN Cross))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="Keep Me Near the Cross" type="VP">
          <tokens>
            <token id="42" string="Keep" />
            <token id="43" string="Me" />
            <token id="44" string="Near" />
            <token id="45" string="the" />
            <token id="46" string="Cross" />
          </tokens>
        </chunking>
        <chunking id="2" string="the Cross" type="NP">
          <tokens>
            <token id="45" string="the" />
            <token id="46" string="Cross" />
          </tokens>
        </chunking>
        <chunking id="3" string="As the climactic votes that put her son on the Supreme Court were cast hundreds of miles away in Washington" type="SBAR">
          <tokens>
            <token id="1" string="As" />
            <token id="2" string="the" />
            <token id="3" string="climactic" />
            <token id="4" string="votes" />
            <token id="5" string="that" />
            <token id="6" string="put" />
            <token id="7" string="her" />
            <token id="8" string="son" />
            <token id="9" string="on" />
            <token id="10" string="the" />
            <token id="11" string="Supreme" />
            <token id="12" string="Court" />
            <token id="13" string="were" />
            <token id="14" string="cast" />
            <token id="15" string="hundreds" />
            <token id="16" string="of" />
            <token id="17" string="miles" />
            <token id="18" string="away" />
            <token id="19" string="in" />
            <token id="20" string="Washington" />
          </tokens>
        </chunking>
        <chunking id="4" string="jumped from her chair , hugged a neighbor and then began to sing a spiritual" type="VP">
          <tokens>
            <token id="24" string="jumped" />
            <token id="25" string="from" />
            <token id="26" string="her" />
            <token id="27" string="chair" />
            <token id="28" string="," />
            <token id="29" string="hugged" />
            <token id="30" string="a" />
            <token id="31" string="neighbor" />
            <token id="32" string="and" />
            <token id="33" string="then" />
            <token id="34" string="began" />
            <token id="35" string="to" />
            <token id="36" string="sing" />
            <token id="37" string="a" />
            <token id="38" string="spiritual" />
          </tokens>
        </chunking>
        <chunking id="5" string="that put her son on the Supreme Court" type="SBAR">
          <tokens>
            <token id="5" string="that" />
            <token id="6" string="put" />
            <token id="7" string="her" />
            <token id="8" string="son" />
            <token id="9" string="on" />
            <token id="10" string="the" />
            <token id="11" string="Supreme" />
            <token id="12" string="Court" />
          </tokens>
        </chunking>
        <chunking id="6" string="son on the Supreme Court" type="NP">
          <tokens>
            <token id="8" string="son" />
            <token id="9" string="on" />
            <token id="10" string="the" />
            <token id="11" string="Supreme" />
            <token id="12" string="Court" />
          </tokens>
        </chunking>
        <chunking id="7" string="the Supreme Court" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="Supreme" />
            <token id="12" string="Court" />
          </tokens>
        </chunking>
        <chunking id="8" string="cast hundreds of miles away in Washington" type="VP">
          <tokens>
            <token id="14" string="cast" />
            <token id="15" string="hundreds" />
            <token id="16" string="of" />
            <token id="17" string="miles" />
            <token id="18" string="away" />
            <token id="19" string="in" />
            <token id="20" string="Washington" />
          </tokens>
        </chunking>
        <chunking id="9" string="sing a spiritual" type="VP">
          <tokens>
            <token id="36" string="sing" />
            <token id="37" string="a" />
            <token id="38" string="spiritual" />
          </tokens>
        </chunking>
        <chunking id="10" string="Me" type="NP">
          <tokens>
            <token id="43" string="Me" />
          </tokens>
        </chunking>
        <chunking id="11" string="to sing a spiritual" type="VP">
          <tokens>
            <token id="35" string="to" />
            <token id="36" string="sing" />
            <token id="37" string="a" />
            <token id="38" string="spiritual" />
          </tokens>
        </chunking>
        <chunking id="12" string="hugged a neighbor" type="VP">
          <tokens>
            <token id="29" string="hugged" />
            <token id="30" string="a" />
            <token id="31" string="neighbor" />
          </tokens>
        </chunking>
        <chunking id="13" string="jumped from her chair" type="VP">
          <tokens>
            <token id="24" string="jumped" />
            <token id="25" string="from" />
            <token id="26" string="her" />
            <token id="27" string="chair" />
          </tokens>
        </chunking>
        <chunking id="14" string="put her son on the Supreme Court" type="VP">
          <tokens>
            <token id="6" string="put" />
            <token id="7" string="her" />
            <token id="8" string="son" />
            <token id="9" string="on" />
            <token id="10" string="the" />
            <token id="11" string="Supreme" />
            <token id="12" string="Court" />
          </tokens>
        </chunking>
        <chunking id="15" string="hundreds of miles" type="NP">
          <tokens>
            <token id="15" string="hundreds" />
            <token id="16" string="of" />
            <token id="17" string="miles" />
          </tokens>
        </chunking>
        <chunking id="16" string="the climactic votes" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="climactic" />
            <token id="4" string="votes" />
          </tokens>
        </chunking>
        <chunking id="17" string="a spiritual" type="NP">
          <tokens>
            <token id="37" string="a" />
            <token id="38" string="spiritual" />
          </tokens>
        </chunking>
        <chunking id="18" string="then began to sing a spiritual" type="VP">
          <tokens>
            <token id="33" string="then" />
            <token id="34" string="began" />
            <token id="35" string="to" />
            <token id="36" string="sing" />
            <token id="37" string="a" />
            <token id="38" string="spiritual" />
          </tokens>
        </chunking>
        <chunking id="19" string="miles" type="NP">
          <tokens>
            <token id="17" string="miles" />
          </tokens>
        </chunking>
        <chunking id="20" string="son" type="NP">
          <tokens>
            <token id="8" string="son" />
          </tokens>
        </chunking>
        <chunking id="21" string="her chair" type="NP">
          <tokens>
            <token id="26" string="her" />
            <token id="27" string="chair" />
          </tokens>
        </chunking>
        <chunking id="22" string="the climactic votes that put her son on the Supreme Court" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="climactic" />
            <token id="4" string="votes" />
            <token id="5" string="that" />
            <token id="6" string="put" />
            <token id="7" string="her" />
            <token id="8" string="son" />
            <token id="9" string="on" />
            <token id="10" string="the" />
            <token id="11" string="Supreme" />
            <token id="12" string="Court" />
          </tokens>
        </chunking>
        <chunking id="23" string="Washington" type="NP">
          <tokens>
            <token id="20" string="Washington" />
          </tokens>
        </chunking>
        <chunking id="24" string="a neighbor" type="NP">
          <tokens>
            <token id="30" string="a" />
            <token id="31" string="neighbor" />
          </tokens>
        </chunking>
        <chunking id="25" string="were cast hundreds of miles away in Washington" type="VP">
          <tokens>
            <token id="13" string="were" />
            <token id="14" string="cast" />
            <token id="15" string="hundreds" />
            <token id="16" string="of" />
            <token id="17" string="miles" />
            <token id="18" string="away" />
            <token id="19" string="in" />
            <token id="20" string="Washington" />
          </tokens>
        </chunking>
        <chunking id="26" string="Leola Williams" type="NP">
          <tokens>
            <token id="22" string="Leola" />
            <token id="23" string="Williams" />
          </tokens>
        </chunking>
        <chunking id="27" string="her" type="NP">
          <tokens>
            <token id="7" string="her" />
          </tokens>
        </chunking>
        <chunking id="28" string="Jesus" type="NP">
          <tokens>
            <token id="41" string="Jesus" />
          </tokens>
        </chunking>
        <chunking id="29" string="hundreds" type="NP">
          <tokens>
            <token id="15" string="hundreds" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="14">cast</governor>
          <dependent id="1">As</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">votes</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">votes</governor>
          <dependent id="3">climactic</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="14">cast</governor>
          <dependent id="4">votes</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">put</governor>
          <dependent id="5">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="4">votes</governor>
          <dependent id="6">put</dependent>
        </dependency>
        <dependency type="iobj">
          <governor id="6">put</governor>
          <dependent id="7">her</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">put</governor>
          <dependent id="8">son</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Court</governor>
          <dependent id="9">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">Court</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Court</governor>
          <dependent id="11">Supreme</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">son</governor>
          <dependent id="12">Court</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="14">cast</governor>
          <dependent id="13">were</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="42">Keep</governor>
          <dependent id="14">cast</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">cast</governor>
          <dependent id="15">hundreds</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">miles</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">hundreds</governor>
          <dependent id="17">miles</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">cast</governor>
          <dependent id="18">away</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">Washington</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">away</governor>
          <dependent id="20">Washington</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">Williams</governor>
          <dependent id="22">Leola</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">jumped</governor>
          <dependent id="23">Williams</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="42">Keep</governor>
          <dependent id="24">jumped</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">chair</governor>
          <dependent id="25">from</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="27">chair</governor>
          <dependent id="26">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">jumped</governor>
          <dependent id="27">chair</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="24">jumped</governor>
          <dependent id="29">hugged</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">neighbor</governor>
          <dependent id="30">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="29">hugged</governor>
          <dependent id="31">neighbor</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="24">jumped</governor>
          <dependent id="32">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="34">began</governor>
          <dependent id="33">then</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="24">jumped</governor>
          <dependent id="34">began</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="36">sing</governor>
          <dependent id="35">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="34">began</governor>
          <dependent id="36">sing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="38">spiritual</governor>
          <dependent id="37">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="36">sing</governor>
          <dependent id="38">spiritual</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="42">Keep</governor>
          <dependent id="41">Jesus</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="42">Keep</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="42">Keep</governor>
          <dependent id="43">Me</dependent>
        </dependency>
        <dependency type="case">
          <governor id="46">Cross</governor>
          <dependent id="44">Near</dependent>
        </dependency>
        <dependency type="det">
          <governor id="46">Cross</governor>
          <dependent id="45">the</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="43">Me</governor>
          <dependent id="46">Cross</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Supreme Court" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="11" string="Supreme" />
            <token id="12" string="Court" />
          </tokens>
        </entity>
        <entity id="2" string="Washington" type="LOCATION" score="0.0">
          <tokens>
            <token id="20" string="Washington" />
          </tokens>
        </entity>
        <entity id="3" string="Leola Williams" type="PERSON" score="0.0">
          <tokens>
            <token id="22" string="Leola" />
            <token id="23" string="Williams" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>; Never had she doubted the outcome, Williams said a short time later.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="doubted" lemma="doubt" stem="doubt" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="outcome" lemma="outcome" stem="outcom" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Williams" lemma="Williams" stem="william" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="10" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="short" lemma="short" stem="short" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="later" lemma="later" stem="later" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (S (ADVP (RB Never) (SBAR (VBD had) (S (NP (PRP she)) (VP (VBD doubted) (NP (DT the) (NN outcome)))))) (, ,) (NP (NNP Williams)) (VP (VBD said) (NP (DT a) (JJ short) (NN time)) (ADVP (RB later)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="said a short time later" type="VP">
          <tokens>
            <token id="10" string="said" />
            <token id="11" string="a" />
            <token id="12" string="short" />
            <token id="13" string="time" />
            <token id="14" string="later" />
          </tokens>
        </chunking>
        <chunking id="2" string="the outcome" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="outcome" />
          </tokens>
        </chunking>
        <chunking id="3" string="a short time" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="short" />
            <token id="13" string="time" />
          </tokens>
        </chunking>
        <chunking id="4" string="Williams" type="NP">
          <tokens>
            <token id="9" string="Williams" />
          </tokens>
        </chunking>
        <chunking id="5" string="doubted the outcome" type="VP">
          <tokens>
            <token id="5" string="doubted" />
            <token id="6" string="the" />
            <token id="7" string="outcome" />
          </tokens>
        </chunking>
        <chunking id="6" string="she" type="NP">
          <tokens>
            <token id="4" string="she" />
          </tokens>
        </chunking>
        <chunking id="7" string="had she doubted the outcome" type="SBAR">
          <tokens>
            <token id="3" string="had" />
            <token id="4" string="she" />
            <token id="5" string="doubted" />
            <token id="6" string="the" />
            <token id="7" string="outcome" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="neg">
          <governor id="10">said</governor>
          <dependent id="2">Never</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="5">doubted</governor>
          <dependent id="3">had</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">doubted</governor>
          <dependent id="4">she</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="2">Never</governor>
          <dependent id="5">doubted</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">outcome</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">doubted</governor>
          <dependent id="7">outcome</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">said</governor>
          <dependent id="9">Williams</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">time</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">time</governor>
          <dependent id="12">short</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">said</governor>
          <dependent id="13">time</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">said</governor>
          <dependent id="14">later</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Williams" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Williams" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>&amp;quot;I didn&amp;apost;t give my child up and I never would,&amp;quot; she said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="give" lemma="give" stem="give" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="child" lemma="child" stem="child" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="up" lemma="up" stem="up" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (S (NP (PRP I)) (VP (VBD did) (RB n't) (VP (VB give) (NP (PRP$ my) (NN child)) (ADVP (RB up))))) (CC and) (S (NP (PRP I)) (ADVP (RB never)) (VP (MD would)))) (, ,) ('' '') (NP (PRP she)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="would" type="VP">
          <tokens>
            <token id="12" string="would" />
          </tokens>
        </chunking>
        <chunking id="2" string="my child" type="NP">
          <tokens>
            <token id="6" string="my" />
            <token id="7" string="child" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="did n't give my child up" type="VP">
          <tokens>
            <token id="3" string="did" />
            <token id="4" string="n't" />
            <token id="5" string="give" />
            <token id="6" string="my" />
            <token id="7" string="child" />
            <token id="8" string="up" />
          </tokens>
        </chunking>
        <chunking id="5" string="said" type="VP">
          <tokens>
            <token id="16" string="said" />
          </tokens>
        </chunking>
        <chunking id="6" string="give my child up" type="VP">
          <tokens>
            <token id="5" string="give" />
            <token id="6" string="my" />
            <token id="7" string="child" />
            <token id="8" string="up" />
          </tokens>
        </chunking>
        <chunking id="7" string="she" type="NP">
          <tokens>
            <token id="15" string="she" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">give</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">give</governor>
          <dependent id="3">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">give</governor>
          <dependent id="4">n't</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">said</governor>
          <dependent id="5">give</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">child</governor>
          <dependent id="6">my</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">give</governor>
          <dependent id="7">child</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">give</governor>
          <dependent id="8">up</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">give</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">would</governor>
          <dependent id="10">I</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="12">would</governor>
          <dependent id="11">never</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">give</governor>
          <dependent id="12">would</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">said</governor>
          <dependent id="15">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">said</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>Then she excused herself to place a phone call to her son, Clarence Thomas.</content>
      <tokens>
        <token id="1" string="Then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="excused" lemma="excuse" stem="excus" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="herself" lemma="herself" stem="herself" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="place" lemma="place" stem="place" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="phone" lemma="phone" stem="phone" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="call" lemma="call" stem="call" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="son" lemma="son" stem="son" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="Clarence" lemma="Clarence" stem="clarenc" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="15" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (RB Then) (NP (PRP she)) (VP (VBD excused) (S (NP (PRP herself)) (VP (TO to) (VP (VB place) (NP (DT a) (NN phone) (NN call)) (PP (TO to) (NP (NP (PRP$ her) (NN son)) (, ,) (NP (NNP Clarence) (NNP Thomas)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a phone call" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="phone" />
            <token id="9" string="call" />
          </tokens>
        </chunking>
        <chunking id="2" string="excused herself to place a phone call to her son , Clarence Thomas" type="VP">
          <tokens>
            <token id="3" string="excused" />
            <token id="4" string="herself" />
            <token id="5" string="to" />
            <token id="6" string="place" />
            <token id="7" string="a" />
            <token id="8" string="phone" />
            <token id="9" string="call" />
            <token id="10" string="to" />
            <token id="11" string="her" />
            <token id="12" string="son" />
            <token id="13" string="," />
            <token id="14" string="Clarence" />
            <token id="15" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="3" string="to place a phone call to her son , Clarence Thomas" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="place" />
            <token id="7" string="a" />
            <token id="8" string="phone" />
            <token id="9" string="call" />
            <token id="10" string="to" />
            <token id="11" string="her" />
            <token id="12" string="son" />
            <token id="13" string="," />
            <token id="14" string="Clarence" />
            <token id="15" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="4" string="herself" type="NP">
          <tokens>
            <token id="4" string="herself" />
          </tokens>
        </chunking>
        <chunking id="5" string="place a phone call to her son , Clarence Thomas" type="VP">
          <tokens>
            <token id="6" string="place" />
            <token id="7" string="a" />
            <token id="8" string="phone" />
            <token id="9" string="call" />
            <token id="10" string="to" />
            <token id="11" string="her" />
            <token id="12" string="son" />
            <token id="13" string="," />
            <token id="14" string="Clarence" />
            <token id="15" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="6" string="she" type="NP">
          <tokens>
            <token id="2" string="she" />
          </tokens>
        </chunking>
        <chunking id="7" string="her son" type="NP">
          <tokens>
            <token id="11" string="her" />
            <token id="12" string="son" />
          </tokens>
        </chunking>
        <chunking id="8" string="her son , Clarence Thomas" type="NP">
          <tokens>
            <token id="11" string="her" />
            <token id="12" string="son" />
            <token id="13" string="," />
            <token id="14" string="Clarence" />
            <token id="15" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="9" string="Clarence Thomas" type="NP">
          <tokens>
            <token id="14" string="Clarence" />
            <token id="15" string="Thomas" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="3">excused</governor>
          <dependent id="1">Then</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">excused</governor>
          <dependent id="2">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">excused</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">excused</governor>
          <dependent id="4">herself</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">place</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">excused</governor>
          <dependent id="6">place</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">call</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">call</governor>
          <dependent id="8">phone</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">place</governor>
          <dependent id="9">call</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">son</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">son</governor>
          <dependent id="11">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">place</governor>
          <dependent id="12">son</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Thomas</governor>
          <dependent id="14">Clarence</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="12">son</governor>
          <dependent id="15">Thomas</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Clarence Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Clarence" />
            <token id="15" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>What would she tell him?</content>
      <tokens>
        <token id="1" string="What" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="tell" lemma="tell" stem="tell" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SBARQ (WHNP (WP What)) (SQ (MD would) (NP (PRP she)) (VP (VB tell) (NP (PRP him)))) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="tell him" type="VP">
          <tokens>
            <token id="4" string="tell" />
            <token id="5" string="him" />
          </tokens>
        </chunking>
        <chunking id="2" string="him" type="NP">
          <tokens>
            <token id="5" string="him" />
          </tokens>
        </chunking>
        <chunking id="3" string="she" type="NP">
          <tokens>
            <token id="3" string="she" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="dep">
          <governor id="4">tell</governor>
          <dependent id="1">What</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">tell</governor>
          <dependent id="2">would</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">tell</governor>
          <dependent id="3">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">tell</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">tell</governor>
          <dependent id="5">him</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>&amp;quot;I love you.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="love" lemma="love" stem="love" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (VBP love) (NP (PRP you))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="2" string="love you" type="VP">
          <tokens>
            <token id="3" string="love" />
            <token id="4" string="you" />
          </tokens>
        </chunking>
        <chunking id="3" string="you" type="NP">
          <tokens>
            <token id="4" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">love</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">love</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">love</governor>
          <dependent id="4">you</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>And, a reporter asked, what would she say to Anita Hill if she had the chance?</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="reporter" lemma="reporter" stem="report" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="asked" lemma="ask" stem="ask" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="say" lemma="say" stem="sai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Anita" lemma="Anita" stem="anita" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="13" string="Hill" lemma="Hill" stem="hill" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="14" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="chance" lemma="chance" stem="chanc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC And) (, ,) (NP (DT a) (NN reporter)) (VP (VP (VBD asked) (, ,) (SBARQ (WHNP (WP what)) (SQ (MD would) (NP (PRP she)) (VP (VB say) (PP (TO to) (NP (NNP Anita) (NNP Hill))))))) (SBAR (IN if) (S (NP (PRP she)) (VP (VBD had) (NP (DT the) (NN chance)))))) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Anita Hill" type="NP">
          <tokens>
            <token id="12" string="Anita" />
            <token id="13" string="Hill" />
          </tokens>
        </chunking>
        <chunking id="2" string="a reporter" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="reporter" />
          </tokens>
        </chunking>
        <chunking id="3" string="say to Anita Hill" type="VP">
          <tokens>
            <token id="10" string="say" />
            <token id="11" string="to" />
            <token id="12" string="Anita" />
            <token id="13" string="Hill" />
          </tokens>
        </chunking>
        <chunking id="4" string="asked , what would she say to Anita Hill if she had the chance" type="VP">
          <tokens>
            <token id="5" string="asked" />
            <token id="6" string="," />
            <token id="7" string="what" />
            <token id="8" string="would" />
            <token id="9" string="she" />
            <token id="10" string="say" />
            <token id="11" string="to" />
            <token id="12" string="Anita" />
            <token id="13" string="Hill" />
            <token id="14" string="if" />
            <token id="15" string="she" />
            <token id="16" string="had" />
            <token id="17" string="the" />
            <token id="18" string="chance" />
          </tokens>
        </chunking>
        <chunking id="5" string="asked , what would she say to Anita Hill" type="VP">
          <tokens>
            <token id="5" string="asked" />
            <token id="6" string="," />
            <token id="7" string="what" />
            <token id="8" string="would" />
            <token id="9" string="she" />
            <token id="10" string="say" />
            <token id="11" string="to" />
            <token id="12" string="Anita" />
            <token id="13" string="Hill" />
          </tokens>
        </chunking>
        <chunking id="6" string="had the chance" type="VP">
          <tokens>
            <token id="16" string="had" />
            <token id="17" string="the" />
            <token id="18" string="chance" />
          </tokens>
        </chunking>
        <chunking id="7" string="if she had the chance" type="SBAR">
          <tokens>
            <token id="14" string="if" />
            <token id="15" string="she" />
            <token id="16" string="had" />
            <token id="17" string="the" />
            <token id="18" string="chance" />
          </tokens>
        </chunking>
        <chunking id="8" string="the chance" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="chance" />
          </tokens>
        </chunking>
        <chunking id="9" string="she" type="NP">
          <tokens>
            <token id="9" string="she" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="5">asked</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">reporter</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">asked</governor>
          <dependent id="4">reporter</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">asked</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">say</governor>
          <dependent id="7">what</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">say</governor>
          <dependent id="8">would</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">say</governor>
          <dependent id="9">she</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">asked</governor>
          <dependent id="10">say</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Hill</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Hill</governor>
          <dependent id="12">Anita</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">say</governor>
          <dependent id="13">Hill</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">had</governor>
          <dependent id="14">if</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">had</governor>
          <dependent id="15">she</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">asked</governor>
          <dependent id="16">had</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">chance</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">had</governor>
          <dependent id="18">chance</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Anita Hill" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Anita" />
            <token id="13" string="Hill" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>; &amp;quot;I&amp;apost;d tell her to pray,&amp;quot; she replied.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="'d" lemma="would" stem="'d" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="tell" lemma="tell" stem="tell" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="her" lemma="she" stem="her" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="pray" lemma="pray" stem="prai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="replied" lemma="reply" stem="repli" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (`` ``) (S (NP (PRP I)) (VP (MD 'd) (VP (VB tell) (S (NP (PRP her)) (VP (TO to) (VP (VB pray))))))) (, ,) ('' '') (NP (PRP she)) (VP (VBD replied)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="replied" type="VP">
          <tokens>
            <token id="12" string="replied" />
          </tokens>
        </chunking>
        <chunking id="2" string="her" type="NP">
          <tokens>
            <token id="6" string="her" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="3" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="to pray" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="pray" />
          </tokens>
        </chunking>
        <chunking id="5" string="pray" type="VP">
          <tokens>
            <token id="8" string="pray" />
          </tokens>
        </chunking>
        <chunking id="6" string="she" type="NP">
          <tokens>
            <token id="11" string="she" />
          </tokens>
        </chunking>
        <chunking id="7" string="'d tell her to pray" type="VP">
          <tokens>
            <token id="4" string="'d" />
            <token id="5" string="tell" />
            <token id="6" string="her" />
            <token id="7" string="to" />
            <token id="8" string="pray" />
          </tokens>
        </chunking>
        <chunking id="8" string="tell her to pray" type="VP">
          <tokens>
            <token id="5" string="tell" />
            <token id="6" string="her" />
            <token id="7" string="to" />
            <token id="8" string="pray" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">tell</governor>
          <dependent id="3">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">tell</governor>
          <dependent id="4">'d</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">replied</governor>
          <dependent id="5">tell</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">tell</governor>
          <dependent id="6">her</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">pray</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">tell</governor>
          <dependent id="8">pray</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">replied</governor>
          <dependent id="11">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">replied</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>&amp;quot;She needs God bad.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="needs" lemma="need" stem="need" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="God" lemma="God" stem="god" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="bad" lemma="bad" stem="bad" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP She)) (VP (VBZ needs) (S (NP (NNP God)) (ADJP (JJ bad)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="bad" type="ADJP">
          <tokens>
            <token id="5" string="bad" />
          </tokens>
        </chunking>
        <chunking id="2" string="God" type="NP">
          <tokens>
            <token id="4" string="God" />
          </tokens>
        </chunking>
        <chunking id="3" string="needs God bad" type="VP">
          <tokens>
            <token id="3" string="needs" />
            <token id="4" string="God" />
            <token id="5" string="bad" />
          </tokens>
        </chunking>
        <chunking id="4" string="She" type="NP">
          <tokens>
            <token id="2" string="She" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">needs</governor>
          <dependent id="2">She</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">needs</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">bad</governor>
          <dependent id="4">God</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">needs</governor>
          <dependent id="5">bad</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>I won&amp;apost;t say nothing bad about her because she&amp;apost;s a mother-child, too.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="wo" lemma="will" stem="wo" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="say" lemma="say" stem="sai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="nothing" lemma="nothing" stem="noth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="bad" lemma="bad" stem="bad" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="mother-child" lemma="mother-child" stem="mother-child" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="too" lemma="too" stem="too" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (MD wo) (RB n't) (VP (VB say) (NP (NN nothing) (JJ bad)) (PP (IN about) (NP (PRP$ her))) (SBAR (IN because) (S (NP (PRP she)) (VP (VBZ 's) (NP (DT a) (JJ mother-child)) (, ,) (ADVP (RB too))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="wo n't say nothing bad about her because she 's a mother-child , too" type="VP">
          <tokens>
            <token id="2" string="wo" />
            <token id="3" string="n't" />
            <token id="4" string="say" />
            <token id="5" string="nothing" />
            <token id="6" string="bad" />
            <token id="7" string="about" />
            <token id="8" string="her" />
            <token id="9" string="because" />
            <token id="10" string="she" />
            <token id="11" string="'s" />
            <token id="12" string="a" />
            <token id="13" string="mother-child" />
            <token id="14" string="," />
            <token id="15" string="too" />
          </tokens>
        </chunking>
        <chunking id="2" string="'s a mother-child , too" type="VP">
          <tokens>
            <token id="11" string="'s" />
            <token id="12" string="a" />
            <token id="13" string="mother-child" />
            <token id="14" string="," />
            <token id="15" string="too" />
          </tokens>
        </chunking>
        <chunking id="3" string="her" type="NP">
          <tokens>
            <token id="8" string="her" />
          </tokens>
        </chunking>
        <chunking id="4" string="a mother-child" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="mother-child" />
          </tokens>
        </chunking>
        <chunking id="5" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="nothing bad" type="NP">
          <tokens>
            <token id="5" string="nothing" />
            <token id="6" string="bad" />
          </tokens>
        </chunking>
        <chunking id="7" string="say nothing bad about her because she 's a mother-child , too" type="VP">
          <tokens>
            <token id="4" string="say" />
            <token id="5" string="nothing" />
            <token id="6" string="bad" />
            <token id="7" string="about" />
            <token id="8" string="her" />
            <token id="9" string="because" />
            <token id="10" string="she" />
            <token id="11" string="'s" />
            <token id="12" string="a" />
            <token id="13" string="mother-child" />
            <token id="14" string="," />
            <token id="15" string="too" />
          </tokens>
        </chunking>
        <chunking id="8" string="because she 's a mother-child , too" type="SBAR">
          <tokens>
            <token id="9" string="because" />
            <token id="10" string="she" />
            <token id="11" string="'s" />
            <token id="12" string="a" />
            <token id="13" string="mother-child" />
            <token id="14" string="," />
            <token id="15" string="too" />
          </tokens>
        </chunking>
        <chunking id="9" string="she" type="NP">
          <tokens>
            <token id="10" string="she" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">say</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">say</governor>
          <dependent id="2">wo</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">say</governor>
          <dependent id="3">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">say</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">say</governor>
          <dependent id="5">nothing</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">nothing</governor>
          <dependent id="6">bad</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">her</governor>
          <dependent id="7">about</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">say</governor>
          <dependent id="8">her</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">mother-child</governor>
          <dependent id="9">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">mother-child</governor>
          <dependent id="10">she</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="13">mother-child</governor>
          <dependent id="11">'s</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">mother-child</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">say</governor>
          <dependent id="13">mother-child</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">mother-child</governor>
          <dependent id="15">too</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>But, whoever put her up to it, I just pray she&amp;apost;ll get her life straightened out.&amp;quot;</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="whoever" lemma="whoever" stem="whoever" pos="WP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="put" lemma="put" stem="put" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="pray" lemma="pray" stem="prai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="'ll" lemma="will" stem="'ll" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="get" lemma="get" stem="get" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="life" lemma="life" stem="life" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="straightened" lemma="straighten" stem="straighten" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (, ,) (SBAR (WHNP (WP whoever)) (S (VP (VBD put) (NP (PRP$ her)) (PRT (RP up)) (PP (TO to) (NP (PRP it))) (, ,) (S (NP (PRP I)) (ADVP (RB just)) (VP (VB pray) (SBAR (S (NP (PRP she)) (VP (MD 'll) (VP (VB get) (NP (PRP$ her) (NN life))))))))))) (VP (VBD straightened) (PRT (RP out))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="whoever put her up to it , I just pray she 'll get her life" type="SBAR">
          <tokens>
            <token id="3" string="whoever" />
            <token id="4" string="put" />
            <token id="5" string="her" />
            <token id="6" string="up" />
            <token id="7" string="to" />
            <token id="8" string="it" />
            <token id="9" string="," />
            <token id="10" string="I" />
            <token id="11" string="just" />
            <token id="12" string="pray" />
            <token id="13" string="she" />
            <token id="14" string="'ll" />
            <token id="15" string="get" />
            <token id="16" string="her" />
            <token id="17" string="life" />
          </tokens>
        </chunking>
        <chunking id="2" string="put her up to it , I just pray she 'll get her life" type="VP">
          <tokens>
            <token id="4" string="put" />
            <token id="5" string="her" />
            <token id="6" string="up" />
            <token id="7" string="to" />
            <token id="8" string="it" />
            <token id="9" string="," />
            <token id="10" string="I" />
            <token id="11" string="just" />
            <token id="12" string="pray" />
            <token id="13" string="she" />
            <token id="14" string="'ll" />
            <token id="15" string="get" />
            <token id="16" string="her" />
            <token id="17" string="life" />
          </tokens>
        </chunking>
        <chunking id="3" string="her" type="NP">
          <tokens>
            <token id="5" string="her" />
          </tokens>
        </chunking>
        <chunking id="4" string="pray she 'll get her life" type="VP">
          <tokens>
            <token id="12" string="pray" />
            <token id="13" string="she" />
            <token id="14" string="'ll" />
            <token id="15" string="get" />
            <token id="16" string="her" />
            <token id="17" string="life" />
          </tokens>
        </chunking>
        <chunking id="5" string="get her life" type="VP">
          <tokens>
            <token id="15" string="get" />
            <token id="16" string="her" />
            <token id="17" string="life" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="10" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="8" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="'ll get her life" type="VP">
          <tokens>
            <token id="14" string="'ll" />
            <token id="15" string="get" />
            <token id="16" string="her" />
            <token id="17" string="life" />
          </tokens>
        </chunking>
        <chunking id="9" string="her life" type="NP">
          <tokens>
            <token id="16" string="her" />
            <token id="17" string="life" />
          </tokens>
        </chunking>
        <chunking id="10" string="straightened out" type="VP">
          <tokens>
            <token id="18" string="straightened" />
            <token id="19" string="out" />
          </tokens>
        </chunking>
        <chunking id="11" string="she 'll get her life" type="SBAR">
          <tokens>
            <token id="13" string="she" />
            <token id="14" string="'ll" />
            <token id="15" string="get" />
            <token id="16" string="her" />
            <token id="17" string="life" />
          </tokens>
        </chunking>
        <chunking id="12" string="she" type="NP">
          <tokens>
            <token id="13" string="she" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="18">straightened</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">put</governor>
          <dependent id="3">whoever</dependent>
        </dependency>
        <dependency type="csubj">
          <governor id="18">straightened</governor>
          <dependent id="4">put</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">put</governor>
          <dependent id="5">her</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="4">put</governor>
          <dependent id="6">up</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">it</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">put</governor>
          <dependent id="8">it</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">pray</governor>
          <dependent id="10">I</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">pray</governor>
          <dependent id="11">just</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">put</governor>
          <dependent id="12">pray</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">get</governor>
          <dependent id="13">she</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">get</governor>
          <dependent id="14">'ll</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">pray</governor>
          <dependent id="15">get</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="17">life</governor>
          <dependent id="16">her</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">get</governor>
          <dependent id="17">life</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">straightened</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="18">straightened</governor>
          <dependent id="19">out</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>; In Thomas&amp;apost; birthplace, the hometown crowd has made no attempt to disguise where its heart lies.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="4" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="5" string="birthplace" lemma="birthplace" stem="birthplac" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="hometown" lemma="hometown" stem="hometown" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="crowd" lemma="crowd" stem="crowd" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="made" lemma="make" stem="made" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="attempt" lemma="attempt" stem="attempt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="disguise" lemma="disguise" stem="disguis" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="heart" lemma="heart" stem="heart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="lies" lemma="lie" stem="li" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (PP (IN In) (NP (NP (NNP Thomas) (POS ')) (NN birthplace))) (, ,) (NP (DT the) (NN hometown) (NN crowd)) (VP (VBZ has) (VP (VBN made) (NP (DT no) (NN attempt) (S (VP (TO to) (VP (VB disguise) (SBAR (WHADVP (WRB where)) (S (NP (PRP$ its) (NN heart)) (VP (VBZ lies)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the hometown crowd" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="hometown" />
            <token id="9" string="crowd" />
          </tokens>
        </chunking>
        <chunking id="2" string="its heart" type="NP">
          <tokens>
            <token id="17" string="its" />
            <token id="18" string="heart" />
          </tokens>
        </chunking>
        <chunking id="3" string="Thomas '" type="NP">
          <tokens>
            <token id="3" string="Thomas" />
            <token id="4" string="'" />
          </tokens>
        </chunking>
        <chunking id="4" string="lies" type="VP">
          <tokens>
            <token id="19" string="lies" />
          </tokens>
        </chunking>
        <chunking id="5" string="no attempt to disguise where its heart lies" type="NP">
          <tokens>
            <token id="12" string="no" />
            <token id="13" string="attempt" />
            <token id="14" string="to" />
            <token id="15" string="disguise" />
            <token id="16" string="where" />
            <token id="17" string="its" />
            <token id="18" string="heart" />
            <token id="19" string="lies" />
          </tokens>
        </chunking>
        <chunking id="6" string="where its heart lies" type="SBAR">
          <tokens>
            <token id="16" string="where" />
            <token id="17" string="its" />
            <token id="18" string="heart" />
            <token id="19" string="lies" />
          </tokens>
        </chunking>
        <chunking id="7" string="Thomas ' birthplace" type="NP">
          <tokens>
            <token id="3" string="Thomas" />
            <token id="4" string="'" />
            <token id="5" string="birthplace" />
          </tokens>
        </chunking>
        <chunking id="8" string="has made no attempt to disguise where its heart lies" type="VP">
          <tokens>
            <token id="10" string="has" />
            <token id="11" string="made" />
            <token id="12" string="no" />
            <token id="13" string="attempt" />
            <token id="14" string="to" />
            <token id="15" string="disguise" />
            <token id="16" string="where" />
            <token id="17" string="its" />
            <token id="18" string="heart" />
            <token id="19" string="lies" />
          </tokens>
        </chunking>
        <chunking id="9" string="where" type="WHADVP">
          <tokens>
            <token id="16" string="where" />
          </tokens>
        </chunking>
        <chunking id="10" string="to disguise where its heart lies" type="VP">
          <tokens>
            <token id="14" string="to" />
            <token id="15" string="disguise" />
            <token id="16" string="where" />
            <token id="17" string="its" />
            <token id="18" string="heart" />
            <token id="19" string="lies" />
          </tokens>
        </chunking>
        <chunking id="11" string="disguise where its heart lies" type="VP">
          <tokens>
            <token id="15" string="disguise" />
            <token id="16" string="where" />
            <token id="17" string="its" />
            <token id="18" string="heart" />
            <token id="19" string="lies" />
          </tokens>
        </chunking>
        <chunking id="12" string="made no attempt to disguise where its heart lies" type="VP">
          <tokens>
            <token id="11" string="made" />
            <token id="12" string="no" />
            <token id="13" string="attempt" />
            <token id="14" string="to" />
            <token id="15" string="disguise" />
            <token id="16" string="where" />
            <token id="17" string="its" />
            <token id="18" string="heart" />
            <token id="19" string="lies" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="5">birthplace</governor>
          <dependent id="2">In</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">birthplace</governor>
          <dependent id="3">Thomas</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">Thomas</governor>
          <dependent id="4">'</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">made</governor>
          <dependent id="5">birthplace</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">crowd</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">crowd</governor>
          <dependent id="8">hometown</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">made</governor>
          <dependent id="9">crowd</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">made</governor>
          <dependent id="10">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">made</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="13">attempt</governor>
          <dependent id="12">no</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">made</governor>
          <dependent id="13">attempt</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">disguise</governor>
          <dependent id="14">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="13">attempt</governor>
          <dependent id="15">disguise</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">lies</governor>
          <dependent id="16">where</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="18">heart</governor>
          <dependent id="17">its</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">lies</governor>
          <dependent id="18">heart</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="15">disguise</governor>
          <dependent id="19">lies</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>A handwritten sign on the main thoroughfare announces: &amp;quot;Pinpoint Georgia, the home of Judge Clarence Thomas.&amp;quot;</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="handwritten" lemma="handwritten" stem="handwritten" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="sign" lemma="sign" stem="sign" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="main" lemma="main" stem="main" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="thoroughfare" lemma="thoroughfare" stem="thoroughfar" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="announces" lemma="announce" stem="announc" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Pinpoint" lemma="Pinpoint" stem="pinpoint" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="Georgia" lemma="Georgia" stem="georgia" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="home" lemma="home" stem="home" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Judge" lemma="Judge" stem="judg" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="true" is_refers="false" />
        <token id="18" string="Clarence" lemma="Clarence" stem="clarenc" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="19" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT A) (JJ handwritten) (NN sign)) (PP (IN on) (NP (DT the) (JJ main) (NN thoroughfare)))) (VP (VBZ announces) (: :) (`` ``) (NP (NP (NNP Pinpoint) (NNP Georgia)) (, ,) (NP (NP (DT the) (NN home)) (PP (IN of) (NP (NNP Judge) (NNP Clarence) (NNP Thomas)))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="A handwritten sign on the main thoroughfare" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="handwritten" />
            <token id="3" string="sign" />
            <token id="4" string="on" />
            <token id="5" string="the" />
            <token id="6" string="main" />
            <token id="7" string="thoroughfare" />
          </tokens>
        </chunking>
        <chunking id="2" string="the home" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="home" />
          </tokens>
        </chunking>
        <chunking id="3" string="Judge Clarence Thomas" type="NP">
          <tokens>
            <token id="17" string="Judge" />
            <token id="18" string="Clarence" />
            <token id="19" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="4" string="announces : `` Pinpoint Georgia , the home of Judge Clarence Thomas" type="VP">
          <tokens>
            <token id="8" string="announces" />
            <token id="9" string=":" />
            <token id="10" string="&quot;" />
            <token id="11" string="Pinpoint" />
            <token id="12" string="Georgia" />
            <token id="13" string="," />
            <token id="14" string="the" />
            <token id="15" string="home" />
            <token id="16" string="of" />
            <token id="17" string="Judge" />
            <token id="18" string="Clarence" />
            <token id="19" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="5" string="the main thoroughfare" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="main" />
            <token id="7" string="thoroughfare" />
          </tokens>
        </chunking>
        <chunking id="6" string="Pinpoint Georgia" type="NP">
          <tokens>
            <token id="11" string="Pinpoint" />
            <token id="12" string="Georgia" />
          </tokens>
        </chunking>
        <chunking id="7" string="A handwritten sign" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="handwritten" />
            <token id="3" string="sign" />
          </tokens>
        </chunking>
        <chunking id="8" string="Pinpoint Georgia , the home of Judge Clarence Thomas" type="NP">
          <tokens>
            <token id="11" string="Pinpoint" />
            <token id="12" string="Georgia" />
            <token id="13" string="," />
            <token id="14" string="the" />
            <token id="15" string="home" />
            <token id="16" string="of" />
            <token id="17" string="Judge" />
            <token id="18" string="Clarence" />
            <token id="19" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="9" string="the home of Judge Clarence Thomas" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="home" />
            <token id="16" string="of" />
            <token id="17" string="Judge" />
            <token id="18" string="Clarence" />
            <token id="19" string="Thomas" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">sign</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">sign</governor>
          <dependent id="2">handwritten</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">announces</governor>
          <dependent id="3">sign</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">thoroughfare</governor>
          <dependent id="4">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">thoroughfare</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">thoroughfare</governor>
          <dependent id="6">main</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">sign</governor>
          <dependent id="7">thoroughfare</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">announces</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Georgia</governor>
          <dependent id="11">Pinpoint</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">announces</governor>
          <dependent id="12">Georgia</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">home</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="12">Georgia</governor>
          <dependent id="15">home</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">Thomas</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">Thomas</governor>
          <dependent id="17">Judge</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">Thomas</governor>
          <dependent id="18">Clarence</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">home</governor>
          <dependent id="19">Thomas</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Georgia" type="LOCATION" score="0.0">
          <tokens>
            <token id="12" string="Georgia" />
          </tokens>
        </entity>
        <entity id="2" string="Judge" type="TITLE" score="0.0">
          <tokens>
            <token id="17" string="Judge" />
          </tokens>
        </entity>
        <entity id="3" string="Clarence Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Clarence" />
            <token id="19" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>; Not surprisingly, no one here seemed to believe Hill&amp;apost;s allegation that Thomas had sexually harassed her between 1981 and 1983 while she worked for him.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="surprisingly" lemma="surprisingly" stem="surprisingli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="one" lemma="one" stem="on" pos="NN" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="7" string="here" lemma="here" stem="here" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="seemed" lemma="seem" stem="seem" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="believe" lemma="believe" stem="believ" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="Hill" lemma="Hill" stem="hill" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="12" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="allegation" lemma="allegation" stem="alleg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="16" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="sexually" lemma="sexually" stem="sexual" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="harassed" lemma="harass" stem="harass" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="between" lemma="between" stem="between" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="1981" lemma="1981" stem="1981" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="22" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="23" string="1983" lemma="1983" stem="1983" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="24" string="while" lemma="while" stem="while" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="worked" lemma="work" stem="work" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (S (ADVP (RB Not) (RB surprisingly)) (, ,) (NP (DT no) (NN one)) (ADVP (RB here)) (VP (VBD seemed) (S (VP (TO to) (VP (VB believe) (NP (NP (NNP Hill) (POS 's)) (NN allegation)) (SBAR (IN that) (S (NP (NNP Thomas)) (VP (VBD had) (VP (ADVP (RB sexually)) (VBN harassed) (NP (PRP$ her)) (PP (IN between) (NP (CD 1981) (CC and) (CD 1983))) (SBAR (IN while) (S (NP (PRP she)) (VP (VBD worked) (PP (IN for) (NP (PRP him))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="sexually harassed her between 1981 and 1983 while she worked for him" type="VP">
          <tokens>
            <token id="17" string="sexually" />
            <token id="18" string="harassed" />
            <token id="19" string="her" />
            <token id="20" string="between" />
            <token id="21" string="1981" />
            <token id="22" string="and" />
            <token id="23" string="1983" />
            <token id="24" string="while" />
            <token id="25" string="she" />
            <token id="26" string="worked" />
            <token id="27" string="for" />
            <token id="28" string="him" />
          </tokens>
        </chunking>
        <chunking id="2" string="no one" type="NP">
          <tokens>
            <token id="5" string="no" />
            <token id="6" string="one" />
          </tokens>
        </chunking>
        <chunking id="3" string="Thomas" type="NP">
          <tokens>
            <token id="15" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="4" string="believe Hill 's allegation that Thomas had sexually harassed her between 1981 and 1983 while she worked for him" type="VP">
          <tokens>
            <token id="10" string="believe" />
            <token id="11" string="Hill" />
            <token id="12" string="'s" />
            <token id="13" string="allegation" />
            <token id="14" string="that" />
            <token id="15" string="Thomas" />
            <token id="16" string="had" />
            <token id="17" string="sexually" />
            <token id="18" string="harassed" />
            <token id="19" string="her" />
            <token id="20" string="between" />
            <token id="21" string="1981" />
            <token id="22" string="and" />
            <token id="23" string="1983" />
            <token id="24" string="while" />
            <token id="25" string="she" />
            <token id="26" string="worked" />
            <token id="27" string="for" />
            <token id="28" string="him" />
          </tokens>
        </chunking>
        <chunking id="5" string="1981 and 1983" type="NP">
          <tokens>
            <token id="21" string="1981" />
            <token id="22" string="and" />
            <token id="23" string="1983" />
          </tokens>
        </chunking>
        <chunking id="6" string="had sexually harassed her between 1981 and 1983 while she worked for him" type="VP">
          <tokens>
            <token id="16" string="had" />
            <token id="17" string="sexually" />
            <token id="18" string="harassed" />
            <token id="19" string="her" />
            <token id="20" string="between" />
            <token id="21" string="1981" />
            <token id="22" string="and" />
            <token id="23" string="1983" />
            <token id="24" string="while" />
            <token id="25" string="she" />
            <token id="26" string="worked" />
            <token id="27" string="for" />
            <token id="28" string="him" />
          </tokens>
        </chunking>
        <chunking id="7" string="him" type="NP">
          <tokens>
            <token id="28" string="him" />
          </tokens>
        </chunking>
        <chunking id="8" string="that Thomas had sexually harassed her between 1981 and 1983 while she worked for him" type="SBAR">
          <tokens>
            <token id="14" string="that" />
            <token id="15" string="Thomas" />
            <token id="16" string="had" />
            <token id="17" string="sexually" />
            <token id="18" string="harassed" />
            <token id="19" string="her" />
            <token id="20" string="between" />
            <token id="21" string="1981" />
            <token id="22" string="and" />
            <token id="23" string="1983" />
            <token id="24" string="while" />
            <token id="25" string="she" />
            <token id="26" string="worked" />
            <token id="27" string="for" />
            <token id="28" string="him" />
          </tokens>
        </chunking>
        <chunking id="9" string="to believe Hill 's allegation that Thomas had sexually harassed her between 1981 and 1983 while she worked for him" type="VP">
          <tokens>
            <token id="9" string="to" />
            <token id="10" string="believe" />
            <token id="11" string="Hill" />
            <token id="12" string="'s" />
            <token id="13" string="allegation" />
            <token id="14" string="that" />
            <token id="15" string="Thomas" />
            <token id="16" string="had" />
            <token id="17" string="sexually" />
            <token id="18" string="harassed" />
            <token id="19" string="her" />
            <token id="20" string="between" />
            <token id="21" string="1981" />
            <token id="22" string="and" />
            <token id="23" string="1983" />
            <token id="24" string="while" />
            <token id="25" string="she" />
            <token id="26" string="worked" />
            <token id="27" string="for" />
            <token id="28" string="him" />
          </tokens>
        </chunking>
        <chunking id="10" string="she" type="NP">
          <tokens>
            <token id="25" string="she" />
          </tokens>
        </chunking>
        <chunking id="11" string="her" type="NP">
          <tokens>
            <token id="19" string="her" />
          </tokens>
        </chunking>
        <chunking id="12" string="worked for him" type="VP">
          <tokens>
            <token id="26" string="worked" />
            <token id="27" string="for" />
            <token id="28" string="him" />
          </tokens>
        </chunking>
        <chunking id="13" string="seemed to believe Hill 's allegation that Thomas had sexually harassed her between 1981 and 1983 while she worked for him" type="VP">
          <tokens>
            <token id="8" string="seemed" />
            <token id="9" string="to" />
            <token id="10" string="believe" />
            <token id="11" string="Hill" />
            <token id="12" string="'s" />
            <token id="13" string="allegation" />
            <token id="14" string="that" />
            <token id="15" string="Thomas" />
            <token id="16" string="had" />
            <token id="17" string="sexually" />
            <token id="18" string="harassed" />
            <token id="19" string="her" />
            <token id="20" string="between" />
            <token id="21" string="1981" />
            <token id="22" string="and" />
            <token id="23" string="1983" />
            <token id="24" string="while" />
            <token id="25" string="she" />
            <token id="26" string="worked" />
            <token id="27" string="for" />
            <token id="28" string="him" />
          </tokens>
        </chunking>
        <chunking id="14" string="Hill 's" type="NP">
          <tokens>
            <token id="11" string="Hill" />
            <token id="12" string="'s" />
          </tokens>
        </chunking>
        <chunking id="15" string="Hill 's allegation" type="NP">
          <tokens>
            <token id="11" string="Hill" />
            <token id="12" string="'s" />
            <token id="13" string="allegation" />
          </tokens>
        </chunking>
        <chunking id="16" string="while she worked for him" type="SBAR">
          <tokens>
            <token id="24" string="while" />
            <token id="25" string="she" />
            <token id="26" string="worked" />
            <token id="27" string="for" />
            <token id="28" string="him" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="dep">
          <governor id="3">surprisingly</governor>
          <dependent id="2">Not</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">seemed</governor>
          <dependent id="3">surprisingly</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">one</governor>
          <dependent id="5">no</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">seemed</governor>
          <dependent id="6">one</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">seemed</governor>
          <dependent id="7">here</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">seemed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">believe</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">seemed</governor>
          <dependent id="10">believe</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">allegation</governor>
          <dependent id="11">Hill</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Hill</governor>
          <dependent id="12">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">believe</governor>
          <dependent id="13">allegation</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">harassed</governor>
          <dependent id="14">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">harassed</governor>
          <dependent id="15">Thomas</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">harassed</governor>
          <dependent id="16">had</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">harassed</governor>
          <dependent id="17">sexually</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">believe</governor>
          <dependent id="18">harassed</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">harassed</governor>
          <dependent id="19">her</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">1981</governor>
          <dependent id="20">between</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">harassed</governor>
          <dependent id="21">1981</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="21">1981</governor>
          <dependent id="22">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="21">1981</governor>
          <dependent id="23">1983</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="26">worked</governor>
          <dependent id="24">while</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">worked</governor>
          <dependent id="25">she</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="18">harassed</governor>
          <dependent id="26">worked</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">him</governor>
          <dependent id="27">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">worked</governor>
          <dependent id="28">him</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Hill" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Hill" />
          </tokens>
        </entity>
        <entity id="2" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="6" string="one" />
          </tokens>
        </entity>
        <entity id="3" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="Thomas" />
          </tokens>
        </entity>
        <entity id="4" string="1981 and 1983" type="DATE" score="0.0">
          <tokens>
            <token id="21" string="1981" />
            <token id="22" string="and" />
            <token id="23" string="1983" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>From a roof, a sign announced: &amp;quot;We believe Clarence.&amp;quot;</content>
      <tokens>
        <token id="1" string="From" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="roof" lemma="roof" stem="roof" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="sign" lemma="sign" stem="sign" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="announced" lemma="announce" stem="announc" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="believe" lemma="believe" stem="believ" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="Clarence" lemma="Clarence" stem="clarenc" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN From) (NP (DT a) (NN roof))) (, ,) (NP (DT a) (NN sign)) (VP (VBD announced) (: :) (`` ``) (S (NP (PRP We)) (VP (VBP believe) (NP (NNP Clarence))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="a sign" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="sign" />
          </tokens>
        </chunking>
        <chunking id="2" string="announced : `` We believe Clarence" type="VP">
          <tokens>
            <token id="7" string="announced" />
            <token id="8" string=":" />
            <token id="9" string="&quot;" />
            <token id="10" string="We" />
            <token id="11" string="believe" />
            <token id="12" string="Clarence" />
          </tokens>
        </chunking>
        <chunking id="3" string="believe Clarence" type="VP">
          <tokens>
            <token id="11" string="believe" />
            <token id="12" string="Clarence" />
          </tokens>
        </chunking>
        <chunking id="4" string="a roof" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="roof" />
          </tokens>
        </chunking>
        <chunking id="5" string="We" type="NP">
          <tokens>
            <token id="10" string="We" />
          </tokens>
        </chunking>
        <chunking id="6" string="Clarence" type="NP">
          <tokens>
            <token id="12" string="Clarence" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">roof</governor>
          <dependent id="1">From</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">roof</governor>
          <dependent id="2">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">announced</governor>
          <dependent id="3">roof</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">sign</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">announced</governor>
          <dependent id="6">sign</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">announced</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">believe</governor>
          <dependent id="10">We</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">announced</governor>
          <dependent id="11">believe</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">believe</governor>
          <dependent id="12">Clarence</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Clarence" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Clarence" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>; Much of the community gathered before the only big-screen television available, at the home of Abraham Famble, deacon of the Sweet Fields of Eden Baptist Church, as the time for the Senate vote neared.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Much" lemma="much" stem="much" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="community" lemma="community" stem="commun" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="gathered" lemma="gather" stem="gather" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="only" lemma="only" stem="onli" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="big-screen" lemma="big-screen" stem="big-screen" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="television" lemma="television" stem="televis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="available" lemma="available" stem="avail" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="home" lemma="home" stem="home" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Abraham" lemma="Abraham" stem="abraham" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="19" string="Famble" lemma="Famble" stem="fambl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="deacon" lemma="deacon" stem="deacon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="Sweet" lemma="Sweet" stem="sweet" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="Fields" lemma="Fields" stem="field" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="Eden" lemma="Eden" stem="eden" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="28" string="Baptist" lemma="Baptist" stem="baptist" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="29" string="Church" lemma="Church" stem="church" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="30" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="Senate" lemma="Senate" stem="senat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="37" string="vote" lemma="vote" stem="vote" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="neared" lemma="near" stem="near" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (: ;) (NP (JJ Much)) (PP (IN of) (NP (NP (DT the) (NN community)) (VP (VBN gathered) (PP (IN before) (NP (DT the) (JJ only) (NN big-screen) (NN television)))))) (ADJP (JJ available)) (, ,) (PP (IN at) (NP (NP (DT the) (NN home)) (PP (IN of) (NP (NNP Abraham) (NNP Famble))))) (, ,) (NP (NP (NN deacon)) (PP (IN of) (NP (NP (DT the) (NNP Sweet) (NNP Fields)) (PP (IN of) (NP (NP (NNP Eden) (NNP Baptist) (NNP Church)) (, ,) (SBAR (IN as) (S (NP (NP (DT the) (NN time)) (PP (IN for) (NP (DT the) (NNP Senate) (NN vote)))) (VP (VBD neared))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Abraham Famble" type="NP">
          <tokens>
            <token id="18" string="Abraham" />
            <token id="19" string="Famble" />
          </tokens>
        </chunking>
        <chunking id="2" string="deacon" type="NP">
          <tokens>
            <token id="21" string="deacon" />
          </tokens>
        </chunking>
        <chunking id="3" string="the time for the Senate vote" type="NP">
          <tokens>
            <token id="32" string="the" />
            <token id="33" string="time" />
            <token id="34" string="for" />
            <token id="35" string="the" />
            <token id="36" string="Senate" />
            <token id="37" string="vote" />
          </tokens>
        </chunking>
        <chunking id="4" string="Much" type="NP">
          <tokens>
            <token id="2" string="Much" />
          </tokens>
        </chunking>
        <chunking id="5" string="the Senate vote" type="NP">
          <tokens>
            <token id="35" string="the" />
            <token id="36" string="Senate" />
            <token id="37" string="vote" />
          </tokens>
        </chunking>
        <chunking id="6" string="available" type="ADJP">
          <tokens>
            <token id="12" string="available" />
          </tokens>
        </chunking>
        <chunking id="7" string="the only big-screen television" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="only" />
            <token id="10" string="big-screen" />
            <token id="11" string="television" />
          </tokens>
        </chunking>
        <chunking id="8" string="deacon of the Sweet Fields of Eden Baptist Church , as the time for the Senate vote neared" type="NP">
          <tokens>
            <token id="21" string="deacon" />
            <token id="22" string="of" />
            <token id="23" string="the" />
            <token id="24" string="Sweet" />
            <token id="25" string="Fields" />
            <token id="26" string="of" />
            <token id="27" string="Eden" />
            <token id="28" string="Baptist" />
            <token id="29" string="Church" />
            <token id="30" string="," />
            <token id="31" string="as" />
            <token id="32" string="the" />
            <token id="33" string="time" />
            <token id="34" string="for" />
            <token id="35" string="the" />
            <token id="36" string="Senate" />
            <token id="37" string="vote" />
            <token id="38" string="neared" />
          </tokens>
        </chunking>
        <chunking id="9" string="the community" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="community" />
          </tokens>
        </chunking>
        <chunking id="10" string="the Sweet Fields" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="Sweet" />
            <token id="25" string="Fields" />
          </tokens>
        </chunking>
        <chunking id="11" string="gathered before the only big-screen television" type="VP">
          <tokens>
            <token id="6" string="gathered" />
            <token id="7" string="before" />
            <token id="8" string="the" />
            <token id="9" string="only" />
            <token id="10" string="big-screen" />
            <token id="11" string="television" />
          </tokens>
        </chunking>
        <chunking id="12" string="the home" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="home" />
          </tokens>
        </chunking>
        <chunking id="13" string="the Sweet Fields of Eden Baptist Church , as the time for the Senate vote neared" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="Sweet" />
            <token id="25" string="Fields" />
            <token id="26" string="of" />
            <token id="27" string="Eden" />
            <token id="28" string="Baptist" />
            <token id="29" string="Church" />
            <token id="30" string="," />
            <token id="31" string="as" />
            <token id="32" string="the" />
            <token id="33" string="time" />
            <token id="34" string="for" />
            <token id="35" string="the" />
            <token id="36" string="Senate" />
            <token id="37" string="vote" />
            <token id="38" string="neared" />
          </tokens>
        </chunking>
        <chunking id="14" string="Eden Baptist Church , as the time for the Senate vote neared" type="NP">
          <tokens>
            <token id="27" string="Eden" />
            <token id="28" string="Baptist" />
            <token id="29" string="Church" />
            <token id="30" string="," />
            <token id="31" string="as" />
            <token id="32" string="the" />
            <token id="33" string="time" />
            <token id="34" string="for" />
            <token id="35" string="the" />
            <token id="36" string="Senate" />
            <token id="37" string="vote" />
            <token id="38" string="neared" />
          </tokens>
        </chunking>
        <chunking id="15" string="Eden Baptist Church" type="NP">
          <tokens>
            <token id="27" string="Eden" />
            <token id="28" string="Baptist" />
            <token id="29" string="Church" />
          </tokens>
        </chunking>
        <chunking id="16" string="; Much of the community gathered before the only big-screen television available , at the home of Abraham Famble , deacon of the Sweet Fields of Eden Baptist Church , as the time for the Senate vote neared ." type="NP">
          <tokens>
            <token id="1" string=";" />
            <token id="2" string="Much" />
            <token id="3" string="of" />
            <token id="4" string="the" />
            <token id="5" string="community" />
            <token id="6" string="gathered" />
            <token id="7" string="before" />
            <token id="8" string="the" />
            <token id="9" string="only" />
            <token id="10" string="big-screen" />
            <token id="11" string="television" />
            <token id="12" string="available" />
            <token id="13" string="," />
            <token id="14" string="at" />
            <token id="15" string="the" />
            <token id="16" string="home" />
            <token id="17" string="of" />
            <token id="18" string="Abraham" />
            <token id="19" string="Famble" />
            <token id="20" string="," />
            <token id="21" string="deacon" />
            <token id="22" string="of" />
            <token id="23" string="the" />
            <token id="24" string="Sweet" />
            <token id="25" string="Fields" />
            <token id="26" string="of" />
            <token id="27" string="Eden" />
            <token id="28" string="Baptist" />
            <token id="29" string="Church" />
            <token id="30" string="," />
            <token id="31" string="as" />
            <token id="32" string="the" />
            <token id="33" string="time" />
            <token id="34" string="for" />
            <token id="35" string="the" />
            <token id="36" string="Senate" />
            <token id="37" string="vote" />
            <token id="38" string="neared" />
            <token id="39" string="." />
          </tokens>
        </chunking>
        <chunking id="17" string="neared" type="VP">
          <tokens>
            <token id="38" string="neared" />
          </tokens>
        </chunking>
        <chunking id="18" string="the community gathered before the only big-screen television" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="community" />
            <token id="6" string="gathered" />
            <token id="7" string="before" />
            <token id="8" string="the" />
            <token id="9" string="only" />
            <token id="10" string="big-screen" />
            <token id="11" string="television" />
          </tokens>
        </chunking>
        <chunking id="19" string="the time" type="NP">
          <tokens>
            <token id="32" string="the" />
            <token id="33" string="time" />
          </tokens>
        </chunking>
        <chunking id="20" string="as the time for the Senate vote neared" type="SBAR">
          <tokens>
            <token id="31" string="as" />
            <token id="32" string="the" />
            <token id="33" string="time" />
            <token id="34" string="for" />
            <token id="35" string="the" />
            <token id="36" string="Senate" />
            <token id="37" string="vote" />
            <token id="38" string="neared" />
          </tokens>
        </chunking>
        <chunking id="21" string="the home of Abraham Famble" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="home" />
            <token id="17" string="of" />
            <token id="18" string="Abraham" />
            <token id="19" string="Famble" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">Much</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">community</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">community</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">Much</governor>
          <dependent id="5">community</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="5">community</governor>
          <dependent id="6">gathered</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">television</governor>
          <dependent id="7">before</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">television</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">television</governor>
          <dependent id="9">only</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">television</governor>
          <dependent id="10">big-screen</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">gathered</governor>
          <dependent id="11">television</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="2">Much</governor>
          <dependent id="12">available</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">home</governor>
          <dependent id="14">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">home</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">Much</governor>
          <dependent id="16">home</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">Famble</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">Famble</governor>
          <dependent id="18">Abraham</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">home</governor>
          <dependent id="19">Famble</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">Much</governor>
          <dependent id="21">deacon</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">Fields</governor>
          <dependent id="22">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">Fields</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">Fields</governor>
          <dependent id="24">Sweet</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">deacon</governor>
          <dependent id="25">Fields</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">Church</governor>
          <dependent id="26">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">Church</governor>
          <dependent id="27">Eden</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">Church</governor>
          <dependent id="28">Baptist</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">Fields</governor>
          <dependent id="29">Church</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="38">neared</governor>
          <dependent id="31">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">time</governor>
          <dependent id="32">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="38">neared</governor>
          <dependent id="33">time</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">vote</governor>
          <dependent id="34">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="37">vote</governor>
          <dependent id="35">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="37">vote</governor>
          <dependent id="36">Senate</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">time</governor>
          <dependent id="37">vote</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="29">Church</governor>
          <dependent id="38">neared</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Abraham Famble" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Abraham" />
            <token id="19" string="Famble" />
          </tokens>
        </entity>
        <entity id="2" string="Eden Baptist Church" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="27" string="Eden" />
            <token id="28" string="Baptist" />
            <token id="29" string="Church" />
          </tokens>
        </entity>
        <entity id="3" string="Senate" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="36" string="Senate" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>Williams prayed silently in the kitchen, asking God to watch over her son as she rubbed her hands nervously.</content>
      <tokens>
        <token id="1" string="Williams" lemma="Williams" stem="william" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="prayed" lemma="pray" stem="prai" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="silently" lemma="silently" stem="silent" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="kitchen" lemma="kitchen" stem="kitchen" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="asking" lemma="ask" stem="ask" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="God" lemma="God" stem="god" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="watch" lemma="watch" stem="watch" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="son" lemma="son" stem="son" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="rubbed" lemma="rub" stem="rub" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="hands" lemma="hand" stem="hand" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="nervously" lemma="nervously" stem="nervous" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Williams)) (VP (VBD prayed) (ADVP (RB silently)) (PP (IN in) (NP (DT the) (NN kitchen))) (, ,) (S (VP (VBG asking) (S (NP (NNP God)) (VP (TO to) (VP (VB watch) (PP (IN over) (NP (PRP$ her) (NN son))) (SBAR (IN as) (S (NP (PRP she)) (VP (VBD rubbed) (NP (PRP$ her) (NNS hands)) (ADVP (RB nervously))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="prayed silently in the kitchen , asking God to watch over her son as she rubbed her hands nervously" type="VP">
          <tokens>
            <token id="2" string="prayed" />
            <token id="3" string="silently" />
            <token id="4" string="in" />
            <token id="5" string="the" />
            <token id="6" string="kitchen" />
            <token id="7" string="," />
            <token id="8" string="asking" />
            <token id="9" string="God" />
            <token id="10" string="to" />
            <token id="11" string="watch" />
            <token id="12" string="over" />
            <token id="13" string="her" />
            <token id="14" string="son" />
            <token id="15" string="as" />
            <token id="16" string="she" />
            <token id="17" string="rubbed" />
            <token id="18" string="her" />
            <token id="19" string="hands" />
            <token id="20" string="nervously" />
          </tokens>
        </chunking>
        <chunking id="2" string="the kitchen" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="kitchen" />
          </tokens>
        </chunking>
        <chunking id="3" string="to watch over her son as she rubbed her hands nervously" type="VP">
          <tokens>
            <token id="10" string="to" />
            <token id="11" string="watch" />
            <token id="12" string="over" />
            <token id="13" string="her" />
            <token id="14" string="son" />
            <token id="15" string="as" />
            <token id="16" string="she" />
            <token id="17" string="rubbed" />
            <token id="18" string="her" />
            <token id="19" string="hands" />
            <token id="20" string="nervously" />
          </tokens>
        </chunking>
        <chunking id="4" string="watch over her son as she rubbed her hands nervously" type="VP">
          <tokens>
            <token id="11" string="watch" />
            <token id="12" string="over" />
            <token id="13" string="her" />
            <token id="14" string="son" />
            <token id="15" string="as" />
            <token id="16" string="she" />
            <token id="17" string="rubbed" />
            <token id="18" string="her" />
            <token id="19" string="hands" />
            <token id="20" string="nervously" />
          </tokens>
        </chunking>
        <chunking id="5" string="as she rubbed her hands nervously" type="SBAR">
          <tokens>
            <token id="15" string="as" />
            <token id="16" string="she" />
            <token id="17" string="rubbed" />
            <token id="18" string="her" />
            <token id="19" string="hands" />
            <token id="20" string="nervously" />
          </tokens>
        </chunking>
        <chunking id="6" string="her hands" type="NP">
          <tokens>
            <token id="18" string="her" />
            <token id="19" string="hands" />
          </tokens>
        </chunking>
        <chunking id="7" string="rubbed her hands nervously" type="VP">
          <tokens>
            <token id="17" string="rubbed" />
            <token id="18" string="her" />
            <token id="19" string="hands" />
            <token id="20" string="nervously" />
          </tokens>
        </chunking>
        <chunking id="8" string="God" type="NP">
          <tokens>
            <token id="9" string="God" />
          </tokens>
        </chunking>
        <chunking id="9" string="Williams" type="NP">
          <tokens>
            <token id="1" string="Williams" />
          </tokens>
        </chunking>
        <chunking id="10" string="asking God to watch over her son as she rubbed her hands nervously" type="VP">
          <tokens>
            <token id="8" string="asking" />
            <token id="9" string="God" />
            <token id="10" string="to" />
            <token id="11" string="watch" />
            <token id="12" string="over" />
            <token id="13" string="her" />
            <token id="14" string="son" />
            <token id="15" string="as" />
            <token id="16" string="she" />
            <token id="17" string="rubbed" />
            <token id="18" string="her" />
            <token id="19" string="hands" />
            <token id="20" string="nervously" />
          </tokens>
        </chunking>
        <chunking id="11" string="her son" type="NP">
          <tokens>
            <token id="13" string="her" />
            <token id="14" string="son" />
          </tokens>
        </chunking>
        <chunking id="12" string="she" type="NP">
          <tokens>
            <token id="16" string="she" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">prayed</governor>
          <dependent id="1">Williams</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">prayed</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="2">prayed</governor>
          <dependent id="3">silently</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">kitchen</governor>
          <dependent id="4">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">kitchen</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">prayed</governor>
          <dependent id="6">kitchen</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="2">prayed</governor>
          <dependent id="8">asking</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">asking</governor>
          <dependent id="9">God</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">watch</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">asking</governor>
          <dependent id="11">watch</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">son</governor>
          <dependent id="12">over</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">son</governor>
          <dependent id="13">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">watch</governor>
          <dependent id="14">son</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">rubbed</governor>
          <dependent id="15">as</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">rubbed</governor>
          <dependent id="16">she</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">watch</governor>
          <dependent id="17">rubbed</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">hands</governor>
          <dependent id="18">her</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">rubbed</governor>
          <dependent id="19">hands</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">rubbed</governor>
          <dependent id="20">nervously</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Williams" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Williams" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>The crowd joined her in the 23rd Psalm : &amp;quot;Though I walk through the valley of the shadow of death . . .&amp;quot;; As the tally reached a majority for Thomas, a cry of joy and applause rang out.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="crowd" lemma="crowd" stem="crowd" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="joined" lemma="join" stem="join" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="her" lemma="she" stem="her" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="23rd" lemma="23rd" stem="23rd" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="8" string="Psalm" lemma="psalm" stem="psalm" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Though" lemma="though" stem="though" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="walk" lemma="walk" stem="walk" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="valley" lemma="valley" stem="vallei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="shadow" lemma="shadow" stem="shadow" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="death" lemma="death" stem="death" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string=". . ." lemma="..." stem=". . ." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="As" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="tally" lemma="tally" stem="talli" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="reached" lemma="reach" stem="reach" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="majority" lemma="majority" stem="major" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="33" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="cry" lemma="cry" stem="cry" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="joy" lemma="joy" stem="joi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="applause" lemma="applause" stem="applaus" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="rang" lemma="ring" stem="rang" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT The) (NN crowd)) (VP (VBD joined) (NP (PRP her)) (PP (IN in) (NP (DT the) (JJ 23rd) (NN Psalm))))) (: :) (S (`` ``) (SBAR (IN Though) (S (NP (PRP I)) (VP (VBP walk) (PP (IN through) (NP (NP (DT the) (NN valley)) (PP (IN of) (NP (NP (DT the) (NN shadow)) (PP (IN of) (NP (NN death)) (: ...)) ('' '')))))) (: ;) (SBAR (IN As) (S (NP (DT the) (NN tally)) (VP (VBD reached) (NP (DT a) (NN majority)) (PP (IN for) (NP (NNP Thomas)))))))) (, ,) (NP (NP (DT a) (NN cry)) (PP (IN of) (NP (NN joy) (CC and) (NN applause)))) (VP (VBD rang) (PRT (RP out)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="joined her in the 23rd Psalm" type="VP">
          <tokens>
            <token id="3" string="joined" />
            <token id="4" string="her" />
            <token id="5" string="in" />
            <token id="6" string="the" />
            <token id="7" string="23rd" />
            <token id="8" string="Psalm" />
          </tokens>
        </chunking>
        <chunking id="2" string="the tally" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="tally" />
          </tokens>
        </chunking>
        <chunking id="3" string="a cry of joy and applause" type="NP">
          <tokens>
            <token id="34" string="a" />
            <token id="35" string="cry" />
            <token id="36" string="of" />
            <token id="37" string="joy" />
            <token id="38" string="and" />
            <token id="39" string="applause" />
          </tokens>
        </chunking>
        <chunking id="4" string="a majority" type="NP">
          <tokens>
            <token id="29" string="a" />
            <token id="30" string="majority" />
          </tokens>
        </chunking>
        <chunking id="5" string="death" type="NP">
          <tokens>
            <token id="21" string="death" />
          </tokens>
        </chunking>
        <chunking id="6" string="rang out" type="VP">
          <tokens>
            <token id="40" string="rang" />
            <token id="41" string="out" />
          </tokens>
        </chunking>
        <chunking id="7" string="Thomas" type="NP">
          <tokens>
            <token id="32" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="8" string="I" type="NP">
          <tokens>
            <token id="12" string="I" />
          </tokens>
        </chunking>
        <chunking id="9" string="As the tally reached a majority for Thomas" type="SBAR">
          <tokens>
            <token id="25" string="As" />
            <token id="26" string="the" />
            <token id="27" string="tally" />
            <token id="28" string="reached" />
            <token id="29" string="a" />
            <token id="30" string="majority" />
            <token id="31" string="for" />
            <token id="32" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="10" string="reached a majority for Thomas" type="VP">
          <tokens>
            <token id="28" string="reached" />
            <token id="29" string="a" />
            <token id="30" string="majority" />
            <token id="31" string="for" />
            <token id="32" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="11" string="a cry" type="NP">
          <tokens>
            <token id="34" string="a" />
            <token id="35" string="cry" />
          </tokens>
        </chunking>
        <chunking id="12" string="the 23rd Psalm" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="23rd" />
            <token id="8" string="Psalm" />
          </tokens>
        </chunking>
        <chunking id="13" string="Though I walk through the valley of the shadow of death ... '' ; As the tally reached a majority for Thomas" type="SBAR">
          <tokens>
            <token id="11" string="Though" />
            <token id="12" string="I" />
            <token id="13" string="walk" />
            <token id="14" string="through" />
            <token id="15" string="the" />
            <token id="16" string="valley" />
            <token id="17" string="of" />
            <token id="18" string="the" />
            <token id="19" string="shadow" />
            <token id="20" string="of" />
            <token id="21" string="death" />
            <token id="22" string=". . ." />
            <token id="23" string="&quot;" />
            <token id="24" string=";" />
            <token id="25" string="As" />
            <token id="26" string="the" />
            <token id="27" string="tally" />
            <token id="28" string="reached" />
            <token id="29" string="a" />
            <token id="30" string="majority" />
            <token id="31" string="for" />
            <token id="32" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="14" string="her" type="NP">
          <tokens>
            <token id="4" string="her" />
          </tokens>
        </chunking>
        <chunking id="15" string="the valley of the shadow of death ... ''" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="valley" />
            <token id="17" string="of" />
            <token id="18" string="the" />
            <token id="19" string="shadow" />
            <token id="20" string="of" />
            <token id="21" string="death" />
            <token id="22" string=". . ." />
            <token id="23" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="16" string="the shadow" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="shadow" />
          </tokens>
        </chunking>
        <chunking id="17" string="The crowd" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="crowd" />
          </tokens>
        </chunking>
        <chunking id="18" string="the valley" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="valley" />
          </tokens>
        </chunking>
        <chunking id="19" string="the shadow of death ... ''" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="shadow" />
            <token id="20" string="of" />
            <token id="21" string="death" />
            <token id="22" string=". . ." />
            <token id="23" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="20" string="walk through the valley of the shadow of death ... ''" type="VP">
          <tokens>
            <token id="13" string="walk" />
            <token id="14" string="through" />
            <token id="15" string="the" />
            <token id="16" string="valley" />
            <token id="17" string="of" />
            <token id="18" string="the" />
            <token id="19" string="shadow" />
            <token id="20" string="of" />
            <token id="21" string="death" />
            <token id="22" string=". . ." />
            <token id="23" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="21" string="joy and applause" type="NP">
          <tokens>
            <token id="37" string="joy" />
            <token id="38" string="and" />
            <token id="39" string="applause" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">crowd</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">joined</governor>
          <dependent id="2">crowd</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">joined</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">joined</governor>
          <dependent id="4">her</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">Psalm</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">Psalm</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">Psalm</governor>
          <dependent id="7">23rd</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">joined</governor>
          <dependent id="8">Psalm</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">walk</governor>
          <dependent id="11">Though</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">walk</governor>
          <dependent id="12">I</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="40">rang</governor>
          <dependent id="13">walk</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">valley</governor>
          <dependent id="14">through</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">valley</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">walk</governor>
          <dependent id="16">valley</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">shadow</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">shadow</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">valley</governor>
          <dependent id="19">shadow</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">death</governor>
          <dependent id="20">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">shadow</governor>
          <dependent id="21">death</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="28">reached</governor>
          <dependent id="25">As</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">tally</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">reached</governor>
          <dependent id="27">tally</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="13">walk</governor>
          <dependent id="28">reached</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">majority</governor>
          <dependent id="29">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="28">reached</governor>
          <dependent id="30">majority</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">Thomas</governor>
          <dependent id="31">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">reached</governor>
          <dependent id="32">Thomas</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">cry</governor>
          <dependent id="34">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="40">rang</governor>
          <dependent id="35">cry</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">joy</governor>
          <dependent id="36">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="35">cry</governor>
          <dependent id="37">joy</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="37">joy</governor>
          <dependent id="38">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="37">joy</governor>
          <dependent id="39">applause</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="3">joined</governor>
          <dependent id="40">rang</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="40">rang</governor>
          <dependent id="41">out</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="23rd" type="ORDINAL" score="0.0">
          <tokens>
            <token id="7" string="23rd" />
          </tokens>
        </entity>
        <entity id="2" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="32" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>&amp;quot;Earth hath no sorrow that heaven cannot heal,&amp;quot; Famble said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Earth" lemma="Earth" stem="earth" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="hath" lemma="have" stem="hath" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="sorrow" lemma="sorrow" stem="sorrow" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="heaven" lemma="heaven" stem="heaven" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="heal" lemma="heal" stem="heal" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Famble" lemma="Famble" stem="fambl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="14" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (NNP Earth)) (VP (VBP hath) (NP (NP (DT no) (NN sorrow)) (SBAR (WHNP (WDT that)) (S (NP (NN heaven)) (VP (MD can) (RB not) (VP (VB heal)))))))) (, ,) ('' '') (NP (NNP Famble)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that heaven can not heal" type="SBAR">
          <tokens>
            <token id="6" string="that" />
            <token id="7" string="heaven" />
            <token id="8" string="can" />
            <token id="9" string="not" />
            <token id="10" string="heal" />
          </tokens>
        </chunking>
        <chunking id="2" string="no sorrow" type="NP">
          <tokens>
            <token id="4" string="no" />
            <token id="5" string="sorrow" />
          </tokens>
        </chunking>
        <chunking id="3" string="Earth" type="NP">
          <tokens>
            <token id="2" string="Earth" />
          </tokens>
        </chunking>
        <chunking id="4" string="no sorrow that heaven can not heal" type="NP">
          <tokens>
            <token id="4" string="no" />
            <token id="5" string="sorrow" />
            <token id="6" string="that" />
            <token id="7" string="heaven" />
            <token id="8" string="can" />
            <token id="9" string="not" />
            <token id="10" string="heal" />
          </tokens>
        </chunking>
        <chunking id="5" string="Famble" type="NP">
          <tokens>
            <token id="13" string="Famble" />
          </tokens>
        </chunking>
        <chunking id="6" string="can not heal" type="VP">
          <tokens>
            <token id="8" string="can" />
            <token id="9" string="not" />
            <token id="10" string="heal" />
          </tokens>
        </chunking>
        <chunking id="7" string="heal" type="VP">
          <tokens>
            <token id="10" string="heal" />
          </tokens>
        </chunking>
        <chunking id="8" string="hath no sorrow that heaven can not heal" type="VP">
          <tokens>
            <token id="3" string="hath" />
            <token id="4" string="no" />
            <token id="5" string="sorrow" />
            <token id="6" string="that" />
            <token id="7" string="heaven" />
            <token id="8" string="can" />
            <token id="9" string="not" />
            <token id="10" string="heal" />
          </tokens>
        </chunking>
        <chunking id="9" string="said" type="VP">
          <tokens>
            <token id="14" string="said" />
          </tokens>
        </chunking>
        <chunking id="10" string="heaven" type="NP">
          <tokens>
            <token id="7" string="heaven" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">hath</governor>
          <dependent id="2">Earth</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">said</governor>
          <dependent id="3">hath</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">sorrow</governor>
          <dependent id="4">no</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">hath</governor>
          <dependent id="5">sorrow</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">heal</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">heal</governor>
          <dependent id="7">heaven</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">heal</governor>
          <dependent id="8">can</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="10">heal</governor>
          <dependent id="9">not</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="5">sorrow</governor>
          <dependent id="10">heal</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">said</governor>
          <dependent id="13">Famble</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Famble" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Famble" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="22-23" string="Leola Williams" id_sentence="1" />
      <mentions>
        <mention ids_tokens="9" string="Williams" id_sentence="2" />
        <mention ids_tokens="1" string="Williams" id_sentence="17" />
        <mention ids_tokens="13" string="her" id_sentence="17" />
        <mention ids_tokens="16" string="she" id_sentence="17" />
        <mention ids_tokens="18" string="her" id_sentence="17" />
        <mention ids_tokens="4" string="her" id_sentence="18" />
        <mention ids_tokens="12" string="I" id_sentence="18" />
      </mentions>
    </coreference>
    <coreference id="2" type="PRONOMINAL">
      <referenced ids_tokens="7" string="her" id_sentence="1" />
      <mentions>
        <mention ids_tokens="4" string="she" id_sentence="2" />
        <mention ids_tokens="2" string="I" id_sentence="3" />
        <mention ids_tokens="6" string="my" id_sentence="3" />
        <mention ids_tokens="10" string="I" id_sentence="3" />
        <mention ids_tokens="15" string="she" id_sentence="3" />
        <mention ids_tokens="2" string="she" id_sentence="4" />
        <mention ids_tokens="4" string="herself" id_sentence="4" />
        <mention ids_tokens="3" string="she" id_sentence="5" />
        <mention ids_tokens="2" string="I" id_sentence="6" />
        <mention ids_tokens="9" string="she" id_sentence="7" />
        <mention ids_tokens="15" string="she" id_sentence="7" />
        <mention ids_tokens="3" string="I" id_sentence="8" />
        <mention ids_tokens="11" string="she" id_sentence="8" />
        <mention ids_tokens="1" string="I" id_sentence="10" />
        <mention ids_tokens="10" string="I" id_sentence="11" />
      </mentions>
    </coreference>
    <coreference id="3" type="PROPER">
      <referenced ids_tokens="17-18-19" string="Judge Clarence Thomas" id_sentence="13" />
      <mentions>
        <mention ids_tokens="11-15" string="her son , Clarence Thomas" id_sentence="4" />
        <mention ids_tokens="11-12" string="her son" id_sentence="4" />
        <mention ids_tokens="14-15" string="Clarence Thomas" id_sentence="4" />
        <mention ids_tokens="5" string="him" id_sentence="5" />
        <mention ids_tokens="3-4" string="Thomas'" id_sentence="12" />
        <mention ids_tokens="15" string="Thomas" id_sentence="14" />
        <mention ids_tokens="12" string="Clarence" id_sentence="15" />
        <mention ids_tokens="13-14" string="her son" id_sentence="17" />
        <mention ids_tokens="32" string="Thomas" id_sentence="18" />
      </mentions>
    </coreference>
    <coreference id="4" type="PROPER">
      <referenced ids_tokens="12-13" string="Anita Hill" id_sentence="7" />
      <mentions>
        <mention ids_tokens="2" string="She" id_sentence="9" />
        <mention ids_tokens="8" string="her" id_sentence="10" />
        <mention ids_tokens="10" string="she" id_sentence="10" />
        <mention ids_tokens="12-13" string="a mother-child" id_sentence="10" />
        <mention ids_tokens="5" string="her" id_sentence="11" />
        <mention ids_tokens="13" string="she" id_sentence="11" />
        <mention ids_tokens="16" string="her" id_sentence="11" />
        <mention ids_tokens="11-12" string="Hill's" id_sentence="14" />
        <mention ids_tokens="19" string="her" id_sentence="14" />
        <mention ids_tokens="25" string="she" id_sentence="14" />
      </mentions>
    </coreference>
    <coreference id="7" type="NOMINAL">
      <referenced ids_tokens="7-8-9" string="the hometown crowd" id_sentence="12" />
      <mentions>
        <mention ids_tokens="1-2" string="The crowd" id_sentence="18" />
      </mentions>
    </coreference>
    <coreference id="9" type="PROPER">
      <referenced ids_tokens="17" string="Judge" id_sentence="13" />
      <mentions>
        <mention ids_tokens="28" string="him" id_sentence="14" />
      </mentions>
    </coreference>
    <coreference id="10" type="PROPER">
      <referenced ids_tokens="18-19" string="Abraham Famble" id_sentence="16" />
      <mentions>
        <mention ids_tokens="13" string="Famble" id_sentence="19" />
      </mentions>
    </coreference>
  </coreferences>
</document>
