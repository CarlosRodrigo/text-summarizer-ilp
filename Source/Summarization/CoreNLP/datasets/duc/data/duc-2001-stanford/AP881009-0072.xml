<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="AP881009-0072">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>Ben Johnson knowingly took steroids and those close close to the runner also were aware of it, fellow Canadian Olympic sprinter Angella Issajenko was quoted as saying in an interview published Sunday.</content>
      <tokens>
        <token id="1" string="Ben" lemma="Ben" stem="ben" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="knowingly" lemma="knowingly" stem="knowingli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="took" lemma="take" stem="took" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="steroids" lemma="steroid" stem="steroid" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="close" lemma="close" stem="close" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="close" lemma="close" stem="close" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="runner" lemma="runner" stem="runner" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="aware" lemma="aware" stem="awar" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="fellow" lemma="fellow" stem="fellow" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="Canadian" lemma="Canadian" stem="canadian" pos="NNP" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="true" is_refers="false" />
        <token id="21" string="Olympic" lemma="Olympic" stem="olympic" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="true" />
        <token id="22" string="sprinter" lemma="sprinter" stem="sprinter" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="Angella" lemma="Angella" stem="angella" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="24" string="Issajenko" lemma="Issajenko" stem="issajenko" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="25" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="quoted" lemma="quote" stem="quot" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="saying" lemma="say" stem="sai" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="31" string="interview" lemma="interview" stem="interview" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string="published" lemma="publish" stem="publish" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="33" string="Sunday" lemma="Sunday" stem="sundai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="34" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNP Ben) (NNP Johnson)) (ADVP (RB knowingly)) (VP (VBD took) (SBAR (S (NP (NP (NNS steroids)) (CC and) (NP (NP (DT those) (JJ close) (NN close)) (PP (TO to) (NP (DT the) (NN runner))))) (ADVP (RB also)) (VP (VBD were) (ADJP (JJ aware) (PP (IN of) (NP (PRP it))))))))) (, ,) (NP (JJ fellow) (NNP Canadian) (NNP Olympic) (NN sprinter) (NNP Angella) (NNP Issajenko)) (VP (VBD was) (VP (VBN quoted) (PP (IN as) (S (VP (VBG saying) (PP (IN in) (NP (NP (DT an) (NN interview)) (VP (VBN published) (NP-TMP (NNP Sunday)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="those close close" type="NP">
          <tokens>
            <token id="7" string="those" />
            <token id="8" string="close" />
            <token id="9" string="close" />
          </tokens>
        </chunking>
        <chunking id="2" string="the runner" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="runner" />
          </tokens>
        </chunking>
        <chunking id="3" string="took steroids and those close close to the runner also were aware of it" type="VP">
          <tokens>
            <token id="4" string="took" />
            <token id="5" string="steroids" />
            <token id="6" string="and" />
            <token id="7" string="those" />
            <token id="8" string="close" />
            <token id="9" string="close" />
            <token id="10" string="to" />
            <token id="11" string="the" />
            <token id="12" string="runner" />
            <token id="13" string="also" />
            <token id="14" string="were" />
            <token id="15" string="aware" />
            <token id="16" string="of" />
            <token id="17" string="it" />
          </tokens>
        </chunking>
        <chunking id="4" string="quoted as saying in an interview published Sunday" type="VP">
          <tokens>
            <token id="26" string="quoted" />
            <token id="27" string="as" />
            <token id="28" string="saying" />
            <token id="29" string="in" />
            <token id="30" string="an" />
            <token id="31" string="interview" />
            <token id="32" string="published" />
            <token id="33" string="Sunday" />
          </tokens>
        </chunking>
        <chunking id="5" string="was quoted as saying in an interview published Sunday" type="VP">
          <tokens>
            <token id="25" string="was" />
            <token id="26" string="quoted" />
            <token id="27" string="as" />
            <token id="28" string="saying" />
            <token id="29" string="in" />
            <token id="30" string="an" />
            <token id="31" string="interview" />
            <token id="32" string="published" />
            <token id="33" string="Sunday" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="17" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="aware of it" type="ADJP">
          <tokens>
            <token id="15" string="aware" />
            <token id="16" string="of" />
            <token id="17" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="Ben Johnson" type="NP">
          <tokens>
            <token id="1" string="Ben" />
            <token id="2" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="9" string="steroids and those close close to the runner also were aware of it" type="SBAR">
          <tokens>
            <token id="5" string="steroids" />
            <token id="6" string="and" />
            <token id="7" string="those" />
            <token id="8" string="close" />
            <token id="9" string="close" />
            <token id="10" string="to" />
            <token id="11" string="the" />
            <token id="12" string="runner" />
            <token id="13" string="also" />
            <token id="14" string="were" />
            <token id="15" string="aware" />
            <token id="16" string="of" />
            <token id="17" string="it" />
          </tokens>
        </chunking>
        <chunking id="10" string="fellow Canadian Olympic sprinter Angella Issajenko" type="NP">
          <tokens>
            <token id="19" string="fellow" />
            <token id="20" string="Canadian" />
            <token id="21" string="Olympic" />
            <token id="22" string="sprinter" />
            <token id="23" string="Angella" />
            <token id="24" string="Issajenko" />
          </tokens>
        </chunking>
        <chunking id="11" string="those close close to the runner" type="NP">
          <tokens>
            <token id="7" string="those" />
            <token id="8" string="close" />
            <token id="9" string="close" />
            <token id="10" string="to" />
            <token id="11" string="the" />
            <token id="12" string="runner" />
          </tokens>
        </chunking>
        <chunking id="12" string="were aware of it" type="VP">
          <tokens>
            <token id="14" string="were" />
            <token id="15" string="aware" />
            <token id="16" string="of" />
            <token id="17" string="it" />
          </tokens>
        </chunking>
        <chunking id="13" string="an interview" type="NP">
          <tokens>
            <token id="30" string="an" />
            <token id="31" string="interview" />
          </tokens>
        </chunking>
        <chunking id="14" string="saying in an interview published Sunday" type="VP">
          <tokens>
            <token id="28" string="saying" />
            <token id="29" string="in" />
            <token id="30" string="an" />
            <token id="31" string="interview" />
            <token id="32" string="published" />
            <token id="33" string="Sunday" />
          </tokens>
        </chunking>
        <chunking id="15" string="published Sunday" type="VP">
          <tokens>
            <token id="32" string="published" />
            <token id="33" string="Sunday" />
          </tokens>
        </chunking>
        <chunking id="16" string="steroids" type="NP">
          <tokens>
            <token id="5" string="steroids" />
          </tokens>
        </chunking>
        <chunking id="17" string="an interview published Sunday" type="NP">
          <tokens>
            <token id="30" string="an" />
            <token id="31" string="interview" />
            <token id="32" string="published" />
            <token id="33" string="Sunday" />
          </tokens>
        </chunking>
        <chunking id="18" string="steroids and those close close to the runner" type="NP">
          <tokens>
            <token id="5" string="steroids" />
            <token id="6" string="and" />
            <token id="7" string="those" />
            <token id="8" string="close" />
            <token id="9" string="close" />
            <token id="10" string="to" />
            <token id="11" string="the" />
            <token id="12" string="runner" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Johnson</governor>
          <dependent id="1">Ben</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">took</governor>
          <dependent id="2">Johnson</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">took</governor>
          <dependent id="3">knowingly</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="26">quoted</governor>
          <dependent id="4">took</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">aware</governor>
          <dependent id="5">steroids</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">steroids</governor>
          <dependent id="6">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">runner</governor>
          <dependent id="7">those</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">runner</governor>
          <dependent id="8">close</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">runner</governor>
          <dependent id="9">close</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="9">close</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">runner</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">steroids</governor>
          <dependent id="12">runner</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">aware</governor>
          <dependent id="13">also</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="15">aware</governor>
          <dependent id="14">were</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">took</governor>
          <dependent id="15">aware</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">it</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">aware</governor>
          <dependent id="17">it</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">Issajenko</governor>
          <dependent id="19">fellow</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">Issajenko</governor>
          <dependent id="20">Canadian</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">Issajenko</governor>
          <dependent id="21">Olympic</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">Issajenko</governor>
          <dependent id="22">sprinter</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">Issajenko</governor>
          <dependent id="23">Angella</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="26">quoted</governor>
          <dependent id="24">Issajenko</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="26">quoted</governor>
          <dependent id="25">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="26">quoted</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="28">saying</governor>
          <dependent id="27">as</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="26">quoted</governor>
          <dependent id="28">saying</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">interview</governor>
          <dependent id="29">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">interview</governor>
          <dependent id="30">an</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">saying</governor>
          <dependent id="31">interview</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="31">interview</governor>
          <dependent id="32">published</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="32">published</governor>
          <dependent id="33">Sunday</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ben Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Ben" />
            <token id="2" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="Canadian" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="20" string="Canadian" />
          </tokens>
        </entity>
        <entity id="3" string="Sunday" type="DATE" score="0.0">
          <tokens>
            <token id="33" string="Sunday" />
          </tokens>
        </entity>
        <entity id="4" string="Olympic" type="MISC" score="0.0">
          <tokens>
            <token id="21" string="Olympic" />
          </tokens>
        </entity>
        <entity id="5" string="Angella Issajenko" type="PERSON" score="0.0">
          <tokens>
            <token id="23" string="Angella" />
            <token id="24" string="Issajenko" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>Johnson _ stripped of his Olympic gold medal in the 100-meter final after he tested positive for the banned steroid stanozolol _ also was taking steroids when he set a world sprint record last summer in Rome, the Toronto Star newspaper quoted Ms. Issajenko as saying.</content>
      <tokens>
        <token id="1" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="_" lemma="_" stem="_" pos="RB" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="stripped" lemma="strip" stem="strip" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="Olympic" lemma="Olympic" stem="olympic" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="7" string="gold" lemma="gold" stem="gold" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="medal" lemma="medal" stem="medal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="100-meter" lemma="100-meter" stem="100-meter" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="final" lemma="final" stem="final" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="tested" lemma="test" stem="test" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="positive" lemma="positive" stem="posit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="banned" lemma="ban" stem="ban" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="steroid" lemma="steroid" stem="steroid" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="stanozolol" lemma="stanozolol" stem="stanozolol" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="_" lemma="_" stem="_" pos="NN" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="taking" lemma="take" stem="take" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="steroids" lemma="steroid" stem="steroid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="set" lemma="set" stem="set" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="sprint" lemma="sprint" stem="sprint" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="record" lemma="record" stem="record" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="35" string="summer" lemma="summer" stem="summer" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="36" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="Rome" lemma="Rome" stem="rome" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="38" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="Toronto" lemma="Toronto" stem="toronto" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="41" string="Star" lemma="Star" stem="star" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="42" string="newspaper" lemma="newspaper" stem="newspap" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="quoted" lemma="quote" stem="quot" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="Ms." lemma="Ms." stem="ms." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="45" string="Issajenko" lemma="Issajenko" stem="issajenko" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="46" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="47" string="saying" lemma="say" stem="sai" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="48" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNP Johnson)) (ADVP (RB _)) (VP (VBD stripped) (PP (IN of) (NP (NP (PRP$ his) (NNP Olympic) (NN gold) (NN medal)) (PP (IN in) (NP (DT the) (JJ 100-meter) (JJ final))))) (SBAR (IN after) (S (NP (PRP he)) (VP (VBD tested) (ADJP (JJ positive)) (SBAR (IN for) (S (NP (DT the) (VBN banned) (NN steroid) (NN stanozolol) (NN _)) (ADVP (RB also)) (VP (VBD was) (VP (VBG taking) (NP (NNS steroids)) (SBAR (WHADVP (WRB when)) (S (NP (PRP he)) (VP (VBD set) (NP (DT a) (NN world) (NN sprint) (NN record)) (NP-TMP (JJ last) (NN summer)) (PP (IN in) (NP (NNP Rome))))))))))))))) (, ,) (NP (DT the) (NNP Toronto) (NNP Star) (NN newspaper)) (VP (VBD quoted) (NP (NP (NNP Ms.) (NNP Issajenko)) (PP (IN as) (S (VP (VBG saying)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="taking steroids when he set a world sprint record last summer in Rome" type="VP">
          <tokens>
            <token id="25" string="taking" />
            <token id="26" string="steroids" />
            <token id="27" string="when" />
            <token id="28" string="he" />
            <token id="29" string="set" />
            <token id="30" string="a" />
            <token id="31" string="world" />
            <token id="32" string="sprint" />
            <token id="33" string="record" />
            <token id="34" string="last" />
            <token id="35" string="summer" />
            <token id="36" string="in" />
            <token id="37" string="Rome" />
          </tokens>
        </chunking>
        <chunking id="2" string="Johnson" type="NP">
          <tokens>
            <token id="1" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="3" string="for the banned steroid stanozolol _ also was taking steroids when he set a world sprint record last summer in Rome" type="SBAR">
          <tokens>
            <token id="17" string="for" />
            <token id="18" string="the" />
            <token id="19" string="banned" />
            <token id="20" string="steroid" />
            <token id="21" string="stanozolol" />
            <token id="22" string="_" />
            <token id="23" string="also" />
            <token id="24" string="was" />
            <token id="25" string="taking" />
            <token id="26" string="steroids" />
            <token id="27" string="when" />
            <token id="28" string="he" />
            <token id="29" string="set" />
            <token id="30" string="a" />
            <token id="31" string="world" />
            <token id="32" string="sprint" />
            <token id="33" string="record" />
            <token id="34" string="last" />
            <token id="35" string="summer" />
            <token id="36" string="in" />
            <token id="37" string="Rome" />
          </tokens>
        </chunking>
        <chunking id="4" string="a world sprint record" type="NP">
          <tokens>
            <token id="30" string="a" />
            <token id="31" string="world" />
            <token id="32" string="sprint" />
            <token id="33" string="record" />
          </tokens>
        </chunking>
        <chunking id="5" string="Ms. Issajenko as saying" type="NP">
          <tokens>
            <token id="44" string="Ms." />
            <token id="45" string="Issajenko" />
            <token id="46" string="as" />
            <token id="47" string="saying" />
          </tokens>
        </chunking>
        <chunking id="6" string="quoted Ms. Issajenko as saying" type="VP">
          <tokens>
            <token id="43" string="quoted" />
            <token id="44" string="Ms." />
            <token id="45" string="Issajenko" />
            <token id="46" string="as" />
            <token id="47" string="saying" />
          </tokens>
        </chunking>
        <chunking id="7" string="when he set a world sprint record last summer in Rome" type="SBAR">
          <tokens>
            <token id="27" string="when" />
            <token id="28" string="he" />
            <token id="29" string="set" />
            <token id="30" string="a" />
            <token id="31" string="world" />
            <token id="32" string="sprint" />
            <token id="33" string="record" />
            <token id="34" string="last" />
            <token id="35" string="summer" />
            <token id="36" string="in" />
            <token id="37" string="Rome" />
          </tokens>
        </chunking>
        <chunking id="8" string="the 100-meter final" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="100-meter" />
            <token id="12" string="final" />
          </tokens>
        </chunking>
        <chunking id="9" string="positive" type="ADJP">
          <tokens>
            <token id="16" string="positive" />
          </tokens>
        </chunking>
        <chunking id="10" string="tested positive for the banned steroid stanozolol _ also was taking steroids when he set a world sprint record last summer in Rome" type="VP">
          <tokens>
            <token id="15" string="tested" />
            <token id="16" string="positive" />
            <token id="17" string="for" />
            <token id="18" string="the" />
            <token id="19" string="banned" />
            <token id="20" string="steroid" />
            <token id="21" string="stanozolol" />
            <token id="22" string="_" />
            <token id="23" string="also" />
            <token id="24" string="was" />
            <token id="25" string="taking" />
            <token id="26" string="steroids" />
            <token id="27" string="when" />
            <token id="28" string="he" />
            <token id="29" string="set" />
            <token id="30" string="a" />
            <token id="31" string="world" />
            <token id="32" string="sprint" />
            <token id="33" string="record" />
            <token id="34" string="last" />
            <token id="35" string="summer" />
            <token id="36" string="in" />
            <token id="37" string="Rome" />
          </tokens>
        </chunking>
        <chunking id="11" string="set a world sprint record last summer in Rome" type="VP">
          <tokens>
            <token id="29" string="set" />
            <token id="30" string="a" />
            <token id="31" string="world" />
            <token id="32" string="sprint" />
            <token id="33" string="record" />
            <token id="34" string="last" />
            <token id="35" string="summer" />
            <token id="36" string="in" />
            <token id="37" string="Rome" />
          </tokens>
        </chunking>
        <chunking id="12" string="when" type="WHADVP">
          <tokens>
            <token id="27" string="when" />
          </tokens>
        </chunking>
        <chunking id="13" string="stripped of his Olympic gold medal in the 100-meter final after he tested positive for the banned steroid stanozolol _ also was taking steroids when he set a world sprint record last summer in Rome" type="VP">
          <tokens>
            <token id="3" string="stripped" />
            <token id="4" string="of" />
            <token id="5" string="his" />
            <token id="6" string="Olympic" />
            <token id="7" string="gold" />
            <token id="8" string="medal" />
            <token id="9" string="in" />
            <token id="10" string="the" />
            <token id="11" string="100-meter" />
            <token id="12" string="final" />
            <token id="13" string="after" />
            <token id="14" string="he" />
            <token id="15" string="tested" />
            <token id="16" string="positive" />
            <token id="17" string="for" />
            <token id="18" string="the" />
            <token id="19" string="banned" />
            <token id="20" string="steroid" />
            <token id="21" string="stanozolol" />
            <token id="22" string="_" />
            <token id="23" string="also" />
            <token id="24" string="was" />
            <token id="25" string="taking" />
            <token id="26" string="steroids" />
            <token id="27" string="when" />
            <token id="28" string="he" />
            <token id="29" string="set" />
            <token id="30" string="a" />
            <token id="31" string="world" />
            <token id="32" string="sprint" />
            <token id="33" string="record" />
            <token id="34" string="last" />
            <token id="35" string="summer" />
            <token id="36" string="in" />
            <token id="37" string="Rome" />
          </tokens>
        </chunking>
        <chunking id="14" string="after he tested positive for the banned steroid stanozolol _ also was taking steroids when he set a world sprint record last summer in Rome" type="SBAR">
          <tokens>
            <token id="13" string="after" />
            <token id="14" string="he" />
            <token id="15" string="tested" />
            <token id="16" string="positive" />
            <token id="17" string="for" />
            <token id="18" string="the" />
            <token id="19" string="banned" />
            <token id="20" string="steroid" />
            <token id="21" string="stanozolol" />
            <token id="22" string="_" />
            <token id="23" string="also" />
            <token id="24" string="was" />
            <token id="25" string="taking" />
            <token id="26" string="steroids" />
            <token id="27" string="when" />
            <token id="28" string="he" />
            <token id="29" string="set" />
            <token id="30" string="a" />
            <token id="31" string="world" />
            <token id="32" string="sprint" />
            <token id="33" string="record" />
            <token id="34" string="last" />
            <token id="35" string="summer" />
            <token id="36" string="in" />
            <token id="37" string="Rome" />
          </tokens>
        </chunking>
        <chunking id="15" string="the Toronto Star newspaper" type="NP">
          <tokens>
            <token id="39" string="the" />
            <token id="40" string="Toronto" />
            <token id="41" string="Star" />
            <token id="42" string="newspaper" />
          </tokens>
        </chunking>
        <chunking id="16" string="Rome" type="NP">
          <tokens>
            <token id="37" string="Rome" />
          </tokens>
        </chunking>
        <chunking id="17" string="his Olympic gold medal" type="NP">
          <tokens>
            <token id="5" string="his" />
            <token id="6" string="Olympic" />
            <token id="7" string="gold" />
            <token id="8" string="medal" />
          </tokens>
        </chunking>
        <chunking id="18" string="the banned steroid stanozolol _" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="banned" />
            <token id="20" string="steroid" />
            <token id="21" string="stanozolol" />
            <token id="22" string="_" />
          </tokens>
        </chunking>
        <chunking id="19" string="Ms. Issajenko" type="NP">
          <tokens>
            <token id="44" string="Ms." />
            <token id="45" string="Issajenko" />
          </tokens>
        </chunking>
        <chunking id="20" string="his Olympic gold medal in the 100-meter final" type="NP">
          <tokens>
            <token id="5" string="his" />
            <token id="6" string="Olympic" />
            <token id="7" string="gold" />
            <token id="8" string="medal" />
            <token id="9" string="in" />
            <token id="10" string="the" />
            <token id="11" string="100-meter" />
            <token id="12" string="final" />
          </tokens>
        </chunking>
        <chunking id="21" string="saying" type="VP">
          <tokens>
            <token id="47" string="saying" />
          </tokens>
        </chunking>
        <chunking id="22" string="steroids" type="NP">
          <tokens>
            <token id="26" string="steroids" />
          </tokens>
        </chunking>
        <chunking id="23" string="he" type="NP">
          <tokens>
            <token id="14" string="he" />
          </tokens>
        </chunking>
        <chunking id="24" string="was taking steroids when he set a world sprint record last summer in Rome" type="VP">
          <tokens>
            <token id="24" string="was" />
            <token id="25" string="taking" />
            <token id="26" string="steroids" />
            <token id="27" string="when" />
            <token id="28" string="he" />
            <token id="29" string="set" />
            <token id="30" string="a" />
            <token id="31" string="world" />
            <token id="32" string="sprint" />
            <token id="33" string="record" />
            <token id="34" string="last" />
            <token id="35" string="summer" />
            <token id="36" string="in" />
            <token id="37" string="Rome" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">stripped</governor>
          <dependent id="1">Johnson</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">stripped</governor>
          <dependent id="2">_</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="43">quoted</governor>
          <dependent id="3">stripped</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">medal</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">medal</governor>
          <dependent id="5">his</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">medal</governor>
          <dependent id="6">Olympic</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">medal</governor>
          <dependent id="7">gold</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">stripped</governor>
          <dependent id="8">medal</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">final</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">final</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">final</governor>
          <dependent id="11">100-meter</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">medal</governor>
          <dependent id="12">final</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">tested</governor>
          <dependent id="13">after</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">tested</governor>
          <dependent id="14">he</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">stripped</governor>
          <dependent id="15">tested</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="15">tested</governor>
          <dependent id="16">positive</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="25">taking</governor>
          <dependent id="17">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">_</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">_</governor>
          <dependent id="19">banned</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">_</governor>
          <dependent id="20">steroid</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">_</governor>
          <dependent id="21">stanozolol</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">taking</governor>
          <dependent id="22">_</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="25">taking</governor>
          <dependent id="23">also</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="25">taking</governor>
          <dependent id="24">was</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="15">tested</governor>
          <dependent id="25">taking</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">taking</governor>
          <dependent id="26">steroids</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="29">set</governor>
          <dependent id="27">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">set</governor>
          <dependent id="28">he</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="25">taking</governor>
          <dependent id="29">set</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">record</governor>
          <dependent id="30">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="33">record</governor>
          <dependent id="31">world</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="33">record</governor>
          <dependent id="32">sprint</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="29">set</governor>
          <dependent id="33">record</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="35">summer</governor>
          <dependent id="34">last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="29">set</governor>
          <dependent id="35">summer</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">Rome</governor>
          <dependent id="36">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">set</governor>
          <dependent id="37">Rome</dependent>
        </dependency>
        <dependency type="det">
          <governor id="42">newspaper</governor>
          <dependent id="39">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="42">newspaper</governor>
          <dependent id="40">Toronto</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="42">newspaper</governor>
          <dependent id="41">Star</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="43">quoted</governor>
          <dependent id="42">newspaper</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="43">quoted</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="45">Issajenko</governor>
          <dependent id="44">Ms.</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="43">quoted</governor>
          <dependent id="45">Issajenko</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="47">saying</governor>
          <dependent id="46">as</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="45">Issajenko</governor>
          <dependent id="47">saying</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="Rome" type="LOCATION" score="0.0">
          <tokens>
            <token id="37" string="Rome" />
          </tokens>
        </entity>
        <entity id="3" string="last summer" type="DATE" score="0.0">
          <tokens>
            <token id="34" string="last" />
            <token id="35" string="summer" />
          </tokens>
        </entity>
        <entity id="4" string="Olympic" type="MISC" score="0.0">
          <tokens>
            <token id="6" string="Olympic" />
          </tokens>
        </entity>
        <entity id="5" string="Toronto Star" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="40" string="Toronto" />
            <token id="41" string="Star" />
          </tokens>
        </entity>
        <entity id="6" string="Issajenko" type="PERSON" score="0.0">
          <tokens>
            <token id="45" string="Issajenko" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>Ms. Issajenko, who also competed in the Olympics in Seoul, South Korea, was quoted as saying she also took the muscle-building drug.</content>
      <tokens>
        <token id="1" string="Ms." lemma="Ms." stem="ms." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="Issajenko" lemma="Issajenko" stem="issajenko" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="competed" lemma="compete" stem="compet" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="Olympics" lemma="Olympics" stem="olympic" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="10" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="Seoul" lemma="Seoul" stem="seoul" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="South" lemma="South" stem="south" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="14" string="Korea" lemma="Korea" stem="korea" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="quoted" lemma="quote" stem="quot" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="saying" lemma="say" stem="sai" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="took" lemma="take" stem="took" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="muscle-building" lemma="muscle-building" stem="muscle-build" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="drug" lemma="drug" stem="drug" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Ms.) (NNP Issajenko)) (, ,) (SBAR (WHNP (WP who)) (S (ADVP (RB also)) (VP (VBD competed) (PP (IN in) (NP (DT the) (NNPS Olympics))) (PP (IN in) (NP (NP (NNP Seoul)) (, ,) (NP (NNP South) (NNP Korea))))))) (, ,)) (VP (VBD was) (VP (VBN quoted) (PP (IN as) (S (VP (VBG saying) (SBAR (S (NP (PRP she)) (ADVP (RB also)) (VP (VBD took) (NP (DT the) (JJ muscle-building) (NN drug)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="she also took the muscle-building drug" type="SBAR">
          <tokens>
            <token id="20" string="she" />
            <token id="21" string="also" />
            <token id="22" string="took" />
            <token id="23" string="the" />
            <token id="24" string="muscle-building" />
            <token id="25" string="drug" />
          </tokens>
        </chunking>
        <chunking id="2" string="Ms. Issajenko , who also competed in the Olympics in Seoul , South Korea ," type="NP">
          <tokens>
            <token id="1" string="Ms." />
            <token id="2" string="Issajenko" />
            <token id="3" string="," />
            <token id="4" string="who" />
            <token id="5" string="also" />
            <token id="6" string="competed" />
            <token id="7" string="in" />
            <token id="8" string="the" />
            <token id="9" string="Olympics" />
            <token id="10" string="in" />
            <token id="11" string="Seoul" />
            <token id="12" string="," />
            <token id="13" string="South" />
            <token id="14" string="Korea" />
            <token id="15" string="," />
          </tokens>
        </chunking>
        <chunking id="3" string="took the muscle-building drug" type="VP">
          <tokens>
            <token id="22" string="took" />
            <token id="23" string="the" />
            <token id="24" string="muscle-building" />
            <token id="25" string="drug" />
          </tokens>
        </chunking>
        <chunking id="4" string="she" type="NP">
          <tokens>
            <token id="20" string="she" />
          </tokens>
        </chunking>
        <chunking id="5" string="Seoul , South Korea" type="NP">
          <tokens>
            <token id="11" string="Seoul" />
            <token id="12" string="," />
            <token id="13" string="South" />
            <token id="14" string="Korea" />
          </tokens>
        </chunking>
        <chunking id="6" string="the muscle-building drug" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="muscle-building" />
            <token id="25" string="drug" />
          </tokens>
        </chunking>
        <chunking id="7" string="Seoul" type="NP">
          <tokens>
            <token id="11" string="Seoul" />
          </tokens>
        </chunking>
        <chunking id="8" string="the Olympics" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="Olympics" />
          </tokens>
        </chunking>
        <chunking id="9" string="South Korea" type="NP">
          <tokens>
            <token id="13" string="South" />
            <token id="14" string="Korea" />
          </tokens>
        </chunking>
        <chunking id="10" string="saying she also took the muscle-building drug" type="VP">
          <tokens>
            <token id="19" string="saying" />
            <token id="20" string="she" />
            <token id="21" string="also" />
            <token id="22" string="took" />
            <token id="23" string="the" />
            <token id="24" string="muscle-building" />
            <token id="25" string="drug" />
          </tokens>
        </chunking>
        <chunking id="11" string="was quoted as saying she also took the muscle-building drug" type="VP">
          <tokens>
            <token id="16" string="was" />
            <token id="17" string="quoted" />
            <token id="18" string="as" />
            <token id="19" string="saying" />
            <token id="20" string="she" />
            <token id="21" string="also" />
            <token id="22" string="took" />
            <token id="23" string="the" />
            <token id="24" string="muscle-building" />
            <token id="25" string="drug" />
          </tokens>
        </chunking>
        <chunking id="12" string="Ms. Issajenko" type="NP">
          <tokens>
            <token id="1" string="Ms." />
            <token id="2" string="Issajenko" />
          </tokens>
        </chunking>
        <chunking id="13" string="competed in the Olympics in Seoul , South Korea" type="VP">
          <tokens>
            <token id="6" string="competed" />
            <token id="7" string="in" />
            <token id="8" string="the" />
            <token id="9" string="Olympics" />
            <token id="10" string="in" />
            <token id="11" string="Seoul" />
            <token id="12" string="," />
            <token id="13" string="South" />
            <token id="14" string="Korea" />
          </tokens>
        </chunking>
        <chunking id="14" string="quoted as saying she also took the muscle-building drug" type="VP">
          <tokens>
            <token id="17" string="quoted" />
            <token id="18" string="as" />
            <token id="19" string="saying" />
            <token id="20" string="she" />
            <token id="21" string="also" />
            <token id="22" string="took" />
            <token id="23" string="the" />
            <token id="24" string="muscle-building" />
            <token id="25" string="drug" />
          </tokens>
        </chunking>
        <chunking id="15" string="who also competed in the Olympics in Seoul , South Korea" type="SBAR">
          <tokens>
            <token id="4" string="who" />
            <token id="5" string="also" />
            <token id="6" string="competed" />
            <token id="7" string="in" />
            <token id="8" string="the" />
            <token id="9" string="Olympics" />
            <token id="10" string="in" />
            <token id="11" string="Seoul" />
            <token id="12" string="," />
            <token id="13" string="South" />
            <token id="14" string="Korea" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Issajenko</governor>
          <dependent id="1">Ms.</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="17">quoted</governor>
          <dependent id="2">Issajenko</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">competed</governor>
          <dependent id="4">who</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">competed</governor>
          <dependent id="5">also</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="2">Issajenko</governor>
          <dependent id="6">competed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Olympics</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">Olympics</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">competed</governor>
          <dependent id="9">Olympics</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Seoul</governor>
          <dependent id="10">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">competed</governor>
          <dependent id="11">Seoul</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Korea</governor>
          <dependent id="13">South</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="11">Seoul</governor>
          <dependent id="14">Korea</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="17">quoted</governor>
          <dependent id="16">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">quoted</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">saying</governor>
          <dependent id="18">as</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="17">quoted</governor>
          <dependent id="19">saying</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">took</governor>
          <dependent id="20">she</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="22">took</governor>
          <dependent id="21">also</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">saying</governor>
          <dependent id="22">took</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">drug</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">drug</governor>
          <dependent id="24">muscle-building</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">took</governor>
          <dependent id="25">drug</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Seoul" type="LOCATION" score="0.0">
          <tokens>
            <token id="11" string="Seoul" />
          </tokens>
        </entity>
        <entity id="2" string="South Korea" type="LOCATION" score="0.0">
          <tokens>
            <token id="13" string="South" />
            <token id="14" string="Korea" />
          </tokens>
        </entity>
        <entity id="3" string="Olympics" type="MISC" score="0.0">
          <tokens>
            <token id="9" string="Olympics" />
          </tokens>
        </entity>
        <entity id="4" string="Issajenko" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Issajenko" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>The Olympics, which began Sept. 17, ended Oct. 2.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Olympics" lemma="Olympics" stem="olympic" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="began" lemma="begin" stem="began" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="Sept." lemma="Sept." stem="sept." pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="7" string="17" lemma="17" stem="17" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="ended" lemma="end" stem="end" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="Oct." lemma="Oct." stem="oct." pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="11" string="2" lemma="2" stem="2" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NNPS Olympics)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBD began) (NP-TMP (NNP Sept.) (CD 17))))) (, ,)) (VP (VBN ended) (NP-TMP (NNP Oct.) (CD 2))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The Olympics , which began Sept. 17 ," type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Olympics" />
            <token id="3" string="," />
            <token id="4" string="which" />
            <token id="5" string="began" />
            <token id="6" string="Sept." />
            <token id="7" string="17" />
            <token id="8" string="," />
          </tokens>
        </chunking>
        <chunking id="2" string="which began Sept. 17" type="SBAR">
          <tokens>
            <token id="4" string="which" />
            <token id="5" string="began" />
            <token id="6" string="Sept." />
            <token id="7" string="17" />
          </tokens>
        </chunking>
        <chunking id="3" string="began Sept. 17" type="VP">
          <tokens>
            <token id="5" string="began" />
            <token id="6" string="Sept." />
            <token id="7" string="17" />
          </tokens>
        </chunking>
        <chunking id="4" string="ended Oct. 2" type="VP">
          <tokens>
            <token id="9" string="ended" />
            <token id="10" string="Oct." />
            <token id="11" string="2" />
          </tokens>
        </chunking>
        <chunking id="5" string="The Olympics" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Olympics" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">Olympics</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">ended</governor>
          <dependent id="2">Olympics</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">began</governor>
          <dependent id="4">which</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="2">Olympics</governor>
          <dependent id="5">began</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="5">began</governor>
          <dependent id="6">Sept.</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="6">Sept.</governor>
          <dependent id="7">17</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">ended</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="9">ended</governor>
          <dependent id="10">Oct.</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="10">Oct.</governor>
          <dependent id="11">2</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Sept. 17" type="DATE" score="0.0">
          <tokens>
            <token id="6" string="Sept." />
            <token id="7" string="17" />
          </tokens>
        </entity>
        <entity id="2" string="Olympics" type="MISC" score="0.0">
          <tokens>
            <token id="2" string="Olympics" />
          </tokens>
        </entity>
        <entity id="3" string="Oct. 2" type="DATE" score="0.0">
          <tokens>
            <token id="10" string="Oct." />
            <token id="11" string="2" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>Later, her husband Tony said Ms. Issajenko denied saying she and Johnson took steroids.</content>
      <tokens>
        <token id="1" string="Later" lemma="later" stem="later" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="husband" lemma="husband" stem="husband" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="Tony" lemma="Tony" stem="toni" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="6" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="Ms." lemma="Ms." stem="ms." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="Issajenko" lemma="Issajenko" stem="issajenko" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="9" string="denied" lemma="deny" stem="deni" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="saying" lemma="say" stem="sai" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="14" string="took" lemma="take" stem="took" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="steroids" lemma="steroid" stem="steroid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Later)) (, ,) (S (NP (PRP$ her) (NN husband) (NNP Tony)) (VP (VBD said) (SBAR (S (NP (NNP Ms.) (NNP Issajenko)) (VP (VBD denied) (S (VP (VBG saying) (NP (PRP she))))))))) (CC and) (S (NP (NNP Johnson)) (VP (VBD took) (NP (NNS steroids)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="her husband Tony" type="NP">
          <tokens>
            <token id="3" string="her" />
            <token id="4" string="husband" />
            <token id="5" string="Tony" />
          </tokens>
        </chunking>
        <chunking id="2" string="Johnson" type="NP">
          <tokens>
            <token id="13" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="3" string="took steroids" type="VP">
          <tokens>
            <token id="14" string="took" />
            <token id="15" string="steroids" />
          </tokens>
        </chunking>
        <chunking id="4" string="said Ms. Issajenko denied saying she" type="VP">
          <tokens>
            <token id="6" string="said" />
            <token id="7" string="Ms." />
            <token id="8" string="Issajenko" />
            <token id="9" string="denied" />
            <token id="10" string="saying" />
            <token id="11" string="she" />
          </tokens>
        </chunking>
        <chunking id="5" string="denied saying she" type="VP">
          <tokens>
            <token id="9" string="denied" />
            <token id="10" string="saying" />
            <token id="11" string="she" />
          </tokens>
        </chunking>
        <chunking id="6" string="Ms. Issajenko" type="NP">
          <tokens>
            <token id="7" string="Ms." />
            <token id="8" string="Issajenko" />
          </tokens>
        </chunking>
        <chunking id="7" string="steroids" type="NP">
          <tokens>
            <token id="15" string="steroids" />
          </tokens>
        </chunking>
        <chunking id="8" string="Ms. Issajenko denied saying she" type="SBAR">
          <tokens>
            <token id="7" string="Ms." />
            <token id="8" string="Issajenko" />
            <token id="9" string="denied" />
            <token id="10" string="saying" />
            <token id="11" string="she" />
          </tokens>
        </chunking>
        <chunking id="9" string="she" type="NP">
          <tokens>
            <token id="11" string="she" />
          </tokens>
        </chunking>
        <chunking id="10" string="saying she" type="VP">
          <tokens>
            <token id="10" string="saying" />
            <token id="11" string="she" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="6">said</governor>
          <dependent id="1">Later</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">Tony</governor>
          <dependent id="3">her</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Tony</governor>
          <dependent id="4">husband</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">said</governor>
          <dependent id="5">Tony</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Issajenko</governor>
          <dependent id="7">Ms.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">denied</governor>
          <dependent id="8">Issajenko</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">said</governor>
          <dependent id="9">denied</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">denied</governor>
          <dependent id="10">saying</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">saying</governor>
          <dependent id="11">she</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">said</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">took</governor>
          <dependent id="13">Johnson</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">said</governor>
          <dependent id="14">took</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">took</governor>
          <dependent id="15">steroids</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Tony" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Tony" />
          </tokens>
        </entity>
        <entity id="2" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Johnson" />
          </tokens>
        </entity>
        <entity id="3" string="Issajenko" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Issajenko" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>The Toronto Star said Sunday that it stood by its story.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="Toronto" lemma="Toronto" stem="toronto" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="3" string="Star" lemma="Star" stem="star" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="4" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="Sunday" lemma="Sunday" stem="sundai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="stood" lemma="stand" stem="stood" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="11" string="story" lemma="story" stem="stori" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNP Toronto) (NNP Star)) (VP (VBD said) (NP-TMP (NNP Sunday)) (SBAR (IN that) (S (NP (PRP it)) (VP (VBD stood) (PP (IN by) (NP (PRP$ its) (NN story))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="its story" type="NP">
          <tokens>
            <token id="10" string="its" />
            <token id="11" string="story" />
          </tokens>
        </chunking>
        <chunking id="2" string="The Toronto Star" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Toronto" />
            <token id="3" string="Star" />
          </tokens>
        </chunking>
        <chunking id="3" string="that it stood by its story" type="SBAR">
          <tokens>
            <token id="6" string="that" />
            <token id="7" string="it" />
            <token id="8" string="stood" />
            <token id="9" string="by" />
            <token id="10" string="its" />
            <token id="11" string="story" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="7" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="stood by its story" type="VP">
          <tokens>
            <token id="8" string="stood" />
            <token id="9" string="by" />
            <token id="10" string="its" />
            <token id="11" string="story" />
          </tokens>
        </chunking>
        <chunking id="6" string="said Sunday that it stood by its story" type="VP">
          <tokens>
            <token id="4" string="said" />
            <token id="5" string="Sunday" />
            <token id="6" string="that" />
            <token id="7" string="it" />
            <token id="8" string="stood" />
            <token id="9" string="by" />
            <token id="10" string="its" />
            <token id="11" string="story" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">Star</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Star</governor>
          <dependent id="2">Toronto</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">said</governor>
          <dependent id="3">Star</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">said</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="4">said</governor>
          <dependent id="5">Sunday</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">stood</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">stood</governor>
          <dependent id="7">it</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">said</governor>
          <dependent id="8">stood</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">story</governor>
          <dependent id="9">by</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">story</governor>
          <dependent id="10">its</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">stood</governor>
          <dependent id="11">story</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Sunday" type="DATE" score="0.0">
          <tokens>
            <token id="5" string="Sunday" />
          </tokens>
        </entity>
        <entity id="2" string="Toronto Star" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="2" string="Toronto" />
            <token id="3" string="Star" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>Ms. Issajenko previously accused a therapist of giving her and Johnson steroids without their knowledge but later retracted the statement.</content>
      <tokens>
        <token id="1" string="Ms." lemma="Ms." stem="ms." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="Issajenko" lemma="Issajenko" stem="issajenko" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="previously" lemma="previously" stem="previous" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="accused" lemma="accuse" stem="accus" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="therapist" lemma="therapist" stem="therapist" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="giving" lemma="give" stem="give" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="her" lemma="she" stem="her" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="12" string="steroids" lemma="steroid" stem="steroid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="without" lemma="without" stem="without" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="knowledge" lemma="knowledge" stem="knowledg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="later" lemma="later" stem="later" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="retracted" lemma="retract" stem="retract" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="statement" lemma="statement" stem="statement" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Ms.) (NNP Issajenko)) (ADVP (RB previously)) (VP (VP (VBD accused) (NP (NP (NP (DT a) (NN therapist)) (PP (IN of) (S (VP (VBG giving) (NP (PRP her)))))) (CC and) (NP (NP (NNP Johnson) (NNS steroids)) (PP (IN without) (NP (PRP$ their) (NN knowledge)))))) (CC but) (VP (ADVP (RB later)) (VBD retracted) (NP (DT the) (NN statement)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a therapist of giving her" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="therapist" />
            <token id="7" string="of" />
            <token id="8" string="giving" />
            <token id="9" string="her" />
          </tokens>
        </chunking>
        <chunking id="2" string="a therapist" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="therapist" />
          </tokens>
        </chunking>
        <chunking id="3" string="accused a therapist of giving her and Johnson steroids without their knowledge" type="VP">
          <tokens>
            <token id="4" string="accused" />
            <token id="5" string="a" />
            <token id="6" string="therapist" />
            <token id="7" string="of" />
            <token id="8" string="giving" />
            <token id="9" string="her" />
            <token id="10" string="and" />
            <token id="11" string="Johnson" />
            <token id="12" string="steroids" />
            <token id="13" string="without" />
            <token id="14" string="their" />
            <token id="15" string="knowledge" />
          </tokens>
        </chunking>
        <chunking id="4" string="a therapist of giving her and Johnson steroids without their knowledge" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="therapist" />
            <token id="7" string="of" />
            <token id="8" string="giving" />
            <token id="9" string="her" />
            <token id="10" string="and" />
            <token id="11" string="Johnson" />
            <token id="12" string="steroids" />
            <token id="13" string="without" />
            <token id="14" string="their" />
            <token id="15" string="knowledge" />
          </tokens>
        </chunking>
        <chunking id="5" string="giving her" type="VP">
          <tokens>
            <token id="8" string="giving" />
            <token id="9" string="her" />
          </tokens>
        </chunking>
        <chunking id="6" string="accused a therapist of giving her and Johnson steroids without their knowledge but later retracted the statement" type="VP">
          <tokens>
            <token id="4" string="accused" />
            <token id="5" string="a" />
            <token id="6" string="therapist" />
            <token id="7" string="of" />
            <token id="8" string="giving" />
            <token id="9" string="her" />
            <token id="10" string="and" />
            <token id="11" string="Johnson" />
            <token id="12" string="steroids" />
            <token id="13" string="without" />
            <token id="14" string="their" />
            <token id="15" string="knowledge" />
            <token id="16" string="but" />
            <token id="17" string="later" />
            <token id="18" string="retracted" />
            <token id="19" string="the" />
            <token id="20" string="statement" />
          </tokens>
        </chunking>
        <chunking id="7" string="their knowledge" type="NP">
          <tokens>
            <token id="14" string="their" />
            <token id="15" string="knowledge" />
          </tokens>
        </chunking>
        <chunking id="8" string="later retracted the statement" type="VP">
          <tokens>
            <token id="17" string="later" />
            <token id="18" string="retracted" />
            <token id="19" string="the" />
            <token id="20" string="statement" />
          </tokens>
        </chunking>
        <chunking id="9" string="her" type="NP">
          <tokens>
            <token id="9" string="her" />
          </tokens>
        </chunking>
        <chunking id="10" string="the statement" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="statement" />
          </tokens>
        </chunking>
        <chunking id="11" string="Johnson steroids without their knowledge" type="NP">
          <tokens>
            <token id="11" string="Johnson" />
            <token id="12" string="steroids" />
            <token id="13" string="without" />
            <token id="14" string="their" />
            <token id="15" string="knowledge" />
          </tokens>
        </chunking>
        <chunking id="12" string="Ms. Issajenko" type="NP">
          <tokens>
            <token id="1" string="Ms." />
            <token id="2" string="Issajenko" />
          </tokens>
        </chunking>
        <chunking id="13" string="Johnson steroids" type="NP">
          <tokens>
            <token id="11" string="Johnson" />
            <token id="12" string="steroids" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Issajenko</governor>
          <dependent id="1">Ms.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">accused</governor>
          <dependent id="2">Issajenko</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">accused</governor>
          <dependent id="3">previously</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">accused</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">therapist</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">accused</governor>
          <dependent id="6">therapist</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">giving</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="6">therapist</governor>
          <dependent id="8">giving</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">giving</governor>
          <dependent id="9">her</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">therapist</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">steroids</governor>
          <dependent id="11">Johnson</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">therapist</governor>
          <dependent id="12">steroids</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">knowledge</governor>
          <dependent id="13">without</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">knowledge</governor>
          <dependent id="14">their</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">steroids</governor>
          <dependent id="15">knowledge</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">accused</governor>
          <dependent id="16">but</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">retracted</governor>
          <dependent id="17">later</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">accused</governor>
          <dependent id="18">retracted</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">statement</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">retracted</governor>
          <dependent id="20">statement</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="previously" type="DATE" score="0.0">
          <tokens>
            <token id="3" string="previously" />
          </tokens>
        </entity>
        <entity id="3" string="Issajenko" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Issajenko" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>Ms. Issajenko in the interview claimed Dr. George Mario (Jamie) Astaphan provided steroids and monitored the program with the knowledge of Charlie Francis, coach of the Mazda Optimist Track Club, which she and Johnson belong to.</content>
      <tokens>
        <token id="1" string="Ms." lemma="Ms." stem="ms." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="Issajenko" lemma="Issajenko" stem="issajenko" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="3" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="interview" lemma="interview" stem="interview" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="claimed" lemma="claim" stem="claim" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="Dr." lemma="Dr." stem="dr." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="George" lemma="George" stem="georg" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="9" string="Mario" lemma="Mario" stem="mario" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="10" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="Jamie" lemma="Jamie" stem="jami" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="12" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="13" string="Astaphan" lemma="Astaphan" stem="astaphan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="14" string="provided" lemma="provide" stem="provid" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="steroids" lemma="steroid" stem="steroid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="monitored" lemma="monitor" stem="monitor" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="program" lemma="program" stem="program" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="knowledge" lemma="knowledge" stem="knowledg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="Charlie" lemma="Charlie" stem="charli" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="25" string="Francis" lemma="Francis" stem="franci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="coach" lemma="coach" stem="coach" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="Mazda" lemma="Mazda" stem="mazda" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="31" string="Optimist" lemma="Optimist" stem="optimist" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="32" string="Track" lemma="Track" stem="track" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="33" string="Club" lemma="Club" stem="club" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="34" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="39" string="belong" lemma="belong" stem="belong" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Ms.) (NNP Issajenko)) (PP (IN in) (NP (DT the) (NN interview)))) (VP (VBD claimed) (SBAR (S (NP (NNP Dr.) (NNP George) (NNP Mario) (PRN (-LRB- -LRB-) (NP (NNP Jamie)) (-RRB- -RRB-)) (NNP Astaphan)) (VP (VP (VBD provided) (NP (NNS steroids))) (CC and) (VP (VBD monitored) (NP (DT the) (NN program)) (PP (IN with) (NP (NP (DT the) (NN knowledge)) (PP (IN of) (NP (NP (NNP Charlie) (NNP Francis)) (, ,) (NP (NP (NN coach)) (PP (IN of) (NP (DT the) (NNP Mazda) (NNP Optimist) (NNP Track) (NNP Club)))) (, ,) (SBAR (WHNP (WDT which)) (S (NP (PRP she) (CC and) (NNP Johnson)) (VP (VBP belong) (PP (TO to)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="she and Johnson" type="NP">
          <tokens>
            <token id="36" string="she" />
            <token id="37" string="and" />
            <token id="38" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="2" string="Dr. George Mario -LRB- Jamie -RRB- Astaphan provided steroids and monitored the program with the knowledge of Charlie Francis , coach of the Mazda Optimist Track Club , which she and Johnson belong to" type="SBAR">
          <tokens>
            <token id="7" string="Dr." />
            <token id="8" string="George" />
            <token id="9" string="Mario" />
            <token id="10" string="(" />
            <token id="11" string="Jamie" />
            <token id="12" string=")" />
            <token id="13" string="Astaphan" />
            <token id="14" string="provided" />
            <token id="15" string="steroids" />
            <token id="16" string="and" />
            <token id="17" string="monitored" />
            <token id="18" string="the" />
            <token id="19" string="program" />
            <token id="20" string="with" />
            <token id="21" string="the" />
            <token id="22" string="knowledge" />
            <token id="23" string="of" />
            <token id="24" string="Charlie" />
            <token id="25" string="Francis" />
            <token id="26" string="," />
            <token id="27" string="coach" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="Mazda" />
            <token id="31" string="Optimist" />
            <token id="32" string="Track" />
            <token id="33" string="Club" />
            <token id="34" string="," />
            <token id="35" string="which" />
            <token id="36" string="she" />
            <token id="37" string="and" />
            <token id="38" string="Johnson" />
            <token id="39" string="belong" />
            <token id="40" string="to" />
          </tokens>
        </chunking>
        <chunking id="3" string="provided steroids and monitored the program with the knowledge of Charlie Francis , coach of the Mazda Optimist Track Club , which she and Johnson belong to" type="VP">
          <tokens>
            <token id="14" string="provided" />
            <token id="15" string="steroids" />
            <token id="16" string="and" />
            <token id="17" string="monitored" />
            <token id="18" string="the" />
            <token id="19" string="program" />
            <token id="20" string="with" />
            <token id="21" string="the" />
            <token id="22" string="knowledge" />
            <token id="23" string="of" />
            <token id="24" string="Charlie" />
            <token id="25" string="Francis" />
            <token id="26" string="," />
            <token id="27" string="coach" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="Mazda" />
            <token id="31" string="Optimist" />
            <token id="32" string="Track" />
            <token id="33" string="Club" />
            <token id="34" string="," />
            <token id="35" string="which" />
            <token id="36" string="she" />
            <token id="37" string="and" />
            <token id="38" string="Johnson" />
            <token id="39" string="belong" />
            <token id="40" string="to" />
          </tokens>
        </chunking>
        <chunking id="4" string="which she and Johnson belong to" type="SBAR">
          <tokens>
            <token id="35" string="which" />
            <token id="36" string="she" />
            <token id="37" string="and" />
            <token id="38" string="Johnson" />
            <token id="39" string="belong" />
            <token id="40" string="to" />
          </tokens>
        </chunking>
        <chunking id="5" string="Ms. Issajenko in the interview" type="NP">
          <tokens>
            <token id="1" string="Ms." />
            <token id="2" string="Issajenko" />
            <token id="3" string="in" />
            <token id="4" string="the" />
            <token id="5" string="interview" />
          </tokens>
        </chunking>
        <chunking id="6" string="monitored the program with the knowledge of Charlie Francis , coach of the Mazda Optimist Track Club , which she and Johnson belong to" type="VP">
          <tokens>
            <token id="17" string="monitored" />
            <token id="18" string="the" />
            <token id="19" string="program" />
            <token id="20" string="with" />
            <token id="21" string="the" />
            <token id="22" string="knowledge" />
            <token id="23" string="of" />
            <token id="24" string="Charlie" />
            <token id="25" string="Francis" />
            <token id="26" string="," />
            <token id="27" string="coach" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="Mazda" />
            <token id="31" string="Optimist" />
            <token id="32" string="Track" />
            <token id="33" string="Club" />
            <token id="34" string="," />
            <token id="35" string="which" />
            <token id="36" string="she" />
            <token id="37" string="and" />
            <token id="38" string="Johnson" />
            <token id="39" string="belong" />
            <token id="40" string="to" />
          </tokens>
        </chunking>
        <chunking id="7" string="coach of the Mazda Optimist Track Club" type="NP">
          <tokens>
            <token id="27" string="coach" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="Mazda" />
            <token id="31" string="Optimist" />
            <token id="32" string="Track" />
            <token id="33" string="Club" />
          </tokens>
        </chunking>
        <chunking id="8" string="the Mazda Optimist Track Club" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="Mazda" />
            <token id="31" string="Optimist" />
            <token id="32" string="Track" />
            <token id="33" string="Club" />
          </tokens>
        </chunking>
        <chunking id="9" string="Charlie Francis" type="NP">
          <tokens>
            <token id="24" string="Charlie" />
            <token id="25" string="Francis" />
          </tokens>
        </chunking>
        <chunking id="10" string="belong to" type="VP">
          <tokens>
            <token id="39" string="belong" />
            <token id="40" string="to" />
          </tokens>
        </chunking>
        <chunking id="11" string="Jamie" type="NP">
          <tokens>
            <token id="11" string="Jamie" />
          </tokens>
        </chunking>
        <chunking id="12" string="the knowledge of Charlie Francis , coach of the Mazda Optimist Track Club , which she and Johnson belong to" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="knowledge" />
            <token id="23" string="of" />
            <token id="24" string="Charlie" />
            <token id="25" string="Francis" />
            <token id="26" string="," />
            <token id="27" string="coach" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="Mazda" />
            <token id="31" string="Optimist" />
            <token id="32" string="Track" />
            <token id="33" string="Club" />
            <token id="34" string="," />
            <token id="35" string="which" />
            <token id="36" string="she" />
            <token id="37" string="and" />
            <token id="38" string="Johnson" />
            <token id="39" string="belong" />
            <token id="40" string="to" />
          </tokens>
        </chunking>
        <chunking id="13" string="claimed Dr. George Mario -LRB- Jamie -RRB- Astaphan provided steroids and monitored the program with the knowledge of Charlie Francis , coach of the Mazda Optimist Track Club , which she and Johnson belong to" type="VP">
          <tokens>
            <token id="6" string="claimed" />
            <token id="7" string="Dr." />
            <token id="8" string="George" />
            <token id="9" string="Mario" />
            <token id="10" string="(" />
            <token id="11" string="Jamie" />
            <token id="12" string=")" />
            <token id="13" string="Astaphan" />
            <token id="14" string="provided" />
            <token id="15" string="steroids" />
            <token id="16" string="and" />
            <token id="17" string="monitored" />
            <token id="18" string="the" />
            <token id="19" string="program" />
            <token id="20" string="with" />
            <token id="21" string="the" />
            <token id="22" string="knowledge" />
            <token id="23" string="of" />
            <token id="24" string="Charlie" />
            <token id="25" string="Francis" />
            <token id="26" string="," />
            <token id="27" string="coach" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="Mazda" />
            <token id="31" string="Optimist" />
            <token id="32" string="Track" />
            <token id="33" string="Club" />
            <token id="34" string="," />
            <token id="35" string="which" />
            <token id="36" string="she" />
            <token id="37" string="and" />
            <token id="38" string="Johnson" />
            <token id="39" string="belong" />
            <token id="40" string="to" />
          </tokens>
        </chunking>
        <chunking id="14" string="Ms. Issajenko" type="NP">
          <tokens>
            <token id="1" string="Ms." />
            <token id="2" string="Issajenko" />
          </tokens>
        </chunking>
        <chunking id="15" string="the knowledge" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="knowledge" />
          </tokens>
        </chunking>
        <chunking id="16" string="Charlie Francis , coach of the Mazda Optimist Track Club , which she and Johnson belong to" type="NP">
          <tokens>
            <token id="24" string="Charlie" />
            <token id="25" string="Francis" />
            <token id="26" string="," />
            <token id="27" string="coach" />
            <token id="28" string="of" />
            <token id="29" string="the" />
            <token id="30" string="Mazda" />
            <token id="31" string="Optimist" />
            <token id="32" string="Track" />
            <token id="33" string="Club" />
            <token id="34" string="," />
            <token id="35" string="which" />
            <token id="36" string="she" />
            <token id="37" string="and" />
            <token id="38" string="Johnson" />
            <token id="39" string="belong" />
            <token id="40" string="to" />
          </tokens>
        </chunking>
        <chunking id="17" string="steroids" type="NP">
          <tokens>
            <token id="15" string="steroids" />
          </tokens>
        </chunking>
        <chunking id="18" string="the interview" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="interview" />
          </tokens>
        </chunking>
        <chunking id="19" string="coach" type="NP">
          <tokens>
            <token id="27" string="coach" />
          </tokens>
        </chunking>
        <chunking id="20" string="Dr. George Mario -LRB- Jamie -RRB- Astaphan" type="NP">
          <tokens>
            <token id="7" string="Dr." />
            <token id="8" string="George" />
            <token id="9" string="Mario" />
            <token id="10" string="(" />
            <token id="11" string="Jamie" />
            <token id="12" string=")" />
            <token id="13" string="Astaphan" />
          </tokens>
        </chunking>
        <chunking id="21" string="provided steroids" type="VP">
          <tokens>
            <token id="14" string="provided" />
            <token id="15" string="steroids" />
          </tokens>
        </chunking>
        <chunking id="22" string="the program" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="program" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Issajenko</governor>
          <dependent id="1">Ms.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">claimed</governor>
          <dependent id="2">Issajenko</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">interview</governor>
          <dependent id="3">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">interview</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">Issajenko</governor>
          <dependent id="5">interview</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">claimed</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Astaphan</governor>
          <dependent id="7">Dr.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Astaphan</governor>
          <dependent id="8">George</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Astaphan</governor>
          <dependent id="9">Mario</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="13">Astaphan</governor>
          <dependent id="11">Jamie</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">provided</governor>
          <dependent id="13">Astaphan</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">claimed</governor>
          <dependent id="14">provided</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">provided</governor>
          <dependent id="15">steroids</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">provided</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">provided</governor>
          <dependent id="17">monitored</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">program</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">monitored</governor>
          <dependent id="19">program</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">knowledge</governor>
          <dependent id="20">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">knowledge</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">monitored</governor>
          <dependent id="22">knowledge</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">Francis</governor>
          <dependent id="23">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">Francis</governor>
          <dependent id="24">Charlie</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">knowledge</governor>
          <dependent id="25">Francis</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="25">Francis</governor>
          <dependent id="27">coach</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">Club</governor>
          <dependent id="28">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">Club</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="33">Club</governor>
          <dependent id="30">Mazda</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="33">Club</governor>
          <dependent id="31">Optimist</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="33">Club</governor>
          <dependent id="32">Track</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">coach</governor>
          <dependent id="33">Club</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="39">belong</governor>
          <dependent id="35">which</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="39">belong</governor>
          <dependent id="36">she</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="36">she</governor>
          <dependent id="37">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="36">she</governor>
          <dependent id="38">Johnson</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="25">Francis</governor>
          <dependent id="39">belong</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">which</governor>
          <dependent id="40">to</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="38" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="Jamie ) Astaphan" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Jamie" />
            <token id="12" string=")" />
            <token id="13" string="Astaphan" />
          </tokens>
        </entity>
        <entity id="3" string="George Mario" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="George" />
            <token id="9" string="Mario" />
          </tokens>
        </entity>
        <entity id="4" string="Mazda Optimist Track Club" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="30" string="Mazda" />
            <token id="31" string="Optimist" />
            <token id="32" string="Track" />
            <token id="33" string="Club" />
          </tokens>
        </entity>
        <entity id="5" string="Charlie Francis" type="PERSON" score="0.0">
          <tokens>
            <token id="24" string="Charlie" />
            <token id="25" string="Francis" />
          </tokens>
        </entity>
        <entity id="6" string="Issajenko" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Issajenko" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>``I just don&amp;apost;t care any more,&amp;apost;&amp;apost; Ms. Issajenko was quoted as saying.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="care" lemma="care" stem="care" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Ms." lemma="Ms." stem="ms." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="Issajenko" lemma="Issajenko" stem="issajenko" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="13" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="quoted" lemma="quote" stem="quot" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="saying" lemma="say" stem="sai" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP I)) (ADVP (RB just)) (VP (VBP do) (RB n't) (VP (VB care) (ADVP (DT any) (RBR more))))) (, ,) ('' '') (NP (NNP Ms.) (NNP Issajenko)) (VP (VBD was) (VP (VBN quoted) (PP (IN as) (S (VP (VBG saying)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was quoted as saying" type="VP">
          <tokens>
            <token id="13" string="was" />
            <token id="14" string="quoted" />
            <token id="15" string="as" />
            <token id="16" string="saying" />
          </tokens>
        </chunking>
        <chunking id="2" string="do n't care any more" type="VP">
          <tokens>
            <token id="4" string="do" />
            <token id="5" string="n't" />
            <token id="6" string="care" />
            <token id="7" string="any" />
            <token id="8" string="more" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="Ms. Issajenko" type="NP">
          <tokens>
            <token id="11" string="Ms." />
            <token id="12" string="Issajenko" />
          </tokens>
        </chunking>
        <chunking id="5" string="saying" type="VP">
          <tokens>
            <token id="16" string="saying" />
          </tokens>
        </chunking>
        <chunking id="6" string="quoted as saying" type="VP">
          <tokens>
            <token id="14" string="quoted" />
            <token id="15" string="as" />
            <token id="16" string="saying" />
          </tokens>
        </chunking>
        <chunking id="7" string="care any more" type="VP">
          <tokens>
            <token id="6" string="care" />
            <token id="7" string="any" />
            <token id="8" string="more" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">care</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">care</governor>
          <dependent id="3">just</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">care</governor>
          <dependent id="4">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">care</governor>
          <dependent id="5">n't</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">quoted</governor>
          <dependent id="6">care</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="8">more</governor>
          <dependent id="7">any</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">care</governor>
          <dependent id="8">more</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Issajenko</governor>
          <dependent id="11">Ms.</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="14">quoted</governor>
          <dependent id="12">Issajenko</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="14">quoted</governor>
          <dependent id="13">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">quoted</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">saying</governor>
          <dependent id="15">as</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="14">quoted</governor>
          <dependent id="16">saying</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Issajenko" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Issajenko" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>``I&amp;apost;m fed up with all the bull.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'m" lemma="be" stem="'m" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="fed" lemma="feed" stem="fed" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="all" lemma="all" stem="all" pos="PDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="bull" lemma="bull" stem="bull" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (VBP 'm) (VP (VBN fed) (PRT (RP up)) (PP (IN with) (NP (PDT all) (DT the) (NN bull))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="2" string="fed up with all the bull" type="VP">
          <tokens>
            <token id="4" string="fed" />
            <token id="5" string="up" />
            <token id="6" string="with" />
            <token id="7" string="all" />
            <token id="8" string="the" />
            <token id="9" string="bull" />
          </tokens>
        </chunking>
        <chunking id="3" string="'m fed up with all the bull" type="VP">
          <tokens>
            <token id="3" string="'m" />
            <token id="4" string="fed" />
            <token id="5" string="up" />
            <token id="6" string="with" />
            <token id="7" string="all" />
            <token id="8" string="the" />
            <token id="9" string="bull" />
          </tokens>
        </chunking>
        <chunking id="4" string="all the bull" type="NP">
          <tokens>
            <token id="7" string="all" />
            <token id="8" string="the" />
            <token id="9" string="bull" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="4">fed</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">fed</governor>
          <dependent id="3">'m</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">fed</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="4">fed</governor>
          <dependent id="5">up</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">bull</governor>
          <dependent id="6">with</dependent>
        </dependency>
        <dependency type="det:predet">
          <governor id="9">bull</governor>
          <dependent id="7">all</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">bull</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">fed</governor>
          <dependent id="9">bull</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>... Ben takes steroids.</content>
      <tokens>
        <token id="1" string="..." lemma="..." stem="..." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Ben" lemma="Ben" stem="ben" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="takes" lemma="take" stem="take" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="steroids" lemma="steroid" stem="steroid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ...) (NP (NNP Ben)) (VP (VBZ takes) (NP (NNS steroids))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="takes steroids" type="VP">
          <tokens>
            <token id="3" string="takes" />
            <token id="4" string="steroids" />
          </tokens>
        </chunking>
        <chunking id="2" string="Ben" type="NP">
          <tokens>
            <token id="2" string="Ben" />
          </tokens>
        </chunking>
        <chunking id="3" string="steroids" type="NP">
          <tokens>
            <token id="4" string="steroids" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">takes</governor>
          <dependent id="2">Ben</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">takes</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">takes</governor>
          <dependent id="4">steroids</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ben" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Ben" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>I take steroids.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="take" lemma="take" stem="take" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="steroids" lemma="steroid" stem="steroid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBP take) (NP (NNS steroids))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="take steroids" type="VP">
          <tokens>
            <token id="2" string="take" />
            <token id="3" string="steroids" />
          </tokens>
        </chunking>
        <chunking id="2" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="3" string="steroids" type="NP">
          <tokens>
            <token id="3" string="steroids" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">take</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">take</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">take</governor>
          <dependent id="3">steroids</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>Jamie (Astaphan) gives them to us and Charlie isn&amp;apost;t a scientist but he knows what&amp;apost;s happening.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="Jamie" lemma="Jamie" stem="jami" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="Astaphan" lemma="Astaphan" stem="astaphan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="gives" lemma="give" stem="give" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="us" lemma="we" stem="u" pos="PRP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Charlie" lemma="Charlie" stem="charli" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="11" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="scientist" lemma="scientist" stem="scientist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="knows" lemma="know" stem="know" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="happening" lemma="happen" stem="happen" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (NNP Jamie)) (PRN (-LRB- -LRB-) (NP (NNP Astaphan)) (-RRB- -RRB-))) (VP (VBZ gives) (NP (PRP them)) (PP (TO to) (NP (PRP us))))) (CC and) (S (NP (NNP Charlie)) (VP (VBZ is) (RB n't) (NP (DT a) (NN scientist)))) (CC but) (S (NP (PRP he)) (VP (VBZ knows) (SBAR (WHNP (WP what)) (S (VP (VBZ 's) (VP (VBG happening))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="is n't a scientist" type="VP">
          <tokens>
            <token id="11" string="is" />
            <token id="12" string="n't" />
            <token id="13" string="a" />
            <token id="14" string="scientist" />
          </tokens>
        </chunking>
        <chunking id="2" string="happening" type="VP">
          <tokens>
            <token id="20" string="happening" />
          </tokens>
        </chunking>
        <chunking id="3" string="a scientist" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="scientist" />
          </tokens>
        </chunking>
        <chunking id="4" string="them" type="NP">
          <tokens>
            <token id="6" string="them" />
          </tokens>
        </chunking>
        <chunking id="5" string="Jamie" type="NP">
          <tokens>
            <token id="1" string="Jamie" />
          </tokens>
        </chunking>
        <chunking id="6" string="Charlie" type="NP">
          <tokens>
            <token id="10" string="Charlie" />
          </tokens>
        </chunking>
        <chunking id="7" string="Astaphan" type="NP">
          <tokens>
            <token id="3" string="Astaphan" />
          </tokens>
        </chunking>
        <chunking id="8" string="Jamie -LRB- Astaphan -RRB-" type="NP">
          <tokens>
            <token id="1" string="Jamie" />
            <token id="2" string="(" />
            <token id="3" string="Astaphan" />
            <token id="4" string=")" />
          </tokens>
        </chunking>
        <chunking id="9" string="what 's happening" type="SBAR">
          <tokens>
            <token id="18" string="what" />
            <token id="19" string="'s" />
            <token id="20" string="happening" />
          </tokens>
        </chunking>
        <chunking id="10" string="knows what 's happening" type="VP">
          <tokens>
            <token id="17" string="knows" />
            <token id="18" string="what" />
            <token id="19" string="'s" />
            <token id="20" string="happening" />
          </tokens>
        </chunking>
        <chunking id="11" string="he" type="NP">
          <tokens>
            <token id="16" string="he" />
          </tokens>
        </chunking>
        <chunking id="12" string="gives them to us" type="VP">
          <tokens>
            <token id="5" string="gives" />
            <token id="6" string="them" />
            <token id="7" string="to" />
            <token id="8" string="us" />
          </tokens>
        </chunking>
        <chunking id="13" string="us" type="NP">
          <tokens>
            <token id="8" string="us" />
          </tokens>
        </chunking>
        <chunking id="14" string="'s happening" type="VP">
          <tokens>
            <token id="19" string="'s" />
            <token id="20" string="happening" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">gives</governor>
          <dependent id="1">Jamie</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="1">Jamie</governor>
          <dependent id="3">Astaphan</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">gives</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">gives</governor>
          <dependent id="6">them</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">us</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">gives</governor>
          <dependent id="8">us</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">gives</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">scientist</governor>
          <dependent id="10">Charlie</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">scientist</governor>
          <dependent id="11">is</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="14">scientist</governor>
          <dependent id="12">n't</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">scientist</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">gives</governor>
          <dependent id="14">scientist</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">gives</governor>
          <dependent id="15">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">knows</governor>
          <dependent id="16">he</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">gives</governor>
          <dependent id="17">knows</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">happening</governor>
          <dependent id="18">what</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="20">happening</governor>
          <dependent id="19">'s</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">knows</governor>
          <dependent id="20">happening</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Jamie" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Jamie" />
          </tokens>
        </entity>
        <entity id="2" string="Charlie" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Charlie" />
          </tokens>
        </entity>
        <entity id="3" string="Astaphan" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Astaphan" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>Johnson, 26, says he has never knowingly taken illegal drugs while Astaphan has said he has never administered stanozolol _ the banned steroid found in the runner&amp;apost;s urine sample after his world record 100-meter run at the Olympics.</content>
      <tokens>
        <token id="1" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="26" lemma="26" stem="26" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="knowingly" lemma="knowingly" stem="knowingli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="taken" lemma="take" stem="taken" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="drugs" lemma="drug" stem="drug" pos="NNS" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="13" string="while" lemma="while" stem="while" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Astaphan" lemma="Astaphan" stem="astaphan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="15" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="said" lemma="say" stem="said" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="administered" lemma="administer" stem="administ" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="stanozolol" lemma="stanozolol" stem="stanozolol" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="_" lemma="_" stem="_" pos="IN" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="banned" lemma="ban" stem="ban" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="steroid" lemma="steroid" stem="steroid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="found" lemma="find" stem="found" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="29" string="runner" lemma="runner" stem="runner" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="30" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="urine" lemma="urine" stem="urin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="sample" lemma="sample" stem="sampl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="35" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="record" lemma="record" stem="record" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="100-meter" lemma="100-meter" stem="100-meter" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="run" lemma="run" stem="run" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="Olympics" lemma="Olympics" stem="olympic" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="42" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Johnson)) (, ,) (NP (CD 26)) (, ,)) (VP (VBZ says) (SBAR (S (NP (PRP he)) (VP (VBZ has) (ADVP (RB never)) (VP (ADVP (RB knowingly)) (VBN taken) (NP (JJ illegal) (NNS drugs)) (SBAR (IN while) (S (NP (NNP Astaphan)) (VP (VBZ has) (VP (VBN said) (SBAR (S (NP (PRP he)) (VP (VBZ has) (ADVP (RB never)) (VP (VBN administered) (NP (NN stanozolol)) (PP (IN _) (NP (NP (DT the) (VBN banned) (NN steroid)) (VP (VBN found) (PP (IN in) (NP (NP (DT the) (NN runner) (POS 's)) (NN urine) (NN sample))) (PP (IN after) (NP (NP (PRP$ his) (ADJP (NN world) (NN record) (JJ 100-meter)) (NN run)) (PP (IN at) (NP (DT the) (NNPS Olympics))))))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="says he has never knowingly taken illegal drugs while Astaphan has said he has never administered stanozolol _ the banned steroid found in the runner 's urine sample after his world record 100-meter run at the Olympics" type="VP">
          <tokens>
            <token id="5" string="says" />
            <token id="6" string="he" />
            <token id="7" string="has" />
            <token id="8" string="never" />
            <token id="9" string="knowingly" />
            <token id="10" string="taken" />
            <token id="11" string="illegal" />
            <token id="12" string="drugs" />
            <token id="13" string="while" />
            <token id="14" string="Astaphan" />
            <token id="15" string="has" />
            <token id="16" string="said" />
            <token id="17" string="he" />
            <token id="18" string="has" />
            <token id="19" string="never" />
            <token id="20" string="administered" />
            <token id="21" string="stanozolol" />
            <token id="22" string="_" />
            <token id="23" string="the" />
            <token id="24" string="banned" />
            <token id="25" string="steroid" />
            <token id="26" string="found" />
            <token id="27" string="in" />
            <token id="28" string="the" />
            <token id="29" string="runner" />
            <token id="30" string="'s" />
            <token id="31" string="urine" />
            <token id="32" string="sample" />
            <token id="33" string="after" />
            <token id="34" string="his" />
            <token id="35" string="world" />
            <token id="36" string="record" />
            <token id="37" string="100-meter" />
            <token id="38" string="run" />
            <token id="39" string="at" />
            <token id="40" string="the" />
            <token id="41" string="Olympics" />
          </tokens>
        </chunking>
        <chunking id="2" string="Johnson" type="NP">
          <tokens>
            <token id="1" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="3" string="said he has never administered stanozolol _ the banned steroid found in the runner 's urine sample after his world record 100-meter run at the Olympics" type="VP">
          <tokens>
            <token id="16" string="said" />
            <token id="17" string="he" />
            <token id="18" string="has" />
            <token id="19" string="never" />
            <token id="20" string="administered" />
            <token id="21" string="stanozolol" />
            <token id="22" string="_" />
            <token id="23" string="the" />
            <token id="24" string="banned" />
            <token id="25" string="steroid" />
            <token id="26" string="found" />
            <token id="27" string="in" />
            <token id="28" string="the" />
            <token id="29" string="runner" />
            <token id="30" string="'s" />
            <token id="31" string="urine" />
            <token id="32" string="sample" />
            <token id="33" string="after" />
            <token id="34" string="his" />
            <token id="35" string="world" />
            <token id="36" string="record" />
            <token id="37" string="100-meter" />
            <token id="38" string="run" />
            <token id="39" string="at" />
            <token id="40" string="the" />
            <token id="41" string="Olympics" />
          </tokens>
        </chunking>
        <chunking id="4" string="he has never knowingly taken illegal drugs while Astaphan has said he has never administered stanozolol _ the banned steroid found in the runner 's urine sample after his world record 100-meter run at the Olympics" type="SBAR">
          <tokens>
            <token id="6" string="he" />
            <token id="7" string="has" />
            <token id="8" string="never" />
            <token id="9" string="knowingly" />
            <token id="10" string="taken" />
            <token id="11" string="illegal" />
            <token id="12" string="drugs" />
            <token id="13" string="while" />
            <token id="14" string="Astaphan" />
            <token id="15" string="has" />
            <token id="16" string="said" />
            <token id="17" string="he" />
            <token id="18" string="has" />
            <token id="19" string="never" />
            <token id="20" string="administered" />
            <token id="21" string="stanozolol" />
            <token id="22" string="_" />
            <token id="23" string="the" />
            <token id="24" string="banned" />
            <token id="25" string="steroid" />
            <token id="26" string="found" />
            <token id="27" string="in" />
            <token id="28" string="the" />
            <token id="29" string="runner" />
            <token id="30" string="'s" />
            <token id="31" string="urine" />
            <token id="32" string="sample" />
            <token id="33" string="after" />
            <token id="34" string="his" />
            <token id="35" string="world" />
            <token id="36" string="record" />
            <token id="37" string="100-meter" />
            <token id="38" string="run" />
            <token id="39" string="at" />
            <token id="40" string="the" />
            <token id="41" string="Olympics" />
          </tokens>
        </chunking>
        <chunking id="5" string="stanozolol" type="NP">
          <tokens>
            <token id="21" string="stanozolol" />
          </tokens>
        </chunking>
        <chunking id="6" string="his world record 100-meter run" type="NP">
          <tokens>
            <token id="34" string="his" />
            <token id="35" string="world" />
            <token id="36" string="record" />
            <token id="37" string="100-meter" />
            <token id="38" string="run" />
          </tokens>
        </chunking>
        <chunking id="7" string="the runner 's urine sample" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="runner" />
            <token id="30" string="'s" />
            <token id="31" string="urine" />
            <token id="32" string="sample" />
          </tokens>
        </chunking>
        <chunking id="8" string="has never administered stanozolol _ the banned steroid found in the runner 's urine sample after his world record 100-meter run at the Olympics" type="VP">
          <tokens>
            <token id="18" string="has" />
            <token id="19" string="never" />
            <token id="20" string="administered" />
            <token id="21" string="stanozolol" />
            <token id="22" string="_" />
            <token id="23" string="the" />
            <token id="24" string="banned" />
            <token id="25" string="steroid" />
            <token id="26" string="found" />
            <token id="27" string="in" />
            <token id="28" string="the" />
            <token id="29" string="runner" />
            <token id="30" string="'s" />
            <token id="31" string="urine" />
            <token id="32" string="sample" />
            <token id="33" string="after" />
            <token id="34" string="his" />
            <token id="35" string="world" />
            <token id="36" string="record" />
            <token id="37" string="100-meter" />
            <token id="38" string="run" />
            <token id="39" string="at" />
            <token id="40" string="the" />
            <token id="41" string="Olympics" />
          </tokens>
        </chunking>
        <chunking id="9" string="has never knowingly taken illegal drugs while Astaphan has said he has never administered stanozolol _ the banned steroid found in the runner 's urine sample after his world record 100-meter run at the Olympics" type="VP">
          <tokens>
            <token id="7" string="has" />
            <token id="8" string="never" />
            <token id="9" string="knowingly" />
            <token id="10" string="taken" />
            <token id="11" string="illegal" />
            <token id="12" string="drugs" />
            <token id="13" string="while" />
            <token id="14" string="Astaphan" />
            <token id="15" string="has" />
            <token id="16" string="said" />
            <token id="17" string="he" />
            <token id="18" string="has" />
            <token id="19" string="never" />
            <token id="20" string="administered" />
            <token id="21" string="stanozolol" />
            <token id="22" string="_" />
            <token id="23" string="the" />
            <token id="24" string="banned" />
            <token id="25" string="steroid" />
            <token id="26" string="found" />
            <token id="27" string="in" />
            <token id="28" string="the" />
            <token id="29" string="runner" />
            <token id="30" string="'s" />
            <token id="31" string="urine" />
            <token id="32" string="sample" />
            <token id="33" string="after" />
            <token id="34" string="his" />
            <token id="35" string="world" />
            <token id="36" string="record" />
            <token id="37" string="100-meter" />
            <token id="38" string="run" />
            <token id="39" string="at" />
            <token id="40" string="the" />
            <token id="41" string="Olympics" />
          </tokens>
        </chunking>
        <chunking id="10" string="he has never administered stanozolol _ the banned steroid found in the runner 's urine sample after his world record 100-meter run at the Olympics" type="SBAR">
          <tokens>
            <token id="17" string="he" />
            <token id="18" string="has" />
            <token id="19" string="never" />
            <token id="20" string="administered" />
            <token id="21" string="stanozolol" />
            <token id="22" string="_" />
            <token id="23" string="the" />
            <token id="24" string="banned" />
            <token id="25" string="steroid" />
            <token id="26" string="found" />
            <token id="27" string="in" />
            <token id="28" string="the" />
            <token id="29" string="runner" />
            <token id="30" string="'s" />
            <token id="31" string="urine" />
            <token id="32" string="sample" />
            <token id="33" string="after" />
            <token id="34" string="his" />
            <token id="35" string="world" />
            <token id="36" string="record" />
            <token id="37" string="100-meter" />
            <token id="38" string="run" />
            <token id="39" string="at" />
            <token id="40" string="the" />
            <token id="41" string="Olympics" />
          </tokens>
        </chunking>
        <chunking id="11" string="administered stanozolol _ the banned steroid found in the runner 's urine sample after his world record 100-meter run at the Olympics" type="VP">
          <tokens>
            <token id="20" string="administered" />
            <token id="21" string="stanozolol" />
            <token id="22" string="_" />
            <token id="23" string="the" />
            <token id="24" string="banned" />
            <token id="25" string="steroid" />
            <token id="26" string="found" />
            <token id="27" string="in" />
            <token id="28" string="the" />
            <token id="29" string="runner" />
            <token id="30" string="'s" />
            <token id="31" string="urine" />
            <token id="32" string="sample" />
            <token id="33" string="after" />
            <token id="34" string="his" />
            <token id="35" string="world" />
            <token id="36" string="record" />
            <token id="37" string="100-meter" />
            <token id="38" string="run" />
            <token id="39" string="at" />
            <token id="40" string="the" />
            <token id="41" string="Olympics" />
          </tokens>
        </chunking>
        <chunking id="12" string="the banned steroid" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="banned" />
            <token id="25" string="steroid" />
          </tokens>
        </chunking>
        <chunking id="13" string="the Olympics" type="NP">
          <tokens>
            <token id="40" string="the" />
            <token id="41" string="Olympics" />
          </tokens>
        </chunking>
        <chunking id="14" string="Astaphan" type="NP">
          <tokens>
            <token id="14" string="Astaphan" />
          </tokens>
        </chunking>
        <chunking id="15" string="has said he has never administered stanozolol _ the banned steroid found in the runner 's urine sample after his world record 100-meter run at the Olympics" type="VP">
          <tokens>
            <token id="15" string="has" />
            <token id="16" string="said" />
            <token id="17" string="he" />
            <token id="18" string="has" />
            <token id="19" string="never" />
            <token id="20" string="administered" />
            <token id="21" string="stanozolol" />
            <token id="22" string="_" />
            <token id="23" string="the" />
            <token id="24" string="banned" />
            <token id="25" string="steroid" />
            <token id="26" string="found" />
            <token id="27" string="in" />
            <token id="28" string="the" />
            <token id="29" string="runner" />
            <token id="30" string="'s" />
            <token id="31" string="urine" />
            <token id="32" string="sample" />
            <token id="33" string="after" />
            <token id="34" string="his" />
            <token id="35" string="world" />
            <token id="36" string="record" />
            <token id="37" string="100-meter" />
            <token id="38" string="run" />
            <token id="39" string="at" />
            <token id="40" string="the" />
            <token id="41" string="Olympics" />
          </tokens>
        </chunking>
        <chunking id="16" string="he" type="NP">
          <tokens>
            <token id="6" string="he" />
          </tokens>
        </chunking>
        <chunking id="17" string="world record 100-meter" type="ADJP">
          <tokens>
            <token id="35" string="world" />
            <token id="36" string="record" />
            <token id="37" string="100-meter" />
          </tokens>
        </chunking>
        <chunking id="18" string="while Astaphan has said he has never administered stanozolol _ the banned steroid found in the runner 's urine sample after his world record 100-meter run at the Olympics" type="SBAR">
          <tokens>
            <token id="13" string="while" />
            <token id="14" string="Astaphan" />
            <token id="15" string="has" />
            <token id="16" string="said" />
            <token id="17" string="he" />
            <token id="18" string="has" />
            <token id="19" string="never" />
            <token id="20" string="administered" />
            <token id="21" string="stanozolol" />
            <token id="22" string="_" />
            <token id="23" string="the" />
            <token id="24" string="banned" />
            <token id="25" string="steroid" />
            <token id="26" string="found" />
            <token id="27" string="in" />
            <token id="28" string="the" />
            <token id="29" string="runner" />
            <token id="30" string="'s" />
            <token id="31" string="urine" />
            <token id="32" string="sample" />
            <token id="33" string="after" />
            <token id="34" string="his" />
            <token id="35" string="world" />
            <token id="36" string="record" />
            <token id="37" string="100-meter" />
            <token id="38" string="run" />
            <token id="39" string="at" />
            <token id="40" string="the" />
            <token id="41" string="Olympics" />
          </tokens>
        </chunking>
        <chunking id="19" string="Johnson , 26 ," type="NP">
          <tokens>
            <token id="1" string="Johnson" />
            <token id="2" string="," />
            <token id="3" string="26" />
            <token id="4" string="," />
          </tokens>
        </chunking>
        <chunking id="20" string="26" type="NP">
          <tokens>
            <token id="3" string="26" />
          </tokens>
        </chunking>
        <chunking id="21" string="found in the runner 's urine sample after his world record 100-meter run at the Olympics" type="VP">
          <tokens>
            <token id="26" string="found" />
            <token id="27" string="in" />
            <token id="28" string="the" />
            <token id="29" string="runner" />
            <token id="30" string="'s" />
            <token id="31" string="urine" />
            <token id="32" string="sample" />
            <token id="33" string="after" />
            <token id="34" string="his" />
            <token id="35" string="world" />
            <token id="36" string="record" />
            <token id="37" string="100-meter" />
            <token id="38" string="run" />
            <token id="39" string="at" />
            <token id="40" string="the" />
            <token id="41" string="Olympics" />
          </tokens>
        </chunking>
        <chunking id="22" string="knowingly taken illegal drugs while Astaphan has said he has never administered stanozolol _ the banned steroid found in the runner 's urine sample after his world record 100-meter run at the Olympics" type="VP">
          <tokens>
            <token id="9" string="knowingly" />
            <token id="10" string="taken" />
            <token id="11" string="illegal" />
            <token id="12" string="drugs" />
            <token id="13" string="while" />
            <token id="14" string="Astaphan" />
            <token id="15" string="has" />
            <token id="16" string="said" />
            <token id="17" string="he" />
            <token id="18" string="has" />
            <token id="19" string="never" />
            <token id="20" string="administered" />
            <token id="21" string="stanozolol" />
            <token id="22" string="_" />
            <token id="23" string="the" />
            <token id="24" string="banned" />
            <token id="25" string="steroid" />
            <token id="26" string="found" />
            <token id="27" string="in" />
            <token id="28" string="the" />
            <token id="29" string="runner" />
            <token id="30" string="'s" />
            <token id="31" string="urine" />
            <token id="32" string="sample" />
            <token id="33" string="after" />
            <token id="34" string="his" />
            <token id="35" string="world" />
            <token id="36" string="record" />
            <token id="37" string="100-meter" />
            <token id="38" string="run" />
            <token id="39" string="at" />
            <token id="40" string="the" />
            <token id="41" string="Olympics" />
          </tokens>
        </chunking>
        <chunking id="23" string="the banned steroid found in the runner 's urine sample after his world record 100-meter run at the Olympics" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="banned" />
            <token id="25" string="steroid" />
            <token id="26" string="found" />
            <token id="27" string="in" />
            <token id="28" string="the" />
            <token id="29" string="runner" />
            <token id="30" string="'s" />
            <token id="31" string="urine" />
            <token id="32" string="sample" />
            <token id="33" string="after" />
            <token id="34" string="his" />
            <token id="35" string="world" />
            <token id="36" string="record" />
            <token id="37" string="100-meter" />
            <token id="38" string="run" />
            <token id="39" string="at" />
            <token id="40" string="the" />
            <token id="41" string="Olympics" />
          </tokens>
        </chunking>
        <chunking id="24" string="the runner 's" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="runner" />
            <token id="30" string="'s" />
          </tokens>
        </chunking>
        <chunking id="25" string="illegal drugs" type="NP">
          <tokens>
            <token id="11" string="illegal" />
            <token id="12" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="26" string="his world record 100-meter run at the Olympics" type="NP">
          <tokens>
            <token id="34" string="his" />
            <token id="35" string="world" />
            <token id="36" string="record" />
            <token id="37" string="100-meter" />
            <token id="38" string="run" />
            <token id="39" string="at" />
            <token id="40" string="the" />
            <token id="41" string="Olympics" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">says</governor>
          <dependent id="1">Johnson</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="1">Johnson</governor>
          <dependent id="3">26</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">says</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">taken</governor>
          <dependent id="6">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">taken</governor>
          <dependent id="7">has</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="10">taken</governor>
          <dependent id="8">never</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">taken</governor>
          <dependent id="9">knowingly</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">says</governor>
          <dependent id="10">taken</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">drugs</governor>
          <dependent id="11">illegal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">taken</governor>
          <dependent id="12">drugs</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">said</governor>
          <dependent id="13">while</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">said</governor>
          <dependent id="14">Astaphan</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">said</governor>
          <dependent id="15">has</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="10">taken</governor>
          <dependent id="16">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">administered</governor>
          <dependent id="17">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="20">administered</governor>
          <dependent id="18">has</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="20">administered</governor>
          <dependent id="19">never</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">said</governor>
          <dependent id="20">administered</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">administered</governor>
          <dependent id="21">stanozolol</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">steroid</governor>
          <dependent id="22">_</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">steroid</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">steroid</governor>
          <dependent id="24">banned</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">administered</governor>
          <dependent id="25">steroid</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="25">steroid</governor>
          <dependent id="26">found</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">sample</governor>
          <dependent id="27">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">runner</governor>
          <dependent id="28">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="32">sample</governor>
          <dependent id="29">runner</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">runner</governor>
          <dependent id="30">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="32">sample</governor>
          <dependent id="31">urine</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">found</governor>
          <dependent id="32">sample</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">run</governor>
          <dependent id="33">after</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="38">run</governor>
          <dependent id="34">his</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="37">100-meter</governor>
          <dependent id="35">world</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="37">100-meter</governor>
          <dependent id="36">record</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="38">run</governor>
          <dependent id="37">100-meter</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">found</governor>
          <dependent id="38">run</dependent>
        </dependency>
        <dependency type="case">
          <governor id="41">Olympics</governor>
          <dependent id="39">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="41">Olympics</governor>
          <dependent id="40">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="38">run</governor>
          <dependent id="41">Olympics</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="26" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="26" />
          </tokens>
        </entity>
        <entity id="3" string="drugs" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="12" string="drugs" />
          </tokens>
        </entity>
        <entity id="4" string="Astaphan" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Astaphan" />
          </tokens>
        </entity>
        <entity id="5" string="Olympics" type="MISC" score="0.0">
          <tokens>
            <token id="41" string="Olympics" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>Francis, meanwhile, has said the test result ``defies all logic&amp;apost;&amp;apost; and could only be explained ``by deliberate manipulation of the testing process.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="Francis" lemma="Francis" stem="franci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="meanwhile" lemma="meanwhile" stem="meanwhil" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="test" lemma="test" stem="test" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="result" lemma="result" stem="result" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="defies" lemma="defy" stem="defi" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="logic" lemma="logic" stem="logic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="explained" lemma="explain" stem="explain" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="deliberate" lemma="deliberate" stem="deliber" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="manipulation" lemma="manipulation" stem="manipul" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="testing" lemma="testing" stem="test" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="process" lemma="process" stem="process" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Francis)) (, ,) (ADVP (RB meanwhile)) (, ,) (VP (VBZ has) (VP (VBD said) (SBAR (S (NP (DT the) (NN test)) (VP (VBP result) (SBAR (S (VP (`` ``) (VP (VBZ defies) (NP (DT all) (NN logic))) ('' '') (CC and) (VP (MD could) (ADVP (RB only)) (VP (VB be) (VP (VBN explained) (PP (`` ``) (IN by) (NP (NP (ADJP (JJ deliberate)) (NN manipulation)) (PP (IN of) (NP (DT the) (NN testing) (NN process)))))))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="deliberate manipulation of the testing process" type="NP">
          <tokens>
            <token id="22" string="deliberate" />
            <token id="23" string="manipulation" />
            <token id="24" string="of" />
            <token id="25" string="the" />
            <token id="26" string="testing" />
            <token id="27" string="process" />
          </tokens>
        </chunking>
        <chunking id="2" string="result `` defies all logic '' and could only be explained `` by deliberate manipulation of the testing process" type="VP">
          <tokens>
            <token id="9" string="result" />
            <token id="10" string="``" />
            <token id="11" string="defies" />
            <token id="12" string="all" />
            <token id="13" string="logic" />
            <token id="14" string="''" />
            <token id="15" string="and" />
            <token id="16" string="could" />
            <token id="17" string="only" />
            <token id="18" string="be" />
            <token id="19" string="explained" />
            <token id="20" string="``" />
            <token id="21" string="by" />
            <token id="22" string="deliberate" />
            <token id="23" string="manipulation" />
            <token id="24" string="of" />
            <token id="25" string="the" />
            <token id="26" string="testing" />
            <token id="27" string="process" />
          </tokens>
        </chunking>
        <chunking id="3" string="the test" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="test" />
          </tokens>
        </chunking>
        <chunking id="4" string="could only be explained `` by deliberate manipulation of the testing process" type="VP">
          <tokens>
            <token id="16" string="could" />
            <token id="17" string="only" />
            <token id="18" string="be" />
            <token id="19" string="explained" />
            <token id="20" string="``" />
            <token id="21" string="by" />
            <token id="22" string="deliberate" />
            <token id="23" string="manipulation" />
            <token id="24" string="of" />
            <token id="25" string="the" />
            <token id="26" string="testing" />
            <token id="27" string="process" />
          </tokens>
        </chunking>
        <chunking id="5" string="be explained `` by deliberate manipulation of the testing process" type="VP">
          <tokens>
            <token id="18" string="be" />
            <token id="19" string="explained" />
            <token id="20" string="``" />
            <token id="21" string="by" />
            <token id="22" string="deliberate" />
            <token id="23" string="manipulation" />
            <token id="24" string="of" />
            <token id="25" string="the" />
            <token id="26" string="testing" />
            <token id="27" string="process" />
          </tokens>
        </chunking>
        <chunking id="6" string="explained `` by deliberate manipulation of the testing process" type="VP">
          <tokens>
            <token id="19" string="explained" />
            <token id="20" string="``" />
            <token id="21" string="by" />
            <token id="22" string="deliberate" />
            <token id="23" string="manipulation" />
            <token id="24" string="of" />
            <token id="25" string="the" />
            <token id="26" string="testing" />
            <token id="27" string="process" />
          </tokens>
        </chunking>
        <chunking id="7" string="defies all logic" type="VP">
          <tokens>
            <token id="11" string="defies" />
            <token id="12" string="all" />
            <token id="13" string="logic" />
          </tokens>
        </chunking>
        <chunking id="8" string="has said the test result `` defies all logic '' and could only be explained `` by deliberate manipulation of the testing process" type="VP">
          <tokens>
            <token id="5" string="has" />
            <token id="6" string="said" />
            <token id="7" string="the" />
            <token id="8" string="test" />
            <token id="9" string="result" />
            <token id="10" string="``" />
            <token id="11" string="defies" />
            <token id="12" string="all" />
            <token id="13" string="logic" />
            <token id="14" string="''" />
            <token id="15" string="and" />
            <token id="16" string="could" />
            <token id="17" string="only" />
            <token id="18" string="be" />
            <token id="19" string="explained" />
            <token id="20" string="``" />
            <token id="21" string="by" />
            <token id="22" string="deliberate" />
            <token id="23" string="manipulation" />
            <token id="24" string="of" />
            <token id="25" string="the" />
            <token id="26" string="testing" />
            <token id="27" string="process" />
          </tokens>
        </chunking>
        <chunking id="9" string="the test result `` defies all logic '' and could only be explained `` by deliberate manipulation of the testing process" type="SBAR">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="test" />
            <token id="9" string="result" />
            <token id="10" string="``" />
            <token id="11" string="defies" />
            <token id="12" string="all" />
            <token id="13" string="logic" />
            <token id="14" string="''" />
            <token id="15" string="and" />
            <token id="16" string="could" />
            <token id="17" string="only" />
            <token id="18" string="be" />
            <token id="19" string="explained" />
            <token id="20" string="``" />
            <token id="21" string="by" />
            <token id="22" string="deliberate" />
            <token id="23" string="manipulation" />
            <token id="24" string="of" />
            <token id="25" string="the" />
            <token id="26" string="testing" />
            <token id="27" string="process" />
          </tokens>
        </chunking>
        <chunking id="10" string="all logic" type="NP">
          <tokens>
            <token id="12" string="all" />
            <token id="13" string="logic" />
          </tokens>
        </chunking>
        <chunking id="11" string="deliberate manipulation" type="NP">
          <tokens>
            <token id="22" string="deliberate" />
            <token id="23" string="manipulation" />
          </tokens>
        </chunking>
        <chunking id="12" string="Francis" type="NP">
          <tokens>
            <token id="1" string="Francis" />
          </tokens>
        </chunking>
        <chunking id="13" string="`` defies all logic '' and could only be explained `` by deliberate manipulation of the testing process" type="SBAR">
          <tokens>
            <token id="10" string="``" />
            <token id="11" string="defies" />
            <token id="12" string="all" />
            <token id="13" string="logic" />
            <token id="14" string="''" />
            <token id="15" string="and" />
            <token id="16" string="could" />
            <token id="17" string="only" />
            <token id="18" string="be" />
            <token id="19" string="explained" />
            <token id="20" string="``" />
            <token id="21" string="by" />
            <token id="22" string="deliberate" />
            <token id="23" string="manipulation" />
            <token id="24" string="of" />
            <token id="25" string="the" />
            <token id="26" string="testing" />
            <token id="27" string="process" />
          </tokens>
        </chunking>
        <chunking id="14" string="the testing process" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="testing" />
            <token id="27" string="process" />
          </tokens>
        </chunking>
        <chunking id="15" string="said the test result `` defies all logic '' and could only be explained `` by deliberate manipulation of the testing process" type="VP">
          <tokens>
            <token id="6" string="said" />
            <token id="7" string="the" />
            <token id="8" string="test" />
            <token id="9" string="result" />
            <token id="10" string="``" />
            <token id="11" string="defies" />
            <token id="12" string="all" />
            <token id="13" string="logic" />
            <token id="14" string="''" />
            <token id="15" string="and" />
            <token id="16" string="could" />
            <token id="17" string="only" />
            <token id="18" string="be" />
            <token id="19" string="explained" />
            <token id="20" string="``" />
            <token id="21" string="by" />
            <token id="22" string="deliberate" />
            <token id="23" string="manipulation" />
            <token id="24" string="of" />
            <token id="25" string="the" />
            <token id="26" string="testing" />
            <token id="27" string="process" />
          </tokens>
        </chunking>
        <chunking id="16" string="deliberate" type="ADJP">
          <tokens>
            <token id="22" string="deliberate" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">said</governor>
          <dependent id="1">Francis</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">said</governor>
          <dependent id="3">meanwhile</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">said</governor>
          <dependent id="5">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">test</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">result</governor>
          <dependent id="8">test</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">said</governor>
          <dependent id="9">result</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">result</governor>
          <dependent id="11">defies</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">logic</governor>
          <dependent id="12">all</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">defies</governor>
          <dependent id="13">logic</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">defies</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="19">explained</governor>
          <dependent id="16">could</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">explained</governor>
          <dependent id="17">only</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="19">explained</governor>
          <dependent id="18">be</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">defies</governor>
          <dependent id="19">explained</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">manipulation</governor>
          <dependent id="21">by</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">manipulation</governor>
          <dependent id="22">deliberate</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">explained</governor>
          <dependent id="23">manipulation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">process</governor>
          <dependent id="24">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">process</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">process</governor>
          <dependent id="26">testing</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">manipulation</governor>
          <dependent id="27">process</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Francis" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Francis" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>Ms. Issajenko, 30, was quoted as saying she had first-hand knowledge Johnson received steroids from Astaphan from 1984 to 1986 but ``Ben was going on his own to Jamie after that.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="Ms." lemma="Ms." stem="ms." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="Issajenko" lemma="Issajenko" stem="issajenko" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="30" lemma="30" stem="30" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="quoted" lemma="quote" stem="quot" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="saying" lemma="say" stem="sai" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="first-hand" lemma="first-hand" stem="first-hand" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="knowledge" lemma="knowledge" stem="knowledg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="15" string="received" lemma="receive" stem="receiv" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="steroids" lemma="steroid" stem="steroid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Astaphan" lemma="Astaphan" stem="astaphan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="19" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="1984" lemma="1984" stem="1984" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="21" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="22" string="1986" lemma="1986" stem="1986" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="23" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="Ben" lemma="Ben" stem="ben" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="26" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="30" string="own" lemma="own" stem="own" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="Jamie" lemma="Jamie" stem="jami" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="33" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (NNP Ms.) (NNP Issajenko)) (, ,) (NP (CD 30)) (, ,)) (VP (VBD was) (VP (VBN quoted) (PP (IN as) (S (VP (VBG saying) (SBAR (S (NP (PRP she)) (VP (VBD had) (NP (JJ first-hand) (NN knowledge))))))))))) (PRN (NP (NNP Johnson)) (VP (VBD received) (NP (NNS steroids)) (PP (IN from) (NP (NNP Astaphan))) (PP (IN from) (NP (CD 1984) (TO to) (CD 1986))))) (CC but) (`` ``) (S (NP (NNP Ben)) (VP (VBD was) (VP (VBG going) (PP (IN on) (NP (PRP$ his) (JJ own))) (PP (TO to) (NP (NNP Jamie))) (PP (IN after) (NP (DT that)))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="she had first-hand knowledge" type="SBAR">
          <tokens>
            <token id="10" string="she" />
            <token id="11" string="had" />
            <token id="12" string="first-hand" />
            <token id="13" string="knowledge" />
          </tokens>
        </chunking>
        <chunking id="2" string="Johnson" type="NP">
          <tokens>
            <token id="14" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="3" string="saying she had first-hand knowledge" type="VP">
          <tokens>
            <token id="9" string="saying" />
            <token id="10" string="she" />
            <token id="11" string="had" />
            <token id="12" string="first-hand" />
            <token id="13" string="knowledge" />
          </tokens>
        </chunking>
        <chunking id="4" string="received steroids from Astaphan from 1984 to 1986" type="VP">
          <tokens>
            <token id="15" string="received" />
            <token id="16" string="steroids" />
            <token id="17" string="from" />
            <token id="18" string="Astaphan" />
            <token id="19" string="from" />
            <token id="20" string="1984" />
            <token id="21" string="to" />
            <token id="22" string="1986" />
          </tokens>
        </chunking>
        <chunking id="5" string="quoted as saying she had first-hand knowledge" type="VP">
          <tokens>
            <token id="7" string="quoted" />
            <token id="8" string="as" />
            <token id="9" string="saying" />
            <token id="10" string="she" />
            <token id="11" string="had" />
            <token id="12" string="first-hand" />
            <token id="13" string="knowledge" />
          </tokens>
        </chunking>
        <chunking id="6" string="Ben" type="NP">
          <tokens>
            <token id="25" string="Ben" />
          </tokens>
        </chunking>
        <chunking id="7" string="she" type="NP">
          <tokens>
            <token id="10" string="she" />
          </tokens>
        </chunking>
        <chunking id="8" string="1984 to 1986" type="NP">
          <tokens>
            <token id="20" string="1984" />
            <token id="21" string="to" />
            <token id="22" string="1986" />
          </tokens>
        </chunking>
        <chunking id="9" string="was going on his own to Jamie after that" type="VP">
          <tokens>
            <token id="26" string="was" />
            <token id="27" string="going" />
            <token id="28" string="on" />
            <token id="29" string="his" />
            <token id="30" string="own" />
            <token id="31" string="to" />
            <token id="32" string="Jamie" />
            <token id="33" string="after" />
            <token id="34" string="that" />
          </tokens>
        </chunking>
        <chunking id="10" string="his own" type="NP">
          <tokens>
            <token id="29" string="his" />
            <token id="30" string="own" />
          </tokens>
        </chunking>
        <chunking id="11" string="first-hand knowledge" type="NP">
          <tokens>
            <token id="12" string="first-hand" />
            <token id="13" string="knowledge" />
          </tokens>
        </chunking>
        <chunking id="12" string="Ms. Issajenko , 30 ," type="NP">
          <tokens>
            <token id="1" string="Ms." />
            <token id="2" string="Issajenko" />
            <token id="3" string="," />
            <token id="4" string="30" />
            <token id="5" string="," />
          </tokens>
        </chunking>
        <chunking id="13" string="that" type="NP">
          <tokens>
            <token id="34" string="that" />
          </tokens>
        </chunking>
        <chunking id="14" string="had first-hand knowledge" type="VP">
          <tokens>
            <token id="11" string="had" />
            <token id="12" string="first-hand" />
            <token id="13" string="knowledge" />
          </tokens>
        </chunking>
        <chunking id="15" string="Jamie" type="NP">
          <tokens>
            <token id="32" string="Jamie" />
          </tokens>
        </chunking>
        <chunking id="16" string="Astaphan" type="NP">
          <tokens>
            <token id="18" string="Astaphan" />
          </tokens>
        </chunking>
        <chunking id="17" string="Ms. Issajenko" type="NP">
          <tokens>
            <token id="1" string="Ms." />
            <token id="2" string="Issajenko" />
          </tokens>
        </chunking>
        <chunking id="18" string="going on his own to Jamie after that" type="VP">
          <tokens>
            <token id="27" string="going" />
            <token id="28" string="on" />
            <token id="29" string="his" />
            <token id="30" string="own" />
            <token id="31" string="to" />
            <token id="32" string="Jamie" />
            <token id="33" string="after" />
            <token id="34" string="that" />
          </tokens>
        </chunking>
        <chunking id="19" string="steroids" type="NP">
          <tokens>
            <token id="16" string="steroids" />
          </tokens>
        </chunking>
        <chunking id="20" string="30" type="NP">
          <tokens>
            <token id="4" string="30" />
          </tokens>
        </chunking>
        <chunking id="21" string="was quoted as saying she had first-hand knowledge" type="VP">
          <tokens>
            <token id="6" string="was" />
            <token id="7" string="quoted" />
            <token id="8" string="as" />
            <token id="9" string="saying" />
            <token id="10" string="she" />
            <token id="11" string="had" />
            <token id="12" string="first-hand" />
            <token id="13" string="knowledge" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Issajenko</governor>
          <dependent id="1">Ms.</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="7">quoted</governor>
          <dependent id="2">Issajenko</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="2">Issajenko</governor>
          <dependent id="4">30</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="7">quoted</governor>
          <dependent id="6">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">quoted</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">saying</governor>
          <dependent id="8">as</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">quoted</governor>
          <dependent id="9">saying</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">had</governor>
          <dependent id="10">she</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">saying</governor>
          <dependent id="11">had</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">knowledge</governor>
          <dependent id="12">first-hand</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">had</governor>
          <dependent id="13">knowledge</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">received</governor>
          <dependent id="14">Johnson</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">quoted</governor>
          <dependent id="15">received</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">received</governor>
          <dependent id="16">steroids</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Astaphan</governor>
          <dependent id="17">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">received</governor>
          <dependent id="18">Astaphan</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">1986</governor>
          <dependent id="19">from</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="22">1986</governor>
          <dependent id="20">1984</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="22">1986</governor>
          <dependent id="21">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">received</governor>
          <dependent id="22">1986</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">quoted</governor>
          <dependent id="23">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">going</governor>
          <dependent id="25">Ben</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="27">going</governor>
          <dependent id="26">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">quoted</governor>
          <dependent id="27">going</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">own</governor>
          <dependent id="28">on</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="30">own</governor>
          <dependent id="29">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">going</governor>
          <dependent id="30">own</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">Jamie</governor>
          <dependent id="31">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">going</governor>
          <dependent id="32">Jamie</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">that</governor>
          <dependent id="33">after</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">going</governor>
          <dependent id="34">that</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Jamie" type="PERSON" score="0.0">
          <tokens>
            <token id="32" string="Jamie" />
          </tokens>
        </entity>
        <entity id="2" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Johnson" />
          </tokens>
        </entity>
        <entity id="3" string="Astaphan" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Astaphan" />
          </tokens>
        </entity>
        <entity id="4" string="Ben" type="PERSON" score="0.0">
          <tokens>
            <token id="25" string="Ben" />
          </tokens>
        </entity>
        <entity id="5" string="Issajenko" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Issajenko" />
          </tokens>
        </entity>
        <entity id="6" string="30" type="NUMBER" score="0.0">
          <tokens>
            <token id="4" string="30" />
          </tokens>
        </entity>
        <entity id="7" string="1984 to 1986" type="DATE" score="0.0">
          <tokens>
            <token id="20" string="1984" />
            <token id="21" string="to" />
            <token id="22" string="1986" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>She also said Astaphan was administering steroids to Johnson when he set a 9.83-second world record in the 100-metre sprint at the world championships in Rome.</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="Astaphan" lemma="Astaphan" stem="astaphan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="5" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="administering" lemma="administer" stem="administ" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="steroids" lemma="steroid" stem="steroid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="10" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="set" lemma="set" stem="set" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="9.83-second" lemma="9.83-second" stem="9.83-second" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="15" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="record" lemma="record" stem="record" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="100-metre" lemma="100-metre" stem="100-metr" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="sprint" lemma="sprint" stem="sprint" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="championships" lemma="championship" stem="championship" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="Rome" lemma="Rome" stem="rome" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP She)) (ADVP (RB also)) (VP (VBD said) (SBAR (S (NP (NNP Astaphan)) (VP (VBD was) (VP (VBG administering) (NP (NNS steroids)) (PP (TO to) (NP (NNP Johnson))) (SBAR (WHADVP (WRB when)) (S (NP (PRP he)) (VP (VBD set) (NP (DT a) (JJ 9.83-second) (NN world) (NN record)) (PP (IN in) (NP (DT the) (JJ 100-metre) (NN sprint))) (PP (IN at) (NP (NP (DT the) (NN world) (NNS championships)) (PP (IN in) (NP (NNP Rome))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the world championships" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="world" />
            <token id="24" string="championships" />
          </tokens>
        </chunking>
        <chunking id="2" string="Johnson" type="NP">
          <tokens>
            <token id="9" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="3" string="said Astaphan was administering steroids to Johnson when he set a 9.83-second world record in the 100-metre sprint at the world championships in Rome" type="VP">
          <tokens>
            <token id="3" string="said" />
            <token id="4" string="Astaphan" />
            <token id="5" string="was" />
            <token id="6" string="administering" />
            <token id="7" string="steroids" />
            <token id="8" string="to" />
            <token id="9" string="Johnson" />
            <token id="10" string="when" />
            <token id="11" string="he" />
            <token id="12" string="set" />
            <token id="13" string="a" />
            <token id="14" string="9.83-second" />
            <token id="15" string="world" />
            <token id="16" string="record" />
            <token id="17" string="in" />
            <token id="18" string="the" />
            <token id="19" string="100-metre" />
            <token id="20" string="sprint" />
            <token id="21" string="at" />
            <token id="22" string="the" />
            <token id="23" string="world" />
            <token id="24" string="championships" />
            <token id="25" string="in" />
            <token id="26" string="Rome" />
          </tokens>
        </chunking>
        <chunking id="4" string="set a 9.83-second world record in the 100-metre sprint at the world championships in Rome" type="VP">
          <tokens>
            <token id="12" string="set" />
            <token id="13" string="a" />
            <token id="14" string="9.83-second" />
            <token id="15" string="world" />
            <token id="16" string="record" />
            <token id="17" string="in" />
            <token id="18" string="the" />
            <token id="19" string="100-metre" />
            <token id="20" string="sprint" />
            <token id="21" string="at" />
            <token id="22" string="the" />
            <token id="23" string="world" />
            <token id="24" string="championships" />
            <token id="25" string="in" />
            <token id="26" string="Rome" />
          </tokens>
        </chunking>
        <chunking id="5" string="the 100-metre sprint" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="100-metre" />
            <token id="20" string="sprint" />
          </tokens>
        </chunking>
        <chunking id="6" string="was administering steroids to Johnson when he set a 9.83-second world record in the 100-metre sprint at the world championships in Rome" type="VP">
          <tokens>
            <token id="5" string="was" />
            <token id="6" string="administering" />
            <token id="7" string="steroids" />
            <token id="8" string="to" />
            <token id="9" string="Johnson" />
            <token id="10" string="when" />
            <token id="11" string="he" />
            <token id="12" string="set" />
            <token id="13" string="a" />
            <token id="14" string="9.83-second" />
            <token id="15" string="world" />
            <token id="16" string="record" />
            <token id="17" string="in" />
            <token id="18" string="the" />
            <token id="19" string="100-metre" />
            <token id="20" string="sprint" />
            <token id="21" string="at" />
            <token id="22" string="the" />
            <token id="23" string="world" />
            <token id="24" string="championships" />
            <token id="25" string="in" />
            <token id="26" string="Rome" />
          </tokens>
        </chunking>
        <chunking id="7" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
        <chunking id="8" string="when" type="WHADVP">
          <tokens>
            <token id="10" string="when" />
          </tokens>
        </chunking>
        <chunking id="9" string="when he set a 9.83-second world record in the 100-metre sprint at the world championships in Rome" type="SBAR">
          <tokens>
            <token id="10" string="when" />
            <token id="11" string="he" />
            <token id="12" string="set" />
            <token id="13" string="a" />
            <token id="14" string="9.83-second" />
            <token id="15" string="world" />
            <token id="16" string="record" />
            <token id="17" string="in" />
            <token id="18" string="the" />
            <token id="19" string="100-metre" />
            <token id="20" string="sprint" />
            <token id="21" string="at" />
            <token id="22" string="the" />
            <token id="23" string="world" />
            <token id="24" string="championships" />
            <token id="25" string="in" />
            <token id="26" string="Rome" />
          </tokens>
        </chunking>
        <chunking id="10" string="Rome" type="NP">
          <tokens>
            <token id="26" string="Rome" />
          </tokens>
        </chunking>
        <chunking id="11" string="a 9.83-second world record" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="9.83-second" />
            <token id="15" string="world" />
            <token id="16" string="record" />
          </tokens>
        </chunking>
        <chunking id="12" string="Astaphan" type="NP">
          <tokens>
            <token id="4" string="Astaphan" />
          </tokens>
        </chunking>
        <chunking id="13" string="Astaphan was administering steroids to Johnson when he set a 9.83-second world record in the 100-metre sprint at the world championships in Rome" type="SBAR">
          <tokens>
            <token id="4" string="Astaphan" />
            <token id="5" string="was" />
            <token id="6" string="administering" />
            <token id="7" string="steroids" />
            <token id="8" string="to" />
            <token id="9" string="Johnson" />
            <token id="10" string="when" />
            <token id="11" string="he" />
            <token id="12" string="set" />
            <token id="13" string="a" />
            <token id="14" string="9.83-second" />
            <token id="15" string="world" />
            <token id="16" string="record" />
            <token id="17" string="in" />
            <token id="18" string="the" />
            <token id="19" string="100-metre" />
            <token id="20" string="sprint" />
            <token id="21" string="at" />
            <token id="22" string="the" />
            <token id="23" string="world" />
            <token id="24" string="championships" />
            <token id="25" string="in" />
            <token id="26" string="Rome" />
          </tokens>
        </chunking>
        <chunking id="14" string="steroids" type="NP">
          <tokens>
            <token id="7" string="steroids" />
          </tokens>
        </chunking>
        <chunking id="15" string="he" type="NP">
          <tokens>
            <token id="11" string="he" />
          </tokens>
        </chunking>
        <chunking id="16" string="administering steroids to Johnson when he set a 9.83-second world record in the 100-metre sprint at the world championships in Rome" type="VP">
          <tokens>
            <token id="6" string="administering" />
            <token id="7" string="steroids" />
            <token id="8" string="to" />
            <token id="9" string="Johnson" />
            <token id="10" string="when" />
            <token id="11" string="he" />
            <token id="12" string="set" />
            <token id="13" string="a" />
            <token id="14" string="9.83-second" />
            <token id="15" string="world" />
            <token id="16" string="record" />
            <token id="17" string="in" />
            <token id="18" string="the" />
            <token id="19" string="100-metre" />
            <token id="20" string="sprint" />
            <token id="21" string="at" />
            <token id="22" string="the" />
            <token id="23" string="world" />
            <token id="24" string="championships" />
            <token id="25" string="in" />
            <token id="26" string="Rome" />
          </tokens>
        </chunking>
        <chunking id="17" string="the world championships in Rome" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="world" />
            <token id="24" string="championships" />
            <token id="25" string="in" />
            <token id="26" string="Rome" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">said</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">said</governor>
          <dependent id="2">also</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">administering</governor>
          <dependent id="4">Astaphan</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">administering</governor>
          <dependent id="5">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">said</governor>
          <dependent id="6">administering</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">administering</governor>
          <dependent id="7">steroids</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Johnson</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">administering</governor>
          <dependent id="9">Johnson</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">set</governor>
          <dependent id="10">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">set</governor>
          <dependent id="11">he</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="6">administering</governor>
          <dependent id="12">set</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">record</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">record</governor>
          <dependent id="14">9.83-second</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">record</governor>
          <dependent id="15">world</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">set</governor>
          <dependent id="16">record</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">sprint</governor>
          <dependent id="17">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">sprint</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">sprint</governor>
          <dependent id="19">100-metre</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">set</governor>
          <dependent id="20">sprint</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">championships</governor>
          <dependent id="21">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">championships</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">championships</governor>
          <dependent id="23">world</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">set</governor>
          <dependent id="24">championships</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">Rome</governor>
          <dependent id="25">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">championships</governor>
          <dependent id="26">Rome</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="Rome" type="LOCATION" score="0.0">
          <tokens>
            <token id="26" string="Rome" />
          </tokens>
        </entity>
        <entity id="3" string="Astaphan" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Astaphan" />
          </tokens>
        </entity>
        <entity id="4" string="9.83-second" type="DURATION" score="0.0">
          <tokens>
            <token id="14" string="9.83-second" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>Johnson&amp;apost;s Seoul run lowered that mark to 9.79 seconds.</content>
      <tokens>
        <token id="1" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="Seoul" lemma="Seoul" stem="seoul" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="4" string="run" lemma="run" stem="run" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="lowered" lemma="lower" stem="lower" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="mark" lemma="mark" stem="mark" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="9.79" lemma="9.79" stem="9.79" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="10" string="seconds" lemma="seconds" stem="second" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Johnson) (POS 's)) (NNP Seoul) (NN run)) (VP (VBD lowered) (PP (IN that) (NP (NN mark))) (PP (TO to) (NP (CD 9.79) (NNS seconds)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="lowered that mark to 9.79 seconds" type="VP">
          <tokens>
            <token id="5" string="lowered" />
            <token id="6" string="that" />
            <token id="7" string="mark" />
            <token id="8" string="to" />
            <token id="9" string="9.79" />
            <token id="10" string="seconds" />
          </tokens>
        </chunking>
        <chunking id="2" string="9.79 seconds" type="NP">
          <tokens>
            <token id="9" string="9.79" />
            <token id="10" string="seconds" />
          </tokens>
        </chunking>
        <chunking id="3" string="Johnson 's Seoul run" type="NP">
          <tokens>
            <token id="1" string="Johnson" />
            <token id="2" string="'s" />
            <token id="3" string="Seoul" />
            <token id="4" string="run" />
          </tokens>
        </chunking>
        <chunking id="4" string="Johnson 's" type="NP">
          <tokens>
            <token id="1" string="Johnson" />
            <token id="2" string="'s" />
          </tokens>
        </chunking>
        <chunking id="5" string="mark" type="NP">
          <tokens>
            <token id="7" string="mark" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="4">run</governor>
          <dependent id="1">Johnson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="1">Johnson</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">run</governor>
          <dependent id="3">Seoul</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">lowered</governor>
          <dependent id="4">run</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">lowered</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">mark</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">lowered</governor>
          <dependent id="7">mark</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">seconds</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="10">seconds</governor>
          <dependent id="9">9.79</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">lowered</governor>
          <dependent id="10">seconds</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="Seoul" type="LOCATION" score="0.0">
          <tokens>
            <token id="3" string="Seoul" />
          </tokens>
        </entity>
        <entity id="3" string="9.79 seconds" type="DURATION" score="0.0">
          <tokens>
            <token id="9" string="9.79" />
            <token id="10" string="seconds" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>Ms. Issajenko, the Canadian 100- and 200-metre champion, said she has been threatened since she has come forward with her accusations against the Jamaican-born Johnson.</content>
      <tokens>
        <token id="1" string="Ms." lemma="Ms." stem="ms." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="Issajenko" lemma="Issajenko" stem="issajenko" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Canadian" lemma="canadian" stem="canadian" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="6" string="100" lemma="100" stem="100" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="7" string="-" lemma="-" stem="-" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="200-metre" lemma="200-metre" stem="200-metr" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="champion" lemma="champion" stem="champion" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="threatened" lemma="threaten" stem="threaten" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="come" lemma="come" stem="come" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="forward" lemma="forward" stem="forward" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="accusations" lemma="accusation" stem="accus" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="27" string="Jamaican-born" lemma="Jamaican-born" stem="jamaican-born" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="28" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Ms.) (NNP Issajenko)) (, ,) (NP (NP (DT the) (JJ Canadian) (CD 100)) (: -) (CC and) (NP (JJ 200-metre) (NN champion)) (, ,)) (VP (VBD said) (SBAR (S (NP (PRP she)) (VP (VBZ has) (VP (VBN been) (VP (VBN threatened) (SBAR (IN since) (S (NP (PRP she)) (VP (VBZ has) (VP (VBN come) (ADVP (RB forward)) (PP (IN with) (NP (NP (PRP$ her) (NNS accusations)) (PP (IN against) (NP (DT the) (NNP Jamaican-born) (NNP Johnson))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="been threatened since she has come forward with her accusations against the Jamaican-born Johnson" type="VP">
          <tokens>
            <token id="15" string="been" />
            <token id="16" string="threatened" />
            <token id="17" string="since" />
            <token id="18" string="she" />
            <token id="19" string="has" />
            <token id="20" string="come" />
            <token id="21" string="forward" />
            <token id="22" string="with" />
            <token id="23" string="her" />
            <token id="24" string="accusations" />
            <token id="25" string="against" />
            <token id="26" string="the" />
            <token id="27" string="Jamaican-born" />
            <token id="28" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="2" string="come forward with her accusations against the Jamaican-born Johnson" type="VP">
          <tokens>
            <token id="20" string="come" />
            <token id="21" string="forward" />
            <token id="22" string="with" />
            <token id="23" string="her" />
            <token id="24" string="accusations" />
            <token id="25" string="against" />
            <token id="26" string="the" />
            <token id="27" string="Jamaican-born" />
            <token id="28" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="3" string="her accusations against the Jamaican-born Johnson" type="NP">
          <tokens>
            <token id="23" string="her" />
            <token id="24" string="accusations" />
            <token id="25" string="against" />
            <token id="26" string="the" />
            <token id="27" string="Jamaican-born" />
            <token id="28" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="4" string="the Canadian 100" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="Canadian" />
            <token id="6" string="100" />
          </tokens>
        </chunking>
        <chunking id="5" string="threatened since she has come forward with her accusations against the Jamaican-born Johnson" type="VP">
          <tokens>
            <token id="16" string="threatened" />
            <token id="17" string="since" />
            <token id="18" string="she" />
            <token id="19" string="has" />
            <token id="20" string="come" />
            <token id="21" string="forward" />
            <token id="22" string="with" />
            <token id="23" string="her" />
            <token id="24" string="accusations" />
            <token id="25" string="against" />
            <token id="26" string="the" />
            <token id="27" string="Jamaican-born" />
            <token id="28" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="6" string="she has been threatened since she has come forward with her accusations against the Jamaican-born Johnson" type="SBAR">
          <tokens>
            <token id="13" string="she" />
            <token id="14" string="has" />
            <token id="15" string="been" />
            <token id="16" string="threatened" />
            <token id="17" string="since" />
            <token id="18" string="she" />
            <token id="19" string="has" />
            <token id="20" string="come" />
            <token id="21" string="forward" />
            <token id="22" string="with" />
            <token id="23" string="her" />
            <token id="24" string="accusations" />
            <token id="25" string="against" />
            <token id="26" string="the" />
            <token id="27" string="Jamaican-born" />
            <token id="28" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="7" string="since she has come forward with her accusations against the Jamaican-born Johnson" type="SBAR">
          <tokens>
            <token id="17" string="since" />
            <token id="18" string="she" />
            <token id="19" string="has" />
            <token id="20" string="come" />
            <token id="21" string="forward" />
            <token id="22" string="with" />
            <token id="23" string="her" />
            <token id="24" string="accusations" />
            <token id="25" string="against" />
            <token id="26" string="the" />
            <token id="27" string="Jamaican-born" />
            <token id="28" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="8" string="200-metre champion" type="NP">
          <tokens>
            <token id="9" string="200-metre" />
            <token id="10" string="champion" />
          </tokens>
        </chunking>
        <chunking id="9" string="she" type="NP">
          <tokens>
            <token id="13" string="she" />
          </tokens>
        </chunking>
        <chunking id="10" string="said she has been threatened since she has come forward with her accusations against the Jamaican-born Johnson" type="VP">
          <tokens>
            <token id="12" string="said" />
            <token id="13" string="she" />
            <token id="14" string="has" />
            <token id="15" string="been" />
            <token id="16" string="threatened" />
            <token id="17" string="since" />
            <token id="18" string="she" />
            <token id="19" string="has" />
            <token id="20" string="come" />
            <token id="21" string="forward" />
            <token id="22" string="with" />
            <token id="23" string="her" />
            <token id="24" string="accusations" />
            <token id="25" string="against" />
            <token id="26" string="the" />
            <token id="27" string="Jamaican-born" />
            <token id="28" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="11" string="has come forward with her accusations against the Jamaican-born Johnson" type="VP">
          <tokens>
            <token id="19" string="has" />
            <token id="20" string="come" />
            <token id="21" string="forward" />
            <token id="22" string="with" />
            <token id="23" string="her" />
            <token id="24" string="accusations" />
            <token id="25" string="against" />
            <token id="26" string="the" />
            <token id="27" string="Jamaican-born" />
            <token id="28" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="12" string="the Canadian 100 - and 200-metre champion ," type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="Canadian" />
            <token id="6" string="100" />
            <token id="7" string="-" />
            <token id="8" string="and" />
            <token id="9" string="200-metre" />
            <token id="10" string="champion" />
            <token id="11" string="," />
          </tokens>
        </chunking>
        <chunking id="13" string="her accusations" type="NP">
          <tokens>
            <token id="23" string="her" />
            <token id="24" string="accusations" />
          </tokens>
        </chunking>
        <chunking id="14" string="Ms. Issajenko" type="NP">
          <tokens>
            <token id="1" string="Ms." />
            <token id="2" string="Issajenko" />
          </tokens>
        </chunking>
        <chunking id="15" string="the Jamaican-born Johnson" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="Jamaican-born" />
            <token id="28" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="16" string="has been threatened since she has come forward with her accusations against the Jamaican-born Johnson" type="VP">
          <tokens>
            <token id="14" string="has" />
            <token id="15" string="been" />
            <token id="16" string="threatened" />
            <token id="17" string="since" />
            <token id="18" string="she" />
            <token id="19" string="has" />
            <token id="20" string="come" />
            <token id="21" string="forward" />
            <token id="22" string="with" />
            <token id="23" string="her" />
            <token id="24" string="accusations" />
            <token id="25" string="against" />
            <token id="26" string="the" />
            <token id="27" string="Jamaican-born" />
            <token id="28" string="Johnson" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Issajenko</governor>
          <dependent id="1">Ms.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">said</governor>
          <dependent id="2">Issajenko</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">100</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">100</governor>
          <dependent id="5">Canadian</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">said</governor>
          <dependent id="6">100</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">100</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">champion</governor>
          <dependent id="9">200-metre</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">100</governor>
          <dependent id="10">champion</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">said</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="16">threatened</governor>
          <dependent id="13">she</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">threatened</governor>
          <dependent id="14">has</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="16">threatened</governor>
          <dependent id="15">been</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">said</governor>
          <dependent id="16">threatened</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">come</governor>
          <dependent id="17">since</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">come</governor>
          <dependent id="18">she</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="20">come</governor>
          <dependent id="19">has</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="16">threatened</governor>
          <dependent id="20">come</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">come</governor>
          <dependent id="21">forward</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">accusations</governor>
          <dependent id="22">with</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="24">accusations</governor>
          <dependent id="23">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">come</governor>
          <dependent id="24">accusations</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">Johnson</governor>
          <dependent id="25">against</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">Johnson</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">Johnson</governor>
          <dependent id="27">Jamaican-born</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">accusations</governor>
          <dependent id="28">Johnson</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="100" type="NUMBER" score="0.0">
          <tokens>
            <token id="6" string="100" />
          </tokens>
        </entity>
        <entity id="2" string="Jamaican-born" type="MISC" score="0.0">
          <tokens>
            <token id="27" string="Jamaican-born" />
          </tokens>
        </entity>
        <entity id="3" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="28" string="Johnson" />
          </tokens>
        </entity>
        <entity id="4" string="Canadian" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="5" string="Canadian" />
          </tokens>
        </entity>
        <entity id="5" string="Issajenko" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Issajenko" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>After Johnson tested positive for steroids at the Olympics, Ms. Issajenko said therapist Waldemar Matuszewski had ``tampered&amp;apost;&amp;apost; with her and Johnson.</content>
      <tokens>
        <token id="1" string="After" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="tested" lemma="test" stem="test" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="positive" lemma="positive" stem="posit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="steroids" lemma="steroid" stem="steroid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="Olympics" lemma="Olympics" stem="olympic" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Ms." lemma="Ms." stem="ms." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="Issajenko" lemma="Issajenko" stem="issajenko" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="13" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="therapist" lemma="therapist" stem="therapist" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="Waldemar" lemma="Waldemar" stem="waldemar" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="16" string="Matuszewski" lemma="Matuszewski" stem="matuszewski" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="17" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="tampered" lemma="tamper" stem="tamper" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="her" lemma="she" stem="her" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="23" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN After) (NP (NP (NNP Johnson)) (VP (VBN tested) (ADJP (JJ positive) (PP (IN for) (NP (NNS steroids)))) (PP (IN at) (NP (DT the) (NNPS Olympics)))))) (, ,) (NP (NNP Ms.) (NNP Issajenko)) (VP (VBD said) (SBAR (S (NP (NN therapist) (NNP Waldemar) (NNP Matuszewski)) (VP (VBD had) (VP (`` ``) (VBN tampered) ('' '') (PP (IN with) (NP (NP (PRP her)) (CC and) (NP (NNP Johnson))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Johnson" type="NP">
          <tokens>
            <token id="2" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="2" string="said therapist Waldemar Matuszewski had `` tampered '' with her and Johnson" type="VP">
          <tokens>
            <token id="13" string="said" />
            <token id="14" string="therapist" />
            <token id="15" string="Waldemar" />
            <token id="16" string="Matuszewski" />
            <token id="17" string="had" />
            <token id="18" string="``" />
            <token id="19" string="tampered" />
            <token id="20" string="''" />
            <token id="21" string="with" />
            <token id="22" string="her" />
            <token id="23" string="and" />
            <token id="24" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="3" string="Johnson tested positive for steroids at the Olympics" type="NP">
          <tokens>
            <token id="2" string="Johnson" />
            <token id="3" string="tested" />
            <token id="4" string="positive" />
            <token id="5" string="for" />
            <token id="6" string="steroids" />
            <token id="7" string="at" />
            <token id="8" string="the" />
            <token id="9" string="Olympics" />
          </tokens>
        </chunking>
        <chunking id="4" string="therapist Waldemar Matuszewski had `` tampered '' with her and Johnson" type="SBAR">
          <tokens>
            <token id="14" string="therapist" />
            <token id="15" string="Waldemar" />
            <token id="16" string="Matuszewski" />
            <token id="17" string="had" />
            <token id="18" string="``" />
            <token id="19" string="tampered" />
            <token id="20" string="''" />
            <token id="21" string="with" />
            <token id="22" string="her" />
            <token id="23" string="and" />
            <token id="24" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="5" string="therapist Waldemar Matuszewski" type="NP">
          <tokens>
            <token id="14" string="therapist" />
            <token id="15" string="Waldemar" />
            <token id="16" string="Matuszewski" />
          </tokens>
        </chunking>
        <chunking id="6" string="the Olympics" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="Olympics" />
          </tokens>
        </chunking>
        <chunking id="7" string="`` tampered '' with her and Johnson" type="VP">
          <tokens>
            <token id="18" string="``" />
            <token id="19" string="tampered" />
            <token id="20" string="''" />
            <token id="21" string="with" />
            <token id="22" string="her" />
            <token id="23" string="and" />
            <token id="24" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="8" string="tested positive for steroids at the Olympics" type="VP">
          <tokens>
            <token id="3" string="tested" />
            <token id="4" string="positive" />
            <token id="5" string="for" />
            <token id="6" string="steroids" />
            <token id="7" string="at" />
            <token id="8" string="the" />
            <token id="9" string="Olympics" />
          </tokens>
        </chunking>
        <chunking id="9" string="her" type="NP">
          <tokens>
            <token id="22" string="her" />
          </tokens>
        </chunking>
        <chunking id="10" string="had `` tampered '' with her and Johnson" type="VP">
          <tokens>
            <token id="17" string="had" />
            <token id="18" string="``" />
            <token id="19" string="tampered" />
            <token id="20" string="''" />
            <token id="21" string="with" />
            <token id="22" string="her" />
            <token id="23" string="and" />
            <token id="24" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="11" string="Ms. Issajenko" type="NP">
          <tokens>
            <token id="11" string="Ms." />
            <token id="12" string="Issajenko" />
          </tokens>
        </chunking>
        <chunking id="12" string="steroids" type="NP">
          <tokens>
            <token id="6" string="steroids" />
          </tokens>
        </chunking>
        <chunking id="13" string="positive for steroids" type="ADJP">
          <tokens>
            <token id="4" string="positive" />
            <token id="5" string="for" />
            <token id="6" string="steroids" />
          </tokens>
        </chunking>
        <chunking id="14" string="her and Johnson" type="NP">
          <tokens>
            <token id="22" string="her" />
            <token id="23" string="and" />
            <token id="24" string="Johnson" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">Johnson</governor>
          <dependent id="1">After</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">said</governor>
          <dependent id="2">Johnson</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="2">Johnson</governor>
          <dependent id="3">tested</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">tested</governor>
          <dependent id="4">positive</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">steroids</governor>
          <dependent id="5">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">positive</governor>
          <dependent id="6">steroids</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Olympics</governor>
          <dependent id="7">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">Olympics</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">tested</governor>
          <dependent id="9">Olympics</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Issajenko</governor>
          <dependent id="11">Ms.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">said</governor>
          <dependent id="12">Issajenko</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Matuszewski</governor>
          <dependent id="14">therapist</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Matuszewski</governor>
          <dependent id="15">Waldemar</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">tampered</governor>
          <dependent id="16">Matuszewski</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="19">tampered</governor>
          <dependent id="17">had</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">said</governor>
          <dependent id="19">tampered</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">her</governor>
          <dependent id="21">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">tampered</governor>
          <dependent id="22">her</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="22">her</governor>
          <dependent id="23">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="22">her</governor>
          <dependent id="24">Johnson</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="Olympics" type="MISC" score="0.0">
          <tokens>
            <token id="9" string="Olympics" />
          </tokens>
        </entity>
        <entity id="3" string="Issajenko" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Issajenko" />
          </tokens>
        </entity>
        <entity id="4" string="Waldemar Matuszewski" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="Waldemar" />
            <token id="16" string="Matuszewski" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>Ms. Issajenko claimed the therapist had put anabolic steroids in the rubbing compound he used to massage their muscles.</content>
      <tokens>
        <token id="1" string="Ms." lemma="Ms." stem="ms." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="Issajenko" lemma="Issajenko" stem="issajenko" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="claimed" lemma="claim" stem="claim" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="therapist" lemma="therapist" stem="therapist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="put" lemma="put" stem="put" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="anabolic" lemma="anabolic" stem="anabol" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="steroids" lemma="steroid" stem="steroid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="rubbing" lemma="rub" stem="rub" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="compound" lemma="compound" stem="compound" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="used" lemma="use" stem="us" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="massage" lemma="massage" stem="massag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="muscles" lemma="muscle" stem="muscl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Ms.) (NNP Issajenko)) (VP (VBD claimed) (SBAR (S (NP (DT the) (NN therapist)) (VP (VBD had) (VP (VBN put) (NP (JJ anabolic) (NNS steroids)) (PP (IN in) (NP (NP (DT the) (VBG rubbing) (NN compound)) (SBAR (S (NP (PRP he)) (VP (VBD used) (PP (TO to) (NP (NN massage))) (NP (PRP$ their) (NNS muscles)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the therapist had put anabolic steroids in the rubbing compound he used to massage their muscles" type="SBAR">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="therapist" />
            <token id="6" string="had" />
            <token id="7" string="put" />
            <token id="8" string="anabolic" />
            <token id="9" string="steroids" />
            <token id="10" string="in" />
            <token id="11" string="the" />
            <token id="12" string="rubbing" />
            <token id="13" string="compound" />
            <token id="14" string="he" />
            <token id="15" string="used" />
            <token id="16" string="to" />
            <token id="17" string="massage" />
            <token id="18" string="their" />
            <token id="19" string="muscles" />
          </tokens>
        </chunking>
        <chunking id="2" string="put anabolic steroids in the rubbing compound he used to massage their muscles" type="VP">
          <tokens>
            <token id="7" string="put" />
            <token id="8" string="anabolic" />
            <token id="9" string="steroids" />
            <token id="10" string="in" />
            <token id="11" string="the" />
            <token id="12" string="rubbing" />
            <token id="13" string="compound" />
            <token id="14" string="he" />
            <token id="15" string="used" />
            <token id="16" string="to" />
            <token id="17" string="massage" />
            <token id="18" string="their" />
            <token id="19" string="muscles" />
          </tokens>
        </chunking>
        <chunking id="3" string="their muscles" type="NP">
          <tokens>
            <token id="18" string="their" />
            <token id="19" string="muscles" />
          </tokens>
        </chunking>
        <chunking id="4" string="the therapist" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="therapist" />
          </tokens>
        </chunking>
        <chunking id="5" string="the rubbing compound he used to massage their muscles" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="rubbing" />
            <token id="13" string="compound" />
            <token id="14" string="he" />
            <token id="15" string="used" />
            <token id="16" string="to" />
            <token id="17" string="massage" />
            <token id="18" string="their" />
            <token id="19" string="muscles" />
          </tokens>
        </chunking>
        <chunking id="6" string="claimed the therapist had put anabolic steroids in the rubbing compound he used to massage their muscles" type="VP">
          <tokens>
            <token id="3" string="claimed" />
            <token id="4" string="the" />
            <token id="5" string="therapist" />
            <token id="6" string="had" />
            <token id="7" string="put" />
            <token id="8" string="anabolic" />
            <token id="9" string="steroids" />
            <token id="10" string="in" />
            <token id="11" string="the" />
            <token id="12" string="rubbing" />
            <token id="13" string="compound" />
            <token id="14" string="he" />
            <token id="15" string="used" />
            <token id="16" string="to" />
            <token id="17" string="massage" />
            <token id="18" string="their" />
            <token id="19" string="muscles" />
          </tokens>
        </chunking>
        <chunking id="7" string="used to massage their muscles" type="VP">
          <tokens>
            <token id="15" string="used" />
            <token id="16" string="to" />
            <token id="17" string="massage" />
            <token id="18" string="their" />
            <token id="19" string="muscles" />
          </tokens>
        </chunking>
        <chunking id="8" string="anabolic steroids" type="NP">
          <tokens>
            <token id="8" string="anabolic" />
            <token id="9" string="steroids" />
          </tokens>
        </chunking>
        <chunking id="9" string="Ms. Issajenko" type="NP">
          <tokens>
            <token id="1" string="Ms." />
            <token id="2" string="Issajenko" />
          </tokens>
        </chunking>
        <chunking id="10" string="he used to massage their muscles" type="SBAR">
          <tokens>
            <token id="14" string="he" />
            <token id="15" string="used" />
            <token id="16" string="to" />
            <token id="17" string="massage" />
            <token id="18" string="their" />
            <token id="19" string="muscles" />
          </tokens>
        </chunking>
        <chunking id="11" string="had put anabolic steroids in the rubbing compound he used to massage their muscles" type="VP">
          <tokens>
            <token id="6" string="had" />
            <token id="7" string="put" />
            <token id="8" string="anabolic" />
            <token id="9" string="steroids" />
            <token id="10" string="in" />
            <token id="11" string="the" />
            <token id="12" string="rubbing" />
            <token id="13" string="compound" />
            <token id="14" string="he" />
            <token id="15" string="used" />
            <token id="16" string="to" />
            <token id="17" string="massage" />
            <token id="18" string="their" />
            <token id="19" string="muscles" />
          </tokens>
        </chunking>
        <chunking id="12" string="he" type="NP">
          <tokens>
            <token id="14" string="he" />
          </tokens>
        </chunking>
        <chunking id="13" string="massage" type="NP">
          <tokens>
            <token id="17" string="massage" />
          </tokens>
        </chunking>
        <chunking id="14" string="the rubbing compound" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="rubbing" />
            <token id="13" string="compound" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Issajenko</governor>
          <dependent id="1">Ms.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">claimed</governor>
          <dependent id="2">Issajenko</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">claimed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">therapist</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">put</governor>
          <dependent id="5">therapist</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">put</governor>
          <dependent id="6">had</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">claimed</governor>
          <dependent id="7">put</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">steroids</governor>
          <dependent id="8">anabolic</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">put</governor>
          <dependent id="9">steroids</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">compound</governor>
          <dependent id="10">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">compound</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">compound</governor>
          <dependent id="12">rubbing</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">put</governor>
          <dependent id="13">compound</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">used</governor>
          <dependent id="14">he</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="13">compound</governor>
          <dependent id="15">used</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">massage</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">used</governor>
          <dependent id="17">massage</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">muscles</governor>
          <dependent id="18">their</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">used</governor>
          <dependent id="19">muscles</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Issajenko" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Issajenko" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>The story was called ``nonsense&amp;apost;&amp;apost; by Canadian Olympic track physician Dr. Robert Luba and Issajenko later retracted her charges against Matuszewski.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="story" lemma="story" stem="stori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="called" lemma="call" stem="call" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="nonsense" lemma="nonsense" stem="nonsens" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Canadian" lemma="Canadian" stem="canadian" pos="NNP" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="10" string="Olympic" lemma="Olympic" stem="olympic" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="11" string="track" lemma="track" stem="track" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="physician" lemma="physician" stem="physician" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="Dr." lemma="Dr." stem="dr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="Robert" lemma="Robert" stem="robert" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="15" string="Luba" lemma="Luba" stem="luba" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Issajenko" lemma="Issajenko" stem="issajenko" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="18" string="later" lemma="later" stem="later" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="retracted" lemma="retract" stem="retract" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="charges" lemma="charge" stem="charg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="Matuszewski" lemma="Matuszewski" stem="matuszewski" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT The) (NN story)) (VP (VBD was) (VP (VBN called) (`` ``) (NP (NN nonsense)) ('' '') (PP (IN by) (NP (NNP Canadian) (NNP Olympic) (NN track) (NN physician) (NNP Dr.) (NNP Robert) (NNP Luba)))))) (CC and) (S (NP (NNP Issajenko)) (ADVP (RB later)) (VP (VBD retracted) (NP (PRP$ her) (NNS charges)) (PP (IN against) (NP (NNP Matuszewski))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was called `` nonsense '' by Canadian Olympic track physician Dr. Robert Luba" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="called" />
            <token id="5" string="``" />
            <token id="6" string="nonsense" />
            <token id="7" string="''" />
            <token id="8" string="by" />
            <token id="9" string="Canadian" />
            <token id="10" string="Olympic" />
            <token id="11" string="track" />
            <token id="12" string="physician" />
            <token id="13" string="Dr." />
            <token id="14" string="Robert" />
            <token id="15" string="Luba" />
          </tokens>
        </chunking>
        <chunking id="2" string="called `` nonsense '' by Canadian Olympic track physician Dr. Robert Luba" type="VP">
          <tokens>
            <token id="4" string="called" />
            <token id="5" string="``" />
            <token id="6" string="nonsense" />
            <token id="7" string="''" />
            <token id="8" string="by" />
            <token id="9" string="Canadian" />
            <token id="10" string="Olympic" />
            <token id="11" string="track" />
            <token id="12" string="physician" />
            <token id="13" string="Dr." />
            <token id="14" string="Robert" />
            <token id="15" string="Luba" />
          </tokens>
        </chunking>
        <chunking id="3" string="retracted her charges against Matuszewski" type="VP">
          <tokens>
            <token id="19" string="retracted" />
            <token id="20" string="her" />
            <token id="21" string="charges" />
            <token id="22" string="against" />
            <token id="23" string="Matuszewski" />
          </tokens>
        </chunking>
        <chunking id="4" string="Issajenko" type="NP">
          <tokens>
            <token id="17" string="Issajenko" />
          </tokens>
        </chunking>
        <chunking id="5" string="her charges" type="NP">
          <tokens>
            <token id="20" string="her" />
            <token id="21" string="charges" />
          </tokens>
        </chunking>
        <chunking id="6" string="nonsense" type="NP">
          <tokens>
            <token id="6" string="nonsense" />
          </tokens>
        </chunking>
        <chunking id="7" string="Matuszewski" type="NP">
          <tokens>
            <token id="23" string="Matuszewski" />
          </tokens>
        </chunking>
        <chunking id="8" string="The story" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="story" />
          </tokens>
        </chunking>
        <chunking id="9" string="Canadian Olympic track physician Dr. Robert Luba" type="NP">
          <tokens>
            <token id="9" string="Canadian" />
            <token id="10" string="Olympic" />
            <token id="11" string="track" />
            <token id="12" string="physician" />
            <token id="13" string="Dr." />
            <token id="14" string="Robert" />
            <token id="15" string="Luba" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">story</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="4">called</governor>
          <dependent id="2">story</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">called</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">called</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">called</governor>
          <dependent id="6">nonsense</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">Luba</governor>
          <dependent id="8">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Luba</governor>
          <dependent id="9">Canadian</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Luba</governor>
          <dependent id="10">Olympic</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Luba</governor>
          <dependent id="11">track</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Luba</governor>
          <dependent id="12">physician</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Luba</governor>
          <dependent id="13">Dr.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Luba</governor>
          <dependent id="14">Robert</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">called</governor>
          <dependent id="15">Luba</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">called</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">retracted</governor>
          <dependent id="17">Issajenko</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">retracted</governor>
          <dependent id="18">later</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">called</governor>
          <dependent id="19">retracted</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="21">charges</governor>
          <dependent id="20">her</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">retracted</governor>
          <dependent id="21">charges</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">Matuszewski</governor>
          <dependent id="22">against</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">retracted</governor>
          <dependent id="23">Matuszewski</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Canadian" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="9" string="Canadian" />
          </tokens>
        </entity>
        <entity id="2" string="Robert Luba" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Robert" />
            <token id="15" string="Luba" />
          </tokens>
        </entity>
        <entity id="3" string="Olympic" type="MISC" score="0.0">
          <tokens>
            <token id="10" string="Olympic" />
          </tokens>
        </entity>
        <entity id="4" string="Issajenko" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="Issajenko" />
          </tokens>
        </entity>
        <entity id="5" string="Matuszewski" type="PERSON" score="0.0">
          <tokens>
            <token id="23" string="Matuszewski" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>The federal government has appointed Ontario Associate Chief Justice Charles Dubin to head a judicial inquiry into the Ben Johnson affair.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="federal" lemma="federal" stem="feder" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="government" lemma="government" stem="govern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="appointed" lemma="appoint" stem="appoint" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="Ontario" lemma="Ontario" stem="ontario" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="7" string="Associate" lemma="Associate" stem="associat" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="Chief" lemma="Chief" stem="chief" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="false" is_refers="false" />
        <token id="9" string="Justice" lemma="Justice" stem="justic" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="Charles" lemma="Charles" stem="charl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="11" string="Dubin" lemma="Dubin" stem="dubin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="head" lemma="head" stem="head" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="judicial" lemma="judicial" stem="judici" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="inquiry" lemma="inquiry" stem="inquiri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Ben" lemma="Ben" stem="ben" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="20" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="21" string="affair" lemma="affair" stem="affair" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (JJ federal) (NN government)) (VP (VBZ has) (VP (VBN appointed) (S (NP (NNP Ontario) (NNP Associate) (NNP Chief) (NNP Justice) (NNP Charles) (NNP Dubin)) (VP (TO to) (VP (VB head) (NP (DT a) (JJ judicial) (NN inquiry)) (PP (IN into) (NP (DT the) (NNP Ben) (NNP Johnson) (NN affair)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="appointed Ontario Associate Chief Justice Charles Dubin to head a judicial inquiry into the Ben Johnson affair" type="VP">
          <tokens>
            <token id="5" string="appointed" />
            <token id="6" string="Ontario" />
            <token id="7" string="Associate" />
            <token id="8" string="Chief" />
            <token id="9" string="Justice" />
            <token id="10" string="Charles" />
            <token id="11" string="Dubin" />
            <token id="12" string="to" />
            <token id="13" string="head" />
            <token id="14" string="a" />
            <token id="15" string="judicial" />
            <token id="16" string="inquiry" />
            <token id="17" string="into" />
            <token id="18" string="the" />
            <token id="19" string="Ben" />
            <token id="20" string="Johnson" />
            <token id="21" string="affair" />
          </tokens>
        </chunking>
        <chunking id="2" string="Ontario Associate Chief Justice Charles Dubin" type="NP">
          <tokens>
            <token id="6" string="Ontario" />
            <token id="7" string="Associate" />
            <token id="8" string="Chief" />
            <token id="9" string="Justice" />
            <token id="10" string="Charles" />
            <token id="11" string="Dubin" />
          </tokens>
        </chunking>
        <chunking id="3" string="to head a judicial inquiry into the Ben Johnson affair" type="VP">
          <tokens>
            <token id="12" string="to" />
            <token id="13" string="head" />
            <token id="14" string="a" />
            <token id="15" string="judicial" />
            <token id="16" string="inquiry" />
            <token id="17" string="into" />
            <token id="18" string="the" />
            <token id="19" string="Ben" />
            <token id="20" string="Johnson" />
            <token id="21" string="affair" />
          </tokens>
        </chunking>
        <chunking id="4" string="has appointed Ontario Associate Chief Justice Charles Dubin to head a judicial inquiry into the Ben Johnson affair" type="VP">
          <tokens>
            <token id="4" string="has" />
            <token id="5" string="appointed" />
            <token id="6" string="Ontario" />
            <token id="7" string="Associate" />
            <token id="8" string="Chief" />
            <token id="9" string="Justice" />
            <token id="10" string="Charles" />
            <token id="11" string="Dubin" />
            <token id="12" string="to" />
            <token id="13" string="head" />
            <token id="14" string="a" />
            <token id="15" string="judicial" />
            <token id="16" string="inquiry" />
            <token id="17" string="into" />
            <token id="18" string="the" />
            <token id="19" string="Ben" />
            <token id="20" string="Johnson" />
            <token id="21" string="affair" />
          </tokens>
        </chunking>
        <chunking id="5" string="the Ben Johnson affair" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="Ben" />
            <token id="20" string="Johnson" />
            <token id="21" string="affair" />
          </tokens>
        </chunking>
        <chunking id="6" string="The federal government" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="federal" />
            <token id="3" string="government" />
          </tokens>
        </chunking>
        <chunking id="7" string="a judicial inquiry" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="judicial" />
            <token id="16" string="inquiry" />
          </tokens>
        </chunking>
        <chunking id="8" string="head a judicial inquiry into the Ben Johnson affair" type="VP">
          <tokens>
            <token id="13" string="head" />
            <token id="14" string="a" />
            <token id="15" string="judicial" />
            <token id="16" string="inquiry" />
            <token id="17" string="into" />
            <token id="18" string="the" />
            <token id="19" string="Ben" />
            <token id="20" string="Johnson" />
            <token id="21" string="affair" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">government</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">government</governor>
          <dependent id="2">federal</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">appointed</governor>
          <dependent id="3">government</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">appointed</governor>
          <dependent id="4">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">appointed</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Dubin</governor>
          <dependent id="6">Ontario</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Dubin</governor>
          <dependent id="7">Associate</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Dubin</governor>
          <dependent id="8">Chief</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Dubin</governor>
          <dependent id="9">Justice</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Dubin</governor>
          <dependent id="10">Charles</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">appointed</governor>
          <dependent id="11">Dubin</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">head</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">appointed</governor>
          <dependent id="13">head</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">inquiry</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">inquiry</governor>
          <dependent id="15">judicial</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">head</governor>
          <dependent id="16">inquiry</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">affair</governor>
          <dependent id="17">into</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">affair</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">affair</governor>
          <dependent id="19">Ben</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">affair</governor>
          <dependent id="20">Johnson</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">head</governor>
          <dependent id="21">affair</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ben Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="19" string="Ben" />
            <token id="20" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="Chief" type="TITLE" score="0.0">
          <tokens>
            <token id="8" string="Chief" />
          </tokens>
        </entity>
        <entity id="3" string="Ontario" type="LOCATION" score="0.0">
          <tokens>
            <token id="6" string="Ontario" />
          </tokens>
        </entity>
        <entity id="4" string="Charles Dubin" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Charles" />
            <token id="11" string="Dubin" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>Astaphan and Francis could not be immediately reached for comment.</content>
      <tokens>
        <token id="1" string="Astaphan" lemma="Astaphan" stem="astaphan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Francis" lemma="Francis" stem="franci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="immediately" lemma="immediately" stem="immedi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="reached" lemma="reach" stem="reach" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="comment" lemma="comment" stem="comment" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Astaphan) (CC and) (NNP Francis)) (VP (MD could) (RB not) (VP (VB be) (VP (ADVP (RB immediately)) (VBN reached) (PP (IN for) (NP (NN comment)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="could not be immediately reached for comment" type="VP">
          <tokens>
            <token id="4" string="could" />
            <token id="5" string="not" />
            <token id="6" string="be" />
            <token id="7" string="immediately" />
            <token id="8" string="reached" />
            <token id="9" string="for" />
            <token id="10" string="comment" />
          </tokens>
        </chunking>
        <chunking id="2" string="immediately reached for comment" type="VP">
          <tokens>
            <token id="7" string="immediately" />
            <token id="8" string="reached" />
            <token id="9" string="for" />
            <token id="10" string="comment" />
          </tokens>
        </chunking>
        <chunking id="3" string="Astaphan and Francis" type="NP">
          <tokens>
            <token id="1" string="Astaphan" />
            <token id="2" string="and" />
            <token id="3" string="Francis" />
          </tokens>
        </chunking>
        <chunking id="4" string="be immediately reached for comment" type="VP">
          <tokens>
            <token id="6" string="be" />
            <token id="7" string="immediately" />
            <token id="8" string="reached" />
            <token id="9" string="for" />
            <token id="10" string="comment" />
          </tokens>
        </chunking>
        <chunking id="5" string="comment" type="NP">
          <tokens>
            <token id="10" string="comment" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="8">reached</governor>
          <dependent id="1">Astaphan</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="1">Astaphan</governor>
          <dependent id="2">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="1">Astaphan</governor>
          <dependent id="3">Francis</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">reached</governor>
          <dependent id="4">could</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="8">reached</governor>
          <dependent id="5">not</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="8">reached</governor>
          <dependent id="6">be</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">reached</governor>
          <dependent id="7">immediately</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">reached</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">comment</governor>
          <dependent id="9">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">reached</governor>
          <dependent id="10">comment</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Francis" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Francis" />
          </tokens>
        </entity>
        <entity id="2" string="Astaphan" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Astaphan" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="26-27-28" string="the Jamaican-born Johnson" id_sentence="19" />
      <mentions>
        <mention ids_tokens="1-2" string="Ben Johnson" id_sentence="1" />
        <mention ids_tokens="1" string="Johnson" id_sentence="2" />
        <mention ids_tokens="5" string="his" id_sentence="2" />
        <mention ids_tokens="14" string="he" id_sentence="2" />
        <mention ids_tokens="13" string="Johnson" id_sentence="5" />
        <mention ids_tokens="11" string="Johnson" id_sentence="7" />
        <mention ids_tokens="38" string="Johnson" id_sentence="8" />
        <mention ids_tokens="2" string="I" id_sentence="9" />
        <mention ids_tokens="2" string="I" id_sentence="10" />
        <mention ids_tokens="1" string="I" id_sentence="12" />
        <mention ids_tokens="1-3" string="Johnson , 26" id_sentence="14" />
        <mention ids_tokens="1" string="Johnson" id_sentence="14" />
        <mention ids_tokens="6" string="he" id_sentence="14" />
        <mention ids_tokens="17" string="he" id_sentence="14" />
        <mention ids_tokens="34" string="his" id_sentence="14" />
        <mention ids_tokens="14" string="Johnson" id_sentence="16" />
        <mention ids_tokens="9" string="Johnson" id_sentence="17" />
        <mention ids_tokens="11" string="he" id_sentence="17" />
        <mention ids_tokens="1-2" string="Johnson's" id_sentence="18" />
        <mention ids_tokens="2-9" string="Johnson tested positive for steroids at the Olympics" id_sentence="20" />
        <mention ids_tokens="24" string="Johnson" id_sentence="20" />
        <mention ids_tokens="19-20" string="Ben Johnson" id_sentence="23" />
      </mentions>
    </coreference>
    <coreference id="2" type="PROPER">
      <referenced ids_tokens="8-9" string="the Olympics" id_sentence="3" />
      <mentions>
        <mention ids_tokens="21" string="Olympic" id_sentence="1" />
        <mention ids_tokens="6" string="Olympic" id_sentence="2" />
        <mention ids_tokens="2" string="Olympics" id_sentence="4" />
        <mention ids_tokens="9" string="Olympics" id_sentence="20" />
        <mention ids_tokens="10" string="Olympic" id_sentence="22" />
      </mentions>
    </coreference>
    <coreference id="5" type="NOMINAL">
      <referenced ids_tokens="11-12" string="the runner" id_sentence="1" />
      <mentions>
        <mention ids_tokens="28-30" string="the runner's" id_sentence="14" />
      </mentions>
    </coreference>
    <coreference id="6" type="PROPER">
      <referenced ids_tokens="19-20-21-22-23-24" string="fellow Canadian Olympic sprinter Angella Issajenko" id_sentence="1" />
      <mentions>
        <mention ids_tokens="44-47" string="Ms. Issajenko as saying" id_sentence="2" />
        <mention ids_tokens="2" string="Issajenko" id_sentence="3" />
        <mention ids_tokens="20" string="she" id_sentence="3" />
        <mention ids_tokens="3" string="her" id_sentence="5" />
        <mention ids_tokens="2" string="Issajenko" id_sentence="16" />
        <mention ids_tokens="10" string="she" id_sentence="16" />
        <mention ids_tokens="1" string="She" id_sentence="17" />
        <mention ids_tokens="2" string="Issajenko" id_sentence="19" />
        <mention ids_tokens="13" string="she" id_sentence="19" />
        <mention ids_tokens="18" string="she" id_sentence="19" />
        <mention ids_tokens="23" string="her" id_sentence="19" />
        <mention ids_tokens="17" string="Issajenko" id_sentence="22" />
        <mention ids_tokens="20" string="her" id_sentence="22" />
      </mentions>
    </coreference>
    <coreference id="7" type="NOMINAL">
      <referenced ids_tokens="30-31-32-33" string="an interview published Sunday" id_sentence="1" />
      <mentions>
        <mention ids_tokens="4-5" string="the interview" id_sentence="8" />
      </mentions>
    </coreference>
    <coreference id="8" type="PROPER">
      <referenced ids_tokens="33" string="Sunday" id_sentence="1" />
      <mentions>
        <mention ids_tokens="7" string="it" id_sentence="6" />
        <mention ids_tokens="10" string="its" id_sentence="6" />
      </mentions>
    </coreference>
    <coreference id="10" type="PROPER">
      <referenced ids_tokens="1-2-3" string="The Toronto Star" id_sentence="6" />
      <mentions>
        <mention ids_tokens="40-41" string="Toronto Star" id_sentence="2" />
      </mentions>
    </coreference>
    <coreference id="12" type="PROPER">
      <referenced ids_tokens="14-15-16" string="therapist Waldemar Matuszewski" id_sentence="20" />
      <mentions>
        <mention ids_tokens="23" string="Matuszewski" id_sentence="22" />
      </mentions>
    </coreference>
    <coreference id="13" type="LIST">
      <referenced ids_tokens="22-23-24" string="her and Johnson" id_sentence="20" />
      <mentions>
        <mention ids_tokens="18" string="their" id_sentence="21" />
      </mentions>
    </coreference>
    <coreference id="15" type="PROPER">
      <referenced ids_tokens="1-2-3-4-5-6-7-8-9-10-11-12-13-14" string="Ms. Issajenko , who also competed in the Olympics in Seoul , South Korea" id_sentence="3" />
      <mentions>
        <mention ids_tokens="7-8" string="Ms. Issajenko" id_sentence="5" />
        <mention ids_tokens="11" string="she" id_sentence="5" />
        <mention ids_tokens="1-2" string="Ms. Issajenko" id_sentence="7" />
        <mention ids_tokens="9" string="her" id_sentence="7" />
        <mention ids_tokens="11-12" string="Ms. Issajenko" id_sentence="9" />
        <mention ids_tokens="1-4" string="Ms. Issajenko , 30" id_sentence="16" />
        <mention ids_tokens="1-2" string="Ms. Issajenko" id_sentence="16" />
        <mention ids_tokens="1-2" string="Ms. Issajenko" id_sentence="19" />
        <mention ids_tokens="11-12" string="Ms. Issajenko" id_sentence="20" />
        <mention ids_tokens="22" string="her" id_sentence="20" />
        <mention ids_tokens="1-2" string="Ms. Issajenko" id_sentence="21" />
      </mentions>
    </coreference>
    <coreference id="16" type="NOMINAL">
      <referenced ids_tokens="10-11" string="its story" id_sentence="6" />
      <mentions>
        <mention ids_tokens="1-2" string="The story" id_sentence="22" />
      </mentions>
    </coreference>
    <coreference id="17" type="NOMINAL">
      <referenced ids_tokens="5-6-7-8-9" string="a therapist of giving her" id_sentence="7" />
      <mentions>
        <mention ids_tokens="4-5" string="the therapist" id_sentence="21" />
        <mention ids_tokens="14" string="he" id_sentence="21" />
      </mentions>
    </coreference>
    <coreference id="18" type="PROPER">
      <referenced ids_tokens="11-12-13" string="Jamie ) Astaphan" id_sentence="8" />
      <mentions>
        <mention ids_tokens="1-4" string="Jamie ( Astaphan )" id_sentence="13" />
        <mention ids_tokens="16" string="he" id_sentence="13" />
        <mention ids_tokens="32" string="Jamie" id_sentence="16" />
      </mentions>
    </coreference>
    <coreference id="19" type="PROPER">
      <referenced ids_tokens="24-25" string="Charlie Francis" id_sentence="8" />
      <mentions>
        <mention ids_tokens="1" string="Francis" id_sentence="15" />
        <mention ids_tokens="3" string="Francis" id_sentence="24" />
      </mentions>
    </coreference>
    <coreference id="20" type="PROPER">
      <referenced ids_tokens="7-8-9-10-11-12-13" string="Dr. George Mario ( Jamie ) Astaphan" id_sentence="8" />
      <mentions>
        <mention ids_tokens="3" string="Astaphan" id_sentence="13" />
        <mention ids_tokens="14" string="Astaphan" id_sentence="14" />
        <mention ids_tokens="18" string="Astaphan" id_sentence="16" />
        <mention ids_tokens="4" string="Astaphan" id_sentence="17" />
        <mention ids_tokens="1" string="Astaphan" id_sentence="24" />
      </mentions>
    </coreference>
    <coreference id="21" type="PROPER">
      <referenced ids_tokens="2" string="Ben" id_sentence="11" />
      <mentions>
        <mention ids_tokens="29" string="his" id_sentence="16" />
      </mentions>
    </coreference>
  </coreferences>
</document>
