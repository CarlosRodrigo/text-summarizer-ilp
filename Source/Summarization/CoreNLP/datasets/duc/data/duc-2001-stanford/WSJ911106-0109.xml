<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="WSJ911106-0109">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>One reason is that term limits would open up politics to many people now excluded from office by career incumbents.</content>
      <tokens>
        <token id="1" string="One" lemma="one" stem="one" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="2" string="reason" lemma="reason" stem="reason" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="term" lemma="term" stem="term" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="limits" lemma="limit" stem="limit" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="open" lemma="open" stem="open" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="politics" lemma="politics" stem="polit" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="15" string="excluded" lemma="exclude" stem="exclud" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="office" lemma="office" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="career" lemma="career" stem="career" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="incumbents" lemma="incumbent" stem="incumb" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (CD One) (NN reason)) (VP (VBZ is) (SBAR (IN that) (S (NP (NN term) (NNS limits)) (VP (MD would) (VP (VB open) (PRT (RP up)) (NP (NNS politics)) (PP (TO to) (NP (NP (JJ many) (NNS people)) (VP (ADVP (RB now)) (VBN excluded) (PP (IN from) (NP (NN office))) (PP (IN by) (NP (NN career) (NNS incumbents))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="politics" type="NP">
          <tokens>
            <token id="10" string="politics" />
          </tokens>
        </chunking>
        <chunking id="2" string="is that term limits would open up politics to many people now excluded from office by career incumbents" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="that" />
            <token id="5" string="term" />
            <token id="6" string="limits" />
            <token id="7" string="would" />
            <token id="8" string="open" />
            <token id="9" string="up" />
            <token id="10" string="politics" />
            <token id="11" string="to" />
            <token id="12" string="many" />
            <token id="13" string="people" />
            <token id="14" string="now" />
            <token id="15" string="excluded" />
            <token id="16" string="from" />
            <token id="17" string="office" />
            <token id="18" string="by" />
            <token id="19" string="career" />
            <token id="20" string="incumbents" />
          </tokens>
        </chunking>
        <chunking id="3" string="open up politics to many people now excluded from office by career incumbents" type="VP">
          <tokens>
            <token id="8" string="open" />
            <token id="9" string="up" />
            <token id="10" string="politics" />
            <token id="11" string="to" />
            <token id="12" string="many" />
            <token id="13" string="people" />
            <token id="14" string="now" />
            <token id="15" string="excluded" />
            <token id="16" string="from" />
            <token id="17" string="office" />
            <token id="18" string="by" />
            <token id="19" string="career" />
            <token id="20" string="incumbents" />
          </tokens>
        </chunking>
        <chunking id="4" string="many people now excluded from office by career incumbents" type="NP">
          <tokens>
            <token id="12" string="many" />
            <token id="13" string="people" />
            <token id="14" string="now" />
            <token id="15" string="excluded" />
            <token id="16" string="from" />
            <token id="17" string="office" />
            <token id="18" string="by" />
            <token id="19" string="career" />
            <token id="20" string="incumbents" />
          </tokens>
        </chunking>
        <chunking id="5" string="One reason" type="NP">
          <tokens>
            <token id="1" string="One" />
            <token id="2" string="reason" />
          </tokens>
        </chunking>
        <chunking id="6" string="term limits" type="NP">
          <tokens>
            <token id="5" string="term" />
            <token id="6" string="limits" />
          </tokens>
        </chunking>
        <chunking id="7" string="would open up politics to many people now excluded from office by career incumbents" type="VP">
          <tokens>
            <token id="7" string="would" />
            <token id="8" string="open" />
            <token id="9" string="up" />
            <token id="10" string="politics" />
            <token id="11" string="to" />
            <token id="12" string="many" />
            <token id="13" string="people" />
            <token id="14" string="now" />
            <token id="15" string="excluded" />
            <token id="16" string="from" />
            <token id="17" string="office" />
            <token id="18" string="by" />
            <token id="19" string="career" />
            <token id="20" string="incumbents" />
          </tokens>
        </chunking>
        <chunking id="8" string="many people" type="NP">
          <tokens>
            <token id="12" string="many" />
            <token id="13" string="people" />
          </tokens>
        </chunking>
        <chunking id="9" string="now excluded from office by career incumbents" type="VP">
          <tokens>
            <token id="14" string="now" />
            <token id="15" string="excluded" />
            <token id="16" string="from" />
            <token id="17" string="office" />
            <token id="18" string="by" />
            <token id="19" string="career" />
            <token id="20" string="incumbents" />
          </tokens>
        </chunking>
        <chunking id="10" string="office" type="NP">
          <tokens>
            <token id="17" string="office" />
          </tokens>
        </chunking>
        <chunking id="11" string="that term limits would open up politics to many people now excluded from office by career incumbents" type="SBAR">
          <tokens>
            <token id="4" string="that" />
            <token id="5" string="term" />
            <token id="6" string="limits" />
            <token id="7" string="would" />
            <token id="8" string="open" />
            <token id="9" string="up" />
            <token id="10" string="politics" />
            <token id="11" string="to" />
            <token id="12" string="many" />
            <token id="13" string="people" />
            <token id="14" string="now" />
            <token id="15" string="excluded" />
            <token id="16" string="from" />
            <token id="17" string="office" />
            <token id="18" string="by" />
            <token id="19" string="career" />
            <token id="20" string="incumbents" />
          </tokens>
        </chunking>
        <chunking id="12" string="career incumbents" type="NP">
          <tokens>
            <token id="19" string="career" />
            <token id="20" string="incumbents" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nummod">
          <governor id="2">reason</governor>
          <dependent id="1">One</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">is</governor>
          <dependent id="2">reason</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">open</governor>
          <dependent id="4">that</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">limits</governor>
          <dependent id="5">term</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">open</governor>
          <dependent id="6">limits</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">open</governor>
          <dependent id="7">would</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">is</governor>
          <dependent id="8">open</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="8">open</governor>
          <dependent id="9">up</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">open</governor>
          <dependent id="10">politics</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">people</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">people</governor>
          <dependent id="12">many</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">open</governor>
          <dependent id="13">people</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">excluded</governor>
          <dependent id="14">now</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="13">people</governor>
          <dependent id="15">excluded</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">office</governor>
          <dependent id="16">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">excluded</governor>
          <dependent id="17">office</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">incumbents</governor>
          <dependent id="18">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">incumbents</governor>
          <dependent id="19">career</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">excluded</governor>
          <dependent id="20">incumbents</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="One" type="NUMBER" score="0.0">
          <tokens>
            <token id="1" string="One" />
          </tokens>
        </entity>
        <entity id="2" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="14" string="now" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>These include blacks, other minorities, and women.</content>
      <tokens>
        <token id="1" string="These" lemma="these" stem="these" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="include" lemma="include" stem="includ" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="blacks" lemma="black" stem="black" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="minorities" lemma="minority" stem="minor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="women" lemma="woman" stem="women" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT These)) (VP (VBP include) (NP (NP (NNS blacks)) (, ,) (NP (JJ other) (NNS minorities)) (, ,) (CC and) (NP (NNS women)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="These" type="NP">
          <tokens>
            <token id="1" string="These" />
          </tokens>
        </chunking>
        <chunking id="2" string="blacks , other minorities , and women" type="NP">
          <tokens>
            <token id="3" string="blacks" />
            <token id="4" string="," />
            <token id="5" string="other" />
            <token id="6" string="minorities" />
            <token id="7" string="," />
            <token id="8" string="and" />
            <token id="9" string="women" />
          </tokens>
        </chunking>
        <chunking id="3" string="blacks" type="NP">
          <tokens>
            <token id="3" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="4" string="include blacks , other minorities , and women" type="VP">
          <tokens>
            <token id="2" string="include" />
            <token id="3" string="blacks" />
            <token id="4" string="," />
            <token id="5" string="other" />
            <token id="6" string="minorities" />
            <token id="7" string="," />
            <token id="8" string="and" />
            <token id="9" string="women" />
          </tokens>
        </chunking>
        <chunking id="5" string="other minorities" type="NP">
          <tokens>
            <token id="5" string="other" />
            <token id="6" string="minorities" />
          </tokens>
        </chunking>
        <chunking id="6" string="women" type="NP">
          <tokens>
            <token id="9" string="women" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">include</governor>
          <dependent id="1">These</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">include</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">include</governor>
          <dependent id="3">blacks</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">minorities</governor>
          <dependent id="5">other</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">blacks</governor>
          <dependent id="6">minorities</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">blacks</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">blacks</governor>
          <dependent id="9">women</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="3" has_coreference="false">
      <content>Most of the authors of Washington state&amp;apost;s term limit are liberal Democrats who want to break up &amp;quot;the old-boy network.&amp;quot;</content>
      <tokens>
        <token id="1" string="Most" lemma="most" stem="most" pos="JJS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="authors" lemma="author" stem="author" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Washington" lemma="Washington" stem="washington" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="7" string="state" lemma="state" stem="state" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="term" lemma="term" stem="term" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="limit" lemma="limit" stem="limit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="liberal" lemma="liberal" stem="liber" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="13" string="Democrats" lemma="Democrats" stem="democrat" pos="NNPS" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="14" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="want" lemma="want" stem="want" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="break" lemma="break" stem="break" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="old-boy" lemma="old-boy" stem="old-boi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="network" lemma="network" stem="network" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (JJS Most)) (PP (IN of) (NP (NP (DT the) (NNS authors)) (PP (IN of) (NP (NP (NNP Washington) (NN state) (POS 's)) (NN term) (NN limit)))))) (VP (VBP are) (NP (NP (JJ liberal) (NNPS Democrats)) (SBAR (WHNP (WP who)) (S (VP (VBP want) (S (VP (TO to) (VP (VB break) (PRT (RP up)) (`` ``) (NP (DT the) (JJ old-boy) (NN network)))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="Most" type="NP">
          <tokens>
            <token id="1" string="Most" />
          </tokens>
        </chunking>
        <chunking id="2" string="liberal Democrats" type="NP">
          <tokens>
            <token id="12" string="liberal" />
            <token id="13" string="Democrats" />
          </tokens>
        </chunking>
        <chunking id="3" string="liberal Democrats who want to break up `` the old-boy network" type="NP">
          <tokens>
            <token id="12" string="liberal" />
            <token id="13" string="Democrats" />
            <token id="14" string="who" />
            <token id="15" string="want" />
            <token id="16" string="to" />
            <token id="17" string="break" />
            <token id="18" string="up" />
            <token id="19" string="&quot;" />
            <token id="20" string="the" />
            <token id="21" string="old-boy" />
            <token id="22" string="network" />
          </tokens>
        </chunking>
        <chunking id="4" string="the authors" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="authors" />
          </tokens>
        </chunking>
        <chunking id="5" string="to break up `` the old-boy network" type="VP">
          <tokens>
            <token id="16" string="to" />
            <token id="17" string="break" />
            <token id="18" string="up" />
            <token id="19" string="&quot;" />
            <token id="20" string="the" />
            <token id="21" string="old-boy" />
            <token id="22" string="network" />
          </tokens>
        </chunking>
        <chunking id="6" string="Most of the authors of Washington state 's term limit" type="NP">
          <tokens>
            <token id="1" string="Most" />
            <token id="2" string="of" />
            <token id="3" string="the" />
            <token id="4" string="authors" />
            <token id="5" string="of" />
            <token id="6" string="Washington" />
            <token id="7" string="state" />
            <token id="8" string="'s" />
            <token id="9" string="term" />
            <token id="10" string="limit" />
          </tokens>
        </chunking>
        <chunking id="7" string="who want to break up `` the old-boy network" type="SBAR">
          <tokens>
            <token id="14" string="who" />
            <token id="15" string="want" />
            <token id="16" string="to" />
            <token id="17" string="break" />
            <token id="18" string="up" />
            <token id="19" string="&quot;" />
            <token id="20" string="the" />
            <token id="21" string="old-boy" />
            <token id="22" string="network" />
          </tokens>
        </chunking>
        <chunking id="8" string="want to break up `` the old-boy network" type="VP">
          <tokens>
            <token id="15" string="want" />
            <token id="16" string="to" />
            <token id="17" string="break" />
            <token id="18" string="up" />
            <token id="19" string="&quot;" />
            <token id="20" string="the" />
            <token id="21" string="old-boy" />
            <token id="22" string="network" />
          </tokens>
        </chunking>
        <chunking id="9" string="are liberal Democrats who want to break up `` the old-boy network" type="VP">
          <tokens>
            <token id="11" string="are" />
            <token id="12" string="liberal" />
            <token id="13" string="Democrats" />
            <token id="14" string="who" />
            <token id="15" string="want" />
            <token id="16" string="to" />
            <token id="17" string="break" />
            <token id="18" string="up" />
            <token id="19" string="&quot;" />
            <token id="20" string="the" />
            <token id="21" string="old-boy" />
            <token id="22" string="network" />
          </tokens>
        </chunking>
        <chunking id="10" string="break up `` the old-boy network" type="VP">
          <tokens>
            <token id="17" string="break" />
            <token id="18" string="up" />
            <token id="19" string="&quot;" />
            <token id="20" string="the" />
            <token id="21" string="old-boy" />
            <token id="22" string="network" />
          </tokens>
        </chunking>
        <chunking id="11" string="Washington state 's term limit" type="NP">
          <tokens>
            <token id="6" string="Washington" />
            <token id="7" string="state" />
            <token id="8" string="'s" />
            <token id="9" string="term" />
            <token id="10" string="limit" />
          </tokens>
        </chunking>
        <chunking id="12" string="the authors of Washington state 's term limit" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="authors" />
            <token id="5" string="of" />
            <token id="6" string="Washington" />
            <token id="7" string="state" />
            <token id="8" string="'s" />
            <token id="9" string="term" />
            <token id="10" string="limit" />
          </tokens>
        </chunking>
        <chunking id="13" string="Washington state 's" type="NP">
          <tokens>
            <token id="6" string="Washington" />
            <token id="7" string="state" />
            <token id="8" string="'s" />
          </tokens>
        </chunking>
        <chunking id="14" string="the old-boy network" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="old-boy" />
            <token id="22" string="network" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="13">Democrats</governor>
          <dependent id="1">Most</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">authors</governor>
          <dependent id="2">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">authors</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Most</governor>
          <dependent id="4">authors</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">limit</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">state</governor>
          <dependent id="6">Washington</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">limit</governor>
          <dependent id="7">state</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">state</governor>
          <dependent id="8">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">limit</governor>
          <dependent id="9">term</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">authors</governor>
          <dependent id="10">limit</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="13">Democrats</governor>
          <dependent id="11">are</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">Democrats</governor>
          <dependent id="12">liberal</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">Democrats</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">want</governor>
          <dependent id="14">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="13">Democrats</governor>
          <dependent id="15">want</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">break</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="15">want</governor>
          <dependent id="17">break</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="17">break</governor>
          <dependent id="18">up</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">network</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">network</governor>
          <dependent id="21">old-boy</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">break</governor>
          <dependent id="22">network</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Washington" type="LOCATION" score="0.0">
          <tokens>
            <token id="6" string="Washington" />
          </tokens>
        </entity>
        <entity id="2" string="liberal Democrats" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="12" string="liberal" />
            <token id="13" string="Democrats" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>One of the authors, Sherry Bockwinkel, says &amp;quot;You won&amp;apost;t see white incumbents hanging on to districts that long ago became largely minority.&amp;quot;</content>
      <tokens>
        <token id="1" string="One" lemma="one" stem="one" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="2" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="authors" lemma="author" stem="author" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Sherry" lemma="Sherry" stem="sherri" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="7" string="Bockwinkel" lemma="Bockwinkel" stem="bockwinkel" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="You" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="wo" lemma="will" stem="wo" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="see" lemma="see" stem="see" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="white" lemma="white" stem="white" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="incumbents" lemma="incumbent" stem="incumb" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="hanging" lemma="hang" stem="hang" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="districts" lemma="district" stem="district" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="long" lemma="long" stem="long" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="ago" lemma="ago" stem="ago" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="became" lemma="become" stem="becam" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="largely" lemma="largely" stem="larg" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="minority" lemma="minority" stem="minor" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NP (CD One)) (PP (IN of) (NP (DT the) (NNS authors)))) (, ,) (NP (NNP Sherry) (NNP Bockwinkel)) (, ,)) (VP (VBZ says) (S (`` ``) (NP (PRP You)) (VP (MD wo) (RB n't) (VP (VB see) (NP (NP (JJ white) (NNS incumbents)) (VP (VBG hanging) (PP (IN on) (PP (TO to) (NP (NP (NNS districts)) (SBAR (WHNP (WDT that)) (S (ADVP (RB long) (RB ago)) (VP (VBD became) (ADJP (RB largely) (NN minority)))))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="white incumbents hanging on to districts that long ago became largely minority" type="NP">
          <tokens>
            <token id="15" string="white" />
            <token id="16" string="incumbents" />
            <token id="17" string="hanging" />
            <token id="18" string="on" />
            <token id="19" string="to" />
            <token id="20" string="districts" />
            <token id="21" string="that" />
            <token id="22" string="long" />
            <token id="23" string="ago" />
            <token id="24" string="became" />
            <token id="25" string="largely" />
            <token id="26" string="minority" />
          </tokens>
        </chunking>
        <chunking id="2" string="largely minority" type="ADJP">
          <tokens>
            <token id="25" string="largely" />
            <token id="26" string="minority" />
          </tokens>
        </chunking>
        <chunking id="3" string="One" type="NP">
          <tokens>
            <token id="1" string="One" />
          </tokens>
        </chunking>
        <chunking id="4" string="Sherry Bockwinkel" type="NP">
          <tokens>
            <token id="6" string="Sherry" />
            <token id="7" string="Bockwinkel" />
          </tokens>
        </chunking>
        <chunking id="5" string="districts" type="NP">
          <tokens>
            <token id="20" string="districts" />
          </tokens>
        </chunking>
        <chunking id="6" string="One of the authors" type="NP">
          <tokens>
            <token id="1" string="One" />
            <token id="2" string="of" />
            <token id="3" string="the" />
            <token id="4" string="authors" />
          </tokens>
        </chunking>
        <chunking id="7" string="the authors" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="authors" />
          </tokens>
        </chunking>
        <chunking id="8" string="wo n't see white incumbents hanging on to districts that long ago became largely minority" type="VP">
          <tokens>
            <token id="12" string="wo" />
            <token id="13" string="n't" />
            <token id="14" string="see" />
            <token id="15" string="white" />
            <token id="16" string="incumbents" />
            <token id="17" string="hanging" />
            <token id="18" string="on" />
            <token id="19" string="to" />
            <token id="20" string="districts" />
            <token id="21" string="that" />
            <token id="22" string="long" />
            <token id="23" string="ago" />
            <token id="24" string="became" />
            <token id="25" string="largely" />
            <token id="26" string="minority" />
          </tokens>
        </chunking>
        <chunking id="9" string="hanging on to districts that long ago became largely minority" type="VP">
          <tokens>
            <token id="17" string="hanging" />
            <token id="18" string="on" />
            <token id="19" string="to" />
            <token id="20" string="districts" />
            <token id="21" string="that" />
            <token id="22" string="long" />
            <token id="23" string="ago" />
            <token id="24" string="became" />
            <token id="25" string="largely" />
            <token id="26" string="minority" />
          </tokens>
        </chunking>
        <chunking id="10" string="that long ago became largely minority" type="SBAR">
          <tokens>
            <token id="21" string="that" />
            <token id="22" string="long" />
            <token id="23" string="ago" />
            <token id="24" string="became" />
            <token id="25" string="largely" />
            <token id="26" string="minority" />
          </tokens>
        </chunking>
        <chunking id="11" string="became largely minority" type="VP">
          <tokens>
            <token id="24" string="became" />
            <token id="25" string="largely" />
            <token id="26" string="minority" />
          </tokens>
        </chunking>
        <chunking id="12" string="white incumbents" type="NP">
          <tokens>
            <token id="15" string="white" />
            <token id="16" string="incumbents" />
          </tokens>
        </chunking>
        <chunking id="13" string="see white incumbents hanging on to districts that long ago became largely minority" type="VP">
          <tokens>
            <token id="14" string="see" />
            <token id="15" string="white" />
            <token id="16" string="incumbents" />
            <token id="17" string="hanging" />
            <token id="18" string="on" />
            <token id="19" string="to" />
            <token id="20" string="districts" />
            <token id="21" string="that" />
            <token id="22" string="long" />
            <token id="23" string="ago" />
            <token id="24" string="became" />
            <token id="25" string="largely" />
            <token id="26" string="minority" />
          </tokens>
        </chunking>
        <chunking id="14" string="One of the authors , Sherry Bockwinkel ," type="NP">
          <tokens>
            <token id="1" string="One" />
            <token id="2" string="of" />
            <token id="3" string="the" />
            <token id="4" string="authors" />
            <token id="5" string="," />
            <token id="6" string="Sherry" />
            <token id="7" string="Bockwinkel" />
            <token id="8" string="," />
          </tokens>
        </chunking>
        <chunking id="15" string="says `` You wo n't see white incumbents hanging on to districts that long ago became largely minority" type="VP">
          <tokens>
            <token id="9" string="says" />
            <token id="10" string="&quot;" />
            <token id="11" string="You" />
            <token id="12" string="wo" />
            <token id="13" string="n't" />
            <token id="14" string="see" />
            <token id="15" string="white" />
            <token id="16" string="incumbents" />
            <token id="17" string="hanging" />
            <token id="18" string="on" />
            <token id="19" string="to" />
            <token id="20" string="districts" />
            <token id="21" string="that" />
            <token id="22" string="long" />
            <token id="23" string="ago" />
            <token id="24" string="became" />
            <token id="25" string="largely" />
            <token id="26" string="minority" />
          </tokens>
        </chunking>
        <chunking id="16" string="districts that long ago became largely minority" type="NP">
          <tokens>
            <token id="20" string="districts" />
            <token id="21" string="that" />
            <token id="22" string="long" />
            <token id="23" string="ago" />
            <token id="24" string="became" />
            <token id="25" string="largely" />
            <token id="26" string="minority" />
          </tokens>
        </chunking>
        <chunking id="17" string="You" type="NP">
          <tokens>
            <token id="11" string="You" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="9">says</governor>
          <dependent id="1">One</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">authors</governor>
          <dependent id="2">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">authors</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">One</governor>
          <dependent id="4">authors</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Bockwinkel</governor>
          <dependent id="6">Sherry</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="1">One</governor>
          <dependent id="7">Bockwinkel</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">says</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">see</governor>
          <dependent id="11">You</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">see</governor>
          <dependent id="12">wo</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="14">see</governor>
          <dependent id="13">n't</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">says</governor>
          <dependent id="14">see</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">incumbents</governor>
          <dependent id="15">white</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">see</governor>
          <dependent id="16">incumbents</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="16">incumbents</governor>
          <dependent id="17">hanging</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">districts</governor>
          <dependent id="18">on</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">districts</governor>
          <dependent id="19">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">hanging</governor>
          <dependent id="20">districts</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">became</governor>
          <dependent id="21">that</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="23">ago</governor>
          <dependent id="22">long</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="24">became</governor>
          <dependent id="23">ago</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="20">districts</governor>
          <dependent id="24">became</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="26">minority</governor>
          <dependent id="25">largely</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="24">became</governor>
          <dependent id="26">minority</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="One" type="NUMBER" score="0.0">
          <tokens>
            <token id="1" string="One" />
          </tokens>
        </entity>
        <entity id="2" string="Sherry Bockwinkel" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Sherry" />
            <token id="7" string="Bockwinkel" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>&amp;quot;Incumbency is the glass ceiling of American politics,&amp;quot; says Kay Slaughter, the Democratic candidate in a special U.S. House election in Virginia yesterday.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Incumbency" lemma="Incumbency" stem="incumbenc" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="glass" lemma="glass" stem="glass" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="ceiling" lemma="ceiling" stem="ceil" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="American" lemma="american" stem="american" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="9" string="politics" lemma="politics" stem="polit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="Kay" lemma="Kay" stem="kai" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="14" string="Slaughter" lemma="Slaughter" stem="slaughter" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Democratic" lemma="democratic" stem="democrat" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="true" is_refers="false" />
        <token id="18" string="candidate" lemma="candidate" stem="candid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="special" lemma="special" stem="special" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="U.S." lemma="U.S." stem="u.s." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="23" string="House" lemma="House" stem="hous" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="24" string="election" lemma="election" stem="elect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="Virginia" lemma="Virginia" stem="virginia" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="27" string="yesterday" lemma="yesterday" stem="yesterdai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (NNP Incumbency)) (VP (VBZ is) (NP (NP (DT the) (NN glass) (NN ceiling)) (PP (IN of) (NP (JJ American) (NNS politics)))))) (, ,) ('' '') (VP (VBZ says)) (NP (NP (NNP Kay) (NNP Slaughter)) (, ,) (NP (NP (DT the) (JJ Democratic) (NN candidate)) (PP (IN in) (NP (NP (DT a) (JJ special) (NNP U.S.) (NNP House) (NN election)) (PP (IN in) (NP (NNP Virginia))) (NP-TMP (NN yesterday)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Kay Slaughter , the Democratic candidate in a special U.S. House election in Virginia yesterday" type="NP">
          <tokens>
            <token id="13" string="Kay" />
            <token id="14" string="Slaughter" />
            <token id="15" string="," />
            <token id="16" string="the" />
            <token id="17" string="Democratic" />
            <token id="18" string="candidate" />
            <token id="19" string="in" />
            <token id="20" string="a" />
            <token id="21" string="special" />
            <token id="22" string="U.S." />
            <token id="23" string="House" />
            <token id="24" string="election" />
            <token id="25" string="in" />
            <token id="26" string="Virginia" />
            <token id="27" string="yesterday" />
          </tokens>
        </chunking>
        <chunking id="2" string="a special U.S. House election in Virginia yesterday" type="NP">
          <tokens>
            <token id="20" string="a" />
            <token id="21" string="special" />
            <token id="22" string="U.S." />
            <token id="23" string="House" />
            <token id="24" string="election" />
            <token id="25" string="in" />
            <token id="26" string="Virginia" />
            <token id="27" string="yesterday" />
          </tokens>
        </chunking>
        <chunking id="3" string="is the glass ceiling of American politics" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="the" />
            <token id="5" string="glass" />
            <token id="6" string="ceiling" />
            <token id="7" string="of" />
            <token id="8" string="American" />
            <token id="9" string="politics" />
          </tokens>
        </chunking>
        <chunking id="4" string="American politics" type="NP">
          <tokens>
            <token id="8" string="American" />
            <token id="9" string="politics" />
          </tokens>
        </chunking>
        <chunking id="5" string="a special U.S. House election" type="NP">
          <tokens>
            <token id="20" string="a" />
            <token id="21" string="special" />
            <token id="22" string="U.S." />
            <token id="23" string="House" />
            <token id="24" string="election" />
          </tokens>
        </chunking>
        <chunking id="6" string="the glass ceiling of American politics" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="glass" />
            <token id="6" string="ceiling" />
            <token id="7" string="of" />
            <token id="8" string="American" />
            <token id="9" string="politics" />
          </tokens>
        </chunking>
        <chunking id="7" string="Incumbency" type="NP">
          <tokens>
            <token id="2" string="Incumbency" />
          </tokens>
        </chunking>
        <chunking id="8" string="says" type="VP">
          <tokens>
            <token id="12" string="says" />
          </tokens>
        </chunking>
        <chunking id="9" string="the Democratic candidate in a special U.S. House election in Virginia yesterday" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="Democratic" />
            <token id="18" string="candidate" />
            <token id="19" string="in" />
            <token id="20" string="a" />
            <token id="21" string="special" />
            <token id="22" string="U.S." />
            <token id="23" string="House" />
            <token id="24" string="election" />
            <token id="25" string="in" />
            <token id="26" string="Virginia" />
            <token id="27" string="yesterday" />
          </tokens>
        </chunking>
        <chunking id="10" string="the glass ceiling" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="glass" />
            <token id="6" string="ceiling" />
          </tokens>
        </chunking>
        <chunking id="11" string="the Democratic candidate" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="Democratic" />
            <token id="18" string="candidate" />
          </tokens>
        </chunking>
        <chunking id="12" string="Virginia" type="NP">
          <tokens>
            <token id="26" string="Virginia" />
          </tokens>
        </chunking>
        <chunking id="13" string="Kay Slaughter" type="NP">
          <tokens>
            <token id="13" string="Kay" />
            <token id="14" string="Slaughter" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">ceiling</governor>
          <dependent id="2">Incumbency</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">ceiling</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">ceiling</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">ceiling</governor>
          <dependent id="5">glass</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">says</governor>
          <dependent id="6">ceiling</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">politics</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">politics</governor>
          <dependent id="8">American</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">ceiling</governor>
          <dependent id="9">politics</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">says</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Slaughter</governor>
          <dependent id="13">Kay</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">says</governor>
          <dependent id="14">Slaughter</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">candidate</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">candidate</governor>
          <dependent id="17">Democratic</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="14">Slaughter</governor>
          <dependent id="18">candidate</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">election</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">election</governor>
          <dependent id="20">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">election</governor>
          <dependent id="21">special</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">election</governor>
          <dependent id="22">U.S.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">election</governor>
          <dependent id="23">House</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">candidate</governor>
          <dependent id="24">election</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">Virginia</governor>
          <dependent id="25">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">election</governor>
          <dependent id="26">Virginia</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="24">election</governor>
          <dependent id="27">yesterday</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="yesterday" type="DATE" score="0.0">
          <tokens>
            <token id="27" string="yesterday" />
          </tokens>
        </entity>
        <entity id="2" string="U.S." type="LOCATION" score="0.0">
          <tokens>
            <token id="22" string="U.S." />
          </tokens>
        </entity>
        <entity id="3" string="House" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="23" string="House" />
          </tokens>
        </entity>
        <entity id="4" string="Democratic" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="17" string="Democratic" />
          </tokens>
        </entity>
        <entity id="5" string="American" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="8" string="American" />
          </tokens>
        </entity>
        <entity id="6" string="Virginia" type="LOCATION" score="0.0">
          <tokens>
            <token id="26" string="Virginia" />
          </tokens>
        </entity>
        <entity id="7" string="Kay Slaughter" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Kay" />
            <token id="14" string="Slaughter" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>She thinks term limits will give women more opportunities in politics; her GOP opponent refused to support federal term limits.</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="thinks" lemma="think" stem="think" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="term" lemma="term" stem="term" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="limits" lemma="limit" stem="limit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="give" lemma="give" stem="give" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="women" lemma="woman" stem="women" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="opportunities" lemma="opportunity" stem="opportun" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="politics" lemma="politics" stem="polit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="GOP" lemma="GOP" stem="gop" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="15" string="opponent" lemma="opponent" stem="oppon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="refused" lemma="refuse" stem="refus" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="support" lemma="support" stem="support" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="federal" lemma="federal" stem="feder" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="term" lemma="term" stem="term" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="limits" lemma="limit" stem="limit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP She)) (VP (VBZ thinks) (SBAR (S (NP (NN term) (NNS limits)) (VP (MD will) (VP (VB give) (NP (NNS women) (RBR more)) (NP (NP (NNS opportunities)) (PP (IN in) (NP (NNS politics)))))))))) (: ;) (S (NP (PRP$ her) (NNP GOP) (NN opponent)) (VP (VBD refused) (S (VP (TO to) (VP (VB support) (NP (JJ federal) (NN term) (NNS limits))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="politics" type="NP">
          <tokens>
            <token id="11" string="politics" />
          </tokens>
        </chunking>
        <chunking id="2" string="opportunities in politics" type="NP">
          <tokens>
            <token id="9" string="opportunities" />
            <token id="10" string="in" />
            <token id="11" string="politics" />
          </tokens>
        </chunking>
        <chunking id="3" string="will give women more opportunities in politics" type="VP">
          <tokens>
            <token id="5" string="will" />
            <token id="6" string="give" />
            <token id="7" string="women" />
            <token id="8" string="more" />
            <token id="9" string="opportunities" />
            <token id="10" string="in" />
            <token id="11" string="politics" />
          </tokens>
        </chunking>
        <chunking id="4" string="her GOP opponent" type="NP">
          <tokens>
            <token id="13" string="her" />
            <token id="14" string="GOP" />
            <token id="15" string="opponent" />
          </tokens>
        </chunking>
        <chunking id="5" string="women more" type="NP">
          <tokens>
            <token id="7" string="women" />
            <token id="8" string="more" />
          </tokens>
        </chunking>
        <chunking id="6" string="term limits" type="NP">
          <tokens>
            <token id="3" string="term" />
            <token id="4" string="limits" />
          </tokens>
        </chunking>
        <chunking id="7" string="opportunities" type="NP">
          <tokens>
            <token id="9" string="opportunities" />
          </tokens>
        </chunking>
        <chunking id="8" string="term limits will give women more opportunities in politics" type="SBAR">
          <tokens>
            <token id="3" string="term" />
            <token id="4" string="limits" />
            <token id="5" string="will" />
            <token id="6" string="give" />
            <token id="7" string="women" />
            <token id="8" string="more" />
            <token id="9" string="opportunities" />
            <token id="10" string="in" />
            <token id="11" string="politics" />
          </tokens>
        </chunking>
        <chunking id="9" string="support federal term limits" type="VP">
          <tokens>
            <token id="18" string="support" />
            <token id="19" string="federal" />
            <token id="20" string="term" />
            <token id="21" string="limits" />
          </tokens>
        </chunking>
        <chunking id="10" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
        <chunking id="11" string="to support federal term limits" type="VP">
          <tokens>
            <token id="17" string="to" />
            <token id="18" string="support" />
            <token id="19" string="federal" />
            <token id="20" string="term" />
            <token id="21" string="limits" />
          </tokens>
        </chunking>
        <chunking id="12" string="refused to support federal term limits" type="VP">
          <tokens>
            <token id="16" string="refused" />
            <token id="17" string="to" />
            <token id="18" string="support" />
            <token id="19" string="federal" />
            <token id="20" string="term" />
            <token id="21" string="limits" />
          </tokens>
        </chunking>
        <chunking id="13" string="give women more opportunities in politics" type="VP">
          <tokens>
            <token id="6" string="give" />
            <token id="7" string="women" />
            <token id="8" string="more" />
            <token id="9" string="opportunities" />
            <token id="10" string="in" />
            <token id="11" string="politics" />
          </tokens>
        </chunking>
        <chunking id="14" string="thinks term limits will give women more opportunities in politics" type="VP">
          <tokens>
            <token id="2" string="thinks" />
            <token id="3" string="term" />
            <token id="4" string="limits" />
            <token id="5" string="will" />
            <token id="6" string="give" />
            <token id="7" string="women" />
            <token id="8" string="more" />
            <token id="9" string="opportunities" />
            <token id="10" string="in" />
            <token id="11" string="politics" />
          </tokens>
        </chunking>
        <chunking id="15" string="federal term limits" type="NP">
          <tokens>
            <token id="19" string="federal" />
            <token id="20" string="term" />
            <token id="21" string="limits" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">thinks</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">thinks</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">limits</governor>
          <dependent id="3">term</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">give</governor>
          <dependent id="4">limits</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">give</governor>
          <dependent id="5">will</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">thinks</governor>
          <dependent id="6">give</dependent>
        </dependency>
        <dependency type="iobj">
          <governor id="6">give</governor>
          <dependent id="7">women</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">women</governor>
          <dependent id="8">more</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">give</governor>
          <dependent id="9">opportunities</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">politics</governor>
          <dependent id="10">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">opportunities</governor>
          <dependent id="11">politics</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">opponent</governor>
          <dependent id="13">her</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">opponent</governor>
          <dependent id="14">GOP</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">refused</governor>
          <dependent id="15">opponent</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="2">thinks</governor>
          <dependent id="16">refused</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">support</governor>
          <dependent id="17">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="16">refused</governor>
          <dependent id="18">support</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">limits</governor>
          <dependent id="19">federal</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">limits</governor>
          <dependent id="20">term</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">support</governor>
          <dependent id="21">limits</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="GOP" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="14" string="GOP" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>Former Rep. Shirley Chisholm, who in 1972 was the first black to run for a majorparty presidential nomination, says &amp;quot;longterm incumbency is a big reason that Congress no longer works and isn&amp;apost;t representative.</content>
      <tokens>
        <token id="1" string="Former" lemma="Former" stem="former" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="Rep." lemma="Rep." stem="rep." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Shirley" lemma="Shirley" stem="shirlei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="4" string="Chisholm" lemma="Chisholm" stem="chisholm" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="1972" lemma="1972" stem="1972" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="9" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="12" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="run" lemma="run" stem="run" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="majorparty" lemma="majorparty" stem="majorparti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="presidential" lemma="presidential" stem="presidenti" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="nomination" lemma="nomination" stem="nomin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="longterm" lemma="longterm" stem="longterm" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="incumbency" lemma="incumbency" stem="incumb" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="big" lemma="big" stem="big" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="reason" lemma="reason" stem="reason" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="Congress" lemma="Congress" stem="congress" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="31" string="no" lemma="no" stem="no" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="longer" lemma="longer" stem="longer" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="works" lemma="work" stem="work" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="representative" lemma="representative" stem="repres" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Former) (NNP Rep.) (NNP Shirley) (NNP Chisholm)) (, ,) (SBAR (WHNP (WP who)) (S (PP (IN in) (NP (CD 1972))) (VP (VBD was) (NP (DT the) (JJ first) (ADJP (JJ black) (S (VP (TO to) (VP (VB run) (PP (IN for) (NP (DT a) (NN majorparty))))))) (JJ presidential) (NN nomination))))) (, ,)) (VP (VBZ says) (S (`` ``) (NP (JJ longterm) (NN incumbency)) (VP (VBZ is) (NP (DT a) (JJ big) (NN reason)) (SBAR (IN that) (S (NP (NNP Congress)) (ADVP (RB no) (RB longer)) (VP (VP (VBZ works)) (CC and) (VP (VBZ is) (RB n't) (ADJP (JJ representative))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="who in 1972 was the first black to run for a majorparty presidential nomination" type="SBAR">
          <tokens>
            <token id="6" string="who" />
            <token id="7" string="in" />
            <token id="8" string="1972" />
            <token id="9" string="was" />
            <token id="10" string="the" />
            <token id="11" string="first" />
            <token id="12" string="black" />
            <token id="13" string="to" />
            <token id="14" string="run" />
            <token id="15" string="for" />
            <token id="16" string="a" />
            <token id="17" string="majorparty" />
            <token id="18" string="presidential" />
            <token id="19" string="nomination" />
          </tokens>
        </chunking>
        <chunking id="2" string="works" type="VP">
          <tokens>
            <token id="33" string="works" />
          </tokens>
        </chunking>
        <chunking id="3" string="Former Rep. Shirley Chisholm , who in 1972 was the first black to run for a majorparty presidential nomination ," type="NP">
          <tokens>
            <token id="1" string="Former" />
            <token id="2" string="Rep." />
            <token id="3" string="Shirley" />
            <token id="4" string="Chisholm" />
            <token id="5" string="," />
            <token id="6" string="who" />
            <token id="7" string="in" />
            <token id="8" string="1972" />
            <token id="9" string="was" />
            <token id="10" string="the" />
            <token id="11" string="first" />
            <token id="12" string="black" />
            <token id="13" string="to" />
            <token id="14" string="run" />
            <token id="15" string="for" />
            <token id="16" string="a" />
            <token id="17" string="majorparty" />
            <token id="18" string="presidential" />
            <token id="19" string="nomination" />
            <token id="20" string="," />
          </tokens>
        </chunking>
        <chunking id="4" string="a majorparty" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="majorparty" />
          </tokens>
        </chunking>
        <chunking id="5" string="was the first black to run for a majorparty presidential nomination" type="VP">
          <tokens>
            <token id="9" string="was" />
            <token id="10" string="the" />
            <token id="11" string="first" />
            <token id="12" string="black" />
            <token id="13" string="to" />
            <token id="14" string="run" />
            <token id="15" string="for" />
            <token id="16" string="a" />
            <token id="17" string="majorparty" />
            <token id="18" string="presidential" />
            <token id="19" string="nomination" />
          </tokens>
        </chunking>
        <chunking id="6" string="to run for a majorparty" type="VP">
          <tokens>
            <token id="13" string="to" />
            <token id="14" string="run" />
            <token id="15" string="for" />
            <token id="16" string="a" />
            <token id="17" string="majorparty" />
          </tokens>
        </chunking>
        <chunking id="7" string="is n't representative" type="VP">
          <tokens>
            <token id="35" string="is" />
            <token id="36" string="n't" />
            <token id="37" string="representative" />
          </tokens>
        </chunking>
        <chunking id="8" string="Former Rep. Shirley Chisholm" type="NP">
          <tokens>
            <token id="1" string="Former" />
            <token id="2" string="Rep." />
            <token id="3" string="Shirley" />
            <token id="4" string="Chisholm" />
          </tokens>
        </chunking>
        <chunking id="9" string="that Congress no longer works and is n't representative" type="SBAR">
          <tokens>
            <token id="29" string="that" />
            <token id="30" string="Congress" />
            <token id="31" string="no" />
            <token id="32" string="longer" />
            <token id="33" string="works" />
            <token id="34" string="and" />
            <token id="35" string="is" />
            <token id="36" string="n't" />
            <token id="37" string="representative" />
          </tokens>
        </chunking>
        <chunking id="10" string="the first black to run for a majorparty presidential nomination" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="first" />
            <token id="12" string="black" />
            <token id="13" string="to" />
            <token id="14" string="run" />
            <token id="15" string="for" />
            <token id="16" string="a" />
            <token id="17" string="majorparty" />
            <token id="18" string="presidential" />
            <token id="19" string="nomination" />
          </tokens>
        </chunking>
        <chunking id="11" string="works and is n't representative" type="VP">
          <tokens>
            <token id="33" string="works" />
            <token id="34" string="and" />
            <token id="35" string="is" />
            <token id="36" string="n't" />
            <token id="37" string="representative" />
          </tokens>
        </chunking>
        <chunking id="12" string="Congress" type="NP">
          <tokens>
            <token id="30" string="Congress" />
          </tokens>
        </chunking>
        <chunking id="13" string="says `` longterm incumbency is a big reason that Congress no longer works and is n't representative" type="VP">
          <tokens>
            <token id="21" string="says" />
            <token id="22" string="&quot;" />
            <token id="23" string="longterm" />
            <token id="24" string="incumbency" />
            <token id="25" string="is" />
            <token id="26" string="a" />
            <token id="27" string="big" />
            <token id="28" string="reason" />
            <token id="29" string="that" />
            <token id="30" string="Congress" />
            <token id="31" string="no" />
            <token id="32" string="longer" />
            <token id="33" string="works" />
            <token id="34" string="and" />
            <token id="35" string="is" />
            <token id="36" string="n't" />
            <token id="37" string="representative" />
          </tokens>
        </chunking>
        <chunking id="14" string="black to run for a majorparty" type="ADJP">
          <tokens>
            <token id="12" string="black" />
            <token id="13" string="to" />
            <token id="14" string="run" />
            <token id="15" string="for" />
            <token id="16" string="a" />
            <token id="17" string="majorparty" />
          </tokens>
        </chunking>
        <chunking id="15" string="1972" type="NP">
          <tokens>
            <token id="8" string="1972" />
          </tokens>
        </chunking>
        <chunking id="16" string="a big reason" type="NP">
          <tokens>
            <token id="26" string="a" />
            <token id="27" string="big" />
            <token id="28" string="reason" />
          </tokens>
        </chunking>
        <chunking id="17" string="longterm incumbency" type="NP">
          <tokens>
            <token id="23" string="longterm" />
            <token id="24" string="incumbency" />
          </tokens>
        </chunking>
        <chunking id="18" string="run for a majorparty" type="VP">
          <tokens>
            <token id="14" string="run" />
            <token id="15" string="for" />
            <token id="16" string="a" />
            <token id="17" string="majorparty" />
          </tokens>
        </chunking>
        <chunking id="19" string="representative" type="ADJP">
          <tokens>
            <token id="37" string="representative" />
          </tokens>
        </chunking>
        <chunking id="20" string="is a big reason that Congress no longer works and is n't representative" type="VP">
          <tokens>
            <token id="25" string="is" />
            <token id="26" string="a" />
            <token id="27" string="big" />
            <token id="28" string="reason" />
            <token id="29" string="that" />
            <token id="30" string="Congress" />
            <token id="31" string="no" />
            <token id="32" string="longer" />
            <token id="33" string="works" />
            <token id="34" string="and" />
            <token id="35" string="is" />
            <token id="36" string="n't" />
            <token id="37" string="representative" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="4">Chisholm</governor>
          <dependent id="1">Former</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Chisholm</governor>
          <dependent id="2">Rep.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Chisholm</governor>
          <dependent id="3">Shirley</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">says</governor>
          <dependent id="4">Chisholm</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">nomination</governor>
          <dependent id="6">who</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">1972</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">nomination</governor>
          <dependent id="8">1972</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="19">nomination</governor>
          <dependent id="9">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">nomination</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">nomination</governor>
          <dependent id="11">first</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">nomination</governor>
          <dependent id="12">black</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">run</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="12">black</governor>
          <dependent id="14">run</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">majorparty</governor>
          <dependent id="15">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">majorparty</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">run</governor>
          <dependent id="17">majorparty</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">nomination</governor>
          <dependent id="18">presidential</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="4">Chisholm</governor>
          <dependent id="19">nomination</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="21">says</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">incumbency</governor>
          <dependent id="23">longterm</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">reason</governor>
          <dependent id="24">incumbency</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="28">reason</governor>
          <dependent id="25">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">reason</governor>
          <dependent id="26">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">reason</governor>
          <dependent id="27">big</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="21">says</governor>
          <dependent id="28">reason</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="33">works</governor>
          <dependent id="29">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="33">works</governor>
          <dependent id="30">Congress</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="32">longer</governor>
          <dependent id="31">no</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="33">works</governor>
          <dependent id="32">longer</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="28">reason</governor>
          <dependent id="33">works</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="33">works</governor>
          <dependent id="34">and</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="37">representative</governor>
          <dependent id="35">is</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="37">representative</governor>
          <dependent id="36">n't</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="33">works</governor>
          <dependent id="37">representative</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="11" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="1972" type="DATE" score="0.0">
          <tokens>
            <token id="8" string="1972" />
          </tokens>
        </entity>
        <entity id="3" string="Shirley Chisholm" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Shirley" />
            <token id="4" string="Chisholm" />
          </tokens>
        </entity>
        <entity id="4" string="Congress" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="30" string="Congress" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>We need a lot more turnover.&amp;quot;</content>
      <tokens>
        <token id="1" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="need" lemma="need" stem="need" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="lot" lemma="lot" stem="lot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="turnover" lemma="turnover" stem="turnov" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP We)) (VP (VBP need) (NP (ADJP (NP (DT a) (NN lot)) (JJR more)) (NN turnover))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="a lot" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="lot" />
          </tokens>
        </chunking>
        <chunking id="2" string="a lot more turnover" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="lot" />
            <token id="5" string="more" />
            <token id="6" string="turnover" />
          </tokens>
        </chunking>
        <chunking id="3" string="need a lot more turnover" type="VP">
          <tokens>
            <token id="2" string="need" />
            <token id="3" string="a" />
            <token id="4" string="lot" />
            <token id="5" string="more" />
            <token id="6" string="turnover" />
          </tokens>
        </chunking>
        <chunking id="4" string="We" type="NP">
          <tokens>
            <token id="1" string="We" />
          </tokens>
        </chunking>
        <chunking id="5" string="a lot more" type="ADJP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="lot" />
            <token id="5" string="more" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">need</governor>
          <dependent id="1">We</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">need</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">lot</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="5">more</governor>
          <dependent id="4">lot</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">turnover</governor>
          <dependent id="5">more</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">need</governor>
          <dependent id="6">turnover</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>Colorado Rep. Ben Nighthorse Campbell, the only American Indian in Congress, backed a term limit measure last year that restricted his own tenure.</content>
      <tokens>
        <token id="1" string="Colorado" lemma="Colorado" stem="colorado" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="2" string="Rep." lemma="Rep." stem="rep." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Ben" lemma="Ben" stem="ben" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="Nighthorse" lemma="Nighthorse" stem="nighthors" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="5" string="Campbell" lemma="Campbell" stem="campbel" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="only" lemma="only" stem="onli" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="American" lemma="american" stem="american" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="10" string="Indian" lemma="indian" stem="indian" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Congress" lemma="Congress" stem="congress" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="backed" lemma="back" stem="back" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="term" lemma="term" stem="term" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="limit" lemma="limit" stem="limit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="measure" lemma="measure" stem="measur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="20" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="21" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="restricted" lemma="restricted" stem="restrict" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="own" lemma="own" stem="own" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="tenure" lemma="tenure" stem="tenur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Colorado) (NNP Rep.) (NNP Ben) (NNP Nighthorse) (NNP Campbell)) (, ,) (NP (NP (DT the) (ADJP (JJ only) (JJ American)) (JJ Indian)) (PP (IN in) (NP (NNP Congress)))) (, ,)) (VP (VBD backed) (NP (DT a) (NN term) (NN limit) (NN measure)) (NP-TMP (JJ last) (NN year)) (PP (IN that) (NP (JJ restricted) (PRP$ his) (JJ own) (NN tenure)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the only American Indian in Congress" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="only" />
            <token id="9" string="American" />
            <token id="10" string="Indian" />
            <token id="11" string="in" />
            <token id="12" string="Congress" />
          </tokens>
        </chunking>
        <chunking id="2" string="a term limit measure" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="term" />
            <token id="17" string="limit" />
            <token id="18" string="measure" />
          </tokens>
        </chunking>
        <chunking id="3" string="Colorado Rep. Ben Nighthorse Campbell" type="NP">
          <tokens>
            <token id="1" string="Colorado" />
            <token id="2" string="Rep." />
            <token id="3" string="Ben" />
            <token id="4" string="Nighthorse" />
            <token id="5" string="Campbell" />
          </tokens>
        </chunking>
        <chunking id="4" string="backed a term limit measure last year that restricted his own tenure" type="VP">
          <tokens>
            <token id="14" string="backed" />
            <token id="15" string="a" />
            <token id="16" string="term" />
            <token id="17" string="limit" />
            <token id="18" string="measure" />
            <token id="19" string="last" />
            <token id="20" string="year" />
            <token id="21" string="that" />
            <token id="22" string="restricted" />
            <token id="23" string="his" />
            <token id="24" string="own" />
            <token id="25" string="tenure" />
          </tokens>
        </chunking>
        <chunking id="5" string="Colorado Rep. Ben Nighthorse Campbell , the only American Indian in Congress ," type="NP">
          <tokens>
            <token id="1" string="Colorado" />
            <token id="2" string="Rep." />
            <token id="3" string="Ben" />
            <token id="4" string="Nighthorse" />
            <token id="5" string="Campbell" />
            <token id="6" string="," />
            <token id="7" string="the" />
            <token id="8" string="only" />
            <token id="9" string="American" />
            <token id="10" string="Indian" />
            <token id="11" string="in" />
            <token id="12" string="Congress" />
            <token id="13" string="," />
          </tokens>
        </chunking>
        <chunking id="6" string="the only American Indian" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="only" />
            <token id="9" string="American" />
            <token id="10" string="Indian" />
          </tokens>
        </chunking>
        <chunking id="7" string="only American" type="ADJP">
          <tokens>
            <token id="8" string="only" />
            <token id="9" string="American" />
          </tokens>
        </chunking>
        <chunking id="8" string="restricted his own tenure" type="NP">
          <tokens>
            <token id="22" string="restricted" />
            <token id="23" string="his" />
            <token id="24" string="own" />
            <token id="25" string="tenure" />
          </tokens>
        </chunking>
        <chunking id="9" string="Congress" type="NP">
          <tokens>
            <token id="12" string="Congress" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="5">Campbell</governor>
          <dependent id="1">Colorado</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Campbell</governor>
          <dependent id="2">Rep.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Campbell</governor>
          <dependent id="3">Ben</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Campbell</governor>
          <dependent id="4">Nighthorse</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">backed</governor>
          <dependent id="5">Campbell</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">Indian</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">American</governor>
          <dependent id="8">only</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">Indian</governor>
          <dependent id="9">American</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="5">Campbell</governor>
          <dependent id="10">Indian</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Congress</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">Indian</governor>
          <dependent id="12">Congress</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">backed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">measure</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">measure</governor>
          <dependent id="16">term</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">measure</governor>
          <dependent id="17">limit</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">backed</governor>
          <dependent id="18">measure</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">year</governor>
          <dependent id="19">last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="14">backed</governor>
          <dependent id="20">year</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">tenure</governor>
          <dependent id="21">that</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">tenure</governor>
          <dependent id="22">restricted</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="25">tenure</governor>
          <dependent id="23">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">tenure</governor>
          <dependent id="24">own</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">backed</governor>
          <dependent id="25">tenure</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Colorado" type="LOCATION" score="0.0">
          <tokens>
            <token id="1" string="Colorado" />
          </tokens>
        </entity>
        <entity id="2" string="Ben Nighthorse Campbell" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Ben" />
            <token id="4" string="Nighthorse" />
            <token id="5" string="Campbell" />
          </tokens>
        </entity>
        <entity id="3" string="American Indian" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="9" string="American" />
            <token id="10" string="Indian" />
          </tokens>
        </entity>
        <entity id="4" string="last year" type="DATE" score="0.0">
          <tokens>
            <token id="19" string="last" />
            <token id="20" string="year" />
          </tokens>
        </entity>
        <entity id="5" string="Congress" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="12" string="Congress" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>Term limits for Congress have been supported by some of history&amp;apost;s most prominent Democrats.</content>
      <tokens>
        <token id="1" string="Term" lemma="term" stem="term" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="limits" lemma="limit" stem="limit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Congress" lemma="Congress" stem="congress" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="5" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="supported" lemma="support" stem="support" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="history" lemma="history" stem="histori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="most" lemma="most" stem="most" pos="RBS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="prominent" lemma="prominent" stem="promin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="Democrats" lemma="Democrats" stem="democrat" pos="NNPS" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NN Term) (NNS limits)) (PP (IN for) (NP (NNP Congress)))) (VP (VBP have) (VP (VBN been) (VP (VBN supported) (PP (IN by) (NP (NP (DT some)) (PP (IN of) (NP (NP (NN history) (POS 's)) (NP (ADJP (RBS most) (JJ prominent)) (NNPS Democrats))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Term limits" type="NP">
          <tokens>
            <token id="1" string="Term" />
            <token id="2" string="limits" />
          </tokens>
        </chunking>
        <chunking id="2" string="some of history 's most prominent Democrats" type="NP">
          <tokens>
            <token id="9" string="some" />
            <token id="10" string="of" />
            <token id="11" string="history" />
            <token id="12" string="'s" />
            <token id="13" string="most" />
            <token id="14" string="prominent" />
            <token id="15" string="Democrats" />
          </tokens>
        </chunking>
        <chunking id="3" string="supported by some of history 's most prominent Democrats" type="VP">
          <tokens>
            <token id="7" string="supported" />
            <token id="8" string="by" />
            <token id="9" string="some" />
            <token id="10" string="of" />
            <token id="11" string="history" />
            <token id="12" string="'s" />
            <token id="13" string="most" />
            <token id="14" string="prominent" />
            <token id="15" string="Democrats" />
          </tokens>
        </chunking>
        <chunking id="4" string="been supported by some of history 's most prominent Democrats" type="VP">
          <tokens>
            <token id="6" string="been" />
            <token id="7" string="supported" />
            <token id="8" string="by" />
            <token id="9" string="some" />
            <token id="10" string="of" />
            <token id="11" string="history" />
            <token id="12" string="'s" />
            <token id="13" string="most" />
            <token id="14" string="prominent" />
            <token id="15" string="Democrats" />
          </tokens>
        </chunking>
        <chunking id="5" string="some" type="NP">
          <tokens>
            <token id="9" string="some" />
          </tokens>
        </chunking>
        <chunking id="6" string="Term limits for Congress" type="NP">
          <tokens>
            <token id="1" string="Term" />
            <token id="2" string="limits" />
            <token id="3" string="for" />
            <token id="4" string="Congress" />
          </tokens>
        </chunking>
        <chunking id="7" string="most prominent" type="ADJP">
          <tokens>
            <token id="13" string="most" />
            <token id="14" string="prominent" />
          </tokens>
        </chunking>
        <chunking id="8" string="have been supported by some of history 's most prominent Democrats" type="VP">
          <tokens>
            <token id="5" string="have" />
            <token id="6" string="been" />
            <token id="7" string="supported" />
            <token id="8" string="by" />
            <token id="9" string="some" />
            <token id="10" string="of" />
            <token id="11" string="history" />
            <token id="12" string="'s" />
            <token id="13" string="most" />
            <token id="14" string="prominent" />
            <token id="15" string="Democrats" />
          </tokens>
        </chunking>
        <chunking id="9" string="most prominent Democrats" type="NP">
          <tokens>
            <token id="13" string="most" />
            <token id="14" string="prominent" />
            <token id="15" string="Democrats" />
          </tokens>
        </chunking>
        <chunking id="10" string="history 's" type="NP">
          <tokens>
            <token id="11" string="history" />
            <token id="12" string="'s" />
          </tokens>
        </chunking>
        <chunking id="11" string="Congress" type="NP">
          <tokens>
            <token id="4" string="Congress" />
          </tokens>
        </chunking>
        <chunking id="12" string="history 's most prominent Democrats" type="NP">
          <tokens>
            <token id="11" string="history" />
            <token id="12" string="'s" />
            <token id="13" string="most" />
            <token id="14" string="prominent" />
            <token id="15" string="Democrats" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">limits</governor>
          <dependent id="1">Term</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="7">supported</governor>
          <dependent id="2">limits</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">Congress</governor>
          <dependent id="3">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">limits</governor>
          <dependent id="4">Congress</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">supported</governor>
          <dependent id="5">have</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="7">supported</governor>
          <dependent id="6">been</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">supported</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">some</governor>
          <dependent id="8">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">supported</governor>
          <dependent id="9">some</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">history</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">some</governor>
          <dependent id="11">history</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">history</governor>
          <dependent id="12">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">prominent</governor>
          <dependent id="13">most</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">Democrats</governor>
          <dependent id="14">prominent</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="11">history</governor>
          <dependent id="15">Democrats</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Democrats" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="15" string="Democrats" />
          </tokens>
        </entity>
        <entity id="2" string="Congress" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="4" string="Congress" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="false">
      <content>Harry Truman and John F. Kennedy both endorsed the idea while they were president.</content>
      <tokens>
        <token id="1" string="Harry" lemma="Harry" stem="harri" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Truman" lemma="Truman" stem="truman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="5" string="F." lemma="F." stem="f." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string="Kennedy" lemma="Kennedy" stem="kennedi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="7" string="both" lemma="both" stem="both" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="endorsed" lemma="endorse" stem="endors" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="idea" lemma="idea" stem="idea" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="while" lemma="while" stem="while" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="president" lemma="president" stem="presid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Harry) (NNP Truman)) (CC and) (NP (NNP John) (NNP F.) (NNP Kennedy))) (ADVP (CC both)) (VP (VBD endorsed) (NP (DT the) (NN idea)) (SBAR (IN while) (S (NP (PRP they)) (VP (VBD were) (NP (NN president)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="president" type="NP">
          <tokens>
            <token id="14" string="president" />
          </tokens>
        </chunking>
        <chunking id="2" string="they" type="NP">
          <tokens>
            <token id="12" string="they" />
          </tokens>
        </chunking>
        <chunking id="3" string="Harry Truman" type="NP">
          <tokens>
            <token id="1" string="Harry" />
            <token id="2" string="Truman" />
          </tokens>
        </chunking>
        <chunking id="4" string="the idea" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="idea" />
          </tokens>
        </chunking>
        <chunking id="5" string="endorsed the idea while they were president" type="VP">
          <tokens>
            <token id="8" string="endorsed" />
            <token id="9" string="the" />
            <token id="10" string="idea" />
            <token id="11" string="while" />
            <token id="12" string="they" />
            <token id="13" string="were" />
            <token id="14" string="president" />
          </tokens>
        </chunking>
        <chunking id="6" string="John F. Kennedy" type="NP">
          <tokens>
            <token id="4" string="John" />
            <token id="5" string="F." />
            <token id="6" string="Kennedy" />
          </tokens>
        </chunking>
        <chunking id="7" string="were president" type="VP">
          <tokens>
            <token id="13" string="were" />
            <token id="14" string="president" />
          </tokens>
        </chunking>
        <chunking id="8" string="Harry Truman and John F. Kennedy" type="NP">
          <tokens>
            <token id="1" string="Harry" />
            <token id="2" string="Truman" />
            <token id="3" string="and" />
            <token id="4" string="John" />
            <token id="5" string="F." />
            <token id="6" string="Kennedy" />
          </tokens>
        </chunking>
        <chunking id="9" string="while they were president" type="SBAR">
          <tokens>
            <token id="11" string="while" />
            <token id="12" string="they" />
            <token id="13" string="were" />
            <token id="14" string="president" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Truman</governor>
          <dependent id="1">Harry</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">endorsed</governor>
          <dependent id="2">Truman</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">Truman</governor>
          <dependent id="3">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Kennedy</governor>
          <dependent id="4">John</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Kennedy</governor>
          <dependent id="5">F.</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">Truman</governor>
          <dependent id="6">Kennedy</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">endorsed</governor>
          <dependent id="7">both</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">endorsed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">idea</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">endorsed</governor>
          <dependent id="10">idea</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">president</governor>
          <dependent id="11">while</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">president</governor>
          <dependent id="12">they</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">president</governor>
          <dependent id="13">were</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="8">endorsed</governor>
          <dependent id="14">president</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Harry Truman" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Harry" />
            <token id="2" string="Truman" />
          </tokens>
        </entity>
        <entity id="2" string="John F. Kennedy" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="John" />
            <token id="5" string="F." />
            <token id="6" string="Kennedy" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>Today, former California Governor Jerry Brown says advocacy of term limits is a key element in his populist presidential campaign against a &amp;quot;constipated&amp;quot; political system.</content>
      <tokens>
        <token id="1" string="Today" lemma="today" stem="todai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="former" lemma="former" stem="former" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="California" lemma="California" stem="california" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="5" string="Governor" lemma="Governor" stem="governor" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="true" is_refers="false" />
        <token id="6" string="Jerry" lemma="Jerry" stem="jerri" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="7" string="Brown" lemma="Brown" stem="brown" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="8" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="advocacy" lemma="advocacy" stem="advocaci" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="term" lemma="term" stem="term" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="limits" lemma="limit" stem="limit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="key" lemma="key" stem="kei" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="element" lemma="element" stem="element" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="populist" lemma="populist" stem="populist" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="true" is_refers="false" />
        <token id="20" string="presidential" lemma="presidential" stem="presidenti" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="campaign" lemma="campaign" stem="campaign" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="constipated" lemma="constipate" stem="constip" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="27" string="political" lemma="political" stem="polit" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="28" string="system" lemma="system" stem="system" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP-TMP (NN Today)) (, ,) (NP (JJ former) (NNP California) (NNP Governor) (NNP Jerry) (NNP Brown)) (VP (VBZ says) (SBAR (S (NP (NP (NN advocacy)) (PP (IN of) (NP (NN term) (NNS limits)))) (VP (VBZ is) (NP (NP (DT a) (JJ key) (NN element)) (PP (IN in) (NP (NP (PRP$ his) (JJ populist) (JJ presidential) (NN campaign)) (PP (IN against) (NP (NP (DT a)) (`` ``) (VP (VBN constipated) ('' '') (NP (JJ political) (NN system)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a" type="NP">
          <tokens>
            <token id="23" string="a" />
          </tokens>
        </chunking>
        <chunking id="2" string="advocacy" type="NP">
          <tokens>
            <token id="9" string="advocacy" />
          </tokens>
        </chunking>
        <chunking id="3" string="term limits" type="NP">
          <tokens>
            <token id="11" string="term" />
            <token id="12" string="limits" />
          </tokens>
        </chunking>
        <chunking id="4" string="a `` constipated '' political system" type="NP">
          <tokens>
            <token id="23" string="a" />
            <token id="24" string="&quot;" />
            <token id="25" string="constipated" />
            <token id="26" string="&quot;" />
            <token id="27" string="political" />
            <token id="28" string="system" />
          </tokens>
        </chunking>
        <chunking id="5" string="his populist presidential campaign against a `` constipated '' political system" type="NP">
          <tokens>
            <token id="18" string="his" />
            <token id="19" string="populist" />
            <token id="20" string="presidential" />
            <token id="21" string="campaign" />
            <token id="22" string="against" />
            <token id="23" string="a" />
            <token id="24" string="&quot;" />
            <token id="25" string="constipated" />
            <token id="26" string="&quot;" />
            <token id="27" string="political" />
            <token id="28" string="system" />
          </tokens>
        </chunking>
        <chunking id="6" string="a key element" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="key" />
            <token id="16" string="element" />
          </tokens>
        </chunking>
        <chunking id="7" string="constipated '' political system" type="VP">
          <tokens>
            <token id="25" string="constipated" />
            <token id="26" string="&quot;" />
            <token id="27" string="political" />
            <token id="28" string="system" />
          </tokens>
        </chunking>
        <chunking id="8" string="former California Governor Jerry Brown" type="NP">
          <tokens>
            <token id="3" string="former" />
            <token id="4" string="California" />
            <token id="5" string="Governor" />
            <token id="6" string="Jerry" />
            <token id="7" string="Brown" />
          </tokens>
        </chunking>
        <chunking id="9" string="a key element in his populist presidential campaign against a `` constipated '' political system" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="key" />
            <token id="16" string="element" />
            <token id="17" string="in" />
            <token id="18" string="his" />
            <token id="19" string="populist" />
            <token id="20" string="presidential" />
            <token id="21" string="campaign" />
            <token id="22" string="against" />
            <token id="23" string="a" />
            <token id="24" string="&quot;" />
            <token id="25" string="constipated" />
            <token id="26" string="&quot;" />
            <token id="27" string="political" />
            <token id="28" string="system" />
          </tokens>
        </chunking>
        <chunking id="10" string="advocacy of term limits" type="NP">
          <tokens>
            <token id="9" string="advocacy" />
            <token id="10" string="of" />
            <token id="11" string="term" />
            <token id="12" string="limits" />
          </tokens>
        </chunking>
        <chunking id="11" string="political system" type="NP">
          <tokens>
            <token id="27" string="political" />
            <token id="28" string="system" />
          </tokens>
        </chunking>
        <chunking id="12" string="says advocacy of term limits is a key element in his populist presidential campaign against a `` constipated '' political system" type="VP">
          <tokens>
            <token id="8" string="says" />
            <token id="9" string="advocacy" />
            <token id="10" string="of" />
            <token id="11" string="term" />
            <token id="12" string="limits" />
            <token id="13" string="is" />
            <token id="14" string="a" />
            <token id="15" string="key" />
            <token id="16" string="element" />
            <token id="17" string="in" />
            <token id="18" string="his" />
            <token id="19" string="populist" />
            <token id="20" string="presidential" />
            <token id="21" string="campaign" />
            <token id="22" string="against" />
            <token id="23" string="a" />
            <token id="24" string="&quot;" />
            <token id="25" string="constipated" />
            <token id="26" string="&quot;" />
            <token id="27" string="political" />
            <token id="28" string="system" />
          </tokens>
        </chunking>
        <chunking id="13" string="his populist presidential campaign" type="NP">
          <tokens>
            <token id="18" string="his" />
            <token id="19" string="populist" />
            <token id="20" string="presidential" />
            <token id="21" string="campaign" />
          </tokens>
        </chunking>
        <chunking id="14" string="is a key element in his populist presidential campaign against a `` constipated '' political system" type="VP">
          <tokens>
            <token id="13" string="is" />
            <token id="14" string="a" />
            <token id="15" string="key" />
            <token id="16" string="element" />
            <token id="17" string="in" />
            <token id="18" string="his" />
            <token id="19" string="populist" />
            <token id="20" string="presidential" />
            <token id="21" string="campaign" />
            <token id="22" string="against" />
            <token id="23" string="a" />
            <token id="24" string="&quot;" />
            <token id="25" string="constipated" />
            <token id="26" string="&quot;" />
            <token id="27" string="political" />
            <token id="28" string="system" />
          </tokens>
        </chunking>
        <chunking id="15" string="advocacy of term limits is a key element in his populist presidential campaign against a `` constipated '' political system" type="SBAR">
          <tokens>
            <token id="9" string="advocacy" />
            <token id="10" string="of" />
            <token id="11" string="term" />
            <token id="12" string="limits" />
            <token id="13" string="is" />
            <token id="14" string="a" />
            <token id="15" string="key" />
            <token id="16" string="element" />
            <token id="17" string="in" />
            <token id="18" string="his" />
            <token id="19" string="populist" />
            <token id="20" string="presidential" />
            <token id="21" string="campaign" />
            <token id="22" string="against" />
            <token id="23" string="a" />
            <token id="24" string="&quot;" />
            <token id="25" string="constipated" />
            <token id="26" string="&quot;" />
            <token id="27" string="political" />
            <token id="28" string="system" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:tmod">
          <governor id="8">says</governor>
          <dependent id="1">Today</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">Brown</governor>
          <dependent id="3">former</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Brown</governor>
          <dependent id="4">California</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Brown</governor>
          <dependent id="5">Governor</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Brown</governor>
          <dependent id="6">Jerry</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">says</governor>
          <dependent id="7">Brown</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">says</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">element</governor>
          <dependent id="9">advocacy</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">limits</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">limits</governor>
          <dependent id="11">term</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">advocacy</governor>
          <dependent id="12">limits</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="16">element</governor>
          <dependent id="13">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">element</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">element</governor>
          <dependent id="15">key</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">says</governor>
          <dependent id="16">element</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">campaign</governor>
          <dependent id="17">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="21">campaign</governor>
          <dependent id="18">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">campaign</governor>
          <dependent id="19">populist</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">campaign</governor>
          <dependent id="20">presidential</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">element</governor>
          <dependent id="21">campaign</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">a</governor>
          <dependent id="22">against</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">campaign</governor>
          <dependent id="23">a</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="23">a</governor>
          <dependent id="25">constipated</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">system</governor>
          <dependent id="27">political</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">constipated</governor>
          <dependent id="28">system</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Governor" type="TITLE" score="0.0">
          <tokens>
            <token id="5" string="Governor" />
          </tokens>
        </entity>
        <entity id="2" string="Today" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="Today" />
          </tokens>
        </entity>
        <entity id="3" string="California" type="LOCATION" score="0.0">
          <tokens>
            <token id="4" string="California" />
          </tokens>
        </entity>
        <entity id="4" string="populist" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="19" string="populist" />
          </tokens>
        </entity>
        <entity id="5" string="Jerry Brown" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Jerry" />
            <token id="7" string="Brown" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>&amp;quot;Term limits are a castor oil that democracy needs to take,&amp;quot; he says.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Term" lemma="term" stem="term" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="limits" lemma="limit" stem="limit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="castor" lemma="castor" stem="castor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="oil" lemma="oil" stem="oil" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="democracy" lemma="democracy" stem="democraci" pos="NN" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="10" string="needs" lemma="need" stem="need" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="take" lemma="take" stem="take" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (NN Term) (NNS limits)) (VP (VBP are) (NP (NP (DT a) (NN castor) (NN oil)) (SBAR (WHNP (WDT that)) (S (NP (NN democracy)) (VP (VBZ needs) (S (VP (TO to) (VP (VB take)))))))))) (, ,) ('' '') (NP (PRP he)) (VP (VBZ says)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Term limits" type="NP">
          <tokens>
            <token id="2" string="Term" />
            <token id="3" string="limits" />
          </tokens>
        </chunking>
        <chunking id="2" string="take" type="VP">
          <tokens>
            <token id="12" string="take" />
          </tokens>
        </chunking>
        <chunking id="3" string="a castor oil that democracy needs to take" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="castor" />
            <token id="7" string="oil" />
            <token id="8" string="that" />
            <token id="9" string="democracy" />
            <token id="10" string="needs" />
            <token id="11" string="to" />
            <token id="12" string="take" />
          </tokens>
        </chunking>
        <chunking id="4" string="says" type="VP">
          <tokens>
            <token id="16" string="says" />
          </tokens>
        </chunking>
        <chunking id="5" string="a castor oil" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="castor" />
            <token id="7" string="oil" />
          </tokens>
        </chunking>
        <chunking id="6" string="that democracy needs to take" type="SBAR">
          <tokens>
            <token id="8" string="that" />
            <token id="9" string="democracy" />
            <token id="10" string="needs" />
            <token id="11" string="to" />
            <token id="12" string="take" />
          </tokens>
        </chunking>
        <chunking id="7" string="he" type="NP">
          <tokens>
            <token id="15" string="he" />
          </tokens>
        </chunking>
        <chunking id="8" string="are a castor oil that democracy needs to take" type="VP">
          <tokens>
            <token id="4" string="are" />
            <token id="5" string="a" />
            <token id="6" string="castor" />
            <token id="7" string="oil" />
            <token id="8" string="that" />
            <token id="9" string="democracy" />
            <token id="10" string="needs" />
            <token id="11" string="to" />
            <token id="12" string="take" />
          </tokens>
        </chunking>
        <chunking id="9" string="to take" type="VP">
          <tokens>
            <token id="11" string="to" />
            <token id="12" string="take" />
          </tokens>
        </chunking>
        <chunking id="10" string="democracy" type="NP">
          <tokens>
            <token id="9" string="democracy" />
          </tokens>
        </chunking>
        <chunking id="11" string="needs to take" type="VP">
          <tokens>
            <token id="10" string="needs" />
            <token id="11" string="to" />
            <token id="12" string="take" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">limits</governor>
          <dependent id="2">Term</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">oil</governor>
          <dependent id="3">limits</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">oil</governor>
          <dependent id="4">are</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">oil</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">oil</governor>
          <dependent id="6">castor</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">says</governor>
          <dependent id="7">oil</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">needs</governor>
          <dependent id="8">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">needs</governor>
          <dependent id="9">democracy</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="7">oil</governor>
          <dependent id="10">needs</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">take</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="10">needs</governor>
          <dependent id="12">take</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">says</governor>
          <dependent id="15">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">says</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="democracy" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="9" string="democracy" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>Last year, as head of the California Democratic Party he refused to sign a party slate mailer against term limits.</content>
      <tokens>
        <token id="1" string="Last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="2" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="head" lemma="head" stem="head" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="California" lemma="California" stem="california" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="9" string="Democratic" lemma="Democratic" stem="democrat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="10" string="Party" lemma="Party" stem="parti" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="11" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="refused" lemma="refuse" stem="refus" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="sign" lemma="sign" stem="sign" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="party" lemma="party" stem="parti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="slate" lemma="slate" stem="slate" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="mailer" lemma="mailer" stem="mailer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="term" lemma="term" stem="term" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="limits" lemma="limit" stem="limit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP-TMP (JJ Last) (NN year)) (, ,) (PP (IN as) (NP (NP (NN head)) (PP (IN of) (NP (DT the) (NNP California) (NNP Democratic) (NNP Party))))) (NP (PRP he)) (VP (VBD refused) (S (VP (TO to) (VP (VB sign) (NP (DT a) (NN party) (NN slate) (NN mailer)) (PP (IN against) (NP (NN term) (NNS limits))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="refused to sign a party slate mailer against term limits" type="VP">
          <tokens>
            <token id="12" string="refused" />
            <token id="13" string="to" />
            <token id="14" string="sign" />
            <token id="15" string="a" />
            <token id="16" string="party" />
            <token id="17" string="slate" />
            <token id="18" string="mailer" />
            <token id="19" string="against" />
            <token id="20" string="term" />
            <token id="21" string="limits" />
          </tokens>
        </chunking>
        <chunking id="2" string="the California Democratic Party" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="California" />
            <token id="9" string="Democratic" />
            <token id="10" string="Party" />
          </tokens>
        </chunking>
        <chunking id="3" string="to sign a party slate mailer against term limits" type="VP">
          <tokens>
            <token id="13" string="to" />
            <token id="14" string="sign" />
            <token id="15" string="a" />
            <token id="16" string="party" />
            <token id="17" string="slate" />
            <token id="18" string="mailer" />
            <token id="19" string="against" />
            <token id="20" string="term" />
            <token id="21" string="limits" />
          </tokens>
        </chunking>
        <chunking id="4" string="a party slate mailer" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="party" />
            <token id="17" string="slate" />
            <token id="18" string="mailer" />
          </tokens>
        </chunking>
        <chunking id="5" string="term limits" type="NP">
          <tokens>
            <token id="20" string="term" />
            <token id="21" string="limits" />
          </tokens>
        </chunking>
        <chunking id="6" string="he" type="NP">
          <tokens>
            <token id="11" string="he" />
          </tokens>
        </chunking>
        <chunking id="7" string="head of the California Democratic Party" type="NP">
          <tokens>
            <token id="5" string="head" />
            <token id="6" string="of" />
            <token id="7" string="the" />
            <token id="8" string="California" />
            <token id="9" string="Democratic" />
            <token id="10" string="Party" />
          </tokens>
        </chunking>
        <chunking id="8" string="sign a party slate mailer against term limits" type="VP">
          <tokens>
            <token id="14" string="sign" />
            <token id="15" string="a" />
            <token id="16" string="party" />
            <token id="17" string="slate" />
            <token id="18" string="mailer" />
            <token id="19" string="against" />
            <token id="20" string="term" />
            <token id="21" string="limits" />
          </tokens>
        </chunking>
        <chunking id="9" string="head" type="NP">
          <tokens>
            <token id="5" string="head" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">year</governor>
          <dependent id="1">Last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="12">refused</governor>
          <dependent id="2">year</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">head</governor>
          <dependent id="4">as</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">refused</governor>
          <dependent id="5">head</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Party</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">Party</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Party</governor>
          <dependent id="8">California</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Party</governor>
          <dependent id="9">Democratic</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">head</governor>
          <dependent id="10">Party</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">refused</governor>
          <dependent id="11">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">refused</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">sign</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="12">refused</governor>
          <dependent id="14">sign</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">mailer</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">mailer</governor>
          <dependent id="16">party</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">mailer</governor>
          <dependent id="17">slate</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">sign</governor>
          <dependent id="18">mailer</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">limits</governor>
          <dependent id="19">against</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">limits</governor>
          <dependent id="20">term</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">sign</governor>
          <dependent id="21">limits</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Last year" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="Last" />
            <token id="2" string="year" />
          </tokens>
        </entity>
        <entity id="2" string="California Democratic Party" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="8" string="California" />
            <token id="9" string="Democratic" />
            <token id="10" string="Party" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>&amp;quot;I saw incumbents spend their time fund-raising and worrying about how to stay in office.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="saw" lemma="see" stem="saw" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="incumbents" lemma="incumbent" stem="incumb" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="spend" lemma="spend" stem="spend" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="7" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="fund-raising" lemma="fund-raising" stem="fund-rais" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="worrying" lemma="worry" stem="worri" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="how" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="stay" lemma="stay" stem="stai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="office" lemma="office" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP I)) (VP (VBD saw) (S (NP (NNS incumbents)) (VP (VB spend) (NP (PRP$ their) (NN time) (NN fund-raising)))))) (CC and) (S (VP (VBG worrying) (PP (IN about) (SBAR (WHADVP (WRB how)) (S (VP (TO to) (VP (VB stay) (PP (IN in) (NP (NN office)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="worrying about how to stay in office" type="VP">
          <tokens>
            <token id="10" string="worrying" />
            <token id="11" string="about" />
            <token id="12" string="how" />
            <token id="13" string="to" />
            <token id="14" string="stay" />
            <token id="15" string="in" />
            <token id="16" string="office" />
          </tokens>
        </chunking>
        <chunking id="2" string="saw incumbents spend their time fund-raising" type="VP">
          <tokens>
            <token id="3" string="saw" />
            <token id="4" string="incumbents" />
            <token id="5" string="spend" />
            <token id="6" string="their" />
            <token id="7" string="time" />
            <token id="8" string="fund-raising" />
          </tokens>
        </chunking>
        <chunking id="3" string="stay in office" type="VP">
          <tokens>
            <token id="14" string="stay" />
            <token id="15" string="in" />
            <token id="16" string="office" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="how to stay in office" type="SBAR">
          <tokens>
            <token id="12" string="how" />
            <token id="13" string="to" />
            <token id="14" string="stay" />
            <token id="15" string="in" />
            <token id="16" string="office" />
          </tokens>
        </chunking>
        <chunking id="6" string="to stay in office" type="VP">
          <tokens>
            <token id="13" string="to" />
            <token id="14" string="stay" />
            <token id="15" string="in" />
            <token id="16" string="office" />
          </tokens>
        </chunking>
        <chunking id="7" string="incumbents" type="NP">
          <tokens>
            <token id="4" string="incumbents" />
          </tokens>
        </chunking>
        <chunking id="8" string="spend their time fund-raising" type="VP">
          <tokens>
            <token id="5" string="spend" />
            <token id="6" string="their" />
            <token id="7" string="time" />
            <token id="8" string="fund-raising" />
          </tokens>
        </chunking>
        <chunking id="9" string="office" type="NP">
          <tokens>
            <token id="16" string="office" />
          </tokens>
        </chunking>
        <chunking id="10" string="their time fund-raising" type="NP">
          <tokens>
            <token id="6" string="their" />
            <token id="7" string="time" />
            <token id="8" string="fund-raising" />
          </tokens>
        </chunking>
        <chunking id="11" string="how" type="WHADVP">
          <tokens>
            <token id="12" string="how" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">saw</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">saw</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">spend</governor>
          <dependent id="4">incumbents</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">saw</governor>
          <dependent id="5">spend</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">fund-raising</governor>
          <dependent id="6">their</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">fund-raising</governor>
          <dependent id="7">time</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">spend</governor>
          <dependent id="8">fund-raising</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">saw</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">saw</governor>
          <dependent id="10">worrying</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">stay</governor>
          <dependent id="11">about</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">stay</governor>
          <dependent id="12">how</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">stay</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="10">worrying</governor>
          <dependent id="14">stay</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">office</governor>
          <dependent id="15">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">stay</governor>
          <dependent id="16">office</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>It&amp;apost;s time more candidates thought of politics as a calling instead of a career.&amp;quot;</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="candidates" lemma="candidate" stem="candid" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="thought" lemma="think" stem="thought" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="politics" lemma="politics" stem="polit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="calling" lemma="call" stem="call" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="instead" lemma="instead" stem="instead" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="career" lemma="career" stem="career" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBZ 's) (NP (NN time)) (ADVP (RBR more)) (SBAR (S (NP (NNS candidates)) (VP (VBD thought) (PP (IN of) (NP (NNS politics))) (S (VP (ADVP (IN as) (DT a)) (VBG calling) (ADVP (RB instead)) (PP (IN of) (NP (DT a) (NN career))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="politics" type="NP">
          <tokens>
            <token id="8" string="politics" />
          </tokens>
        </chunking>
        <chunking id="2" string="as a calling instead of a career" type="VP">
          <tokens>
            <token id="9" string="as" />
            <token id="10" string="a" />
            <token id="11" string="calling" />
            <token id="12" string="instead" />
            <token id="13" string="of" />
            <token id="14" string="a" />
            <token id="15" string="career" />
          </tokens>
        </chunking>
        <chunking id="3" string="thought of politics as a calling instead of a career" type="VP">
          <tokens>
            <token id="6" string="thought" />
            <token id="7" string="of" />
            <token id="8" string="politics" />
            <token id="9" string="as" />
            <token id="10" string="a" />
            <token id="11" string="calling" />
            <token id="12" string="instead" />
            <token id="13" string="of" />
            <token id="14" string="a" />
            <token id="15" string="career" />
          </tokens>
        </chunking>
        <chunking id="4" string="a career" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="career" />
          </tokens>
        </chunking>
        <chunking id="5" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="6" string="time" type="NP">
          <tokens>
            <token id="3" string="time" />
          </tokens>
        </chunking>
        <chunking id="7" string="'s time more candidates thought of politics as a calling instead of a career" type="VP">
          <tokens>
            <token id="2" string="'s" />
            <token id="3" string="time" />
            <token id="4" string="more" />
            <token id="5" string="candidates" />
            <token id="6" string="thought" />
            <token id="7" string="of" />
            <token id="8" string="politics" />
            <token id="9" string="as" />
            <token id="10" string="a" />
            <token id="11" string="calling" />
            <token id="12" string="instead" />
            <token id="13" string="of" />
            <token id="14" string="a" />
            <token id="15" string="career" />
          </tokens>
        </chunking>
        <chunking id="8" string="candidates thought of politics as a calling instead of a career" type="SBAR">
          <tokens>
            <token id="5" string="candidates" />
            <token id="6" string="thought" />
            <token id="7" string="of" />
            <token id="8" string="politics" />
            <token id="9" string="as" />
            <token id="10" string="a" />
            <token id="11" string="calling" />
            <token id="12" string="instead" />
            <token id="13" string="of" />
            <token id="14" string="a" />
            <token id="15" string="career" />
          </tokens>
        </chunking>
        <chunking id="9" string="candidates" type="NP">
          <tokens>
            <token id="5" string="candidates" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">time</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="3">time</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">time</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">time</governor>
          <dependent id="4">more</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">thought</governor>
          <dependent id="5">candidates</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="3">time</governor>
          <dependent id="6">thought</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">politics</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">thought</governor>
          <dependent id="8">politics</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">a</governor>
          <dependent id="9">as</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">calling</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">thought</governor>
          <dependent id="11">calling</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">calling</governor>
          <dependent id="12">instead</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">career</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">career</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">calling</governor>
          <dependent id="15">career</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>Mr. Brown says arguments that legislative staff and the unelected bureaucracy would gain power under term limits are simply proof that &amp;quot;we must curb the excessive power of those political players as well.&amp;quot;</content>
      <tokens>
        <token id="1" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="Brown" lemma="Brown" stem="brown" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="arguments" lemma="argument" stem="argument" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="legislative" lemma="legislative" stem="legisl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="staff" lemma="staff" stem="staff" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="unelected" lemma="unelected" stem="unelect" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="bureaucracy" lemma="bureaucracy" stem="bureaucraci" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="gain" lemma="gain" stem="gain" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="power" lemma="power" stem="power" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="under" lemma="under" stem="under" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="term" lemma="term" stem="term" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="limits" lemma="limit" stem="limit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="simply" lemma="simply" stem="simpli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="proof" lemma="proof" stem="proof" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="must" lemma="must" stem="must" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="curb" lemma="curb" stem="curb" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="excessive" lemma="excessive" stem="excess" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="power" lemma="power" stem="power" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="political" lemma="political" stem="polit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="players" lemma="player" stem="player" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="as" lemma="as" stem="a" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="well" lemma="well" stem="well" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Mr.) (NNP Brown)) (VP (VBZ says) (SBAR (S (NP (NP (NNS arguments)) (SBAR (WHNP (WDT that)) (S (NP (NP (JJ legislative) (NN staff)) (CC and) (NP (DT the) (JJ unelected) (NN bureaucracy))) (VP (MD would) (VP (VB gain) (NP (NN power)) (PP (IN under) (NP (NN term) (NNS limits)))))))) (VP (VBP are) (ADVP (RB simply)) (NP (NN proof)) (SBAR (IN that) (`` ``) (S (NP (PRP we)) (VP (MD must) (VP (VB curb) (NP (NP (DT the) (JJ excessive) (NN power)) (PP (IN of) (NP (DT those) (JJ political) (NNS players)))) (ADVP (RB as) (RB well)))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="arguments that legislative staff and the unelected bureaucracy would gain power under term limits are simply proof that `` we must curb the excessive power of those political players as well" type="SBAR">
          <tokens>
            <token id="4" string="arguments" />
            <token id="5" string="that" />
            <token id="6" string="legislative" />
            <token id="7" string="staff" />
            <token id="8" string="and" />
            <token id="9" string="the" />
            <token id="10" string="unelected" />
            <token id="11" string="bureaucracy" />
            <token id="12" string="would" />
            <token id="13" string="gain" />
            <token id="14" string="power" />
            <token id="15" string="under" />
            <token id="16" string="term" />
            <token id="17" string="limits" />
            <token id="18" string="are" />
            <token id="19" string="simply" />
            <token id="20" string="proof" />
            <token id="21" string="that" />
            <token id="22" string="&quot;" />
            <token id="23" string="we" />
            <token id="24" string="must" />
            <token id="25" string="curb" />
            <token id="26" string="the" />
            <token id="27" string="excessive" />
            <token id="28" string="power" />
            <token id="29" string="of" />
            <token id="30" string="those" />
            <token id="31" string="political" />
            <token id="32" string="players" />
            <token id="33" string="as" />
            <token id="34" string="well" />
          </tokens>
        </chunking>
        <chunking id="2" string="those political players" type="NP">
          <tokens>
            <token id="30" string="those" />
            <token id="31" string="political" />
            <token id="32" string="players" />
          </tokens>
        </chunking>
        <chunking id="3" string="that legislative staff and the unelected bureaucracy would gain power under term limits" type="SBAR">
          <tokens>
            <token id="5" string="that" />
            <token id="6" string="legislative" />
            <token id="7" string="staff" />
            <token id="8" string="and" />
            <token id="9" string="the" />
            <token id="10" string="unelected" />
            <token id="11" string="bureaucracy" />
            <token id="12" string="would" />
            <token id="13" string="gain" />
            <token id="14" string="power" />
            <token id="15" string="under" />
            <token id="16" string="term" />
            <token id="17" string="limits" />
          </tokens>
        </chunking>
        <chunking id="4" string="legislative staff and the unelected bureaucracy" type="NP">
          <tokens>
            <token id="6" string="legislative" />
            <token id="7" string="staff" />
            <token id="8" string="and" />
            <token id="9" string="the" />
            <token id="10" string="unelected" />
            <token id="11" string="bureaucracy" />
          </tokens>
        </chunking>
        <chunking id="5" string="are simply proof that `` we must curb the excessive power of those political players as well" type="VP">
          <tokens>
            <token id="18" string="are" />
            <token id="19" string="simply" />
            <token id="20" string="proof" />
            <token id="21" string="that" />
            <token id="22" string="&quot;" />
            <token id="23" string="we" />
            <token id="24" string="must" />
            <token id="25" string="curb" />
            <token id="26" string="the" />
            <token id="27" string="excessive" />
            <token id="28" string="power" />
            <token id="29" string="of" />
            <token id="30" string="those" />
            <token id="31" string="political" />
            <token id="32" string="players" />
            <token id="33" string="as" />
            <token id="34" string="well" />
          </tokens>
        </chunking>
        <chunking id="6" string="that `` we must curb the excessive power of those political players as well" type="SBAR">
          <tokens>
            <token id="21" string="that" />
            <token id="22" string="&quot;" />
            <token id="23" string="we" />
            <token id="24" string="must" />
            <token id="25" string="curb" />
            <token id="26" string="the" />
            <token id="27" string="excessive" />
            <token id="28" string="power" />
            <token id="29" string="of" />
            <token id="30" string="those" />
            <token id="31" string="political" />
            <token id="32" string="players" />
            <token id="33" string="as" />
            <token id="34" string="well" />
          </tokens>
        </chunking>
        <chunking id="7" string="would gain power under term limits" type="VP">
          <tokens>
            <token id="12" string="would" />
            <token id="13" string="gain" />
            <token id="14" string="power" />
            <token id="15" string="under" />
            <token id="16" string="term" />
            <token id="17" string="limits" />
          </tokens>
        </chunking>
        <chunking id="8" string="the unelected bureaucracy" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="unelected" />
            <token id="11" string="bureaucracy" />
          </tokens>
        </chunking>
        <chunking id="9" string="term limits" type="NP">
          <tokens>
            <token id="16" string="term" />
            <token id="17" string="limits" />
          </tokens>
        </chunking>
        <chunking id="10" string="we" type="NP">
          <tokens>
            <token id="23" string="we" />
          </tokens>
        </chunking>
        <chunking id="11" string="Mr. Brown" type="NP">
          <tokens>
            <token id="1" string="Mr." />
            <token id="2" string="Brown" />
          </tokens>
        </chunking>
        <chunking id="12" string="says arguments that legislative staff and the unelected bureaucracy would gain power under term limits are simply proof that `` we must curb the excessive power of those political players as well" type="VP">
          <tokens>
            <token id="3" string="says" />
            <token id="4" string="arguments" />
            <token id="5" string="that" />
            <token id="6" string="legislative" />
            <token id="7" string="staff" />
            <token id="8" string="and" />
            <token id="9" string="the" />
            <token id="10" string="unelected" />
            <token id="11" string="bureaucracy" />
            <token id="12" string="would" />
            <token id="13" string="gain" />
            <token id="14" string="power" />
            <token id="15" string="under" />
            <token id="16" string="term" />
            <token id="17" string="limits" />
            <token id="18" string="are" />
            <token id="19" string="simply" />
            <token id="20" string="proof" />
            <token id="21" string="that" />
            <token id="22" string="&quot;" />
            <token id="23" string="we" />
            <token id="24" string="must" />
            <token id="25" string="curb" />
            <token id="26" string="the" />
            <token id="27" string="excessive" />
            <token id="28" string="power" />
            <token id="29" string="of" />
            <token id="30" string="those" />
            <token id="31" string="political" />
            <token id="32" string="players" />
            <token id="33" string="as" />
            <token id="34" string="well" />
          </tokens>
        </chunking>
        <chunking id="13" string="arguments that legislative staff and the unelected bureaucracy would gain power under term limits" type="NP">
          <tokens>
            <token id="4" string="arguments" />
            <token id="5" string="that" />
            <token id="6" string="legislative" />
            <token id="7" string="staff" />
            <token id="8" string="and" />
            <token id="9" string="the" />
            <token id="10" string="unelected" />
            <token id="11" string="bureaucracy" />
            <token id="12" string="would" />
            <token id="13" string="gain" />
            <token id="14" string="power" />
            <token id="15" string="under" />
            <token id="16" string="term" />
            <token id="17" string="limits" />
          </tokens>
        </chunking>
        <chunking id="14" string="the excessive power of those political players" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="excessive" />
            <token id="28" string="power" />
            <token id="29" string="of" />
            <token id="30" string="those" />
            <token id="31" string="political" />
            <token id="32" string="players" />
          </tokens>
        </chunking>
        <chunking id="15" string="arguments" type="NP">
          <tokens>
            <token id="4" string="arguments" />
          </tokens>
        </chunking>
        <chunking id="16" string="legislative staff" type="NP">
          <tokens>
            <token id="6" string="legislative" />
            <token id="7" string="staff" />
          </tokens>
        </chunking>
        <chunking id="17" string="curb the excessive power of those political players as well" type="VP">
          <tokens>
            <token id="25" string="curb" />
            <token id="26" string="the" />
            <token id="27" string="excessive" />
            <token id="28" string="power" />
            <token id="29" string="of" />
            <token id="30" string="those" />
            <token id="31" string="political" />
            <token id="32" string="players" />
            <token id="33" string="as" />
            <token id="34" string="well" />
          </tokens>
        </chunking>
        <chunking id="18" string="power" type="NP">
          <tokens>
            <token id="14" string="power" />
          </tokens>
        </chunking>
        <chunking id="19" string="proof" type="NP">
          <tokens>
            <token id="20" string="proof" />
          </tokens>
        </chunking>
        <chunking id="20" string="gain power under term limits" type="VP">
          <tokens>
            <token id="13" string="gain" />
            <token id="14" string="power" />
            <token id="15" string="under" />
            <token id="16" string="term" />
            <token id="17" string="limits" />
          </tokens>
        </chunking>
        <chunking id="21" string="the excessive power" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="excessive" />
            <token id="28" string="power" />
          </tokens>
        </chunking>
        <chunking id="22" string="must curb the excessive power of those political players as well" type="VP">
          <tokens>
            <token id="24" string="must" />
            <token id="25" string="curb" />
            <token id="26" string="the" />
            <token id="27" string="excessive" />
            <token id="28" string="power" />
            <token id="29" string="of" />
            <token id="30" string="those" />
            <token id="31" string="political" />
            <token id="32" string="players" />
            <token id="33" string="as" />
            <token id="34" string="well" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Brown</governor>
          <dependent id="1">Mr.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">says</governor>
          <dependent id="2">Brown</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">says</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">proof</governor>
          <dependent id="4">arguments</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">gain</governor>
          <dependent id="5">that</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">staff</governor>
          <dependent id="6">legislative</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">gain</governor>
          <dependent id="7">staff</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">staff</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">bureaucracy</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">bureaucracy</governor>
          <dependent id="10">unelected</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">staff</governor>
          <dependent id="11">bureaucracy</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">gain</governor>
          <dependent id="12">would</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="4">arguments</governor>
          <dependent id="13">gain</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">gain</governor>
          <dependent id="14">power</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">limits</governor>
          <dependent id="15">under</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">limits</governor>
          <dependent id="16">term</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">gain</governor>
          <dependent id="17">limits</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="20">proof</governor>
          <dependent id="18">are</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">proof</governor>
          <dependent id="19">simply</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">says</governor>
          <dependent id="20">proof</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="25">curb</governor>
          <dependent id="21">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">curb</governor>
          <dependent id="23">we</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="25">curb</governor>
          <dependent id="24">must</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="20">proof</governor>
          <dependent id="25">curb</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">power</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">power</governor>
          <dependent id="27">excessive</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">curb</governor>
          <dependent id="28">power</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">players</governor>
          <dependent id="29">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">players</governor>
          <dependent id="30">those</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="32">players</governor>
          <dependent id="31">political</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">power</governor>
          <dependent id="32">players</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="25">curb</governor>
          <dependent id="33">as</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="33">as</governor>
          <dependent id="34">well</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Brown" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Brown" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>He notes both groups opposed term limits in his home state; the California initiative included budget cuts that retired more than 700 legislative staffers.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="notes" lemma="note" stem="note" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="both" lemma="both" stem="both" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="groups" lemma="group" stem="group" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="opposed" lemma="oppose" stem="oppos" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="term" lemma="term" stem="term" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="limits" lemma="limit" stem="limit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="10" string="home" lemma="home" stem="home" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="state" lemma="state" stem="state" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="California" lemma="California" stem="california" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="15" string="initiative" lemma="initiative" stem="initi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="included" lemma="include" stem="includ" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="budget" lemma="budget" stem="budget" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="cuts" lemma="cut" stem="cut" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="retired" lemma="retire" stem="retir" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="700" lemma="700" stem="700" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="24" string="legislative" lemma="legislative" stem="legisl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="staffers" lemma="staffer" stem="staffer" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP He)) (VP (VBZ notes) (SBAR (S (NP (DT both) (NNS groups)) (VP (VBD opposed) (NP (NN term) (NNS limits)) (PP (IN in) (NP (PRP$ his) (NN home) (NN state)))))))) (: ;) (S (NP (DT the) (NNP California) (NN initiative)) (VP (VBD included) (NP (NP (NN budget) (NNS cuts)) (SBAR (WHNP (WDT that)) (S (VP (VBD retired) (NP (QP (JJR more) (IN than) (CD 700)) (JJ legislative) (NNS staffers)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="budget cuts" type="NP">
          <tokens>
            <token id="17" string="budget" />
            <token id="18" string="cuts" />
          </tokens>
        </chunking>
        <chunking id="2" string="retired more than 700 legislative staffers" type="VP">
          <tokens>
            <token id="20" string="retired" />
            <token id="21" string="more" />
            <token id="22" string="than" />
            <token id="23" string="700" />
            <token id="24" string="legislative" />
            <token id="25" string="staffers" />
          </tokens>
        </chunking>
        <chunking id="3" string="his home state" type="NP">
          <tokens>
            <token id="9" string="his" />
            <token id="10" string="home" />
            <token id="11" string="state" />
          </tokens>
        </chunking>
        <chunking id="4" string="the California initiative" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="California" />
            <token id="15" string="initiative" />
          </tokens>
        </chunking>
        <chunking id="5" string="opposed term limits in his home state" type="VP">
          <tokens>
            <token id="5" string="opposed" />
            <token id="6" string="term" />
            <token id="7" string="limits" />
            <token id="8" string="in" />
            <token id="9" string="his" />
            <token id="10" string="home" />
            <token id="11" string="state" />
          </tokens>
        </chunking>
        <chunking id="6" string="term limits" type="NP">
          <tokens>
            <token id="6" string="term" />
            <token id="7" string="limits" />
          </tokens>
        </chunking>
        <chunking id="7" string="that retired more than 700 legislative staffers" type="SBAR">
          <tokens>
            <token id="19" string="that" />
            <token id="20" string="retired" />
            <token id="21" string="more" />
            <token id="22" string="than" />
            <token id="23" string="700" />
            <token id="24" string="legislative" />
            <token id="25" string="staffers" />
          </tokens>
        </chunking>
        <chunking id="8" string="notes both groups opposed term limits in his home state" type="VP">
          <tokens>
            <token id="2" string="notes" />
            <token id="3" string="both" />
            <token id="4" string="groups" />
            <token id="5" string="opposed" />
            <token id="6" string="term" />
            <token id="7" string="limits" />
            <token id="8" string="in" />
            <token id="9" string="his" />
            <token id="10" string="home" />
            <token id="11" string="state" />
          </tokens>
        </chunking>
        <chunking id="9" string="budget cuts that retired more than 700 legislative staffers" type="NP">
          <tokens>
            <token id="17" string="budget" />
            <token id="18" string="cuts" />
            <token id="19" string="that" />
            <token id="20" string="retired" />
            <token id="21" string="more" />
            <token id="22" string="than" />
            <token id="23" string="700" />
            <token id="24" string="legislative" />
            <token id="25" string="staffers" />
          </tokens>
        </chunking>
        <chunking id="10" string="included budget cuts that retired more than 700 legislative staffers" type="VP">
          <tokens>
            <token id="16" string="included" />
            <token id="17" string="budget" />
            <token id="18" string="cuts" />
            <token id="19" string="that" />
            <token id="20" string="retired" />
            <token id="21" string="more" />
            <token id="22" string="than" />
            <token id="23" string="700" />
            <token id="24" string="legislative" />
            <token id="25" string="staffers" />
          </tokens>
        </chunking>
        <chunking id="11" string="both groups" type="NP">
          <tokens>
            <token id="3" string="both" />
            <token id="4" string="groups" />
          </tokens>
        </chunking>
        <chunking id="12" string="both groups opposed term limits in his home state" type="SBAR">
          <tokens>
            <token id="3" string="both" />
            <token id="4" string="groups" />
            <token id="5" string="opposed" />
            <token id="6" string="term" />
            <token id="7" string="limits" />
            <token id="8" string="in" />
            <token id="9" string="his" />
            <token id="10" string="home" />
            <token id="11" string="state" />
          </tokens>
        </chunking>
        <chunking id="13" string="more than 700 legislative staffers" type="NP">
          <tokens>
            <token id="21" string="more" />
            <token id="22" string="than" />
            <token id="23" string="700" />
            <token id="24" string="legislative" />
            <token id="25" string="staffers" />
          </tokens>
        </chunking>
        <chunking id="14" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">notes</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">notes</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">groups</governor>
          <dependent id="3">both</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">opposed</governor>
          <dependent id="4">groups</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">notes</governor>
          <dependent id="5">opposed</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">limits</governor>
          <dependent id="6">term</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">opposed</governor>
          <dependent id="7">limits</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">state</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">state</governor>
          <dependent id="9">his</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">state</governor>
          <dependent id="10">home</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">opposed</governor>
          <dependent id="11">state</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">initiative</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">initiative</governor>
          <dependent id="14">California</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">included</governor>
          <dependent id="15">initiative</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="2">notes</governor>
          <dependent id="16">included</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">cuts</governor>
          <dependent id="17">budget</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">included</governor>
          <dependent id="18">cuts</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">retired</governor>
          <dependent id="19">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="18">cuts</governor>
          <dependent id="20">retired</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="23">700</governor>
          <dependent id="21">more</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="21">more</governor>
          <dependent id="22">than</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="25">staffers</governor>
          <dependent id="23">700</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">staffers</governor>
          <dependent id="24">legislative</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">retired</governor>
          <dependent id="25">staffers</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="California" type="LOCATION" score="0.0">
          <tokens>
            <token id="14" string="California" />
          </tokens>
        </entity>
        <entity id="2" string="700" type="NUMBER" score="0.0">
          <tokens>
            <token id="23" string="700" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>Other former Democratic governors who favor term limits include Vermont&amp;apost;s Madeleine Kunin and Colorado&amp;apost;s RichardLamm.</content>
      <tokens>
        <token id="1" string="Other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="former" lemma="former" stem="former" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Democratic" lemma="democratic" stem="democrat" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="4" string="governors" lemma="governor" stem="governor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="favor" lemma="favor" stem="favor" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="term" lemma="term" stem="term" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="limits" lemma="limit" stem="limit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="include" lemma="include" stem="includ" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="Vermont" lemma="Vermont" stem="vermont" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="11" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Madeleine" lemma="Madeleine" stem="madelein" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="13" string="Kunin" lemma="Kunin" stem="kunin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Colorado" lemma="Colorado" stem="colorado" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="16" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="RichardLamm" lemma="RichardLamm" stem="richardlamm" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (JJ Other) (JJ former) (JJ Democratic) (NNS governors)) (SBAR (WHNP (WP who)) (S (VP (VBP favor) (NP (NN term) (NNS limits)))))) (VP (VBP include) (NP (NP (NP (NNP Vermont) (POS 's)) (NNP Madeleine) (NNP Kunin)) (CC and) (NP (NP (NNP Colorado) (POS 's)) (NNP RichardLamm)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="include Vermont 's Madeleine Kunin and Colorado 's RichardLamm" type="VP">
          <tokens>
            <token id="9" string="include" />
            <token id="10" string="Vermont" />
            <token id="11" string="'s" />
            <token id="12" string="Madeleine" />
            <token id="13" string="Kunin" />
            <token id="14" string="and" />
            <token id="15" string="Colorado" />
            <token id="16" string="'s" />
            <token id="17" string="RichardLamm" />
          </tokens>
        </chunking>
        <chunking id="2" string="Colorado 's RichardLamm" type="NP">
          <tokens>
            <token id="15" string="Colorado" />
            <token id="16" string="'s" />
            <token id="17" string="RichardLamm" />
          </tokens>
        </chunking>
        <chunking id="3" string="who favor term limits" type="SBAR">
          <tokens>
            <token id="5" string="who" />
            <token id="6" string="favor" />
            <token id="7" string="term" />
            <token id="8" string="limits" />
          </tokens>
        </chunking>
        <chunking id="4" string="Vermont 's Madeleine Kunin" type="NP">
          <tokens>
            <token id="10" string="Vermont" />
            <token id="11" string="'s" />
            <token id="12" string="Madeleine" />
            <token id="13" string="Kunin" />
          </tokens>
        </chunking>
        <chunking id="5" string="Vermont 's" type="NP">
          <tokens>
            <token id="10" string="Vermont" />
            <token id="11" string="'s" />
          </tokens>
        </chunking>
        <chunking id="6" string="Colorado 's" type="NP">
          <tokens>
            <token id="15" string="Colorado" />
            <token id="16" string="'s" />
          </tokens>
        </chunking>
        <chunking id="7" string="favor term limits" type="VP">
          <tokens>
            <token id="6" string="favor" />
            <token id="7" string="term" />
            <token id="8" string="limits" />
          </tokens>
        </chunking>
        <chunking id="8" string="Other former Democratic governors who favor term limits" type="NP">
          <tokens>
            <token id="1" string="Other" />
            <token id="2" string="former" />
            <token id="3" string="Democratic" />
            <token id="4" string="governors" />
            <token id="5" string="who" />
            <token id="6" string="favor" />
            <token id="7" string="term" />
            <token id="8" string="limits" />
          </tokens>
        </chunking>
        <chunking id="9" string="term limits" type="NP">
          <tokens>
            <token id="7" string="term" />
            <token id="8" string="limits" />
          </tokens>
        </chunking>
        <chunking id="10" string="Other former Democratic governors" type="NP">
          <tokens>
            <token id="1" string="Other" />
            <token id="2" string="former" />
            <token id="3" string="Democratic" />
            <token id="4" string="governors" />
          </tokens>
        </chunking>
        <chunking id="11" string="Vermont 's Madeleine Kunin and Colorado 's RichardLamm" type="NP">
          <tokens>
            <token id="10" string="Vermont" />
            <token id="11" string="'s" />
            <token id="12" string="Madeleine" />
            <token id="13" string="Kunin" />
            <token id="14" string="and" />
            <token id="15" string="Colorado" />
            <token id="16" string="'s" />
            <token id="17" string="RichardLamm" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="4">governors</governor>
          <dependent id="1">Other</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">governors</governor>
          <dependent id="2">former</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">governors</governor>
          <dependent id="3">Democratic</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">include</governor>
          <dependent id="4">governors</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">favor</governor>
          <dependent id="5">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="4">governors</governor>
          <dependent id="6">favor</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">limits</governor>
          <dependent id="7">term</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">favor</governor>
          <dependent id="8">limits</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">include</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">Kunin</governor>
          <dependent id="10">Vermont</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Vermont</governor>
          <dependent id="11">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Kunin</governor>
          <dependent id="12">Madeleine</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">include</governor>
          <dependent id="13">Kunin</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">Kunin</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="17">RichardLamm</governor>
          <dependent id="15">Colorado</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">Colorado</governor>
          <dependent id="16">'s</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">Kunin</governor>
          <dependent id="17">RichardLamm</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Vermont" type="LOCATION" score="0.0">
          <tokens>
            <token id="10" string="Vermont" />
          </tokens>
        </entity>
        <entity id="2" string="Democratic" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="3" string="Democratic" />
          </tokens>
        </entity>
        <entity id="3" string="Madeleine Kunin" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Madeleine" />
            <token id="13" string="Kunin" />
          </tokens>
        </entity>
        <entity id="4" string="Colorado" type="LOCATION" score="0.0">
          <tokens>
            <token id="15" string="Colorado" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>&amp;quot;Breaking the gridlock of incumbency could throw the doors open to new people and new ideas that would make politics rewarding, meaningful and fun,&amp;quot; says Ms. Kunin.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Breaking" lemma="break" stem="break" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="gridlock" lemma="gridlock" stem="gridlock" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="incumbency" lemma="incumbency" stem="incumb" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="throw" lemma="throw" stem="throw" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="doors" lemma="door" stem="door" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="open" lemma="open" stem="open" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="new" lemma="new" stem="new" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="new" lemma="new" stem="new" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="ideas" lemma="idea" stem="idea" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="make" lemma="make" stem="make" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="politics" lemma="politics" stem="polit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="rewarding" lemma="reward" stem="reward" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="meaningful" lemma="meaningful" stem="meaning" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="fun" lemma="fun" stem="fun" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="Ms." lemma="Ms." stem="ms." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="31" string="Kunin" lemma="Kunin" stem="kunin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (S (VP (VBG Breaking) (NP (NP (DT the) (NN gridlock)) (PP (IN of) (NP (NN incumbency)))))) (VP (MD could) (VP (VB throw) (S (NP (DT the) (NNS doors)) (ADJP (JJ open) (PP (TO to) (NP (NP (JJ new) (NNS people)) (CC and) (NP (NP (JJ new) (NNS ideas)) (SBAR (WHNP (WDT that)) (S (VP (MD would) (VP (VB make) (NP (NP (NP (NNS politics)) (VP (VBG rewarding))) (, ,) (ADJP (JJ meaningful) (CC and) (NN fun))))))))))))))) (, ,) ('' '') (VP (VBZ says)) (NP (NNP Ms.) (NNP Kunin)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="politics" type="NP">
          <tokens>
            <token id="21" string="politics" />
          </tokens>
        </chunking>
        <chunking id="2" string="incumbency" type="NP">
          <tokens>
            <token id="6" string="incumbency" />
          </tokens>
        </chunking>
        <chunking id="3" string="throw the doors open to new people and new ideas that would make politics rewarding , meaningful and fun" type="VP">
          <tokens>
            <token id="8" string="throw" />
            <token id="9" string="the" />
            <token id="10" string="doors" />
            <token id="11" string="open" />
            <token id="12" string="to" />
            <token id="13" string="new" />
            <token id="14" string="people" />
            <token id="15" string="and" />
            <token id="16" string="new" />
            <token id="17" string="ideas" />
            <token id="18" string="that" />
            <token id="19" string="would" />
            <token id="20" string="make" />
            <token id="21" string="politics" />
            <token id="22" string="rewarding" />
            <token id="23" string="," />
            <token id="24" string="meaningful" />
            <token id="25" string="and" />
            <token id="26" string="fun" />
          </tokens>
        </chunking>
        <chunking id="4" string="rewarding" type="VP">
          <tokens>
            <token id="22" string="rewarding" />
          </tokens>
        </chunking>
        <chunking id="5" string="politics rewarding , meaningful and fun" type="NP">
          <tokens>
            <token id="21" string="politics" />
            <token id="22" string="rewarding" />
            <token id="23" string="," />
            <token id="24" string="meaningful" />
            <token id="25" string="and" />
            <token id="26" string="fun" />
          </tokens>
        </chunking>
        <chunking id="6" string="that would make politics rewarding , meaningful and fun" type="SBAR">
          <tokens>
            <token id="18" string="that" />
            <token id="19" string="would" />
            <token id="20" string="make" />
            <token id="21" string="politics" />
            <token id="22" string="rewarding" />
            <token id="23" string="," />
            <token id="24" string="meaningful" />
            <token id="25" string="and" />
            <token id="26" string="fun" />
          </tokens>
        </chunking>
        <chunking id="7" string="would make politics rewarding , meaningful and fun" type="VP">
          <tokens>
            <token id="19" string="would" />
            <token id="20" string="make" />
            <token id="21" string="politics" />
            <token id="22" string="rewarding" />
            <token id="23" string="," />
            <token id="24" string="meaningful" />
            <token id="25" string="and" />
            <token id="26" string="fun" />
          </tokens>
        </chunking>
        <chunking id="8" string="new people" type="NP">
          <tokens>
            <token id="13" string="new" />
            <token id="14" string="people" />
          </tokens>
        </chunking>
        <chunking id="9" string="new ideas" type="NP">
          <tokens>
            <token id="16" string="new" />
            <token id="17" string="ideas" />
          </tokens>
        </chunking>
        <chunking id="10" string="Breaking the gridlock of incumbency" type="VP">
          <tokens>
            <token id="2" string="Breaking" />
            <token id="3" string="the" />
            <token id="4" string="gridlock" />
            <token id="5" string="of" />
            <token id="6" string="incumbency" />
          </tokens>
        </chunking>
        <chunking id="11" string="make politics rewarding , meaningful and fun" type="VP">
          <tokens>
            <token id="20" string="make" />
            <token id="21" string="politics" />
            <token id="22" string="rewarding" />
            <token id="23" string="," />
            <token id="24" string="meaningful" />
            <token id="25" string="and" />
            <token id="26" string="fun" />
          </tokens>
        </chunking>
        <chunking id="12" string="the gridlock" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="gridlock" />
          </tokens>
        </chunking>
        <chunking id="13" string="says" type="VP">
          <tokens>
            <token id="29" string="says" />
          </tokens>
        </chunking>
        <chunking id="14" string="new ideas that would make politics rewarding , meaningful and fun" type="NP">
          <tokens>
            <token id="16" string="new" />
            <token id="17" string="ideas" />
            <token id="18" string="that" />
            <token id="19" string="would" />
            <token id="20" string="make" />
            <token id="21" string="politics" />
            <token id="22" string="rewarding" />
            <token id="23" string="," />
            <token id="24" string="meaningful" />
            <token id="25" string="and" />
            <token id="26" string="fun" />
          </tokens>
        </chunking>
        <chunking id="15" string="open to new people and new ideas that would make politics rewarding , meaningful and fun" type="ADJP">
          <tokens>
            <token id="11" string="open" />
            <token id="12" string="to" />
            <token id="13" string="new" />
            <token id="14" string="people" />
            <token id="15" string="and" />
            <token id="16" string="new" />
            <token id="17" string="ideas" />
            <token id="18" string="that" />
            <token id="19" string="would" />
            <token id="20" string="make" />
            <token id="21" string="politics" />
            <token id="22" string="rewarding" />
            <token id="23" string="," />
            <token id="24" string="meaningful" />
            <token id="25" string="and" />
            <token id="26" string="fun" />
          </tokens>
        </chunking>
        <chunking id="16" string="new people and new ideas that would make politics rewarding , meaningful and fun" type="NP">
          <tokens>
            <token id="13" string="new" />
            <token id="14" string="people" />
            <token id="15" string="and" />
            <token id="16" string="new" />
            <token id="17" string="ideas" />
            <token id="18" string="that" />
            <token id="19" string="would" />
            <token id="20" string="make" />
            <token id="21" string="politics" />
            <token id="22" string="rewarding" />
            <token id="23" string="," />
            <token id="24" string="meaningful" />
            <token id="25" string="and" />
            <token id="26" string="fun" />
          </tokens>
        </chunking>
        <chunking id="17" string="the gridlock of incumbency" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="gridlock" />
            <token id="5" string="of" />
            <token id="6" string="incumbency" />
          </tokens>
        </chunking>
        <chunking id="18" string="meaningful and fun" type="ADJP">
          <tokens>
            <token id="24" string="meaningful" />
            <token id="25" string="and" />
            <token id="26" string="fun" />
          </tokens>
        </chunking>
        <chunking id="19" string="the doors" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="doors" />
          </tokens>
        </chunking>
        <chunking id="20" string="could throw the doors open to new people and new ideas that would make politics rewarding , meaningful and fun" type="VP">
          <tokens>
            <token id="7" string="could" />
            <token id="8" string="throw" />
            <token id="9" string="the" />
            <token id="10" string="doors" />
            <token id="11" string="open" />
            <token id="12" string="to" />
            <token id="13" string="new" />
            <token id="14" string="people" />
            <token id="15" string="and" />
            <token id="16" string="new" />
            <token id="17" string="ideas" />
            <token id="18" string="that" />
            <token id="19" string="would" />
            <token id="20" string="make" />
            <token id="21" string="politics" />
            <token id="22" string="rewarding" />
            <token id="23" string="," />
            <token id="24" string="meaningful" />
            <token id="25" string="and" />
            <token id="26" string="fun" />
          </tokens>
        </chunking>
        <chunking id="21" string="politics rewarding" type="NP">
          <tokens>
            <token id="21" string="politics" />
            <token id="22" string="rewarding" />
          </tokens>
        </chunking>
        <chunking id="22" string="Ms. Kunin" type="NP">
          <tokens>
            <token id="30" string="Ms." />
            <token id="31" string="Kunin" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="csubj">
          <governor id="8">throw</governor>
          <dependent id="2">Breaking</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">gridlock</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">Breaking</governor>
          <dependent id="4">gridlock</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">incumbency</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">gridlock</governor>
          <dependent id="6">incumbency</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">throw</governor>
          <dependent id="7">could</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="29">says</governor>
          <dependent id="8">throw</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">doors</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">open</governor>
          <dependent id="10">doors</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">throw</governor>
          <dependent id="11">open</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">people</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">people</governor>
          <dependent id="13">new</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">open</governor>
          <dependent id="14">people</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">people</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">ideas</governor>
          <dependent id="16">new</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">people</governor>
          <dependent id="17">ideas</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">make</governor>
          <dependent id="18">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="20">make</governor>
          <dependent id="19">would</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="17">ideas</governor>
          <dependent id="20">make</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">make</governor>
          <dependent id="21">politics</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="21">politics</governor>
          <dependent id="22">rewarding</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">politics</governor>
          <dependent id="24">meaningful</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="24">meaningful</governor>
          <dependent id="25">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="24">meaningful</governor>
          <dependent id="26">fun</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="29">says</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">Kunin</governor>
          <dependent id="30">Ms.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">says</governor>
          <dependent id="31">Kunin</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Kunin" type="PERSON" score="0.0">
          <tokens>
            <token id="31" string="Kunin" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="false">
      <content>&amp;quot;The system needs a kick in the rear,&amp;quot; says Mr. Lamm.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="system" lemma="system" stem="system" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="needs" lemma="need" stem="need" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="kick" lemma="kick" stem="kick" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="rear" lemma="rear" stem="rear" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="Lamm" lemma="Lamm" stem="lamm" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (DT The) (NN system)) (VP (VBZ needs) (NP (NP (DT a) (NN kick)) (PP (IN in) (NP (DT the) (NN rear)))))) (, ,) ('' '') (VP (VBZ says)) (NP (NNP Mr.) (NNP Lamm)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a kick in the rear" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="kick" />
            <token id="7" string="in" />
            <token id="8" string="the" />
            <token id="9" string="rear" />
          </tokens>
        </chunking>
        <chunking id="2" string="the rear" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="rear" />
          </tokens>
        </chunking>
        <chunking id="3" string="says" type="VP">
          <tokens>
            <token id="12" string="says" />
          </tokens>
        </chunking>
        <chunking id="4" string="needs a kick in the rear" type="VP">
          <tokens>
            <token id="4" string="needs" />
            <token id="5" string="a" />
            <token id="6" string="kick" />
            <token id="7" string="in" />
            <token id="8" string="the" />
            <token id="9" string="rear" />
          </tokens>
        </chunking>
        <chunking id="5" string="The system" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="system" />
          </tokens>
        </chunking>
        <chunking id="6" string="Mr. Lamm" type="NP">
          <tokens>
            <token id="13" string="Mr." />
            <token id="14" string="Lamm" />
          </tokens>
        </chunking>
        <chunking id="7" string="a kick" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="kick" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">system</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">needs</governor>
          <dependent id="3">system</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">says</governor>
          <dependent id="4">needs</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">kick</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">needs</governor>
          <dependent id="6">kick</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">rear</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">rear</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">kick</governor>
          <dependent id="9">rear</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">says</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Lamm</governor>
          <dependent id="13">Mr.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">says</governor>
          <dependent id="14">Lamm</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lamm" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Lamm" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>&amp;quot;Term limits have flaws, but they will provide badly needed competition.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Term" lemma="term" stem="term" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="limits" lemma="limit" stem="limit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="flaws" lemma="flaw" stem="flaw" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="provide" lemma="provide" stem="provid" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="badly" lemma="badly" stem="badli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="needed" lemma="need" stem="need" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="competition" lemma="competition" stem="competit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (NN Term) (NNS limits)) (VP (VBP have) (NP (NNS flaws)))) (, ,) (CC but) (S (NP (PRP they)) (VP (MD will) (VP (VB provide) (NP (ADJP (RB badly) (VBN needed)) (NN competition))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="Term limits" type="NP">
          <tokens>
            <token id="2" string="Term" />
            <token id="3" string="limits" />
          </tokens>
        </chunking>
        <chunking id="2" string="badly needed competition" type="NP">
          <tokens>
            <token id="11" string="badly" />
            <token id="12" string="needed" />
            <token id="13" string="competition" />
          </tokens>
        </chunking>
        <chunking id="3" string="have flaws" type="VP">
          <tokens>
            <token id="4" string="have" />
            <token id="5" string="flaws" />
          </tokens>
        </chunking>
        <chunking id="4" string="they" type="NP">
          <tokens>
            <token id="8" string="they" />
          </tokens>
        </chunking>
        <chunking id="5" string="badly needed" type="ADJP">
          <tokens>
            <token id="11" string="badly" />
            <token id="12" string="needed" />
          </tokens>
        </chunking>
        <chunking id="6" string="provide badly needed competition" type="VP">
          <tokens>
            <token id="10" string="provide" />
            <token id="11" string="badly" />
            <token id="12" string="needed" />
            <token id="13" string="competition" />
          </tokens>
        </chunking>
        <chunking id="7" string="flaws" type="NP">
          <tokens>
            <token id="5" string="flaws" />
          </tokens>
        </chunking>
        <chunking id="8" string="will provide badly needed competition" type="VP">
          <tokens>
            <token id="9" string="will" />
            <token id="10" string="provide" />
            <token id="11" string="badly" />
            <token id="12" string="needed" />
            <token id="13" string="competition" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">limits</governor>
          <dependent id="2">Term</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">have</governor>
          <dependent id="3">limits</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">have</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">have</governor>
          <dependent id="5">flaws</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">have</governor>
          <dependent id="7">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">provide</governor>
          <dependent id="8">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">provide</governor>
          <dependent id="9">will</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">have</governor>
          <dependent id="10">provide</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">needed</governor>
          <dependent id="11">badly</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">competition</governor>
          <dependent id="12">needed</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">provide</governor>
          <dependent id="13">competition</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="23" has_coreference="false">
      <content>While many prominent Democrats support term limits, party &amp;quot;apparatchiks&amp;quot; are dead set against them.</content>
      <tokens>
        <token id="1" string="While" lemma="while" stem="while" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="prominent" lemma="prominent" stem="promin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="Democrats" lemma="Democrats" stem="democrat" pos="NNPS" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="5" string="support" lemma="support" stem="support" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="term" lemma="term" stem="term" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="limits" lemma="limit" stem="limit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="party" lemma="party" stem="parti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="apparatchiks" lemma="apparatchik" stem="apparatchik" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="dead" lemma="dead" stem="dead" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="set" lemma="set" stem="set" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN While) (S (NP (ADJP (JJ many) (JJ prominent)) (NNPS Democrats)) (VP (VBP support) (NP (NN term) (NNS limits))))) (, ,) (NP (NP (NN party)) (`` ``) (NP (NNS apparatchiks)) ('' '')) (VP (VBP are) (NP (NP (JJ dead) (NN set)) (PP (IN against) (NP (PRP them))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="While many prominent Democrats support term limits" type="SBAR">
          <tokens>
            <token id="1" string="While" />
            <token id="2" string="many" />
            <token id="3" string="prominent" />
            <token id="4" string="Democrats" />
            <token id="5" string="support" />
            <token id="6" string="term" />
            <token id="7" string="limits" />
          </tokens>
        </chunking>
        <chunking id="2" string="many prominent" type="ADJP">
          <tokens>
            <token id="2" string="many" />
            <token id="3" string="prominent" />
          </tokens>
        </chunking>
        <chunking id="3" string="party `` apparatchiks ''" type="NP">
          <tokens>
            <token id="9" string="party" />
            <token id="10" string="&quot;" />
            <token id="11" string="apparatchiks" />
            <token id="12" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="4" string="apparatchiks" type="NP">
          <tokens>
            <token id="11" string="apparatchiks" />
          </tokens>
        </chunking>
        <chunking id="5" string="many prominent Democrats" type="NP">
          <tokens>
            <token id="2" string="many" />
            <token id="3" string="prominent" />
            <token id="4" string="Democrats" />
          </tokens>
        </chunking>
        <chunking id="6" string="dead set" type="NP">
          <tokens>
            <token id="14" string="dead" />
            <token id="15" string="set" />
          </tokens>
        </chunking>
        <chunking id="7" string="term limits" type="NP">
          <tokens>
            <token id="6" string="term" />
            <token id="7" string="limits" />
          </tokens>
        </chunking>
        <chunking id="8" string="are dead set against them" type="VP">
          <tokens>
            <token id="13" string="are" />
            <token id="14" string="dead" />
            <token id="15" string="set" />
            <token id="16" string="against" />
            <token id="17" string="them" />
          </tokens>
        </chunking>
        <chunking id="9" string="party" type="NP">
          <tokens>
            <token id="9" string="party" />
          </tokens>
        </chunking>
        <chunking id="10" string="them" type="NP">
          <tokens>
            <token id="17" string="them" />
          </tokens>
        </chunking>
        <chunking id="11" string="support term limits" type="VP">
          <tokens>
            <token id="5" string="support" />
            <token id="6" string="term" />
            <token id="7" string="limits" />
          </tokens>
        </chunking>
        <chunking id="12" string="dead set against them" type="NP">
          <tokens>
            <token id="14" string="dead" />
            <token id="15" string="set" />
            <token id="16" string="against" />
            <token id="17" string="them" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="5">support</governor>
          <dependent id="1">While</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">prominent</governor>
          <dependent id="2">many</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">Democrats</governor>
          <dependent id="3">prominent</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">support</governor>
          <dependent id="4">Democrats</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="15">set</governor>
          <dependent id="5">support</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">limits</governor>
          <dependent id="6">term</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">support</governor>
          <dependent id="7">limits</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">set</governor>
          <dependent id="9">party</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="9">party</governor>
          <dependent id="11">apparatchiks</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="15">set</governor>
          <dependent id="13">are</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">set</governor>
          <dependent id="14">dead</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">set</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">them</governor>
          <dependent id="16">against</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">set</governor>
          <dependent id="17">them</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Democrats" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="4" string="Democrats" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>The Democratic Congressional Campaign Committee has quietly put out the word that it will blacklist political consultants who advise candidates to back term limits and has told pollsters not to ask term-limit questions.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="Democratic" lemma="democratic" stem="democrat" pos="JJ" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="3" string="Congressional" lemma="Congressional" stem="congression" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="4" string="Campaign" lemma="Campaign" stem="campaign" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="5" string="Committee" lemma="Committee" stem="committe" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="6" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="quietly" lemma="quietly" stem="quietli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="put" lemma="put" stem="put" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="word" lemma="word" stem="word" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="blacklist" lemma="blacklist" stem="blacklist" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="political" lemma="political" stem="polit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="consultants" lemma="consultant" stem="consult" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="advise" lemma="advise" stem="advis" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="candidates" lemma="candidate" stem="candid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="back" lemma="back" stem="back" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="term" lemma="term" stem="term" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="limits" lemma="limit" stem="limit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="told" lemma="tell" stem="told" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="pollsters" lemma="pollster" stem="pollster" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="ask" lemma="ask" stem="ask" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="term-limit" lemma="term-limit" stem="term-limit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="questions" lemma="question" stem="question" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (JJ Democratic) (NNP Congressional) (NNP Campaign) (NNP Committee)) (VP (VP (VBZ has) (ADVP (RB quietly)) (VP (VBN put) (PRT (RP out)) (NP (DT the) (NN word)) (SBAR (IN that) (S (NP (PRP it)) (VP (MD will) (VP (VB blacklist) (NP (NP (JJ political) (NNS consultants)) (SBAR (WHNP (WP who)) (S (VP (VBP advise) (S (NP (NNS candidates)) (VP (TO to) (VP (VB back) (NP (NN term) (NNS limits))))))))))))))) (CC and) (VP (VBZ has) (VP (VBN told) (NP (NNS pollsters)) (S (RB not) (VP (TO to) (VP (VB ask) (NP (JJ term-limit) (NNS questions)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that it will blacklist political consultants who advise candidates to back term limits" type="SBAR">
          <tokens>
            <token id="12" string="that" />
            <token id="13" string="it" />
            <token id="14" string="will" />
            <token id="15" string="blacklist" />
            <token id="16" string="political" />
            <token id="17" string="consultants" />
            <token id="18" string="who" />
            <token id="19" string="advise" />
            <token id="20" string="candidates" />
            <token id="21" string="to" />
            <token id="22" string="back" />
            <token id="23" string="term" />
            <token id="24" string="limits" />
          </tokens>
        </chunking>
        <chunking id="2" string="The Democratic Congressional Campaign Committee" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Democratic" />
            <token id="3" string="Congressional" />
            <token id="4" string="Campaign" />
            <token id="5" string="Committee" />
          </tokens>
        </chunking>
        <chunking id="3" string="advise candidates to back term limits" type="VP">
          <tokens>
            <token id="19" string="advise" />
            <token id="20" string="candidates" />
            <token id="21" string="to" />
            <token id="22" string="back" />
            <token id="23" string="term" />
            <token id="24" string="limits" />
          </tokens>
        </chunking>
        <chunking id="4" string="will blacklist political consultants who advise candidates to back term limits" type="VP">
          <tokens>
            <token id="14" string="will" />
            <token id="15" string="blacklist" />
            <token id="16" string="political" />
            <token id="17" string="consultants" />
            <token id="18" string="who" />
            <token id="19" string="advise" />
            <token id="20" string="candidates" />
            <token id="21" string="to" />
            <token id="22" string="back" />
            <token id="23" string="term" />
            <token id="24" string="limits" />
          </tokens>
        </chunking>
        <chunking id="5" string="who advise candidates to back term limits" type="SBAR">
          <tokens>
            <token id="18" string="who" />
            <token id="19" string="advise" />
            <token id="20" string="candidates" />
            <token id="21" string="to" />
            <token id="22" string="back" />
            <token id="23" string="term" />
            <token id="24" string="limits" />
          </tokens>
        </chunking>
        <chunking id="6" string="has quietly put out the word that it will blacklist political consultants who advise candidates to back term limits and has told pollsters not to ask term-limit questions" type="VP">
          <tokens>
            <token id="6" string="has" />
            <token id="7" string="quietly" />
            <token id="8" string="put" />
            <token id="9" string="out" />
            <token id="10" string="the" />
            <token id="11" string="word" />
            <token id="12" string="that" />
            <token id="13" string="it" />
            <token id="14" string="will" />
            <token id="15" string="blacklist" />
            <token id="16" string="political" />
            <token id="17" string="consultants" />
            <token id="18" string="who" />
            <token id="19" string="advise" />
            <token id="20" string="candidates" />
            <token id="21" string="to" />
            <token id="22" string="back" />
            <token id="23" string="term" />
            <token id="24" string="limits" />
            <token id="25" string="and" />
            <token id="26" string="has" />
            <token id="27" string="told" />
            <token id="28" string="pollsters" />
            <token id="29" string="not" />
            <token id="30" string="to" />
            <token id="31" string="ask" />
            <token id="32" string="term-limit" />
            <token id="33" string="questions" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="13" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="term limits" type="NP">
          <tokens>
            <token id="23" string="term" />
            <token id="24" string="limits" />
          </tokens>
        </chunking>
        <chunking id="9" string="political consultants who advise candidates to back term limits" type="NP">
          <tokens>
            <token id="16" string="political" />
            <token id="17" string="consultants" />
            <token id="18" string="who" />
            <token id="19" string="advise" />
            <token id="20" string="candidates" />
            <token id="21" string="to" />
            <token id="22" string="back" />
            <token id="23" string="term" />
            <token id="24" string="limits" />
          </tokens>
        </chunking>
        <chunking id="10" string="back term limits" type="VP">
          <tokens>
            <token id="22" string="back" />
            <token id="23" string="term" />
            <token id="24" string="limits" />
          </tokens>
        </chunking>
        <chunking id="11" string="candidates" type="NP">
          <tokens>
            <token id="20" string="candidates" />
          </tokens>
        </chunking>
        <chunking id="12" string="pollsters" type="NP">
          <tokens>
            <token id="28" string="pollsters" />
          </tokens>
        </chunking>
        <chunking id="13" string="ask term-limit questions" type="VP">
          <tokens>
            <token id="31" string="ask" />
            <token id="32" string="term-limit" />
            <token id="33" string="questions" />
          </tokens>
        </chunking>
        <chunking id="14" string="to ask term-limit questions" type="VP">
          <tokens>
            <token id="30" string="to" />
            <token id="31" string="ask" />
            <token id="32" string="term-limit" />
            <token id="33" string="questions" />
          </tokens>
        </chunking>
        <chunking id="15" string="has quietly put out the word that it will blacklist political consultants who advise candidates to back term limits" type="VP">
          <tokens>
            <token id="6" string="has" />
            <token id="7" string="quietly" />
            <token id="8" string="put" />
            <token id="9" string="out" />
            <token id="10" string="the" />
            <token id="11" string="word" />
            <token id="12" string="that" />
            <token id="13" string="it" />
            <token id="14" string="will" />
            <token id="15" string="blacklist" />
            <token id="16" string="political" />
            <token id="17" string="consultants" />
            <token id="18" string="who" />
            <token id="19" string="advise" />
            <token id="20" string="candidates" />
            <token id="21" string="to" />
            <token id="22" string="back" />
            <token id="23" string="term" />
            <token id="24" string="limits" />
          </tokens>
        </chunking>
        <chunking id="16" string="political consultants" type="NP">
          <tokens>
            <token id="16" string="political" />
            <token id="17" string="consultants" />
          </tokens>
        </chunking>
        <chunking id="17" string="blacklist political consultants who advise candidates to back term limits" type="VP">
          <tokens>
            <token id="15" string="blacklist" />
            <token id="16" string="political" />
            <token id="17" string="consultants" />
            <token id="18" string="who" />
            <token id="19" string="advise" />
            <token id="20" string="candidates" />
            <token id="21" string="to" />
            <token id="22" string="back" />
            <token id="23" string="term" />
            <token id="24" string="limits" />
          </tokens>
        </chunking>
        <chunking id="18" string="has told pollsters not to ask term-limit questions" type="VP">
          <tokens>
            <token id="26" string="has" />
            <token id="27" string="told" />
            <token id="28" string="pollsters" />
            <token id="29" string="not" />
            <token id="30" string="to" />
            <token id="31" string="ask" />
            <token id="32" string="term-limit" />
            <token id="33" string="questions" />
          </tokens>
        </chunking>
        <chunking id="19" string="term-limit questions" type="NP">
          <tokens>
            <token id="32" string="term-limit" />
            <token id="33" string="questions" />
          </tokens>
        </chunking>
        <chunking id="20" string="put out the word that it will blacklist political consultants who advise candidates to back term limits" type="VP">
          <tokens>
            <token id="8" string="put" />
            <token id="9" string="out" />
            <token id="10" string="the" />
            <token id="11" string="word" />
            <token id="12" string="that" />
            <token id="13" string="it" />
            <token id="14" string="will" />
            <token id="15" string="blacklist" />
            <token id="16" string="political" />
            <token id="17" string="consultants" />
            <token id="18" string="who" />
            <token id="19" string="advise" />
            <token id="20" string="candidates" />
            <token id="21" string="to" />
            <token id="22" string="back" />
            <token id="23" string="term" />
            <token id="24" string="limits" />
          </tokens>
        </chunking>
        <chunking id="21" string="the word" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="word" />
          </tokens>
        </chunking>
        <chunking id="22" string="told pollsters not to ask term-limit questions" type="VP">
          <tokens>
            <token id="27" string="told" />
            <token id="28" string="pollsters" />
            <token id="29" string="not" />
            <token id="30" string="to" />
            <token id="31" string="ask" />
            <token id="32" string="term-limit" />
            <token id="33" string="questions" />
          </tokens>
        </chunking>
        <chunking id="23" string="to back term limits" type="VP">
          <tokens>
            <token id="21" string="to" />
            <token id="22" string="back" />
            <token id="23" string="term" />
            <token id="24" string="limits" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="5">Committee</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">Committee</governor>
          <dependent id="2">Democratic</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Committee</governor>
          <dependent id="3">Congressional</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Committee</governor>
          <dependent id="4">Campaign</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">put</governor>
          <dependent id="5">Committee</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">put</governor>
          <dependent id="6">has</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">put</governor>
          <dependent id="7">quietly</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">put</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="8">put</governor>
          <dependent id="9">out</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">word</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">put</governor>
          <dependent id="11">word</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">blacklist</governor>
          <dependent id="12">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">blacklist</governor>
          <dependent id="13">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">blacklist</governor>
          <dependent id="14">will</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">put</governor>
          <dependent id="15">blacklist</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">consultants</governor>
          <dependent id="16">political</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">blacklist</governor>
          <dependent id="17">consultants</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">advise</governor>
          <dependent id="18">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="17">consultants</governor>
          <dependent id="19">advise</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">advise</governor>
          <dependent id="20">candidates</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">back</governor>
          <dependent id="21">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="19">advise</governor>
          <dependent id="22">back</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">limits</governor>
          <dependent id="23">term</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">back</governor>
          <dependent id="24">limits</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">put</governor>
          <dependent id="25">and</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="27">told</governor>
          <dependent id="26">has</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">put</governor>
          <dependent id="27">told</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="27">told</governor>
          <dependent id="28">pollsters</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="31">ask</governor>
          <dependent id="29">not</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="31">ask</governor>
          <dependent id="30">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="27">told</governor>
          <dependent id="31">ask</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="33">questions</governor>
          <dependent id="32">term-limit</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="31">ask</governor>
          <dependent id="33">questions</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Democratic Congressional Campaign Committee" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="2" string="Democratic" />
            <token id="3" string="Congressional" />
            <token id="4" string="Campaign" />
            <token id="5" string="Committee" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>Intimidation like that has slowed support for term limits among Democratic officeholders, but there are exceptions.</content>
      <tokens>
        <token id="1" string="Intimidation" lemma="intimidation" stem="intimid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="slowed" lemma="slow" stem="slow" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="support" lemma="support" stem="support" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="term" lemma="term" stem="term" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="limits" lemma="limit" stem="limit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="among" lemma="among" stem="among" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="Democratic" lemma="democratic" stem="democrat" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="12" string="officeholders" lemma="officeholder" stem="officehold" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="exceptions" lemma="exception" stem="except" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (NN Intimidation)) (PP (IN like) (NP (DT that)))) (VP (VBZ has) (VP (VBN slowed) (NP (NP (NN support)) (PP (IN for) (NP (NN term) (NNS limits)))) (PP (IN among) (NP (JJ Democratic) (NNS officeholders)))))) (, ,) (CC but) (S (NP (EX there)) (VP (VBP are) (NP (NNS exceptions)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Intimidation" type="NP">
          <tokens>
            <token id="1" string="Intimidation" />
          </tokens>
        </chunking>
        <chunking id="2" string="that" type="NP">
          <tokens>
            <token id="3" string="that" />
          </tokens>
        </chunking>
        <chunking id="3" string="there" type="NP">
          <tokens>
            <token id="15" string="there" />
          </tokens>
        </chunking>
        <chunking id="4" string="has slowed support for term limits among Democratic officeholders" type="VP">
          <tokens>
            <token id="4" string="has" />
            <token id="5" string="slowed" />
            <token id="6" string="support" />
            <token id="7" string="for" />
            <token id="8" string="term" />
            <token id="9" string="limits" />
            <token id="10" string="among" />
            <token id="11" string="Democratic" />
            <token id="12" string="officeholders" />
          </tokens>
        </chunking>
        <chunking id="5" string="support for term limits" type="NP">
          <tokens>
            <token id="6" string="support" />
            <token id="7" string="for" />
            <token id="8" string="term" />
            <token id="9" string="limits" />
          </tokens>
        </chunking>
        <chunking id="6" string="are exceptions" type="VP">
          <tokens>
            <token id="16" string="are" />
            <token id="17" string="exceptions" />
          </tokens>
        </chunking>
        <chunking id="7" string="Democratic officeholders" type="NP">
          <tokens>
            <token id="11" string="Democratic" />
            <token id="12" string="officeholders" />
          </tokens>
        </chunking>
        <chunking id="8" string="slowed support for term limits among Democratic officeholders" type="VP">
          <tokens>
            <token id="5" string="slowed" />
            <token id="6" string="support" />
            <token id="7" string="for" />
            <token id="8" string="term" />
            <token id="9" string="limits" />
            <token id="10" string="among" />
            <token id="11" string="Democratic" />
            <token id="12" string="officeholders" />
          </tokens>
        </chunking>
        <chunking id="9" string="exceptions" type="NP">
          <tokens>
            <token id="17" string="exceptions" />
          </tokens>
        </chunking>
        <chunking id="10" string="term limits" type="NP">
          <tokens>
            <token id="8" string="term" />
            <token id="9" string="limits" />
          </tokens>
        </chunking>
        <chunking id="11" string="support" type="NP">
          <tokens>
            <token id="6" string="support" />
          </tokens>
        </chunking>
        <chunking id="12" string="Intimidation like that" type="NP">
          <tokens>
            <token id="1" string="Intimidation" />
            <token id="2" string="like" />
            <token id="3" string="that" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">slowed</governor>
          <dependent id="1">Intimidation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">that</governor>
          <dependent id="2">like</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Intimidation</governor>
          <dependent id="3">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">slowed</governor>
          <dependent id="4">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">slowed</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">slowed</governor>
          <dependent id="6">support</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">limits</governor>
          <dependent id="7">for</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">limits</governor>
          <dependent id="8">term</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">support</governor>
          <dependent id="9">limits</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">officeholders</governor>
          <dependent id="10">among</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">officeholders</governor>
          <dependent id="11">Democratic</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">slowed</governor>
          <dependent id="12">officeholders</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">slowed</governor>
          <dependent id="14">but</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="16">are</governor>
          <dependent id="15">there</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">slowed</governor>
          <dependent id="16">are</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">are</governor>
          <dependent id="17">exceptions</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Democratic" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="11" string="Democratic" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="26" has_coreference="true">
      <content>In Massachusetts, the state&amp;apost;s Democratic attorney general and secretary of state both favor term limits.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Massachusetts" lemma="Massachusetts" stem="massachusett" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="state" lemma="state" stem="state" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="Democratic" lemma="democratic" stem="democrat" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="8" string="attorney" lemma="attorney" stem="attornei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="general" lemma="general" stem="gener" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="secretary" lemma="secretary" stem="secretari" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="state" lemma="state" stem="state" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="both" lemma="both" stem="both" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="favor" lemma="favor" stem="favor" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="term" lemma="term" stem="term" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="limits" lemma="limit" stem="limit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (NNP Massachusetts))) (, ,) (NP (NP (NP (DT the) (NN state) (POS 's)) (JJ Democratic) (NN attorney) (NN general) (CC and) (NN secretary)) (PP (IN of) (NP (NN state)))) (ADVP (CC both)) (VP (VBP favor) (NP (NN term) (NNS limits))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Massachusetts" type="NP">
          <tokens>
            <token id="2" string="Massachusetts" />
          </tokens>
        </chunking>
        <chunking id="2" string="the state 's Democratic attorney general and secretary of state" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="state" />
            <token id="6" string="'s" />
            <token id="7" string="Democratic" />
            <token id="8" string="attorney" />
            <token id="9" string="general" />
            <token id="10" string="and" />
            <token id="11" string="secretary" />
            <token id="12" string="of" />
            <token id="13" string="state" />
          </tokens>
        </chunking>
        <chunking id="3" string="the state 's" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="state" />
            <token id="6" string="'s" />
          </tokens>
        </chunking>
        <chunking id="4" string="favor term limits" type="VP">
          <tokens>
            <token id="15" string="favor" />
            <token id="16" string="term" />
            <token id="17" string="limits" />
          </tokens>
        </chunking>
        <chunking id="5" string="state" type="NP">
          <tokens>
            <token id="13" string="state" />
          </tokens>
        </chunking>
        <chunking id="6" string="term limits" type="NP">
          <tokens>
            <token id="16" string="term" />
            <token id="17" string="limits" />
          </tokens>
        </chunking>
        <chunking id="7" string="the state 's Democratic attorney general and secretary" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="state" />
            <token id="6" string="'s" />
            <token id="7" string="Democratic" />
            <token id="8" string="attorney" />
            <token id="9" string="general" />
            <token id="10" string="and" />
            <token id="11" string="secretary" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">Massachusetts</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">favor</governor>
          <dependent id="2">Massachusetts</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">state</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">general</governor>
          <dependent id="5">state</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">state</governor>
          <dependent id="6">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">general</governor>
          <dependent id="7">Democratic</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">general</governor>
          <dependent id="8">attorney</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">favor</governor>
          <dependent id="9">general</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">general</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">general</governor>
          <dependent id="11">secretary</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">state</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">general</governor>
          <dependent id="13">state</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">favor</governor>
          <dependent id="14">both</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">favor</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">limits</governor>
          <dependent id="16">term</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">favor</governor>
          <dependent id="17">limits</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Massachusetts" type="LOCATION" score="0.0">
          <tokens>
            <token id="2" string="Massachusetts" />
          </tokens>
        </entity>
        <entity id="2" string="Democratic" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="7" string="Democratic" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="27" has_coreference="false">
      <content>In Texas, Gov. Ann Richards says she &amp;quot;would be glad&amp;quot; to sign a bill limiting congressional and legislative terms.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Texas" lemma="Texas" stem="texa" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Gov." lemma="Gov." stem="gov." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="Ann" lemma="Ann" stem="ann" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string="Richards" lemma="Richards" stem="richard" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="7" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="glad" lemma="glad" stem="glad" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="sign" lemma="sign" stem="sign" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="bill" lemma="bill" stem="bill" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="limiting" lemma="limit" stem="limit" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="congressional" lemma="congressional" stem="congression" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="legislative" lemma="legislative" stem="legisl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="terms" lemma="term" stem="term" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (NNP Texas))) (, ,) (NP (NNP Gov.) (NNP Ann) (NNP Richards)) (VP (VBZ says) (SBAR (S (NP (PRP she)) (`` ``) (VP (MD would) (VP (VB be) (ADJP (JJ glad) ('' '')) (S (VP (TO to) (VP (VB sign) (NP (NP (DT a) (NN bill)) (VP (VBG limiting) (NP (JJ congressional) (CC and) (JJ legislative) (NNS terms)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Gov. Ann Richards" type="NP">
          <tokens>
            <token id="4" string="Gov." />
            <token id="5" string="Ann" />
            <token id="6" string="Richards" />
          </tokens>
        </chunking>
        <chunking id="2" string="glad ''" type="ADJP">
          <tokens>
            <token id="12" string="glad" />
            <token id="13" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="3" string="she `` would be glad '' to sign a bill limiting congressional and legislative terms" type="SBAR">
          <tokens>
            <token id="8" string="she" />
            <token id="9" string="&quot;" />
            <token id="10" string="would" />
            <token id="11" string="be" />
            <token id="12" string="glad" />
            <token id="13" string="&quot;" />
            <token id="14" string="to" />
            <token id="15" string="sign" />
            <token id="16" string="a" />
            <token id="17" string="bill" />
            <token id="18" string="limiting" />
            <token id="19" string="congressional" />
            <token id="20" string="and" />
            <token id="21" string="legislative" />
            <token id="22" string="terms" />
          </tokens>
        </chunking>
        <chunking id="4" string="limiting congressional and legislative terms" type="VP">
          <tokens>
            <token id="18" string="limiting" />
            <token id="19" string="congressional" />
            <token id="20" string="and" />
            <token id="21" string="legislative" />
            <token id="22" string="terms" />
          </tokens>
        </chunking>
        <chunking id="5" string="to sign a bill limiting congressional and legislative terms" type="VP">
          <tokens>
            <token id="14" string="to" />
            <token id="15" string="sign" />
            <token id="16" string="a" />
            <token id="17" string="bill" />
            <token id="18" string="limiting" />
            <token id="19" string="congressional" />
            <token id="20" string="and" />
            <token id="21" string="legislative" />
            <token id="22" string="terms" />
          </tokens>
        </chunking>
        <chunking id="6" string="would be glad '' to sign a bill limiting congressional and legislative terms" type="VP">
          <tokens>
            <token id="10" string="would" />
            <token id="11" string="be" />
            <token id="12" string="glad" />
            <token id="13" string="&quot;" />
            <token id="14" string="to" />
            <token id="15" string="sign" />
            <token id="16" string="a" />
            <token id="17" string="bill" />
            <token id="18" string="limiting" />
            <token id="19" string="congressional" />
            <token id="20" string="and" />
            <token id="21" string="legislative" />
            <token id="22" string="terms" />
          </tokens>
        </chunking>
        <chunking id="7" string="she" type="NP">
          <tokens>
            <token id="8" string="she" />
          </tokens>
        </chunking>
        <chunking id="8" string="be glad '' to sign a bill limiting congressional and legislative terms" type="VP">
          <tokens>
            <token id="11" string="be" />
            <token id="12" string="glad" />
            <token id="13" string="&quot;" />
            <token id="14" string="to" />
            <token id="15" string="sign" />
            <token id="16" string="a" />
            <token id="17" string="bill" />
            <token id="18" string="limiting" />
            <token id="19" string="congressional" />
            <token id="20" string="and" />
            <token id="21" string="legislative" />
            <token id="22" string="terms" />
          </tokens>
        </chunking>
        <chunking id="9" string="congressional and legislative terms" type="NP">
          <tokens>
            <token id="19" string="congressional" />
            <token id="20" string="and" />
            <token id="21" string="legislative" />
            <token id="22" string="terms" />
          </tokens>
        </chunking>
        <chunking id="10" string="sign a bill limiting congressional and legislative terms" type="VP">
          <tokens>
            <token id="15" string="sign" />
            <token id="16" string="a" />
            <token id="17" string="bill" />
            <token id="18" string="limiting" />
            <token id="19" string="congressional" />
            <token id="20" string="and" />
            <token id="21" string="legislative" />
            <token id="22" string="terms" />
          </tokens>
        </chunking>
        <chunking id="11" string="a bill" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="bill" />
          </tokens>
        </chunking>
        <chunking id="12" string="Texas" type="NP">
          <tokens>
            <token id="2" string="Texas" />
          </tokens>
        </chunking>
        <chunking id="13" string="a bill limiting congressional and legislative terms" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="bill" />
            <token id="18" string="limiting" />
            <token id="19" string="congressional" />
            <token id="20" string="and" />
            <token id="21" string="legislative" />
            <token id="22" string="terms" />
          </tokens>
        </chunking>
        <chunking id="14" string="says she `` would be glad '' to sign a bill limiting congressional and legislative terms" type="VP">
          <tokens>
            <token id="7" string="says" />
            <token id="8" string="she" />
            <token id="9" string="&quot;" />
            <token id="10" string="would" />
            <token id="11" string="be" />
            <token id="12" string="glad" />
            <token id="13" string="&quot;" />
            <token id="14" string="to" />
            <token id="15" string="sign" />
            <token id="16" string="a" />
            <token id="17" string="bill" />
            <token id="18" string="limiting" />
            <token id="19" string="congressional" />
            <token id="20" string="and" />
            <token id="21" string="legislative" />
            <token id="22" string="terms" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">Texas</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">says</governor>
          <dependent id="2">Texas</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Richards</governor>
          <dependent id="4">Gov.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Richards</governor>
          <dependent id="5">Ann</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">says</governor>
          <dependent id="6">Richards</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">says</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">glad</governor>
          <dependent id="8">she</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">glad</governor>
          <dependent id="10">would</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">glad</governor>
          <dependent id="11">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">says</governor>
          <dependent id="12">glad</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">sign</governor>
          <dependent id="14">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="12">glad</governor>
          <dependent id="15">sign</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">bill</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">sign</governor>
          <dependent id="17">bill</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="17">bill</governor>
          <dependent id="18">limiting</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">terms</governor>
          <dependent id="19">congressional</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="19">congressional</governor>
          <dependent id="20">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">congressional</governor>
          <dependent id="21">legislative</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">limiting</governor>
          <dependent id="22">terms</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Texas" type="LOCATION" score="0.0">
          <tokens>
            <token id="2" string="Texas" />
          </tokens>
        </entity>
        <entity id="2" string="Ann Richards" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Ann" />
            <token id="6" string="Richards" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="28" has_coreference="false">
      <content>Lt. Gov. Bob Bullock also leans in favor of term limits.</content>
      <tokens>
        <token id="1" string="Lt." lemma="Lt." stem="lt." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="Gov." lemma="Gov." stem="gov." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Bob" lemma="Bob" stem="bob" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="4" string="Bullock" lemma="Bullock" stem="bullock" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="5" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="leans" lemma="lean" stem="lean" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="favor" lemma="favor" stem="favor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="term" lemma="term" stem="term" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="limits" lemma="limit" stem="limit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Lt.) (NNP Gov.) (NNP Bob) (NNP Bullock)) (ADVP (RB also)) (VP (VBZ leans) (PP (IN in) (NP (NP (NN favor)) (PP (IN of) (NP (NN term) (NNS limits)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="leans in favor of term limits" type="VP">
          <tokens>
            <token id="6" string="leans" />
            <token id="7" string="in" />
            <token id="8" string="favor" />
            <token id="9" string="of" />
            <token id="10" string="term" />
            <token id="11" string="limits" />
          </tokens>
        </chunking>
        <chunking id="2" string="Lt. Gov. Bob Bullock" type="NP">
          <tokens>
            <token id="1" string="Lt." />
            <token id="2" string="Gov." />
            <token id="3" string="Bob" />
            <token id="4" string="Bullock" />
          </tokens>
        </chunking>
        <chunking id="3" string="favor of term limits" type="NP">
          <tokens>
            <token id="8" string="favor" />
            <token id="9" string="of" />
            <token id="10" string="term" />
            <token id="11" string="limits" />
          </tokens>
        </chunking>
        <chunking id="4" string="favor" type="NP">
          <tokens>
            <token id="8" string="favor" />
          </tokens>
        </chunking>
        <chunking id="5" string="term limits" type="NP">
          <tokens>
            <token id="10" string="term" />
            <token id="11" string="limits" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="4">Bullock</governor>
          <dependent id="1">Lt.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Bullock</governor>
          <dependent id="2">Gov.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Bullock</governor>
          <dependent id="3">Bob</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">leans</governor>
          <dependent id="4">Bullock</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">leans</governor>
          <dependent id="5">also</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">leans</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">favor</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">leans</governor>
          <dependent id="8">favor</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">limits</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">limits</governor>
          <dependent id="10">term</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">favor</governor>
          <dependent id="11">limits</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Bob Bullock" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Bob" />
            <token id="4" string="Bullock" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="29" has_coreference="true">
      <content>Journalists are under fewer constraints than elected officials in expressing enthusiasm for term limits.</content>
      <tokens>
        <token id="1" string="Journalists" lemma="journalist" stem="journalist" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="under" lemma="under" stem="under" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="fewer" lemma="fewer" stem="fewer" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="constraints" lemma="constraint" stem="constraint" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="elected" lemma="elect" stem="elect" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="officials" lemma="official" stem="offici" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="expressing" lemma="express" stem="express" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="enthusiasm" lemma="enthusiasm" stem="enthusiasm" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="term" lemma="term" stem="term" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="limits" lemma="limit" stem="limit" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNS Journalists)) (VP (VBP are) (PP (IN under) (NP (NP (JJR fewer) (NNS constraints)) (PP (IN than) (NP (NP (VBN elected) (NNS officials)) (PP (IN in) (S (VP (VBG expressing) (NP (NN enthusiasm)) (PP (IN for) (NP (NN term) (NNS limits))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="fewer constraints than elected officials in expressing enthusiasm for term limits" type="NP">
          <tokens>
            <token id="4" string="fewer" />
            <token id="5" string="constraints" />
            <token id="6" string="than" />
            <token id="7" string="elected" />
            <token id="8" string="officials" />
            <token id="9" string="in" />
            <token id="10" string="expressing" />
            <token id="11" string="enthusiasm" />
            <token id="12" string="for" />
            <token id="13" string="term" />
            <token id="14" string="limits" />
          </tokens>
        </chunking>
        <chunking id="2" string="enthusiasm" type="NP">
          <tokens>
            <token id="11" string="enthusiasm" />
          </tokens>
        </chunking>
        <chunking id="3" string="expressing enthusiasm for term limits" type="VP">
          <tokens>
            <token id="10" string="expressing" />
            <token id="11" string="enthusiasm" />
            <token id="12" string="for" />
            <token id="13" string="term" />
            <token id="14" string="limits" />
          </tokens>
        </chunking>
        <chunking id="4" string="are under fewer constraints than elected officials in expressing enthusiasm for term limits" type="VP">
          <tokens>
            <token id="2" string="are" />
            <token id="3" string="under" />
            <token id="4" string="fewer" />
            <token id="5" string="constraints" />
            <token id="6" string="than" />
            <token id="7" string="elected" />
            <token id="8" string="officials" />
            <token id="9" string="in" />
            <token id="10" string="expressing" />
            <token id="11" string="enthusiasm" />
            <token id="12" string="for" />
            <token id="13" string="term" />
            <token id="14" string="limits" />
          </tokens>
        </chunking>
        <chunking id="5" string="elected officials in expressing enthusiasm for term limits" type="NP">
          <tokens>
            <token id="7" string="elected" />
            <token id="8" string="officials" />
            <token id="9" string="in" />
            <token id="10" string="expressing" />
            <token id="11" string="enthusiasm" />
            <token id="12" string="for" />
            <token id="13" string="term" />
            <token id="14" string="limits" />
          </tokens>
        </chunking>
        <chunking id="6" string="Journalists" type="NP">
          <tokens>
            <token id="1" string="Journalists" />
          </tokens>
        </chunking>
        <chunking id="7" string="elected officials" type="NP">
          <tokens>
            <token id="7" string="elected" />
            <token id="8" string="officials" />
          </tokens>
        </chunking>
        <chunking id="8" string="fewer constraints" type="NP">
          <tokens>
            <token id="4" string="fewer" />
            <token id="5" string="constraints" />
          </tokens>
        </chunking>
        <chunking id="9" string="term limits" type="NP">
          <tokens>
            <token id="13" string="term" />
            <token id="14" string="limits" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">constraints</governor>
          <dependent id="1">Journalists</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">constraints</governor>
          <dependent id="2">are</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">constraints</governor>
          <dependent id="3">under</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">constraints</governor>
          <dependent id="4">fewer</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">constraints</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">officials</governor>
          <dependent id="6">than</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">officials</governor>
          <dependent id="7">elected</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">constraints</governor>
          <dependent id="8">officials</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">expressing</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="8">officials</governor>
          <dependent id="10">expressing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">expressing</governor>
          <dependent id="11">enthusiasm</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">limits</governor>
          <dependent id="12">for</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">limits</governor>
          <dependent id="13">term</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">expressing</governor>
          <dependent id="14">limits</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="30" has_coreference="true">
      <content>Among those who have, and who will never be accused of being card-carrying Republicans, are: Washington Post columnist Richard Cohen, syndicated columnist Richard Reeves, the National Journal&amp;apost;s Neal Peirce and Time magazine&amp;apost;s Michael Kramer.</content>
      <tokens>
        <token id="1" string="Among" lemma="among" stem="among" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="accused" lemma="accuse" stem="accus" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="being" lemma="be" stem="be" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="card-carrying" lemma="card-carrying" stem="card-carri" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="Republicans" lemma="Republicans" stem="republican" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Washington" lemma="Washington" stem="washington" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="20" string="Post" lemma="Post" stem="post" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="21" string="columnist" lemma="columnist" stem="columnist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="Richard" lemma="Richard" stem="richard" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="23" string="Cohen" lemma="Cohen" stem="cohen" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="syndicated" lemma="syndicate" stem="syndic" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="columnist" lemma="columnist" stem="columnist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="Richard" lemma="Richard" stem="richard" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="28" string="Reeves" lemma="Reeves" stem="reev" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="29" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="31" string="National" lemma="National" stem="nation" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="32" string="Journal" lemma="Journal" stem="journal" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="33" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="34" string="Neal" lemma="Neal" stem="neal" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="35" string="Peirce" lemma="Peirce" stem="peirc" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="36" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="Time" lemma="Time" stem="time" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="38" string="magazine" lemma="magazine" stem="magazin" pos="NN" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="39" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="Michael" lemma="Michael" stem="michael" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="41" string="Kramer" lemma="Kramer" stem="kramer" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="42" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN Among) (NP (DT those))) (SBAR (SBAR (WHNP (WP who)) (S (VP (VBP have)))) (, ,) (CC and) (SBAR (WHNP (WP who)) (S (VP (MD will) (ADVP (RB never)) (VP (VB be) (VP (VBN accused) (PP (IN of) (S (VP (VBG being) (NP (JJ card-carrying) (NNPS Republicans))))))))))) (, ,) (VP (VBP are) (: :) (NP (NP (NNP Washington) (NNP Post) (NN columnist) (NNP Richard) (NNP Cohen)) (, ,) (VP (VBN syndicated) (NP (NP (NN columnist) (NNP Richard) (NNP Reeves)) (, ,) (NP (NP (NP (DT the) (NNP National) (NNP Journal) (POS 's)) (NNP Neal) (NNP Peirce)) (CC and) (NP (NP (NNP Time) (NN magazine) (POS 's)) (NNP Michael) (NNP Kramer))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="who will never be accused of being card-carrying Republicans" type="SBAR">
          <tokens>
            <token id="7" string="who" />
            <token id="8" string="will" />
            <token id="9" string="never" />
            <token id="10" string="be" />
            <token id="11" string="accused" />
            <token id="12" string="of" />
            <token id="13" string="being" />
            <token id="14" string="card-carrying" />
            <token id="15" string="Republicans" />
          </tokens>
        </chunking>
        <chunking id="2" string="accused of being card-carrying Republicans" type="VP">
          <tokens>
            <token id="11" string="accused" />
            <token id="12" string="of" />
            <token id="13" string="being" />
            <token id="14" string="card-carrying" />
            <token id="15" string="Republicans" />
          </tokens>
        </chunking>
        <chunking id="3" string="Time magazine 's Michael Kramer" type="NP">
          <tokens>
            <token id="37" string="Time" />
            <token id="38" string="magazine" />
            <token id="39" string="'s" />
            <token id="40" string="Michael" />
            <token id="41" string="Kramer" />
          </tokens>
        </chunking>
        <chunking id="4" string="Time magazine 's" type="NP">
          <tokens>
            <token id="37" string="Time" />
            <token id="38" string="magazine" />
            <token id="39" string="'s" />
          </tokens>
        </chunking>
        <chunking id="5" string="be accused of being card-carrying Republicans" type="VP">
          <tokens>
            <token id="10" string="be" />
            <token id="11" string="accused" />
            <token id="12" string="of" />
            <token id="13" string="being" />
            <token id="14" string="card-carrying" />
            <token id="15" string="Republicans" />
          </tokens>
        </chunking>
        <chunking id="6" string="are : Washington Post columnist Richard Cohen , syndicated columnist Richard Reeves , the National Journal 's Neal Peirce and Time magazine 's Michael Kramer" type="VP">
          <tokens>
            <token id="17" string="are" />
            <token id="18" string=":" />
            <token id="19" string="Washington" />
            <token id="20" string="Post" />
            <token id="21" string="columnist" />
            <token id="22" string="Richard" />
            <token id="23" string="Cohen" />
            <token id="24" string="," />
            <token id="25" string="syndicated" />
            <token id="26" string="columnist" />
            <token id="27" string="Richard" />
            <token id="28" string="Reeves" />
            <token id="29" string="," />
            <token id="30" string="the" />
            <token id="31" string="National" />
            <token id="32" string="Journal" />
            <token id="33" string="'s" />
            <token id="34" string="Neal" />
            <token id="35" string="Peirce" />
            <token id="36" string="and" />
            <token id="37" string="Time" />
            <token id="38" string="magazine" />
            <token id="39" string="'s" />
            <token id="40" string="Michael" />
            <token id="41" string="Kramer" />
          </tokens>
        </chunking>
        <chunking id="7" string="the National Journal 's Neal Peirce and Time magazine 's Michael Kramer" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="National" />
            <token id="32" string="Journal" />
            <token id="33" string="'s" />
            <token id="34" string="Neal" />
            <token id="35" string="Peirce" />
            <token id="36" string="and" />
            <token id="37" string="Time" />
            <token id="38" string="magazine" />
            <token id="39" string="'s" />
            <token id="40" string="Michael" />
            <token id="41" string="Kramer" />
          </tokens>
        </chunking>
        <chunking id="8" string="Washington Post columnist Richard Cohen" type="NP">
          <tokens>
            <token id="19" string="Washington" />
            <token id="20" string="Post" />
            <token id="21" string="columnist" />
            <token id="22" string="Richard" />
            <token id="23" string="Cohen" />
          </tokens>
        </chunking>
        <chunking id="9" string="syndicated columnist Richard Reeves , the National Journal 's Neal Peirce and Time magazine 's Michael Kramer" type="VP">
          <tokens>
            <token id="25" string="syndicated" />
            <token id="26" string="columnist" />
            <token id="27" string="Richard" />
            <token id="28" string="Reeves" />
            <token id="29" string="," />
            <token id="30" string="the" />
            <token id="31" string="National" />
            <token id="32" string="Journal" />
            <token id="33" string="'s" />
            <token id="34" string="Neal" />
            <token id="35" string="Peirce" />
            <token id="36" string="and" />
            <token id="37" string="Time" />
            <token id="38" string="magazine" />
            <token id="39" string="'s" />
            <token id="40" string="Michael" />
            <token id="41" string="Kramer" />
          </tokens>
        </chunking>
        <chunking id="10" string="columnist Richard Reeves , the National Journal 's Neal Peirce and Time magazine 's Michael Kramer" type="NP">
          <tokens>
            <token id="26" string="columnist" />
            <token id="27" string="Richard" />
            <token id="28" string="Reeves" />
            <token id="29" string="," />
            <token id="30" string="the" />
            <token id="31" string="National" />
            <token id="32" string="Journal" />
            <token id="33" string="'s" />
            <token id="34" string="Neal" />
            <token id="35" string="Peirce" />
            <token id="36" string="and" />
            <token id="37" string="Time" />
            <token id="38" string="magazine" />
            <token id="39" string="'s" />
            <token id="40" string="Michael" />
            <token id="41" string="Kramer" />
          </tokens>
        </chunking>
        <chunking id="11" string="card-carrying Republicans" type="NP">
          <tokens>
            <token id="14" string="card-carrying" />
            <token id="15" string="Republicans" />
          </tokens>
        </chunking>
        <chunking id="12" string="being card-carrying Republicans" type="VP">
          <tokens>
            <token id="13" string="being" />
            <token id="14" string="card-carrying" />
            <token id="15" string="Republicans" />
          </tokens>
        </chunking>
        <chunking id="13" string="Washington Post columnist Richard Cohen , syndicated columnist Richard Reeves , the National Journal 's Neal Peirce and Time magazine 's Michael Kramer" type="NP">
          <tokens>
            <token id="19" string="Washington" />
            <token id="20" string="Post" />
            <token id="21" string="columnist" />
            <token id="22" string="Richard" />
            <token id="23" string="Cohen" />
            <token id="24" string="," />
            <token id="25" string="syndicated" />
            <token id="26" string="columnist" />
            <token id="27" string="Richard" />
            <token id="28" string="Reeves" />
            <token id="29" string="," />
            <token id="30" string="the" />
            <token id="31" string="National" />
            <token id="32" string="Journal" />
            <token id="33" string="'s" />
            <token id="34" string="Neal" />
            <token id="35" string="Peirce" />
            <token id="36" string="and" />
            <token id="37" string="Time" />
            <token id="38" string="magazine" />
            <token id="39" string="'s" />
            <token id="40" string="Michael" />
            <token id="41" string="Kramer" />
          </tokens>
        </chunking>
        <chunking id="14" string="have" type="VP">
          <tokens>
            <token id="4" string="have" />
          </tokens>
        </chunking>
        <chunking id="15" string="will never be accused of being card-carrying Republicans" type="VP">
          <tokens>
            <token id="8" string="will" />
            <token id="9" string="never" />
            <token id="10" string="be" />
            <token id="11" string="accused" />
            <token id="12" string="of" />
            <token id="13" string="being" />
            <token id="14" string="card-carrying" />
            <token id="15" string="Republicans" />
          </tokens>
        </chunking>
        <chunking id="16" string="columnist Richard Reeves" type="NP">
          <tokens>
            <token id="26" string="columnist" />
            <token id="27" string="Richard" />
            <token id="28" string="Reeves" />
          </tokens>
        </chunking>
        <chunking id="17" string="who have" type="SBAR">
          <tokens>
            <token id="3" string="who" />
            <token id="4" string="have" />
          </tokens>
        </chunking>
        <chunking id="18" string="who have , and who will never be accused of being card-carrying Republicans" type="SBAR">
          <tokens>
            <token id="3" string="who" />
            <token id="4" string="have" />
            <token id="5" string="," />
            <token id="6" string="and" />
            <token id="7" string="who" />
            <token id="8" string="will" />
            <token id="9" string="never" />
            <token id="10" string="be" />
            <token id="11" string="accused" />
            <token id="12" string="of" />
            <token id="13" string="being" />
            <token id="14" string="card-carrying" />
            <token id="15" string="Republicans" />
          </tokens>
        </chunking>
        <chunking id="19" string="the National Journal 's Neal Peirce" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="National" />
            <token id="32" string="Journal" />
            <token id="33" string="'s" />
            <token id="34" string="Neal" />
            <token id="35" string="Peirce" />
          </tokens>
        </chunking>
        <chunking id="20" string="the National Journal 's" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="National" />
            <token id="32" string="Journal" />
            <token id="33" string="'s" />
          </tokens>
        </chunking>
        <chunking id="21" string="those" type="NP">
          <tokens>
            <token id="2" string="those" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">those</governor>
          <dependent id="1">Among</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">Cohen</governor>
          <dependent id="2">those</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">have</governor>
          <dependent id="3">who</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="23">Cohen</governor>
          <dependent id="4">have</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">have</governor>
          <dependent id="6">and</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="11">accused</governor>
          <dependent id="7">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">accused</governor>
          <dependent id="8">will</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="11">accused</governor>
          <dependent id="9">never</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="11">accused</governor>
          <dependent id="10">be</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">have</governor>
          <dependent id="11">accused</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">Republicans</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="15">Republicans</governor>
          <dependent id="13">being</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">Republicans</governor>
          <dependent id="14">card-carrying</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">accused</governor>
          <dependent id="15">Republicans</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="23">Cohen</governor>
          <dependent id="17">are</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">Cohen</governor>
          <dependent id="19">Washington</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">Cohen</governor>
          <dependent id="20">Post</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">Cohen</governor>
          <dependent id="21">columnist</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">Cohen</governor>
          <dependent id="22">Richard</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="23">Cohen</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="23">Cohen</governor>
          <dependent id="25">syndicated</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">Reeves</governor>
          <dependent id="26">columnist</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">Reeves</governor>
          <dependent id="27">Richard</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">syndicated</governor>
          <dependent id="28">Reeves</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">Journal</governor>
          <dependent id="30">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="32">Journal</governor>
          <dependent id="31">National</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="35">Peirce</governor>
          <dependent id="32">Journal</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">Journal</governor>
          <dependent id="33">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">Peirce</governor>
          <dependent id="34">Neal</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="28">Reeves</governor>
          <dependent id="35">Peirce</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="35">Peirce</governor>
          <dependent id="36">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="38">magazine</governor>
          <dependent id="37">Time</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="41">Kramer</governor>
          <dependent id="38">magazine</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">magazine</governor>
          <dependent id="39">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="41">Kramer</governor>
          <dependent id="40">Michael</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="35">Peirce</governor>
          <dependent id="41">Kramer</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Republicans" type="MISC" score="0.0">
          <tokens>
            <token id="15" string="Republicans" />
          </tokens>
        </entity>
        <entity id="2" string="Richard Reeves" type="PERSON" score="0.0">
          <tokens>
            <token id="27" string="Richard" />
            <token id="28" string="Reeves" />
          </tokens>
        </entity>
        <entity id="3" string="Michael Kramer" type="PERSON" score="0.0">
          <tokens>
            <token id="40" string="Michael" />
            <token id="41" string="Kramer" />
          </tokens>
        </entity>
        <entity id="4" string="Time magazine" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="37" string="Time" />
            <token id="38" string="magazine" />
          </tokens>
        </entity>
        <entity id="5" string="Richard Cohen" type="PERSON" score="0.0">
          <tokens>
            <token id="22" string="Richard" />
            <token id="23" string="Cohen" />
          </tokens>
        </entity>
        <entity id="6" string="National Journal" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="31" string="National" />
            <token id="32" string="Journal" />
          </tokens>
        </entity>
        <entity id="7" string="Neal Peirce" type="PERSON" score="0.0">
          <tokens>
            <token id="34" string="Neal" />
            <token id="35" string="Peirce" />
          </tokens>
        </entity>
        <entity id="8" string="Washington Post" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="19" string="Washington" />
            <token id="20" string="Post" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="31" has_coreference="true">
      <content>Hendrik Hertzberg, a former speechwriter for Jimmy Carter who edited the New Republic until last month, agrees term limits would mean a loss of some distinguished legislators.</content>
      <tokens>
        <token id="1" string="Hendrik" lemma="Hendrik" stem="hendrik" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Hertzberg" lemma="Hertzberg" stem="hertzberg" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="former" lemma="former" stem="former" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="speechwriter" lemma="speechwriter" stem="speechwrit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Jimmy" lemma="Jimmy" stem="jimmi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="9" string="Carter" lemma="Carter" stem="carter" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="10" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="edited" lemma="edit" stem="edit" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="New" lemma="New" stem="new" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="14" string="Republic" lemma="Republic" stem="republ" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="15" string="until" lemma="until" stem="until" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="17" string="month" lemma="month" stem="month" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="agrees" lemma="agree" stem="agre" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="term" lemma="term" stem="term" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="limits" lemma="limit" stem="limit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="mean" lemma="mean" stem="mean" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="loss" lemma="loss" stem="loss" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="28" string="distinguished" lemma="distinguished" stem="distinguish" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="legislators" lemma="legislator" stem="legisl" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Hendrik) (NNP Hertzberg)) (, ,) (NP (NP (DT a) (JJ former) (NN speechwriter)) (PP (IN for) (NP (NP (NNP Jimmy) (NNP Carter)) (SBAR (WHNP (WP who)) (S (VP (VBD edited) (NP (DT the) (NNP New) (NNP Republic)) (PP (IN until) (NP (JJ last) (NN month))))))))) (, ,)) (VP (VBZ agrees) (SBAR (S (NP (NN term) (NNS limits)) (VP (MD would) (VP (VB mean) (NP (NP (DT a) (NN loss)) (PP (IN of) (NP (DT some) (JJ distinguished) (NNS legislators))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="who edited the New Republic until last month" type="SBAR">
          <tokens>
            <token id="10" string="who" />
            <token id="11" string="edited" />
            <token id="12" string="the" />
            <token id="13" string="New" />
            <token id="14" string="Republic" />
            <token id="15" string="until" />
            <token id="16" string="last" />
            <token id="17" string="month" />
          </tokens>
        </chunking>
        <chunking id="2" string="edited the New Republic until last month" type="VP">
          <tokens>
            <token id="11" string="edited" />
            <token id="12" string="the" />
            <token id="13" string="New" />
            <token id="14" string="Republic" />
            <token id="15" string="until" />
            <token id="16" string="last" />
            <token id="17" string="month" />
          </tokens>
        </chunking>
        <chunking id="3" string="last month" type="NP">
          <tokens>
            <token id="16" string="last" />
            <token id="17" string="month" />
          </tokens>
        </chunking>
        <chunking id="4" string="a former speechwriter" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="former" />
            <token id="6" string="speechwriter" />
          </tokens>
        </chunking>
        <chunking id="5" string="Jimmy Carter who edited the New Republic until last month" type="NP">
          <tokens>
            <token id="8" string="Jimmy" />
            <token id="9" string="Carter" />
            <token id="10" string="who" />
            <token id="11" string="edited" />
            <token id="12" string="the" />
            <token id="13" string="New" />
            <token id="14" string="Republic" />
            <token id="15" string="until" />
            <token id="16" string="last" />
            <token id="17" string="month" />
          </tokens>
        </chunking>
        <chunking id="6" string="term limits" type="NP">
          <tokens>
            <token id="20" string="term" />
            <token id="21" string="limits" />
          </tokens>
        </chunking>
        <chunking id="7" string="term limits would mean a loss of some distinguished legislators" type="SBAR">
          <tokens>
            <token id="20" string="term" />
            <token id="21" string="limits" />
            <token id="22" string="would" />
            <token id="23" string="mean" />
            <token id="24" string="a" />
            <token id="25" string="loss" />
            <token id="26" string="of" />
            <token id="27" string="some" />
            <token id="28" string="distinguished" />
            <token id="29" string="legislators" />
          </tokens>
        </chunking>
        <chunking id="8" string="mean a loss of some distinguished legislators" type="VP">
          <tokens>
            <token id="23" string="mean" />
            <token id="24" string="a" />
            <token id="25" string="loss" />
            <token id="26" string="of" />
            <token id="27" string="some" />
            <token id="28" string="distinguished" />
            <token id="29" string="legislators" />
          </tokens>
        </chunking>
        <chunking id="9" string="a loss of some distinguished legislators" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="loss" />
            <token id="26" string="of" />
            <token id="27" string="some" />
            <token id="28" string="distinguished" />
            <token id="29" string="legislators" />
          </tokens>
        </chunking>
        <chunking id="10" string="Hendrik Hertzberg , a former speechwriter for Jimmy Carter who edited the New Republic until last month ," type="NP">
          <tokens>
            <token id="1" string="Hendrik" />
            <token id="2" string="Hertzberg" />
            <token id="3" string="," />
            <token id="4" string="a" />
            <token id="5" string="former" />
            <token id="6" string="speechwriter" />
            <token id="7" string="for" />
            <token id="8" string="Jimmy" />
            <token id="9" string="Carter" />
            <token id="10" string="who" />
            <token id="11" string="edited" />
            <token id="12" string="the" />
            <token id="13" string="New" />
            <token id="14" string="Republic" />
            <token id="15" string="until" />
            <token id="16" string="last" />
            <token id="17" string="month" />
            <token id="18" string="," />
          </tokens>
        </chunking>
        <chunking id="11" string="Jimmy Carter" type="NP">
          <tokens>
            <token id="8" string="Jimmy" />
            <token id="9" string="Carter" />
          </tokens>
        </chunking>
        <chunking id="12" string="some distinguished legislators" type="NP">
          <tokens>
            <token id="27" string="some" />
            <token id="28" string="distinguished" />
            <token id="29" string="legislators" />
          </tokens>
        </chunking>
        <chunking id="13" string="the New Republic" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="New" />
            <token id="14" string="Republic" />
          </tokens>
        </chunking>
        <chunking id="14" string="would mean a loss of some distinguished legislators" type="VP">
          <tokens>
            <token id="22" string="would" />
            <token id="23" string="mean" />
            <token id="24" string="a" />
            <token id="25" string="loss" />
            <token id="26" string="of" />
            <token id="27" string="some" />
            <token id="28" string="distinguished" />
            <token id="29" string="legislators" />
          </tokens>
        </chunking>
        <chunking id="15" string="Hendrik Hertzberg" type="NP">
          <tokens>
            <token id="1" string="Hendrik" />
            <token id="2" string="Hertzberg" />
          </tokens>
        </chunking>
        <chunking id="16" string="a former speechwriter for Jimmy Carter who edited the New Republic until last month" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="former" />
            <token id="6" string="speechwriter" />
            <token id="7" string="for" />
            <token id="8" string="Jimmy" />
            <token id="9" string="Carter" />
            <token id="10" string="who" />
            <token id="11" string="edited" />
            <token id="12" string="the" />
            <token id="13" string="New" />
            <token id="14" string="Republic" />
            <token id="15" string="until" />
            <token id="16" string="last" />
            <token id="17" string="month" />
          </tokens>
        </chunking>
        <chunking id="17" string="agrees term limits would mean a loss of some distinguished legislators" type="VP">
          <tokens>
            <token id="19" string="agrees" />
            <token id="20" string="term" />
            <token id="21" string="limits" />
            <token id="22" string="would" />
            <token id="23" string="mean" />
            <token id="24" string="a" />
            <token id="25" string="loss" />
            <token id="26" string="of" />
            <token id="27" string="some" />
            <token id="28" string="distinguished" />
            <token id="29" string="legislators" />
          </tokens>
        </chunking>
        <chunking id="18" string="a loss" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="loss" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Hertzberg</governor>
          <dependent id="1">Hendrik</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">agrees</governor>
          <dependent id="2">Hertzberg</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">speechwriter</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">speechwriter</governor>
          <dependent id="5">former</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">Hertzberg</governor>
          <dependent id="6">speechwriter</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Carter</governor>
          <dependent id="7">for</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Carter</governor>
          <dependent id="8">Jimmy</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">speechwriter</governor>
          <dependent id="9">Carter</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">edited</governor>
          <dependent id="10">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="9">Carter</governor>
          <dependent id="11">edited</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">Republic</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Republic</governor>
          <dependent id="13">New</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">edited</governor>
          <dependent id="14">Republic</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">month</governor>
          <dependent id="15">until</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">month</governor>
          <dependent id="16">last</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">edited</governor>
          <dependent id="17">month</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="19">agrees</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">limits</governor>
          <dependent id="20">term</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">mean</governor>
          <dependent id="21">limits</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="23">mean</governor>
          <dependent id="22">would</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">agrees</governor>
          <dependent id="23">mean</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">loss</governor>
          <dependent id="24">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">mean</governor>
          <dependent id="25">loss</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">legislators</governor>
          <dependent id="26">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">legislators</governor>
          <dependent id="27">some</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">legislators</governor>
          <dependent id="28">distinguished</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">loss</governor>
          <dependent id="29">legislators</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Jimmy Carter" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Jimmy" />
            <token id="9" string="Carter" />
          </tokens>
        </entity>
        <entity id="2" string="New Republic" type="LOCATION" score="0.0">
          <tokens>
            <token id="13" string="New" />
            <token id="14" string="Republic" />
          </tokens>
        </entity>
        <entity id="3" string="last month" type="DATE" score="0.0">
          <tokens>
            <token id="16" string="last" />
            <token id="17" string="month" />
          </tokens>
        </entity>
        <entity id="4" string="Hendrik Hertzberg" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Hendrik" />
            <token id="2" string="Hertzberg" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="32" has_coreference="true">
      <content>However, he concludes &amp;quot;it would be a cost worth paying to be rid of the much larger number of time-servers who have learned nothing from longevity in office except cynicism, complacency and a sense of diminished possibility.&amp;quot;</content>
      <tokens>
        <token id="1" string="However" lemma="however" stem="howev" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="concludes" lemma="conclude" stem="conclud" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="cost" lemma="cost" stem="cost" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="worth" lemma="worth" stem="worth" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="paying" lemma="pay" stem="pai" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="rid" lemma="rid" stem="rid" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="much" lemma="much" stem="much" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="larger" lemma="larger" stem="larger" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="number" lemma="number" stem="number" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="time-servers" lemma="time-server" stem="time-serv" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="23" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="learned" lemma="learn" stem="learn" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="26" string="nothing" lemma="nothing" stem="noth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="27" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="28" string="longevity" lemma="longevity" stem="longev" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="29" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="30" string="office" lemma="office" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="31" string="except" lemma="except" stem="except" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="32" string="cynicism" lemma="cynicism" stem="cynic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="33" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="34" string="complacency" lemma="complacency" stem="complac" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="35" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="36" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="37" string="sense" lemma="sense" stem="sens" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="38" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="39" string="diminished" lemma="diminish" stem="diminish" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="40" string="possibility" lemma="possibility" stem="possibl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="41" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB However)) (, ,) (NP (PRP he)) (VP (VBZ concludes) (S (`` ``) (NP (PRP it)) (VP (MD would) (VP (VB be) (NP (NP (DT a) (NN cost)) (PP (JJ worth) (S (VP (VBG paying) (S (VP (TO to) (VP (VB be) (ADJP (JJ rid) (PP (IN of) (NP (NP (DT the) (JJ much) (JJR larger) (NN number)) (PP (IN of) (NP (NP (NNS time-servers)) (SBAR (WHNP (WP who)) (S (VP (VBP have) (VP (VBN learned) (NP (NN nothing)) (PP (IN from) (NP (NP (NN longevity)) (PP (IN in) (NP (NP (NN office)) (PP (IN except) (NP (NP (NN cynicism)) (, ,) (NP (NN complacency)) (CC and) (NP (DT a) (NN sense)))))) (PP (IN of) (NP (ADJP (VBN diminished)) (NN possibility))))))))))))))))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="cynicism" type="NP">
          <tokens>
            <token id="32" string="cynicism" />
          </tokens>
        </chunking>
        <chunking id="2" string="have learned nothing from longevity in office except cynicism , complacency and a sense of diminished possibility" type="VP">
          <tokens>
            <token id="24" string="have" />
            <token id="25" string="learned" />
            <token id="26" string="nothing" />
            <token id="27" string="from" />
            <token id="28" string="longevity" />
            <token id="29" string="in" />
            <token id="30" string="office" />
            <token id="31" string="except" />
            <token id="32" string="cynicism" />
            <token id="33" string="," />
            <token id="34" string="complacency" />
            <token id="35" string="and" />
            <token id="36" string="a" />
            <token id="37" string="sense" />
            <token id="38" string="of" />
            <token id="39" string="diminished" />
            <token id="40" string="possibility" />
          </tokens>
        </chunking>
        <chunking id="3" string="time-servers" type="NP">
          <tokens>
            <token id="22" string="time-servers" />
          </tokens>
        </chunking>
        <chunking id="4" string="nothing" type="NP">
          <tokens>
            <token id="26" string="nothing" />
          </tokens>
        </chunking>
        <chunking id="5" string="time-servers who have learned nothing from longevity in office except cynicism , complacency and a sense of diminished possibility" type="NP">
          <tokens>
            <token id="22" string="time-servers" />
            <token id="23" string="who" />
            <token id="24" string="have" />
            <token id="25" string="learned" />
            <token id="26" string="nothing" />
            <token id="27" string="from" />
            <token id="28" string="longevity" />
            <token id="29" string="in" />
            <token id="30" string="office" />
            <token id="31" string="except" />
            <token id="32" string="cynicism" />
            <token id="33" string="," />
            <token id="34" string="complacency" />
            <token id="35" string="and" />
            <token id="36" string="a" />
            <token id="37" string="sense" />
            <token id="38" string="of" />
            <token id="39" string="diminished" />
            <token id="40" string="possibility" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="6" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="the much larger number" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="much" />
            <token id="19" string="larger" />
            <token id="20" string="number" />
          </tokens>
        </chunking>
        <chunking id="8" string="would be a cost worth paying to be rid of the much larger number of time-servers who have learned nothing from longevity in office except cynicism , complacency and a sense of diminished possibility" type="VP">
          <tokens>
            <token id="7" string="would" />
            <token id="8" string="be" />
            <token id="9" string="a" />
            <token id="10" string="cost" />
            <token id="11" string="worth" />
            <token id="12" string="paying" />
            <token id="13" string="to" />
            <token id="14" string="be" />
            <token id="15" string="rid" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="much" />
            <token id="19" string="larger" />
            <token id="20" string="number" />
            <token id="21" string="of" />
            <token id="22" string="time-servers" />
            <token id="23" string="who" />
            <token id="24" string="have" />
            <token id="25" string="learned" />
            <token id="26" string="nothing" />
            <token id="27" string="from" />
            <token id="28" string="longevity" />
            <token id="29" string="in" />
            <token id="30" string="office" />
            <token id="31" string="except" />
            <token id="32" string="cynicism" />
            <token id="33" string="," />
            <token id="34" string="complacency" />
            <token id="35" string="and" />
            <token id="36" string="a" />
            <token id="37" string="sense" />
            <token id="38" string="of" />
            <token id="39" string="diminished" />
            <token id="40" string="possibility" />
          </tokens>
        </chunking>
        <chunking id="9" string="who have learned nothing from longevity in office except cynicism , complacency and a sense of diminished possibility" type="SBAR">
          <tokens>
            <token id="23" string="who" />
            <token id="24" string="have" />
            <token id="25" string="learned" />
            <token id="26" string="nothing" />
            <token id="27" string="from" />
            <token id="28" string="longevity" />
            <token id="29" string="in" />
            <token id="30" string="office" />
            <token id="31" string="except" />
            <token id="32" string="cynicism" />
            <token id="33" string="," />
            <token id="34" string="complacency" />
            <token id="35" string="and" />
            <token id="36" string="a" />
            <token id="37" string="sense" />
            <token id="38" string="of" />
            <token id="39" string="diminished" />
            <token id="40" string="possibility" />
          </tokens>
        </chunking>
        <chunking id="10" string="office except cynicism , complacency and a sense" type="NP">
          <tokens>
            <token id="30" string="office" />
            <token id="31" string="except" />
            <token id="32" string="cynicism" />
            <token id="33" string="," />
            <token id="34" string="complacency" />
            <token id="35" string="and" />
            <token id="36" string="a" />
            <token id="37" string="sense" />
          </tokens>
        </chunking>
        <chunking id="11" string="learned nothing from longevity in office except cynicism , complacency and a sense of diminished possibility" type="VP">
          <tokens>
            <token id="25" string="learned" />
            <token id="26" string="nothing" />
            <token id="27" string="from" />
            <token id="28" string="longevity" />
            <token id="29" string="in" />
            <token id="30" string="office" />
            <token id="31" string="except" />
            <token id="32" string="cynicism" />
            <token id="33" string="," />
            <token id="34" string="complacency" />
            <token id="35" string="and" />
            <token id="36" string="a" />
            <token id="37" string="sense" />
            <token id="38" string="of" />
            <token id="39" string="diminished" />
            <token id="40" string="possibility" />
          </tokens>
        </chunking>
        <chunking id="12" string="be rid of the much larger number of time-servers who have learned nothing from longevity in office except cynicism , complacency and a sense of diminished possibility" type="VP">
          <tokens>
            <token id="14" string="be" />
            <token id="15" string="rid" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="much" />
            <token id="19" string="larger" />
            <token id="20" string="number" />
            <token id="21" string="of" />
            <token id="22" string="time-servers" />
            <token id="23" string="who" />
            <token id="24" string="have" />
            <token id="25" string="learned" />
            <token id="26" string="nothing" />
            <token id="27" string="from" />
            <token id="28" string="longevity" />
            <token id="29" string="in" />
            <token id="30" string="office" />
            <token id="31" string="except" />
            <token id="32" string="cynicism" />
            <token id="33" string="," />
            <token id="34" string="complacency" />
            <token id="35" string="and" />
            <token id="36" string="a" />
            <token id="37" string="sense" />
            <token id="38" string="of" />
            <token id="39" string="diminished" />
            <token id="40" string="possibility" />
          </tokens>
        </chunking>
        <chunking id="13" string="concludes `` it would be a cost worth paying to be rid of the much larger number of time-servers who have learned nothing from longevity in office except cynicism , complacency and a sense of diminished possibility" type="VP">
          <tokens>
            <token id="4" string="concludes" />
            <token id="5" string="&quot;" />
            <token id="6" string="it" />
            <token id="7" string="would" />
            <token id="8" string="be" />
            <token id="9" string="a" />
            <token id="10" string="cost" />
            <token id="11" string="worth" />
            <token id="12" string="paying" />
            <token id="13" string="to" />
            <token id="14" string="be" />
            <token id="15" string="rid" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="much" />
            <token id="19" string="larger" />
            <token id="20" string="number" />
            <token id="21" string="of" />
            <token id="22" string="time-servers" />
            <token id="23" string="who" />
            <token id="24" string="have" />
            <token id="25" string="learned" />
            <token id="26" string="nothing" />
            <token id="27" string="from" />
            <token id="28" string="longevity" />
            <token id="29" string="in" />
            <token id="30" string="office" />
            <token id="31" string="except" />
            <token id="32" string="cynicism" />
            <token id="33" string="," />
            <token id="34" string="complacency" />
            <token id="35" string="and" />
            <token id="36" string="a" />
            <token id="37" string="sense" />
            <token id="38" string="of" />
            <token id="39" string="diminished" />
            <token id="40" string="possibility" />
          </tokens>
        </chunking>
        <chunking id="14" string="a sense" type="NP">
          <tokens>
            <token id="36" string="a" />
            <token id="37" string="sense" />
          </tokens>
        </chunking>
        <chunking id="15" string="longevity in office except cynicism , complacency and a sense of diminished possibility" type="NP">
          <tokens>
            <token id="28" string="longevity" />
            <token id="29" string="in" />
            <token id="30" string="office" />
            <token id="31" string="except" />
            <token id="32" string="cynicism" />
            <token id="33" string="," />
            <token id="34" string="complacency" />
            <token id="35" string="and" />
            <token id="36" string="a" />
            <token id="37" string="sense" />
            <token id="38" string="of" />
            <token id="39" string="diminished" />
            <token id="40" string="possibility" />
          </tokens>
        </chunking>
        <chunking id="16" string="diminished possibility" type="NP">
          <tokens>
            <token id="39" string="diminished" />
            <token id="40" string="possibility" />
          </tokens>
        </chunking>
        <chunking id="17" string="he" type="NP">
          <tokens>
            <token id="3" string="he" />
          </tokens>
        </chunking>
        <chunking id="18" string="rid of the much larger number of time-servers who have learned nothing from longevity in office except cynicism , complacency and a sense of diminished possibility" type="ADJP">
          <tokens>
            <token id="15" string="rid" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="much" />
            <token id="19" string="larger" />
            <token id="20" string="number" />
            <token id="21" string="of" />
            <token id="22" string="time-servers" />
            <token id="23" string="who" />
            <token id="24" string="have" />
            <token id="25" string="learned" />
            <token id="26" string="nothing" />
            <token id="27" string="from" />
            <token id="28" string="longevity" />
            <token id="29" string="in" />
            <token id="30" string="office" />
            <token id="31" string="except" />
            <token id="32" string="cynicism" />
            <token id="33" string="," />
            <token id="34" string="complacency" />
            <token id="35" string="and" />
            <token id="36" string="a" />
            <token id="37" string="sense" />
            <token id="38" string="of" />
            <token id="39" string="diminished" />
            <token id="40" string="possibility" />
          </tokens>
        </chunking>
        <chunking id="19" string="paying to be rid of the much larger number of time-servers who have learned nothing from longevity in office except cynicism , complacency and a sense of diminished possibility" type="VP">
          <tokens>
            <token id="12" string="paying" />
            <token id="13" string="to" />
            <token id="14" string="be" />
            <token id="15" string="rid" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="much" />
            <token id="19" string="larger" />
            <token id="20" string="number" />
            <token id="21" string="of" />
            <token id="22" string="time-servers" />
            <token id="23" string="who" />
            <token id="24" string="have" />
            <token id="25" string="learned" />
            <token id="26" string="nothing" />
            <token id="27" string="from" />
            <token id="28" string="longevity" />
            <token id="29" string="in" />
            <token id="30" string="office" />
            <token id="31" string="except" />
            <token id="32" string="cynicism" />
            <token id="33" string="," />
            <token id="34" string="complacency" />
            <token id="35" string="and" />
            <token id="36" string="a" />
            <token id="37" string="sense" />
            <token id="38" string="of" />
            <token id="39" string="diminished" />
            <token id="40" string="possibility" />
          </tokens>
        </chunking>
        <chunking id="20" string="complacency" type="NP">
          <tokens>
            <token id="34" string="complacency" />
          </tokens>
        </chunking>
        <chunking id="21" string="the much larger number of time-servers who have learned nothing from longevity in office except cynicism , complacency and a sense of diminished possibility" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="much" />
            <token id="19" string="larger" />
            <token id="20" string="number" />
            <token id="21" string="of" />
            <token id="22" string="time-servers" />
            <token id="23" string="who" />
            <token id="24" string="have" />
            <token id="25" string="learned" />
            <token id="26" string="nothing" />
            <token id="27" string="from" />
            <token id="28" string="longevity" />
            <token id="29" string="in" />
            <token id="30" string="office" />
            <token id="31" string="except" />
            <token id="32" string="cynicism" />
            <token id="33" string="," />
            <token id="34" string="complacency" />
            <token id="35" string="and" />
            <token id="36" string="a" />
            <token id="37" string="sense" />
            <token id="38" string="of" />
            <token id="39" string="diminished" />
            <token id="40" string="possibility" />
          </tokens>
        </chunking>
        <chunking id="22" string="office" type="NP">
          <tokens>
            <token id="30" string="office" />
          </tokens>
        </chunking>
        <chunking id="23" string="diminished" type="ADJP">
          <tokens>
            <token id="39" string="diminished" />
          </tokens>
        </chunking>
        <chunking id="24" string="cynicism , complacency and a sense" type="NP">
          <tokens>
            <token id="32" string="cynicism" />
            <token id="33" string="," />
            <token id="34" string="complacency" />
            <token id="35" string="and" />
            <token id="36" string="a" />
            <token id="37" string="sense" />
          </tokens>
        </chunking>
        <chunking id="25" string="longevity" type="NP">
          <tokens>
            <token id="28" string="longevity" />
          </tokens>
        </chunking>
        <chunking id="26" string="a cost" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="cost" />
          </tokens>
        </chunking>
        <chunking id="27" string="a cost worth paying to be rid of the much larger number of time-servers who have learned nothing from longevity in office except cynicism , complacency and a sense of diminished possibility" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="cost" />
            <token id="11" string="worth" />
            <token id="12" string="paying" />
            <token id="13" string="to" />
            <token id="14" string="be" />
            <token id="15" string="rid" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="much" />
            <token id="19" string="larger" />
            <token id="20" string="number" />
            <token id="21" string="of" />
            <token id="22" string="time-servers" />
            <token id="23" string="who" />
            <token id="24" string="have" />
            <token id="25" string="learned" />
            <token id="26" string="nothing" />
            <token id="27" string="from" />
            <token id="28" string="longevity" />
            <token id="29" string="in" />
            <token id="30" string="office" />
            <token id="31" string="except" />
            <token id="32" string="cynicism" />
            <token id="33" string="," />
            <token id="34" string="complacency" />
            <token id="35" string="and" />
            <token id="36" string="a" />
            <token id="37" string="sense" />
            <token id="38" string="of" />
            <token id="39" string="diminished" />
            <token id="40" string="possibility" />
          </tokens>
        </chunking>
        <chunking id="28" string="to be rid of the much larger number of time-servers who have learned nothing from longevity in office except cynicism , complacency and a sense of diminished possibility" type="VP">
          <tokens>
            <token id="13" string="to" />
            <token id="14" string="be" />
            <token id="15" string="rid" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="much" />
            <token id="19" string="larger" />
            <token id="20" string="number" />
            <token id="21" string="of" />
            <token id="22" string="time-servers" />
            <token id="23" string="who" />
            <token id="24" string="have" />
            <token id="25" string="learned" />
            <token id="26" string="nothing" />
            <token id="27" string="from" />
            <token id="28" string="longevity" />
            <token id="29" string="in" />
            <token id="30" string="office" />
            <token id="31" string="except" />
            <token id="32" string="cynicism" />
            <token id="33" string="," />
            <token id="34" string="complacency" />
            <token id="35" string="and" />
            <token id="36" string="a" />
            <token id="37" string="sense" />
            <token id="38" string="of" />
            <token id="39" string="diminished" />
            <token id="40" string="possibility" />
          </tokens>
        </chunking>
        <chunking id="29" string="be a cost worth paying to be rid of the much larger number of time-servers who have learned nothing from longevity in office except cynicism , complacency and a sense of diminished possibility" type="VP">
          <tokens>
            <token id="8" string="be" />
            <token id="9" string="a" />
            <token id="10" string="cost" />
            <token id="11" string="worth" />
            <token id="12" string="paying" />
            <token id="13" string="to" />
            <token id="14" string="be" />
            <token id="15" string="rid" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="much" />
            <token id="19" string="larger" />
            <token id="20" string="number" />
            <token id="21" string="of" />
            <token id="22" string="time-servers" />
            <token id="23" string="who" />
            <token id="24" string="have" />
            <token id="25" string="learned" />
            <token id="26" string="nothing" />
            <token id="27" string="from" />
            <token id="28" string="longevity" />
            <token id="29" string="in" />
            <token id="30" string="office" />
            <token id="31" string="except" />
            <token id="32" string="cynicism" />
            <token id="33" string="," />
            <token id="34" string="complacency" />
            <token id="35" string="and" />
            <token id="36" string="a" />
            <token id="37" string="sense" />
            <token id="38" string="of" />
            <token id="39" string="diminished" />
            <token id="40" string="possibility" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="4">concludes</governor>
          <dependent id="1">However</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">concludes</governor>
          <dependent id="3">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">concludes</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">cost</governor>
          <dependent id="6">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">cost</governor>
          <dependent id="7">would</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="10">cost</governor>
          <dependent id="8">be</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">cost</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">concludes</governor>
          <dependent id="10">cost</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">paying</governor>
          <dependent id="11">worth</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="10">cost</governor>
          <dependent id="12">paying</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">rid</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="15">rid</governor>
          <dependent id="14">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="12">paying</governor>
          <dependent id="15">rid</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">number</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">number</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">number</governor>
          <dependent id="18">much</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">number</governor>
          <dependent id="19">larger</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">rid</governor>
          <dependent id="20">number</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">time-servers</governor>
          <dependent id="21">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">number</governor>
          <dependent id="22">time-servers</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">learned</governor>
          <dependent id="23">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="25">learned</governor>
          <dependent id="24">have</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="22">time-servers</governor>
          <dependent id="25">learned</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">learned</governor>
          <dependent id="26">nothing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">longevity</governor>
          <dependent id="27">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">learned</governor>
          <dependent id="28">longevity</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">office</governor>
          <dependent id="29">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">longevity</governor>
          <dependent id="30">office</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">cynicism</governor>
          <dependent id="31">except</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">office</governor>
          <dependent id="32">cynicism</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="32">cynicism</governor>
          <dependent id="34">complacency</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="32">cynicism</governor>
          <dependent id="35">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="37">sense</governor>
          <dependent id="36">a</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="32">cynicism</governor>
          <dependent id="37">sense</dependent>
        </dependency>
        <dependency type="case">
          <governor id="40">possibility</governor>
          <dependent id="38">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="40">possibility</governor>
          <dependent id="39">diminished</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">longevity</governor>
          <dependent id="40">possibility</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="33" has_coreference="true">
      <content>Columnist Ellen Goodman says &amp;quot;We have to learn once again that ideal public service is, by definition, temporary.&amp;quot;</content>
      <tokens>
        <token id="1" string="Columnist" lemma="Columnist" stem="columnist" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="true" is_refers="false" />
        <token id="2" string="Ellen" lemma="Ellen" stem="ellen" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="Goodman" lemma="Goodman" stem="goodman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="learn" lemma="learn" stem="learn" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="once" lemma="once" stem="onc" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="11" string="again" lemma="again" stem="again" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="ideal" lemma="ideal" stem="ideal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="public" lemma="public" stem="public" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="service" lemma="service" stem="servic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="definition" lemma="definition" stem="definit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="temporary" lemma="temporary" stem="temporari" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Columnist) (NNP Ellen) (NNP Goodman)) (VP (VBZ says) (S (`` ``) (NP (PRP We)) (VP (VBP have) (S (VP (TO to) (VP (VB learn) (ADVP (ADVP (RB once) (RB again)) (SBAR (IN that) (S (NP (JJ ideal) (JJ public) (NN service)) (VP (VBZ is) (ADJP (PRN (, ,) (PP (IN by) (NP (NN definition))) (, ,)) (JJ temporary)))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="to learn once again that ideal public service is , by definition , temporary" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="learn" />
            <token id="10" string="once" />
            <token id="11" string="again" />
            <token id="12" string="that" />
            <token id="13" string="ideal" />
            <token id="14" string="public" />
            <token id="15" string="service" />
            <token id="16" string="is" />
            <token id="17" string="," />
            <token id="18" string="by" />
            <token id="19" string="definition" />
            <token id="20" string="," />
            <token id="21" string="temporary" />
          </tokens>
        </chunking>
        <chunking id="2" string=", by definition , temporary" type="ADJP">
          <tokens>
            <token id="17" string="," />
            <token id="18" string="by" />
            <token id="19" string="definition" />
            <token id="20" string="," />
            <token id="21" string="temporary" />
          </tokens>
        </chunking>
        <chunking id="3" string="Columnist Ellen Goodman" type="NP">
          <tokens>
            <token id="1" string="Columnist" />
            <token id="2" string="Ellen" />
            <token id="3" string="Goodman" />
          </tokens>
        </chunking>
        <chunking id="4" string="is , by definition , temporary" type="VP">
          <tokens>
            <token id="16" string="is" />
            <token id="17" string="," />
            <token id="18" string="by" />
            <token id="19" string="definition" />
            <token id="20" string="," />
            <token id="21" string="temporary" />
          </tokens>
        </chunking>
        <chunking id="5" string="learn once again that ideal public service is , by definition , temporary" type="VP">
          <tokens>
            <token id="9" string="learn" />
            <token id="10" string="once" />
            <token id="11" string="again" />
            <token id="12" string="that" />
            <token id="13" string="ideal" />
            <token id="14" string="public" />
            <token id="15" string="service" />
            <token id="16" string="is" />
            <token id="17" string="," />
            <token id="18" string="by" />
            <token id="19" string="definition" />
            <token id="20" string="," />
            <token id="21" string="temporary" />
          </tokens>
        </chunking>
        <chunking id="6" string="definition" type="NP">
          <tokens>
            <token id="19" string="definition" />
          </tokens>
        </chunking>
        <chunking id="7" string="says `` We have to learn once again that ideal public service is , by definition , temporary" type="VP">
          <tokens>
            <token id="4" string="says" />
            <token id="5" string="&quot;" />
            <token id="6" string="We" />
            <token id="7" string="have" />
            <token id="8" string="to" />
            <token id="9" string="learn" />
            <token id="10" string="once" />
            <token id="11" string="again" />
            <token id="12" string="that" />
            <token id="13" string="ideal" />
            <token id="14" string="public" />
            <token id="15" string="service" />
            <token id="16" string="is" />
            <token id="17" string="," />
            <token id="18" string="by" />
            <token id="19" string="definition" />
            <token id="20" string="," />
            <token id="21" string="temporary" />
          </tokens>
        </chunking>
        <chunking id="8" string="that ideal public service is , by definition , temporary" type="SBAR">
          <tokens>
            <token id="12" string="that" />
            <token id="13" string="ideal" />
            <token id="14" string="public" />
            <token id="15" string="service" />
            <token id="16" string="is" />
            <token id="17" string="," />
            <token id="18" string="by" />
            <token id="19" string="definition" />
            <token id="20" string="," />
            <token id="21" string="temporary" />
          </tokens>
        </chunking>
        <chunking id="9" string="We" type="NP">
          <tokens>
            <token id="6" string="We" />
          </tokens>
        </chunking>
        <chunking id="10" string="have to learn once again that ideal public service is , by definition , temporary" type="VP">
          <tokens>
            <token id="7" string="have" />
            <token id="8" string="to" />
            <token id="9" string="learn" />
            <token id="10" string="once" />
            <token id="11" string="again" />
            <token id="12" string="that" />
            <token id="13" string="ideal" />
            <token id="14" string="public" />
            <token id="15" string="service" />
            <token id="16" string="is" />
            <token id="17" string="," />
            <token id="18" string="by" />
            <token id="19" string="definition" />
            <token id="20" string="," />
            <token id="21" string="temporary" />
          </tokens>
        </chunking>
        <chunking id="11" string="ideal public service" type="NP">
          <tokens>
            <token id="13" string="ideal" />
            <token id="14" string="public" />
            <token id="15" string="service" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Goodman</governor>
          <dependent id="1">Columnist</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Goodman</governor>
          <dependent id="2">Ellen</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">says</governor>
          <dependent id="3">Goodman</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">says</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">have</governor>
          <dependent id="6">We</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">says</governor>
          <dependent id="7">have</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">learn</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">have</governor>
          <dependent id="9">learn</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">again</governor>
          <dependent id="10">once</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">learn</governor>
          <dependent id="11">again</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">temporary</governor>
          <dependent id="12">that</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">service</governor>
          <dependent id="13">ideal</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">service</governor>
          <dependent id="14">public</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">temporary</governor>
          <dependent id="15">service</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="21">temporary</governor>
          <dependent id="16">is</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">definition</governor>
          <dependent id="18">by</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="21">temporary</governor>
          <dependent id="19">definition</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">again</governor>
          <dependent id="21">temporary</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Columnist" type="TITLE" score="0.0">
          <tokens>
            <token id="1" string="Columnist" />
          </tokens>
        </entity>
        <entity id="2" string="once" type="DATE" score="0.0">
          <tokens>
            <token id="10" string="once" />
          </tokens>
        </entity>
        <entity id="3" string="Ellen Goodman" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Ellen" />
            <token id="3" string="Goodman" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="34" has_coreference="true">
      <content>She thinks the current Congress proves &amp;quot;the politically privileged class has become more isolated than experienced.&amp;quot;</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="thinks" lemma="think" stem="think" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="current" lemma="current" stem="current" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="5" string="Congress" lemma="Congress" stem="congress" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="6" string="proves" lemma="prove" stem="prove" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="politically" lemma="politically" stem="polit" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="privileged" lemma="privileged" stem="privileg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="class" lemma="class" stem="class" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="become" lemma="become" stem="becom" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="isolated" lemma="isolate" stem="isol" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="experienced" lemma="experienced" stem="experienc" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP She)) (VP (VBZ thinks) (SBAR (S (NP (DT the) (JJ current) (NNP Congress)) (VP (VBZ proves) (S (`` ``) (NP (DT the) (RB politically) (JJ privileged) (NN class)) (VP (VBZ has) (VP (VBN become) (S (ADJP (RBR more) (VBN isolated) (PP (IN than) (ADJP (JJ experienced)))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="become more isolated than experienced" type="VP">
          <tokens>
            <token id="13" string="become" />
            <token id="14" string="more" />
            <token id="15" string="isolated" />
            <token id="16" string="than" />
            <token id="17" string="experienced" />
          </tokens>
        </chunking>
        <chunking id="2" string="the current Congress" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="current" />
            <token id="5" string="Congress" />
          </tokens>
        </chunking>
        <chunking id="3" string="the current Congress proves `` the politically privileged class has become more isolated than experienced" type="SBAR">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="current" />
            <token id="5" string="Congress" />
            <token id="6" string="proves" />
            <token id="7" string="&quot;" />
            <token id="8" string="the" />
            <token id="9" string="politically" />
            <token id="10" string="privileged" />
            <token id="11" string="class" />
            <token id="12" string="has" />
            <token id="13" string="become" />
            <token id="14" string="more" />
            <token id="15" string="isolated" />
            <token id="16" string="than" />
            <token id="17" string="experienced" />
          </tokens>
        </chunking>
        <chunking id="4" string="has become more isolated than experienced" type="VP">
          <tokens>
            <token id="12" string="has" />
            <token id="13" string="become" />
            <token id="14" string="more" />
            <token id="15" string="isolated" />
            <token id="16" string="than" />
            <token id="17" string="experienced" />
          </tokens>
        </chunking>
        <chunking id="5" string="thinks the current Congress proves `` the politically privileged class has become more isolated than experienced" type="VP">
          <tokens>
            <token id="2" string="thinks" />
            <token id="3" string="the" />
            <token id="4" string="current" />
            <token id="5" string="Congress" />
            <token id="6" string="proves" />
            <token id="7" string="&quot;" />
            <token id="8" string="the" />
            <token id="9" string="politically" />
            <token id="10" string="privileged" />
            <token id="11" string="class" />
            <token id="12" string="has" />
            <token id="13" string="become" />
            <token id="14" string="more" />
            <token id="15" string="isolated" />
            <token id="16" string="than" />
            <token id="17" string="experienced" />
          </tokens>
        </chunking>
        <chunking id="6" string="the politically privileged class" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="politically" />
            <token id="10" string="privileged" />
            <token id="11" string="class" />
          </tokens>
        </chunking>
        <chunking id="7" string="proves `` the politically privileged class has become more isolated than experienced" type="VP">
          <tokens>
            <token id="6" string="proves" />
            <token id="7" string="&quot;" />
            <token id="8" string="the" />
            <token id="9" string="politically" />
            <token id="10" string="privileged" />
            <token id="11" string="class" />
            <token id="12" string="has" />
            <token id="13" string="become" />
            <token id="14" string="more" />
            <token id="15" string="isolated" />
            <token id="16" string="than" />
            <token id="17" string="experienced" />
          </tokens>
        </chunking>
        <chunking id="8" string="experienced" type="ADJP">
          <tokens>
            <token id="17" string="experienced" />
          </tokens>
        </chunking>
        <chunking id="9" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
        <chunking id="10" string="more isolated than experienced" type="ADJP">
          <tokens>
            <token id="14" string="more" />
            <token id="15" string="isolated" />
            <token id="16" string="than" />
            <token id="17" string="experienced" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">thinks</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">thinks</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">Congress</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">Congress</governor>
          <dependent id="4">current</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">proves</governor>
          <dependent id="5">Congress</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">thinks</governor>
          <dependent id="6">proves</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">class</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">class</governor>
          <dependent id="9">politically</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">class</governor>
          <dependent id="10">privileged</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">become</governor>
          <dependent id="11">class</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">become</governor>
          <dependent id="12">has</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">proves</governor>
          <dependent id="13">become</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">isolated</governor>
          <dependent id="14">more</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="13">become</governor>
          <dependent id="15">isolated</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">experienced</governor>
          <dependent id="16">than</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="15">isolated</governor>
          <dependent id="17">experienced</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="current" type="DATE" score="0.0">
          <tokens>
            <token id="4" string="current" />
          </tokens>
        </entity>
        <entity id="2" string="Congress" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="5" string="Congress" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="35" has_coreference="true">
      <content>Such recent body-blows to Congress as Kitegate and the Clarence Thomas hearings have convinced some liberal media outlets to reevaluate term limits.</content>
      <tokens>
        <token id="1" string="Such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="recent" lemma="recent" stem="recent" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="body-blows" lemma="body-blow" stem="body-blow" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Congress" lemma="Congress" stem="congress" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="6" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Kitegate" lemma="Kitegate" stem="kiteg" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Clarence" lemma="Clarence" stem="clarenc" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="11" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="12" string="hearings" lemma="hearing" stem="hear" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="convinced" lemma="convince" stem="convinc" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="liberal" lemma="liberal" stem="liber" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="true" is_refers="false" />
        <token id="17" string="media" lemma="media" stem="media" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="outlets" lemma="outlet" stem="outlet" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="reevaluate" lemma="reevaluate" stem="reevalu" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="term" lemma="term" stem="term" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="limits" lemma="limit" stem="limit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (JJ Such) (JJ recent) (NNS body-blows)) (PP (TO to) (NP (NP (NNP Congress) (IN as) (NNP Kitegate)) (CC and) (NP (DT the) (NNP Clarence) (NNP Thomas) (NNS hearings))))) (VP (VBP have) (VP (VBN convinced) (S (NP (DT some) (JJ liberal) (NNS media) (NNS outlets)) (VP (TO to) (VP (VB reevaluate) (NP (NN term) (NNS limits))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Such recent body-blows to Congress as Kitegate and the Clarence Thomas hearings" type="NP">
          <tokens>
            <token id="1" string="Such" />
            <token id="2" string="recent" />
            <token id="3" string="body-blows" />
            <token id="4" string="to" />
            <token id="5" string="Congress" />
            <token id="6" string="as" />
            <token id="7" string="Kitegate" />
            <token id="8" string="and" />
            <token id="9" string="the" />
            <token id="10" string="Clarence" />
            <token id="11" string="Thomas" />
            <token id="12" string="hearings" />
          </tokens>
        </chunking>
        <chunking id="2" string="Congress as Kitegate and the Clarence Thomas hearings" type="NP">
          <tokens>
            <token id="5" string="Congress" />
            <token id="6" string="as" />
            <token id="7" string="Kitegate" />
            <token id="8" string="and" />
            <token id="9" string="the" />
            <token id="10" string="Clarence" />
            <token id="11" string="Thomas" />
            <token id="12" string="hearings" />
          </tokens>
        </chunking>
        <chunking id="3" string="Congress as Kitegate" type="NP">
          <tokens>
            <token id="5" string="Congress" />
            <token id="6" string="as" />
            <token id="7" string="Kitegate" />
          </tokens>
        </chunking>
        <chunking id="4" string="convinced some liberal media outlets to reevaluate term limits" type="VP">
          <tokens>
            <token id="14" string="convinced" />
            <token id="15" string="some" />
            <token id="16" string="liberal" />
            <token id="17" string="media" />
            <token id="18" string="outlets" />
            <token id="19" string="to" />
            <token id="20" string="reevaluate" />
            <token id="21" string="term" />
            <token id="22" string="limits" />
          </tokens>
        </chunking>
        <chunking id="5" string="reevaluate term limits" type="VP">
          <tokens>
            <token id="20" string="reevaluate" />
            <token id="21" string="term" />
            <token id="22" string="limits" />
          </tokens>
        </chunking>
        <chunking id="6" string="term limits" type="NP">
          <tokens>
            <token id="21" string="term" />
            <token id="22" string="limits" />
          </tokens>
        </chunking>
        <chunking id="7" string="some liberal media outlets" type="NP">
          <tokens>
            <token id="15" string="some" />
            <token id="16" string="liberal" />
            <token id="17" string="media" />
            <token id="18" string="outlets" />
          </tokens>
        </chunking>
        <chunking id="8" string="the Clarence Thomas hearings" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="Clarence" />
            <token id="11" string="Thomas" />
            <token id="12" string="hearings" />
          </tokens>
        </chunking>
        <chunking id="9" string="to reevaluate term limits" type="VP">
          <tokens>
            <token id="19" string="to" />
            <token id="20" string="reevaluate" />
            <token id="21" string="term" />
            <token id="22" string="limits" />
          </tokens>
        </chunking>
        <chunking id="10" string="Such recent body-blows" type="NP">
          <tokens>
            <token id="1" string="Such" />
            <token id="2" string="recent" />
            <token id="3" string="body-blows" />
          </tokens>
        </chunking>
        <chunking id="11" string="have convinced some liberal media outlets to reevaluate term limits" type="VP">
          <tokens>
            <token id="13" string="have" />
            <token id="14" string="convinced" />
            <token id="15" string="some" />
            <token id="16" string="liberal" />
            <token id="17" string="media" />
            <token id="18" string="outlets" />
            <token id="19" string="to" />
            <token id="20" string="reevaluate" />
            <token id="21" string="term" />
            <token id="22" string="limits" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="3">body-blows</governor>
          <dependent id="1">Such</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">body-blows</governor>
          <dependent id="2">recent</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">convinced</governor>
          <dependent id="3">body-blows</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Kitegate</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Kitegate</governor>
          <dependent id="5">Congress</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">Kitegate</governor>
          <dependent id="6">as</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">body-blows</governor>
          <dependent id="7">Kitegate</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">Kitegate</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">hearings</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">hearings</governor>
          <dependent id="10">Clarence</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">hearings</governor>
          <dependent id="11">Thomas</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">Kitegate</governor>
          <dependent id="12">hearings</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">convinced</governor>
          <dependent id="13">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">convinced</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">outlets</governor>
          <dependent id="15">some</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">outlets</governor>
          <dependent id="16">liberal</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">outlets</governor>
          <dependent id="17">media</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">convinced</governor>
          <dependent id="18">outlets</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">reevaluate</governor>
          <dependent id="19">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="14">convinced</governor>
          <dependent id="20">reevaluate</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">limits</governor>
          <dependent id="21">term</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">reevaluate</governor>
          <dependent id="22">limits</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Kitegate" type="LOCATION" score="0.0">
          <tokens>
            <token id="7" string="Kitegate" />
          </tokens>
        </entity>
        <entity id="2" string="liberal" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="16" string="liberal" />
          </tokens>
        </entity>
        <entity id="3" string="Congress" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="5" string="Congress" />
          </tokens>
        </entity>
        <entity id="4" string="Clarence Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Clarence" />
            <token id="11" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="36" has_coreference="true">
      <content>The liberal Seattle Times, Washington state&amp;apost;s largest newspaper, stunned its readers by endorsing term limits.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="liberal" lemma="liberal" stem="liber" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="3" string="Seattle" lemma="Seattle" stem="seattl" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="4" string="Times" lemma="Times" stem="time" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Washington" lemma="Washington" stem="washington" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="7" string="state" lemma="state" stem="state" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="largest" lemma="largest" stem="largest" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="newspaper" lemma="newspaper" stem="newspap" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="stunned" lemma="stun" stem="stun" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="readers" lemma="reader" stem="reader" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="endorsing" lemma="endorse" stem="endors" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="term" lemma="term" stem="term" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="limits" lemma="limit" stem="limit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (JJ liberal) (NNP Seattle) (NNP Times)) (, ,) (NP (NP (NNP Washington) (NN state) (POS 's)) (JJS largest) (NN newspaper)) (, ,)) (VP (VBD stunned) (NP (PRP$ its) (NNS readers)) (PP (IN by) (S (VP (VBG endorsing) (NP (NN term) (NNS limits)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The liberal Seattle Times" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="liberal" />
            <token id="3" string="Seattle" />
            <token id="4" string="Times" />
          </tokens>
        </chunking>
        <chunking id="2" string="stunned its readers by endorsing term limits" type="VP">
          <tokens>
            <token id="12" string="stunned" />
            <token id="13" string="its" />
            <token id="14" string="readers" />
            <token id="15" string="by" />
            <token id="16" string="endorsing" />
            <token id="17" string="term" />
            <token id="18" string="limits" />
          </tokens>
        </chunking>
        <chunking id="3" string="The liberal Seattle Times , Washington state 's largest newspaper ," type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="liberal" />
            <token id="3" string="Seattle" />
            <token id="4" string="Times" />
            <token id="5" string="," />
            <token id="6" string="Washington" />
            <token id="7" string="state" />
            <token id="8" string="'s" />
            <token id="9" string="largest" />
            <token id="10" string="newspaper" />
            <token id="11" string="," />
          </tokens>
        </chunking>
        <chunking id="4" string="its readers" type="NP">
          <tokens>
            <token id="13" string="its" />
            <token id="14" string="readers" />
          </tokens>
        </chunking>
        <chunking id="5" string="term limits" type="NP">
          <tokens>
            <token id="17" string="term" />
            <token id="18" string="limits" />
          </tokens>
        </chunking>
        <chunking id="6" string="Washington state 's largest newspaper" type="NP">
          <tokens>
            <token id="6" string="Washington" />
            <token id="7" string="state" />
            <token id="8" string="'s" />
            <token id="9" string="largest" />
            <token id="10" string="newspaper" />
          </tokens>
        </chunking>
        <chunking id="7" string="Washington state 's" type="NP">
          <tokens>
            <token id="6" string="Washington" />
            <token id="7" string="state" />
            <token id="8" string="'s" />
          </tokens>
        </chunking>
        <chunking id="8" string="endorsing term limits" type="VP">
          <tokens>
            <token id="16" string="endorsing" />
            <token id="17" string="term" />
            <token id="18" string="limits" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">Times</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">Times</governor>
          <dependent id="2">liberal</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Times</governor>
          <dependent id="3">Seattle</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">stunned</governor>
          <dependent id="4">Times</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">state</governor>
          <dependent id="6">Washington</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">newspaper</governor>
          <dependent id="7">state</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">state</governor>
          <dependent id="8">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">newspaper</governor>
          <dependent id="9">largest</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="4">Times</governor>
          <dependent id="10">newspaper</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">stunned</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">readers</governor>
          <dependent id="13">its</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">stunned</governor>
          <dependent id="14">readers</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">endorsing</governor>
          <dependent id="15">by</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">stunned</governor>
          <dependent id="16">endorsing</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">limits</governor>
          <dependent id="17">term</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">endorsing</governor>
          <dependent id="18">limits</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Washington" type="LOCATION" score="0.0">
          <tokens>
            <token id="6" string="Washington" />
          </tokens>
        </entity>
        <entity id="2" string="liberal" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="2" string="liberal" />
          </tokens>
        </entity>
        <entity id="3" string="Seattle Times" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="3" string="Seattle" />
            <token id="4" string="Times" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="37" has_coreference="false">
      <content>WCVB-TV, the ABC affiliate in Boston, has often had its liberal editorials called &amp;quot;the Boston Globe of the airwaves.&amp;quot;</content>
      <tokens>
        <token id="1" string="WCVB-TV" lemma="WCVB-TV" stem="wcvb-tv" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="ABC" lemma="ABC" stem="abc" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="5" string="affiliate" lemma="affiliate" stem="affili" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Boston" lemma="Boston" stem="boston" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="often" lemma="often" stem="often" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="liberal" lemma="liberal" stem="liber" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="14" string="editorials" lemma="editorial" stem="editori" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="called" lemma="call" stem="call" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="18" string="Boston" lemma="Boston" stem="boston" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="19" string="Globe" lemma="Globe" stem="globe" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="20" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="airwaves" lemma="airwave" stem="airwav" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP WCVB-TV)) (, ,) (NP (NP (DT the) (NNP ABC) (NN affiliate)) (PP (IN in) (NP (NNP Boston)))) (, ,)) (VP (VBZ has) (ADVP (RB often)) (VP (VBD had) (NP (PRP$ its) (JJ liberal) (NNS editorials)) (VP (VBN called) (S (`` ``) (NP (NP (DT the) (NNP Boston) (NNP Globe)) (PP (IN of) (NP (DT the) (NNS airwaves)))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="had its liberal editorials called `` the Boston Globe of the airwaves" type="VP">
          <tokens>
            <token id="11" string="had" />
            <token id="12" string="its" />
            <token id="13" string="liberal" />
            <token id="14" string="editorials" />
            <token id="15" string="called" />
            <token id="16" string="&quot;" />
            <token id="17" string="the" />
            <token id="18" string="Boston" />
            <token id="19" string="Globe" />
            <token id="20" string="of" />
            <token id="21" string="the" />
            <token id="22" string="airwaves" />
          </tokens>
        </chunking>
        <chunking id="2" string="the Boston Globe" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="Boston" />
            <token id="19" string="Globe" />
          </tokens>
        </chunking>
        <chunking id="3" string="WCVB-TV , the ABC affiliate in Boston ," type="NP">
          <tokens>
            <token id="1" string="WCVB-TV" />
            <token id="2" string="," />
            <token id="3" string="the" />
            <token id="4" string="ABC" />
            <token id="5" string="affiliate" />
            <token id="6" string="in" />
            <token id="7" string="Boston" />
            <token id="8" string="," />
          </tokens>
        </chunking>
        <chunking id="4" string="the ABC affiliate in Boston" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="ABC" />
            <token id="5" string="affiliate" />
            <token id="6" string="in" />
            <token id="7" string="Boston" />
          </tokens>
        </chunking>
        <chunking id="5" string="WCVB-TV" type="NP">
          <tokens>
            <token id="1" string="WCVB-TV" />
          </tokens>
        </chunking>
        <chunking id="6" string="its liberal editorials" type="NP">
          <tokens>
            <token id="12" string="its" />
            <token id="13" string="liberal" />
            <token id="14" string="editorials" />
          </tokens>
        </chunking>
        <chunking id="7" string="the Boston Globe of the airwaves" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="Boston" />
            <token id="19" string="Globe" />
            <token id="20" string="of" />
            <token id="21" string="the" />
            <token id="22" string="airwaves" />
          </tokens>
        </chunking>
        <chunking id="8" string="the airwaves" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="airwaves" />
          </tokens>
        </chunking>
        <chunking id="9" string="called `` the Boston Globe of the airwaves" type="VP">
          <tokens>
            <token id="15" string="called" />
            <token id="16" string="&quot;" />
            <token id="17" string="the" />
            <token id="18" string="Boston" />
            <token id="19" string="Globe" />
            <token id="20" string="of" />
            <token id="21" string="the" />
            <token id="22" string="airwaves" />
          </tokens>
        </chunking>
        <chunking id="10" string="Boston" type="NP">
          <tokens>
            <token id="7" string="Boston" />
          </tokens>
        </chunking>
        <chunking id="11" string="the ABC affiliate" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="ABC" />
            <token id="5" string="affiliate" />
          </tokens>
        </chunking>
        <chunking id="12" string="has often had its liberal editorials called `` the Boston Globe of the airwaves" type="VP">
          <tokens>
            <token id="9" string="has" />
            <token id="10" string="often" />
            <token id="11" string="had" />
            <token id="12" string="its" />
            <token id="13" string="liberal" />
            <token id="14" string="editorials" />
            <token id="15" string="called" />
            <token id="16" string="&quot;" />
            <token id="17" string="the" />
            <token id="18" string="Boston" />
            <token id="19" string="Globe" />
            <token id="20" string="of" />
            <token id="21" string="the" />
            <token id="22" string="airwaves" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="15">called</governor>
          <dependent id="1">WCVB-TV</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">affiliate</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">affiliate</governor>
          <dependent id="4">ABC</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="1">WCVB-TV</governor>
          <dependent id="5">affiliate</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Boston</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">affiliate</governor>
          <dependent id="7">Boston</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">called</governor>
          <dependent id="9">has</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">called</governor>
          <dependent id="10">often</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">called</governor>
          <dependent id="11">had</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">editorials</governor>
          <dependent id="12">its</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">editorials</governor>
          <dependent id="13">liberal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">called</governor>
          <dependent id="14">editorials</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">called</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">Globe</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">Globe</governor>
          <dependent id="18">Boston</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="15">called</governor>
          <dependent id="19">Globe</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">airwaves</governor>
          <dependent id="20">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">airwaves</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">Globe</governor>
          <dependent id="22">airwaves</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="ABC" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="4" string="ABC" />
          </tokens>
        </entity>
        <entity id="2" string="the Boston Globe" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="Boston" />
            <token id="19" string="Globe" />
          </tokens>
        </entity>
        <entity id="3" string="WCVB-TV" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="1" string="WCVB-TV" />
          </tokens>
        </entity>
        <entity id="4" string="Boston" type="LOCATION" score="0.0">
          <tokens>
            <token id="7" string="Boston" />
          </tokens>
        </entity>
        <entity id="5" string="liberal" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="13" string="liberal" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="38" has_coreference="false">
      <content>In April, it denounced term limits as &amp;quot;the latest anti-government fad to sweep the country.&amp;quot;</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="April" lemma="April" stem="april" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="denounced" lemma="denounce" stem="denounc" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="term" lemma="term" stem="term" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="limits" lemma="limit" stem="limit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="latest" lemma="latest" stem="latest" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="anti-government" lemma="anti-government" stem="anti-govern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="fad" lemma="fad" stem="fad" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="sweep" lemma="sweep" stem="sweep" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="country" lemma="country" stem="countri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (NNP April))) (, ,) (NP (PRP it)) (VP (VBD denounced) (NP (NN term) (NNS limits)) (PP (IN as) (`` ``) (NP (DT the) (JJS latest) (NN anti-government) (NN fad))) (PP (TO to) (NP (NP (NN sweep)) (NP (DT the) (NN country))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="the latest anti-government fad" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="latest" />
            <token id="12" string="anti-government" />
            <token id="13" string="fad" />
          </tokens>
        </chunking>
        <chunking id="2" string="denounced term limits as `` the latest anti-government fad to sweep the country" type="VP">
          <tokens>
            <token id="5" string="denounced" />
            <token id="6" string="term" />
            <token id="7" string="limits" />
            <token id="8" string="as" />
            <token id="9" string="&quot;" />
            <token id="10" string="the" />
            <token id="11" string="latest" />
            <token id="12" string="anti-government" />
            <token id="13" string="fad" />
            <token id="14" string="to" />
            <token id="15" string="sweep" />
            <token id="16" string="the" />
            <token id="17" string="country" />
          </tokens>
        </chunking>
        <chunking id="3" string="the country" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="country" />
          </tokens>
        </chunking>
        <chunking id="4" string="sweep" type="NP">
          <tokens>
            <token id="15" string="sweep" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="4" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="term limits" type="NP">
          <tokens>
            <token id="6" string="term" />
            <token id="7" string="limits" />
          </tokens>
        </chunking>
        <chunking id="7" string="sweep the country" type="NP">
          <tokens>
            <token id="15" string="sweep" />
            <token id="16" string="the" />
            <token id="17" string="country" />
          </tokens>
        </chunking>
        <chunking id="8" string="April" type="NP">
          <tokens>
            <token id="2" string="April" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">April</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">denounced</governor>
          <dependent id="2">April</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">denounced</governor>
          <dependent id="4">it</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">denounced</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">limits</governor>
          <dependent id="6">term</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">denounced</governor>
          <dependent id="7">limits</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">fad</governor>
          <dependent id="8">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">fad</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">fad</governor>
          <dependent id="11">latest</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">fad</governor>
          <dependent id="12">anti-government</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">denounced</governor>
          <dependent id="13">fad</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">sweep</governor>
          <dependent id="14">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">denounced</governor>
          <dependent id="15">sweep</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">country</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="15">sweep</governor>
          <dependent id="17">country</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="April" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="April" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="39" has_coreference="true">
      <content>Last month, the station made a highly unusual about-face and endorsed term limits for Congress: &amp;quot;We&amp;apost;re not going to get {leadership} till we have a massive infusion of new blood.&amp;quot;</content>
      <tokens>
        <token id="1" string="Last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="2" string="month" lemma="month" stem="month" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="station" lemma="station" stem="station" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="made" lemma="make" stem="made" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="highly" lemma="highly" stem="highli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="unusual" lemma="unusual" stem="unusu" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="about-face" lemma="about-face" stem="about-fac" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="endorsed" lemma="endorse" stem="endors" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="term" lemma="term" stem="term" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="limits" lemma="limit" stem="limit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="Congress" lemma="Congress" stem="congress" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="17" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="'re" lemma="be" stem="'re" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="get" lemma="get" stem="get" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="{" lemma="-lcb-" stem="{" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="leadership" lemma="leadership" stem="leadership" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="}" lemma="-rcb-" stem="}" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="till" lemma="till" stem="till" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="30" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="massive" lemma="massive" stem="massiv" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="infusion" lemma="infusion" stem="infus" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="new" lemma="new" stem="new" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="blood" lemma="blood" stem="blood" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP-TMP (JJ Last) (NN month)) (, ,) (NP (DT the) (NN station)) (VP (VP (VBD made) (NP (DT a) (ADJP (RB highly) (JJ unusual)) (NN about-face))) (CC and) (VP (VBD endorsed) (NP (NN term) (NNS limits)) (PP (IN for) (NP (NNP Congress)))))) (: :) (`` ``) (S (NP (PRP We)) (VP (VBP 're) (RB not) (VP (VBG going) (S (VP (TO to) (VP (VB get) (-LRB- -LCB-) (NP (NN leadership)) (-RRB- -RCB-)))) (SBAR (IN till) (S (NP (PRP we)) (VP (VBP have) (NP (NP (DT a) (JJ massive) (NN infusion)) (PP (IN of) (NP (JJ new) (NN blood)))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="to get -LCB- leadership -RCB-" type="VP">
          <tokens>
            <token id="23" string="to" />
            <token id="24" string="get" />
            <token id="25" string="{" />
            <token id="26" string="leadership" />
            <token id="27" string="}" />
          </tokens>
        </chunking>
        <chunking id="2" string="going to get -LCB- leadership -RCB- till we have a massive infusion of new blood" type="VP">
          <tokens>
            <token id="22" string="going" />
            <token id="23" string="to" />
            <token id="24" string="get" />
            <token id="25" string="{" />
            <token id="26" string="leadership" />
            <token id="27" string="}" />
            <token id="28" string="till" />
            <token id="29" string="we" />
            <token id="30" string="have" />
            <token id="31" string="a" />
            <token id="32" string="massive" />
            <token id="33" string="infusion" />
            <token id="34" string="of" />
            <token id="35" string="new" />
            <token id="36" string="blood" />
          </tokens>
        </chunking>
        <chunking id="3" string="a massive infusion" type="NP">
          <tokens>
            <token id="31" string="a" />
            <token id="32" string="massive" />
            <token id="33" string="infusion" />
          </tokens>
        </chunking>
        <chunking id="4" string="a highly unusual about-face" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="highly" />
            <token id="9" string="unusual" />
            <token id="10" string="about-face" />
          </tokens>
        </chunking>
        <chunking id="5" string="term limits" type="NP">
          <tokens>
            <token id="13" string="term" />
            <token id="14" string="limits" />
          </tokens>
        </chunking>
        <chunking id="6" string="the station" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="station" />
          </tokens>
        </chunking>
        <chunking id="7" string="We" type="NP">
          <tokens>
            <token id="19" string="We" />
          </tokens>
        </chunking>
        <chunking id="8" string="'re not going to get -LCB- leadership -RCB- till we have a massive infusion of new blood" type="VP">
          <tokens>
            <token id="20" string="'re" />
            <token id="21" string="not" />
            <token id="22" string="going" />
            <token id="23" string="to" />
            <token id="24" string="get" />
            <token id="25" string="{" />
            <token id="26" string="leadership" />
            <token id="27" string="}" />
            <token id="28" string="till" />
            <token id="29" string="we" />
            <token id="30" string="have" />
            <token id="31" string="a" />
            <token id="32" string="massive" />
            <token id="33" string="infusion" />
            <token id="34" string="of" />
            <token id="35" string="new" />
            <token id="36" string="blood" />
          </tokens>
        </chunking>
        <chunking id="9" string="we" type="NP">
          <tokens>
            <token id="29" string="we" />
          </tokens>
        </chunking>
        <chunking id="10" string="Congress" type="NP">
          <tokens>
            <token id="16" string="Congress" />
          </tokens>
        </chunking>
        <chunking id="11" string="new blood" type="NP">
          <tokens>
            <token id="35" string="new" />
            <token id="36" string="blood" />
          </tokens>
        </chunking>
        <chunking id="12" string="leadership" type="NP">
          <tokens>
            <token id="26" string="leadership" />
          </tokens>
        </chunking>
        <chunking id="13" string="made a highly unusual about-face and endorsed term limits for Congress" type="VP">
          <tokens>
            <token id="6" string="made" />
            <token id="7" string="a" />
            <token id="8" string="highly" />
            <token id="9" string="unusual" />
            <token id="10" string="about-face" />
            <token id="11" string="and" />
            <token id="12" string="endorsed" />
            <token id="13" string="term" />
            <token id="14" string="limits" />
            <token id="15" string="for" />
            <token id="16" string="Congress" />
          </tokens>
        </chunking>
        <chunking id="14" string="till we have a massive infusion of new blood" type="SBAR">
          <tokens>
            <token id="28" string="till" />
            <token id="29" string="we" />
            <token id="30" string="have" />
            <token id="31" string="a" />
            <token id="32" string="massive" />
            <token id="33" string="infusion" />
            <token id="34" string="of" />
            <token id="35" string="new" />
            <token id="36" string="blood" />
          </tokens>
        </chunking>
        <chunking id="15" string="a massive infusion of new blood" type="NP">
          <tokens>
            <token id="31" string="a" />
            <token id="32" string="massive" />
            <token id="33" string="infusion" />
            <token id="34" string="of" />
            <token id="35" string="new" />
            <token id="36" string="blood" />
          </tokens>
        </chunking>
        <chunking id="16" string="have a massive infusion of new blood" type="VP">
          <tokens>
            <token id="30" string="have" />
            <token id="31" string="a" />
            <token id="32" string="massive" />
            <token id="33" string="infusion" />
            <token id="34" string="of" />
            <token id="35" string="new" />
            <token id="36" string="blood" />
          </tokens>
        </chunking>
        <chunking id="17" string="endorsed term limits for Congress" type="VP">
          <tokens>
            <token id="12" string="endorsed" />
            <token id="13" string="term" />
            <token id="14" string="limits" />
            <token id="15" string="for" />
            <token id="16" string="Congress" />
          </tokens>
        </chunking>
        <chunking id="18" string="get -LCB- leadership -RCB-" type="VP">
          <tokens>
            <token id="24" string="get" />
            <token id="25" string="{" />
            <token id="26" string="leadership" />
            <token id="27" string="}" />
          </tokens>
        </chunking>
        <chunking id="19" string="made a highly unusual about-face" type="VP">
          <tokens>
            <token id="6" string="made" />
            <token id="7" string="a" />
            <token id="8" string="highly" />
            <token id="9" string="unusual" />
            <token id="10" string="about-face" />
          </tokens>
        </chunking>
        <chunking id="20" string="highly unusual" type="ADJP">
          <tokens>
            <token id="8" string="highly" />
            <token id="9" string="unusual" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">month</governor>
          <dependent id="1">Last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="6">made</governor>
          <dependent id="2">month</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">station</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">made</governor>
          <dependent id="5">station</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">made</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">about-face</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">unusual</governor>
          <dependent id="8">highly</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">about-face</governor>
          <dependent id="9">unusual</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">made</governor>
          <dependent id="10">about-face</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">made</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">made</governor>
          <dependent id="12">endorsed</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">limits</governor>
          <dependent id="13">term</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">endorsed</governor>
          <dependent id="14">limits</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">Congress</governor>
          <dependent id="15">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">endorsed</governor>
          <dependent id="16">Congress</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">going</governor>
          <dependent id="19">We</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="22">going</governor>
          <dependent id="20">'re</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="22">going</governor>
          <dependent id="21">not</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="6">made</governor>
          <dependent id="22">going</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">get</governor>
          <dependent id="23">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="22">going</governor>
          <dependent id="24">get</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">get</governor>
          <dependent id="26">leadership</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="30">have</governor>
          <dependent id="28">till</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="30">have</governor>
          <dependent id="29">we</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="22">going</governor>
          <dependent id="30">have</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">infusion</governor>
          <dependent id="31">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="33">infusion</governor>
          <dependent id="32">massive</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="30">have</governor>
          <dependent id="33">infusion</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">blood</governor>
          <dependent id="34">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="36">blood</governor>
          <dependent id="35">new</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">infusion</governor>
          <dependent id="36">blood</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Last month" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="Last" />
            <token id="2" string="month" />
          </tokens>
        </entity>
        <entity id="2" string="Congress" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="16" string="Congress" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="40" has_coreference="true">
      <content>Among Democratic Party activists, James Calaway of Texas is typical of those who now favor term limits.</content>
      <tokens>
        <token id="1" string="Among" lemma="among" stem="among" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="Democratic" lemma="Democratic" stem="democrat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="3" string="Party" lemma="Party" stem="parti" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="4" string="activists" lemma="activist" stem="activist" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="James" lemma="James" stem="jame" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="7" string="Calaway" lemma="Calaway" stem="calawai" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Texas" lemma="Texas" stem="texa" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="10" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="typical" lemma="typical" stem="typic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="16" string="favor" lemma="favor" stem="favor" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="term" lemma="term" stem="term" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="limits" lemma="limit" stem="limit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN Among) (NP (NNP Democratic) (NNP Party) (NNS activists))) (, ,) (NP (NP (NNP James) (NNP Calaway)) (PP (IN of) (NP (NNP Texas)))) (VP (VBZ is) (ADJP (JJ typical) (PP (IN of) (NP (NP (DT those)) (SBAR (WHNP (WP who)) (S (ADVP (RB now)) (VP (VBP favor) (NP (NN term) (NNS limits))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Democratic Party activists" type="NP">
          <tokens>
            <token id="2" string="Democratic" />
            <token id="3" string="Party" />
            <token id="4" string="activists" />
          </tokens>
        </chunking>
        <chunking id="2" string="is typical of those who now favor term limits" type="VP">
          <tokens>
            <token id="10" string="is" />
            <token id="11" string="typical" />
            <token id="12" string="of" />
            <token id="13" string="those" />
            <token id="14" string="who" />
            <token id="15" string="now" />
            <token id="16" string="favor" />
            <token id="17" string="term" />
            <token id="18" string="limits" />
          </tokens>
        </chunking>
        <chunking id="3" string="typical of those who now favor term limits" type="ADJP">
          <tokens>
            <token id="11" string="typical" />
            <token id="12" string="of" />
            <token id="13" string="those" />
            <token id="14" string="who" />
            <token id="15" string="now" />
            <token id="16" string="favor" />
            <token id="17" string="term" />
            <token id="18" string="limits" />
          </tokens>
        </chunking>
        <chunking id="4" string="Texas" type="NP">
          <tokens>
            <token id="9" string="Texas" />
          </tokens>
        </chunking>
        <chunking id="5" string="favor term limits" type="VP">
          <tokens>
            <token id="16" string="favor" />
            <token id="17" string="term" />
            <token id="18" string="limits" />
          </tokens>
        </chunking>
        <chunking id="6" string="term limits" type="NP">
          <tokens>
            <token id="17" string="term" />
            <token id="18" string="limits" />
          </tokens>
        </chunking>
        <chunking id="7" string="James Calaway" type="NP">
          <tokens>
            <token id="6" string="James" />
            <token id="7" string="Calaway" />
          </tokens>
        </chunking>
        <chunking id="8" string="James Calaway of Texas" type="NP">
          <tokens>
            <token id="6" string="James" />
            <token id="7" string="Calaway" />
            <token id="8" string="of" />
            <token id="9" string="Texas" />
          </tokens>
        </chunking>
        <chunking id="9" string="those who now favor term limits" type="NP">
          <tokens>
            <token id="13" string="those" />
            <token id="14" string="who" />
            <token id="15" string="now" />
            <token id="16" string="favor" />
            <token id="17" string="term" />
            <token id="18" string="limits" />
          </tokens>
        </chunking>
        <chunking id="10" string="who now favor term limits" type="SBAR">
          <tokens>
            <token id="14" string="who" />
            <token id="15" string="now" />
            <token id="16" string="favor" />
            <token id="17" string="term" />
            <token id="18" string="limits" />
          </tokens>
        </chunking>
        <chunking id="11" string="those" type="NP">
          <tokens>
            <token id="13" string="those" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">activists</governor>
          <dependent id="1">Among</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">activists</governor>
          <dependent id="2">Democratic</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">activists</governor>
          <dependent id="3">Party</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">typical</governor>
          <dependent id="4">activists</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Calaway</governor>
          <dependent id="6">James</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">typical</governor>
          <dependent id="7">Calaway</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Texas</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">Calaway</governor>
          <dependent id="9">Texas</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">typical</governor>
          <dependent id="10">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">typical</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">those</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">typical</governor>
          <dependent id="13">those</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">favor</governor>
          <dependent id="14">who</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">favor</governor>
          <dependent id="15">now</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="13">those</governor>
          <dependent id="16">favor</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">limits</governor>
          <dependent id="17">term</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">favor</governor>
          <dependent id="18">limits</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="15" string="now" />
          </tokens>
        </entity>
        <entity id="2" string="Democratic Party" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="2" string="Democratic" />
            <token id="3" string="Party" />
          </tokens>
        </entity>
        <entity id="3" string="Texas" type="LOCATION" score="0.0">
          <tokens>
            <token id="9" string="Texas" />
          </tokens>
        </entity>
        <entity id="4" string="James Calaway" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="James" />
            <token id="7" string="Calaway" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="41" has_coreference="true">
      <content>Currently the national treasurer for the American Civil Liberties Union, Mr. Calaway was also chairman of the national Democratic Party&amp;apost;s $15 million &amp;quot;Victory Fund&amp;quot; in 1988.</content>
      <tokens>
        <token id="1" string="Currently" lemma="currently" stem="current" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="national" lemma="national" stem="nation" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="treasurer" lemma="treasurer" stem="treasur" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="American" lemma="American" stem="american" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="8" string="Civil" lemma="Civil" stem="civil" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="9" string="Liberties" lemma="Liberties" stem="liberti" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="10" string="Union" lemma="Union" stem="union" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="Calaway" lemma="Calaway" stem="calawai" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="14" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="chairman" lemma="chairman" stem="chairman" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="national" lemma="national" stem="nation" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="Democratic" lemma="Democratic" stem="democrat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="21" string="Party" lemma="Party" stem="parti" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="22" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="true" is_refers="false" />
        <token id="24" string="15" lemma="15" stem="15" pos="CD" type="Number" isStopWord="false" ner="MONEY" is_referenced="true" is_refers="false" />
        <token id="25" string="million" lemma="million" stem="million" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="true" is_refers="false" />
        <token id="26" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="27" string="Victory" lemma="Victory" stem="victori" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="28" string="Fund" lemma="Fund" stem="fund" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="30" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="1988" lemma="1988" stem="1988" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (ADVP (RB Currently)) (NP (NP (DT the) (JJ national) (NN treasurer)) (PP (IN for) (NP (DT the) (NNP American) (NNP Civil) (NNP Liberties) (NNP Union))))) (, ,) (NP (NNP Mr.) (NNP Calaway)) (VP (VBD was) (ADVP (RB also)) (NP (NP (NN chairman)) (PP (IN of) (NP (NP (NP (DT the) (JJ national) (NNP Democratic) (NNP Party) (POS 's)) (QP ($ $) (CD 15) (CD million))) (`` ``) (NP (NNP Victory) (NNP Fund)) ('' ''))) (PP (IN in) (NP (CD 1988))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="1988" type="NP">
          <tokens>
            <token id="31" string="1988" />
          </tokens>
        </chunking>
        <chunking id="2" string="the national Democratic Party 's $ 15 million `` Victory Fund ''" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="national" />
            <token id="20" string="Democratic" />
            <token id="21" string="Party" />
            <token id="22" string="'s" />
            <token id="23" string="$" />
            <token id="24" string="15" />
            <token id="25" string="million" />
            <token id="26" string="&quot;" />
            <token id="27" string="Victory" />
            <token id="28" string="Fund" />
            <token id="29" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="3" string="the national Democratic Party 's $ 15 million" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="national" />
            <token id="20" string="Democratic" />
            <token id="21" string="Party" />
            <token id="22" string="'s" />
            <token id="23" string="$" />
            <token id="24" string="15" />
            <token id="25" string="million" />
          </tokens>
        </chunking>
        <chunking id="4" string="Mr. Calaway" type="NP">
          <tokens>
            <token id="12" string="Mr." />
            <token id="13" string="Calaway" />
          </tokens>
        </chunking>
        <chunking id="5" string="the national treasurer for the American Civil Liberties Union" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="national" />
            <token id="4" string="treasurer" />
            <token id="5" string="for" />
            <token id="6" string="the" />
            <token id="7" string="American" />
            <token id="8" string="Civil" />
            <token id="9" string="Liberties" />
            <token id="10" string="Union" />
          </tokens>
        </chunking>
        <chunking id="6" string="the national treasurer" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="national" />
            <token id="4" string="treasurer" />
          </tokens>
        </chunking>
        <chunking id="7" string="chairman of the national Democratic Party 's $ 15 million `` Victory Fund '' in 1988" type="NP">
          <tokens>
            <token id="16" string="chairman" />
            <token id="17" string="of" />
            <token id="18" string="the" />
            <token id="19" string="national" />
            <token id="20" string="Democratic" />
            <token id="21" string="Party" />
            <token id="22" string="'s" />
            <token id="23" string="$" />
            <token id="24" string="15" />
            <token id="25" string="million" />
            <token id="26" string="&quot;" />
            <token id="27" string="Victory" />
            <token id="28" string="Fund" />
            <token id="29" string="&quot;" />
            <token id="30" string="in" />
            <token id="31" string="1988" />
          </tokens>
        </chunking>
        <chunking id="8" string="Victory Fund" type="NP">
          <tokens>
            <token id="27" string="Victory" />
            <token id="28" string="Fund" />
          </tokens>
        </chunking>
        <chunking id="9" string="the American Civil Liberties Union" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="American" />
            <token id="8" string="Civil" />
            <token id="9" string="Liberties" />
            <token id="10" string="Union" />
          </tokens>
        </chunking>
        <chunking id="10" string="was also chairman of the national Democratic Party 's $ 15 million `` Victory Fund '' in 1988" type="VP">
          <tokens>
            <token id="14" string="was" />
            <token id="15" string="also" />
            <token id="16" string="chairman" />
            <token id="17" string="of" />
            <token id="18" string="the" />
            <token id="19" string="national" />
            <token id="20" string="Democratic" />
            <token id="21" string="Party" />
            <token id="22" string="'s" />
            <token id="23" string="$" />
            <token id="24" string="15" />
            <token id="25" string="million" />
            <token id="26" string="&quot;" />
            <token id="27" string="Victory" />
            <token id="28" string="Fund" />
            <token id="29" string="&quot;" />
            <token id="30" string="in" />
            <token id="31" string="1988" />
          </tokens>
        </chunking>
        <chunking id="11" string="chairman" type="NP">
          <tokens>
            <token id="16" string="chairman" />
          </tokens>
        </chunking>
        <chunking id="12" string="the national Democratic Party 's" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="national" />
            <token id="20" string="Democratic" />
            <token id="21" string="Party" />
            <token id="22" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="4">treasurer</governor>
          <dependent id="1">Currently</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">treasurer</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">treasurer</governor>
          <dependent id="3">national</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">chairman</governor>
          <dependent id="4">treasurer</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Union</governor>
          <dependent id="5">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">Union</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Union</governor>
          <dependent id="7">American</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Union</governor>
          <dependent id="8">Civil</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Union</governor>
          <dependent id="9">Liberties</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">treasurer</governor>
          <dependent id="10">Union</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Calaway</governor>
          <dependent id="12">Mr.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">chairman</governor>
          <dependent id="13">Calaway</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="16">chairman</governor>
          <dependent id="14">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">chairman</governor>
          <dependent id="15">also</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">chairman</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">Party</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">Party</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">Party</governor>
          <dependent id="19">national</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">Party</governor>
          <dependent id="20">Democratic</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">chairman</governor>
          <dependent id="21">Party</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">Party</governor>
          <dependent id="22">'s</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="21">Party</governor>
          <dependent id="23">$</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">million</governor>
          <dependent id="24">15</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="23">$</governor>
          <dependent id="25">million</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">Fund</governor>
          <dependent id="27">Victory</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="21">Party</governor>
          <dependent id="28">Fund</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">1988</governor>
          <dependent id="30">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">chairman</governor>
          <dependent id="31">1988</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1988" type="DATE" score="0.0">
          <tokens>
            <token id="31" string="1988" />
          </tokens>
        </entity>
        <entity id="2" string="Currently" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="Currently" />
          </tokens>
        </entity>
        <entity id="3" string="$ 15 million" type="MONEY" score="0.0">
          <tokens>
            <token id="23" string="$" />
            <token id="24" string="15" />
            <token id="25" string="million" />
          </tokens>
        </entity>
        <entity id="4" string="American Civil Liberties Union" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="7" string="American" />
            <token id="8" string="Civil" />
            <token id="9" string="Liberties" />
            <token id="10" string="Union" />
          </tokens>
        </entity>
        <entity id="5" string="Democratic Party" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="20" string="Democratic" />
            <token id="21" string="Party" />
          </tokens>
        </entity>
        <entity id="6" string="Calaway" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Calaway" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="42" has_coreference="true">
      <content>He says term limits would mean &amp;quot;we&amp;apost;re governed by citizens who go home after their service and not permanent, elitist people who never leave office.&amp;quot;</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="term" lemma="term" stem="term" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="limits" lemma="limit" stem="limit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="mean" lemma="mean" stem="mean" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="'re" lemma="be" stem="'re" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="governed" lemma="govern" stem="govern" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="citizens" lemma="citizen" stem="citizen" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="go" lemma="go" stem="go" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="home" lemma="home" stem="home" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="service" lemma="service" stem="servic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="permanent" lemma="permanent" stem="perman" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="elitist" lemma="elitist" stem="elitist" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="leave" lemma="leave" stem="leav" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="office" lemma="office" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBZ says) (SBAR (S (NP (NN term) (NNS limits)) (VP (MD would) (VP (VB mean) (S (`` ``) (NP (PRP we)) (VP (VBP 're) (VP (VBN governed) (PP (IN by) (NP (NP (NNS citizens)) (SBAR (WHNP (WP who)) (S (VP (VBP go) (ADVP (NN home)) (PP (IN after) (NP (NP (PRP$ their) (NN service)) (CC and) (NP (RB not) (JJ permanent)))) (, ,) (NP (NP (JJ elitist) (NNS people)) (SBAR (WHNP (WP who)) (S (ADVP (RB never)) (VP (VBP leave) (NP (NN office))))))))))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="mean `` we 're governed by citizens who go home after their service and not permanent , elitist people who never leave office" type="VP">
          <tokens>
            <token id="6" string="mean" />
            <token id="7" string="&quot;" />
            <token id="8" string="we" />
            <token id="9" string="'re" />
            <token id="10" string="governed" />
            <token id="11" string="by" />
            <token id="12" string="citizens" />
            <token id="13" string="who" />
            <token id="14" string="go" />
            <token id="15" string="home" />
            <token id="16" string="after" />
            <token id="17" string="their" />
            <token id="18" string="service" />
            <token id="19" string="and" />
            <token id="20" string="not" />
            <token id="21" string="permanent" />
            <token id="22" string="," />
            <token id="23" string="elitist" />
            <token id="24" string="people" />
            <token id="25" string="who" />
            <token id="26" string="never" />
            <token id="27" string="leave" />
            <token id="28" string="office" />
          </tokens>
        </chunking>
        <chunking id="2" string="elitist people" type="NP">
          <tokens>
            <token id="23" string="elitist" />
            <token id="24" string="people" />
          </tokens>
        </chunking>
        <chunking id="3" string="term limits would mean `` we 're governed by citizens who go home after their service and not permanent , elitist people who never leave office" type="SBAR">
          <tokens>
            <token id="3" string="term" />
            <token id="4" string="limits" />
            <token id="5" string="would" />
            <token id="6" string="mean" />
            <token id="7" string="&quot;" />
            <token id="8" string="we" />
            <token id="9" string="'re" />
            <token id="10" string="governed" />
            <token id="11" string="by" />
            <token id="12" string="citizens" />
            <token id="13" string="who" />
            <token id="14" string="go" />
            <token id="15" string="home" />
            <token id="16" string="after" />
            <token id="17" string="their" />
            <token id="18" string="service" />
            <token id="19" string="and" />
            <token id="20" string="not" />
            <token id="21" string="permanent" />
            <token id="22" string="," />
            <token id="23" string="elitist" />
            <token id="24" string="people" />
            <token id="25" string="who" />
            <token id="26" string="never" />
            <token id="27" string="leave" />
            <token id="28" string="office" />
          </tokens>
        </chunking>
        <chunking id="4" string="leave office" type="VP">
          <tokens>
            <token id="27" string="leave" />
            <token id="28" string="office" />
          </tokens>
        </chunking>
        <chunking id="5" string="their service" type="NP">
          <tokens>
            <token id="17" string="their" />
            <token id="18" string="service" />
          </tokens>
        </chunking>
        <chunking id="6" string="elitist people who never leave office" type="NP">
          <tokens>
            <token id="23" string="elitist" />
            <token id="24" string="people" />
            <token id="25" string="who" />
            <token id="26" string="never" />
            <token id="27" string="leave" />
            <token id="28" string="office" />
          </tokens>
        </chunking>
        <chunking id="7" string="term limits" type="NP">
          <tokens>
            <token id="3" string="term" />
            <token id="4" string="limits" />
          </tokens>
        </chunking>
        <chunking id="8" string="office" type="NP">
          <tokens>
            <token id="28" string="office" />
          </tokens>
        </chunking>
        <chunking id="9" string="we" type="NP">
          <tokens>
            <token id="8" string="we" />
          </tokens>
        </chunking>
        <chunking id="10" string="their service and not permanent" type="NP">
          <tokens>
            <token id="17" string="their" />
            <token id="18" string="service" />
            <token id="19" string="and" />
            <token id="20" string="not" />
            <token id="21" string="permanent" />
          </tokens>
        </chunking>
        <chunking id="11" string="citizens who go home after their service and not permanent , elitist people who never leave office" type="NP">
          <tokens>
            <token id="12" string="citizens" />
            <token id="13" string="who" />
            <token id="14" string="go" />
            <token id="15" string="home" />
            <token id="16" string="after" />
            <token id="17" string="their" />
            <token id="18" string="service" />
            <token id="19" string="and" />
            <token id="20" string="not" />
            <token id="21" string="permanent" />
            <token id="22" string="," />
            <token id="23" string="elitist" />
            <token id="24" string="people" />
            <token id="25" string="who" />
            <token id="26" string="never" />
            <token id="27" string="leave" />
            <token id="28" string="office" />
          </tokens>
        </chunking>
        <chunking id="12" string="'re governed by citizens who go home after their service and not permanent , elitist people who never leave office" type="VP">
          <tokens>
            <token id="9" string="'re" />
            <token id="10" string="governed" />
            <token id="11" string="by" />
            <token id="12" string="citizens" />
            <token id="13" string="who" />
            <token id="14" string="go" />
            <token id="15" string="home" />
            <token id="16" string="after" />
            <token id="17" string="their" />
            <token id="18" string="service" />
            <token id="19" string="and" />
            <token id="20" string="not" />
            <token id="21" string="permanent" />
            <token id="22" string="," />
            <token id="23" string="elitist" />
            <token id="24" string="people" />
            <token id="25" string="who" />
            <token id="26" string="never" />
            <token id="27" string="leave" />
            <token id="28" string="office" />
          </tokens>
        </chunking>
        <chunking id="13" string="who never leave office" type="SBAR">
          <tokens>
            <token id="25" string="who" />
            <token id="26" string="never" />
            <token id="27" string="leave" />
            <token id="28" string="office" />
          </tokens>
        </chunking>
        <chunking id="14" string="who go home after their service and not permanent , elitist people who never leave office" type="SBAR">
          <tokens>
            <token id="13" string="who" />
            <token id="14" string="go" />
            <token id="15" string="home" />
            <token id="16" string="after" />
            <token id="17" string="their" />
            <token id="18" string="service" />
            <token id="19" string="and" />
            <token id="20" string="not" />
            <token id="21" string="permanent" />
            <token id="22" string="," />
            <token id="23" string="elitist" />
            <token id="24" string="people" />
            <token id="25" string="who" />
            <token id="26" string="never" />
            <token id="27" string="leave" />
            <token id="28" string="office" />
          </tokens>
        </chunking>
        <chunking id="15" string="would mean `` we 're governed by citizens who go home after their service and not permanent , elitist people who never leave office" type="VP">
          <tokens>
            <token id="5" string="would" />
            <token id="6" string="mean" />
            <token id="7" string="&quot;" />
            <token id="8" string="we" />
            <token id="9" string="'re" />
            <token id="10" string="governed" />
            <token id="11" string="by" />
            <token id="12" string="citizens" />
            <token id="13" string="who" />
            <token id="14" string="go" />
            <token id="15" string="home" />
            <token id="16" string="after" />
            <token id="17" string="their" />
            <token id="18" string="service" />
            <token id="19" string="and" />
            <token id="20" string="not" />
            <token id="21" string="permanent" />
            <token id="22" string="," />
            <token id="23" string="elitist" />
            <token id="24" string="people" />
            <token id="25" string="who" />
            <token id="26" string="never" />
            <token id="27" string="leave" />
            <token id="28" string="office" />
          </tokens>
        </chunking>
        <chunking id="16" string="go home after their service and not permanent , elitist people who never leave office" type="VP">
          <tokens>
            <token id="14" string="go" />
            <token id="15" string="home" />
            <token id="16" string="after" />
            <token id="17" string="their" />
            <token id="18" string="service" />
            <token id="19" string="and" />
            <token id="20" string="not" />
            <token id="21" string="permanent" />
            <token id="22" string="," />
            <token id="23" string="elitist" />
            <token id="24" string="people" />
            <token id="25" string="who" />
            <token id="26" string="never" />
            <token id="27" string="leave" />
            <token id="28" string="office" />
          </tokens>
        </chunking>
        <chunking id="17" string="says term limits would mean `` we 're governed by citizens who go home after their service and not permanent , elitist people who never leave office" type="VP">
          <tokens>
            <token id="2" string="says" />
            <token id="3" string="term" />
            <token id="4" string="limits" />
            <token id="5" string="would" />
            <token id="6" string="mean" />
            <token id="7" string="&quot;" />
            <token id="8" string="we" />
            <token id="9" string="'re" />
            <token id="10" string="governed" />
            <token id="11" string="by" />
            <token id="12" string="citizens" />
            <token id="13" string="who" />
            <token id="14" string="go" />
            <token id="15" string="home" />
            <token id="16" string="after" />
            <token id="17" string="their" />
            <token id="18" string="service" />
            <token id="19" string="and" />
            <token id="20" string="not" />
            <token id="21" string="permanent" />
            <token id="22" string="," />
            <token id="23" string="elitist" />
            <token id="24" string="people" />
            <token id="25" string="who" />
            <token id="26" string="never" />
            <token id="27" string="leave" />
            <token id="28" string="office" />
          </tokens>
        </chunking>
        <chunking id="18" string="not permanent" type="NP">
          <tokens>
            <token id="20" string="not" />
            <token id="21" string="permanent" />
          </tokens>
        </chunking>
        <chunking id="19" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="20" string="governed by citizens who go home after their service and not permanent , elitist people who never leave office" type="VP">
          <tokens>
            <token id="10" string="governed" />
            <token id="11" string="by" />
            <token id="12" string="citizens" />
            <token id="13" string="who" />
            <token id="14" string="go" />
            <token id="15" string="home" />
            <token id="16" string="after" />
            <token id="17" string="their" />
            <token id="18" string="service" />
            <token id="19" string="and" />
            <token id="20" string="not" />
            <token id="21" string="permanent" />
            <token id="22" string="," />
            <token id="23" string="elitist" />
            <token id="24" string="people" />
            <token id="25" string="who" />
            <token id="26" string="never" />
            <token id="27" string="leave" />
            <token id="28" string="office" />
          </tokens>
        </chunking>
        <chunking id="21" string="citizens" type="NP">
          <tokens>
            <token id="12" string="citizens" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">says</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">says</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">limits</governor>
          <dependent id="3">term</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">mean</governor>
          <dependent id="4">limits</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">mean</governor>
          <dependent id="5">would</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">says</governor>
          <dependent id="6">mean</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="10">governed</governor>
          <dependent id="8">we</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="10">governed</governor>
          <dependent id="9">'re</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">mean</governor>
          <dependent id="10">governed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">citizens</governor>
          <dependent id="11">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">governed</governor>
          <dependent id="12">citizens</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">go</governor>
          <dependent id="13">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="12">citizens</governor>
          <dependent id="14">go</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">go</governor>
          <dependent id="15">home</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">service</governor>
          <dependent id="16">after</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="18">service</governor>
          <dependent id="17">their</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">go</governor>
          <dependent id="18">service</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="18">service</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="21">permanent</governor>
          <dependent id="20">not</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">service</governor>
          <dependent id="21">permanent</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">people</governor>
          <dependent id="23">elitist</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">go</governor>
          <dependent id="24">people</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">leave</governor>
          <dependent id="25">who</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="27">leave</governor>
          <dependent id="26">never</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="24">people</governor>
          <dependent id="27">leave</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="27">leave</governor>
          <dependent id="28">office</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="43" has_coreference="true">
      <content>Other Texas Democrats who have joined him include Frances &amp;quot;Sissy&amp;quot; Farenthold, who cochaired George McGovern&amp;apost;s 1972 national campaign, and Leonel Castillo, Jimmy Carter&amp;apost;s director of the Immigration and Naturalization Service.</content>
      <tokens>
        <token id="1" string="Other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Texas" lemma="Texas" stem="texa" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="3" string="Democrats" lemma="Democrats" stem="democrat" pos="NNPS" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="4" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="joined" lemma="join" stem="join" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="include" lemma="include" stem="includ" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="Frances" lemma="Frances" stem="franc" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="10" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="11" string="Sissy" lemma="Sissy" stem="sissi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="12" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="13" string="Farenthold" lemma="Farenthold" stem="farenthold" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="cochaired" lemma="cochair" stem="cochair" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="George" lemma="George" stem="georg" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="18" string="McGovern" lemma="McGovern" stem="mcgovern" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="19" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="1972" lemma="1972" stem="1972" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="21" string="national" lemma="national" stem="nation" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="campaign" lemma="campaign" stem="campaign" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="Leonel" lemma="Leonel" stem="leonel" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="26" string="Castillo" lemma="Castillo" stem="castillo" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="27" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="Jimmy" lemma="Jimmy" stem="jimmi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="29" string="Carter" lemma="Carter" stem="carter" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="30" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="director" lemma="director" stem="director" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="Immigration" lemma="Immigration" stem="immigrat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="35" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="36" string="Naturalization" lemma="Naturalization" stem="natur" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="37" string="Service" lemma="Service" stem="servic" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="38" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (JJ Other) (NNP Texas) (NNPS Democrats)) (SBAR (WHNP (WP who)) (S (VP (VBP have) (VP (VBN joined) (NP (PRP him))))))) (VP (VBP include) (NP (NP (NNP Frances) (`` ``) (NNP Sissy) ('' '') (NNP Farenthold)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD cochaired) (NP (NP (NP (NNP George) (NNP McGovern) (POS 's)) (CD 1972) (JJ national) (NN campaign)) (, ,) (CC and) (NP (NP (NNP Leonel) (NNP Castillo)) (, ,) (NP (NP (NP (NNP Jimmy) (NNP Carter) (POS 's)) (NN director)) (PP (IN of) (NP (DT the) (NNP Immigration) (CC and) (NNP Naturalization) (NNP Service))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="include Frances `` Sissy '' Farenthold , who cochaired George McGovern 's 1972 national campaign , and Leonel Castillo , Jimmy Carter 's director of the Immigration and Naturalization Service" type="VP">
          <tokens>
            <token id="8" string="include" />
            <token id="9" string="Frances" />
            <token id="10" string="&quot;" />
            <token id="11" string="Sissy" />
            <token id="12" string="&quot;" />
            <token id="13" string="Farenthold" />
            <token id="14" string="," />
            <token id="15" string="who" />
            <token id="16" string="cochaired" />
            <token id="17" string="George" />
            <token id="18" string="McGovern" />
            <token id="19" string="'s" />
            <token id="20" string="1972" />
            <token id="21" string="national" />
            <token id="22" string="campaign" />
            <token id="23" string="," />
            <token id="24" string="and" />
            <token id="25" string="Leonel" />
            <token id="26" string="Castillo" />
            <token id="27" string="," />
            <token id="28" string="Jimmy" />
            <token id="29" string="Carter" />
            <token id="30" string="'s" />
            <token id="31" string="director" />
            <token id="32" string="of" />
            <token id="33" string="the" />
            <token id="34" string="Immigration" />
            <token id="35" string="and" />
            <token id="36" string="Naturalization" />
            <token id="37" string="Service" />
          </tokens>
        </chunking>
        <chunking id="2" string="cochaired George McGovern 's 1972 national campaign , and Leonel Castillo , Jimmy Carter 's director of the Immigration and Naturalization Service" type="VP">
          <tokens>
            <token id="16" string="cochaired" />
            <token id="17" string="George" />
            <token id="18" string="McGovern" />
            <token id="19" string="'s" />
            <token id="20" string="1972" />
            <token id="21" string="national" />
            <token id="22" string="campaign" />
            <token id="23" string="," />
            <token id="24" string="and" />
            <token id="25" string="Leonel" />
            <token id="26" string="Castillo" />
            <token id="27" string="," />
            <token id="28" string="Jimmy" />
            <token id="29" string="Carter" />
            <token id="30" string="'s" />
            <token id="31" string="director" />
            <token id="32" string="of" />
            <token id="33" string="the" />
            <token id="34" string="Immigration" />
            <token id="35" string="and" />
            <token id="36" string="Naturalization" />
            <token id="37" string="Service" />
          </tokens>
        </chunking>
        <chunking id="3" string="Other Texas Democrats" type="NP">
          <tokens>
            <token id="1" string="Other" />
            <token id="2" string="Texas" />
            <token id="3" string="Democrats" />
          </tokens>
        </chunking>
        <chunking id="4" string="Leonel Castillo , Jimmy Carter 's director of the Immigration and Naturalization Service" type="NP">
          <tokens>
            <token id="25" string="Leonel" />
            <token id="26" string="Castillo" />
            <token id="27" string="," />
            <token id="28" string="Jimmy" />
            <token id="29" string="Carter" />
            <token id="30" string="'s" />
            <token id="31" string="director" />
            <token id="32" string="of" />
            <token id="33" string="the" />
            <token id="34" string="Immigration" />
            <token id="35" string="and" />
            <token id="36" string="Naturalization" />
            <token id="37" string="Service" />
          </tokens>
        </chunking>
        <chunking id="5" string="Jimmy Carter 's director of the Immigration and Naturalization Service" type="NP">
          <tokens>
            <token id="28" string="Jimmy" />
            <token id="29" string="Carter" />
            <token id="30" string="'s" />
            <token id="31" string="director" />
            <token id="32" string="of" />
            <token id="33" string="the" />
            <token id="34" string="Immigration" />
            <token id="35" string="and" />
            <token id="36" string="Naturalization" />
            <token id="37" string="Service" />
          </tokens>
        </chunking>
        <chunking id="6" string="have joined him" type="VP">
          <tokens>
            <token id="5" string="have" />
            <token id="6" string="joined" />
            <token id="7" string="him" />
          </tokens>
        </chunking>
        <chunking id="7" string="him" type="NP">
          <tokens>
            <token id="7" string="him" />
          </tokens>
        </chunking>
        <chunking id="8" string="George McGovern 's 1972 national campaign" type="NP">
          <tokens>
            <token id="17" string="George" />
            <token id="18" string="McGovern" />
            <token id="19" string="'s" />
            <token id="20" string="1972" />
            <token id="21" string="national" />
            <token id="22" string="campaign" />
          </tokens>
        </chunking>
        <chunking id="9" string="who have joined him" type="SBAR">
          <tokens>
            <token id="4" string="who" />
            <token id="5" string="have" />
            <token id="6" string="joined" />
            <token id="7" string="him" />
          </tokens>
        </chunking>
        <chunking id="10" string="George McGovern 's 1972 national campaign , and Leonel Castillo , Jimmy Carter 's director of the Immigration and Naturalization Service" type="NP">
          <tokens>
            <token id="17" string="George" />
            <token id="18" string="McGovern" />
            <token id="19" string="'s" />
            <token id="20" string="1972" />
            <token id="21" string="national" />
            <token id="22" string="campaign" />
            <token id="23" string="," />
            <token id="24" string="and" />
            <token id="25" string="Leonel" />
            <token id="26" string="Castillo" />
            <token id="27" string="," />
            <token id="28" string="Jimmy" />
            <token id="29" string="Carter" />
            <token id="30" string="'s" />
            <token id="31" string="director" />
            <token id="32" string="of" />
            <token id="33" string="the" />
            <token id="34" string="Immigration" />
            <token id="35" string="and" />
            <token id="36" string="Naturalization" />
            <token id="37" string="Service" />
          </tokens>
        </chunking>
        <chunking id="11" string="Leonel Castillo" type="NP">
          <tokens>
            <token id="25" string="Leonel" />
            <token id="26" string="Castillo" />
          </tokens>
        </chunking>
        <chunking id="12" string="George McGovern 's" type="NP">
          <tokens>
            <token id="17" string="George" />
            <token id="18" string="McGovern" />
            <token id="19" string="'s" />
          </tokens>
        </chunking>
        <chunking id="13" string="Frances `` Sissy '' Farenthold , who cochaired George McGovern 's 1972 national campaign , and Leonel Castillo , Jimmy Carter 's director of the Immigration and Naturalization Service" type="NP">
          <tokens>
            <token id="9" string="Frances" />
            <token id="10" string="&quot;" />
            <token id="11" string="Sissy" />
            <token id="12" string="&quot;" />
            <token id="13" string="Farenthold" />
            <token id="14" string="," />
            <token id="15" string="who" />
            <token id="16" string="cochaired" />
            <token id="17" string="George" />
            <token id="18" string="McGovern" />
            <token id="19" string="'s" />
            <token id="20" string="1972" />
            <token id="21" string="national" />
            <token id="22" string="campaign" />
            <token id="23" string="," />
            <token id="24" string="and" />
            <token id="25" string="Leonel" />
            <token id="26" string="Castillo" />
            <token id="27" string="," />
            <token id="28" string="Jimmy" />
            <token id="29" string="Carter" />
            <token id="30" string="'s" />
            <token id="31" string="director" />
            <token id="32" string="of" />
            <token id="33" string="the" />
            <token id="34" string="Immigration" />
            <token id="35" string="and" />
            <token id="36" string="Naturalization" />
            <token id="37" string="Service" />
          </tokens>
        </chunking>
        <chunking id="14" string="the Immigration and Naturalization Service" type="NP">
          <tokens>
            <token id="33" string="the" />
            <token id="34" string="Immigration" />
            <token id="35" string="and" />
            <token id="36" string="Naturalization" />
            <token id="37" string="Service" />
          </tokens>
        </chunking>
        <chunking id="15" string="Frances `` Sissy '' Farenthold" type="NP">
          <tokens>
            <token id="9" string="Frances" />
            <token id="10" string="&quot;" />
            <token id="11" string="Sissy" />
            <token id="12" string="&quot;" />
            <token id="13" string="Farenthold" />
          </tokens>
        </chunking>
        <chunking id="16" string="Jimmy Carter 's" type="NP">
          <tokens>
            <token id="28" string="Jimmy" />
            <token id="29" string="Carter" />
            <token id="30" string="'s" />
          </tokens>
        </chunking>
        <chunking id="17" string="Other Texas Democrats who have joined him" type="NP">
          <tokens>
            <token id="1" string="Other" />
            <token id="2" string="Texas" />
            <token id="3" string="Democrats" />
            <token id="4" string="who" />
            <token id="5" string="have" />
            <token id="6" string="joined" />
            <token id="7" string="him" />
          </tokens>
        </chunking>
        <chunking id="18" string="who cochaired George McGovern 's 1972 national campaign , and Leonel Castillo , Jimmy Carter 's director of the Immigration and Naturalization Service" type="SBAR">
          <tokens>
            <token id="15" string="who" />
            <token id="16" string="cochaired" />
            <token id="17" string="George" />
            <token id="18" string="McGovern" />
            <token id="19" string="'s" />
            <token id="20" string="1972" />
            <token id="21" string="national" />
            <token id="22" string="campaign" />
            <token id="23" string="," />
            <token id="24" string="and" />
            <token id="25" string="Leonel" />
            <token id="26" string="Castillo" />
            <token id="27" string="," />
            <token id="28" string="Jimmy" />
            <token id="29" string="Carter" />
            <token id="30" string="'s" />
            <token id="31" string="director" />
            <token id="32" string="of" />
            <token id="33" string="the" />
            <token id="34" string="Immigration" />
            <token id="35" string="and" />
            <token id="36" string="Naturalization" />
            <token id="37" string="Service" />
          </tokens>
        </chunking>
        <chunking id="19" string="joined him" type="VP">
          <tokens>
            <token id="6" string="joined" />
            <token id="7" string="him" />
          </tokens>
        </chunking>
        <chunking id="20" string="Jimmy Carter 's director" type="NP">
          <tokens>
            <token id="28" string="Jimmy" />
            <token id="29" string="Carter" />
            <token id="30" string="'s" />
            <token id="31" string="director" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="3">Democrats</governor>
          <dependent id="1">Other</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Democrats</governor>
          <dependent id="2">Texas</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">include</governor>
          <dependent id="3">Democrats</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">joined</governor>
          <dependent id="4">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">joined</governor>
          <dependent id="5">have</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="3">Democrats</governor>
          <dependent id="6">joined</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">joined</governor>
          <dependent id="7">him</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">include</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Farenthold</governor>
          <dependent id="9">Frances</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Farenthold</governor>
          <dependent id="11">Sissy</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">include</governor>
          <dependent id="13">Farenthold</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">cochaired</governor>
          <dependent id="15">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="13">Farenthold</governor>
          <dependent id="16">cochaired</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">McGovern</governor>
          <dependent id="17">George</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="22">campaign</governor>
          <dependent id="18">McGovern</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">McGovern</governor>
          <dependent id="19">'s</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="22">campaign</governor>
          <dependent id="20">1972</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">campaign</governor>
          <dependent id="21">national</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">cochaired</governor>
          <dependent id="22">campaign</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="22">campaign</governor>
          <dependent id="24">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">Castillo</governor>
          <dependent id="25">Leonel</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="22">campaign</governor>
          <dependent id="26">Castillo</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">Carter</governor>
          <dependent id="28">Jimmy</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="31">director</governor>
          <dependent id="29">Carter</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">Carter</governor>
          <dependent id="30">'s</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="26">Castillo</governor>
          <dependent id="31">director</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">Service</governor>
          <dependent id="32">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="37">Service</governor>
          <dependent id="33">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="37">Service</governor>
          <dependent id="34">Immigration</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="34">Immigration</governor>
          <dependent id="35">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="34">Immigration</governor>
          <dependent id="36">Naturalization</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">director</governor>
          <dependent id="37">Service</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Democrats" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="3" string="Democrats" />
          </tokens>
        </entity>
        <entity id="2" string="Immigration and Naturalization Service" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="34" string="Immigration" />
            <token id="35" string="and" />
            <token id="36" string="Naturalization" />
            <token id="37" string="Service" />
          </tokens>
        </entity>
        <entity id="3" string="Jimmy Carter" type="PERSON" score="0.0">
          <tokens>
            <token id="28" string="Jimmy" />
            <token id="29" string="Carter" />
          </tokens>
        </entity>
        <entity id="4" string="1972" type="DATE" score="0.0">
          <tokens>
            <token id="20" string="1972" />
          </tokens>
        </entity>
        <entity id="5" string="Texas" type="LOCATION" score="0.0">
          <tokens>
            <token id="2" string="Texas" />
          </tokens>
        </entity>
        <entity id="6" string="George McGovern" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="George" />
            <token id="18" string="McGovern" />
          </tokens>
        </entity>
        <entity id="7" string="Leonel Castillo" type="PERSON" score="0.0">
          <tokens>
            <token id="25" string="Leonel" />
            <token id="26" string="Castillo" />
          </tokens>
        </entity>
        <entity id="8" string="Frances &quot; Sissy &quot; Farenthold" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Frances" />
            <token id="10" string="&quot;" />
            <token id="11" string="Sissy" />
            <token id="12" string="&quot;" />
            <token id="13" string="Farenthold" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="44" has_coreference="true">
      <content>Neo-liberals, who believe that centralized bureaucracies are the biggest obstacle to reforming government, are also warming to term limits.</content>
      <tokens>
        <token id="1" string="Neo-liberals" lemma="neo-liberal" stem="neo-liber" pos="NNS" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="believe" lemma="believe" stem="believ" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="centralized" lemma="centralized" stem="central" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="bureaucracies" lemma="bureaucracy" stem="bureaucraci" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="biggest" lemma="biggest" stem="biggest" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="obstacle" lemma="obstacle" stem="obstacl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="reforming" lemma="reform" stem="reform" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="government" lemma="government" stem="govern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="warming" lemma="warm" stem="warm" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="term" lemma="term" stem="term" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="limits" lemma="limit" stem="limit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNS Neo-liberals)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBP believe) (SBAR (IN that) (S (NP (JJ centralized) (NNS bureaucracies)) (VP (VBP are) (NP (NP (DT the) (JJS biggest) (NN obstacle)) (PP (TO to) (S (VP (VBG reforming) (NP (NN government)))))))))))) (, ,)) (VP (VBP are) (ADVP (RB also)) (VP (VBG warming) (S (VP (TO to) (VP (VB term) (NP (NNS limits))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Neo-liberals , who believe that centralized bureaucracies are the biggest obstacle to reforming government ," type="NP">
          <tokens>
            <token id="1" string="Neo-liberals" />
            <token id="2" string="," />
            <token id="3" string="who" />
            <token id="4" string="believe" />
            <token id="5" string="that" />
            <token id="6" string="centralized" />
            <token id="7" string="bureaucracies" />
            <token id="8" string="are" />
            <token id="9" string="the" />
            <token id="10" string="biggest" />
            <token id="11" string="obstacle" />
            <token id="12" string="to" />
            <token id="13" string="reforming" />
            <token id="14" string="government" />
            <token id="15" string="," />
          </tokens>
        </chunking>
        <chunking id="2" string="to term limits" type="VP">
          <tokens>
            <token id="19" string="to" />
            <token id="20" string="term" />
            <token id="21" string="limits" />
          </tokens>
        </chunking>
        <chunking id="3" string="the biggest obstacle" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="biggest" />
            <token id="11" string="obstacle" />
          </tokens>
        </chunking>
        <chunking id="4" string="term limits" type="VP">
          <tokens>
            <token id="20" string="term" />
            <token id="21" string="limits" />
          </tokens>
        </chunking>
        <chunking id="5" string="reforming government" type="VP">
          <tokens>
            <token id="13" string="reforming" />
            <token id="14" string="government" />
          </tokens>
        </chunking>
        <chunking id="6" string="Neo-liberals" type="NP">
          <tokens>
            <token id="1" string="Neo-liberals" />
          </tokens>
        </chunking>
        <chunking id="7" string="who believe that centralized bureaucracies are the biggest obstacle to reforming government" type="SBAR">
          <tokens>
            <token id="3" string="who" />
            <token id="4" string="believe" />
            <token id="5" string="that" />
            <token id="6" string="centralized" />
            <token id="7" string="bureaucracies" />
            <token id="8" string="are" />
            <token id="9" string="the" />
            <token id="10" string="biggest" />
            <token id="11" string="obstacle" />
            <token id="12" string="to" />
            <token id="13" string="reforming" />
            <token id="14" string="government" />
          </tokens>
        </chunking>
        <chunking id="8" string="the biggest obstacle to reforming government" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="biggest" />
            <token id="11" string="obstacle" />
            <token id="12" string="to" />
            <token id="13" string="reforming" />
            <token id="14" string="government" />
          </tokens>
        </chunking>
        <chunking id="9" string="centralized bureaucracies" type="NP">
          <tokens>
            <token id="6" string="centralized" />
            <token id="7" string="bureaucracies" />
          </tokens>
        </chunking>
        <chunking id="10" string="limits" type="NP">
          <tokens>
            <token id="21" string="limits" />
          </tokens>
        </chunking>
        <chunking id="11" string="government" type="NP">
          <tokens>
            <token id="14" string="government" />
          </tokens>
        </chunking>
        <chunking id="12" string="believe that centralized bureaucracies are the biggest obstacle to reforming government" type="VP">
          <tokens>
            <token id="4" string="believe" />
            <token id="5" string="that" />
            <token id="6" string="centralized" />
            <token id="7" string="bureaucracies" />
            <token id="8" string="are" />
            <token id="9" string="the" />
            <token id="10" string="biggest" />
            <token id="11" string="obstacle" />
            <token id="12" string="to" />
            <token id="13" string="reforming" />
            <token id="14" string="government" />
          </tokens>
        </chunking>
        <chunking id="13" string="warming to term limits" type="VP">
          <tokens>
            <token id="18" string="warming" />
            <token id="19" string="to" />
            <token id="20" string="term" />
            <token id="21" string="limits" />
          </tokens>
        </chunking>
        <chunking id="14" string="are the biggest obstacle to reforming government" type="VP">
          <tokens>
            <token id="8" string="are" />
            <token id="9" string="the" />
            <token id="10" string="biggest" />
            <token id="11" string="obstacle" />
            <token id="12" string="to" />
            <token id="13" string="reforming" />
            <token id="14" string="government" />
          </tokens>
        </chunking>
        <chunking id="15" string="that centralized bureaucracies are the biggest obstacle to reforming government" type="SBAR">
          <tokens>
            <token id="5" string="that" />
            <token id="6" string="centralized" />
            <token id="7" string="bureaucracies" />
            <token id="8" string="are" />
            <token id="9" string="the" />
            <token id="10" string="biggest" />
            <token id="11" string="obstacle" />
            <token id="12" string="to" />
            <token id="13" string="reforming" />
            <token id="14" string="government" />
          </tokens>
        </chunking>
        <chunking id="16" string="are also warming to term limits" type="VP">
          <tokens>
            <token id="16" string="are" />
            <token id="17" string="also" />
            <token id="18" string="warming" />
            <token id="19" string="to" />
            <token id="20" string="term" />
            <token id="21" string="limits" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="18">warming</governor>
          <dependent id="1">Neo-liberals</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">believe</governor>
          <dependent id="3">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="1">Neo-liberals</governor>
          <dependent id="4">believe</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">obstacle</governor>
          <dependent id="5">that</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">bureaucracies</governor>
          <dependent id="6">centralized</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">obstacle</governor>
          <dependent id="7">bureaucracies</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">obstacle</governor>
          <dependent id="8">are</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">obstacle</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">obstacle</governor>
          <dependent id="10">biggest</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">believe</governor>
          <dependent id="11">obstacle</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">reforming</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="11">obstacle</governor>
          <dependent id="13">reforming</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">reforming</governor>
          <dependent id="14">government</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">warming</governor>
          <dependent id="16">are</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">warming</governor>
          <dependent id="17">also</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">warming</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">term</governor>
          <dependent id="19">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="18">warming</governor>
          <dependent id="20">term</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">term</governor>
          <dependent id="21">limits</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Neo-liberals" type="MISC" score="0.0">
          <tokens>
            <token id="1" string="Neo-liberals" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="45" has_coreference="true">
      <content>David Osborne, who became sort of a guru for neo-liberals with his book &amp;quot;Laboratories of Democracy,&amp;quot; speaks for many reform-minded liberals when he says, &amp;quot;Term limits are necessary to shake things up and disrupt the careerist mindset that leads to so much cowardice in elected officials.&amp;quot;</content>
      <tokens>
        <token id="1" string="David" lemma="David" stem="david" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Osborne" lemma="Osborne" stem="osborn" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="became" lemma="become" stem="becam" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="sort" lemma="sort" stem="sort" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="guru" lemma="guru" stem="guru" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="neo-liberals" lemma="neo-liberal" stem="neo-liber" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="book" lemma="book" stem="book" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="Laboratories" lemma="Laboratories" stem="laboratori" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Democracy" lemma="Democracy" stem="democraci" pos="NNP" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="speaks" lemma="speak" stem="speak" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="reform-minded" lemma="reform-minded" stem="reform-mind" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="liberals" lemma="liberal" stem="liber" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="Term" lemma="term" stem="term" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="limits" lemma="limit" stem="limit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="necessary" lemma="necessary" stem="necessari" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="shake" lemma="shake" stem="shake" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="things" lemma="thing" stem="thing" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="disrupt" lemma="disrupt" stem="disrupt" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="careerist" lemma="careerist" stem="careerist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="mindset" lemma="mindset" stem="mindset" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="leads" lemma="lead" stem="lead" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="46" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="48" string="much" lemma="much" stem="much" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="49" string="cowardice" lemma="cowardice" stem="cowardic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="50" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="51" string="elected" lemma="elect" stem="elect" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="52" string="officials" lemma="official" stem="offici" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="53" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="54" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP David) (NNP Osborne)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD became) (NP (NP (NN sort)) (PP (IN of) (NP (NP (DT a) (NN guru)) (PP (IN for) (NP (NNS neo-liberals)))))) (PP (IN with) (NP (PRP$ his) (NN book) (`` ``) (NNP Laboratories) (IN of) (NNP Democracy)))))) (, ,) ('' '')) (VP (VBZ speaks) (PP (IN for) (NP (JJ many) (JJ reform-minded) (NNS liberals))) (SBAR (WHADVP (WRB when)) (S (NP (PRP he)) (VP (VBZ says) (, ,) (`` ``) (S (NP (NN Term) (NNS limits)) (VP (VBP are) (ADJP (JJ necessary) (S (VP (TO to) (VP (VP (VB shake) (NP (NNS things)) (PRT (RP up))) (CC and) (VP (VB disrupt) (NP (NP (DT the) (NN careerist) (NN mindset)) (SBAR (WHNP (WDT that)) (S (VP (VBZ leads) (PP (TO to) (NP (NP (ADJP (RB so) (JJ much)) (NN cowardice)) (PP (IN in) (NP (VBN elected) (NNS officials)))))))))))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="when he says , `` Term limits are necessary to shake things up and disrupt the careerist mindset that leads to so much cowardice in elected officials" type="SBAR">
          <tokens>
            <token id="26" string="when" />
            <token id="27" string="he" />
            <token id="28" string="says" />
            <token id="29" string="," />
            <token id="30" string="&quot;" />
            <token id="31" string="Term" />
            <token id="32" string="limits" />
            <token id="33" string="are" />
            <token id="34" string="necessary" />
            <token id="35" string="to" />
            <token id="36" string="shake" />
            <token id="37" string="things" />
            <token id="38" string="up" />
            <token id="39" string="and" />
            <token id="40" string="disrupt" />
            <token id="41" string="the" />
            <token id="42" string="careerist" />
            <token id="43" string="mindset" />
            <token id="44" string="that" />
            <token id="45" string="leads" />
            <token id="46" string="to" />
            <token id="47" string="so" />
            <token id="48" string="much" />
            <token id="49" string="cowardice" />
            <token id="50" string="in" />
            <token id="51" string="elected" />
            <token id="52" string="officials" />
          </tokens>
        </chunking>
        <chunking id="2" string="the careerist mindset that leads to so much cowardice in elected officials" type="NP">
          <tokens>
            <token id="41" string="the" />
            <token id="42" string="careerist" />
            <token id="43" string="mindset" />
            <token id="44" string="that" />
            <token id="45" string="leads" />
            <token id="46" string="to" />
            <token id="47" string="so" />
            <token id="48" string="much" />
            <token id="49" string="cowardice" />
            <token id="50" string="in" />
            <token id="51" string="elected" />
            <token id="52" string="officials" />
          </tokens>
        </chunking>
        <chunking id="3" string="so much cowardice" type="NP">
          <tokens>
            <token id="47" string="so" />
            <token id="48" string="much" />
            <token id="49" string="cowardice" />
          </tokens>
        </chunking>
        <chunking id="4" string="sort" type="NP">
          <tokens>
            <token id="6" string="sort" />
          </tokens>
        </chunking>
        <chunking id="5" string="leads to so much cowardice in elected officials" type="VP">
          <tokens>
            <token id="45" string="leads" />
            <token id="46" string="to" />
            <token id="47" string="so" />
            <token id="48" string="much" />
            <token id="49" string="cowardice" />
            <token id="50" string="in" />
            <token id="51" string="elected" />
            <token id="52" string="officials" />
          </tokens>
        </chunking>
        <chunking id="6" string="the careerist mindset" type="NP">
          <tokens>
            <token id="41" string="the" />
            <token id="42" string="careerist" />
            <token id="43" string="mindset" />
          </tokens>
        </chunking>
        <chunking id="7" string="David Osborne , who became sort of a guru for neo-liberals with his book `` Laboratories of Democracy , ''" type="NP">
          <tokens>
            <token id="1" string="David" />
            <token id="2" string="Osborne" />
            <token id="3" string="," />
            <token id="4" string="who" />
            <token id="5" string="became" />
            <token id="6" string="sort" />
            <token id="7" string="of" />
            <token id="8" string="a" />
            <token id="9" string="guru" />
            <token id="10" string="for" />
            <token id="11" string="neo-liberals" />
            <token id="12" string="with" />
            <token id="13" string="his" />
            <token id="14" string="book" />
            <token id="15" string="&quot;" />
            <token id="16" string="Laboratories" />
            <token id="17" string="of" />
            <token id="18" string="Democracy" />
            <token id="19" string="," />
            <token id="20" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="8" string="became sort of a guru for neo-liberals with his book `` Laboratories of Democracy" type="VP">
          <tokens>
            <token id="5" string="became" />
            <token id="6" string="sort" />
            <token id="7" string="of" />
            <token id="8" string="a" />
            <token id="9" string="guru" />
            <token id="10" string="for" />
            <token id="11" string="neo-liberals" />
            <token id="12" string="with" />
            <token id="13" string="his" />
            <token id="14" string="book" />
            <token id="15" string="&quot;" />
            <token id="16" string="Laboratories" />
            <token id="17" string="of" />
            <token id="18" string="Democracy" />
          </tokens>
        </chunking>
        <chunking id="9" string="a guru" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="guru" />
          </tokens>
        </chunking>
        <chunking id="10" string="many reform-minded liberals" type="NP">
          <tokens>
            <token id="23" string="many" />
            <token id="24" string="reform-minded" />
            <token id="25" string="liberals" />
          </tokens>
        </chunking>
        <chunking id="11" string="elected officials" type="NP">
          <tokens>
            <token id="51" string="elected" />
            <token id="52" string="officials" />
          </tokens>
        </chunking>
        <chunking id="12" string="so much cowardice in elected officials" type="NP">
          <tokens>
            <token id="47" string="so" />
            <token id="48" string="much" />
            <token id="49" string="cowardice" />
            <token id="50" string="in" />
            <token id="51" string="elected" />
            <token id="52" string="officials" />
          </tokens>
        </chunking>
        <chunking id="13" string="shake things up and disrupt the careerist mindset that leads to so much cowardice in elected officials" type="VP">
          <tokens>
            <token id="36" string="shake" />
            <token id="37" string="things" />
            <token id="38" string="up" />
            <token id="39" string="and" />
            <token id="40" string="disrupt" />
            <token id="41" string="the" />
            <token id="42" string="careerist" />
            <token id="43" string="mindset" />
            <token id="44" string="that" />
            <token id="45" string="leads" />
            <token id="46" string="to" />
            <token id="47" string="so" />
            <token id="48" string="much" />
            <token id="49" string="cowardice" />
            <token id="50" string="in" />
            <token id="51" string="elected" />
            <token id="52" string="officials" />
          </tokens>
        </chunking>
        <chunking id="14" string="he" type="NP">
          <tokens>
            <token id="27" string="he" />
          </tokens>
        </chunking>
        <chunking id="15" string="says , `` Term limits are necessary to shake things up and disrupt the careerist mindset that leads to so much cowardice in elected officials" type="VP">
          <tokens>
            <token id="28" string="says" />
            <token id="29" string="," />
            <token id="30" string="&quot;" />
            <token id="31" string="Term" />
            <token id="32" string="limits" />
            <token id="33" string="are" />
            <token id="34" string="necessary" />
            <token id="35" string="to" />
            <token id="36" string="shake" />
            <token id="37" string="things" />
            <token id="38" string="up" />
            <token id="39" string="and" />
            <token id="40" string="disrupt" />
            <token id="41" string="the" />
            <token id="42" string="careerist" />
            <token id="43" string="mindset" />
            <token id="44" string="that" />
            <token id="45" string="leads" />
            <token id="46" string="to" />
            <token id="47" string="so" />
            <token id="48" string="much" />
            <token id="49" string="cowardice" />
            <token id="50" string="in" />
            <token id="51" string="elected" />
            <token id="52" string="officials" />
          </tokens>
        </chunking>
        <chunking id="16" string="Term limits" type="NP">
          <tokens>
            <token id="31" string="Term" />
            <token id="32" string="limits" />
          </tokens>
        </chunking>
        <chunking id="17" string="David Osborne" type="NP">
          <tokens>
            <token id="1" string="David" />
            <token id="2" string="Osborne" />
          </tokens>
        </chunking>
        <chunking id="18" string="are necessary to shake things up and disrupt the careerist mindset that leads to so much cowardice in elected officials" type="VP">
          <tokens>
            <token id="33" string="are" />
            <token id="34" string="necessary" />
            <token id="35" string="to" />
            <token id="36" string="shake" />
            <token id="37" string="things" />
            <token id="38" string="up" />
            <token id="39" string="and" />
            <token id="40" string="disrupt" />
            <token id="41" string="the" />
            <token id="42" string="careerist" />
            <token id="43" string="mindset" />
            <token id="44" string="that" />
            <token id="45" string="leads" />
            <token id="46" string="to" />
            <token id="47" string="so" />
            <token id="48" string="much" />
            <token id="49" string="cowardice" />
            <token id="50" string="in" />
            <token id="51" string="elected" />
            <token id="52" string="officials" />
          </tokens>
        </chunking>
        <chunking id="19" string="shake things up" type="VP">
          <tokens>
            <token id="36" string="shake" />
            <token id="37" string="things" />
            <token id="38" string="up" />
          </tokens>
        </chunking>
        <chunking id="20" string="that leads to so much cowardice in elected officials" type="SBAR">
          <tokens>
            <token id="44" string="that" />
            <token id="45" string="leads" />
            <token id="46" string="to" />
            <token id="47" string="so" />
            <token id="48" string="much" />
            <token id="49" string="cowardice" />
            <token id="50" string="in" />
            <token id="51" string="elected" />
            <token id="52" string="officials" />
          </tokens>
        </chunking>
        <chunking id="21" string="necessary to shake things up and disrupt the careerist mindset that leads to so much cowardice in elected officials" type="ADJP">
          <tokens>
            <token id="34" string="necessary" />
            <token id="35" string="to" />
            <token id="36" string="shake" />
            <token id="37" string="things" />
            <token id="38" string="up" />
            <token id="39" string="and" />
            <token id="40" string="disrupt" />
            <token id="41" string="the" />
            <token id="42" string="careerist" />
            <token id="43" string="mindset" />
            <token id="44" string="that" />
            <token id="45" string="leads" />
            <token id="46" string="to" />
            <token id="47" string="so" />
            <token id="48" string="much" />
            <token id="49" string="cowardice" />
            <token id="50" string="in" />
            <token id="51" string="elected" />
            <token id="52" string="officials" />
          </tokens>
        </chunking>
        <chunking id="22" string="to shake things up and disrupt the careerist mindset that leads to so much cowardice in elected officials" type="VP">
          <tokens>
            <token id="35" string="to" />
            <token id="36" string="shake" />
            <token id="37" string="things" />
            <token id="38" string="up" />
            <token id="39" string="and" />
            <token id="40" string="disrupt" />
            <token id="41" string="the" />
            <token id="42" string="careerist" />
            <token id="43" string="mindset" />
            <token id="44" string="that" />
            <token id="45" string="leads" />
            <token id="46" string="to" />
            <token id="47" string="so" />
            <token id="48" string="much" />
            <token id="49" string="cowardice" />
            <token id="50" string="in" />
            <token id="51" string="elected" />
            <token id="52" string="officials" />
          </tokens>
        </chunking>
        <chunking id="23" string="when" type="WHADVP">
          <tokens>
            <token id="26" string="when" />
          </tokens>
        </chunking>
        <chunking id="24" string="neo-liberals" type="NP">
          <tokens>
            <token id="11" string="neo-liberals" />
          </tokens>
        </chunking>
        <chunking id="25" string="speaks for many reform-minded liberals when he says , `` Term limits are necessary to shake things up and disrupt the careerist mindset that leads to so much cowardice in elected officials" type="VP">
          <tokens>
            <token id="21" string="speaks" />
            <token id="22" string="for" />
            <token id="23" string="many" />
            <token id="24" string="reform-minded" />
            <token id="25" string="liberals" />
            <token id="26" string="when" />
            <token id="27" string="he" />
            <token id="28" string="says" />
            <token id="29" string="," />
            <token id="30" string="&quot;" />
            <token id="31" string="Term" />
            <token id="32" string="limits" />
            <token id="33" string="are" />
            <token id="34" string="necessary" />
            <token id="35" string="to" />
            <token id="36" string="shake" />
            <token id="37" string="things" />
            <token id="38" string="up" />
            <token id="39" string="and" />
            <token id="40" string="disrupt" />
            <token id="41" string="the" />
            <token id="42" string="careerist" />
            <token id="43" string="mindset" />
            <token id="44" string="that" />
            <token id="45" string="leads" />
            <token id="46" string="to" />
            <token id="47" string="so" />
            <token id="48" string="much" />
            <token id="49" string="cowardice" />
            <token id="50" string="in" />
            <token id="51" string="elected" />
            <token id="52" string="officials" />
          </tokens>
        </chunking>
        <chunking id="26" string="disrupt the careerist mindset that leads to so much cowardice in elected officials" type="VP">
          <tokens>
            <token id="40" string="disrupt" />
            <token id="41" string="the" />
            <token id="42" string="careerist" />
            <token id="43" string="mindset" />
            <token id="44" string="that" />
            <token id="45" string="leads" />
            <token id="46" string="to" />
            <token id="47" string="so" />
            <token id="48" string="much" />
            <token id="49" string="cowardice" />
            <token id="50" string="in" />
            <token id="51" string="elected" />
            <token id="52" string="officials" />
          </tokens>
        </chunking>
        <chunking id="27" string="things" type="NP">
          <tokens>
            <token id="37" string="things" />
          </tokens>
        </chunking>
        <chunking id="28" string="his book `` Laboratories of Democracy" type="NP">
          <tokens>
            <token id="13" string="his" />
            <token id="14" string="book" />
            <token id="15" string="&quot;" />
            <token id="16" string="Laboratories" />
            <token id="17" string="of" />
            <token id="18" string="Democracy" />
          </tokens>
        </chunking>
        <chunking id="29" string="sort of a guru for neo-liberals" type="NP">
          <tokens>
            <token id="6" string="sort" />
            <token id="7" string="of" />
            <token id="8" string="a" />
            <token id="9" string="guru" />
            <token id="10" string="for" />
            <token id="11" string="neo-liberals" />
          </tokens>
        </chunking>
        <chunking id="30" string="a guru for neo-liberals" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="guru" />
            <token id="10" string="for" />
            <token id="11" string="neo-liberals" />
          </tokens>
        </chunking>
        <chunking id="31" string="so much" type="ADJP">
          <tokens>
            <token id="47" string="so" />
            <token id="48" string="much" />
          </tokens>
        </chunking>
        <chunking id="32" string="who became sort of a guru for neo-liberals with his book `` Laboratories of Democracy" type="SBAR">
          <tokens>
            <token id="4" string="who" />
            <token id="5" string="became" />
            <token id="6" string="sort" />
            <token id="7" string="of" />
            <token id="8" string="a" />
            <token id="9" string="guru" />
            <token id="10" string="for" />
            <token id="11" string="neo-liberals" />
            <token id="12" string="with" />
            <token id="13" string="his" />
            <token id="14" string="book" />
            <token id="15" string="&quot;" />
            <token id="16" string="Laboratories" />
            <token id="17" string="of" />
            <token id="18" string="Democracy" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Osborne</governor>
          <dependent id="1">David</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">speaks</governor>
          <dependent id="2">Osborne</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">became</governor>
          <dependent id="4">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="2">Osborne</governor>
          <dependent id="5">became</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">became</governor>
          <dependent id="6">sort</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">guru</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">guru</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">sort</governor>
          <dependent id="9">guru</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">neo-liberals</governor>
          <dependent id="10">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">guru</governor>
          <dependent id="11">neo-liberals</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Democracy</governor>
          <dependent id="12">with</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="18">Democracy</governor>
          <dependent id="13">his</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Democracy</governor>
          <dependent id="14">book</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Democracy</governor>
          <dependent id="16">Laboratories</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">Democracy</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">became</governor>
          <dependent id="18">Democracy</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="21">speaks</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">liberals</governor>
          <dependent id="22">for</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">liberals</governor>
          <dependent id="23">many</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">liberals</governor>
          <dependent id="24">reform-minded</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">speaks</governor>
          <dependent id="25">liberals</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="28">says</governor>
          <dependent id="26">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">says</governor>
          <dependent id="27">he</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="21">speaks</governor>
          <dependent id="28">says</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="32">limits</governor>
          <dependent id="31">Term</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="34">necessary</governor>
          <dependent id="32">limits</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="34">necessary</governor>
          <dependent id="33">are</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="28">says</governor>
          <dependent id="34">necessary</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="36">shake</governor>
          <dependent id="35">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="34">necessary</governor>
          <dependent id="36">shake</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="36">shake</governor>
          <dependent id="37">things</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="36">shake</governor>
          <dependent id="38">up</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="36">shake</governor>
          <dependent id="39">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="36">shake</governor>
          <dependent id="40">disrupt</dependent>
        </dependency>
        <dependency type="det">
          <governor id="43">mindset</governor>
          <dependent id="41">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="43">mindset</governor>
          <dependent id="42">careerist</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="40">disrupt</governor>
          <dependent id="43">mindset</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="45">leads</governor>
          <dependent id="44">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="43">mindset</governor>
          <dependent id="45">leads</dependent>
        </dependency>
        <dependency type="case">
          <governor id="49">cowardice</governor>
          <dependent id="46">to</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="48">much</governor>
          <dependent id="47">so</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="49">cowardice</governor>
          <dependent id="48">much</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="45">leads</governor>
          <dependent id="49">cowardice</dependent>
        </dependency>
        <dependency type="case">
          <governor id="52">officials</governor>
          <dependent id="50">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="52">officials</governor>
          <dependent id="51">elected</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="49">cowardice</governor>
          <dependent id="52">officials</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="David Osborne" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="David" />
            <token id="2" string="Osborne" />
          </tokens>
        </entity>
        <entity id="2" string="Democracy" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="18" string="Democracy" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="46" has_coreference="true">
      <content>While Speaker Tom Foley reacts to term limits the way that Linus in the comic strip &amp;quot;Peanuts&amp;quot; would if his security blanket were taken away, some House Democrats think his concern that term limits would result in large GOP gains in Congress is a fantasy.</content>
      <tokens>
        <token id="1" string="While" lemma="while" stem="while" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Speaker" lemma="Speaker" stem="speaker" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="Tom" lemma="Tom" stem="tom" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="Foley" lemma="Foley" stem="folei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="5" string="reacts" lemma="react" stem="react" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="term" lemma="term" stem="term" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="limits" lemma="limit" stem="limit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="way" lemma="way" stem="wai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Linus" lemma="Linus" stem="linu" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="comic" lemma="comic" stem="comic" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="strip" lemma="strip" stem="strip" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="Peanuts" lemma="Peanuts" stem="peanut" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="security" lemma="security" stem="secur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="blanket" lemma="blanket" stem="blanket" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="taken" lemma="take" stem="taken" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="away" lemma="away" stem="awai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="30" string="House" lemma="House" stem="hous" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="31" string="Democrats" lemma="Democrats" stem="democrat" pos="NNPS" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="true" is_refers="false" />
        <token id="32" string="think" lemma="think" stem="think" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="concern" lemma="concern" stem="concern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="term" lemma="term" stem="term" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="limits" lemma="limit" stem="limit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="result" lemma="result" stem="result" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="large" lemma="large" stem="larg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="GOP" lemma="GOP" stem="gop" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="43" string="gains" lemma="gain" stem="gain" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="Congress" lemma="Congress" stem="congress" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="46" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="48" string="fantasy" lemma="fantasy" stem="fantasi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="49" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN While) (S (NP (NNP Speaker) (NNP Tom) (NNP Foley)) (VP (VBZ reacts) (S (VP (TO to) (VP (VB term) (NP (NP (NNS limits)) (NP (DT the) (NN way))) (SBAR (IN that) (S (NP (NP (NNP Linus)) (PP (IN in) (NP (DT the) (JJ comic) (NN strip) (`` ``) (NNP Peanuts) ('' '')))) (VP (MD would) (SBAR (IN if) (S (NP (PRP$ his) (NN security) (NN blanket)) (VP (VBD were) (VP (VBN taken) (ADVP (RB away))))))))))))))) (, ,) (NP (DT some) (NNP House) (NNPS Democrats)) (VP (VB think) (NP (PRP$ his) (NN concern)) (SBAR (IN that) (S (NP (NN term) (NNS limits)) (VP (MD would) (VP (VB result) (PP (IN in) (NP (JJ large) (NNP GOP) (NNS gains))) (SBAR (IN in) (S (NP (NNP Congress)) (VP (VBZ is) (NP (DT a) (NN fantasy)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="limits the way" type="NP">
          <tokens>
            <token id="8" string="limits" />
            <token id="9" string="the" />
            <token id="10" string="way" />
          </tokens>
        </chunking>
        <chunking id="2" string="think his concern that term limits would result in large GOP gains in Congress is a fantasy" type="VP">
          <tokens>
            <token id="32" string="think" />
            <token id="33" string="his" />
            <token id="34" string="concern" />
            <token id="35" string="that" />
            <token id="36" string="term" />
            <token id="37" string="limits" />
            <token id="38" string="would" />
            <token id="39" string="result" />
            <token id="40" string="in" />
            <token id="41" string="large" />
            <token id="42" string="GOP" />
            <token id="43" string="gains" />
            <token id="44" string="in" />
            <token id="45" string="Congress" />
            <token id="46" string="is" />
            <token id="47" string="a" />
            <token id="48" string="fantasy" />
          </tokens>
        </chunking>
        <chunking id="3" string="the comic strip `` Peanuts ''" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="comic" />
            <token id="16" string="strip" />
            <token id="17" string="&quot;" />
            <token id="18" string="Peanuts" />
            <token id="19" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="4" string="some House Democrats" type="NP">
          <tokens>
            <token id="29" string="some" />
            <token id="30" string="House" />
            <token id="31" string="Democrats" />
          </tokens>
        </chunking>
        <chunking id="5" string="if his security blanket were taken away" type="SBAR">
          <tokens>
            <token id="21" string="if" />
            <token id="22" string="his" />
            <token id="23" string="security" />
            <token id="24" string="blanket" />
            <token id="25" string="were" />
            <token id="26" string="taken" />
            <token id="27" string="away" />
          </tokens>
        </chunking>
        <chunking id="6" string="taken away" type="VP">
          <tokens>
            <token id="26" string="taken" />
            <token id="27" string="away" />
          </tokens>
        </chunking>
        <chunking id="7" string="Linus in the comic strip `` Peanuts ''" type="NP">
          <tokens>
            <token id="12" string="Linus" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="comic" />
            <token id="16" string="strip" />
            <token id="17" string="&quot;" />
            <token id="18" string="Peanuts" />
            <token id="19" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="8" string="Linus" type="NP">
          <tokens>
            <token id="12" string="Linus" />
          </tokens>
        </chunking>
        <chunking id="9" string="result in large GOP gains in Congress is a fantasy" type="VP">
          <tokens>
            <token id="39" string="result" />
            <token id="40" string="in" />
            <token id="41" string="large" />
            <token id="42" string="GOP" />
            <token id="43" string="gains" />
            <token id="44" string="in" />
            <token id="45" string="Congress" />
            <token id="46" string="is" />
            <token id="47" string="a" />
            <token id="48" string="fantasy" />
          </tokens>
        </chunking>
        <chunking id="10" string="were taken away" type="VP">
          <tokens>
            <token id="25" string="were" />
            <token id="26" string="taken" />
            <token id="27" string="away" />
          </tokens>
        </chunking>
        <chunking id="11" string="his security blanket" type="NP">
          <tokens>
            <token id="22" string="his" />
            <token id="23" string="security" />
            <token id="24" string="blanket" />
          </tokens>
        </chunking>
        <chunking id="12" string="term limits the way that Linus in the comic strip `` Peanuts '' would if his security blanket were taken away" type="VP">
          <tokens>
            <token id="7" string="term" />
            <token id="8" string="limits" />
            <token id="9" string="the" />
            <token id="10" string="way" />
            <token id="11" string="that" />
            <token id="12" string="Linus" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="comic" />
            <token id="16" string="strip" />
            <token id="17" string="&quot;" />
            <token id="18" string="Peanuts" />
            <token id="19" string="&quot;" />
            <token id="20" string="would" />
            <token id="21" string="if" />
            <token id="22" string="his" />
            <token id="23" string="security" />
            <token id="24" string="blanket" />
            <token id="25" string="were" />
            <token id="26" string="taken" />
            <token id="27" string="away" />
          </tokens>
        </chunking>
        <chunking id="13" string="a fantasy" type="NP">
          <tokens>
            <token id="47" string="a" />
            <token id="48" string="fantasy" />
          </tokens>
        </chunking>
        <chunking id="14" string="Speaker Tom Foley" type="NP">
          <tokens>
            <token id="2" string="Speaker" />
            <token id="3" string="Tom" />
            <token id="4" string="Foley" />
          </tokens>
        </chunking>
        <chunking id="15" string="large GOP gains" type="NP">
          <tokens>
            <token id="41" string="large" />
            <token id="42" string="GOP" />
            <token id="43" string="gains" />
          </tokens>
        </chunking>
        <chunking id="16" string="term limits" type="NP">
          <tokens>
            <token id="36" string="term" />
            <token id="37" string="limits" />
          </tokens>
        </chunking>
        <chunking id="17" string="his concern" type="NP">
          <tokens>
            <token id="33" string="his" />
            <token id="34" string="concern" />
          </tokens>
        </chunking>
        <chunking id="18" string="While Speaker Tom Foley reacts to term limits the way that Linus in the comic strip `` Peanuts '' would if his security blanket were taken away" type="SBAR">
          <tokens>
            <token id="1" string="While" />
            <token id="2" string="Speaker" />
            <token id="3" string="Tom" />
            <token id="4" string="Foley" />
            <token id="5" string="reacts" />
            <token id="6" string="to" />
            <token id="7" string="term" />
            <token id="8" string="limits" />
            <token id="9" string="the" />
            <token id="10" string="way" />
            <token id="11" string="that" />
            <token id="12" string="Linus" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="comic" />
            <token id="16" string="strip" />
            <token id="17" string="&quot;" />
            <token id="18" string="Peanuts" />
            <token id="19" string="&quot;" />
            <token id="20" string="would" />
            <token id="21" string="if" />
            <token id="22" string="his" />
            <token id="23" string="security" />
            <token id="24" string="blanket" />
            <token id="25" string="were" />
            <token id="26" string="taken" />
            <token id="27" string="away" />
          </tokens>
        </chunking>
        <chunking id="19" string="reacts to term limits the way that Linus in the comic strip `` Peanuts '' would if his security blanket were taken away" type="VP">
          <tokens>
            <token id="5" string="reacts" />
            <token id="6" string="to" />
            <token id="7" string="term" />
            <token id="8" string="limits" />
            <token id="9" string="the" />
            <token id="10" string="way" />
            <token id="11" string="that" />
            <token id="12" string="Linus" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="comic" />
            <token id="16" string="strip" />
            <token id="17" string="&quot;" />
            <token id="18" string="Peanuts" />
            <token id="19" string="&quot;" />
            <token id="20" string="would" />
            <token id="21" string="if" />
            <token id="22" string="his" />
            <token id="23" string="security" />
            <token id="24" string="blanket" />
            <token id="25" string="were" />
            <token id="26" string="taken" />
            <token id="27" string="away" />
          </tokens>
        </chunking>
        <chunking id="20" string="to term limits the way that Linus in the comic strip `` Peanuts '' would if his security blanket were taken away" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="term" />
            <token id="8" string="limits" />
            <token id="9" string="the" />
            <token id="10" string="way" />
            <token id="11" string="that" />
            <token id="12" string="Linus" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="comic" />
            <token id="16" string="strip" />
            <token id="17" string="&quot;" />
            <token id="18" string="Peanuts" />
            <token id="19" string="&quot;" />
            <token id="20" string="would" />
            <token id="21" string="if" />
            <token id="22" string="his" />
            <token id="23" string="security" />
            <token id="24" string="blanket" />
            <token id="25" string="were" />
            <token id="26" string="taken" />
            <token id="27" string="away" />
          </tokens>
        </chunking>
        <chunking id="21" string="Congress" type="NP">
          <tokens>
            <token id="45" string="Congress" />
          </tokens>
        </chunking>
        <chunking id="22" string="is a fantasy" type="VP">
          <tokens>
            <token id="46" string="is" />
            <token id="47" string="a" />
            <token id="48" string="fantasy" />
          </tokens>
        </chunking>
        <chunking id="23" string="limits" type="NP">
          <tokens>
            <token id="8" string="limits" />
          </tokens>
        </chunking>
        <chunking id="24" string="that term limits would result in large GOP gains in Congress is a fantasy" type="SBAR">
          <tokens>
            <token id="35" string="that" />
            <token id="36" string="term" />
            <token id="37" string="limits" />
            <token id="38" string="would" />
            <token id="39" string="result" />
            <token id="40" string="in" />
            <token id="41" string="large" />
            <token id="42" string="GOP" />
            <token id="43" string="gains" />
            <token id="44" string="in" />
            <token id="45" string="Congress" />
            <token id="46" string="is" />
            <token id="47" string="a" />
            <token id="48" string="fantasy" />
          </tokens>
        </chunking>
        <chunking id="25" string="in Congress is a fantasy" type="SBAR">
          <tokens>
            <token id="44" string="in" />
            <token id="45" string="Congress" />
            <token id="46" string="is" />
            <token id="47" string="a" />
            <token id="48" string="fantasy" />
          </tokens>
        </chunking>
        <chunking id="26" string="that Linus in the comic strip `` Peanuts '' would if his security blanket were taken away" type="SBAR">
          <tokens>
            <token id="11" string="that" />
            <token id="12" string="Linus" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="comic" />
            <token id="16" string="strip" />
            <token id="17" string="&quot;" />
            <token id="18" string="Peanuts" />
            <token id="19" string="&quot;" />
            <token id="20" string="would" />
            <token id="21" string="if" />
            <token id="22" string="his" />
            <token id="23" string="security" />
            <token id="24" string="blanket" />
            <token id="25" string="were" />
            <token id="26" string="taken" />
            <token id="27" string="away" />
          </tokens>
        </chunking>
        <chunking id="27" string="the way" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="way" />
          </tokens>
        </chunking>
        <chunking id="28" string="would if his security blanket were taken away" type="VP">
          <tokens>
            <token id="20" string="would" />
            <token id="21" string="if" />
            <token id="22" string="his" />
            <token id="23" string="security" />
            <token id="24" string="blanket" />
            <token id="25" string="were" />
            <token id="26" string="taken" />
            <token id="27" string="away" />
          </tokens>
        </chunking>
        <chunking id="29" string="would result in large GOP gains in Congress is a fantasy" type="VP">
          <tokens>
            <token id="38" string="would" />
            <token id="39" string="result" />
            <token id="40" string="in" />
            <token id="41" string="large" />
            <token id="42" string="GOP" />
            <token id="43" string="gains" />
            <token id="44" string="in" />
            <token id="45" string="Congress" />
            <token id="46" string="is" />
            <token id="47" string="a" />
            <token id="48" string="fantasy" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="5">reacts</governor>
          <dependent id="1">While</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Foley</governor>
          <dependent id="2">Speaker</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Foley</governor>
          <dependent id="3">Tom</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">reacts</governor>
          <dependent id="4">Foley</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="32">think</governor>
          <dependent id="5">reacts</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">term</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">reacts</governor>
          <dependent id="7">term</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">term</governor>
          <dependent id="8">limits</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">way</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="8">limits</governor>
          <dependent id="10">way</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">would</governor>
          <dependent id="11">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">would</governor>
          <dependent id="12">Linus</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Peanuts</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">Peanuts</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">Peanuts</governor>
          <dependent id="15">comic</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Peanuts</governor>
          <dependent id="16">strip</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">Linus</governor>
          <dependent id="18">Peanuts</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">term</governor>
          <dependent id="20">would</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="26">taken</governor>
          <dependent id="21">if</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="24">blanket</governor>
          <dependent id="22">his</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">blanket</governor>
          <dependent id="23">security</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="26">taken</governor>
          <dependent id="24">blanket</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="26">taken</governor>
          <dependent id="25">were</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="20">would</governor>
          <dependent id="26">taken</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="26">taken</governor>
          <dependent id="27">away</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">Democrats</governor>
          <dependent id="29">some</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">Democrats</governor>
          <dependent id="30">House</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="32">think</governor>
          <dependent id="31">Democrats</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="32">think</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="34">concern</governor>
          <dependent id="33">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="32">think</governor>
          <dependent id="34">concern</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="39">result</governor>
          <dependent id="35">that</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="37">limits</governor>
          <dependent id="36">term</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="39">result</governor>
          <dependent id="37">limits</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="39">result</governor>
          <dependent id="38">would</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="32">think</governor>
          <dependent id="39">result</dependent>
        </dependency>
        <dependency type="case">
          <governor id="43">gains</governor>
          <dependent id="40">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="43">gains</governor>
          <dependent id="41">large</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="43">gains</governor>
          <dependent id="42">GOP</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="39">result</governor>
          <dependent id="43">gains</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="48">fantasy</governor>
          <dependent id="44">in</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="48">fantasy</governor>
          <dependent id="45">Congress</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="48">fantasy</governor>
          <dependent id="46">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="48">fantasy</governor>
          <dependent id="47">a</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="39">result</governor>
          <dependent id="48">fantasy</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Democrats" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="31" string="Democrats" />
          </tokens>
        </entity>
        <entity id="2" string="House" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="30" string="House" />
          </tokens>
        </entity>
        <entity id="3" string="GOP" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="42" string="GOP" />
          </tokens>
        </entity>
        <entity id="4" string="Linus" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Linus" />
          </tokens>
        </entity>
        <entity id="5" string="Tom Foley" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Tom" />
            <token id="4" string="Foley" />
          </tokens>
        </entity>
        <entity id="6" string="Congress" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="45" string="Congress" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="47" has_coreference="true">
      <content>&amp;quot;People who say term limits are a Republican plot to oust incumbents should know that a majority of open seats are won by Democrats,&amp;quot; says Rep. Andy Jacobs of Indiana.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="People" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="say" lemma="say" stem="sai" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="term" lemma="term" stem="term" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="limits" lemma="limit" stem="limit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Republican" lemma="republican" stem="republican" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="10" string="plot" lemma="plot" stem="plot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="oust" lemma="oust" stem="oust" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="incumbents" lemma="incumbent" stem="incumb" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="should" lemma="should" stem="should" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="know" lemma="know" stem="know" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="majority" lemma="majority" stem="major" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="open" lemma="open" stem="open" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="seats" lemma="seat" stem="seat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="won" lemma="win" stem="won" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="Democrats" lemma="Democrats" stem="democrat" pos="NNPS" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="true" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="Rep." lemma="Rep." stem="rep." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="Andy" lemma="Andy" stem="andy" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="31" string="Jacobs" lemma="Jacobs" stem="jacob" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="32" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="Indiana" lemma="Indiana" stem="indiana" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="34" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (NP (NNS People)) (SBAR (WHNP (WP who)) (S (VP (VBP say) (SBAR (S (NP (NN term) (NNS limits)) (VP (VBP are) (NP (DT a) (JJ Republican) (NN plot) (S (VP (TO to) (VP (VB oust) (NP (NNS incumbents))))))))))))) (VP (MD should) (VP (VB know) (SBAR (IN that) (S (NP (NP (DT a) (NN majority)) (PP (IN of) (NP (JJ open) (NNS seats)))) (VP (VBP are) (VP (VBN won) (PP (IN by) (NP (NNPS Democrats)))))))))) (, ,) ('' '') (VP (VBZ says)) (NP (NP (NNP Rep.) (NNP Andy) (NNP Jacobs)) (PP (IN of) (NP (NNP Indiana)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a Republican plot to oust incumbents" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="Republican" />
            <token id="10" string="plot" />
            <token id="11" string="to" />
            <token id="12" string="oust" />
            <token id="13" string="incumbents" />
          </tokens>
        </chunking>
        <chunking id="2" string="that a majority of open seats are won by Democrats" type="SBAR">
          <tokens>
            <token id="16" string="that" />
            <token id="17" string="a" />
            <token id="18" string="majority" />
            <token id="19" string="of" />
            <token id="20" string="open" />
            <token id="21" string="seats" />
            <token id="22" string="are" />
            <token id="23" string="won" />
            <token id="24" string="by" />
            <token id="25" string="Democrats" />
          </tokens>
        </chunking>
        <chunking id="3" string="a majority of open seats" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="majority" />
            <token id="19" string="of" />
            <token id="20" string="open" />
            <token id="21" string="seats" />
          </tokens>
        </chunking>
        <chunking id="4" string="a majority" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="majority" />
          </tokens>
        </chunking>
        <chunking id="5" string="who say term limits are a Republican plot to oust incumbents" type="SBAR">
          <tokens>
            <token id="3" string="who" />
            <token id="4" string="say" />
            <token id="5" string="term" />
            <token id="6" string="limits" />
            <token id="7" string="are" />
            <token id="8" string="a" />
            <token id="9" string="Republican" />
            <token id="10" string="plot" />
            <token id="11" string="to" />
            <token id="12" string="oust" />
            <token id="13" string="incumbents" />
          </tokens>
        </chunking>
        <chunking id="6" string="know that a majority of open seats are won by Democrats" type="VP">
          <tokens>
            <token id="15" string="know" />
            <token id="16" string="that" />
            <token id="17" string="a" />
            <token id="18" string="majority" />
            <token id="19" string="of" />
            <token id="20" string="open" />
            <token id="21" string="seats" />
            <token id="22" string="are" />
            <token id="23" string="won" />
            <token id="24" string="by" />
            <token id="25" string="Democrats" />
          </tokens>
        </chunking>
        <chunking id="7" string="Rep. Andy Jacobs of Indiana" type="NP">
          <tokens>
            <token id="29" string="Rep." />
            <token id="30" string="Andy" />
            <token id="31" string="Jacobs" />
            <token id="32" string="of" />
            <token id="33" string="Indiana" />
          </tokens>
        </chunking>
        <chunking id="8" string="People who say term limits are a Republican plot to oust incumbents" type="NP">
          <tokens>
            <token id="2" string="People" />
            <token id="3" string="who" />
            <token id="4" string="say" />
            <token id="5" string="term" />
            <token id="6" string="limits" />
            <token id="7" string="are" />
            <token id="8" string="a" />
            <token id="9" string="Republican" />
            <token id="10" string="plot" />
            <token id="11" string="to" />
            <token id="12" string="oust" />
            <token id="13" string="incumbents" />
          </tokens>
        </chunking>
        <chunking id="9" string="Indiana" type="NP">
          <tokens>
            <token id="33" string="Indiana" />
          </tokens>
        </chunking>
        <chunking id="10" string="People" type="NP">
          <tokens>
            <token id="2" string="People" />
          </tokens>
        </chunking>
        <chunking id="11" string="term limits are a Republican plot to oust incumbents" type="SBAR">
          <tokens>
            <token id="5" string="term" />
            <token id="6" string="limits" />
            <token id="7" string="are" />
            <token id="8" string="a" />
            <token id="9" string="Republican" />
            <token id="10" string="plot" />
            <token id="11" string="to" />
            <token id="12" string="oust" />
            <token id="13" string="incumbents" />
          </tokens>
        </chunking>
        <chunking id="12" string="term limits" type="NP">
          <tokens>
            <token id="5" string="term" />
            <token id="6" string="limits" />
          </tokens>
        </chunking>
        <chunking id="13" string="won by Democrats" type="VP">
          <tokens>
            <token id="23" string="won" />
            <token id="24" string="by" />
            <token id="25" string="Democrats" />
          </tokens>
        </chunking>
        <chunking id="14" string="should know that a majority of open seats are won by Democrats" type="VP">
          <tokens>
            <token id="14" string="should" />
            <token id="15" string="know" />
            <token id="16" string="that" />
            <token id="17" string="a" />
            <token id="18" string="majority" />
            <token id="19" string="of" />
            <token id="20" string="open" />
            <token id="21" string="seats" />
            <token id="22" string="are" />
            <token id="23" string="won" />
            <token id="24" string="by" />
            <token id="25" string="Democrats" />
          </tokens>
        </chunking>
        <chunking id="15" string="Rep. Andy Jacobs" type="NP">
          <tokens>
            <token id="29" string="Rep." />
            <token id="30" string="Andy" />
            <token id="31" string="Jacobs" />
          </tokens>
        </chunking>
        <chunking id="16" string="Democrats" type="NP">
          <tokens>
            <token id="25" string="Democrats" />
          </tokens>
        </chunking>
        <chunking id="17" string="says" type="VP">
          <tokens>
            <token id="28" string="says" />
          </tokens>
        </chunking>
        <chunking id="18" string="oust incumbents" type="VP">
          <tokens>
            <token id="12" string="oust" />
            <token id="13" string="incumbents" />
          </tokens>
        </chunking>
        <chunking id="19" string="say term limits are a Republican plot to oust incumbents" type="VP">
          <tokens>
            <token id="4" string="say" />
            <token id="5" string="term" />
            <token id="6" string="limits" />
            <token id="7" string="are" />
            <token id="8" string="a" />
            <token id="9" string="Republican" />
            <token id="10" string="plot" />
            <token id="11" string="to" />
            <token id="12" string="oust" />
            <token id="13" string="incumbents" />
          </tokens>
        </chunking>
        <chunking id="20" string="incumbents" type="NP">
          <tokens>
            <token id="13" string="incumbents" />
          </tokens>
        </chunking>
        <chunking id="21" string="are won by Democrats" type="VP">
          <tokens>
            <token id="22" string="are" />
            <token id="23" string="won" />
            <token id="24" string="by" />
            <token id="25" string="Democrats" />
          </tokens>
        </chunking>
        <chunking id="22" string="open seats" type="NP">
          <tokens>
            <token id="20" string="open" />
            <token id="21" string="seats" />
          </tokens>
        </chunking>
        <chunking id="23" string="are a Republican plot to oust incumbents" type="VP">
          <tokens>
            <token id="7" string="are" />
            <token id="8" string="a" />
            <token id="9" string="Republican" />
            <token id="10" string="plot" />
            <token id="11" string="to" />
            <token id="12" string="oust" />
            <token id="13" string="incumbents" />
          </tokens>
        </chunking>
        <chunking id="24" string="to oust incumbents" type="VP">
          <tokens>
            <token id="11" string="to" />
            <token id="12" string="oust" />
            <token id="13" string="incumbents" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="15">know</governor>
          <dependent id="2">People</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">say</governor>
          <dependent id="3">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="2">People</governor>
          <dependent id="4">say</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">limits</governor>
          <dependent id="5">term</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">plot</governor>
          <dependent id="6">limits</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="10">plot</governor>
          <dependent id="7">are</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">plot</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">plot</governor>
          <dependent id="9">Republican</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">say</governor>
          <dependent id="10">plot</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">oust</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="10">plot</governor>
          <dependent id="12">oust</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">oust</governor>
          <dependent id="13">incumbents</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">know</governor>
          <dependent id="14">should</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="28">says</governor>
          <dependent id="15">know</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">won</governor>
          <dependent id="16">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">majority</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="23">won</governor>
          <dependent id="18">majority</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">seats</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">seats</governor>
          <dependent id="20">open</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">majority</governor>
          <dependent id="21">seats</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="23">won</governor>
          <dependent id="22">are</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">know</governor>
          <dependent id="23">won</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">Democrats</governor>
          <dependent id="24">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">won</governor>
          <dependent id="25">Democrats</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="28">says</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">Jacobs</governor>
          <dependent id="29">Rep.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">Jacobs</governor>
          <dependent id="30">Andy</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">says</governor>
          <dependent id="31">Jacobs</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">Indiana</governor>
          <dependent id="32">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">Jacobs</governor>
          <dependent id="33">Indiana</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Democrats" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="25" string="Democrats" />
          </tokens>
        </entity>
        <entity id="2" string="Indiana" type="LOCATION" score="0.0">
          <tokens>
            <token id="33" string="Indiana" />
          </tokens>
        </entity>
        <entity id="3" string="Republican" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="9" string="Republican" />
          </tokens>
        </entity>
        <entity id="4" string="Andy Jacobs" type="PERSON" score="0.0">
          <tokens>
            <token id="30" string="Andy" />
            <token id="31" string="Jacobs" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="48" has_coreference="true">
      <content>Indeed, the Democratic Party could actually be helped by term limits, according to former Oklahoma state legislator Cleta Mitchell, a self-described &amp;quot;liberal feminist&amp;quot; who works with the Denver-based term limit group Americans Back in Charge.</content>
      <tokens>
        <token id="1" string="Indeed" lemma="indeed" stem="indeed" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="Democratic" lemma="Democratic" stem="democrat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="5" string="Party" lemma="Party" stem="parti" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="6" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="actually" lemma="actually" stem="actual" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="helped" lemma="help" stem="help" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="term" lemma="term" stem="term" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="limits" lemma="limit" stem="limit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="according" lemma="accord" stem="accord" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="former" lemma="former" stem="former" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="Oklahoma" lemma="Oklahoma" stem="oklahoma" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="18" string="state" lemma="state" stem="state" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="legislator" lemma="legislator" stem="legisl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="Cleta" lemma="Cleta" stem="cleta" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="21" string="Mitchell" lemma="Mitchell" stem="mitchel" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="self-described" lemma="self-described" stem="self-describ" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="liberal" lemma="liberal" stem="liber" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="27" string="feminist" lemma="feminist" stem="feminist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="works" lemma="work" stem="work" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="33" string="Denver-based" lemma="denver-based" stem="denver-bas" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="34" string="term" lemma="term" stem="term" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="35" string="limit" lemma="limit" stem="limit" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="36" string="group" lemma="group" stem="group" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="37" string="Americans" lemma="Americans" stem="american" pos="NNPS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="38" string="Back" lemma="back" stem="back" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="39" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="40" string="Charge" lemma="Charge" stem="charg" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="41" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Indeed)) (, ,) (NP (DT the) (NNP Democratic) (NNP Party)) (VP (MD could) (ADVP (RB actually)) (VP (VB be) (VP (VBN helped) (PP (IN by) (NP (NN term) (NNS limits))) (, ,) (PP (VBG according) (PP (TO to) (NP (NP (JJ former) (NNP Oklahoma) (NN state) (NN legislator) (NNP Cleta) (NNP Mitchell)) (, ,) (NP (NP (DT a) (JJ self-described) (`` ``) (JJ liberal) (NN feminist) ('' '')) (SBAR (WHNP (WP who)) (S (VP (VBZ works) (PP (IN with) (NP (NP (NP (DT the) (JJ Denver-based) (NN term) (NN limit) (NN group)) (NNPS Americans)) (ADVP (RB Back) (PP (IN in) (NP (NNP Charge)))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="be helped by term limits , according to former Oklahoma state legislator Cleta Mitchell , a self-described `` liberal feminist '' who works with the Denver-based term limit group Americans Back in Charge" type="VP">
          <tokens>
            <token id="8" string="be" />
            <token id="9" string="helped" />
            <token id="10" string="by" />
            <token id="11" string="term" />
            <token id="12" string="limits" />
            <token id="13" string="," />
            <token id="14" string="according" />
            <token id="15" string="to" />
            <token id="16" string="former" />
            <token id="17" string="Oklahoma" />
            <token id="18" string="state" />
            <token id="19" string="legislator" />
            <token id="20" string="Cleta" />
            <token id="21" string="Mitchell" />
            <token id="22" string="," />
            <token id="23" string="a" />
            <token id="24" string="self-described" />
            <token id="25" string="&quot;" />
            <token id="26" string="liberal" />
            <token id="27" string="feminist" />
            <token id="28" string="&quot;" />
            <token id="29" string="who" />
            <token id="30" string="works" />
            <token id="31" string="with" />
            <token id="32" string="the" />
            <token id="33" string="Denver-based" />
            <token id="34" string="term" />
            <token id="35" string="limit" />
            <token id="36" string="group" />
            <token id="37" string="Americans" />
            <token id="38" string="Back" />
            <token id="39" string="in" />
            <token id="40" string="Charge" />
          </tokens>
        </chunking>
        <chunking id="2" string="the Democratic Party" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="Democratic" />
            <token id="5" string="Party" />
          </tokens>
        </chunking>
        <chunking id="3" string="term limits" type="NP">
          <tokens>
            <token id="11" string="term" />
            <token id="12" string="limits" />
          </tokens>
        </chunking>
        <chunking id="4" string="the Denver-based term limit group" type="NP">
          <tokens>
            <token id="32" string="the" />
            <token id="33" string="Denver-based" />
            <token id="34" string="term" />
            <token id="35" string="limit" />
            <token id="36" string="group" />
          </tokens>
        </chunking>
        <chunking id="5" string="a self-described `` liberal feminist '' who works with the Denver-based term limit group Americans Back in Charge" type="NP">
          <tokens>
            <token id="23" string="a" />
            <token id="24" string="self-described" />
            <token id="25" string="&quot;" />
            <token id="26" string="liberal" />
            <token id="27" string="feminist" />
            <token id="28" string="&quot;" />
            <token id="29" string="who" />
            <token id="30" string="works" />
            <token id="31" string="with" />
            <token id="32" string="the" />
            <token id="33" string="Denver-based" />
            <token id="34" string="term" />
            <token id="35" string="limit" />
            <token id="36" string="group" />
            <token id="37" string="Americans" />
            <token id="38" string="Back" />
            <token id="39" string="in" />
            <token id="40" string="Charge" />
          </tokens>
        </chunking>
        <chunking id="6" string="works with the Denver-based term limit group Americans Back in Charge" type="VP">
          <tokens>
            <token id="30" string="works" />
            <token id="31" string="with" />
            <token id="32" string="the" />
            <token id="33" string="Denver-based" />
            <token id="34" string="term" />
            <token id="35" string="limit" />
            <token id="36" string="group" />
            <token id="37" string="Americans" />
            <token id="38" string="Back" />
            <token id="39" string="in" />
            <token id="40" string="Charge" />
          </tokens>
        </chunking>
        <chunking id="7" string="could actually be helped by term limits , according to former Oklahoma state legislator Cleta Mitchell , a self-described `` liberal feminist '' who works with the Denver-based term limit group Americans Back in Charge" type="VP">
          <tokens>
            <token id="6" string="could" />
            <token id="7" string="actually" />
            <token id="8" string="be" />
            <token id="9" string="helped" />
            <token id="10" string="by" />
            <token id="11" string="term" />
            <token id="12" string="limits" />
            <token id="13" string="," />
            <token id="14" string="according" />
            <token id="15" string="to" />
            <token id="16" string="former" />
            <token id="17" string="Oklahoma" />
            <token id="18" string="state" />
            <token id="19" string="legislator" />
            <token id="20" string="Cleta" />
            <token id="21" string="Mitchell" />
            <token id="22" string="," />
            <token id="23" string="a" />
            <token id="24" string="self-described" />
            <token id="25" string="&quot;" />
            <token id="26" string="liberal" />
            <token id="27" string="feminist" />
            <token id="28" string="&quot;" />
            <token id="29" string="who" />
            <token id="30" string="works" />
            <token id="31" string="with" />
            <token id="32" string="the" />
            <token id="33" string="Denver-based" />
            <token id="34" string="term" />
            <token id="35" string="limit" />
            <token id="36" string="group" />
            <token id="37" string="Americans" />
            <token id="38" string="Back" />
            <token id="39" string="in" />
            <token id="40" string="Charge" />
          </tokens>
        </chunking>
        <chunking id="8" string="former Oklahoma state legislator Cleta Mitchell" type="NP">
          <tokens>
            <token id="16" string="former" />
            <token id="17" string="Oklahoma" />
            <token id="18" string="state" />
            <token id="19" string="legislator" />
            <token id="20" string="Cleta" />
            <token id="21" string="Mitchell" />
          </tokens>
        </chunking>
        <chunking id="9" string="the Denver-based term limit group Americans Back in Charge" type="NP">
          <tokens>
            <token id="32" string="the" />
            <token id="33" string="Denver-based" />
            <token id="34" string="term" />
            <token id="35" string="limit" />
            <token id="36" string="group" />
            <token id="37" string="Americans" />
            <token id="38" string="Back" />
            <token id="39" string="in" />
            <token id="40" string="Charge" />
          </tokens>
        </chunking>
        <chunking id="10" string="Charge" type="NP">
          <tokens>
            <token id="40" string="Charge" />
          </tokens>
        </chunking>
        <chunking id="11" string="who works with the Denver-based term limit group Americans Back in Charge" type="SBAR">
          <tokens>
            <token id="29" string="who" />
            <token id="30" string="works" />
            <token id="31" string="with" />
            <token id="32" string="the" />
            <token id="33" string="Denver-based" />
            <token id="34" string="term" />
            <token id="35" string="limit" />
            <token id="36" string="group" />
            <token id="37" string="Americans" />
            <token id="38" string="Back" />
            <token id="39" string="in" />
            <token id="40" string="Charge" />
          </tokens>
        </chunking>
        <chunking id="12" string="former Oklahoma state legislator Cleta Mitchell , a self-described `` liberal feminist '' who works with the Denver-based term limit group Americans Back in Charge" type="NP">
          <tokens>
            <token id="16" string="former" />
            <token id="17" string="Oklahoma" />
            <token id="18" string="state" />
            <token id="19" string="legislator" />
            <token id="20" string="Cleta" />
            <token id="21" string="Mitchell" />
            <token id="22" string="," />
            <token id="23" string="a" />
            <token id="24" string="self-described" />
            <token id="25" string="&quot;" />
            <token id="26" string="liberal" />
            <token id="27" string="feminist" />
            <token id="28" string="&quot;" />
            <token id="29" string="who" />
            <token id="30" string="works" />
            <token id="31" string="with" />
            <token id="32" string="the" />
            <token id="33" string="Denver-based" />
            <token id="34" string="term" />
            <token id="35" string="limit" />
            <token id="36" string="group" />
            <token id="37" string="Americans" />
            <token id="38" string="Back" />
            <token id="39" string="in" />
            <token id="40" string="Charge" />
          </tokens>
        </chunking>
        <chunking id="13" string="the Denver-based term limit group Americans" type="NP">
          <tokens>
            <token id="32" string="the" />
            <token id="33" string="Denver-based" />
            <token id="34" string="term" />
            <token id="35" string="limit" />
            <token id="36" string="group" />
            <token id="37" string="Americans" />
          </tokens>
        </chunking>
        <chunking id="14" string="helped by term limits , according to former Oklahoma state legislator Cleta Mitchell , a self-described `` liberal feminist '' who works with the Denver-based term limit group Americans Back in Charge" type="VP">
          <tokens>
            <token id="9" string="helped" />
            <token id="10" string="by" />
            <token id="11" string="term" />
            <token id="12" string="limits" />
            <token id="13" string="," />
            <token id="14" string="according" />
            <token id="15" string="to" />
            <token id="16" string="former" />
            <token id="17" string="Oklahoma" />
            <token id="18" string="state" />
            <token id="19" string="legislator" />
            <token id="20" string="Cleta" />
            <token id="21" string="Mitchell" />
            <token id="22" string="," />
            <token id="23" string="a" />
            <token id="24" string="self-described" />
            <token id="25" string="&quot;" />
            <token id="26" string="liberal" />
            <token id="27" string="feminist" />
            <token id="28" string="&quot;" />
            <token id="29" string="who" />
            <token id="30" string="works" />
            <token id="31" string="with" />
            <token id="32" string="the" />
            <token id="33" string="Denver-based" />
            <token id="34" string="term" />
            <token id="35" string="limit" />
            <token id="36" string="group" />
            <token id="37" string="Americans" />
            <token id="38" string="Back" />
            <token id="39" string="in" />
            <token id="40" string="Charge" />
          </tokens>
        </chunking>
        <chunking id="15" string="a self-described `` liberal feminist ''" type="NP">
          <tokens>
            <token id="23" string="a" />
            <token id="24" string="self-described" />
            <token id="25" string="&quot;" />
            <token id="26" string="liberal" />
            <token id="27" string="feminist" />
            <token id="28" string="&quot;" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="9">helped</governor>
          <dependent id="1">Indeed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">Party</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Party</governor>
          <dependent id="4">Democratic</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="9">helped</governor>
          <dependent id="5">Party</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">helped</governor>
          <dependent id="6">could</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">helped</governor>
          <dependent id="7">actually</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="9">helped</governor>
          <dependent id="8">be</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">helped</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">limits</governor>
          <dependent id="10">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">limits</governor>
          <dependent id="11">term</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">helped</governor>
          <dependent id="12">limits</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">Mitchell</governor>
          <dependent id="14">according</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="14">according</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">Mitchell</governor>
          <dependent id="16">former</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">Mitchell</governor>
          <dependent id="17">Oklahoma</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">Mitchell</governor>
          <dependent id="18">state</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">Mitchell</governor>
          <dependent id="19">legislator</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">Mitchell</governor>
          <dependent id="20">Cleta</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">helped</governor>
          <dependent id="21">Mitchell</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">feminist</governor>
          <dependent id="23">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">feminist</governor>
          <dependent id="24">self-described</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">feminist</governor>
          <dependent id="26">liberal</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="21">Mitchell</governor>
          <dependent id="27">feminist</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="30">works</governor>
          <dependent id="29">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="27">feminist</governor>
          <dependent id="30">works</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">Americans</governor>
          <dependent id="31">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="36">group</governor>
          <dependent id="32">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="36">group</governor>
          <dependent id="33">Denver-based</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="36">group</governor>
          <dependent id="34">term</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="36">group</governor>
          <dependent id="35">limit</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="37">Americans</governor>
          <dependent id="36">group</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">works</governor>
          <dependent id="37">Americans</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="37">Americans</governor>
          <dependent id="38">Back</dependent>
        </dependency>
        <dependency type="case">
          <governor id="40">Charge</governor>
          <dependent id="39">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="38">Back</governor>
          <dependent id="40">Charge</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Oklahoma" type="LOCATION" score="0.0">
          <tokens>
            <token id="17" string="Oklahoma" />
          </tokens>
        </entity>
        <entity id="2" string="Cleta Mitchell" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="Cleta" />
            <token id="21" string="Mitchell" />
          </tokens>
        </entity>
        <entity id="3" string="Denver-based" type="MISC" score="0.0">
          <tokens>
            <token id="33" string="Denver-based" />
          </tokens>
        </entity>
        <entity id="4" string="Democratic Party" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="4" string="Democratic" />
            <token id="5" string="Party" />
          </tokens>
        </entity>
        <entity id="5" string="liberal" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="26" string="liberal" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="49" has_coreference="true">
      <content>&amp;quot;Democrats must offer voters more than the simple powers of incumbency,&amp;quot; she says.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Democrats" lemma="democrat" stem="democrat" pos="NNS" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="true" />
        <token id="3" string="must" lemma="must" stem="must" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="offer" lemma="offer" stem="offer" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="voters" lemma="voter" stem="voter" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="simple" lemma="simple" stem="simpl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="powers" lemma="power" stem="power" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="incumbency" lemma="incumbency" stem="incumb" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (NNS Democrats)) (VP (MD must) (VP (VB offer) (NP (NNS voters)) (NP (NP (QP (JJR more) (IN than) (DT the)) (JJ simple) (NNS powers)) (PP (IN of) (NP (NN incumbency))))))) (, ,) ('' '') (NP (PRP she)) (VP (VBZ says)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Democrats" type="NP">
          <tokens>
            <token id="2" string="Democrats" />
          </tokens>
        </chunking>
        <chunking id="2" string="must offer voters more than the simple powers of incumbency" type="VP">
          <tokens>
            <token id="3" string="must" />
            <token id="4" string="offer" />
            <token id="5" string="voters" />
            <token id="6" string="more" />
            <token id="7" string="than" />
            <token id="8" string="the" />
            <token id="9" string="simple" />
            <token id="10" string="powers" />
            <token id="11" string="of" />
            <token id="12" string="incumbency" />
          </tokens>
        </chunking>
        <chunking id="3" string="says" type="VP">
          <tokens>
            <token id="16" string="says" />
          </tokens>
        </chunking>
        <chunking id="4" string="incumbency" type="NP">
          <tokens>
            <token id="12" string="incumbency" />
          </tokens>
        </chunking>
        <chunking id="5" string="voters" type="NP">
          <tokens>
            <token id="5" string="voters" />
          </tokens>
        </chunking>
        <chunking id="6" string="more than the simple powers" type="NP">
          <tokens>
            <token id="6" string="more" />
            <token id="7" string="than" />
            <token id="8" string="the" />
            <token id="9" string="simple" />
            <token id="10" string="powers" />
          </tokens>
        </chunking>
        <chunking id="7" string="more than the simple powers of incumbency" type="NP">
          <tokens>
            <token id="6" string="more" />
            <token id="7" string="than" />
            <token id="8" string="the" />
            <token id="9" string="simple" />
            <token id="10" string="powers" />
            <token id="11" string="of" />
            <token id="12" string="incumbency" />
          </tokens>
        </chunking>
        <chunking id="8" string="offer voters more than the simple powers of incumbency" type="VP">
          <tokens>
            <token id="4" string="offer" />
            <token id="5" string="voters" />
            <token id="6" string="more" />
            <token id="7" string="than" />
            <token id="8" string="the" />
            <token id="9" string="simple" />
            <token id="10" string="powers" />
            <token id="11" string="of" />
            <token id="12" string="incumbency" />
          </tokens>
        </chunking>
        <chunking id="9" string="she" type="NP">
          <tokens>
            <token id="15" string="she" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">offer</governor>
          <dependent id="2">Democrats</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">offer</governor>
          <dependent id="3">must</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">says</governor>
          <dependent id="4">offer</dependent>
        </dependency>
        <dependency type="iobj">
          <governor id="4">offer</governor>
          <dependent id="5">voters</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">the</governor>
          <dependent id="6">more</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="6">more</governor>
          <dependent id="7">than</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="10">powers</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">powers</governor>
          <dependent id="9">simple</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">offer</governor>
          <dependent id="10">powers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">incumbency</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">powers</governor>
          <dependent id="12">incumbency</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">says</governor>
          <dependent id="15">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">says</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Democrats" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="2" string="Democrats" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="50" has_coreference="true">
      <content>&amp;quot;So long as our party is dominated by cynical veterans it will turn off the young people who are our party&amp;apost;s future.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="So" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="long" lemma="long" stem="long" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="our" lemma="we" stem="our" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="party" lemma="party" stem="parti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="dominated" lemma="dominate" stem="domin" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="cynical" lemma="cynical" stem="cynic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="veterans" lemma="veteran" stem="veteran" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="turn" lemma="turn" stem="turn" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="off" lemma="off" stem="off" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="young" lemma="young" stem="young" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="our" lemma="we" stem="our" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="party" lemma="party" stem="parti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="23" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="future" lemma="future" stem="futur" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (SBAR (ADVP (RB So) (RB long)) (IN as) (S (NP (PRP$ our) (NN party)) (VP (VBZ is) (VP (VBN dominated) (PP (IN by) (NP (JJ cynical) (NNS veterans))))))) (NP (PRP it)) (VP (MD will) (VP (VB turn) (PRT (RP off)) (NP (NP (DT the) (JJ young) (NNS people)) (SBAR (WHNP (WP who)) (S (VP (VBP are) (NP (NP (PRP$ our) (NN party) (POS 's)) (NN future)))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="dominated by cynical veterans" type="VP">
          <tokens>
            <token id="8" string="dominated" />
            <token id="9" string="by" />
            <token id="10" string="cynical" />
            <token id="11" string="veterans" />
          </tokens>
        </chunking>
        <chunking id="2" string="turn off the young people who are our party 's future" type="VP">
          <tokens>
            <token id="14" string="turn" />
            <token id="15" string="off" />
            <token id="16" string="the" />
            <token id="17" string="young" />
            <token id="18" string="people" />
            <token id="19" string="who" />
            <token id="20" string="are" />
            <token id="21" string="our" />
            <token id="22" string="party" />
            <token id="23" string="'s" />
            <token id="24" string="future" />
          </tokens>
        </chunking>
        <chunking id="3" string="our party 's" type="NP">
          <tokens>
            <token id="21" string="our" />
            <token id="22" string="party" />
            <token id="23" string="'s" />
          </tokens>
        </chunking>
        <chunking id="4" string="is dominated by cynical veterans" type="VP">
          <tokens>
            <token id="7" string="is" />
            <token id="8" string="dominated" />
            <token id="9" string="by" />
            <token id="10" string="cynical" />
            <token id="11" string="veterans" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="12" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="are our party 's future" type="VP">
          <tokens>
            <token id="20" string="are" />
            <token id="21" string="our" />
            <token id="22" string="party" />
            <token id="23" string="'s" />
            <token id="24" string="future" />
          </tokens>
        </chunking>
        <chunking id="7" string="our party 's future" type="NP">
          <tokens>
            <token id="21" string="our" />
            <token id="22" string="party" />
            <token id="23" string="'s" />
            <token id="24" string="future" />
          </tokens>
        </chunking>
        <chunking id="8" string="So long as our party is dominated by cynical veterans" type="SBAR">
          <tokens>
            <token id="2" string="So" />
            <token id="3" string="long" />
            <token id="4" string="as" />
            <token id="5" string="our" />
            <token id="6" string="party" />
            <token id="7" string="is" />
            <token id="8" string="dominated" />
            <token id="9" string="by" />
            <token id="10" string="cynical" />
            <token id="11" string="veterans" />
          </tokens>
        </chunking>
        <chunking id="9" string="the young people who are our party 's future" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="young" />
            <token id="18" string="people" />
            <token id="19" string="who" />
            <token id="20" string="are" />
            <token id="21" string="our" />
            <token id="22" string="party" />
            <token id="23" string="'s" />
            <token id="24" string="future" />
          </tokens>
        </chunking>
        <chunking id="10" string="will turn off the young people who are our party 's future" type="VP">
          <tokens>
            <token id="13" string="will" />
            <token id="14" string="turn" />
            <token id="15" string="off" />
            <token id="16" string="the" />
            <token id="17" string="young" />
            <token id="18" string="people" />
            <token id="19" string="who" />
            <token id="20" string="are" />
            <token id="21" string="our" />
            <token id="22" string="party" />
            <token id="23" string="'s" />
            <token id="24" string="future" />
          </tokens>
        </chunking>
        <chunking id="11" string="cynical veterans" type="NP">
          <tokens>
            <token id="10" string="cynical" />
            <token id="11" string="veterans" />
          </tokens>
        </chunking>
        <chunking id="12" string="who are our party 's future" type="SBAR">
          <tokens>
            <token id="19" string="who" />
            <token id="20" string="are" />
            <token id="21" string="our" />
            <token id="22" string="party" />
            <token id="23" string="'s" />
            <token id="24" string="future" />
          </tokens>
        </chunking>
        <chunking id="13" string="the young people" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="young" />
            <token id="18" string="people" />
          </tokens>
        </chunking>
        <chunking id="14" string="our party" type="NP">
          <tokens>
            <token id="5" string="our" />
            <token id="6" string="party" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="3">long</governor>
          <dependent id="2">So</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">dominated</governor>
          <dependent id="3">long</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">dominated</governor>
          <dependent id="4">as</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">party</governor>
          <dependent id="5">our</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="8">dominated</governor>
          <dependent id="6">party</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="8">dominated</governor>
          <dependent id="7">is</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="14">turn</governor>
          <dependent id="8">dominated</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">veterans</governor>
          <dependent id="9">by</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">veterans</governor>
          <dependent id="10">cynical</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">dominated</governor>
          <dependent id="11">veterans</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">turn</governor>
          <dependent id="12">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">turn</governor>
          <dependent id="13">will</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">turn</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="14">turn</governor>
          <dependent id="15">off</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">people</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">people</governor>
          <dependent id="17">young</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">turn</governor>
          <dependent id="18">people</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">future</governor>
          <dependent id="19">who</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="24">future</governor>
          <dependent id="20">are</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="22">party</governor>
          <dependent id="21">our</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="24">future</governor>
          <dependent id="22">party</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">party</governor>
          <dependent id="23">'s</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="18">people</governor>
          <dependent id="24">future</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="future" type="DATE" score="0.0">
          <tokens>
            <token id="24" string="future" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="51" has_coreference="false">
      <content>No one suggests the drive to enact term limits will be easy -- especially in states that ban voter initiatives.</content>
      <tokens>
        <token id="1" string="No" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="one" lemma="one" stem="on" pos="NN" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="3" string="suggests" lemma="suggest" stem="suggest" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="drive" lemma="drive" stem="drive" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="enact" lemma="enact" stem="enact" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="term" lemma="term" stem="term" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="limits" lemma="limit" stem="limit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="easy" lemma="easy" stem="easi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="especially" lemma="especially" stem="especi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="states" lemma="state" stem="state" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="ban" lemma="ban" stem="ban" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="voter" lemma="voter" stem="voter" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="initiatives" lemma="initiative" stem="initi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT No) (NN one)) (VP (VBZ suggests) (NP (DT the) (NN drive) (S (VP (TO to) (VP (VB enact) (SBAR (S (NP (NN term) (NNS limits)) (VP (MD will) (VP (VB be) (ADJP (JJ easy)) (: --) (PP (RB especially) (IN in) (NP (NP (NNS states)) (SBAR (WHNP (WDT that)) (S (VP (VBP ban) (NP (NN voter) (NNS initiatives)))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="No one" type="NP">
          <tokens>
            <token id="1" string="No" />
            <token id="2" string="one" />
          </tokens>
        </chunking>
        <chunking id="2" string="term limits will be easy -- especially in states that ban voter initiatives" type="SBAR">
          <tokens>
            <token id="8" string="term" />
            <token id="9" string="limits" />
            <token id="10" string="will" />
            <token id="11" string="be" />
            <token id="12" string="easy" />
            <token id="13" string="--" />
            <token id="14" string="especially" />
            <token id="15" string="in" />
            <token id="16" string="states" />
            <token id="17" string="that" />
            <token id="18" string="ban" />
            <token id="19" string="voter" />
            <token id="20" string="initiatives" />
          </tokens>
        </chunking>
        <chunking id="3" string="term limits" type="NP">
          <tokens>
            <token id="8" string="term" />
            <token id="9" string="limits" />
          </tokens>
        </chunking>
        <chunking id="4" string="voter initiatives" type="NP">
          <tokens>
            <token id="19" string="voter" />
            <token id="20" string="initiatives" />
          </tokens>
        </chunking>
        <chunking id="5" string="ban voter initiatives" type="VP">
          <tokens>
            <token id="18" string="ban" />
            <token id="19" string="voter" />
            <token id="20" string="initiatives" />
          </tokens>
        </chunking>
        <chunking id="6" string="states" type="NP">
          <tokens>
            <token id="16" string="states" />
          </tokens>
        </chunking>
        <chunking id="7" string="to enact term limits will be easy -- especially in states that ban voter initiatives" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="enact" />
            <token id="8" string="term" />
            <token id="9" string="limits" />
            <token id="10" string="will" />
            <token id="11" string="be" />
            <token id="12" string="easy" />
            <token id="13" string="--" />
            <token id="14" string="especially" />
            <token id="15" string="in" />
            <token id="16" string="states" />
            <token id="17" string="that" />
            <token id="18" string="ban" />
            <token id="19" string="voter" />
            <token id="20" string="initiatives" />
          </tokens>
        </chunking>
        <chunking id="8" string="will be easy -- especially in states that ban voter initiatives" type="VP">
          <tokens>
            <token id="10" string="will" />
            <token id="11" string="be" />
            <token id="12" string="easy" />
            <token id="13" string="--" />
            <token id="14" string="especially" />
            <token id="15" string="in" />
            <token id="16" string="states" />
            <token id="17" string="that" />
            <token id="18" string="ban" />
            <token id="19" string="voter" />
            <token id="20" string="initiatives" />
          </tokens>
        </chunking>
        <chunking id="9" string="easy" type="ADJP">
          <tokens>
            <token id="12" string="easy" />
          </tokens>
        </chunking>
        <chunking id="10" string="the drive to enact term limits will be easy -- especially in states that ban voter initiatives" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="drive" />
            <token id="6" string="to" />
            <token id="7" string="enact" />
            <token id="8" string="term" />
            <token id="9" string="limits" />
            <token id="10" string="will" />
            <token id="11" string="be" />
            <token id="12" string="easy" />
            <token id="13" string="--" />
            <token id="14" string="especially" />
            <token id="15" string="in" />
            <token id="16" string="states" />
            <token id="17" string="that" />
            <token id="18" string="ban" />
            <token id="19" string="voter" />
            <token id="20" string="initiatives" />
          </tokens>
        </chunking>
        <chunking id="11" string="be easy -- especially in states that ban voter initiatives" type="VP">
          <tokens>
            <token id="11" string="be" />
            <token id="12" string="easy" />
            <token id="13" string="--" />
            <token id="14" string="especially" />
            <token id="15" string="in" />
            <token id="16" string="states" />
            <token id="17" string="that" />
            <token id="18" string="ban" />
            <token id="19" string="voter" />
            <token id="20" string="initiatives" />
          </tokens>
        </chunking>
        <chunking id="12" string="that ban voter initiatives" type="SBAR">
          <tokens>
            <token id="17" string="that" />
            <token id="18" string="ban" />
            <token id="19" string="voter" />
            <token id="20" string="initiatives" />
          </tokens>
        </chunking>
        <chunking id="13" string="suggests the drive to enact term limits will be easy -- especially in states that ban voter initiatives" type="VP">
          <tokens>
            <token id="3" string="suggests" />
            <token id="4" string="the" />
            <token id="5" string="drive" />
            <token id="6" string="to" />
            <token id="7" string="enact" />
            <token id="8" string="term" />
            <token id="9" string="limits" />
            <token id="10" string="will" />
            <token id="11" string="be" />
            <token id="12" string="easy" />
            <token id="13" string="--" />
            <token id="14" string="especially" />
            <token id="15" string="in" />
            <token id="16" string="states" />
            <token id="17" string="that" />
            <token id="18" string="ban" />
            <token id="19" string="voter" />
            <token id="20" string="initiatives" />
          </tokens>
        </chunking>
        <chunking id="14" string="enact term limits will be easy -- especially in states that ban voter initiatives" type="VP">
          <tokens>
            <token id="7" string="enact" />
            <token id="8" string="term" />
            <token id="9" string="limits" />
            <token id="10" string="will" />
            <token id="11" string="be" />
            <token id="12" string="easy" />
            <token id="13" string="--" />
            <token id="14" string="especially" />
            <token id="15" string="in" />
            <token id="16" string="states" />
            <token id="17" string="that" />
            <token id="18" string="ban" />
            <token id="19" string="voter" />
            <token id="20" string="initiatives" />
          </tokens>
        </chunking>
        <chunking id="15" string="states that ban voter initiatives" type="NP">
          <tokens>
            <token id="16" string="states" />
            <token id="17" string="that" />
            <token id="18" string="ban" />
            <token id="19" string="voter" />
            <token id="20" string="initiatives" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="neg">
          <governor id="2">one</governor>
          <dependent id="1">No</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">suggests</governor>
          <dependent id="2">one</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">suggests</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">drive</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">suggests</governor>
          <dependent id="5">drive</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">enact</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="5">drive</governor>
          <dependent id="7">enact</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">limits</governor>
          <dependent id="8">term</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">easy</governor>
          <dependent id="9">limits</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">easy</governor>
          <dependent id="10">will</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">easy</governor>
          <dependent id="11">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">enact</governor>
          <dependent id="12">easy</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">states</governor>
          <dependent id="14">especially</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">states</governor>
          <dependent id="15">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">easy</governor>
          <dependent id="16">states</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">ban</governor>
          <dependent id="17">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="16">states</governor>
          <dependent id="18">ban</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">initiatives</governor>
          <dependent id="19">voter</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">ban</governor>
          <dependent id="20">initiatives</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="2" string="one" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="52" has_coreference="false">
      <content>But there are already signs that business lobbies, labor unions and other term limit opponents are relying more on convincing judges -- starting with Florida&amp;apost;s heavily politicized state Supreme Court -- to overturn state term limits than on trying to convince voters to reject the idea.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="already" lemma="already" stem="alreadi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="signs" lemma="sign" stem="sign" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="business" lemma="business" stem="busi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="lobbies" lemma="lobby" stem="lobbi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="labor" lemma="labor" stem="labor" pos="NN" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="11" string="unions" lemma="union" stem="union" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="term" lemma="term" stem="term" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="limit" lemma="limit" stem="limit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="opponents" lemma="opponent" stem="oppon" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="relying" lemma="rely" stem="reli" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="convincing" lemma="convincing" stem="convinc" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="judges" lemma="judge" stem="judg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="starting" lemma="start" stem="start" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="Florida" lemma="Florida" stem="florida" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="27" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="heavily" lemma="heavily" stem="heavili" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="politicized" lemma="politicize" stem="politic" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="state" lemma="state" stem="state" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="Supreme" lemma="Supreme" stem="suprem" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="32" string="Court" lemma="Court" stem="court" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="33" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="overturn" lemma="overturn" stem="overturn" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="state" lemma="state" stem="state" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="term" lemma="term" stem="term" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="limits" lemma="limit" stem="limit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="trying" lemma="try" stem="try" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="convince" lemma="convince" stem="convinc" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="voters" lemma="voter" stem="voter" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="reject" lemma="reject" stem="reject" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="47" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="48" string="idea" lemma="idea" stem="idea" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="49" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (EX there)) (VP (VBP are) (ADVP (RB already)) (NP (NP (NNS signs)) (SBAR (IN that) (S (NP (NP (NN business) (NNS lobbies)) (, ,) (NP (NN labor) (NNS unions)) (CC and) (NP (JJ other) (NN term) (NN limit) (NNS opponents))) (VP (VBP are) (VP (VBG relying) (ADVP (RBR more) (PP (IN on) (NP (JJ convincing) (NNS judges)))) (: --) (PP (VBG starting) (PP (IN with) (NP (NP (NP (NP (NNP Florida) (POS 's)) (ADJP (RB heavily) (VBN politicized)) (NN state)) (PRN (NP (NNP Supreme) (NNP Court)))) (: --) (S (VP (TO to) (VP (VB overturn) (NP (NN state) (NN term) (NNS limits)) (PP (IN than) (PP (IN on) (S (VP (VBG trying) (S (VP (TO to) (VP (VB convince) (NP (NNS voters))))))))))))))) (S (VP (TO to) (VP (VB reject) (NP (DT the) (NN idea))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that business lobbies , labor unions and other term limit opponents are relying more on convincing judges -- starting with Florida 's heavily politicized state Supreme Court -- to overturn state term limits than on trying to convince voters to reject the idea" type="SBAR">
          <tokens>
            <token id="6" string="that" />
            <token id="7" string="business" />
            <token id="8" string="lobbies" />
            <token id="9" string="," />
            <token id="10" string="labor" />
            <token id="11" string="unions" />
            <token id="12" string="and" />
            <token id="13" string="other" />
            <token id="14" string="term" />
            <token id="15" string="limit" />
            <token id="16" string="opponents" />
            <token id="17" string="are" />
            <token id="18" string="relying" />
            <token id="19" string="more" />
            <token id="20" string="on" />
            <token id="21" string="convincing" />
            <token id="22" string="judges" />
            <token id="23" string="--" />
            <token id="24" string="starting" />
            <token id="25" string="with" />
            <token id="26" string="Florida" />
            <token id="27" string="'s" />
            <token id="28" string="heavily" />
            <token id="29" string="politicized" />
            <token id="30" string="state" />
            <token id="31" string="Supreme" />
            <token id="32" string="Court" />
            <token id="33" string="--" />
            <token id="34" string="to" />
            <token id="35" string="overturn" />
            <token id="36" string="state" />
            <token id="37" string="term" />
            <token id="38" string="limits" />
            <token id="39" string="than" />
            <token id="40" string="on" />
            <token id="41" string="trying" />
            <token id="42" string="to" />
            <token id="43" string="convince" />
            <token id="44" string="voters" />
            <token id="45" string="to" />
            <token id="46" string="reject" />
            <token id="47" string="the" />
            <token id="48" string="idea" />
          </tokens>
        </chunking>
        <chunking id="2" string="Supreme Court" type="NP">
          <tokens>
            <token id="31" string="Supreme" />
            <token id="32" string="Court" />
          </tokens>
        </chunking>
        <chunking id="3" string="business lobbies , labor unions and other term limit opponents" type="NP">
          <tokens>
            <token id="7" string="business" />
            <token id="8" string="lobbies" />
            <token id="9" string="," />
            <token id="10" string="labor" />
            <token id="11" string="unions" />
            <token id="12" string="and" />
            <token id="13" string="other" />
            <token id="14" string="term" />
            <token id="15" string="limit" />
            <token id="16" string="opponents" />
          </tokens>
        </chunking>
        <chunking id="4" string="are already signs that business lobbies , labor unions and other term limit opponents are relying more on convincing judges -- starting with Florida 's heavily politicized state Supreme Court -- to overturn state term limits than on trying to convince voters to reject the idea" type="VP">
          <tokens>
            <token id="3" string="are" />
            <token id="4" string="already" />
            <token id="5" string="signs" />
            <token id="6" string="that" />
            <token id="7" string="business" />
            <token id="8" string="lobbies" />
            <token id="9" string="," />
            <token id="10" string="labor" />
            <token id="11" string="unions" />
            <token id="12" string="and" />
            <token id="13" string="other" />
            <token id="14" string="term" />
            <token id="15" string="limit" />
            <token id="16" string="opponents" />
            <token id="17" string="are" />
            <token id="18" string="relying" />
            <token id="19" string="more" />
            <token id="20" string="on" />
            <token id="21" string="convincing" />
            <token id="22" string="judges" />
            <token id="23" string="--" />
            <token id="24" string="starting" />
            <token id="25" string="with" />
            <token id="26" string="Florida" />
            <token id="27" string="'s" />
            <token id="28" string="heavily" />
            <token id="29" string="politicized" />
            <token id="30" string="state" />
            <token id="31" string="Supreme" />
            <token id="32" string="Court" />
            <token id="33" string="--" />
            <token id="34" string="to" />
            <token id="35" string="overturn" />
            <token id="36" string="state" />
            <token id="37" string="term" />
            <token id="38" string="limits" />
            <token id="39" string="than" />
            <token id="40" string="on" />
            <token id="41" string="trying" />
            <token id="42" string="to" />
            <token id="43" string="convince" />
            <token id="44" string="voters" />
            <token id="45" string="to" />
            <token id="46" string="reject" />
            <token id="47" string="the" />
            <token id="48" string="idea" />
          </tokens>
        </chunking>
        <chunking id="5" string="labor unions" type="NP">
          <tokens>
            <token id="10" string="labor" />
            <token id="11" string="unions" />
          </tokens>
        </chunking>
        <chunking id="6" string="signs that business lobbies , labor unions and other term limit opponents are relying more on convincing judges -- starting with Florida 's heavily politicized state Supreme Court -- to overturn state term limits than on trying to convince voters to reject the idea" type="NP">
          <tokens>
            <token id="5" string="signs" />
            <token id="6" string="that" />
            <token id="7" string="business" />
            <token id="8" string="lobbies" />
            <token id="9" string="," />
            <token id="10" string="labor" />
            <token id="11" string="unions" />
            <token id="12" string="and" />
            <token id="13" string="other" />
            <token id="14" string="term" />
            <token id="15" string="limit" />
            <token id="16" string="opponents" />
            <token id="17" string="are" />
            <token id="18" string="relying" />
            <token id="19" string="more" />
            <token id="20" string="on" />
            <token id="21" string="convincing" />
            <token id="22" string="judges" />
            <token id="23" string="--" />
            <token id="24" string="starting" />
            <token id="25" string="with" />
            <token id="26" string="Florida" />
            <token id="27" string="'s" />
            <token id="28" string="heavily" />
            <token id="29" string="politicized" />
            <token id="30" string="state" />
            <token id="31" string="Supreme" />
            <token id="32" string="Court" />
            <token id="33" string="--" />
            <token id="34" string="to" />
            <token id="35" string="overturn" />
            <token id="36" string="state" />
            <token id="37" string="term" />
            <token id="38" string="limits" />
            <token id="39" string="than" />
            <token id="40" string="on" />
            <token id="41" string="trying" />
            <token id="42" string="to" />
            <token id="43" string="convince" />
            <token id="44" string="voters" />
            <token id="45" string="to" />
            <token id="46" string="reject" />
            <token id="47" string="the" />
            <token id="48" string="idea" />
          </tokens>
        </chunking>
        <chunking id="7" string="to reject the idea" type="VP">
          <tokens>
            <token id="45" string="to" />
            <token id="46" string="reject" />
            <token id="47" string="the" />
            <token id="48" string="idea" />
          </tokens>
        </chunking>
        <chunking id="8" string="there" type="NP">
          <tokens>
            <token id="2" string="there" />
          </tokens>
        </chunking>
        <chunking id="9" string="convincing judges" type="NP">
          <tokens>
            <token id="21" string="convincing" />
            <token id="22" string="judges" />
          </tokens>
        </chunking>
        <chunking id="10" string="convince voters" type="VP">
          <tokens>
            <token id="43" string="convince" />
            <token id="44" string="voters" />
          </tokens>
        </chunking>
        <chunking id="11" string="voters" type="NP">
          <tokens>
            <token id="44" string="voters" />
          </tokens>
        </chunking>
        <chunking id="12" string="are relying more on convincing judges -- starting with Florida 's heavily politicized state Supreme Court -- to overturn state term limits than on trying to convince voters to reject the idea" type="VP">
          <tokens>
            <token id="17" string="are" />
            <token id="18" string="relying" />
            <token id="19" string="more" />
            <token id="20" string="on" />
            <token id="21" string="convincing" />
            <token id="22" string="judges" />
            <token id="23" string="--" />
            <token id="24" string="starting" />
            <token id="25" string="with" />
            <token id="26" string="Florida" />
            <token id="27" string="'s" />
            <token id="28" string="heavily" />
            <token id="29" string="politicized" />
            <token id="30" string="state" />
            <token id="31" string="Supreme" />
            <token id="32" string="Court" />
            <token id="33" string="--" />
            <token id="34" string="to" />
            <token id="35" string="overturn" />
            <token id="36" string="state" />
            <token id="37" string="term" />
            <token id="38" string="limits" />
            <token id="39" string="than" />
            <token id="40" string="on" />
            <token id="41" string="trying" />
            <token id="42" string="to" />
            <token id="43" string="convince" />
            <token id="44" string="voters" />
            <token id="45" string="to" />
            <token id="46" string="reject" />
            <token id="47" string="the" />
            <token id="48" string="idea" />
          </tokens>
        </chunking>
        <chunking id="13" string="Florida 's heavily politicized state" type="NP">
          <tokens>
            <token id="26" string="Florida" />
            <token id="27" string="'s" />
            <token id="28" string="heavily" />
            <token id="29" string="politicized" />
            <token id="30" string="state" />
          </tokens>
        </chunking>
        <chunking id="14" string="to overturn state term limits than on trying to convince voters" type="VP">
          <tokens>
            <token id="34" string="to" />
            <token id="35" string="overturn" />
            <token id="36" string="state" />
            <token id="37" string="term" />
            <token id="38" string="limits" />
            <token id="39" string="than" />
            <token id="40" string="on" />
            <token id="41" string="trying" />
            <token id="42" string="to" />
            <token id="43" string="convince" />
            <token id="44" string="voters" />
          </tokens>
        </chunking>
        <chunking id="15" string="overturn state term limits than on trying to convince voters" type="VP">
          <tokens>
            <token id="35" string="overturn" />
            <token id="36" string="state" />
            <token id="37" string="term" />
            <token id="38" string="limits" />
            <token id="39" string="than" />
            <token id="40" string="on" />
            <token id="41" string="trying" />
            <token id="42" string="to" />
            <token id="43" string="convince" />
            <token id="44" string="voters" />
          </tokens>
        </chunking>
        <chunking id="16" string="other term limit opponents" type="NP">
          <tokens>
            <token id="13" string="other" />
            <token id="14" string="term" />
            <token id="15" string="limit" />
            <token id="16" string="opponents" />
          </tokens>
        </chunking>
        <chunking id="17" string="Florida 's heavily politicized state Supreme Court -- to overturn state term limits than on trying to convince voters" type="NP">
          <tokens>
            <token id="26" string="Florida" />
            <token id="27" string="'s" />
            <token id="28" string="heavily" />
            <token id="29" string="politicized" />
            <token id="30" string="state" />
            <token id="31" string="Supreme" />
            <token id="32" string="Court" />
            <token id="33" string="--" />
            <token id="34" string="to" />
            <token id="35" string="overturn" />
            <token id="36" string="state" />
            <token id="37" string="term" />
            <token id="38" string="limits" />
            <token id="39" string="than" />
            <token id="40" string="on" />
            <token id="41" string="trying" />
            <token id="42" string="to" />
            <token id="43" string="convince" />
            <token id="44" string="voters" />
          </tokens>
        </chunking>
        <chunking id="18" string="state term limits" type="NP">
          <tokens>
            <token id="36" string="state" />
            <token id="37" string="term" />
            <token id="38" string="limits" />
          </tokens>
        </chunking>
        <chunking id="19" string="Florida 's heavily politicized state Supreme Court" type="NP">
          <tokens>
            <token id="26" string="Florida" />
            <token id="27" string="'s" />
            <token id="28" string="heavily" />
            <token id="29" string="politicized" />
            <token id="30" string="state" />
            <token id="31" string="Supreme" />
            <token id="32" string="Court" />
          </tokens>
        </chunking>
        <chunking id="20" string="signs" type="NP">
          <tokens>
            <token id="5" string="signs" />
          </tokens>
        </chunking>
        <chunking id="21" string="trying to convince voters" type="VP">
          <tokens>
            <token id="41" string="trying" />
            <token id="42" string="to" />
            <token id="43" string="convince" />
            <token id="44" string="voters" />
          </tokens>
        </chunking>
        <chunking id="22" string="heavily politicized" type="ADJP">
          <tokens>
            <token id="28" string="heavily" />
            <token id="29" string="politicized" />
          </tokens>
        </chunking>
        <chunking id="23" string="relying more on convincing judges -- starting with Florida 's heavily politicized state Supreme Court -- to overturn state term limits than on trying to convince voters to reject the idea" type="VP">
          <tokens>
            <token id="18" string="relying" />
            <token id="19" string="more" />
            <token id="20" string="on" />
            <token id="21" string="convincing" />
            <token id="22" string="judges" />
            <token id="23" string="--" />
            <token id="24" string="starting" />
            <token id="25" string="with" />
            <token id="26" string="Florida" />
            <token id="27" string="'s" />
            <token id="28" string="heavily" />
            <token id="29" string="politicized" />
            <token id="30" string="state" />
            <token id="31" string="Supreme" />
            <token id="32" string="Court" />
            <token id="33" string="--" />
            <token id="34" string="to" />
            <token id="35" string="overturn" />
            <token id="36" string="state" />
            <token id="37" string="term" />
            <token id="38" string="limits" />
            <token id="39" string="than" />
            <token id="40" string="on" />
            <token id="41" string="trying" />
            <token id="42" string="to" />
            <token id="43" string="convince" />
            <token id="44" string="voters" />
            <token id="45" string="to" />
            <token id="46" string="reject" />
            <token id="47" string="the" />
            <token id="48" string="idea" />
          </tokens>
        </chunking>
        <chunking id="24" string="reject the idea" type="VP">
          <tokens>
            <token id="46" string="reject" />
            <token id="47" string="the" />
            <token id="48" string="idea" />
          </tokens>
        </chunking>
        <chunking id="25" string="Florida 's" type="NP">
          <tokens>
            <token id="26" string="Florida" />
            <token id="27" string="'s" />
          </tokens>
        </chunking>
        <chunking id="26" string="to convince voters" type="VP">
          <tokens>
            <token id="42" string="to" />
            <token id="43" string="convince" />
            <token id="44" string="voters" />
          </tokens>
        </chunking>
        <chunking id="27" string="the idea" type="NP">
          <tokens>
            <token id="47" string="the" />
            <token id="48" string="idea" />
          </tokens>
        </chunking>
        <chunking id="28" string="business lobbies" type="NP">
          <tokens>
            <token id="7" string="business" />
            <token id="8" string="lobbies" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="3">are</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="3">are</governor>
          <dependent id="2">there</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">are</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">are</governor>
          <dependent id="4">already</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">are</governor>
          <dependent id="5">signs</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">relying</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">lobbies</governor>
          <dependent id="7">business</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">relying</governor>
          <dependent id="8">lobbies</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">unions</governor>
          <dependent id="10">labor</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">lobbies</governor>
          <dependent id="11">unions</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">lobbies</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">opponents</governor>
          <dependent id="13">other</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">opponents</governor>
          <dependent id="14">term</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">opponents</governor>
          <dependent id="15">limit</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">lobbies</governor>
          <dependent id="16">opponents</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">relying</governor>
          <dependent id="17">are</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="5">signs</governor>
          <dependent id="18">relying</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">relying</governor>
          <dependent id="19">more</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">judges</governor>
          <dependent id="20">on</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">judges</governor>
          <dependent id="21">convincing</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">more</governor>
          <dependent id="22">judges</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">state</governor>
          <dependent id="24">starting</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">state</governor>
          <dependent id="25">with</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="30">state</governor>
          <dependent id="26">Florida</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">Florida</governor>
          <dependent id="27">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="29">politicized</governor>
          <dependent id="28">heavily</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="30">state</governor>
          <dependent id="29">politicized</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="18">relying</governor>
          <dependent id="30">state</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="32">Court</governor>
          <dependent id="31">Supreme</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="30">state</governor>
          <dependent id="32">Court</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="35">overturn</governor>
          <dependent id="34">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="30">state</governor>
          <dependent id="35">overturn</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="38">limits</governor>
          <dependent id="36">state</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="38">limits</governor>
          <dependent id="37">term</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="35">overturn</governor>
          <dependent id="38">limits</dependent>
        </dependency>
        <dependency type="case">
          <governor id="41">trying</governor>
          <dependent id="39">than</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="41">trying</governor>
          <dependent id="40">on</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="35">overturn</governor>
          <dependent id="41">trying</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="43">convince</governor>
          <dependent id="42">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="41">trying</governor>
          <dependent id="43">convince</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="43">convince</governor>
          <dependent id="44">voters</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="46">reject</governor>
          <dependent id="45">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="18">relying</governor>
          <dependent id="46">reject</dependent>
        </dependency>
        <dependency type="det">
          <governor id="48">idea</governor>
          <dependent id="47">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="46">reject</governor>
          <dependent id="48">idea</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="labor" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="10" string="labor" />
          </tokens>
        </entity>
        <entity id="2" string="Supreme Court" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="31" string="Supreme" />
            <token id="32" string="Court" />
          </tokens>
        </entity>
        <entity id="3" string="Florida" type="LOCATION" score="0.0">
          <tokens>
            <token id="26" string="Florida" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="53" has_coreference="false">
      <content>The leading anti-term limit group, Let the People Decide, has closed its Washington, D.C., offices and been reduced to a skeleton staff.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="leading" lemma="lead" stem="lead" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="anti-term" lemma="anti-term" stem="anti-term" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="limit" lemma="limit" stem="limit" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="group" lemma="group" stem="group" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Let" lemma="let" stem="let" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="People" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="10" string="Decide" lemma="decide" stem="decid" pos="VBP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="closed" lemma="close" stem="close" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Washington" lemma="Washington" stem="washington" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="D.C." lemma="D.C." stem="d.c." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="offices" lemma="office" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="reduced" lemma="reduce" stem="reduc" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="skeleton" lemma="skeleton" stem="skeleton" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="staff" lemma="staff" stem="staff" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (VBG leading) (JJ anti-term) (NN limit) (NN group)) (, ,) (S (VP (VB Let) (SBAR (S (NP (DT the) (NNS People)) (VP (VBP Decide)))))) (, ,) (VP (VBZ has) (VP (VP (VBN closed) (S (NP (PRP$ its)) (NP (NAC (NNP Washington) (, ,) (NNP D.C.) (, ,)) (NNS offices)))) (CC and) (VP (VBN been) (VP (VBN reduced) (PP (TO to) (NP (DT a) (NN skeleton) (NN staff))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Decide" type="VP">
          <tokens>
            <token id="10" string="Decide" />
          </tokens>
        </chunking>
        <chunking id="2" string="the People" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="People" />
          </tokens>
        </chunking>
        <chunking id="3" string="has closed its Washington , D.C. , offices and been reduced to a skeleton staff" type="VP">
          <tokens>
            <token id="12" string="has" />
            <token id="13" string="closed" />
            <token id="14" string="its" />
            <token id="15" string="Washington" />
            <token id="16" string="," />
            <token id="17" string="D.C." />
            <token id="18" string="," />
            <token id="19" string="offices" />
            <token id="20" string="and" />
            <token id="21" string="been" />
            <token id="22" string="reduced" />
            <token id="23" string="to" />
            <token id="24" string="a" />
            <token id="25" string="skeleton" />
            <token id="26" string="staff" />
          </tokens>
        </chunking>
        <chunking id="4" string="its" type="NP">
          <tokens>
            <token id="14" string="its" />
          </tokens>
        </chunking>
        <chunking id="5" string="Let the People Decide" type="VP">
          <tokens>
            <token id="7" string="Let" />
            <token id="8" string="the" />
            <token id="9" string="People" />
            <token id="10" string="Decide" />
          </tokens>
        </chunking>
        <chunking id="6" string="reduced to a skeleton staff" type="VP">
          <tokens>
            <token id="22" string="reduced" />
            <token id="23" string="to" />
            <token id="24" string="a" />
            <token id="25" string="skeleton" />
            <token id="26" string="staff" />
          </tokens>
        </chunking>
        <chunking id="7" string="closed its Washington , D.C. , offices" type="VP">
          <tokens>
            <token id="13" string="closed" />
            <token id="14" string="its" />
            <token id="15" string="Washington" />
            <token id="16" string="," />
            <token id="17" string="D.C." />
            <token id="18" string="," />
            <token id="19" string="offices" />
          </tokens>
        </chunking>
        <chunking id="8" string="a skeleton staff" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="skeleton" />
            <token id="26" string="staff" />
          </tokens>
        </chunking>
        <chunking id="9" string="the People Decide" type="SBAR">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="People" />
            <token id="10" string="Decide" />
          </tokens>
        </chunking>
        <chunking id="10" string="closed its Washington , D.C. , offices and been reduced to a skeleton staff" type="VP">
          <tokens>
            <token id="13" string="closed" />
            <token id="14" string="its" />
            <token id="15" string="Washington" />
            <token id="16" string="," />
            <token id="17" string="D.C." />
            <token id="18" string="," />
            <token id="19" string="offices" />
            <token id="20" string="and" />
            <token id="21" string="been" />
            <token id="22" string="reduced" />
            <token id="23" string="to" />
            <token id="24" string="a" />
            <token id="25" string="skeleton" />
            <token id="26" string="staff" />
          </tokens>
        </chunking>
        <chunking id="11" string="been reduced to a skeleton staff" type="VP">
          <tokens>
            <token id="21" string="been" />
            <token id="22" string="reduced" />
            <token id="23" string="to" />
            <token id="24" string="a" />
            <token id="25" string="skeleton" />
            <token id="26" string="staff" />
          </tokens>
        </chunking>
        <chunking id="12" string="Washington , D.C. , offices" type="NP">
          <tokens>
            <token id="15" string="Washington" />
            <token id="16" string="," />
            <token id="17" string="D.C." />
            <token id="18" string="," />
            <token id="19" string="offices" />
          </tokens>
        </chunking>
        <chunking id="13" string="The leading anti-term limit group" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="leading" />
            <token id="3" string="anti-term" />
            <token id="4" string="limit" />
            <token id="5" string="group" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="5">group</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">group</governor>
          <dependent id="2">leading</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">group</governor>
          <dependent id="3">anti-term</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">group</governor>
          <dependent id="4">limit</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">closed</governor>
          <dependent id="5">group</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">closed</governor>
          <dependent id="7">Let</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">People</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">Decide</governor>
          <dependent id="9">People</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">Let</governor>
          <dependent id="10">Decide</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">closed</governor>
          <dependent id="12">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">closed</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">offices</governor>
          <dependent id="14">its</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="19">offices</governor>
          <dependent id="15">Washington</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="15">Washington</governor>
          <dependent id="17">D.C.</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="13">closed</governor>
          <dependent id="19">offices</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">closed</governor>
          <dependent id="20">and</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="22">reduced</governor>
          <dependent id="21">been</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">closed</governor>
          <dependent id="22">reduced</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">staff</governor>
          <dependent id="23">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">staff</governor>
          <dependent id="24">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">staff</governor>
          <dependent id="25">skeleton</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">reduced</governor>
          <dependent id="26">staff</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Washington" type="LOCATION" score="0.0">
          <tokens>
            <token id="15" string="Washington" />
          </tokens>
        </entity>
        <entity id="2" string="D.C." type="LOCATION" score="0.0">
          <tokens>
            <token id="17" string="D.C." />
          </tokens>
        </entity>
        <entity id="3" string="People Decide" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="9" string="People" />
            <token id="10" string="Decide" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="54" has_coreference="true">
      <content>--- Mr. Fund is a Journal editorial writer.</content>
      <tokens>
        <token id="1" string="---" lemma="--" stem="---" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="Fund" lemma="Fund" stem="fund" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Journal" lemma="Journal" stem="journal" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="7" string="editorial" lemma="editorial" stem="editori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="writer" lemma="writer" stem="writer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: --) (NP (NNP Mr.) (NNP Fund)) (VP (VBZ is) (NP (DT a) (NNP Journal) (NN editorial) (NN writer))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a Journal editorial writer" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="Journal" />
            <token id="7" string="editorial" />
            <token id="8" string="writer" />
          </tokens>
        </chunking>
        <chunking id="2" string="is a Journal editorial writer" type="VP">
          <tokens>
            <token id="4" string="is" />
            <token id="5" string="a" />
            <token id="6" string="Journal" />
            <token id="7" string="editorial" />
            <token id="8" string="writer" />
          </tokens>
        </chunking>
        <chunking id="3" string="Mr. Fund" type="NP">
          <tokens>
            <token id="2" string="Mr." />
            <token id="3" string="Fund" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Fund</governor>
          <dependent id="2">Mr.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">writer</governor>
          <dependent id="3">Fund</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">writer</governor>
          <dependent id="4">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">writer</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">writer</governor>
          <dependent id="6">Journal</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">writer</governor>
          <dependent id="7">editorial</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">writer</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Fund" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Fund" />
          </tokens>
        </entity>
        <entity id="2" string="Journal" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="6" string="Journal" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="NOMINAL">
      <referenced ids_tokens="5-6" string="term limits" id_sentence="1" />
      <mentions>
        <mention ids_tokens="21" string="limits" id_sentence="44" />
      </mentions>
    </coreference>
    <coreference id="3" type="NOMINAL">
      <referenced ids_tokens="9" string="women" id_sentence="2" />
      <mentions>
        <mention ids_tokens="7-8" string="women more" id_sentence="6" />
        <mention ids_tokens="1" string="We" id_sentence="8" />
      </mentions>
    </coreference>
    <coreference id="6" type="NOMINAL">
      <referenced ids_tokens="15-16-17-18-19-20-21-22-23-24-25-26" string="white incumbents hanging on to districts that long ago became largely minority" id_sentence="4" />
      <mentions>
        <mention ids_tokens="4" string="incumbents" id_sentence="15" />
        <mention ids_tokens="6" string="their" id_sentence="15" />
        <mention ids_tokens="13" string="incumbents" id_sentence="47" />
      </mentions>
    </coreference>
    <coreference id="7" type="PROPER">
      <referenced ids_tokens="13-14" string="Kay Slaughter" id_sentence="5" />
      <mentions>
        <mention ids_tokens="1" string="She" id_sentence="6" />
        <mention ids_tokens="13" string="her" id_sentence="6" />
      </mentions>
    </coreference>
    <coreference id="12" type="PROPER">
      <referenced ids_tokens="3-4-5" string="the current Congress" id_sentence="34" />
      <mentions>
        <mention ids_tokens="30" string="Congress" id_sentence="7" />
        <mention ids_tokens="12" string="Congress" id_sentence="9" />
        <mention ids_tokens="4" string="Congress" id_sentence="10" />
        <mention ids_tokens="5" string="Congress" id_sentence="35" />
        <mention ids_tokens="16" string="Congress" id_sentence="39" />
        <mention ids_tokens="45" string="Congress" id_sentence="46" />
        <mention ids_tokens="47-48" string="a fantasy" id_sentence="46" />
      </mentions>
    </coreference>
    <coreference id="13" type="PROPER">
      <referenced ids_tokens="1" string="Colorado" id_sentence="9" />
      <mentions>
        <mention ids_tokens="15-16" string="Colorado's" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="19" type="PROPER">
      <referenced ids_tokens="3-4-5-6-7" string="former California Governor Jerry Brown" id_sentence="12" />
      <mentions>
        <mention ids_tokens="15" string="he" id_sentence="13" />
        <mention ids_tokens="11" string="he" id_sentence="14" />
        <mention ids_tokens="1-2" string="Mr. Brown" id_sentence="17" />
        <mention ids_tokens="1" string="He" id_sentence="18" />
        <mention ids_tokens="9" string="his" id_sentence="18" />
      </mentions>
    </coreference>
    <coreference id="21" type="PROPER">
      <referenced ids_tokens="7-8-9-10" string="the California Democratic Party" id_sentence="14" />
      <mentions>
        <mention ids_tokens="2" string="I" id_sentence="15" />
        <mention ids_tokens="2-3" string="Democratic Party" id_sentence="40" />
      </mentions>
    </coreference>
    <coreference id="22" type="NOMINAL">
      <referenced ids_tokens="6-7-8" string="their time fund-raising" id_sentence="15" />
      <mentions>
        <mention ids_tokens="1" string="It" id_sentence="16" />
        <mention ids_tokens="3" string="time" id_sentence="16" />
      </mentions>
    </coreference>
    <coreference id="23" type="NOMINAL">
      <referenced ids_tokens="5" string="candidates" id_sentence="16" />
      <mentions>
        <mention ids_tokens="23" string="we" id_sentence="17" />
      </mentions>
    </coreference>
    <coreference id="24" type="NOMINAL">
      <referenced ids_tokens="9-10-11" string="his home state" id_sentence="18" />
      <mentions>
        <mention ids_tokens="4-6" string="the state's" id_sentence="26" />
      </mentions>
    </coreference>
    <coreference id="25" type="PROPER">
      <referenced ids_tokens="12-13" string="Madeleine Kunin" id_sentence="19" />
      <mentions>
        <mention ids_tokens="30-31" string="Ms. Kunin" id_sentence="20" />
      </mentions>
    </coreference>
    <coreference id="26" type="NOMINAL">
      <referenced ids_tokens="13-14" string="new people" id_sentence="20" />
      <mentions>
        <mention ids_tokens="8" string="they" id_sentence="22" />
      </mentions>
    </coreference>
    <coreference id="28" type="PROPER">
      <referenced ids_tokens="1-2-3-4-5" string="The Democratic Congressional Campaign Committee" id_sentence="24" />
      <mentions>
        <mention ids_tokens="3" string="that" id_sentence="25" />
      </mentions>
    </coreference>
    <coreference id="31" type="NOMINAL">
      <referenced ids_tokens="7-8-9-10-11-12-13-14" string="elected officials in expressing enthusiasm for term limits" id_sentence="29" />
      <mentions>
        <mention ids_tokens="51-52" string="elected officials" id_sentence="45" />
      </mentions>
    </coreference>
    <coreference id="32" type="NOMINAL">
      <referenced ids_tokens="2" string="those" id_sentence="30" />
      <mentions>
        <mention ids_tokens="13-18" string="those who now favor term limits" id_sentence="40" />
        <mention ids_tokens="17" string="their" id_sentence="42" />
      </mentions>
    </coreference>
    <coreference id="33" type="PROPER">
      <referenced ids_tokens="30-31-32-33" string="the National Journal 's" id_sentence="30" />
      <mentions>
        <mention ids_tokens="6" string="Journal" id_sentence="54" />
      </mentions>
    </coreference>
    <coreference id="34" type="PROPER">
      <referenced ids_tokens="1-2" string="Hendrik Hertzberg" id_sentence="31" />
      <mentions>
        <mention ids_tokens="3" string="he" id_sentence="32" />
      </mentions>
    </coreference>
    <coreference id="35" type="PROPER">
      <referenced ids_tokens="8-9-10-11-12-13-14-15-16-17" string="Jimmy Carter who edited the New Republic until last month" id_sentence="31" />
      <mentions>
        <mention ids_tokens="28-30" string="Jimmy Carter's" id_sentence="43" />
      </mentions>
    </coreference>
    <coreference id="36" type="PROPER">
      <referenced ids_tokens="12-13-14" string="the New Republic" id_sentence="31" />
      <mentions>
        <mention ids_tokens="6" string="it" id_sentence="32" />
        <mention ids_tokens="9-40" string="a cost worth paying to be rid of the much larger number of time-servers who have learned nothing from longevity in office except cynicism , complacency and a sense of diminished possibility" id_sentence="32" />
      </mentions>
    </coreference>
    <coreference id="38" type="NOMINAL">
      <referenced ids_tokens="27-28-29" string="some distinguished legislators" id_sentence="31" />
      <mentions>
        <mention ids_tokens="6" string="We" id_sentence="33" />
      </mentions>
    </coreference>
    <coreference id="39" type="PROPER">
      <referenced ids_tokens="1-2-3" string="Columnist Ellen Goodman" id_sentence="33" />
      <mentions>
        <mention ids_tokens="1" string="She" id_sentence="34" />
      </mentions>
    </coreference>
    <coreference id="42" type="NOMINAL">
      <referenced ids_tokens="13-14" string="its readers" id_sentence="36" />
      <mentions>
        <mention ids_tokens="19" string="We" id_sentence="39" />
        <mention ids_tokens="29" string="we" id_sentence="39" />
      </mentions>
    </coreference>
    <coreference id="45" type="NOMINAL">
      <referenced ids_tokens="2-3-4" string="Democratic Party activists" id_sentence="40" />
      <mentions>
        <mention ids_tokens="8" string="we" id_sentence="42" />
      </mentions>
    </coreference>
    <coreference id="46" type="NOMINAL">
      <referenced ids_tokens="2-3-4-5-6-7-8-9-10" string="the national treasurer for the American Civil Liberties Union" id_sentence="41" />
      <mentions>
        <mention ids_tokens="1" string="He" id_sentence="42" />
        <mention ids_tokens="7" string="him" id_sentence="43" />
      </mentions>
    </coreference>
    <coreference id="48" type="PROPER">
      <referenced ids_tokens="18-19-20-21-22-23-24-25-26-27-28-29" string="the national Democratic Party 's $ 15 million &quot; Victory Fund &quot;" id_sentence="41" />
      <mentions>
        <mention ids_tokens="3-5" string="the Democratic Party" id_sentence="48" />
        <mention ids_tokens="5-6" string="our party" id_sentence="50" />
        <mention ids_tokens="12" string="it" id_sentence="50" />
        <mention ids_tokens="21-23" string="our party's" id_sentence="50" />
      </mentions>
    </coreference>
    <coreference id="54" type="PROPER">
      <referenced ids_tokens="29-30-31" string="some House Democrats" id_sentence="46" />
      <mentions>
        <mention ids_tokens="25" string="Democrats" id_sentence="47" />
        <mention ids_tokens="2" string="Democrats" id_sentence="49" />
        <mention ids_tokens="15" string="she" id_sentence="49" />
      </mentions>
    </coreference>
    <coreference id="56" type="PROPER">
      <referenced ids_tokens="32-33-34-35-36-37-38-39-40" string="the Denver-based term limit group Americans Back in Charge" id_sentence="48" />
      <mentions>
        <mention ids_tokens="5" string="our" id_sentence="50" />
        <mention ids_tokens="21" string="our" id_sentence="50" />
      </mentions>
    </coreference>
  </coreferences>
</document>
