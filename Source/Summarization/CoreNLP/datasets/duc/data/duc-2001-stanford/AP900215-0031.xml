<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="AP900215-0031">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>Black Americans suffer six times more tuberculosis than whites do, and one important reason appears to be a genetic susceptibility to the disease, according to a study today.</content>
      <tokens>
        <token id="1" string="Black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="2" string="Americans" lemma="Americans" stem="american" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="3" string="suffer" lemma="suffer" stem="suffer" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="six" lemma="six" stem="six" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="5" string="times" lemma="time" stem="time" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="tuberculosis" lemma="tuberculosis" stem="tuberculosi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="whites" lemma="whites" stem="white" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="14" string="important" lemma="important" stem="import" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="reason" lemma="reason" stem="reason" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="appears" lemma="appear" stem="appear" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="genetic" lemma="genetic" stem="genet" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="susceptibility" lemma="susceptibility" stem="suscept" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="according" lemma="accord" stem="accord" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="study" lemma="study" stem="studi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="today" lemma="today" stem="todai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (JJ Black) (NNPS Americans)) (VP (VBP suffer) (ADJP (ADVP (NP (CD six) (NNS times)) (RBR more)) (NN tuberculosis)) (SBAR (IN than) (S (NP (NNS whites)) (VP (VBP do)))))) (, ,) (CC and) (S (NP (CD one) (JJ important) (NN reason)) (VP (VBZ appears) (S (VP (TO to) (VP (VB be) (NP (NP (DT a) (JJ genetic) (NN susceptibility)) (PP (TO to) (NP (DT the) (NN disease)))) (, ,) (PP (VBG according) (PP (TO to) (NP (DT a) (NN study) (NN today))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Black Americans" type="NP">
          <tokens>
            <token id="1" string="Black" />
            <token id="2" string="Americans" />
          </tokens>
        </chunking>
        <chunking id="2" string="a genetic susceptibility" type="NP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="genetic" />
            <token id="21" string="susceptibility" />
          </tokens>
        </chunking>
        <chunking id="3" string="do" type="VP">
          <tokens>
            <token id="10" string="do" />
          </tokens>
        </chunking>
        <chunking id="4" string="one important reason" type="NP">
          <tokens>
            <token id="13" string="one" />
            <token id="14" string="important" />
            <token id="15" string="reason" />
          </tokens>
        </chunking>
        <chunking id="5" string="than whites do" type="SBAR">
          <tokens>
            <token id="8" string="than" />
            <token id="9" string="whites" />
            <token id="10" string="do" />
          </tokens>
        </chunking>
        <chunking id="6" string="to be a genetic susceptibility to the disease , according to a study today" type="VP">
          <tokens>
            <token id="17" string="to" />
            <token id="18" string="be" />
            <token id="19" string="a" />
            <token id="20" string="genetic" />
            <token id="21" string="susceptibility" />
            <token id="22" string="to" />
            <token id="23" string="the" />
            <token id="24" string="disease" />
            <token id="25" string="," />
            <token id="26" string="according" />
            <token id="27" string="to" />
            <token id="28" string="a" />
            <token id="29" string="study" />
            <token id="30" string="today" />
          </tokens>
        </chunking>
        <chunking id="7" string="a genetic susceptibility to the disease" type="NP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="genetic" />
            <token id="21" string="susceptibility" />
            <token id="22" string="to" />
            <token id="23" string="the" />
            <token id="24" string="disease" />
          </tokens>
        </chunking>
        <chunking id="8" string="the disease" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="disease" />
          </tokens>
        </chunking>
        <chunking id="9" string="six times more tuberculosis" type="ADJP">
          <tokens>
            <token id="4" string="six" />
            <token id="5" string="times" />
            <token id="6" string="more" />
            <token id="7" string="tuberculosis" />
          </tokens>
        </chunking>
        <chunking id="10" string="whites" type="NP">
          <tokens>
            <token id="9" string="whites" />
          </tokens>
        </chunking>
        <chunking id="11" string="six times" type="NP">
          <tokens>
            <token id="4" string="six" />
            <token id="5" string="times" />
          </tokens>
        </chunking>
        <chunking id="12" string="a study today" type="NP">
          <tokens>
            <token id="28" string="a" />
            <token id="29" string="study" />
            <token id="30" string="today" />
          </tokens>
        </chunking>
        <chunking id="13" string="be a genetic susceptibility to the disease , according to a study today" type="VP">
          <tokens>
            <token id="18" string="be" />
            <token id="19" string="a" />
            <token id="20" string="genetic" />
            <token id="21" string="susceptibility" />
            <token id="22" string="to" />
            <token id="23" string="the" />
            <token id="24" string="disease" />
            <token id="25" string="," />
            <token id="26" string="according" />
            <token id="27" string="to" />
            <token id="28" string="a" />
            <token id="29" string="study" />
            <token id="30" string="today" />
          </tokens>
        </chunking>
        <chunking id="14" string="suffer six times more tuberculosis than whites do" type="VP">
          <tokens>
            <token id="3" string="suffer" />
            <token id="4" string="six" />
            <token id="5" string="times" />
            <token id="6" string="more" />
            <token id="7" string="tuberculosis" />
            <token id="8" string="than" />
            <token id="9" string="whites" />
            <token id="10" string="do" />
          </tokens>
        </chunking>
        <chunking id="15" string="appears to be a genetic susceptibility to the disease , according to a study today" type="VP">
          <tokens>
            <token id="16" string="appears" />
            <token id="17" string="to" />
            <token id="18" string="be" />
            <token id="19" string="a" />
            <token id="20" string="genetic" />
            <token id="21" string="susceptibility" />
            <token id="22" string="to" />
            <token id="23" string="the" />
            <token id="24" string="disease" />
            <token id="25" string="," />
            <token id="26" string="according" />
            <token id="27" string="to" />
            <token id="28" string="a" />
            <token id="29" string="study" />
            <token id="30" string="today" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">Americans</governor>
          <dependent id="1">Black</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">suffer</governor>
          <dependent id="2">Americans</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">suffer</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="5">times</governor>
          <dependent id="4">six</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="6">more</governor>
          <dependent id="5">times</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">tuberculosis</governor>
          <dependent id="6">more</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">suffer</governor>
          <dependent id="7">tuberculosis</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">do</governor>
          <dependent id="8">than</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">do</governor>
          <dependent id="9">whites</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">suffer</governor>
          <dependent id="10">do</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">suffer</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="15">reason</governor>
          <dependent id="13">one</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">reason</governor>
          <dependent id="14">important</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">appears</governor>
          <dependent id="15">reason</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">suffer</governor>
          <dependent id="16">appears</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">susceptibility</governor>
          <dependent id="17">to</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="21">susceptibility</governor>
          <dependent id="18">be</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">susceptibility</governor>
          <dependent id="19">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">susceptibility</governor>
          <dependent id="20">genetic</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="16">appears</governor>
          <dependent id="21">susceptibility</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">disease</governor>
          <dependent id="22">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">disease</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">susceptibility</governor>
          <dependent id="24">disease</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">today</governor>
          <dependent id="26">according</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="26">according</governor>
          <dependent id="27">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">today</governor>
          <dependent id="28">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">today</governor>
          <dependent id="29">study</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">susceptibility</governor>
          <dependent id="30">today</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="six" type="NUMBER" score="0.0">
          <tokens>
            <token id="4" string="six" />
          </tokens>
        </entity>
        <entity id="2" string="Black Americans" type="MISC" score="0.0">
          <tokens>
            <token id="1" string="Black" />
            <token id="2" string="Americans" />
          </tokens>
        </entity>
        <entity id="3" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="13" string="one" />
          </tokens>
        </entity>
        <entity id="4" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="24" string="disease" />
          </tokens>
        </entity>
        <entity id="5" string="today" type="DATE" score="0.0">
          <tokens>
            <token id="30" string="today" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>The research found that when living conditions are identical, black people are twice as likely as whites to get infected with the TB bacteria.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="research" lemma="research" stem="research" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="found" lemma="find" stem="found" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="living" lemma="live" stem="live" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="conditions" lemma="condition" stem="condit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="identical" lemma="identical" stem="ident" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="twice" lemma="twice" stem="twice" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="as" lemma="as" stem="a" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="likely" lemma="likely" stem="like" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="whites" lemma="whites" stem="white" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="get" lemma="get" stem="get" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="infected" lemma="infect" stem="infect" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="TB" lemma="tb" stem="tb" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="false" />
        <token id="25" string="bacteria" lemma="bacterium" stem="bacteria" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN research)) (VP (VBD found) (SBAR (IN that) (S (SBAR (WHADVP (WRB when)) (S (NP (VBG living) (NNS conditions)) (VP (VBP are) (ADJP (JJ identical))))) (, ,) (NP (JJ black) (NNS people)) (VP (VBP are) (ADJP (RB twice) (RB as) (JJ likely) (PP (IN as) (NP (NNS whites))) (S (VP (TO to) (VP (VB get) (VP (VBN infected) (PP (IN with) (NP (DT the) (NN TB) (NNS bacteria)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that when living conditions are identical , black people are twice as likely as whites to get infected with the TB bacteria" type="SBAR">
          <tokens>
            <token id="4" string="that" />
            <token id="5" string="when" />
            <token id="6" string="living" />
            <token id="7" string="conditions" />
            <token id="8" string="are" />
            <token id="9" string="identical" />
            <token id="10" string="," />
            <token id="11" string="black" />
            <token id="12" string="people" />
            <token id="13" string="are" />
            <token id="14" string="twice" />
            <token id="15" string="as" />
            <token id="16" string="likely" />
            <token id="17" string="as" />
            <token id="18" string="whites" />
            <token id="19" string="to" />
            <token id="20" string="get" />
            <token id="21" string="infected" />
            <token id="22" string="with" />
            <token id="23" string="the" />
            <token id="24" string="TB" />
            <token id="25" string="bacteria" />
          </tokens>
        </chunking>
        <chunking id="2" string="black people" type="NP">
          <tokens>
            <token id="11" string="black" />
            <token id="12" string="people" />
          </tokens>
        </chunking>
        <chunking id="3" string="infected with the TB bacteria" type="VP">
          <tokens>
            <token id="21" string="infected" />
            <token id="22" string="with" />
            <token id="23" string="the" />
            <token id="24" string="TB" />
            <token id="25" string="bacteria" />
          </tokens>
        </chunking>
        <chunking id="4" string="twice as likely as whites to get infected with the TB bacteria" type="ADJP">
          <tokens>
            <token id="14" string="twice" />
            <token id="15" string="as" />
            <token id="16" string="likely" />
            <token id="17" string="as" />
            <token id="18" string="whites" />
            <token id="19" string="to" />
            <token id="20" string="get" />
            <token id="21" string="infected" />
            <token id="22" string="with" />
            <token id="23" string="the" />
            <token id="24" string="TB" />
            <token id="25" string="bacteria" />
          </tokens>
        </chunking>
        <chunking id="5" string="found that when living conditions are identical , black people are twice as likely as whites to get infected with the TB bacteria" type="VP">
          <tokens>
            <token id="3" string="found" />
            <token id="4" string="that" />
            <token id="5" string="when" />
            <token id="6" string="living" />
            <token id="7" string="conditions" />
            <token id="8" string="are" />
            <token id="9" string="identical" />
            <token id="10" string="," />
            <token id="11" string="black" />
            <token id="12" string="people" />
            <token id="13" string="are" />
            <token id="14" string="twice" />
            <token id="15" string="as" />
            <token id="16" string="likely" />
            <token id="17" string="as" />
            <token id="18" string="whites" />
            <token id="19" string="to" />
            <token id="20" string="get" />
            <token id="21" string="infected" />
            <token id="22" string="with" />
            <token id="23" string="the" />
            <token id="24" string="TB" />
            <token id="25" string="bacteria" />
          </tokens>
        </chunking>
        <chunking id="6" string="are identical" type="VP">
          <tokens>
            <token id="8" string="are" />
            <token id="9" string="identical" />
          </tokens>
        </chunking>
        <chunking id="7" string="when" type="WHADVP">
          <tokens>
            <token id="5" string="when" />
          </tokens>
        </chunking>
        <chunking id="8" string="get infected with the TB bacteria" type="VP">
          <tokens>
            <token id="20" string="get" />
            <token id="21" string="infected" />
            <token id="22" string="with" />
            <token id="23" string="the" />
            <token id="24" string="TB" />
            <token id="25" string="bacteria" />
          </tokens>
        </chunking>
        <chunking id="9" string="identical" type="ADJP">
          <tokens>
            <token id="9" string="identical" />
          </tokens>
        </chunking>
        <chunking id="10" string="whites" type="NP">
          <tokens>
            <token id="18" string="whites" />
          </tokens>
        </chunking>
        <chunking id="11" string="the TB bacteria" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="TB" />
            <token id="25" string="bacteria" />
          </tokens>
        </chunking>
        <chunking id="12" string="to get infected with the TB bacteria" type="VP">
          <tokens>
            <token id="19" string="to" />
            <token id="20" string="get" />
            <token id="21" string="infected" />
            <token id="22" string="with" />
            <token id="23" string="the" />
            <token id="24" string="TB" />
            <token id="25" string="bacteria" />
          </tokens>
        </chunking>
        <chunking id="13" string="when living conditions are identical" type="SBAR">
          <tokens>
            <token id="5" string="when" />
            <token id="6" string="living" />
            <token id="7" string="conditions" />
            <token id="8" string="are" />
            <token id="9" string="identical" />
          </tokens>
        </chunking>
        <chunking id="14" string="living conditions" type="NP">
          <tokens>
            <token id="6" string="living" />
            <token id="7" string="conditions" />
          </tokens>
        </chunking>
        <chunking id="15" string="The research" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="research" />
          </tokens>
        </chunking>
        <chunking id="16" string="are twice as likely as whites to get infected with the TB bacteria" type="VP">
          <tokens>
            <token id="13" string="are" />
            <token id="14" string="twice" />
            <token id="15" string="as" />
            <token id="16" string="likely" />
            <token id="17" string="as" />
            <token id="18" string="whites" />
            <token id="19" string="to" />
            <token id="20" string="get" />
            <token id="21" string="infected" />
            <token id="22" string="with" />
            <token id="23" string="the" />
            <token id="24" string="TB" />
            <token id="25" string="bacteria" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">research</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">found</governor>
          <dependent id="2">research</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">found</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">likely</governor>
          <dependent id="4">that</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">identical</governor>
          <dependent id="5">when</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">conditions</governor>
          <dependent id="6">living</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">identical</governor>
          <dependent id="7">conditions</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="9">identical</governor>
          <dependent id="8">are</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="16">likely</governor>
          <dependent id="9">identical</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">people</governor>
          <dependent id="11">black</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">likely</governor>
          <dependent id="12">people</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="16">likely</governor>
          <dependent id="13">are</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">likely</governor>
          <dependent id="14">twice</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">likely</governor>
          <dependent id="15">as</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">found</governor>
          <dependent id="16">likely</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">whites</governor>
          <dependent id="17">as</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">likely</governor>
          <dependent id="18">whites</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">infected</governor>
          <dependent id="19">to</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="21">infected</governor>
          <dependent id="20">get</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="16">likely</governor>
          <dependent id="21">infected</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">bacteria</governor>
          <dependent id="22">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">bacteria</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">bacteria</governor>
          <dependent id="24">TB</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">infected</governor>
          <dependent id="25">bacteria</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="TB" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="24" string="TB" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>The relatively high rate of TB among blacks has traditionally been blamed on crowded housing and other conditions of poverty.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="relatively" lemma="relatively" stem="rel" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="high" lemma="high" stem="high" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="rate" lemma="rate" stem="rate" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="TB" lemma="tb" stem="tb" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="7" string="among" lemma="among" stem="among" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="blacks" lemma="black" stem="black" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="traditionally" lemma="traditionally" stem="tradition" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="blamed" lemma="blame" stem="blame" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="crowded" lemma="crowded" stem="crowd" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="housing" lemma="housing" stem="hous" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="conditions" lemma="condition" stem="condit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="poverty" lemma="poverty" stem="poverti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (ADJP (RB relatively) (JJ high)) (NN rate)) (PP (IN of) (NP (NP (NN TB)) (PP (IN among) (NP (NNS blacks)))))) (VP (VBZ has) (ADVP (RB traditionally)) (VP (VBN been) (VP (VBN blamed) (PP (IN on) (NP (NP (JJ crowded) (UCP (NN housing) (CC and) (JJ other)) (NNS conditions)) (PP (IN of) (NP (NN poverty)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="TB among blacks" type="NP">
          <tokens>
            <token id="6" string="TB" />
            <token id="7" string="among" />
            <token id="8" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="2" string="The relatively high rate of TB among blacks" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="relatively" />
            <token id="3" string="high" />
            <token id="4" string="rate" />
            <token id="5" string="of" />
            <token id="6" string="TB" />
            <token id="7" string="among" />
            <token id="8" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="3" string="has traditionally been blamed on crowded housing and other conditions of poverty" type="VP">
          <tokens>
            <token id="9" string="has" />
            <token id="10" string="traditionally" />
            <token id="11" string="been" />
            <token id="12" string="blamed" />
            <token id="13" string="on" />
            <token id="14" string="crowded" />
            <token id="15" string="housing" />
            <token id="16" string="and" />
            <token id="17" string="other" />
            <token id="18" string="conditions" />
            <token id="19" string="of" />
            <token id="20" string="poverty" />
          </tokens>
        </chunking>
        <chunking id="4" string="relatively high" type="ADJP">
          <tokens>
            <token id="2" string="relatively" />
            <token id="3" string="high" />
          </tokens>
        </chunking>
        <chunking id="5" string="been blamed on crowded housing and other conditions of poverty" type="VP">
          <tokens>
            <token id="11" string="been" />
            <token id="12" string="blamed" />
            <token id="13" string="on" />
            <token id="14" string="crowded" />
            <token id="15" string="housing" />
            <token id="16" string="and" />
            <token id="17" string="other" />
            <token id="18" string="conditions" />
            <token id="19" string="of" />
            <token id="20" string="poverty" />
          </tokens>
        </chunking>
        <chunking id="6" string="The relatively high rate" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="relatively" />
            <token id="3" string="high" />
            <token id="4" string="rate" />
          </tokens>
        </chunking>
        <chunking id="7" string="blamed on crowded housing and other conditions of poverty" type="VP">
          <tokens>
            <token id="12" string="blamed" />
            <token id="13" string="on" />
            <token id="14" string="crowded" />
            <token id="15" string="housing" />
            <token id="16" string="and" />
            <token id="17" string="other" />
            <token id="18" string="conditions" />
            <token id="19" string="of" />
            <token id="20" string="poverty" />
          </tokens>
        </chunking>
        <chunking id="8" string="blacks" type="NP">
          <tokens>
            <token id="8" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="9" string="crowded housing and other conditions of poverty" type="NP">
          <tokens>
            <token id="14" string="crowded" />
            <token id="15" string="housing" />
            <token id="16" string="and" />
            <token id="17" string="other" />
            <token id="18" string="conditions" />
            <token id="19" string="of" />
            <token id="20" string="poverty" />
          </tokens>
        </chunking>
        <chunking id="10" string="poverty" type="NP">
          <tokens>
            <token id="20" string="poverty" />
          </tokens>
        </chunking>
        <chunking id="11" string="TB" type="NP">
          <tokens>
            <token id="6" string="TB" />
          </tokens>
        </chunking>
        <chunking id="12" string="crowded housing and other conditions" type="NP">
          <tokens>
            <token id="14" string="crowded" />
            <token id="15" string="housing" />
            <token id="16" string="and" />
            <token id="17" string="other" />
            <token id="18" string="conditions" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">rate</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">high</governor>
          <dependent id="2">relatively</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">rate</governor>
          <dependent id="3">high</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="12">blamed</governor>
          <dependent id="4">rate</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">TB</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">rate</governor>
          <dependent id="6">TB</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">blacks</governor>
          <dependent id="7">among</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">TB</governor>
          <dependent id="8">blacks</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">blamed</governor>
          <dependent id="9">has</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">blamed</governor>
          <dependent id="10">traditionally</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="12">blamed</governor>
          <dependent id="11">been</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">blamed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">conditions</governor>
          <dependent id="13">on</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">conditions</governor>
          <dependent id="14">crowded</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">conditions</governor>
          <dependent id="15">housing</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">housing</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">housing</governor>
          <dependent id="17">other</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">blamed</governor>
          <dependent id="18">conditions</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">poverty</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">conditions</governor>
          <dependent id="20">poverty</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="TB" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="6" string="TB" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="false">
      <content>While social factors undoubtedly play a central role, the study suggests that innate susceptibility also contributes.</content>
      <tokens>
        <token id="1" string="While" lemma="while" stem="while" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="social" lemma="social" stem="social" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="factors" lemma="factor" stem="factor" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="undoubtedly" lemma="undoubtedly" stem="undoubtedli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="play" lemma="play" stem="plai" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="central" lemma="central" stem="central" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="role" lemma="role" stem="role" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="study" lemma="study" stem="studi" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="suggests" lemma="suggest" stem="suggest" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="innate" lemma="innate" stem="innat" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="susceptibility" lemma="susceptibility" stem="suscept" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="contributes" lemma="contribute" stem="contribut" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN While) (S (NP (JJ social) (NNS factors)) (ADVP (RB undoubtedly)) (VP (VBP play) (NP (DT a) (JJ central) (NN role))))) (, ,) (NP (DT the) (NN study)) (VP (VBZ suggests) (SBAR (IN that) (S (NP (JJ innate) (NN susceptibility)) (ADVP (RB also)) (VP (VBZ contributes))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="While social factors undoubtedly play a central role" type="SBAR">
          <tokens>
            <token id="1" string="While" />
            <token id="2" string="social" />
            <token id="3" string="factors" />
            <token id="4" string="undoubtedly" />
            <token id="5" string="play" />
            <token id="6" string="a" />
            <token id="7" string="central" />
            <token id="8" string="role" />
          </tokens>
        </chunking>
        <chunking id="2" string="a central role" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="central" />
            <token id="8" string="role" />
          </tokens>
        </chunking>
        <chunking id="3" string="the study" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="study" />
          </tokens>
        </chunking>
        <chunking id="4" string="social factors" type="NP">
          <tokens>
            <token id="2" string="social" />
            <token id="3" string="factors" />
          </tokens>
        </chunking>
        <chunking id="5" string="that innate susceptibility also contributes" type="SBAR">
          <tokens>
            <token id="13" string="that" />
            <token id="14" string="innate" />
            <token id="15" string="susceptibility" />
            <token id="16" string="also" />
            <token id="17" string="contributes" />
          </tokens>
        </chunking>
        <chunking id="6" string="play a central role" type="VP">
          <tokens>
            <token id="5" string="play" />
            <token id="6" string="a" />
            <token id="7" string="central" />
            <token id="8" string="role" />
          </tokens>
        </chunking>
        <chunking id="7" string="innate susceptibility" type="NP">
          <tokens>
            <token id="14" string="innate" />
            <token id="15" string="susceptibility" />
          </tokens>
        </chunking>
        <chunking id="8" string="contributes" type="VP">
          <tokens>
            <token id="17" string="contributes" />
          </tokens>
        </chunking>
        <chunking id="9" string="suggests that innate susceptibility also contributes" type="VP">
          <tokens>
            <token id="12" string="suggests" />
            <token id="13" string="that" />
            <token id="14" string="innate" />
            <token id="15" string="susceptibility" />
            <token id="16" string="also" />
            <token id="17" string="contributes" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="5">play</governor>
          <dependent id="1">While</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">factors</governor>
          <dependent id="2">social</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">play</governor>
          <dependent id="3">factors</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">play</governor>
          <dependent id="4">undoubtedly</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">suggests</governor>
          <dependent id="5">play</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">role</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">role</governor>
          <dependent id="7">central</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">play</governor>
          <dependent id="8">role</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">study</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">suggests</governor>
          <dependent id="11">study</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">suggests</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">contributes</governor>
          <dependent id="13">that</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">susceptibility</governor>
          <dependent id="14">innate</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">contributes</governor>
          <dependent id="15">susceptibility</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">contributes</governor>
          <dependent id="16">also</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">suggests</governor>
          <dependent id="17">contributes</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>``We found that there is a systemic difference between whites and blacks,&amp;apost;&amp;apost; said Dr. William W. Stead.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="found" lemma="find" stem="found" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="systemic" lemma="systemic" stem="system" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="difference" lemma="difference" stem="differ" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="between" lemma="between" stem="between" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="whites" lemma="whites" stem="white" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="blacks" lemma="black" stem="black" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="Dr." lemma="Dr." stem="dr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="William" lemma="William" stem="william" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="19" string="W." lemma="W." stem="w." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="20" string="Stead" lemma="Stead" stem="stead" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (PRP We)) (VP (VBD found) (SBAR (IN that) (S (NP (EX there)) (VP (VBZ is) (NP (NP (DT a) (JJ systemic) (NN difference)) (PP (IN between) (NP (NNS whites) (CC and) (NNS blacks))))))))) (, ,) ('' '') (VP (VBD said)) (NP (NNP Dr.) (NNP William) (NNP W.) (NNP Stead)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="there" type="NP">
          <tokens>
            <token id="5" string="there" />
          </tokens>
        </chunking>
        <chunking id="2" string="a systemic difference between whites and blacks" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="systemic" />
            <token id="9" string="difference" />
            <token id="10" string="between" />
            <token id="11" string="whites" />
            <token id="12" string="and" />
            <token id="13" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="3" string="a systemic difference" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="systemic" />
            <token id="9" string="difference" />
          </tokens>
        </chunking>
        <chunking id="4" string="found that there is a systemic difference between whites and blacks" type="VP">
          <tokens>
            <token id="3" string="found" />
            <token id="4" string="that" />
            <token id="5" string="there" />
            <token id="6" string="is" />
            <token id="7" string="a" />
            <token id="8" string="systemic" />
            <token id="9" string="difference" />
            <token id="10" string="between" />
            <token id="11" string="whites" />
            <token id="12" string="and" />
            <token id="13" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="5" string="that there is a systemic difference between whites and blacks" type="SBAR">
          <tokens>
            <token id="4" string="that" />
            <token id="5" string="there" />
            <token id="6" string="is" />
            <token id="7" string="a" />
            <token id="8" string="systemic" />
            <token id="9" string="difference" />
            <token id="10" string="between" />
            <token id="11" string="whites" />
            <token id="12" string="and" />
            <token id="13" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="6" string="is a systemic difference between whites and blacks" type="VP">
          <tokens>
            <token id="6" string="is" />
            <token id="7" string="a" />
            <token id="8" string="systemic" />
            <token id="9" string="difference" />
            <token id="10" string="between" />
            <token id="11" string="whites" />
            <token id="12" string="and" />
            <token id="13" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="7" string="whites and blacks" type="NP">
          <tokens>
            <token id="11" string="whites" />
            <token id="12" string="and" />
            <token id="13" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="8" string="We" type="NP">
          <tokens>
            <token id="2" string="We" />
          </tokens>
        </chunking>
        <chunking id="9" string="said" type="VP">
          <tokens>
            <token id="16" string="said" />
          </tokens>
        </chunking>
        <chunking id="10" string="Dr. William W. Stead" type="NP">
          <tokens>
            <token id="17" string="Dr." />
            <token id="18" string="William" />
            <token id="19" string="W." />
            <token id="20" string="Stead" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">found</governor>
          <dependent id="2">We</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">said</governor>
          <dependent id="3">found</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">is</governor>
          <dependent id="4">that</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="6">is</governor>
          <dependent id="5">there</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">found</governor>
          <dependent id="6">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">difference</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">difference</governor>
          <dependent id="8">systemic</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">is</governor>
          <dependent id="9">difference</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">whites</governor>
          <dependent id="10">between</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">difference</governor>
          <dependent id="11">whites</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">whites</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">whites</governor>
          <dependent id="13">blacks</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Stead</governor>
          <dependent id="17">Dr.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Stead</governor>
          <dependent id="18">William</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Stead</governor>
          <dependent id="19">W.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">said</governor>
          <dependent id="20">Stead</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="William W. Stead" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="William" />
            <token id="19" string="W." />
            <token id="20" string="Stead" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="false">
      <content>``Whites seem to be more able to fend off the organism without it&amp;apost;s ever being able to establish an infection.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Whites" lemma="whites" stem="white" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="seem" lemma="seem" stem="seem" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="able" lemma="able" stem="abl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="fend" lemma="fend" stem="fend" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="off" lemma="off" stem="off" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="organism" lemma="organism" stem="organ" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="without" lemma="without" stem="without" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="ever" lemma="ever" stem="ever" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="being" lemma="be" stem="be" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="able" lemma="able" stem="abl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="establish" lemma="establish" stem="establish" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="infection" lemma="infection" stem="infect" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (NNS Whites)) (VP (VBP seem) (S (VP (TO to) (VP (VB be) (ADJP (RBR more) (JJ able) (S (VP (TO to) (VP (VB fend) (PRT (RP off)) (NP (DT the) (NN organism)) (PP (IN without) (S (NP (PRP it)) (VP (VBZ 's) (ADVP (RB ever)) (VP (VBG being) (ADJP (JJ able) (S (VP (TO to) (VP (VB establish) (NP (DT an) (NN infection)))))))))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="'s ever being able to establish an infection" type="VP">
          <tokens>
            <token id="15" string="'s" />
            <token id="16" string="ever" />
            <token id="17" string="being" />
            <token id="18" string="able" />
            <token id="19" string="to" />
            <token id="20" string="establish" />
            <token id="21" string="an" />
            <token id="22" string="infection" />
          </tokens>
        </chunking>
        <chunking id="2" string="be more able to fend off the organism without it 's ever being able to establish an infection" type="VP">
          <tokens>
            <token id="5" string="be" />
            <token id="6" string="more" />
            <token id="7" string="able" />
            <token id="8" string="to" />
            <token id="9" string="fend" />
            <token id="10" string="off" />
            <token id="11" string="the" />
            <token id="12" string="organism" />
            <token id="13" string="without" />
            <token id="14" string="it" />
            <token id="15" string="'s" />
            <token id="16" string="ever" />
            <token id="17" string="being" />
            <token id="18" string="able" />
            <token id="19" string="to" />
            <token id="20" string="establish" />
            <token id="21" string="an" />
            <token id="22" string="infection" />
          </tokens>
        </chunking>
        <chunking id="3" string="more able to fend off the organism without it 's ever being able to establish an infection" type="ADJP">
          <tokens>
            <token id="6" string="more" />
            <token id="7" string="able" />
            <token id="8" string="to" />
            <token id="9" string="fend" />
            <token id="10" string="off" />
            <token id="11" string="the" />
            <token id="12" string="organism" />
            <token id="13" string="without" />
            <token id="14" string="it" />
            <token id="15" string="'s" />
            <token id="16" string="ever" />
            <token id="17" string="being" />
            <token id="18" string="able" />
            <token id="19" string="to" />
            <token id="20" string="establish" />
            <token id="21" string="an" />
            <token id="22" string="infection" />
          </tokens>
        </chunking>
        <chunking id="4" string="the organism" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="organism" />
          </tokens>
        </chunking>
        <chunking id="5" string="being able to establish an infection" type="VP">
          <tokens>
            <token id="17" string="being" />
            <token id="18" string="able" />
            <token id="19" string="to" />
            <token id="20" string="establish" />
            <token id="21" string="an" />
            <token id="22" string="infection" />
          </tokens>
        </chunking>
        <chunking id="6" string="seem to be more able to fend off the organism without it 's ever being able to establish an infection" type="VP">
          <tokens>
            <token id="3" string="seem" />
            <token id="4" string="to" />
            <token id="5" string="be" />
            <token id="6" string="more" />
            <token id="7" string="able" />
            <token id="8" string="to" />
            <token id="9" string="fend" />
            <token id="10" string="off" />
            <token id="11" string="the" />
            <token id="12" string="organism" />
            <token id="13" string="without" />
            <token id="14" string="it" />
            <token id="15" string="'s" />
            <token id="16" string="ever" />
            <token id="17" string="being" />
            <token id="18" string="able" />
            <token id="19" string="to" />
            <token id="20" string="establish" />
            <token id="21" string="an" />
            <token id="22" string="infection" />
          </tokens>
        </chunking>
        <chunking id="7" string="able to establish an infection" type="ADJP">
          <tokens>
            <token id="18" string="able" />
            <token id="19" string="to" />
            <token id="20" string="establish" />
            <token id="21" string="an" />
            <token id="22" string="infection" />
          </tokens>
        </chunking>
        <chunking id="8" string="Whites" type="NP">
          <tokens>
            <token id="2" string="Whites" />
          </tokens>
        </chunking>
        <chunking id="9" string="fend off the organism without it 's ever being able to establish an infection" type="VP">
          <tokens>
            <token id="9" string="fend" />
            <token id="10" string="off" />
            <token id="11" string="the" />
            <token id="12" string="organism" />
            <token id="13" string="without" />
            <token id="14" string="it" />
            <token id="15" string="'s" />
            <token id="16" string="ever" />
            <token id="17" string="being" />
            <token id="18" string="able" />
            <token id="19" string="to" />
            <token id="20" string="establish" />
            <token id="21" string="an" />
            <token id="22" string="infection" />
          </tokens>
        </chunking>
        <chunking id="10" string="it" type="NP">
          <tokens>
            <token id="14" string="it" />
          </tokens>
        </chunking>
        <chunking id="11" string="an infection" type="NP">
          <tokens>
            <token id="21" string="an" />
            <token id="22" string="infection" />
          </tokens>
        </chunking>
        <chunking id="12" string="to be more able to fend off the organism without it 's ever being able to establish an infection" type="VP">
          <tokens>
            <token id="4" string="to" />
            <token id="5" string="be" />
            <token id="6" string="more" />
            <token id="7" string="able" />
            <token id="8" string="to" />
            <token id="9" string="fend" />
            <token id="10" string="off" />
            <token id="11" string="the" />
            <token id="12" string="organism" />
            <token id="13" string="without" />
            <token id="14" string="it" />
            <token id="15" string="'s" />
            <token id="16" string="ever" />
            <token id="17" string="being" />
            <token id="18" string="able" />
            <token id="19" string="to" />
            <token id="20" string="establish" />
            <token id="21" string="an" />
            <token id="22" string="infection" />
          </tokens>
        </chunking>
        <chunking id="13" string="establish an infection" type="VP">
          <tokens>
            <token id="20" string="establish" />
            <token id="21" string="an" />
            <token id="22" string="infection" />
          </tokens>
        </chunking>
        <chunking id="14" string="to fend off the organism without it 's ever being able to establish an infection" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="fend" />
            <token id="10" string="off" />
            <token id="11" string="the" />
            <token id="12" string="organism" />
            <token id="13" string="without" />
            <token id="14" string="it" />
            <token id="15" string="'s" />
            <token id="16" string="ever" />
            <token id="17" string="being" />
            <token id="18" string="able" />
            <token id="19" string="to" />
            <token id="20" string="establish" />
            <token id="21" string="an" />
            <token id="22" string="infection" />
          </tokens>
        </chunking>
        <chunking id="15" string="to establish an infection" type="VP">
          <tokens>
            <token id="19" string="to" />
            <token id="20" string="establish" />
            <token id="21" string="an" />
            <token id="22" string="infection" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">seem</governor>
          <dependent id="2">Whites</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">seem</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">able</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">able</governor>
          <dependent id="5">be</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">able</governor>
          <dependent id="6">more</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">seem</governor>
          <dependent id="7">able</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">fend</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">able</governor>
          <dependent id="9">fend</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="9">fend</governor>
          <dependent id="10">off</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">organism</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">fend</governor>
          <dependent id="12">organism</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">able</governor>
          <dependent id="13">without</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">able</governor>
          <dependent id="14">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">able</governor>
          <dependent id="15">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">able</governor>
          <dependent id="16">ever</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="18">able</governor>
          <dependent id="17">being</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">fend</governor>
          <dependent id="18">able</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">establish</governor>
          <dependent id="19">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="18">able</governor>
          <dependent id="20">establish</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">infection</governor>
          <dependent id="21">an</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">establish</governor>
          <dependent id="22">infection</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="infection" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="22" string="infection" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>Stead, a tuberculosis specialist at the Arkansas Department of Health, discovered the racial difference while analyzing health statistics from nursing homes and prisons.</content>
      <tokens>
        <token id="1" string="Stead" lemma="stead" stem="stead" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="tuberculosis" lemma="tuberculosis" stem="tuberculosi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="specialist" lemma="specialist" stem="specialist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="Arkansas" lemma="Arkansas" stem="arkansa" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="9" string="Department" lemma="Department" stem="depart" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="11" string="Health" lemma="Health" stem="health" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="discovered" lemma="discover" stem="discov" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="racial" lemma="racial" stem="racial" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="difference" lemma="difference" stem="differ" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="while" lemma="while" stem="while" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="analyzing" lemma="analyze" stem="analyz" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="health" lemma="health" stem="health" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="statistics" lemma="statistics" stem="statist" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="nursing" lemma="nurse" stem="nurs" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="homes" lemma="home" stem="home" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="prisons" lemma="prison" stem="prison" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NN Stead)) (, ,) (NP (NP (DT a) (NN tuberculosis) (NN specialist)) (PP (IN at) (NP (NP (DT the) (NNP Arkansas) (NNP Department)) (PP (IN of) (NP (NNP Health)))))) (, ,)) (VP (VBD discovered) (NP (DT the) (JJ racial) (NN difference)) (PP (IN while) (S (VP (VBG analyzing) (NP (NN health) (NNS statistics)) (PP (IN from) (S (VP (VBG nursing) (NP (NNS homes) (CC and) (NNS prisons))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Stead" type="NP">
          <tokens>
            <token id="1" string="Stead" />
          </tokens>
        </chunking>
        <chunking id="2" string="Health" type="NP">
          <tokens>
            <token id="11" string="Health" />
          </tokens>
        </chunking>
        <chunking id="3" string="homes and prisons" type="NP">
          <tokens>
            <token id="23" string="homes" />
            <token id="24" string="and" />
            <token id="25" string="prisons" />
          </tokens>
        </chunking>
        <chunking id="4" string="health statistics" type="NP">
          <tokens>
            <token id="19" string="health" />
            <token id="20" string="statistics" />
          </tokens>
        </chunking>
        <chunking id="5" string="the Arkansas Department of Health" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="Arkansas" />
            <token id="9" string="Department" />
            <token id="10" string="of" />
            <token id="11" string="Health" />
          </tokens>
        </chunking>
        <chunking id="6" string="a tuberculosis specialist" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="tuberculosis" />
            <token id="5" string="specialist" />
          </tokens>
        </chunking>
        <chunking id="7" string="nursing homes and prisons" type="VP">
          <tokens>
            <token id="22" string="nursing" />
            <token id="23" string="homes" />
            <token id="24" string="and" />
            <token id="25" string="prisons" />
          </tokens>
        </chunking>
        <chunking id="8" string="a tuberculosis specialist at the Arkansas Department of Health" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="tuberculosis" />
            <token id="5" string="specialist" />
            <token id="6" string="at" />
            <token id="7" string="the" />
            <token id="8" string="Arkansas" />
            <token id="9" string="Department" />
            <token id="10" string="of" />
            <token id="11" string="Health" />
          </tokens>
        </chunking>
        <chunking id="9" string="Stead , a tuberculosis specialist at the Arkansas Department of Health ," type="NP">
          <tokens>
            <token id="1" string="Stead" />
            <token id="2" string="," />
            <token id="3" string="a" />
            <token id="4" string="tuberculosis" />
            <token id="5" string="specialist" />
            <token id="6" string="at" />
            <token id="7" string="the" />
            <token id="8" string="Arkansas" />
            <token id="9" string="Department" />
            <token id="10" string="of" />
            <token id="11" string="Health" />
            <token id="12" string="," />
          </tokens>
        </chunking>
        <chunking id="10" string="the Arkansas Department" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="Arkansas" />
            <token id="9" string="Department" />
          </tokens>
        </chunking>
        <chunking id="11" string="the racial difference" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="racial" />
            <token id="16" string="difference" />
          </tokens>
        </chunking>
        <chunking id="12" string="discovered the racial difference while analyzing health statistics from nursing homes and prisons" type="VP">
          <tokens>
            <token id="13" string="discovered" />
            <token id="14" string="the" />
            <token id="15" string="racial" />
            <token id="16" string="difference" />
            <token id="17" string="while" />
            <token id="18" string="analyzing" />
            <token id="19" string="health" />
            <token id="20" string="statistics" />
            <token id="21" string="from" />
            <token id="22" string="nursing" />
            <token id="23" string="homes" />
            <token id="24" string="and" />
            <token id="25" string="prisons" />
          </tokens>
        </chunking>
        <chunking id="13" string="analyzing health statistics from nursing homes and prisons" type="VP">
          <tokens>
            <token id="18" string="analyzing" />
            <token id="19" string="health" />
            <token id="20" string="statistics" />
            <token id="21" string="from" />
            <token id="22" string="nursing" />
            <token id="23" string="homes" />
            <token id="24" string="and" />
            <token id="25" string="prisons" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="13">discovered</governor>
          <dependent id="1">Stead</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">specialist</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">specialist</governor>
          <dependent id="4">tuberculosis</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="1">Stead</governor>
          <dependent id="5">specialist</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Department</governor>
          <dependent id="6">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">Department</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Department</governor>
          <dependent id="8">Arkansas</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">specialist</governor>
          <dependent id="9">Department</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Health</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">Department</governor>
          <dependent id="11">Health</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">discovered</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">difference</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">difference</governor>
          <dependent id="15">racial</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">discovered</governor>
          <dependent id="16">difference</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">analyzing</governor>
          <dependent id="17">while</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="13">discovered</governor>
          <dependent id="18">analyzing</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">statistics</governor>
          <dependent id="19">health</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">analyzing</governor>
          <dependent id="20">statistics</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">nursing</governor>
          <dependent id="21">from</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="18">analyzing</governor>
          <dependent id="22">nursing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">nursing</governor>
          <dependent id="23">homes</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="23">homes</governor>
          <dependent id="24">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="23">homes</governor>
          <dependent id="25">prisons</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Arkansas Department of Health" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="8" string="Arkansas" />
            <token id="9" string="Department" />
            <token id="10" string="of" />
            <token id="11" string="Health" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>``It&amp;apost;s a very intriguing finding,&amp;apost;&amp;apost; commented Dr. George Comstock of Johns Hopkins University.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="intriguing" lemma="intriguing" stem="intrigu" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="finding" lemma="finding" stem="find" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="commented" lemma="comment" stem="comment" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="Dr." lemma="Dr." stem="dr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="George" lemma="George" stem="georg" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="13" string="Comstock" lemma="Comstock" stem="comstock" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Johns" lemma="Johns" stem="john" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="16" string="Hopkins" lemma="Hopkins" stem="hopkin" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="17" string="University" lemma="University" stem="univers" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (PRP It)) (VP (VBZ 's) (NP (DT a) (ADJP (RB very) (JJ intriguing)) (NN finding)))) (, ,) ('' '') (VP (VBD commented)) (NP (NP (NNP Dr.) (NNP George) (NNP Comstock)) (PP (IN of) (NP (NNP Johns) (NNP Hopkins) (NNP University)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Johns Hopkins University" type="NP">
          <tokens>
            <token id="15" string="Johns" />
            <token id="16" string="Hopkins" />
            <token id="17" string="University" />
          </tokens>
        </chunking>
        <chunking id="2" string="a very intriguing finding" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="very" />
            <token id="6" string="intriguing" />
            <token id="7" string="finding" />
          </tokens>
        </chunking>
        <chunking id="3" string="Dr. George Comstock of Johns Hopkins University" type="NP">
          <tokens>
            <token id="11" string="Dr." />
            <token id="12" string="George" />
            <token id="13" string="Comstock" />
            <token id="14" string="of" />
            <token id="15" string="Johns" />
            <token id="16" string="Hopkins" />
            <token id="17" string="University" />
          </tokens>
        </chunking>
        <chunking id="4" string="very intriguing" type="ADJP">
          <tokens>
            <token id="5" string="very" />
            <token id="6" string="intriguing" />
          </tokens>
        </chunking>
        <chunking id="5" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="6" string="Dr. George Comstock" type="NP">
          <tokens>
            <token id="11" string="Dr." />
            <token id="12" string="George" />
            <token id="13" string="Comstock" />
          </tokens>
        </chunking>
        <chunking id="7" string="'s a very intriguing finding" type="VP">
          <tokens>
            <token id="3" string="'s" />
            <token id="4" string="a" />
            <token id="5" string="very" />
            <token id="6" string="intriguing" />
            <token id="7" string="finding" />
          </tokens>
        </chunking>
        <chunking id="8" string="commented" type="VP">
          <tokens>
            <token id="10" string="commented" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="7">finding</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">finding</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">finding</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">intriguing</governor>
          <dependent id="5">very</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">finding</governor>
          <dependent id="6">intriguing</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">commented</governor>
          <dependent id="7">finding</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">commented</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Comstock</governor>
          <dependent id="11">Dr.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Comstock</governor>
          <dependent id="12">George</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">commented</governor>
          <dependent id="13">Comstock</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">University</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">University</governor>
          <dependent id="15">Johns</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">University</governor>
          <dependent id="16">Hopkins</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">Comstock</governor>
          <dependent id="17">University</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johns Hopkins University" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="15" string="Johns" />
            <token id="16" string="Hopkins" />
            <token id="17" string="University" />
          </tokens>
        </entity>
        <entity id="2" string="George Comstock" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="George" />
            <token id="13" string="Comstock" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>``I never quite believe anything until somebody replicates it.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="quite" lemma="quite" stem="quit" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="believe" lemma="believe" stem="believ" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="anything" lemma="anything" stem="anyth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="until" lemma="until" stem="until" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="somebody" lemma="somebody" stem="somebodi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="replicates" lemma="replicate" stem="replic" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (ADVP (RB never) (RB quite)) (VP (VB believe) (NP (NN anything)) (SBAR (IN until) (S (NP (NN somebody)) (VP (VBZ replicates) (NP (PRP it)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="replicates it" type="VP">
          <tokens>
            <token id="9" string="replicates" />
            <token id="10" string="it" />
          </tokens>
        </chunking>
        <chunking id="2" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="3" string="until somebody replicates it" type="SBAR">
          <tokens>
            <token id="7" string="until" />
            <token id="8" string="somebody" />
            <token id="9" string="replicates" />
            <token id="10" string="it" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="10" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="believe anything until somebody replicates it" type="VP">
          <tokens>
            <token id="5" string="believe" />
            <token id="6" string="anything" />
            <token id="7" string="until" />
            <token id="8" string="somebody" />
            <token id="9" string="replicates" />
            <token id="10" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="anything" type="NP">
          <tokens>
            <token id="6" string="anything" />
          </tokens>
        </chunking>
        <chunking id="7" string="somebody" type="NP">
          <tokens>
            <token id="8" string="somebody" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">believe</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">quite</governor>
          <dependent id="3">never</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">believe</governor>
          <dependent id="4">quite</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">believe</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">believe</governor>
          <dependent id="6">anything</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">replicates</governor>
          <dependent id="7">until</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">replicates</governor>
          <dependent id="8">somebody</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">believe</governor>
          <dependent id="9">replicates</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">replicates</governor>
          <dependent id="10">it</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>But I don&amp;apost;t know of any real holes in this one.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="know" lemma="know" stem="know" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="real" lemma="real" stem="real" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="holes" lemma="hole" stem="hole" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (PRP I)) (VP (VBP do) (RB n't) (VP (VB know) (PP (IN of) (NP (NP (DT any) (JJ real) (NNS holes)) (PP (IN in) (NP (DT this) (CD one))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="this one" type="NP">
          <tokens>
            <token id="11" string="this" />
            <token id="12" string="one" />
          </tokens>
        </chunking>
        <chunking id="2" string="do n't know of any real holes in this one" type="VP">
          <tokens>
            <token id="3" string="do" />
            <token id="4" string="n't" />
            <token id="5" string="know" />
            <token id="6" string="of" />
            <token id="7" string="any" />
            <token id="8" string="real" />
            <token id="9" string="holes" />
            <token id="10" string="in" />
            <token id="11" string="this" />
            <token id="12" string="one" />
          </tokens>
        </chunking>
        <chunking id="3" string="any real holes" type="NP">
          <tokens>
            <token id="7" string="any" />
            <token id="8" string="real" />
            <token id="9" string="holes" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="know of any real holes in this one" type="VP">
          <tokens>
            <token id="5" string="know" />
            <token id="6" string="of" />
            <token id="7" string="any" />
            <token id="8" string="real" />
            <token id="9" string="holes" />
            <token id="10" string="in" />
            <token id="11" string="this" />
            <token id="12" string="one" />
          </tokens>
        </chunking>
        <chunking id="6" string="any real holes in this one" type="NP">
          <tokens>
            <token id="7" string="any" />
            <token id="8" string="real" />
            <token id="9" string="holes" />
            <token id="10" string="in" />
            <token id="11" string="this" />
            <token id="12" string="one" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="5">know</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">know</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">know</governor>
          <dependent id="3">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">know</governor>
          <dependent id="4">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">know</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">holes</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">holes</governor>
          <dependent id="7">any</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">holes</governor>
          <dependent id="8">real</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">know</governor>
          <dependent id="9">holes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">one</governor>
          <dependent id="10">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">one</governor>
          <dependent id="11">this</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">holes</governor>
          <dependent id="12">one</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="12" string="one" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>At the National Institute of Allergy and Infectious Diseases, Dr. George Curlin called the findings ``plausible and provocative.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="At" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="National" lemma="National" stem="nation" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="4" string="Institute" lemma="Institute" stem="institut" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="6" string="Allergy" lemma="Allergy" stem="allergi" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Infectious" lemma="infectious" stem="infectiou" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="Diseases" lemma="disease" stem="diseas" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Dr." lemma="Dr." stem="dr." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="George" lemma="George" stem="georg" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="13" string="Curlin" lemma="Curlin" stem="curlin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="14" string="called" lemma="call" stem="call" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="findings" lemma="finding" stem="find" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="plausible" lemma="plausible" stem="plausibl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="provocative" lemma="provocative" stem="provoc" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN At) (NP (NP (DT the) (NNP National) (NNP Institute)) (PP (IN of) (NP (UCP (NP (NNP Allergy)) (CC and) (ADJP (JJ Infectious))) (NNS Diseases))))) (, ,) (NP (NNP Dr.) (NNP George) (NNP Curlin)) (VP (VBD called) (S (NP (DT the) (NNS findings)) (`` ``) (ADJP (JJ plausible) (CC and) (JJ provocative)))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="Infectious" type="ADJP">
          <tokens>
            <token id="8" string="Infectious" />
          </tokens>
        </chunking>
        <chunking id="2" string="the National Institute of Allergy and Infectious Diseases" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="National" />
            <token id="4" string="Institute" />
            <token id="5" string="of" />
            <token id="6" string="Allergy" />
            <token id="7" string="and" />
            <token id="8" string="Infectious" />
            <token id="9" string="Diseases" />
          </tokens>
        </chunking>
        <chunking id="3" string="the findings" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="findings" />
          </tokens>
        </chunking>
        <chunking id="4" string="Allergy and Infectious Diseases" type="NP">
          <tokens>
            <token id="6" string="Allergy" />
            <token id="7" string="and" />
            <token id="8" string="Infectious" />
            <token id="9" string="Diseases" />
          </tokens>
        </chunking>
        <chunking id="5" string="Dr. George Curlin" type="NP">
          <tokens>
            <token id="11" string="Dr." />
            <token id="12" string="George" />
            <token id="13" string="Curlin" />
          </tokens>
        </chunking>
        <chunking id="6" string="called the findings `` plausible and provocative" type="VP">
          <tokens>
            <token id="14" string="called" />
            <token id="15" string="the" />
            <token id="16" string="findings" />
            <token id="17" string="``" />
            <token id="18" string="plausible" />
            <token id="19" string="and" />
            <token id="20" string="provocative" />
          </tokens>
        </chunking>
        <chunking id="7" string="the National Institute" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="National" />
            <token id="4" string="Institute" />
          </tokens>
        </chunking>
        <chunking id="8" string="Allergy" type="NP">
          <tokens>
            <token id="6" string="Allergy" />
          </tokens>
        </chunking>
        <chunking id="9" string="plausible and provocative" type="ADJP">
          <tokens>
            <token id="18" string="plausible" />
            <token id="19" string="and" />
            <token id="20" string="provocative" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">Institute</governor>
          <dependent id="1">At</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">Institute</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Institute</governor>
          <dependent id="3">National</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">called</governor>
          <dependent id="4">Institute</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Diseases</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Diseases</governor>
          <dependent id="6">Allergy</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">Allergy</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">Allergy</governor>
          <dependent id="8">Infectious</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">Institute</governor>
          <dependent id="9">Diseases</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Curlin</governor>
          <dependent id="11">Dr.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Curlin</governor>
          <dependent id="12">George</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">called</governor>
          <dependent id="13">Curlin</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">called</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">findings</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="18">plausible</governor>
          <dependent id="16">findings</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="14">called</governor>
          <dependent id="18">plausible</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="18">plausible</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">plausible</governor>
          <dependent id="20">provocative</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="National Institute of Allergy" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="3" string="National" />
            <token id="4" string="Institute" />
            <token id="5" string="of" />
            <token id="6" string="Allergy" />
          </tokens>
        </entity>
        <entity id="2" string="George Curlin" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="George" />
            <token id="13" string="Curlin" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>However, he added: ``I&amp;apost;m scared to death that people are going to say this explains it all and forget everything else.</content>
      <tokens>
        <token id="1" string="However" lemma="however" stem="howev" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="added" lemma="add" stem="ad" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="'m" lemma="be" stem="'m" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="scared" lemma="scared" stem="scare" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="death" lemma="death" stem="death" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="say" lemma="say" stem="sai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="explains" lemma="explain" stem="explain" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="forget" lemma="forget" stem="forget" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="everything" lemma="everything" stem="everyth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="else" lemma="else" stem="els" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB However)) (, ,) (NP (PRP he)) (VP (VBD added) (: :) (`` ``) (S (NP (PRP I)) (VP (VBP 'm) (ADJP (JJ scared) (PP (TO to) (NP (NN death)))) (SBAR (IN that) (S (NP (NNS people)) (VP (VBP are) (VP (VBG going) (S (VP (TO to) (VP (VP (VB say) (SBAR (S (NP (DT this)) (VP (VBZ explains) (S (NP (PRP it)) (NP (DT all))))))) (CC and) (VP (VB forget) (S (NP (NN everything)) (ADJP (RB else)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="all" type="NP">
          <tokens>
            <token id="21" string="all" />
          </tokens>
        </chunking>
        <chunking id="2" string="to say this explains it all and forget everything else" type="VP">
          <tokens>
            <token id="16" string="to" />
            <token id="17" string="say" />
            <token id="18" string="this" />
            <token id="19" string="explains" />
            <token id="20" string="it" />
            <token id="21" string="all" />
            <token id="22" string="and" />
            <token id="23" string="forget" />
            <token id="24" string="everything" />
            <token id="25" string="else" />
          </tokens>
        </chunking>
        <chunking id="3" string="added : `` I 'm scared to death that people are going to say this explains it all and forget everything else" type="VP">
          <tokens>
            <token id="4" string="added" />
            <token id="5" string=":" />
            <token id="6" string="``" />
            <token id="7" string="I" />
            <token id="8" string="'m" />
            <token id="9" string="scared" />
            <token id="10" string="to" />
            <token id="11" string="death" />
            <token id="12" string="that" />
            <token id="13" string="people" />
            <token id="14" string="are" />
            <token id="15" string="going" />
            <token id="16" string="to" />
            <token id="17" string="say" />
            <token id="18" string="this" />
            <token id="19" string="explains" />
            <token id="20" string="it" />
            <token id="21" string="all" />
            <token id="22" string="and" />
            <token id="23" string="forget" />
            <token id="24" string="everything" />
            <token id="25" string="else" />
          </tokens>
        </chunking>
        <chunking id="4" string="death" type="NP">
          <tokens>
            <token id="11" string="death" />
          </tokens>
        </chunking>
        <chunking id="5" string="explains it all" type="VP">
          <tokens>
            <token id="19" string="explains" />
            <token id="20" string="it" />
            <token id="21" string="all" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="7" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="are going to say this explains it all and forget everything else" type="VP">
          <tokens>
            <token id="14" string="are" />
            <token id="15" string="going" />
            <token id="16" string="to" />
            <token id="17" string="say" />
            <token id="18" string="this" />
            <token id="19" string="explains" />
            <token id="20" string="it" />
            <token id="21" string="all" />
            <token id="22" string="and" />
            <token id="23" string="forget" />
            <token id="24" string="everything" />
            <token id="25" string="else" />
          </tokens>
        </chunking>
        <chunking id="8" string="say this explains it all" type="VP">
          <tokens>
            <token id="17" string="say" />
            <token id="18" string="this" />
            <token id="19" string="explains" />
            <token id="20" string="it" />
            <token id="21" string="all" />
          </tokens>
        </chunking>
        <chunking id="9" string="it" type="NP">
          <tokens>
            <token id="20" string="it" />
          </tokens>
        </chunking>
        <chunking id="10" string="this" type="NP">
          <tokens>
            <token id="18" string="this" />
          </tokens>
        </chunking>
        <chunking id="11" string="people" type="NP">
          <tokens>
            <token id="13" string="people" />
          </tokens>
        </chunking>
        <chunking id="12" string="say this explains it all and forget everything else" type="VP">
          <tokens>
            <token id="17" string="say" />
            <token id="18" string="this" />
            <token id="19" string="explains" />
            <token id="20" string="it" />
            <token id="21" string="all" />
            <token id="22" string="and" />
            <token id="23" string="forget" />
            <token id="24" string="everything" />
            <token id="25" string="else" />
          </tokens>
        </chunking>
        <chunking id="13" string="forget everything else" type="VP">
          <tokens>
            <token id="23" string="forget" />
            <token id="24" string="everything" />
            <token id="25" string="else" />
          </tokens>
        </chunking>
        <chunking id="14" string="that people are going to say this explains it all and forget everything else" type="SBAR">
          <tokens>
            <token id="12" string="that" />
            <token id="13" string="people" />
            <token id="14" string="are" />
            <token id="15" string="going" />
            <token id="16" string="to" />
            <token id="17" string="say" />
            <token id="18" string="this" />
            <token id="19" string="explains" />
            <token id="20" string="it" />
            <token id="21" string="all" />
            <token id="22" string="and" />
            <token id="23" string="forget" />
            <token id="24" string="everything" />
            <token id="25" string="else" />
          </tokens>
        </chunking>
        <chunking id="15" string="going to say this explains it all and forget everything else" type="VP">
          <tokens>
            <token id="15" string="going" />
            <token id="16" string="to" />
            <token id="17" string="say" />
            <token id="18" string="this" />
            <token id="19" string="explains" />
            <token id="20" string="it" />
            <token id="21" string="all" />
            <token id="22" string="and" />
            <token id="23" string="forget" />
            <token id="24" string="everything" />
            <token id="25" string="else" />
          </tokens>
        </chunking>
        <chunking id="16" string="else" type="ADJP">
          <tokens>
            <token id="25" string="else" />
          </tokens>
        </chunking>
        <chunking id="17" string="scared to death" type="ADJP">
          <tokens>
            <token id="9" string="scared" />
            <token id="10" string="to" />
            <token id="11" string="death" />
          </tokens>
        </chunking>
        <chunking id="18" string="this explains it all" type="SBAR">
          <tokens>
            <token id="18" string="this" />
            <token id="19" string="explains" />
            <token id="20" string="it" />
            <token id="21" string="all" />
          </tokens>
        </chunking>
        <chunking id="19" string="he" type="NP">
          <tokens>
            <token id="3" string="he" />
          </tokens>
        </chunking>
        <chunking id="20" string="'m scared to death that people are going to say this explains it all and forget everything else" type="VP">
          <tokens>
            <token id="8" string="'m" />
            <token id="9" string="scared" />
            <token id="10" string="to" />
            <token id="11" string="death" />
            <token id="12" string="that" />
            <token id="13" string="people" />
            <token id="14" string="are" />
            <token id="15" string="going" />
            <token id="16" string="to" />
            <token id="17" string="say" />
            <token id="18" string="this" />
            <token id="19" string="explains" />
            <token id="20" string="it" />
            <token id="21" string="all" />
            <token id="22" string="and" />
            <token id="23" string="forget" />
            <token id="24" string="everything" />
            <token id="25" string="else" />
          </tokens>
        </chunking>
        <chunking id="21" string="everything" type="NP">
          <tokens>
            <token id="24" string="everything" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="4">added</governor>
          <dependent id="1">However</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">added</governor>
          <dependent id="3">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">added</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">scared</governor>
          <dependent id="7">I</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="9">scared</governor>
          <dependent id="8">'m</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">added</governor>
          <dependent id="9">scared</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">death</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">scared</governor>
          <dependent id="11">death</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">going</governor>
          <dependent id="12">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">going</governor>
          <dependent id="13">people</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">going</governor>
          <dependent id="14">are</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">scared</governor>
          <dependent id="15">going</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">say</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="15">going</governor>
          <dependent id="17">say</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">explains</governor>
          <dependent id="18">this</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">say</governor>
          <dependent id="19">explains</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">all</governor>
          <dependent id="20">it</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="19">explains</governor>
          <dependent id="21">all</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">say</governor>
          <dependent id="22">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">say</governor>
          <dependent id="23">forget</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">else</governor>
          <dependent id="24">everything</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="23">forget</governor>
          <dependent id="25">else</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>Of the total six times difference, what proportion is attributable to biology and what to social factors?</content>
      <tokens>
        <token id="1" string="Of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="total" lemma="total" stem="total" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="six" lemma="six" stem="six" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="5" string="times" lemma="time" stem="time" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="difference" lemma="difference" stem="differ" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="what" lemma="what" stem="what" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="proportion" lemma="proportion" stem="proport" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="attributable" lemma="attributable" stem="attribut" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="biology" lemma="biology" stem="biologi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="social" lemma="social" stem="social" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="factors" lemma="factor" stem="factor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SBARQ (PP (IN Of) (NP (DT the) (JJ total) (ADJP (QP (CD six) (NNS times))) (NN difference))) (, ,) (WHNP (WDT what) (NN proportion)) (SQ (VBZ is) (ADJP (JJ attributable) (PP (TO to) (NP (NP (NN biology)) (CC and) (NP (WP what)))) (PP (TO to) (NP (JJ social) (NNS factors))))) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="biology" type="NP">
          <tokens>
            <token id="13" string="biology" />
          </tokens>
        </chunking>
        <chunking id="2" string="six times" type="ADJP">
          <tokens>
            <token id="4" string="six" />
            <token id="5" string="times" />
          </tokens>
        </chunking>
        <chunking id="3" string="what" type="NP">
          <tokens>
            <token id="15" string="what" />
          </tokens>
        </chunking>
        <chunking id="4" string="social factors" type="NP">
          <tokens>
            <token id="17" string="social" />
            <token id="18" string="factors" />
          </tokens>
        </chunking>
        <chunking id="5" string="attributable to biology and what to social factors" type="ADJP">
          <tokens>
            <token id="11" string="attributable" />
            <token id="12" string="to" />
            <token id="13" string="biology" />
            <token id="14" string="and" />
            <token id="15" string="what" />
            <token id="16" string="to" />
            <token id="17" string="social" />
            <token id="18" string="factors" />
          </tokens>
        </chunking>
        <chunking id="6" string="biology and what" type="NP">
          <tokens>
            <token id="13" string="biology" />
            <token id="14" string="and" />
            <token id="15" string="what" />
          </tokens>
        </chunking>
        <chunking id="7" string="the total six times difference" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="total" />
            <token id="4" string="six" />
            <token id="5" string="times" />
            <token id="6" string="difference" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="6">difference</governor>
          <dependent id="1">Of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">difference</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">difference</governor>
          <dependent id="3">total</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">times</governor>
          <dependent id="4">six</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="6">difference</governor>
          <dependent id="5">times</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">attributable</governor>
          <dependent id="6">difference</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">proportion</governor>
          <dependent id="8">what</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">attributable</governor>
          <dependent id="9">proportion</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">attributable</governor>
          <dependent id="10">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">attributable</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">biology</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">attributable</governor>
          <dependent id="13">biology</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">biology</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">biology</governor>
          <dependent id="15">what</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">factors</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">factors</governor>
          <dependent id="17">social</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">attributable</governor>
          <dependent id="18">factors</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="six" type="NUMBER" score="0.0">
          <tokens>
            <token id="4" string="six" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>I would say that biology is relatively minor.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="say" lemma="say" stem="sai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="biology" lemma="biology" stem="biologi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="relatively" lemma="relatively" stem="rel" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="minor" lemma="minor" stem="minor" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (MD would) (VP (VB say) (SBAR (IN that) (S (NP (NN biology)) (VP (VBZ is) (ADJP (RB relatively) (JJ minor))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="biology" type="NP">
          <tokens>
            <token id="5" string="biology" />
          </tokens>
        </chunking>
        <chunking id="2" string="relatively minor" type="ADJP">
          <tokens>
            <token id="7" string="relatively" />
            <token id="8" string="minor" />
          </tokens>
        </chunking>
        <chunking id="3" string="is relatively minor" type="VP">
          <tokens>
            <token id="6" string="is" />
            <token id="7" string="relatively" />
            <token id="8" string="minor" />
          </tokens>
        </chunking>
        <chunking id="4" string="that biology is relatively minor" type="SBAR">
          <tokens>
            <token id="4" string="that" />
            <token id="5" string="biology" />
            <token id="6" string="is" />
            <token id="7" string="relatively" />
            <token id="8" string="minor" />
          </tokens>
        </chunking>
        <chunking id="5" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="would say that biology is relatively minor" type="VP">
          <tokens>
            <token id="2" string="would" />
            <token id="3" string="say" />
            <token id="4" string="that" />
            <token id="5" string="biology" />
            <token id="6" string="is" />
            <token id="7" string="relatively" />
            <token id="8" string="minor" />
          </tokens>
        </chunking>
        <chunking id="7" string="say that biology is relatively minor" type="VP">
          <tokens>
            <token id="3" string="say" />
            <token id="4" string="that" />
            <token id="5" string="biology" />
            <token id="6" string="is" />
            <token id="7" string="relatively" />
            <token id="8" string="minor" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">say</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">say</governor>
          <dependent id="2">would</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">say</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">minor</governor>
          <dependent id="4">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">minor</governor>
          <dependent id="5">biology</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">minor</governor>
          <dependent id="6">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">minor</governor>
          <dependent id="7">relatively</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">say</governor>
          <dependent id="8">minor</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>Stead&amp;apost;s study, published in the New England Journal of Medicine, was based largely on a review of 25,398 elderly people who were free of TB infection when they were admitted to Arkansas nursing homes.</content>
      <tokens>
        <token id="1" string="Stead" lemma="Stead" stem="stead" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="study" lemma="study" stem="studi" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="published" lemma="publish" stem="publish" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="New" lemma="New" stem="new" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="9" string="England" lemma="England" stem="england" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="10" string="Journal" lemma="Journal" stem="journal" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="12" string="Medicine" lemma="Medicine" stem="medicin" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="based" lemma="base" stem="base" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="largely" lemma="largely" stem="larg" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="review" lemma="review" stem="review" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="25,398" lemma="25,398" stem="25,398" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="22" string="elderly" lemma="elderly" stem="elderli" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="26" string="free" lemma="free" stem="free" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="28" string="TB" lemma="tb" stem="tb" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="false" />
        <token id="29" string="infection" lemma="infection" stem="infect" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="false" />
        <token id="30" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="31" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="32" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="33" string="admitted" lemma="admit" stem="admit" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="34" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="35" string="Arkansas" lemma="Arkansas" stem="arkansa" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="36" string="nursing" lemma="nursing" stem="nurs" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="37" string="homes" lemma="home" stem="home" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="38" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NP (NNP Stead) (POS 's)) (NN study)) (, ,) (VP (VBN published) (PP (IN in) (NP (NP (DT the) (NNP New) (NNP England) (NNP Journal)) (PP (IN of) (NP (NNP Medicine)))))) (, ,)) (VP (VBD was) (VP (VBN based) (ADVP (RB largely)) (PP (IN on) (NP (NP (DT a) (NN review)) (PP (IN of) (NP (NP (CD 25,398) (JJ elderly) (NNS people)) (SBAR (WHNP (WP who)) (S (VP (VBD were) (ADJP (JJ free) (PP (IN of) (NP (NN TB) (NN infection)))) (SBAR (WHADVP (WRB when)) (S (NP (PRP they)) (VP (VBD were) (VP (VBN admitted) (PP (TO to) (NP (NNP Arkansas) (NN nursing) (NNS homes)))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the New England Journal" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="New" />
            <token id="9" string="England" />
            <token id="10" string="Journal" />
          </tokens>
        </chunking>
        <chunking id="2" string="Arkansas nursing homes" type="NP">
          <tokens>
            <token id="35" string="Arkansas" />
            <token id="36" string="nursing" />
            <token id="37" string="homes" />
          </tokens>
        </chunking>
        <chunking id="3" string="was based largely on a review of 25,398 elderly people who were free of TB infection when they were admitted to Arkansas nursing homes" type="VP">
          <tokens>
            <token id="14" string="was" />
            <token id="15" string="based" />
            <token id="16" string="largely" />
            <token id="17" string="on" />
            <token id="18" string="a" />
            <token id="19" string="review" />
            <token id="20" string="of" />
            <token id="21" string="25,398" />
            <token id="22" string="elderly" />
            <token id="23" string="people" />
            <token id="24" string="who" />
            <token id="25" string="were" />
            <token id="26" string="free" />
            <token id="27" string="of" />
            <token id="28" string="TB" />
            <token id="29" string="infection" />
            <token id="30" string="when" />
            <token id="31" string="they" />
            <token id="32" string="were" />
            <token id="33" string="admitted" />
            <token id="34" string="to" />
            <token id="35" string="Arkansas" />
            <token id="36" string="nursing" />
            <token id="37" string="homes" />
          </tokens>
        </chunking>
        <chunking id="4" string="were admitted to Arkansas nursing homes" type="VP">
          <tokens>
            <token id="32" string="were" />
            <token id="33" string="admitted" />
            <token id="34" string="to" />
            <token id="35" string="Arkansas" />
            <token id="36" string="nursing" />
            <token id="37" string="homes" />
          </tokens>
        </chunking>
        <chunking id="5" string="Stead 's study , published in the New England Journal of Medicine ," type="NP">
          <tokens>
            <token id="1" string="Stead" />
            <token id="2" string="'s" />
            <token id="3" string="study" />
            <token id="4" string="," />
            <token id="5" string="published" />
            <token id="6" string="in" />
            <token id="7" string="the" />
            <token id="8" string="New" />
            <token id="9" string="England" />
            <token id="10" string="Journal" />
            <token id="11" string="of" />
            <token id="12" string="Medicine" />
            <token id="13" string="," />
          </tokens>
        </chunking>
        <chunking id="6" string="Stead 's study" type="NP">
          <tokens>
            <token id="1" string="Stead" />
            <token id="2" string="'s" />
            <token id="3" string="study" />
          </tokens>
        </chunking>
        <chunking id="7" string="when" type="WHADVP">
          <tokens>
            <token id="30" string="when" />
          </tokens>
        </chunking>
        <chunking id="8" string="they" type="NP">
          <tokens>
            <token id="31" string="they" />
          </tokens>
        </chunking>
        <chunking id="9" string="who were free of TB infection when they were admitted to Arkansas nursing homes" type="SBAR">
          <tokens>
            <token id="24" string="who" />
            <token id="25" string="were" />
            <token id="26" string="free" />
            <token id="27" string="of" />
            <token id="28" string="TB" />
            <token id="29" string="infection" />
            <token id="30" string="when" />
            <token id="31" string="they" />
            <token id="32" string="were" />
            <token id="33" string="admitted" />
            <token id="34" string="to" />
            <token id="35" string="Arkansas" />
            <token id="36" string="nursing" />
            <token id="37" string="homes" />
          </tokens>
        </chunking>
        <chunking id="10" string="Medicine" type="NP">
          <tokens>
            <token id="12" string="Medicine" />
          </tokens>
        </chunking>
        <chunking id="11" string="were free of TB infection when they were admitted to Arkansas nursing homes" type="VP">
          <tokens>
            <token id="25" string="were" />
            <token id="26" string="free" />
            <token id="27" string="of" />
            <token id="28" string="TB" />
            <token id="29" string="infection" />
            <token id="30" string="when" />
            <token id="31" string="they" />
            <token id="32" string="were" />
            <token id="33" string="admitted" />
            <token id="34" string="to" />
            <token id="35" string="Arkansas" />
            <token id="36" string="nursing" />
            <token id="37" string="homes" />
          </tokens>
        </chunking>
        <chunking id="12" string="published in the New England Journal of Medicine" type="VP">
          <tokens>
            <token id="5" string="published" />
            <token id="6" string="in" />
            <token id="7" string="the" />
            <token id="8" string="New" />
            <token id="9" string="England" />
            <token id="10" string="Journal" />
            <token id="11" string="of" />
            <token id="12" string="Medicine" />
          </tokens>
        </chunking>
        <chunking id="13" string="Stead 's" type="NP">
          <tokens>
            <token id="1" string="Stead" />
            <token id="2" string="'s" />
          </tokens>
        </chunking>
        <chunking id="14" string="when they were admitted to Arkansas nursing homes" type="SBAR">
          <tokens>
            <token id="30" string="when" />
            <token id="31" string="they" />
            <token id="32" string="were" />
            <token id="33" string="admitted" />
            <token id="34" string="to" />
            <token id="35" string="Arkansas" />
            <token id="36" string="nursing" />
            <token id="37" string="homes" />
          </tokens>
        </chunking>
        <chunking id="15" string="based largely on a review of 25,398 elderly people who were free of TB infection when they were admitted to Arkansas nursing homes" type="VP">
          <tokens>
            <token id="15" string="based" />
            <token id="16" string="largely" />
            <token id="17" string="on" />
            <token id="18" string="a" />
            <token id="19" string="review" />
            <token id="20" string="of" />
            <token id="21" string="25,398" />
            <token id="22" string="elderly" />
            <token id="23" string="people" />
            <token id="24" string="who" />
            <token id="25" string="were" />
            <token id="26" string="free" />
            <token id="27" string="of" />
            <token id="28" string="TB" />
            <token id="29" string="infection" />
            <token id="30" string="when" />
            <token id="31" string="they" />
            <token id="32" string="were" />
            <token id="33" string="admitted" />
            <token id="34" string="to" />
            <token id="35" string="Arkansas" />
            <token id="36" string="nursing" />
            <token id="37" string="homes" />
          </tokens>
        </chunking>
        <chunking id="16" string="25,398 elderly people who were free of TB infection when they were admitted to Arkansas nursing homes" type="NP">
          <tokens>
            <token id="21" string="25,398" />
            <token id="22" string="elderly" />
            <token id="23" string="people" />
            <token id="24" string="who" />
            <token id="25" string="were" />
            <token id="26" string="free" />
            <token id="27" string="of" />
            <token id="28" string="TB" />
            <token id="29" string="infection" />
            <token id="30" string="when" />
            <token id="31" string="they" />
            <token id="32" string="were" />
            <token id="33" string="admitted" />
            <token id="34" string="to" />
            <token id="35" string="Arkansas" />
            <token id="36" string="nursing" />
            <token id="37" string="homes" />
          </tokens>
        </chunking>
        <chunking id="17" string="admitted to Arkansas nursing homes" type="VP">
          <tokens>
            <token id="33" string="admitted" />
            <token id="34" string="to" />
            <token id="35" string="Arkansas" />
            <token id="36" string="nursing" />
            <token id="37" string="homes" />
          </tokens>
        </chunking>
        <chunking id="18" string="25,398 elderly people" type="NP">
          <tokens>
            <token id="21" string="25,398" />
            <token id="22" string="elderly" />
            <token id="23" string="people" />
          </tokens>
        </chunking>
        <chunking id="19" string="the New England Journal of Medicine" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="New" />
            <token id="9" string="England" />
            <token id="10" string="Journal" />
            <token id="11" string="of" />
            <token id="12" string="Medicine" />
          </tokens>
        </chunking>
        <chunking id="20" string="a review" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="review" />
          </tokens>
        </chunking>
        <chunking id="21" string="free of TB infection" type="ADJP">
          <tokens>
            <token id="26" string="free" />
            <token id="27" string="of" />
            <token id="28" string="TB" />
            <token id="29" string="infection" />
          </tokens>
        </chunking>
        <chunking id="22" string="a review of 25,398 elderly people who were free of TB infection when they were admitted to Arkansas nursing homes" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="review" />
            <token id="20" string="of" />
            <token id="21" string="25,398" />
            <token id="22" string="elderly" />
            <token id="23" string="people" />
            <token id="24" string="who" />
            <token id="25" string="were" />
            <token id="26" string="free" />
            <token id="27" string="of" />
            <token id="28" string="TB" />
            <token id="29" string="infection" />
            <token id="30" string="when" />
            <token id="31" string="they" />
            <token id="32" string="were" />
            <token id="33" string="admitted" />
            <token id="34" string="to" />
            <token id="35" string="Arkansas" />
            <token id="36" string="nursing" />
            <token id="37" string="homes" />
          </tokens>
        </chunking>
        <chunking id="23" string="TB infection" type="NP">
          <tokens>
            <token id="28" string="TB" />
            <token id="29" string="infection" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="3">study</governor>
          <dependent id="1">Stead</dependent>
        </dependency>
        <dependency type="case">
          <governor id="1">Stead</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="15">based</governor>
          <dependent id="3">study</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="3">study</governor>
          <dependent id="5">published</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Journal</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">Journal</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Journal</governor>
          <dependent id="8">New</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Journal</governor>
          <dependent id="9">England</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">published</governor>
          <dependent id="10">Journal</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Medicine</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">Journal</governor>
          <dependent id="12">Medicine</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="15">based</governor>
          <dependent id="14">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">based</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">based</governor>
          <dependent id="16">largely</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">review</governor>
          <dependent id="17">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">review</governor>
          <dependent id="18">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">based</governor>
          <dependent id="19">review</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">people</governor>
          <dependent id="20">of</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="23">people</governor>
          <dependent id="21">25,398</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">people</governor>
          <dependent id="22">elderly</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">review</governor>
          <dependent id="23">people</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">free</governor>
          <dependent id="24">who</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="26">free</governor>
          <dependent id="25">were</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="23">people</governor>
          <dependent id="26">free</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">infection</governor>
          <dependent id="27">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">infection</governor>
          <dependent id="28">TB</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">free</governor>
          <dependent id="29">infection</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="33">admitted</governor>
          <dependent id="30">when</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="33">admitted</governor>
          <dependent id="31">they</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="33">admitted</governor>
          <dependent id="32">were</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="26">free</governor>
          <dependent id="33">admitted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">homes</governor>
          <dependent id="34">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="37">homes</governor>
          <dependent id="35">Arkansas</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="37">homes</governor>
          <dependent id="36">nursing</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">admitted</governor>
          <dependent id="37">homes</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="25,398" type="NUMBER" score="0.0">
          <tokens>
            <token id="21" string="25,398" />
          </tokens>
        </entity>
        <entity id="2" string="New England Journal of Medicine" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="8" string="New" />
            <token id="9" string="England" />
            <token id="10" string="Journal" />
            <token id="11" string="of" />
            <token id="12" string="Medicine" />
          </tokens>
        </entity>
        <entity id="3" string="Arkansas" type="LOCATION" score="0.0">
          <tokens>
            <token id="35" string="Arkansas" />
          </tokens>
        </entity>
        <entity id="4" string="TB infection" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="28" string="TB" />
            <token id="29" string="infection" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>When they were retested at least two months later, 14 percent of blacks and 7 percent of whites showed evidence of new infections.</content>
      <tokens>
        <token id="1" string="When" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="retested" lemma="retest" stem="retest" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string="least" lemma="least" stem="least" pos="JJS" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="7" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="8" string="months" lemma="month" stem="month" pos="NNS" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="9" string="later" lemma="later" stem="later" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="14" lemma="14" stem="14" pos="CD" type="Number" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="12" string="percent" lemma="percent" stem="percent" pos="NN" type="Word" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="blacks" lemma="black" stem="black" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="7" lemma="7" stem="7" pos="CD" type="Number" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="true" />
        <token id="17" string="percent" lemma="percent" stem="percent" pos="NN" type="Word" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="true" />
        <token id="18" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="whites" lemma="whites" stem="white" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="showed" lemma="show" stem="show" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="evidence" lemma="evidence" stem="evid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="new" lemma="new" stem="new" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="infections" lemma="infection" stem="infect" pos="NNS" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (WHADVP (WRB When)) (S (NP (PRP they)) (VP (VBD were) (VP (VBN retested) (ADVP (NP (QP (IN at) (JJS least) (CD two)) (NNS months)) (RB later)))))) (, ,) (NP (NP (CD 14) (NN percent)) (PP (IN of) (NP (NP (NNS blacks)) (CC and) (NP (NP (CD 7) (NN percent)) (PP (IN of) (NP (NNS whites))))))) (VP (VBD showed) (NP (NP (NN evidence)) (PP (IN of) (NP (JJ new) (NNS infections))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="showed evidence of new infections" type="VP">
          <tokens>
            <token id="20" string="showed" />
            <token id="21" string="evidence" />
            <token id="22" string="of" />
            <token id="23" string="new" />
            <token id="24" string="infections" />
          </tokens>
        </chunking>
        <chunking id="2" string="evidence of new infections" type="NP">
          <tokens>
            <token id="21" string="evidence" />
            <token id="22" string="of" />
            <token id="23" string="new" />
            <token id="24" string="infections" />
          </tokens>
        </chunking>
        <chunking id="3" string="at least two months" type="NP">
          <tokens>
            <token id="5" string="at" />
            <token id="6" string="least" />
            <token id="7" string="two" />
            <token id="8" string="months" />
          </tokens>
        </chunking>
        <chunking id="4" string="7 percent of whites" type="NP">
          <tokens>
            <token id="16" string="7" />
            <token id="17" string="percent" />
            <token id="18" string="of" />
            <token id="19" string="whites" />
          </tokens>
        </chunking>
        <chunking id="5" string="14 percent" type="NP">
          <tokens>
            <token id="11" string="14" />
            <token id="12" string="percent" />
          </tokens>
        </chunking>
        <chunking id="6" string="blacks and 7 percent of whites" type="NP">
          <tokens>
            <token id="14" string="blacks" />
            <token id="15" string="and" />
            <token id="16" string="7" />
            <token id="17" string="percent" />
            <token id="18" string="of" />
            <token id="19" string="whites" />
          </tokens>
        </chunking>
        <chunking id="7" string="evidence" type="NP">
          <tokens>
            <token id="21" string="evidence" />
          </tokens>
        </chunking>
        <chunking id="8" string="blacks" type="NP">
          <tokens>
            <token id="14" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="9" string="retested at least two months later" type="VP">
          <tokens>
            <token id="4" string="retested" />
            <token id="5" string="at" />
            <token id="6" string="least" />
            <token id="7" string="two" />
            <token id="8" string="months" />
            <token id="9" string="later" />
          </tokens>
        </chunking>
        <chunking id="10" string="When they were retested at least two months later" type="SBAR">
          <tokens>
            <token id="1" string="When" />
            <token id="2" string="they" />
            <token id="3" string="were" />
            <token id="4" string="retested" />
            <token id="5" string="at" />
            <token id="6" string="least" />
            <token id="7" string="two" />
            <token id="8" string="months" />
            <token id="9" string="later" />
          </tokens>
        </chunking>
        <chunking id="11" string="When" type="WHADVP">
          <tokens>
            <token id="1" string="When" />
          </tokens>
        </chunking>
        <chunking id="12" string="they" type="NP">
          <tokens>
            <token id="2" string="they" />
          </tokens>
        </chunking>
        <chunking id="13" string="whites" type="NP">
          <tokens>
            <token id="19" string="whites" />
          </tokens>
        </chunking>
        <chunking id="14" string="14 percent of blacks and 7 percent of whites" type="NP">
          <tokens>
            <token id="11" string="14" />
            <token id="12" string="percent" />
            <token id="13" string="of" />
            <token id="14" string="blacks" />
            <token id="15" string="and" />
            <token id="16" string="7" />
            <token id="17" string="percent" />
            <token id="18" string="of" />
            <token id="19" string="whites" />
          </tokens>
        </chunking>
        <chunking id="15" string="7 percent" type="NP">
          <tokens>
            <token id="16" string="7" />
            <token id="17" string="percent" />
          </tokens>
        </chunking>
        <chunking id="16" string="were retested at least two months later" type="VP">
          <tokens>
            <token id="3" string="were" />
            <token id="4" string="retested" />
            <token id="5" string="at" />
            <token id="6" string="least" />
            <token id="7" string="two" />
            <token id="8" string="months" />
            <token id="9" string="later" />
          </tokens>
        </chunking>
        <chunking id="17" string="new infections" type="NP">
          <tokens>
            <token id="23" string="new" />
            <token id="24" string="infections" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="4">retested</governor>
          <dependent id="1">When</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="4">retested</governor>
          <dependent id="2">they</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">retested</governor>
          <dependent id="3">were</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="20">showed</governor>
          <dependent id="4">retested</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">least</governor>
          <dependent id="5">at</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="7">two</governor>
          <dependent id="6">least</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="8">months</governor>
          <dependent id="7">two</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="9">later</governor>
          <dependent id="8">months</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">retested</governor>
          <dependent id="9">later</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="12">percent</governor>
          <dependent id="11">14</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">showed</governor>
          <dependent id="12">percent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">blacks</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">percent</governor>
          <dependent id="14">blacks</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">blacks</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="17">percent</governor>
          <dependent id="16">7</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">blacks</governor>
          <dependent id="17">percent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">whites</governor>
          <dependent id="18">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">percent</governor>
          <dependent id="19">whites</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="20">showed</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">showed</governor>
          <dependent id="21">evidence</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">infections</governor>
          <dependent id="22">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">infections</governor>
          <dependent id="23">new</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">evidence</governor>
          <dependent id="24">infections</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="14 percent" type="PERCENT" score="0.0">
          <tokens>
            <token id="11" string="14" />
            <token id="12" string="percent" />
          </tokens>
        </entity>
        <entity id="2" string="infections" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="24" string="infections" />
          </tokens>
        </entity>
        <entity id="3" string="at least two months later" type="DATE" score="0.0">
          <tokens>
            <token id="5" string="at" />
            <token id="6" string="least" />
            <token id="7" string="two" />
            <token id="8" string="months" />
            <token id="9" string="later" />
          </tokens>
        </entity>
        <entity id="4" string="7 percent" type="PERCENT" score="0.0">
          <tokens>
            <token id="16" string="7" />
            <token id="17" string="percent" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>Prison data from Arkansas and Minnesota also found that black inmates were twice as likely as white prisoners to catch the bacteria while incarcerated.</content>
      <tokens>
        <token id="1" string="Prison" lemma="prison" stem="prison" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="data" lemma="datum" stem="data" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Arkansas" lemma="Arkansas" stem="arkansa" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="5" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Minnesota" lemma="Minnesota" stem="minnesota" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="7" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="found" lemma="find" stem="found" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="inmates" lemma="inmate" stem="inmat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="twice" lemma="twice" stem="twice" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="as" lemma="as" stem="a" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="likely" lemma="likely" stem="like" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="white" lemma="white" stem="white" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="prisoners" lemma="prisoner" stem="prison" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="catch" lemma="catch" stem="catch" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="bacteria" lemma="bacterium" stem="bacteria" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="23" string="while" lemma="while" stem="while" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="incarcerated" lemma="incarcerate" stem="incarcer" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NN Prison) (NNS data)) (PP (IN from) (NP (NNP Arkansas) (CC and) (NNP Minnesota)))) (ADVP (RB also)) (VP (VBD found) (SBAR (IN that) (S (NP (JJ black) (NNS inmates)) (VP (VBD were) (ADJP (RB twice) (RB as) (JJ likely)) (PP (IN as) (NP (JJ white) (NNS prisoners))) (S (VP (TO to) (VP (VB catch) (NP (DT the) (NNS bacteria))))) (SBAR (IN while) (S (VP (VBN incarcerated)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Prison data" type="NP">
          <tokens>
            <token id="1" string="Prison" />
            <token id="2" string="data" />
          </tokens>
        </chunking>
        <chunking id="2" string="incarcerated" type="VP">
          <tokens>
            <token id="24" string="incarcerated" />
          </tokens>
        </chunking>
        <chunking id="3" string="the bacteria" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="bacteria" />
          </tokens>
        </chunking>
        <chunking id="4" string="twice as likely" type="ADJP">
          <tokens>
            <token id="13" string="twice" />
            <token id="14" string="as" />
            <token id="15" string="likely" />
          </tokens>
        </chunking>
        <chunking id="5" string="found that black inmates were twice as likely as white prisoners to catch the bacteria while incarcerated" type="VP">
          <tokens>
            <token id="8" string="found" />
            <token id="9" string="that" />
            <token id="10" string="black" />
            <token id="11" string="inmates" />
            <token id="12" string="were" />
            <token id="13" string="twice" />
            <token id="14" string="as" />
            <token id="15" string="likely" />
            <token id="16" string="as" />
            <token id="17" string="white" />
            <token id="18" string="prisoners" />
            <token id="19" string="to" />
            <token id="20" string="catch" />
            <token id="21" string="the" />
            <token id="22" string="bacteria" />
            <token id="23" string="while" />
            <token id="24" string="incarcerated" />
          </tokens>
        </chunking>
        <chunking id="6" string="were twice as likely as white prisoners to catch the bacteria while incarcerated" type="VP">
          <tokens>
            <token id="12" string="were" />
            <token id="13" string="twice" />
            <token id="14" string="as" />
            <token id="15" string="likely" />
            <token id="16" string="as" />
            <token id="17" string="white" />
            <token id="18" string="prisoners" />
            <token id="19" string="to" />
            <token id="20" string="catch" />
            <token id="21" string="the" />
            <token id="22" string="bacteria" />
            <token id="23" string="while" />
            <token id="24" string="incarcerated" />
          </tokens>
        </chunking>
        <chunking id="7" string="while incarcerated" type="SBAR">
          <tokens>
            <token id="23" string="while" />
            <token id="24" string="incarcerated" />
          </tokens>
        </chunking>
        <chunking id="8" string="white prisoners" type="NP">
          <tokens>
            <token id="17" string="white" />
            <token id="18" string="prisoners" />
          </tokens>
        </chunking>
        <chunking id="9" string="Arkansas and Minnesota" type="NP">
          <tokens>
            <token id="4" string="Arkansas" />
            <token id="5" string="and" />
            <token id="6" string="Minnesota" />
          </tokens>
        </chunking>
        <chunking id="10" string="to catch the bacteria" type="VP">
          <tokens>
            <token id="19" string="to" />
            <token id="20" string="catch" />
            <token id="21" string="the" />
            <token id="22" string="bacteria" />
          </tokens>
        </chunking>
        <chunking id="11" string="Prison data from Arkansas and Minnesota" type="NP">
          <tokens>
            <token id="1" string="Prison" />
            <token id="2" string="data" />
            <token id="3" string="from" />
            <token id="4" string="Arkansas" />
            <token id="5" string="and" />
            <token id="6" string="Minnesota" />
          </tokens>
        </chunking>
        <chunking id="12" string="that black inmates were twice as likely as white prisoners to catch the bacteria while incarcerated" type="SBAR">
          <tokens>
            <token id="9" string="that" />
            <token id="10" string="black" />
            <token id="11" string="inmates" />
            <token id="12" string="were" />
            <token id="13" string="twice" />
            <token id="14" string="as" />
            <token id="15" string="likely" />
            <token id="16" string="as" />
            <token id="17" string="white" />
            <token id="18" string="prisoners" />
            <token id="19" string="to" />
            <token id="20" string="catch" />
            <token id="21" string="the" />
            <token id="22" string="bacteria" />
            <token id="23" string="while" />
            <token id="24" string="incarcerated" />
          </tokens>
        </chunking>
        <chunking id="13" string="catch the bacteria" type="VP">
          <tokens>
            <token id="20" string="catch" />
            <token id="21" string="the" />
            <token id="22" string="bacteria" />
          </tokens>
        </chunking>
        <chunking id="14" string="black inmates" type="NP">
          <tokens>
            <token id="10" string="black" />
            <token id="11" string="inmates" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">data</governor>
          <dependent id="1">Prison</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">found</governor>
          <dependent id="2">data</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">Arkansas</governor>
          <dependent id="3">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">data</governor>
          <dependent id="4">Arkansas</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">Arkansas</governor>
          <dependent id="5">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">Arkansas</governor>
          <dependent id="6">Minnesota</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">found</governor>
          <dependent id="7">also</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">found</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">likely</governor>
          <dependent id="9">that</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">inmates</governor>
          <dependent id="10">black</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">likely</governor>
          <dependent id="11">inmates</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="15">likely</governor>
          <dependent id="12">were</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">likely</governor>
          <dependent id="13">twice</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">likely</governor>
          <dependent id="14">as</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">found</governor>
          <dependent id="15">likely</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">prisoners</governor>
          <dependent id="16">as</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">prisoners</governor>
          <dependent id="17">white</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">likely</governor>
          <dependent id="18">prisoners</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">catch</governor>
          <dependent id="19">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="15">likely</governor>
          <dependent id="20">catch</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">bacteria</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">catch</governor>
          <dependent id="22">bacteria</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">incarcerated</governor>
          <dependent id="23">while</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="15">likely</governor>
          <dependent id="24">incarcerated</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Minnesota" type="LOCATION" score="0.0">
          <tokens>
            <token id="6" string="Minnesota" />
          </tokens>
        </entity>
        <entity id="2" string="Arkansas" type="LOCATION" score="0.0">
          <tokens>
            <token id="4" string="Arkansas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>Another soon-to-be published study reports the discovery of a racial difference in the way blood cells respond to the TB bacteria, which could help explain why blacks seem to be more prone to tuberculosis.</content>
      <tokens>
        <token id="1" string="Another" lemma="another" stem="another" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="soon-to-be" lemma="soon-to-be" stem="soon-to-b" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="published" lemma="publish" stem="publish" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="study" lemma="study" stem="studi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="reports" lemma="report" stem="report" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="discovery" lemma="discovery" stem="discoveri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="racial" lemma="racial" stem="racial" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="difference" lemma="difference" stem="differ" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="way" lemma="way" stem="wai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="blood" lemma="blood" stem="blood" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="cells" lemma="cell" stem="cell" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="respond" lemma="respond" stem="respond" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="TB" lemma="tb" stem="tb" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="true" />
        <token id="21" string="bacteria" lemma="bacterium" stem="bacteria" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="25" string="help" lemma="help" stem="help" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="26" string="explain" lemma="explain" stem="explain" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="27" string="why" lemma="why" stem="why" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="28" string="blacks" lemma="black" stem="black" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="29" string="seem" lemma="seem" stem="seem" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="30" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="32" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="33" string="prone" lemma="prone" stem="prone" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="34" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="35" string="tuberculosis" lemma="tuberculosis" stem="tuberculosi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT Another) (JJ soon-to-be) (VBN published) (NN study)) (VP (VBZ reports) (NP (NP (DT the) (NN discovery)) (PP (IN of) (NP (NP (DT a) (JJ racial) (NN difference)) (PP (IN in) (NP (NP (DT the) (NN way)) (SBAR (S (NP (NN blood) (NNS cells)) (VP (VBP respond) (PP (TO to) (NP (NP (DT the) (NN TB) (NNS bacteria)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (MD could) (VP (VB help) (VP (VB explain) (SBAR (WHADVP (WRB why)) (S (NP (NNS blacks)) (VP (VBP seem) (S (VP (TO to) (VP (VB be) (ADJP (RBR more) (JJ prone) (PP (TO to) (NP (NN tuberculosis)))))))))))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="more prone to tuberculosis" type="ADJP">
          <tokens>
            <token id="32" string="more" />
            <token id="33" string="prone" />
            <token id="34" string="to" />
            <token id="35" string="tuberculosis" />
          </tokens>
        </chunking>
        <chunking id="2" string="a racial difference" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="racial" />
            <token id="11" string="difference" />
          </tokens>
        </chunking>
        <chunking id="3" string="tuberculosis" type="NP">
          <tokens>
            <token id="35" string="tuberculosis" />
          </tokens>
        </chunking>
        <chunking id="4" string="respond to the TB bacteria , which could help explain why blacks seem to be more prone to tuberculosis" type="VP">
          <tokens>
            <token id="17" string="respond" />
            <token id="18" string="to" />
            <token id="19" string="the" />
            <token id="20" string="TB" />
            <token id="21" string="bacteria" />
            <token id="22" string="," />
            <token id="23" string="which" />
            <token id="24" string="could" />
            <token id="25" string="help" />
            <token id="26" string="explain" />
            <token id="27" string="why" />
            <token id="28" string="blacks" />
            <token id="29" string="seem" />
            <token id="30" string="to" />
            <token id="31" string="be" />
            <token id="32" string="more" />
            <token id="33" string="prone" />
            <token id="34" string="to" />
            <token id="35" string="tuberculosis" />
          </tokens>
        </chunking>
        <chunking id="5" string="blood cells" type="NP">
          <tokens>
            <token id="15" string="blood" />
            <token id="16" string="cells" />
          </tokens>
        </chunking>
        <chunking id="6" string="to be more prone to tuberculosis" type="VP">
          <tokens>
            <token id="30" string="to" />
            <token id="31" string="be" />
            <token id="32" string="more" />
            <token id="33" string="prone" />
            <token id="34" string="to" />
            <token id="35" string="tuberculosis" />
          </tokens>
        </chunking>
        <chunking id="7" string="could help explain why blacks seem to be more prone to tuberculosis" type="VP">
          <tokens>
            <token id="24" string="could" />
            <token id="25" string="help" />
            <token id="26" string="explain" />
            <token id="27" string="why" />
            <token id="28" string="blacks" />
            <token id="29" string="seem" />
            <token id="30" string="to" />
            <token id="31" string="be" />
            <token id="32" string="more" />
            <token id="33" string="prone" />
            <token id="34" string="to" />
            <token id="35" string="tuberculosis" />
          </tokens>
        </chunking>
        <chunking id="8" string="the TB bacteria , which could help explain why blacks seem to be more prone to tuberculosis" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="TB" />
            <token id="21" string="bacteria" />
            <token id="22" string="," />
            <token id="23" string="which" />
            <token id="24" string="could" />
            <token id="25" string="help" />
            <token id="26" string="explain" />
            <token id="27" string="why" />
            <token id="28" string="blacks" />
            <token id="29" string="seem" />
            <token id="30" string="to" />
            <token id="31" string="be" />
            <token id="32" string="more" />
            <token id="33" string="prone" />
            <token id="34" string="to" />
            <token id="35" string="tuberculosis" />
          </tokens>
        </chunking>
        <chunking id="9" string="be more prone to tuberculosis" type="VP">
          <tokens>
            <token id="31" string="be" />
            <token id="32" string="more" />
            <token id="33" string="prone" />
            <token id="34" string="to" />
            <token id="35" string="tuberculosis" />
          </tokens>
        </chunking>
        <chunking id="10" string="the discovery of a racial difference in the way blood cells respond to the TB bacteria , which could help explain why blacks seem to be more prone to tuberculosis" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="discovery" />
            <token id="8" string="of" />
            <token id="9" string="a" />
            <token id="10" string="racial" />
            <token id="11" string="difference" />
            <token id="12" string="in" />
            <token id="13" string="the" />
            <token id="14" string="way" />
            <token id="15" string="blood" />
            <token id="16" string="cells" />
            <token id="17" string="respond" />
            <token id="18" string="to" />
            <token id="19" string="the" />
            <token id="20" string="TB" />
            <token id="21" string="bacteria" />
            <token id="22" string="," />
            <token id="23" string="which" />
            <token id="24" string="could" />
            <token id="25" string="help" />
            <token id="26" string="explain" />
            <token id="27" string="why" />
            <token id="28" string="blacks" />
            <token id="29" string="seem" />
            <token id="30" string="to" />
            <token id="31" string="be" />
            <token id="32" string="more" />
            <token id="33" string="prone" />
            <token id="34" string="to" />
            <token id="35" string="tuberculosis" />
          </tokens>
        </chunking>
        <chunking id="11" string="the discovery" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="discovery" />
          </tokens>
        </chunking>
        <chunking id="12" string="a racial difference in the way blood cells respond to the TB bacteria , which could help explain why blacks seem to be more prone to tuberculosis" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="racial" />
            <token id="11" string="difference" />
            <token id="12" string="in" />
            <token id="13" string="the" />
            <token id="14" string="way" />
            <token id="15" string="blood" />
            <token id="16" string="cells" />
            <token id="17" string="respond" />
            <token id="18" string="to" />
            <token id="19" string="the" />
            <token id="20" string="TB" />
            <token id="21" string="bacteria" />
            <token id="22" string="," />
            <token id="23" string="which" />
            <token id="24" string="could" />
            <token id="25" string="help" />
            <token id="26" string="explain" />
            <token id="27" string="why" />
            <token id="28" string="blacks" />
            <token id="29" string="seem" />
            <token id="30" string="to" />
            <token id="31" string="be" />
            <token id="32" string="more" />
            <token id="33" string="prone" />
            <token id="34" string="to" />
            <token id="35" string="tuberculosis" />
          </tokens>
        </chunking>
        <chunking id="13" string="explain why blacks seem to be more prone to tuberculosis" type="VP">
          <tokens>
            <token id="26" string="explain" />
            <token id="27" string="why" />
            <token id="28" string="blacks" />
            <token id="29" string="seem" />
            <token id="30" string="to" />
            <token id="31" string="be" />
            <token id="32" string="more" />
            <token id="33" string="prone" />
            <token id="34" string="to" />
            <token id="35" string="tuberculosis" />
          </tokens>
        </chunking>
        <chunking id="14" string="why" type="WHADVP">
          <tokens>
            <token id="27" string="why" />
          </tokens>
        </chunking>
        <chunking id="15" string="seem to be more prone to tuberculosis" type="VP">
          <tokens>
            <token id="29" string="seem" />
            <token id="30" string="to" />
            <token id="31" string="be" />
            <token id="32" string="more" />
            <token id="33" string="prone" />
            <token id="34" string="to" />
            <token id="35" string="tuberculosis" />
          </tokens>
        </chunking>
        <chunking id="16" string="blacks" type="NP">
          <tokens>
            <token id="28" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="17" string="Another soon-to-be published study" type="NP">
          <tokens>
            <token id="1" string="Another" />
            <token id="2" string="soon-to-be" />
            <token id="3" string="published" />
            <token id="4" string="study" />
          </tokens>
        </chunking>
        <chunking id="18" string="help explain why blacks seem to be more prone to tuberculosis" type="VP">
          <tokens>
            <token id="25" string="help" />
            <token id="26" string="explain" />
            <token id="27" string="why" />
            <token id="28" string="blacks" />
            <token id="29" string="seem" />
            <token id="30" string="to" />
            <token id="31" string="be" />
            <token id="32" string="more" />
            <token id="33" string="prone" />
            <token id="34" string="to" />
            <token id="35" string="tuberculosis" />
          </tokens>
        </chunking>
        <chunking id="19" string="reports the discovery of a racial difference in the way blood cells respond to the TB bacteria , which could help explain why blacks seem to be more prone to tuberculosis" type="VP">
          <tokens>
            <token id="5" string="reports" />
            <token id="6" string="the" />
            <token id="7" string="discovery" />
            <token id="8" string="of" />
            <token id="9" string="a" />
            <token id="10" string="racial" />
            <token id="11" string="difference" />
            <token id="12" string="in" />
            <token id="13" string="the" />
            <token id="14" string="way" />
            <token id="15" string="blood" />
            <token id="16" string="cells" />
            <token id="17" string="respond" />
            <token id="18" string="to" />
            <token id="19" string="the" />
            <token id="20" string="TB" />
            <token id="21" string="bacteria" />
            <token id="22" string="," />
            <token id="23" string="which" />
            <token id="24" string="could" />
            <token id="25" string="help" />
            <token id="26" string="explain" />
            <token id="27" string="why" />
            <token id="28" string="blacks" />
            <token id="29" string="seem" />
            <token id="30" string="to" />
            <token id="31" string="be" />
            <token id="32" string="more" />
            <token id="33" string="prone" />
            <token id="34" string="to" />
            <token id="35" string="tuberculosis" />
          </tokens>
        </chunking>
        <chunking id="20" string="which could help explain why blacks seem to be more prone to tuberculosis" type="SBAR">
          <tokens>
            <token id="23" string="which" />
            <token id="24" string="could" />
            <token id="25" string="help" />
            <token id="26" string="explain" />
            <token id="27" string="why" />
            <token id="28" string="blacks" />
            <token id="29" string="seem" />
            <token id="30" string="to" />
            <token id="31" string="be" />
            <token id="32" string="more" />
            <token id="33" string="prone" />
            <token id="34" string="to" />
            <token id="35" string="tuberculosis" />
          </tokens>
        </chunking>
        <chunking id="21" string="the TB bacteria" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="TB" />
            <token id="21" string="bacteria" />
          </tokens>
        </chunking>
        <chunking id="22" string="why blacks seem to be more prone to tuberculosis" type="SBAR">
          <tokens>
            <token id="27" string="why" />
            <token id="28" string="blacks" />
            <token id="29" string="seem" />
            <token id="30" string="to" />
            <token id="31" string="be" />
            <token id="32" string="more" />
            <token id="33" string="prone" />
            <token id="34" string="to" />
            <token id="35" string="tuberculosis" />
          </tokens>
        </chunking>
        <chunking id="23" string="the way" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="way" />
          </tokens>
        </chunking>
        <chunking id="24" string="blood cells respond to the TB bacteria , which could help explain why blacks seem to be more prone to tuberculosis" type="SBAR">
          <tokens>
            <token id="15" string="blood" />
            <token id="16" string="cells" />
            <token id="17" string="respond" />
            <token id="18" string="to" />
            <token id="19" string="the" />
            <token id="20" string="TB" />
            <token id="21" string="bacteria" />
            <token id="22" string="," />
            <token id="23" string="which" />
            <token id="24" string="could" />
            <token id="25" string="help" />
            <token id="26" string="explain" />
            <token id="27" string="why" />
            <token id="28" string="blacks" />
            <token id="29" string="seem" />
            <token id="30" string="to" />
            <token id="31" string="be" />
            <token id="32" string="more" />
            <token id="33" string="prone" />
            <token id="34" string="to" />
            <token id="35" string="tuberculosis" />
          </tokens>
        </chunking>
        <chunking id="25" string="the way blood cells respond to the TB bacteria , which could help explain why blacks seem to be more prone to tuberculosis" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="way" />
            <token id="15" string="blood" />
            <token id="16" string="cells" />
            <token id="17" string="respond" />
            <token id="18" string="to" />
            <token id="19" string="the" />
            <token id="20" string="TB" />
            <token id="21" string="bacteria" />
            <token id="22" string="," />
            <token id="23" string="which" />
            <token id="24" string="could" />
            <token id="25" string="help" />
            <token id="26" string="explain" />
            <token id="27" string="why" />
            <token id="28" string="blacks" />
            <token id="29" string="seem" />
            <token id="30" string="to" />
            <token id="31" string="be" />
            <token id="32" string="more" />
            <token id="33" string="prone" />
            <token id="34" string="to" />
            <token id="35" string="tuberculosis" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">study</governor>
          <dependent id="1">Another</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">study</governor>
          <dependent id="2">soon-to-be</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">study</governor>
          <dependent id="3">published</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">reports</governor>
          <dependent id="4">study</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">reports</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">discovery</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">reports</governor>
          <dependent id="7">discovery</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">difference</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">difference</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">difference</governor>
          <dependent id="10">racial</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">discovery</governor>
          <dependent id="11">difference</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">way</governor>
          <dependent id="12">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">way</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">difference</governor>
          <dependent id="14">way</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">cells</governor>
          <dependent id="15">blood</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">respond</governor>
          <dependent id="16">cells</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="14">way</governor>
          <dependent id="17">respond</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">bacteria</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">bacteria</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">bacteria</governor>
          <dependent id="20">TB</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">respond</governor>
          <dependent id="21">bacteria</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">help</governor>
          <dependent id="23">which</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="25">help</governor>
          <dependent id="24">could</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="21">bacteria</governor>
          <dependent id="25">help</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="25">help</governor>
          <dependent id="26">explain</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="29">seem</governor>
          <dependent id="27">why</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">seem</governor>
          <dependent id="28">blacks</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="26">explain</governor>
          <dependent id="29">seem</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="33">prone</governor>
          <dependent id="30">to</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="33">prone</governor>
          <dependent id="31">be</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="33">prone</governor>
          <dependent id="32">more</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="29">seem</governor>
          <dependent id="33">prone</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">tuberculosis</governor>
          <dependent id="34">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">prone</governor>
          <dependent id="35">tuberculosis</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="TB" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="20" string="TB" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="false">
      <content>About 22,000 cases of tuberculosis are reported annually in the United States, resulting in 1,700 deaths.</content>
      <tokens>
        <token id="1" string="About" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="22,000" lemma="22,000" stem="22,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="3" string="cases" lemma="case" stem="case" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="tuberculosis" lemma="tuberculosis" stem="tuberculosi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="reported" lemma="report" stem="report" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="annually" lemma="annually" stem="annual" pos="RB" type="Word" isStopWord="false" ner="SET" is_referenced="false" is_refers="false" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="United" lemma="United" stem="unite" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="12" string="States" lemma="States" stem="state" pos="NNPS" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="resulting" lemma="result" stem="result" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="1,700" lemma="1,700" stem="1,700" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="17" string="deaths" lemma="death" stem="death" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN About) (NP (CD 22,000))) (NP (NP (NNS cases)) (PP (IN of) (NP (NN tuberculosis)))) (VP (VBP are) (VP (VBN reported) (ADVP (RB annually)) (PP (IN in) (NP (DT the) (NNP United) (NNPS States))) (, ,) (S (VP (VBG resulting) (PP (IN in) (NP (CD 1,700) (NNS deaths))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the United States" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="United" />
            <token id="12" string="States" />
          </tokens>
        </chunking>
        <chunking id="2" string="cases" type="NP">
          <tokens>
            <token id="3" string="cases" />
          </tokens>
        </chunking>
        <chunking id="3" string="resulting in 1,700 deaths" type="VP">
          <tokens>
            <token id="14" string="resulting" />
            <token id="15" string="in" />
            <token id="16" string="1,700" />
            <token id="17" string="deaths" />
          </tokens>
        </chunking>
        <chunking id="4" string="22,000" type="NP">
          <tokens>
            <token id="2" string="22,000" />
          </tokens>
        </chunking>
        <chunking id="5" string="tuberculosis" type="NP">
          <tokens>
            <token id="5" string="tuberculosis" />
          </tokens>
        </chunking>
        <chunking id="6" string="are reported annually in the United States , resulting in 1,700 deaths" type="VP">
          <tokens>
            <token id="6" string="are" />
            <token id="7" string="reported" />
            <token id="8" string="annually" />
            <token id="9" string="in" />
            <token id="10" string="the" />
            <token id="11" string="United" />
            <token id="12" string="States" />
            <token id="13" string="," />
            <token id="14" string="resulting" />
            <token id="15" string="in" />
            <token id="16" string="1,700" />
            <token id="17" string="deaths" />
          </tokens>
        </chunking>
        <chunking id="7" string="cases of tuberculosis" type="NP">
          <tokens>
            <token id="3" string="cases" />
            <token id="4" string="of" />
            <token id="5" string="tuberculosis" />
          </tokens>
        </chunking>
        <chunking id="8" string="reported annually in the United States , resulting in 1,700 deaths" type="VP">
          <tokens>
            <token id="7" string="reported" />
            <token id="8" string="annually" />
            <token id="9" string="in" />
            <token id="10" string="the" />
            <token id="11" string="United" />
            <token id="12" string="States" />
            <token id="13" string="," />
            <token id="14" string="resulting" />
            <token id="15" string="in" />
            <token id="16" string="1,700" />
            <token id="17" string="deaths" />
          </tokens>
        </chunking>
        <chunking id="9" string="1,700 deaths" type="NP">
          <tokens>
            <token id="16" string="1,700" />
            <token id="17" string="deaths" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">22,000</governor>
          <dependent id="1">About</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">reported</governor>
          <dependent id="2">22,000</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="7">reported</governor>
          <dependent id="3">cases</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">tuberculosis</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">cases</governor>
          <dependent id="5">tuberculosis</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="7">reported</governor>
          <dependent id="6">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">reported</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">reported</governor>
          <dependent id="8">annually</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">States</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">States</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">States</governor>
          <dependent id="11">United</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">reported</governor>
          <dependent id="12">States</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">reported</governor>
          <dependent id="14">resulting</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">deaths</governor>
          <dependent id="15">in</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="17">deaths</governor>
          <dependent id="16">1,700</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">resulting</governor>
          <dependent id="17">deaths</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="22,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="2" string="22,000" />
          </tokens>
        </entity>
        <entity id="2" string="United States" type="LOCATION" score="0.0">
          <tokens>
            <token id="11" string="United" />
            <token id="12" string="States" />
          </tokens>
        </entity>
        <entity id="3" string="annually" type="SET" score="0.0">
          <tokens>
            <token id="8" string="annually" />
          </tokens>
        </entity>
        <entity id="4" string="1,700" type="NUMBER" score="0.0">
          <tokens>
            <token id="16" string="1,700" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>In the population at large, tuberculosis is about six times as common among blacks as whites.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="population" lemma="population" stem="popul" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="large" lemma="large" stem="larg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="tuberculosis" lemma="tuberculosis" stem="tuberculosi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="six" lemma="six" stem="six" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="11" string="times" lemma="time" stem="time" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="common" lemma="common" stem="common" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="among" lemma="among" stem="among" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="blacks" lemma="black" stem="black" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="whites" lemma="whites" stem="white" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (NP (DT the) (NN population)) (PP (IN at) (NP (JJ large))))) (, ,) (NP (NN tuberculosis)) (VP (VBZ is) (VP (IN about) (NP (QP (CD six) (NNS times) (IN as) (JJ common))) (PP (IN among) (NP (NP (NNS blacks)) (PP (IN as) (NP (NNS whites))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the population at large" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="population" />
            <token id="4" string="at" />
            <token id="5" string="large" />
          </tokens>
        </chunking>
        <chunking id="2" string="the population" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="population" />
          </tokens>
        </chunking>
        <chunking id="3" string="whites" type="NP">
          <tokens>
            <token id="17" string="whites" />
          </tokens>
        </chunking>
        <chunking id="4" string="tuberculosis" type="NP">
          <tokens>
            <token id="7" string="tuberculosis" />
          </tokens>
        </chunking>
        <chunking id="5" string="blacks as whites" type="NP">
          <tokens>
            <token id="15" string="blacks" />
            <token id="16" string="as" />
            <token id="17" string="whites" />
          </tokens>
        </chunking>
        <chunking id="6" string="large" type="NP">
          <tokens>
            <token id="5" string="large" />
          </tokens>
        </chunking>
        <chunking id="7" string="six times as common" type="NP">
          <tokens>
            <token id="10" string="six" />
            <token id="11" string="times" />
            <token id="12" string="as" />
            <token id="13" string="common" />
          </tokens>
        </chunking>
        <chunking id="8" string="about six times as common among blacks as whites" type="VP">
          <tokens>
            <token id="9" string="about" />
            <token id="10" string="six" />
            <token id="11" string="times" />
            <token id="12" string="as" />
            <token id="13" string="common" />
            <token id="14" string="among" />
            <token id="15" string="blacks" />
            <token id="16" string="as" />
            <token id="17" string="whites" />
          </tokens>
        </chunking>
        <chunking id="9" string="is about six times as common among blacks as whites" type="VP">
          <tokens>
            <token id="8" string="is" />
            <token id="9" string="about" />
            <token id="10" string="six" />
            <token id="11" string="times" />
            <token id="12" string="as" />
            <token id="13" string="common" />
            <token id="14" string="among" />
            <token id="15" string="blacks" />
            <token id="16" string="as" />
            <token id="17" string="whites" />
          </tokens>
        </chunking>
        <chunking id="10" string="blacks" type="NP">
          <tokens>
            <token id="15" string="blacks" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">population</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">population</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">times</governor>
          <dependent id="3">population</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">large</governor>
          <dependent id="4">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">population</governor>
          <dependent id="5">large</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">times</governor>
          <dependent id="7">tuberculosis</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">times</governor>
          <dependent id="8">is</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="11">times</governor>
          <dependent id="9">about</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">times</governor>
          <dependent id="10">six</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">times</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">times</governor>
          <dependent id="12">as</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">times</governor>
          <dependent id="13">common</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">blacks</governor>
          <dependent id="14">among</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">times</governor>
          <dependent id="15">blacks</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">whites</governor>
          <dependent id="16">as</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">blacks</governor>
          <dependent id="17">whites</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="six" type="NUMBER" score="0.0">
          <tokens>
            <token id="10" string="six" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>An estimated 10 million Americans are believed to be infected with the bacteria but not sick.</content>
      <tokens>
        <token id="1" string="An" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="estimated" lemma="estimate" stem="estim" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="10" lemma="10" stem="10" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="4" string="million" lemma="million" stem="million" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="5" string="Americans" lemma="Americans" stem="american" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="6" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="believed" lemma="believe" stem="believ" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="infected" lemma="infect" stem="infect" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="bacteria" lemma="bacterium" stem="bacteria" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="sick" lemma="sick" stem="sick" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT An) (VBN estimated) (QP (CD 10) (CD million))) (NP (NNPS Americans)) (VP (VP (VBP are) (VP (VBN believed) (S (VP (TO to) (VP (VB be) (VP (VBN infected) (PP (IN with) (NP (DT the) (NNS bacteria))))))))) (CC but) (VP (RB not) (ADJP (JJ sick)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="infected with the bacteria" type="VP">
          <tokens>
            <token id="10" string="infected" />
            <token id="11" string="with" />
            <token id="12" string="the" />
            <token id="13" string="bacteria" />
          </tokens>
        </chunking>
        <chunking id="2" string="An estimated 10 million" type="NP">
          <tokens>
            <token id="1" string="An" />
            <token id="2" string="estimated" />
            <token id="3" string="10" />
            <token id="4" string="million" />
          </tokens>
        </chunking>
        <chunking id="3" string="believed to be infected with the bacteria" type="VP">
          <tokens>
            <token id="7" string="believed" />
            <token id="8" string="to" />
            <token id="9" string="be" />
            <token id="10" string="infected" />
            <token id="11" string="with" />
            <token id="12" string="the" />
            <token id="13" string="bacteria" />
          </tokens>
        </chunking>
        <chunking id="4" string="the bacteria" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="bacteria" />
          </tokens>
        </chunking>
        <chunking id="5" string="not sick" type="VP">
          <tokens>
            <token id="15" string="not" />
            <token id="16" string="sick" />
          </tokens>
        </chunking>
        <chunking id="6" string="Americans" type="NP">
          <tokens>
            <token id="5" string="Americans" />
          </tokens>
        </chunking>
        <chunking id="7" string="to be infected with the bacteria" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="be" />
            <token id="10" string="infected" />
            <token id="11" string="with" />
            <token id="12" string="the" />
            <token id="13" string="bacteria" />
          </tokens>
        </chunking>
        <chunking id="8" string="sick" type="ADJP">
          <tokens>
            <token id="16" string="sick" />
          </tokens>
        </chunking>
        <chunking id="9" string="are believed to be infected with the bacteria but not sick" type="VP">
          <tokens>
            <token id="6" string="are" />
            <token id="7" string="believed" />
            <token id="8" string="to" />
            <token id="9" string="be" />
            <token id="10" string="infected" />
            <token id="11" string="with" />
            <token id="12" string="the" />
            <token id="13" string="bacteria" />
            <token id="14" string="but" />
            <token id="15" string="not" />
            <token id="16" string="sick" />
          </tokens>
        </chunking>
        <chunking id="10" string="be infected with the bacteria" type="VP">
          <tokens>
            <token id="9" string="be" />
            <token id="10" string="infected" />
            <token id="11" string="with" />
            <token id="12" string="the" />
            <token id="13" string="bacteria" />
          </tokens>
        </chunking>
        <chunking id="11" string="are believed to be infected with the bacteria" type="VP">
          <tokens>
            <token id="6" string="are" />
            <token id="7" string="believed" />
            <token id="8" string="to" />
            <token id="9" string="be" />
            <token id="10" string="infected" />
            <token id="11" string="with" />
            <token id="12" string="the" />
            <token id="13" string="bacteria" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">million</governor>
          <dependent id="1">An</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">million</governor>
          <dependent id="2">estimated</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">million</governor>
          <dependent id="3">10</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="7">believed</governor>
          <dependent id="4">million</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="7">believed</governor>
          <dependent id="5">Americans</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="7">believed</governor>
          <dependent id="6">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">believed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">infected</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="10">infected</governor>
          <dependent id="9">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">believed</governor>
          <dependent id="10">infected</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">bacteria</governor>
          <dependent id="11">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">bacteria</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">infected</governor>
          <dependent id="13">bacteria</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">believed</governor>
          <dependent id="14">but</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="16">sick</governor>
          <dependent id="15">not</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">believed</governor>
          <dependent id="16">sick</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Americans" type="MISC" score="0.0">
          <tokens>
            <token id="5" string="Americans" />
          </tokens>
        </entity>
        <entity id="2" string="10 million" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="10" />
            <token id="4" string="million" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="false">
      <content>The disease, which attacks the lungs, has long been associated with poor, crowded living conditions.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="attacks" lemma="attack" stem="attack" pos="VBZ" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="lungs" lemma="lung" stem="lung" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="long" lemma="long" stem="long" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="associated" lemma="associate" stem="associ" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="poor" lemma="poor" stem="poor" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="crowded" lemma="crowded" stem="crowd" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="living" lemma="living" stem="live" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="conditions" lemma="condition" stem="condit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NN disease)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ attacks) (NP (DT the) (NNS lungs))))) (, ,)) (VP (VBZ has) (ADVP (RB long)) (VP (VBN been) (VP (VBN associated) (PP (IN with) (NP (JJ poor) (, ,) (JJ crowded) (NN living) (NNS conditions)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="associated with poor , crowded living conditions" type="VP">
          <tokens>
            <token id="12" string="associated" />
            <token id="13" string="with" />
            <token id="14" string="poor" />
            <token id="15" string="," />
            <token id="16" string="crowded" />
            <token id="17" string="living" />
            <token id="18" string="conditions" />
          </tokens>
        </chunking>
        <chunking id="2" string="the lungs" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="lungs" />
          </tokens>
        </chunking>
        <chunking id="3" string="has long been associated with poor , crowded living conditions" type="VP">
          <tokens>
            <token id="9" string="has" />
            <token id="10" string="long" />
            <token id="11" string="been" />
            <token id="12" string="associated" />
            <token id="13" string="with" />
            <token id="14" string="poor" />
            <token id="15" string="," />
            <token id="16" string="crowded" />
            <token id="17" string="living" />
            <token id="18" string="conditions" />
          </tokens>
        </chunking>
        <chunking id="4" string="which attacks the lungs" type="SBAR">
          <tokens>
            <token id="4" string="which" />
            <token id="5" string="attacks" />
            <token id="6" string="the" />
            <token id="7" string="lungs" />
          </tokens>
        </chunking>
        <chunking id="5" string="poor , crowded living conditions" type="NP">
          <tokens>
            <token id="14" string="poor" />
            <token id="15" string="," />
            <token id="16" string="crowded" />
            <token id="17" string="living" />
            <token id="18" string="conditions" />
          </tokens>
        </chunking>
        <chunking id="6" string="The disease" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="disease" />
          </tokens>
        </chunking>
        <chunking id="7" string="attacks the lungs" type="VP">
          <tokens>
            <token id="5" string="attacks" />
            <token id="6" string="the" />
            <token id="7" string="lungs" />
          </tokens>
        </chunking>
        <chunking id="8" string="The disease , which attacks the lungs ," type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="disease" />
            <token id="3" string="," />
            <token id="4" string="which" />
            <token id="5" string="attacks" />
            <token id="6" string="the" />
            <token id="7" string="lungs" />
            <token id="8" string="," />
          </tokens>
        </chunking>
        <chunking id="9" string="been associated with poor , crowded living conditions" type="VP">
          <tokens>
            <token id="11" string="been" />
            <token id="12" string="associated" />
            <token id="13" string="with" />
            <token id="14" string="poor" />
            <token id="15" string="," />
            <token id="16" string="crowded" />
            <token id="17" string="living" />
            <token id="18" string="conditions" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">disease</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="12">associated</governor>
          <dependent id="2">disease</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">attacks</governor>
          <dependent id="4">which</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="2">disease</governor>
          <dependent id="5">attacks</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">lungs</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">attacks</governor>
          <dependent id="7">lungs</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">associated</governor>
          <dependent id="9">has</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">associated</governor>
          <dependent id="10">long</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="12">associated</governor>
          <dependent id="11">been</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">associated</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">conditions</governor>
          <dependent id="13">with</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">conditions</governor>
          <dependent id="14">poor</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">conditions</governor>
          <dependent id="16">crowded</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">conditions</governor>
          <dependent id="17">living</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">associated</governor>
          <dependent id="18">conditions</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="2" string="disease" />
          </tokens>
        </entity>
        <entity id="2" string="attacks" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="5" string="attacks" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>Stead&amp;apost;s study found that blacks got infected more readily than whites, regardless of the race of the person who initially brought the infection into the nursing home.</content>
      <tokens>
        <token id="1" string="Stead" lemma="Stead" stem="stead" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="study" lemma="study" stem="studi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="found" lemma="find" stem="found" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="blacks" lemma="black" stem="black" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="got" lemma="get" stem="got" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="infected" lemma="infect" stem="infect" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="readily" lemma="readily" stem="readili" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="whites" lemma="whites" stem="white" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="regardless" lemma="regardless" stem="regardless" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="race" lemma="race" stem="race" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="person" lemma="person" stem="person" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="initially" lemma="initially" stem="initi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="brought" lemma="bring" stem="brought" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="infection" lemma="infection" stem="infect" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="true" />
        <token id="26" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="nursing" lemma="nursing" stem="nurs" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="home" lemma="home" stem="home" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Stead) (POS 's)) (NN study)) (VP (VBD found) (SBAR (IN that) (S (NP (NNS blacks)) (VP (VBD got) (VP (VBN infected) (ADVP (RBR more) (RB readily)) (PP (IN than) (NP (NNS whites))) (, ,) (ADVP (RB regardless) (PP (IN of) (NP (NP (DT the) (NN race)) (PP (IN of) (NP (NP (DT the) (NN person)) (SBAR (WHNP (WP who)) (S (ADVP (RB initially)) (VP (VBD brought) (NP (DT the) (NN infection)) (PP (IN into) (NP (DT the) (NN nursing) (NN home)))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the person who initially brought the infection into the nursing home" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="person" />
            <token id="21" string="who" />
            <token id="22" string="initially" />
            <token id="23" string="brought" />
            <token id="24" string="the" />
            <token id="25" string="infection" />
            <token id="26" string="into" />
            <token id="27" string="the" />
            <token id="28" string="nursing" />
            <token id="29" string="home" />
          </tokens>
        </chunking>
        <chunking id="2" string="the race of the person who initially brought the infection into the nursing home" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="race" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="person" />
            <token id="21" string="who" />
            <token id="22" string="initially" />
            <token id="23" string="brought" />
            <token id="24" string="the" />
            <token id="25" string="infection" />
            <token id="26" string="into" />
            <token id="27" string="the" />
            <token id="28" string="nursing" />
            <token id="29" string="home" />
          </tokens>
        </chunking>
        <chunking id="3" string="the infection" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="infection" />
          </tokens>
        </chunking>
        <chunking id="4" string="blacks" type="NP">
          <tokens>
            <token id="6" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="5" string="who initially brought the infection into the nursing home" type="SBAR">
          <tokens>
            <token id="21" string="who" />
            <token id="22" string="initially" />
            <token id="23" string="brought" />
            <token id="24" string="the" />
            <token id="25" string="infection" />
            <token id="26" string="into" />
            <token id="27" string="the" />
            <token id="28" string="nursing" />
            <token id="29" string="home" />
          </tokens>
        </chunking>
        <chunking id="6" string="Stead 's study" type="NP">
          <tokens>
            <token id="1" string="Stead" />
            <token id="2" string="'s" />
            <token id="3" string="study" />
          </tokens>
        </chunking>
        <chunking id="7" string="infected more readily than whites , regardless of the race of the person who initially brought the infection into the nursing home" type="VP">
          <tokens>
            <token id="8" string="infected" />
            <token id="9" string="more" />
            <token id="10" string="readily" />
            <token id="11" string="than" />
            <token id="12" string="whites" />
            <token id="13" string="," />
            <token id="14" string="regardless" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="race" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="person" />
            <token id="21" string="who" />
            <token id="22" string="initially" />
            <token id="23" string="brought" />
            <token id="24" string="the" />
            <token id="25" string="infection" />
            <token id="26" string="into" />
            <token id="27" string="the" />
            <token id="28" string="nursing" />
            <token id="29" string="home" />
          </tokens>
        </chunking>
        <chunking id="8" string="brought the infection into the nursing home" type="VP">
          <tokens>
            <token id="23" string="brought" />
            <token id="24" string="the" />
            <token id="25" string="infection" />
            <token id="26" string="into" />
            <token id="27" string="the" />
            <token id="28" string="nursing" />
            <token id="29" string="home" />
          </tokens>
        </chunking>
        <chunking id="9" string="that blacks got infected more readily than whites , regardless of the race of the person who initially brought the infection into the nursing home" type="SBAR">
          <tokens>
            <token id="5" string="that" />
            <token id="6" string="blacks" />
            <token id="7" string="got" />
            <token id="8" string="infected" />
            <token id="9" string="more" />
            <token id="10" string="readily" />
            <token id="11" string="than" />
            <token id="12" string="whites" />
            <token id="13" string="," />
            <token id="14" string="regardless" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="race" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="person" />
            <token id="21" string="who" />
            <token id="22" string="initially" />
            <token id="23" string="brought" />
            <token id="24" string="the" />
            <token id="25" string="infection" />
            <token id="26" string="into" />
            <token id="27" string="the" />
            <token id="28" string="nursing" />
            <token id="29" string="home" />
          </tokens>
        </chunking>
        <chunking id="10" string="whites" type="NP">
          <tokens>
            <token id="12" string="whites" />
          </tokens>
        </chunking>
        <chunking id="11" string="the person" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="person" />
          </tokens>
        </chunking>
        <chunking id="12" string="Stead 's" type="NP">
          <tokens>
            <token id="1" string="Stead" />
            <token id="2" string="'s" />
          </tokens>
        </chunking>
        <chunking id="13" string="found that blacks got infected more readily than whites , regardless of the race of the person who initially brought the infection into the nursing home" type="VP">
          <tokens>
            <token id="4" string="found" />
            <token id="5" string="that" />
            <token id="6" string="blacks" />
            <token id="7" string="got" />
            <token id="8" string="infected" />
            <token id="9" string="more" />
            <token id="10" string="readily" />
            <token id="11" string="than" />
            <token id="12" string="whites" />
            <token id="13" string="," />
            <token id="14" string="regardless" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="race" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="person" />
            <token id="21" string="who" />
            <token id="22" string="initially" />
            <token id="23" string="brought" />
            <token id="24" string="the" />
            <token id="25" string="infection" />
            <token id="26" string="into" />
            <token id="27" string="the" />
            <token id="28" string="nursing" />
            <token id="29" string="home" />
          </tokens>
        </chunking>
        <chunking id="14" string="the nursing home" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="nursing" />
            <token id="29" string="home" />
          </tokens>
        </chunking>
        <chunking id="15" string="got infected more readily than whites , regardless of the race of the person who initially brought the infection into the nursing home" type="VP">
          <tokens>
            <token id="7" string="got" />
            <token id="8" string="infected" />
            <token id="9" string="more" />
            <token id="10" string="readily" />
            <token id="11" string="than" />
            <token id="12" string="whites" />
            <token id="13" string="," />
            <token id="14" string="regardless" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="race" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="person" />
            <token id="21" string="who" />
            <token id="22" string="initially" />
            <token id="23" string="brought" />
            <token id="24" string="the" />
            <token id="25" string="infection" />
            <token id="26" string="into" />
            <token id="27" string="the" />
            <token id="28" string="nursing" />
            <token id="29" string="home" />
          </tokens>
        </chunking>
        <chunking id="16" string="the race" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="race" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="3">study</governor>
          <dependent id="1">Stead</dependent>
        </dependency>
        <dependency type="case">
          <governor id="1">Stead</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">found</governor>
          <dependent id="3">study</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">found</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">infected</governor>
          <dependent id="5">that</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="8">infected</governor>
          <dependent id="6">blacks</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="8">infected</governor>
          <dependent id="7">got</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">found</governor>
          <dependent id="8">infected</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">readily</governor>
          <dependent id="9">more</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">infected</governor>
          <dependent id="10">readily</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">whites</governor>
          <dependent id="11">than</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">infected</governor>
          <dependent id="12">whites</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">race</governor>
          <dependent id="14">regardless</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="14">regardless</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">race</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">infected</governor>
          <dependent id="17">race</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">person</governor>
          <dependent id="18">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">person</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">race</governor>
          <dependent id="20">person</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">brought</governor>
          <dependent id="21">who</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="23">brought</governor>
          <dependent id="22">initially</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="20">person</governor>
          <dependent id="23">brought</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">infection</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">brought</governor>
          <dependent id="25">infection</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">home</governor>
          <dependent id="26">into</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">home</governor>
          <dependent id="27">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">home</governor>
          <dependent id="28">nursing</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">brought</governor>
          <dependent id="29">home</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="infection" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="25" string="infection" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>In homes where the initial source of the disease was white, 17 percent of blacks and 12 percent of whites caught the infection.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="homes" lemma="home" stem="home" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="initial" lemma="initial" stem="initi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="source" lemma="source" stem="sourc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="10" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="white" lemma="white" stem="white" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="17" lemma="17" stem="17" pos="CD" type="Number" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="14" string="percent" lemma="percent" stem="percent" pos="NN" type="Word" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="blacks" lemma="black" stem="black" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="12" lemma="12" stem="12" pos="CD" type="Number" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="19" string="percent" lemma="percent" stem="percent" pos="NN" type="Word" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="20" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="whites" lemma="whites" stem="white" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="caught" lemma="catch" stem="caught" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="infection" lemma="infection" stem="infect" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="true" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (NP (NNS homes)) (SBAR (WHADVP (WRB where)) (S (NP (NP (DT the) (JJ initial) (NN source)) (PP (IN of) (NP (DT the) (NN disease)))) (VP (VBD was) (ADJP (JJ white))))))) (, ,) (NP (NP (CD 17) (NN percent)) (PP (IN of) (NP (NP (NNS blacks)) (CC and) (NP (NP (CD 12) (NN percent)) (PP (IN of) (NP (NNS whites))))))) (VP (VBD caught) (NP (DT the) (NN infection))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="homes where the initial source of the disease was white" type="NP">
          <tokens>
            <token id="2" string="homes" />
            <token id="3" string="where" />
            <token id="4" string="the" />
            <token id="5" string="initial" />
            <token id="6" string="source" />
            <token id="7" string="of" />
            <token id="8" string="the" />
            <token id="9" string="disease" />
            <token id="10" string="was" />
            <token id="11" string="white" />
          </tokens>
        </chunking>
        <chunking id="2" string="where the initial source of the disease was white" type="SBAR">
          <tokens>
            <token id="3" string="where" />
            <token id="4" string="the" />
            <token id="5" string="initial" />
            <token id="6" string="source" />
            <token id="7" string="of" />
            <token id="8" string="the" />
            <token id="9" string="disease" />
            <token id="10" string="was" />
            <token id="11" string="white" />
          </tokens>
        </chunking>
        <chunking id="3" string="the infection" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="infection" />
          </tokens>
        </chunking>
        <chunking id="4" string="17 percent of blacks and 12 percent of whites" type="NP">
          <tokens>
            <token id="13" string="17" />
            <token id="14" string="percent" />
            <token id="15" string="of" />
            <token id="16" string="blacks" />
            <token id="17" string="and" />
            <token id="18" string="12" />
            <token id="19" string="percent" />
            <token id="20" string="of" />
            <token id="21" string="whites" />
          </tokens>
        </chunking>
        <chunking id="5" string="blacks" type="NP">
          <tokens>
            <token id="16" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="6" string="12 percent of whites" type="NP">
          <tokens>
            <token id="18" string="12" />
            <token id="19" string="percent" />
            <token id="20" string="of" />
            <token id="21" string="whites" />
          </tokens>
        </chunking>
        <chunking id="7" string="caught the infection" type="VP">
          <tokens>
            <token id="22" string="caught" />
            <token id="23" string="the" />
            <token id="24" string="infection" />
          </tokens>
        </chunking>
        <chunking id="8" string="the initial source of the disease" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="initial" />
            <token id="6" string="source" />
            <token id="7" string="of" />
            <token id="8" string="the" />
            <token id="9" string="disease" />
          </tokens>
        </chunking>
        <chunking id="9" string="the disease" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="disease" />
          </tokens>
        </chunking>
        <chunking id="10" string="whites" type="NP">
          <tokens>
            <token id="21" string="whites" />
          </tokens>
        </chunking>
        <chunking id="11" string="white" type="ADJP">
          <tokens>
            <token id="11" string="white" />
          </tokens>
        </chunking>
        <chunking id="12" string="was white" type="VP">
          <tokens>
            <token id="10" string="was" />
            <token id="11" string="white" />
          </tokens>
        </chunking>
        <chunking id="13" string="the initial source" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="initial" />
            <token id="6" string="source" />
          </tokens>
        </chunking>
        <chunking id="14" string="17 percent" type="NP">
          <tokens>
            <token id="13" string="17" />
            <token id="14" string="percent" />
          </tokens>
        </chunking>
        <chunking id="15" string="where" type="WHADVP">
          <tokens>
            <token id="3" string="where" />
          </tokens>
        </chunking>
        <chunking id="16" string="blacks and 12 percent of whites" type="NP">
          <tokens>
            <token id="16" string="blacks" />
            <token id="17" string="and" />
            <token id="18" string="12" />
            <token id="19" string="percent" />
            <token id="20" string="of" />
            <token id="21" string="whites" />
          </tokens>
        </chunking>
        <chunking id="17" string="homes" type="NP">
          <tokens>
            <token id="2" string="homes" />
          </tokens>
        </chunking>
        <chunking id="18" string="12 percent" type="NP">
          <tokens>
            <token id="18" string="12" />
            <token id="19" string="percent" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">homes</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">caught</governor>
          <dependent id="2">homes</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">white</governor>
          <dependent id="3">where</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">source</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">source</governor>
          <dependent id="5">initial</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">white</governor>
          <dependent id="6">source</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">disease</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">disease</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">source</governor>
          <dependent id="9">disease</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">white</governor>
          <dependent id="10">was</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="2">homes</governor>
          <dependent id="11">white</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="14">percent</governor>
          <dependent id="13">17</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">caught</governor>
          <dependent id="14">percent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">blacks</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">percent</governor>
          <dependent id="16">blacks</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">blacks</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="19">percent</governor>
          <dependent id="18">12</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">blacks</governor>
          <dependent id="19">percent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">whites</governor>
          <dependent id="20">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">percent</governor>
          <dependent id="21">whites</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="22">caught</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">infection</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">caught</governor>
          <dependent id="24">infection</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="infection" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="24" string="infection" />
          </tokens>
        </entity>
        <entity id="2" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="9" string="disease" />
          </tokens>
        </entity>
        <entity id="3" string="17 percent" type="PERCENT" score="0.0">
          <tokens>
            <token id="13" string="17" />
            <token id="14" string="percent" />
          </tokens>
        </entity>
        <entity id="4" string="12 percent" type="PERCENT" score="0.0">
          <tokens>
            <token id="18" string="12" />
            <token id="19" string="percent" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>When the primary source was black, 12 percent of blacks and 8 percent of whites contracted the bacteria.</content>
      <tokens>
        <token id="1" string="When" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="primary" lemma="primary" stem="primari" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="source" lemma="source" stem="sourc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="12" lemma="12" stem="12" pos="CD" type="Number" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="9" string="percent" lemma="percent" stem="percent" pos="NN" type="Word" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="blacks" lemma="black" stem="black" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="8" lemma="8" stem="8" pos="CD" type="Number" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="14" string="percent" lemma="percent" stem="percent" pos="NN" type="Word" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="whites" lemma="whites" stem="white" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="contracted" lemma="contract" stem="contract" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="bacteria" lemma="bacterium" stem="bacteria" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (WHADVP (WRB When)) (S (NP (DT the) (JJ primary) (NN source)) (VP (VBD was) (ADJP (JJ black))))) (, ,) (NP (NP (CD 12) (NN percent)) (PP (IN of) (NP (NP (NNS blacks)) (CC and) (NP (NP (CD 8) (NN percent)) (PP (IN of) (NP (NNS whites))))))) (VP (VBD contracted) (NP (DT the) (NNS bacteria))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the primary source" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="primary" />
            <token id="4" string="source" />
          </tokens>
        </chunking>
        <chunking id="2" string="the bacteria" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="bacteria" />
          </tokens>
        </chunking>
        <chunking id="3" string="was black" type="VP">
          <tokens>
            <token id="5" string="was" />
            <token id="6" string="black" />
          </tokens>
        </chunking>
        <chunking id="4" string="black" type="ADJP">
          <tokens>
            <token id="6" string="black" />
          </tokens>
        </chunking>
        <chunking id="5" string="blacks" type="NP">
          <tokens>
            <token id="11" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="6" string="12 percent of blacks and 8 percent of whites" type="NP">
          <tokens>
            <token id="8" string="12" />
            <token id="9" string="percent" />
            <token id="10" string="of" />
            <token id="11" string="blacks" />
            <token id="12" string="and" />
            <token id="13" string="8" />
            <token id="14" string="percent" />
            <token id="15" string="of" />
            <token id="16" string="whites" />
          </tokens>
        </chunking>
        <chunking id="7" string="When the primary source was black" type="SBAR">
          <tokens>
            <token id="1" string="When" />
            <token id="2" string="the" />
            <token id="3" string="primary" />
            <token id="4" string="source" />
            <token id="5" string="was" />
            <token id="6" string="black" />
          </tokens>
        </chunking>
        <chunking id="8" string="contracted the bacteria" type="VP">
          <tokens>
            <token id="17" string="contracted" />
            <token id="18" string="the" />
            <token id="19" string="bacteria" />
          </tokens>
        </chunking>
        <chunking id="9" string="When" type="WHADVP">
          <tokens>
            <token id="1" string="When" />
          </tokens>
        </chunking>
        <chunking id="10" string="blacks and 8 percent of whites" type="NP">
          <tokens>
            <token id="11" string="blacks" />
            <token id="12" string="and" />
            <token id="13" string="8" />
            <token id="14" string="percent" />
            <token id="15" string="of" />
            <token id="16" string="whites" />
          </tokens>
        </chunking>
        <chunking id="11" string="whites" type="NP">
          <tokens>
            <token id="16" string="whites" />
          </tokens>
        </chunking>
        <chunking id="12" string="8 percent of whites" type="NP">
          <tokens>
            <token id="13" string="8" />
            <token id="14" string="percent" />
            <token id="15" string="of" />
            <token id="16" string="whites" />
          </tokens>
        </chunking>
        <chunking id="13" string="8 percent" type="NP">
          <tokens>
            <token id="13" string="8" />
            <token id="14" string="percent" />
          </tokens>
        </chunking>
        <chunking id="14" string="12 percent" type="NP">
          <tokens>
            <token id="8" string="12" />
            <token id="9" string="percent" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="6">black</governor>
          <dependent id="1">When</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">source</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">source</governor>
          <dependent id="3">primary</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">black</governor>
          <dependent id="4">source</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">black</governor>
          <dependent id="5">was</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="17">contracted</governor>
          <dependent id="6">black</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="9">percent</governor>
          <dependent id="8">12</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">contracted</governor>
          <dependent id="9">percent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">blacks</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">percent</governor>
          <dependent id="11">blacks</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">blacks</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="14">percent</governor>
          <dependent id="13">8</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">blacks</governor>
          <dependent id="14">percent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">whites</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">percent</governor>
          <dependent id="16">whites</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">contracted</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">bacteria</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">contracted</governor>
          <dependent id="19">bacteria</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="8 percent" type="PERCENT" score="0.0">
          <tokens>
            <token id="13" string="8" />
            <token id="14" string="percent" />
          </tokens>
        </entity>
        <entity id="2" string="12 percent" type="PERCENT" score="0.0">
          <tokens>
            <token id="8" string="12" />
            <token id="9" string="percent" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="26" has_coreference="false">
      <content>This phase of the study also suggests, however, that infected whites are more potent spreaders of the infection than are blacks.</content>
      <tokens>
        <token id="1" string="This" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="phase" lemma="phase" stem="phase" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="study" lemma="study" stem="studi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="suggests" lemma="suggest" stem="suggest" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="however" lemma="however" stem="howev" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="infected" lemma="infected" stem="infect" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="whites" lemma="whites" stem="white" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="potent" lemma="potent" stem="potent" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="spreaders" lemma="spreader" stem="spreader" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="infection" lemma="infection" stem="infect" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="21" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="blacks" lemma="black" stem="black" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT This) (NN phase)) (PP (IN of) (NP (DT the) (NN study)))) (ADVP (RB also)) (VP (VBZ suggests) (, ,) (ADVP (RB however)) (, ,) (SBAR (IN that) (S (NP (JJ infected) (NNS whites)) (VP (VBP are) (NP (NP (ADJP (RBR more) (JJ potent)) (NNS spreaders)) (PP (IN of) (NP (NP (DT the) (NN infection)) (SBAR (IN than) (S (VP (VBP are) (NP (NNS blacks)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="more potent" type="ADJP">
          <tokens>
            <token id="15" string="more" />
            <token id="16" string="potent" />
          </tokens>
        </chunking>
        <chunking id="2" string="the study" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="study" />
          </tokens>
        </chunking>
        <chunking id="3" string="than are blacks" type="SBAR">
          <tokens>
            <token id="21" string="than" />
            <token id="22" string="are" />
            <token id="23" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="4" string="suggests , however , that infected whites are more potent spreaders of the infection than are blacks" type="VP">
          <tokens>
            <token id="7" string="suggests" />
            <token id="8" string="," />
            <token id="9" string="however" />
            <token id="10" string="," />
            <token id="11" string="that" />
            <token id="12" string="infected" />
            <token id="13" string="whites" />
            <token id="14" string="are" />
            <token id="15" string="more" />
            <token id="16" string="potent" />
            <token id="17" string="spreaders" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="infection" />
            <token id="21" string="than" />
            <token id="22" string="are" />
            <token id="23" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="5" string="the infection" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="infection" />
          </tokens>
        </chunking>
        <chunking id="6" string="blacks" type="NP">
          <tokens>
            <token id="23" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="7" string="that infected whites are more potent spreaders of the infection than are blacks" type="SBAR">
          <tokens>
            <token id="11" string="that" />
            <token id="12" string="infected" />
            <token id="13" string="whites" />
            <token id="14" string="are" />
            <token id="15" string="more" />
            <token id="16" string="potent" />
            <token id="17" string="spreaders" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="infection" />
            <token id="21" string="than" />
            <token id="22" string="are" />
            <token id="23" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="8" string="infected whites" type="NP">
          <tokens>
            <token id="12" string="infected" />
            <token id="13" string="whites" />
          </tokens>
        </chunking>
        <chunking id="9" string="more potent spreaders" type="NP">
          <tokens>
            <token id="15" string="more" />
            <token id="16" string="potent" />
            <token id="17" string="spreaders" />
          </tokens>
        </chunking>
        <chunking id="10" string="more potent spreaders of the infection than are blacks" type="NP">
          <tokens>
            <token id="15" string="more" />
            <token id="16" string="potent" />
            <token id="17" string="spreaders" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="infection" />
            <token id="21" string="than" />
            <token id="22" string="are" />
            <token id="23" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="11" string="the infection than are blacks" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="infection" />
            <token id="21" string="than" />
            <token id="22" string="are" />
            <token id="23" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="12" string="This phase of the study" type="NP">
          <tokens>
            <token id="1" string="This" />
            <token id="2" string="phase" />
            <token id="3" string="of" />
            <token id="4" string="the" />
            <token id="5" string="study" />
          </tokens>
        </chunking>
        <chunking id="13" string="are blacks" type="VP">
          <tokens>
            <token id="22" string="are" />
            <token id="23" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="14" string="This phase" type="NP">
          <tokens>
            <token id="1" string="This" />
            <token id="2" string="phase" />
          </tokens>
        </chunking>
        <chunking id="15" string="are more potent spreaders of the infection than are blacks" type="VP">
          <tokens>
            <token id="14" string="are" />
            <token id="15" string="more" />
            <token id="16" string="potent" />
            <token id="17" string="spreaders" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="infection" />
            <token id="21" string="than" />
            <token id="22" string="are" />
            <token id="23" string="blacks" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">phase</governor>
          <dependent id="1">This</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">suggests</governor>
          <dependent id="2">phase</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">study</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">study</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">phase</governor>
          <dependent id="5">study</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">suggests</governor>
          <dependent id="6">also</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">suggests</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">suggests</governor>
          <dependent id="9">however</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">spreaders</governor>
          <dependent id="11">that</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">whites</governor>
          <dependent id="12">infected</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">spreaders</governor>
          <dependent id="13">whites</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="17">spreaders</governor>
          <dependent id="14">are</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">potent</governor>
          <dependent id="15">more</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">spreaders</governor>
          <dependent id="16">potent</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">suggests</governor>
          <dependent id="17">spreaders</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">infection</governor>
          <dependent id="18">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">infection</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">spreaders</governor>
          <dependent id="20">infection</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">blacks</governor>
          <dependent id="21">than</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="23">blacks</governor>
          <dependent id="22">are</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="20">infection</governor>
          <dependent id="23">blacks</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="infection" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="20" string="infection" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>Stead speculated that whites have evolved better defenses against TB, because the bacteria has long been common in Europe and parts of Africa north of the Sahara, but is traditionally rare in sub-Saharan Africa.</content>
      <tokens>
        <token id="1" string="Stead" lemma="stead" stem="stead" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="speculated" lemma="speculate" stem="specul" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="whites" lemma="whites" stem="white" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="evolved" lemma="evolve" stem="evolv" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="better" lemma="better" stem="better" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="defenses" lemma="defens" stem="defens" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="TB" lemma="tb" stem="tb" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="bacteria" lemma="bacterium" stem="bacteria" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="long" lemma="long" stem="long" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="common" lemma="common" stem="common" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Europe" lemma="Europe" stem="europ" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="21" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="parts" lemma="part" stem="part" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="Africa" lemma="Africa" stem="africa" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="25" string="north" lemma="north" stem="north" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="Sahara" lemma="Sahara" stem="sahara" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="29" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="traditionally" lemma="traditionally" stem="tradition" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="rare" lemma="rare" stem="rare" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="sub-Saharan" lemma="sub-Saharan" stem="sub-saharan" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="36" string="Africa" lemma="Africa" stem="africa" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="37" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NN Stead)) (VP (VBD speculated) (SBAR (IN that) (S (NP (NNS whites)) (VP (VBP have) (VP (VBN evolved) (NP (JJR better) (NNS defenses)) (PP (IN against) (NP (NN TB))) (, ,) (SBAR (IN because) (S (NP (DT the) (NNS bacteria)) (VP (VP (VBZ has) (ADVP (RB long)) (VP (VBN been) (ADJP (JJ common)) (PP (IN in) (NP (NP (NNP Europe)) (CC and) (NP (NP (NNS parts)) (PP (IN of) (NP (NNP Africa) (NN north))) (PP (IN of) (NP (DT the) (NNP Sahara)))))))) (, ,) (CC but) (VP (VBZ is) (ADJP (RB traditionally) (JJ rare)) (PP (IN in) (NP (NNP sub-Saharan) (NNP Africa)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Stead" type="NP">
          <tokens>
            <token id="1" string="Stead" />
          </tokens>
        </chunking>
        <chunking id="2" string="the bacteria" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="bacteria" />
          </tokens>
        </chunking>
        <chunking id="3" string="is traditionally rare in sub-Saharan Africa" type="VP">
          <tokens>
            <token id="31" string="is" />
            <token id="32" string="traditionally" />
            <token id="33" string="rare" />
            <token id="34" string="in" />
            <token id="35" string="sub-Saharan" />
            <token id="36" string="Africa" />
          </tokens>
        </chunking>
        <chunking id="4" string="have evolved better defenses against TB , because the bacteria has long been common in Europe and parts of Africa north of the Sahara , but is traditionally rare in sub-Saharan Africa" type="VP">
          <tokens>
            <token id="5" string="have" />
            <token id="6" string="evolved" />
            <token id="7" string="better" />
            <token id="8" string="defenses" />
            <token id="9" string="against" />
            <token id="10" string="TB" />
            <token id="11" string="," />
            <token id="12" string="because" />
            <token id="13" string="the" />
            <token id="14" string="bacteria" />
            <token id="15" string="has" />
            <token id="16" string="long" />
            <token id="17" string="been" />
            <token id="18" string="common" />
            <token id="19" string="in" />
            <token id="20" string="Europe" />
            <token id="21" string="and" />
            <token id="22" string="parts" />
            <token id="23" string="of" />
            <token id="24" string="Africa" />
            <token id="25" string="north" />
            <token id="26" string="of" />
            <token id="27" string="the" />
            <token id="28" string="Sahara" />
            <token id="29" string="," />
            <token id="30" string="but" />
            <token id="31" string="is" />
            <token id="32" string="traditionally" />
            <token id="33" string="rare" />
            <token id="34" string="in" />
            <token id="35" string="sub-Saharan" />
            <token id="36" string="Africa" />
          </tokens>
        </chunking>
        <chunking id="5" string="because the bacteria has long been common in Europe and parts of Africa north of the Sahara , but is traditionally rare in sub-Saharan Africa" type="SBAR">
          <tokens>
            <token id="12" string="because" />
            <token id="13" string="the" />
            <token id="14" string="bacteria" />
            <token id="15" string="has" />
            <token id="16" string="long" />
            <token id="17" string="been" />
            <token id="18" string="common" />
            <token id="19" string="in" />
            <token id="20" string="Europe" />
            <token id="21" string="and" />
            <token id="22" string="parts" />
            <token id="23" string="of" />
            <token id="24" string="Africa" />
            <token id="25" string="north" />
            <token id="26" string="of" />
            <token id="27" string="the" />
            <token id="28" string="Sahara" />
            <token id="29" string="," />
            <token id="30" string="but" />
            <token id="31" string="is" />
            <token id="32" string="traditionally" />
            <token id="33" string="rare" />
            <token id="34" string="in" />
            <token id="35" string="sub-Saharan" />
            <token id="36" string="Africa" />
          </tokens>
        </chunking>
        <chunking id="6" string="Europe" type="NP">
          <tokens>
            <token id="20" string="Europe" />
          </tokens>
        </chunking>
        <chunking id="7" string="been common in Europe and parts of Africa north of the Sahara" type="VP">
          <tokens>
            <token id="17" string="been" />
            <token id="18" string="common" />
            <token id="19" string="in" />
            <token id="20" string="Europe" />
            <token id="21" string="and" />
            <token id="22" string="parts" />
            <token id="23" string="of" />
            <token id="24" string="Africa" />
            <token id="25" string="north" />
            <token id="26" string="of" />
            <token id="27" string="the" />
            <token id="28" string="Sahara" />
          </tokens>
        </chunking>
        <chunking id="8" string="parts" type="NP">
          <tokens>
            <token id="22" string="parts" />
          </tokens>
        </chunking>
        <chunking id="9" string="that whites have evolved better defenses against TB , because the bacteria has long been common in Europe and parts of Africa north of the Sahara , but is traditionally rare in sub-Saharan Africa" type="SBAR">
          <tokens>
            <token id="3" string="that" />
            <token id="4" string="whites" />
            <token id="5" string="have" />
            <token id="6" string="evolved" />
            <token id="7" string="better" />
            <token id="8" string="defenses" />
            <token id="9" string="against" />
            <token id="10" string="TB" />
            <token id="11" string="," />
            <token id="12" string="because" />
            <token id="13" string="the" />
            <token id="14" string="bacteria" />
            <token id="15" string="has" />
            <token id="16" string="long" />
            <token id="17" string="been" />
            <token id="18" string="common" />
            <token id="19" string="in" />
            <token id="20" string="Europe" />
            <token id="21" string="and" />
            <token id="22" string="parts" />
            <token id="23" string="of" />
            <token id="24" string="Africa" />
            <token id="25" string="north" />
            <token id="26" string="of" />
            <token id="27" string="the" />
            <token id="28" string="Sahara" />
            <token id="29" string="," />
            <token id="30" string="but" />
            <token id="31" string="is" />
            <token id="32" string="traditionally" />
            <token id="33" string="rare" />
            <token id="34" string="in" />
            <token id="35" string="sub-Saharan" />
            <token id="36" string="Africa" />
          </tokens>
        </chunking>
        <chunking id="10" string="traditionally rare" type="ADJP">
          <tokens>
            <token id="32" string="traditionally" />
            <token id="33" string="rare" />
          </tokens>
        </chunking>
        <chunking id="11" string="TB" type="NP">
          <tokens>
            <token id="10" string="TB" />
          </tokens>
        </chunking>
        <chunking id="12" string="has long been common in Europe and parts of Africa north of the Sahara" type="VP">
          <tokens>
            <token id="15" string="has" />
            <token id="16" string="long" />
            <token id="17" string="been" />
            <token id="18" string="common" />
            <token id="19" string="in" />
            <token id="20" string="Europe" />
            <token id="21" string="and" />
            <token id="22" string="parts" />
            <token id="23" string="of" />
            <token id="24" string="Africa" />
            <token id="25" string="north" />
            <token id="26" string="of" />
            <token id="27" string="the" />
            <token id="28" string="Sahara" />
          </tokens>
        </chunking>
        <chunking id="13" string="parts of Africa north of the Sahara" type="NP">
          <tokens>
            <token id="22" string="parts" />
            <token id="23" string="of" />
            <token id="24" string="Africa" />
            <token id="25" string="north" />
            <token id="26" string="of" />
            <token id="27" string="the" />
            <token id="28" string="Sahara" />
          </tokens>
        </chunking>
        <chunking id="14" string="Africa north" type="NP">
          <tokens>
            <token id="24" string="Africa" />
            <token id="25" string="north" />
          </tokens>
        </chunking>
        <chunking id="15" string="whites" type="NP">
          <tokens>
            <token id="4" string="whites" />
          </tokens>
        </chunking>
        <chunking id="16" string="sub-Saharan Africa" type="NP">
          <tokens>
            <token id="35" string="sub-Saharan" />
            <token id="36" string="Africa" />
          </tokens>
        </chunking>
        <chunking id="17" string="speculated that whites have evolved better defenses against TB , because the bacteria has long been common in Europe and parts of Africa north of the Sahara , but is traditionally rare in sub-Saharan Africa" type="VP">
          <tokens>
            <token id="2" string="speculated" />
            <token id="3" string="that" />
            <token id="4" string="whites" />
            <token id="5" string="have" />
            <token id="6" string="evolved" />
            <token id="7" string="better" />
            <token id="8" string="defenses" />
            <token id="9" string="against" />
            <token id="10" string="TB" />
            <token id="11" string="," />
            <token id="12" string="because" />
            <token id="13" string="the" />
            <token id="14" string="bacteria" />
            <token id="15" string="has" />
            <token id="16" string="long" />
            <token id="17" string="been" />
            <token id="18" string="common" />
            <token id="19" string="in" />
            <token id="20" string="Europe" />
            <token id="21" string="and" />
            <token id="22" string="parts" />
            <token id="23" string="of" />
            <token id="24" string="Africa" />
            <token id="25" string="north" />
            <token id="26" string="of" />
            <token id="27" string="the" />
            <token id="28" string="Sahara" />
            <token id="29" string="," />
            <token id="30" string="but" />
            <token id="31" string="is" />
            <token id="32" string="traditionally" />
            <token id="33" string="rare" />
            <token id="34" string="in" />
            <token id="35" string="sub-Saharan" />
            <token id="36" string="Africa" />
          </tokens>
        </chunking>
        <chunking id="18" string="better defenses" type="NP">
          <tokens>
            <token id="7" string="better" />
            <token id="8" string="defenses" />
          </tokens>
        </chunking>
        <chunking id="19" string="common" type="ADJP">
          <tokens>
            <token id="18" string="common" />
          </tokens>
        </chunking>
        <chunking id="20" string="Europe and parts of Africa north of the Sahara" type="NP">
          <tokens>
            <token id="20" string="Europe" />
            <token id="21" string="and" />
            <token id="22" string="parts" />
            <token id="23" string="of" />
            <token id="24" string="Africa" />
            <token id="25" string="north" />
            <token id="26" string="of" />
            <token id="27" string="the" />
            <token id="28" string="Sahara" />
          </tokens>
        </chunking>
        <chunking id="21" string="the Sahara" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="Sahara" />
          </tokens>
        </chunking>
        <chunking id="22" string="has long been common in Europe and parts of Africa north of the Sahara , but is traditionally rare in sub-Saharan Africa" type="VP">
          <tokens>
            <token id="15" string="has" />
            <token id="16" string="long" />
            <token id="17" string="been" />
            <token id="18" string="common" />
            <token id="19" string="in" />
            <token id="20" string="Europe" />
            <token id="21" string="and" />
            <token id="22" string="parts" />
            <token id="23" string="of" />
            <token id="24" string="Africa" />
            <token id="25" string="north" />
            <token id="26" string="of" />
            <token id="27" string="the" />
            <token id="28" string="Sahara" />
            <token id="29" string="," />
            <token id="30" string="but" />
            <token id="31" string="is" />
            <token id="32" string="traditionally" />
            <token id="33" string="rare" />
            <token id="34" string="in" />
            <token id="35" string="sub-Saharan" />
            <token id="36" string="Africa" />
          </tokens>
        </chunking>
        <chunking id="23" string="evolved better defenses against TB , because the bacteria has long been common in Europe and parts of Africa north of the Sahara , but is traditionally rare in sub-Saharan Africa" type="VP">
          <tokens>
            <token id="6" string="evolved" />
            <token id="7" string="better" />
            <token id="8" string="defenses" />
            <token id="9" string="against" />
            <token id="10" string="TB" />
            <token id="11" string="," />
            <token id="12" string="because" />
            <token id="13" string="the" />
            <token id="14" string="bacteria" />
            <token id="15" string="has" />
            <token id="16" string="long" />
            <token id="17" string="been" />
            <token id="18" string="common" />
            <token id="19" string="in" />
            <token id="20" string="Europe" />
            <token id="21" string="and" />
            <token id="22" string="parts" />
            <token id="23" string="of" />
            <token id="24" string="Africa" />
            <token id="25" string="north" />
            <token id="26" string="of" />
            <token id="27" string="the" />
            <token id="28" string="Sahara" />
            <token id="29" string="," />
            <token id="30" string="but" />
            <token id="31" string="is" />
            <token id="32" string="traditionally" />
            <token id="33" string="rare" />
            <token id="34" string="in" />
            <token id="35" string="sub-Saharan" />
            <token id="36" string="Africa" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">speculated</governor>
          <dependent id="1">Stead</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">speculated</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">evolved</governor>
          <dependent id="3">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">evolved</governor>
          <dependent id="4">whites</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">evolved</governor>
          <dependent id="5">have</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">speculated</governor>
          <dependent id="6">evolved</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">defenses</governor>
          <dependent id="7">better</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">evolved</governor>
          <dependent id="8">defenses</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">TB</governor>
          <dependent id="9">against</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">evolved</governor>
          <dependent id="10">TB</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">common</governor>
          <dependent id="12">because</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">bacteria</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">common</governor>
          <dependent id="14">bacteria</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">common</governor>
          <dependent id="15">has</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">common</governor>
          <dependent id="16">long</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="18">common</governor>
          <dependent id="17">been</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="6">evolved</governor>
          <dependent id="18">common</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">Europe</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">common</governor>
          <dependent id="20">Europe</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="20">Europe</governor>
          <dependent id="21">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="20">Europe</governor>
          <dependent id="22">parts</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">north</governor>
          <dependent id="23">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">north</governor>
          <dependent id="24">Africa</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">parts</governor>
          <dependent id="25">north</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">Sahara</governor>
          <dependent id="26">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">Sahara</governor>
          <dependent id="27">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">parts</governor>
          <dependent id="28">Sahara</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="18">common</governor>
          <dependent id="30">but</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="33">rare</governor>
          <dependent id="31">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="33">rare</governor>
          <dependent id="32">traditionally</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">common</governor>
          <dependent id="33">rare</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">Africa</governor>
          <dependent id="34">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="36">Africa</governor>
          <dependent id="35">sub-Saharan</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">rare</governor>
          <dependent id="36">Africa</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Africa" type="LOCATION" score="0.0">
          <tokens>
            <token id="24" string="Africa" />
          </tokens>
        </entity>
        <entity id="2" string="Europe" type="LOCATION" score="0.0">
          <tokens>
            <token id="20" string="Europe" />
          </tokens>
        </entity>
        <entity id="3" string="Sahara" type="LOCATION" score="0.0">
          <tokens>
            <token id="28" string="Sahara" />
          </tokens>
        </entity>
        <entity id="4" string="TB" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="10" string="TB" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="28" has_coreference="true">
      <content>By contrast, blacks are genetically more resistant than whites to malaria, which is common in Africa.</content>
      <tokens>
        <token id="1" string="By" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="contrast" lemma="contrast" stem="contrast" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="blacks" lemma="black" stem="black" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="genetically" lemma="genetically" stem="genet" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="resistant" lemma="resistant" stem="resist" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="whites" lemma="whites" stem="white" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="malaria" lemma="malaria" stem="malaria" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="common" lemma="common" stem="common" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Africa" lemma="Africa" stem="africa" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN By) (NP (NN contrast))) (, ,) (NP (NNS blacks)) (VP (VBP are) (ADJP (ADJP (RB genetically) (RBR more) (JJ resistant) (PP (IN than) (NP (NNS whites)))) (PP (TO to) (NP (NP (NN malaria)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (ADJP (JJ common) (PP (IN in) (NP (NNP Africa))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="genetically more resistant than whites" type="ADJP">
          <tokens>
            <token id="6" string="genetically" />
            <token id="7" string="more" />
            <token id="8" string="resistant" />
            <token id="9" string="than" />
            <token id="10" string="whites" />
          </tokens>
        </chunking>
        <chunking id="2" string="whites" type="NP">
          <tokens>
            <token id="10" string="whites" />
          </tokens>
        </chunking>
        <chunking id="3" string="contrast" type="NP">
          <tokens>
            <token id="2" string="contrast" />
          </tokens>
        </chunking>
        <chunking id="4" string="are genetically more resistant than whites to malaria , which is common in Africa" type="VP">
          <tokens>
            <token id="5" string="are" />
            <token id="6" string="genetically" />
            <token id="7" string="more" />
            <token id="8" string="resistant" />
            <token id="9" string="than" />
            <token id="10" string="whites" />
            <token id="11" string="to" />
            <token id="12" string="malaria" />
            <token id="13" string="," />
            <token id="14" string="which" />
            <token id="15" string="is" />
            <token id="16" string="common" />
            <token id="17" string="in" />
            <token id="18" string="Africa" />
          </tokens>
        </chunking>
        <chunking id="5" string="Africa" type="NP">
          <tokens>
            <token id="18" string="Africa" />
          </tokens>
        </chunking>
        <chunking id="6" string="malaria , which is common in Africa" type="NP">
          <tokens>
            <token id="12" string="malaria" />
            <token id="13" string="," />
            <token id="14" string="which" />
            <token id="15" string="is" />
            <token id="16" string="common" />
            <token id="17" string="in" />
            <token id="18" string="Africa" />
          </tokens>
        </chunking>
        <chunking id="7" string="genetically more resistant than whites to malaria , which is common in Africa" type="ADJP">
          <tokens>
            <token id="6" string="genetically" />
            <token id="7" string="more" />
            <token id="8" string="resistant" />
            <token id="9" string="than" />
            <token id="10" string="whites" />
            <token id="11" string="to" />
            <token id="12" string="malaria" />
            <token id="13" string="," />
            <token id="14" string="which" />
            <token id="15" string="is" />
            <token id="16" string="common" />
            <token id="17" string="in" />
            <token id="18" string="Africa" />
          </tokens>
        </chunking>
        <chunking id="8" string="blacks" type="NP">
          <tokens>
            <token id="4" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="9" string="is common in Africa" type="VP">
          <tokens>
            <token id="15" string="is" />
            <token id="16" string="common" />
            <token id="17" string="in" />
            <token id="18" string="Africa" />
          </tokens>
        </chunking>
        <chunking id="10" string="common in Africa" type="ADJP">
          <tokens>
            <token id="16" string="common" />
            <token id="17" string="in" />
            <token id="18" string="Africa" />
          </tokens>
        </chunking>
        <chunking id="11" string="malaria" type="NP">
          <tokens>
            <token id="12" string="malaria" />
          </tokens>
        </chunking>
        <chunking id="12" string="which is common in Africa" type="SBAR">
          <tokens>
            <token id="14" string="which" />
            <token id="15" string="is" />
            <token id="16" string="common" />
            <token id="17" string="in" />
            <token id="18" string="Africa" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">contrast</governor>
          <dependent id="1">By</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">resistant</governor>
          <dependent id="2">contrast</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">resistant</governor>
          <dependent id="4">blacks</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">resistant</governor>
          <dependent id="5">are</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">resistant</governor>
          <dependent id="6">genetically</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">resistant</governor>
          <dependent id="7">more</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">resistant</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">whites</governor>
          <dependent id="9">than</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">resistant</governor>
          <dependent id="10">whites</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">malaria</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">resistant</governor>
          <dependent id="12">malaria</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">common</governor>
          <dependent id="14">which</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="16">common</governor>
          <dependent id="15">is</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="12">malaria</governor>
          <dependent id="16">common</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Africa</governor>
          <dependent id="17">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">common</governor>
          <dependent id="18">Africa</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Africa" type="LOCATION" score="0.0">
          <tokens>
            <token id="18" string="Africa" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="29" has_coreference="true">
      <content>In the other study, Dr. Alfred Crowle of Webb-Waring Lung Institute at the University of Colorado found differences in the resistance of germ-eating blood cells called macrophages.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="study" lemma="study" stem="studi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Dr." lemma="Dr." stem="dr." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="Alfred" lemma="Alfred" stem="alfred" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="8" string="Crowle" lemma="Crowle" stem="crowl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="Webb-Waring" lemma="Webb-Waring" stem="webb-war" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="11" string="Lung" lemma="lung" stem="lung" pos="NN" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="12" string="Institute" lemma="Institute" stem="institut" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="13" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="University" lemma="University" stem="univers" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="17" string="Colorado" lemma="Colorado" stem="colorado" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="18" string="found" lemma="find" stem="found" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="differences" lemma="difference" stem="differ" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="resistance" lemma="resistance" stem="resist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="germ-eating" lemma="germ-eating" stem="germ-eat" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="blood" lemma="blood" stem="blood" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="cells" lemma="cell" stem="cell" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="called" lemma="call" stem="call" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="28" string="macrophages" lemma="macrophage" stem="macrophag" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (DT the) (JJ other) (NN study))) (, ,) (NP (NP (NNP Dr.) (NNP Alfred) (NNP Crowle)) (PP (IN of) (NP (NP (NNP Webb-Waring) (NN Lung) (NNP Institute)) (PP (IN at) (NP (NP (DT the) (NNP University)) (PP (IN of) (NP (NNP Colorado)))))))) (VP (VBD found) (NP (NNS differences)) (PP (IN in) (NP (NP (DT the) (NN resistance)) (PP (IN of) (NP (NP (JJ germ-eating) (NN blood) (NNS cells)) (VP (VBN called) (NP (NNS macrophages)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Dr. Alfred Crowle of Webb-Waring Lung Institute at the University of Colorado" type="NP">
          <tokens>
            <token id="6" string="Dr." />
            <token id="7" string="Alfred" />
            <token id="8" string="Crowle" />
            <token id="9" string="of" />
            <token id="10" string="Webb-Waring" />
            <token id="11" string="Lung" />
            <token id="12" string="Institute" />
            <token id="13" string="at" />
            <token id="14" string="the" />
            <token id="15" string="University" />
            <token id="16" string="of" />
            <token id="17" string="Colorado" />
          </tokens>
        </chunking>
        <chunking id="2" string="the other study" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="other" />
            <token id="4" string="study" />
          </tokens>
        </chunking>
        <chunking id="3" string="differences" type="NP">
          <tokens>
            <token id="19" string="differences" />
          </tokens>
        </chunking>
        <chunking id="4" string="called macrophages" type="VP">
          <tokens>
            <token id="27" string="called" />
            <token id="28" string="macrophages" />
          </tokens>
        </chunking>
        <chunking id="5" string="the University of Colorado" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="University" />
            <token id="16" string="of" />
            <token id="17" string="Colorado" />
          </tokens>
        </chunking>
        <chunking id="6" string="germ-eating blood cells" type="NP">
          <tokens>
            <token id="24" string="germ-eating" />
            <token id="25" string="blood" />
            <token id="26" string="cells" />
          </tokens>
        </chunking>
        <chunking id="7" string="Dr. Alfred Crowle" type="NP">
          <tokens>
            <token id="6" string="Dr." />
            <token id="7" string="Alfred" />
            <token id="8" string="Crowle" />
          </tokens>
        </chunking>
        <chunking id="8" string="Webb-Waring Lung Institute at the University of Colorado" type="NP">
          <tokens>
            <token id="10" string="Webb-Waring" />
            <token id="11" string="Lung" />
            <token id="12" string="Institute" />
            <token id="13" string="at" />
            <token id="14" string="the" />
            <token id="15" string="University" />
            <token id="16" string="of" />
            <token id="17" string="Colorado" />
          </tokens>
        </chunking>
        <chunking id="9" string="the resistance of germ-eating blood cells called macrophages" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="resistance" />
            <token id="23" string="of" />
            <token id="24" string="germ-eating" />
            <token id="25" string="blood" />
            <token id="26" string="cells" />
            <token id="27" string="called" />
            <token id="28" string="macrophages" />
          </tokens>
        </chunking>
        <chunking id="10" string="germ-eating blood cells called macrophages" type="NP">
          <tokens>
            <token id="24" string="germ-eating" />
            <token id="25" string="blood" />
            <token id="26" string="cells" />
            <token id="27" string="called" />
            <token id="28" string="macrophages" />
          </tokens>
        </chunking>
        <chunking id="11" string="found differences in the resistance of germ-eating blood cells called macrophages" type="VP">
          <tokens>
            <token id="18" string="found" />
            <token id="19" string="differences" />
            <token id="20" string="in" />
            <token id="21" string="the" />
            <token id="22" string="resistance" />
            <token id="23" string="of" />
            <token id="24" string="germ-eating" />
            <token id="25" string="blood" />
            <token id="26" string="cells" />
            <token id="27" string="called" />
            <token id="28" string="macrophages" />
          </tokens>
        </chunking>
        <chunking id="12" string="Colorado" type="NP">
          <tokens>
            <token id="17" string="Colorado" />
          </tokens>
        </chunking>
        <chunking id="13" string="the resistance" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="resistance" />
          </tokens>
        </chunking>
        <chunking id="14" string="Webb-Waring Lung Institute" type="NP">
          <tokens>
            <token id="10" string="Webb-Waring" />
            <token id="11" string="Lung" />
            <token id="12" string="Institute" />
          </tokens>
        </chunking>
        <chunking id="15" string="the University" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="University" />
          </tokens>
        </chunking>
        <chunking id="16" string="macrophages" type="NP">
          <tokens>
            <token id="28" string="macrophages" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">study</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">study</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">study</governor>
          <dependent id="3">other</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">found</governor>
          <dependent id="4">study</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Crowle</governor>
          <dependent id="6">Dr.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Crowle</governor>
          <dependent id="7">Alfred</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">found</governor>
          <dependent id="8">Crowle</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Institute</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Institute</governor>
          <dependent id="10">Webb-Waring</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Institute</governor>
          <dependent id="11">Lung</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">Crowle</governor>
          <dependent id="12">Institute</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">University</governor>
          <dependent id="13">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">University</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">Institute</governor>
          <dependent id="15">University</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">Colorado</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">University</governor>
          <dependent id="17">Colorado</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">found</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">found</governor>
          <dependent id="19">differences</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">resistance</governor>
          <dependent id="20">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">resistance</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">found</governor>
          <dependent id="22">resistance</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">cells</governor>
          <dependent id="23">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">cells</governor>
          <dependent id="24">germ-eating</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">cells</governor>
          <dependent id="25">blood</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">resistance</governor>
          <dependent id="26">cells</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="26">cells</governor>
          <dependent id="27">called</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="27">called</governor>
          <dependent id="28">macrophages</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="University of Colorado" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="15" string="University" />
            <token id="16" string="of" />
            <token id="17" string="Colorado" />
          </tokens>
        </entity>
        <entity id="2" string="Webb-Waring Lung Institute" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="10" string="Webb-Waring" />
            <token id="11" string="Lung" />
            <token id="12" string="Institute" />
          </tokens>
        </entity>
        <entity id="3" string="Alfred Crowle" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Alfred" />
            <token id="8" string="Crowle" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="30" has_coreference="true">
      <content>In blacks, these cells are more likely to harbor TB infections.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="blacks" lemma="black" stem="black" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="these" lemma="these" stem="these" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="cells" lemma="cell" stem="cell" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="likely" lemma="likely" stem="like" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="harbor" lemma="harbor" stem="harbor" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="TB" lemma="tb" stem="tb" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="12" string="infections" lemma="infection" stem="infect" pos="NNS" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (NNS blacks))) (, ,) (NP (DT these) (NNS cells)) (VP (VBP are) (ADJP (RBR more) (JJ likely) (S (VP (TO to) (VP (VB harbor) (NP (NN TB) (NNS infections))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="these cells" type="NP">
          <tokens>
            <token id="4" string="these" />
            <token id="5" string="cells" />
          </tokens>
        </chunking>
        <chunking id="2" string="to harbor TB infections" type="VP">
          <tokens>
            <token id="9" string="to" />
            <token id="10" string="harbor" />
            <token id="11" string="TB" />
            <token id="12" string="infections" />
          </tokens>
        </chunking>
        <chunking id="3" string="more likely to harbor TB infections" type="ADJP">
          <tokens>
            <token id="7" string="more" />
            <token id="8" string="likely" />
            <token id="9" string="to" />
            <token id="10" string="harbor" />
            <token id="11" string="TB" />
            <token id="12" string="infections" />
          </tokens>
        </chunking>
        <chunking id="4" string="TB infections" type="NP">
          <tokens>
            <token id="11" string="TB" />
            <token id="12" string="infections" />
          </tokens>
        </chunking>
        <chunking id="5" string="blacks" type="NP">
          <tokens>
            <token id="2" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="6" string="are more likely to harbor TB infections" type="VP">
          <tokens>
            <token id="6" string="are" />
            <token id="7" string="more" />
            <token id="8" string="likely" />
            <token id="9" string="to" />
            <token id="10" string="harbor" />
            <token id="11" string="TB" />
            <token id="12" string="infections" />
          </tokens>
        </chunking>
        <chunking id="7" string="harbor TB infections" type="VP">
          <tokens>
            <token id="10" string="harbor" />
            <token id="11" string="TB" />
            <token id="12" string="infections" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">blacks</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">likely</governor>
          <dependent id="2">blacks</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">cells</governor>
          <dependent id="4">these</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">likely</governor>
          <dependent id="5">cells</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">likely</governor>
          <dependent id="6">are</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">likely</governor>
          <dependent id="7">more</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">likely</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">harbor</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">likely</governor>
          <dependent id="10">harbor</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">infections</governor>
          <dependent id="11">TB</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">harbor</governor>
          <dependent id="12">infections</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="TB infections" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="11" string="TB" />
            <token id="12" string="infections" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="31" has_coreference="true">
      <content>``This helps explain why black people are more susceptible to tuberculosis than are white people,&amp;apost;&amp;apost; said Crowle.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="This" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="helps" lemma="help" stem="help" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="explain" lemma="explain" stem="explain" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="why" lemma="why" stem="why" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="susceptible" lemma="susceptible" stem="suscept" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="tuberculosis" lemma="tuberculosis" stem="tuberculosi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="white" lemma="white" stem="white" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="Crowle" lemma="Crowle" stem="crowl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (DT This)) (VP (VBZ helps) (VP (VB explain) (SBAR (WHADVP (WRB why)) (S (NP (JJ black) (NNS people)) (VP (VBP are) (ADJP (ADJP (RBR more) (JJ susceptible) (PP (TO to) (NP (NN tuberculosis)))) (SBAR (IN than) (S (VP (VBP are) (NP (JJ white) (NNS people)))))))))))) (, ,) ('' '') (VP (VBD said)) (NP (NNP Crowle)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Crowle" type="NP">
          <tokens>
            <token id="20" string="Crowle" />
          </tokens>
        </chunking>
        <chunking id="2" string="black people" type="NP">
          <tokens>
            <token id="6" string="black" />
            <token id="7" string="people" />
          </tokens>
        </chunking>
        <chunking id="3" string="explain why black people are more susceptible to tuberculosis than are white people" type="VP">
          <tokens>
            <token id="4" string="explain" />
            <token id="5" string="why" />
            <token id="6" string="black" />
            <token id="7" string="people" />
            <token id="8" string="are" />
            <token id="9" string="more" />
            <token id="10" string="susceptible" />
            <token id="11" string="to" />
            <token id="12" string="tuberculosis" />
            <token id="13" string="than" />
            <token id="14" string="are" />
            <token id="15" string="white" />
            <token id="16" string="people" />
          </tokens>
        </chunking>
        <chunking id="4" string="tuberculosis" type="NP">
          <tokens>
            <token id="12" string="tuberculosis" />
          </tokens>
        </chunking>
        <chunking id="5" string="why black people are more susceptible to tuberculosis than are white people" type="SBAR">
          <tokens>
            <token id="5" string="why" />
            <token id="6" string="black" />
            <token id="7" string="people" />
            <token id="8" string="are" />
            <token id="9" string="more" />
            <token id="10" string="susceptible" />
            <token id="11" string="to" />
            <token id="12" string="tuberculosis" />
            <token id="13" string="than" />
            <token id="14" string="are" />
            <token id="15" string="white" />
            <token id="16" string="people" />
          </tokens>
        </chunking>
        <chunking id="6" string="why" type="WHADVP">
          <tokens>
            <token id="5" string="why" />
          </tokens>
        </chunking>
        <chunking id="7" string="are white people" type="VP">
          <tokens>
            <token id="14" string="are" />
            <token id="15" string="white" />
            <token id="16" string="people" />
          </tokens>
        </chunking>
        <chunking id="8" string="are more susceptible to tuberculosis than are white people" type="VP">
          <tokens>
            <token id="8" string="are" />
            <token id="9" string="more" />
            <token id="10" string="susceptible" />
            <token id="11" string="to" />
            <token id="12" string="tuberculosis" />
            <token id="13" string="than" />
            <token id="14" string="are" />
            <token id="15" string="white" />
            <token id="16" string="people" />
          </tokens>
        </chunking>
        <chunking id="9" string="more susceptible to tuberculosis" type="ADJP">
          <tokens>
            <token id="9" string="more" />
            <token id="10" string="susceptible" />
            <token id="11" string="to" />
            <token id="12" string="tuberculosis" />
          </tokens>
        </chunking>
        <chunking id="10" string="than are white people" type="SBAR">
          <tokens>
            <token id="13" string="than" />
            <token id="14" string="are" />
            <token id="15" string="white" />
            <token id="16" string="people" />
          </tokens>
        </chunking>
        <chunking id="11" string="more susceptible to tuberculosis than are white people" type="ADJP">
          <tokens>
            <token id="9" string="more" />
            <token id="10" string="susceptible" />
            <token id="11" string="to" />
            <token id="12" string="tuberculosis" />
            <token id="13" string="than" />
            <token id="14" string="are" />
            <token id="15" string="white" />
            <token id="16" string="people" />
          </tokens>
        </chunking>
        <chunking id="12" string="helps explain why black people are more susceptible to tuberculosis than are white people" type="VP">
          <tokens>
            <token id="3" string="helps" />
            <token id="4" string="explain" />
            <token id="5" string="why" />
            <token id="6" string="black" />
            <token id="7" string="people" />
            <token id="8" string="are" />
            <token id="9" string="more" />
            <token id="10" string="susceptible" />
            <token id="11" string="to" />
            <token id="12" string="tuberculosis" />
            <token id="13" string="than" />
            <token id="14" string="are" />
            <token id="15" string="white" />
            <token id="16" string="people" />
          </tokens>
        </chunking>
        <chunking id="13" string="This" type="NP">
          <tokens>
            <token id="2" string="This" />
          </tokens>
        </chunking>
        <chunking id="14" string="white people" type="NP">
          <tokens>
            <token id="15" string="white" />
            <token id="16" string="people" />
          </tokens>
        </chunking>
        <chunking id="15" string="said" type="VP">
          <tokens>
            <token id="19" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">helps</governor>
          <dependent id="2">This</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">said</governor>
          <dependent id="3">helps</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">helps</governor>
          <dependent id="4">explain</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">susceptible</governor>
          <dependent id="5">why</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">people</governor>
          <dependent id="6">black</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">susceptible</governor>
          <dependent id="7">people</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="10">susceptible</governor>
          <dependent id="8">are</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">susceptible</governor>
          <dependent id="9">more</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">explain</governor>
          <dependent id="10">susceptible</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">tuberculosis</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">susceptible</governor>
          <dependent id="12">tuberculosis</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">people</governor>
          <dependent id="13">than</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="16">people</governor>
          <dependent id="14">are</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">people</governor>
          <dependent id="15">white</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">susceptible</governor>
          <dependent id="16">people</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="19">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">said</governor>
          <dependent id="20">Crowle</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Crowle" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="Crowle" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="32" has_coreference="false">
      <content>At the turn of the century, TB was the nation&amp;apost;s leading cause of death.</content>
      <tokens>
        <token id="1" string="At" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="turn" lemma="turn" stem="turn" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string="century" lemma="century" stem="centuri" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="TB" lemma="tb" stem="tb" pos="NN" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="9" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="nation" lemma="nation" stem="nation" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="leading" lemma="lead" stem="lead" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="cause" lemma="cause" stem="caus" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="death" lemma="death" stem="death" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN At) (NP (NP (DT the) (NN turn)) (PP (IN of) (NP (DT the) (NN century))))) (, ,) (NP (NN TB)) (VP (VBD was) (NP (NP (NP (DT the) (NN nation) (POS 's)) (VBG leading) (NN cause)) (PP (IN of) (NP (NN death))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the nation 's leading cause" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="nation" />
            <token id="12" string="'s" />
            <token id="13" string="leading" />
            <token id="14" string="cause" />
          </tokens>
        </chunking>
        <chunking id="2" string="the nation 's leading cause of death" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="nation" />
            <token id="12" string="'s" />
            <token id="13" string="leading" />
            <token id="14" string="cause" />
            <token id="15" string="of" />
            <token id="16" string="death" />
          </tokens>
        </chunking>
        <chunking id="3" string="death" type="NP">
          <tokens>
            <token id="16" string="death" />
          </tokens>
        </chunking>
        <chunking id="4" string="the turn of the century" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="turn" />
            <token id="4" string="of" />
            <token id="5" string="the" />
            <token id="6" string="century" />
          </tokens>
        </chunking>
        <chunking id="5" string="the century" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="century" />
          </tokens>
        </chunking>
        <chunking id="6" string="the turn" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="turn" />
          </tokens>
        </chunking>
        <chunking id="7" string="was the nation 's leading cause of death" type="VP">
          <tokens>
            <token id="9" string="was" />
            <token id="10" string="the" />
            <token id="11" string="nation" />
            <token id="12" string="'s" />
            <token id="13" string="leading" />
            <token id="14" string="cause" />
            <token id="15" string="of" />
            <token id="16" string="death" />
          </tokens>
        </chunking>
        <chunking id="8" string="TB" type="NP">
          <tokens>
            <token id="8" string="TB" />
          </tokens>
        </chunking>
        <chunking id="9" string="the nation 's" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="nation" />
            <token id="12" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">turn</governor>
          <dependent id="1">At</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">turn</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">cause</governor>
          <dependent id="3">turn</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">century</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">century</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">turn</governor>
          <dependent id="6">century</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">cause</governor>
          <dependent id="8">TB</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">cause</governor>
          <dependent id="9">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">nation</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">cause</governor>
          <dependent id="11">nation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">nation</governor>
          <dependent id="12">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">cause</governor>
          <dependent id="13">leading</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">cause</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">death</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">cause</governor>
          <dependent id="16">death</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="the century" type="DATE" score="0.0">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="century" />
          </tokens>
        </entity>
        <entity id="2" string="TB" type="LOCATION" score="0.0">
          <tokens>
            <token id="8" string="TB" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="33" has_coreference="false">
      <content>The number of cases fell steadily in recent decades until 1984.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="number" lemma="number" stem="number" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="cases" lemma="case" stem="case" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="fell" lemma="fall" stem="fell" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="steadily" lemma="steadily" stem="steadili" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="recent" lemma="recent" stem="recent" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="9" string="decades" lemma="decade" stem="decad" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="10" string="until" lemma="until" stem="until" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="1984" lemma="1984" stem="1984" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NN number)) (PP (IN of) (NP (NNS cases)))) (VP (VBD fell) (ADVP (RB steadily)) (PP (IN in) (NP (JJ recent) (NNS decades))) (PP (IN until) (NP (CD 1984)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="cases" type="NP">
          <tokens>
            <token id="4" string="cases" />
          </tokens>
        </chunking>
        <chunking id="2" string="The number of cases" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="number" />
            <token id="3" string="of" />
            <token id="4" string="cases" />
          </tokens>
        </chunking>
        <chunking id="3" string="1984" type="NP">
          <tokens>
            <token id="11" string="1984" />
          </tokens>
        </chunking>
        <chunking id="4" string="The number" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="number" />
          </tokens>
        </chunking>
        <chunking id="5" string="fell steadily in recent decades until 1984" type="VP">
          <tokens>
            <token id="5" string="fell" />
            <token id="6" string="steadily" />
            <token id="7" string="in" />
            <token id="8" string="recent" />
            <token id="9" string="decades" />
            <token id="10" string="until" />
            <token id="11" string="1984" />
          </tokens>
        </chunking>
        <chunking id="6" string="recent decades" type="NP">
          <tokens>
            <token id="8" string="recent" />
            <token id="9" string="decades" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">number</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">fell</governor>
          <dependent id="2">number</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">cases</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">number</governor>
          <dependent id="4">cases</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">fell</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">fell</governor>
          <dependent id="6">steadily</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">decades</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">decades</governor>
          <dependent id="8">recent</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">fell</governor>
          <dependent id="9">decades</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">1984</governor>
          <dependent id="10">until</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">fell</governor>
          <dependent id="11">1984</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1984" type="DATE" score="0.0">
          <tokens>
            <token id="11" string="1984" />
          </tokens>
        </entity>
        <entity id="2" string="recent decades" type="DURATION" score="0.0">
          <tokens>
            <token id="8" string="recent" />
            <token id="9" string="decades" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="34" has_coreference="true">
      <content>Experts believe the decline has leveled off in part because of the emergence of the AIDS virus, which weaken the body&amp;apost;s resistance to TB bacteria.</content>
      <tokens>
        <token id="1" string="Experts" lemma="expert" stem="expert" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="believe" lemma="believe" stem="believ" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="decline" lemma="decline" stem="declin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="leveled" lemma="level" stem="level" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="off" lemma="off" stem="off" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="part" lemma="part" stem="part" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="emergence" lemma="emergence" stem="emerg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="AIDS" lemma="aids" stem="aids" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="17" string="virus" lemma="virus" stem="viru" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="weaken" lemma="weaken" stem="weaken" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="body" lemma="body" stem="bodi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="resistance" lemma="resistance" stem="resist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="TB" lemma="tb" stem="tb" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="true" />
        <token id="27" string="bacteria" lemma="bacterium" stem="bacteria" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNS Experts)) (VP (VBP believe) (SBAR (S (NP (DT the) (NN decline)) (VP (VBZ has) (VP (VBN leveled) (PRT (RP off)) (PP (IN in) (NP (NN part))) (PP (IN because) (IN of) (NP (NP (DT the) (NN emergence)) (PP (IN of) (NP (NP (DT the) (NN AIDS) (NN virus)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBP weaken) (NP (NP (DT the) (NN body) (POS 's)) (NN resistance)) (PP (TO to) (NP (NN TB) (NNS bacteria))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="has leveled off in part because of the emergence of the AIDS virus , which weaken the body 's resistance to TB bacteria" type="VP">
          <tokens>
            <token id="5" string="has" />
            <token id="6" string="leveled" />
            <token id="7" string="off" />
            <token id="8" string="in" />
            <token id="9" string="part" />
            <token id="10" string="because" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="emergence" />
            <token id="14" string="of" />
            <token id="15" string="the" />
            <token id="16" string="AIDS" />
            <token id="17" string="virus" />
            <token id="18" string="," />
            <token id="19" string="which" />
            <token id="20" string="weaken" />
            <token id="21" string="the" />
            <token id="22" string="body" />
            <token id="23" string="'s" />
            <token id="24" string="resistance" />
            <token id="25" string="to" />
            <token id="26" string="TB" />
            <token id="27" string="bacteria" />
          </tokens>
        </chunking>
        <chunking id="2" string="leveled off in part because of the emergence of the AIDS virus , which weaken the body 's resistance to TB bacteria" type="VP">
          <tokens>
            <token id="6" string="leveled" />
            <token id="7" string="off" />
            <token id="8" string="in" />
            <token id="9" string="part" />
            <token id="10" string="because" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="emergence" />
            <token id="14" string="of" />
            <token id="15" string="the" />
            <token id="16" string="AIDS" />
            <token id="17" string="virus" />
            <token id="18" string="," />
            <token id="19" string="which" />
            <token id="20" string="weaken" />
            <token id="21" string="the" />
            <token id="22" string="body" />
            <token id="23" string="'s" />
            <token id="24" string="resistance" />
            <token id="25" string="to" />
            <token id="26" string="TB" />
            <token id="27" string="bacteria" />
          </tokens>
        </chunking>
        <chunking id="3" string="Experts" type="NP">
          <tokens>
            <token id="1" string="Experts" />
          </tokens>
        </chunking>
        <chunking id="4" string="part" type="NP">
          <tokens>
            <token id="9" string="part" />
          </tokens>
        </chunking>
        <chunking id="5" string="the emergence" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="emergence" />
          </tokens>
        </chunking>
        <chunking id="6" string="the body 's resistance" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="body" />
            <token id="23" string="'s" />
            <token id="24" string="resistance" />
          </tokens>
        </chunking>
        <chunking id="7" string="believe the decline has leveled off in part because of the emergence of the AIDS virus , which weaken the body 's resistance to TB bacteria" type="VP">
          <tokens>
            <token id="2" string="believe" />
            <token id="3" string="the" />
            <token id="4" string="decline" />
            <token id="5" string="has" />
            <token id="6" string="leveled" />
            <token id="7" string="off" />
            <token id="8" string="in" />
            <token id="9" string="part" />
            <token id="10" string="because" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="emergence" />
            <token id="14" string="of" />
            <token id="15" string="the" />
            <token id="16" string="AIDS" />
            <token id="17" string="virus" />
            <token id="18" string="," />
            <token id="19" string="which" />
            <token id="20" string="weaken" />
            <token id="21" string="the" />
            <token id="22" string="body" />
            <token id="23" string="'s" />
            <token id="24" string="resistance" />
            <token id="25" string="to" />
            <token id="26" string="TB" />
            <token id="27" string="bacteria" />
          </tokens>
        </chunking>
        <chunking id="8" string="weaken the body 's resistance to TB bacteria" type="VP">
          <tokens>
            <token id="20" string="weaken" />
            <token id="21" string="the" />
            <token id="22" string="body" />
            <token id="23" string="'s" />
            <token id="24" string="resistance" />
            <token id="25" string="to" />
            <token id="26" string="TB" />
            <token id="27" string="bacteria" />
          </tokens>
        </chunking>
        <chunking id="9" string="the decline" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="decline" />
          </tokens>
        </chunking>
        <chunking id="10" string="the decline has leveled off in part because of the emergence of the AIDS virus , which weaken the body 's resistance to TB bacteria" type="SBAR">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="decline" />
            <token id="5" string="has" />
            <token id="6" string="leveled" />
            <token id="7" string="off" />
            <token id="8" string="in" />
            <token id="9" string="part" />
            <token id="10" string="because" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="emergence" />
            <token id="14" string="of" />
            <token id="15" string="the" />
            <token id="16" string="AIDS" />
            <token id="17" string="virus" />
            <token id="18" string="," />
            <token id="19" string="which" />
            <token id="20" string="weaken" />
            <token id="21" string="the" />
            <token id="22" string="body" />
            <token id="23" string="'s" />
            <token id="24" string="resistance" />
            <token id="25" string="to" />
            <token id="26" string="TB" />
            <token id="27" string="bacteria" />
          </tokens>
        </chunking>
        <chunking id="11" string="the AIDS virus , which weaken the body 's resistance to TB bacteria" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="AIDS" />
            <token id="17" string="virus" />
            <token id="18" string="," />
            <token id="19" string="which" />
            <token id="20" string="weaken" />
            <token id="21" string="the" />
            <token id="22" string="body" />
            <token id="23" string="'s" />
            <token id="24" string="resistance" />
            <token id="25" string="to" />
            <token id="26" string="TB" />
            <token id="27" string="bacteria" />
          </tokens>
        </chunking>
        <chunking id="12" string="the AIDS virus" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="AIDS" />
            <token id="17" string="virus" />
          </tokens>
        </chunking>
        <chunking id="13" string="which weaken the body 's resistance to TB bacteria" type="SBAR">
          <tokens>
            <token id="19" string="which" />
            <token id="20" string="weaken" />
            <token id="21" string="the" />
            <token id="22" string="body" />
            <token id="23" string="'s" />
            <token id="24" string="resistance" />
            <token id="25" string="to" />
            <token id="26" string="TB" />
            <token id="27" string="bacteria" />
          </tokens>
        </chunking>
        <chunking id="14" string="the emergence of the AIDS virus , which weaken the body 's resistance to TB bacteria" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="emergence" />
            <token id="14" string="of" />
            <token id="15" string="the" />
            <token id="16" string="AIDS" />
            <token id="17" string="virus" />
            <token id="18" string="," />
            <token id="19" string="which" />
            <token id="20" string="weaken" />
            <token id="21" string="the" />
            <token id="22" string="body" />
            <token id="23" string="'s" />
            <token id="24" string="resistance" />
            <token id="25" string="to" />
            <token id="26" string="TB" />
            <token id="27" string="bacteria" />
          </tokens>
        </chunking>
        <chunking id="15" string="the body 's" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="body" />
            <token id="23" string="'s" />
          </tokens>
        </chunking>
        <chunking id="16" string="TB bacteria" type="NP">
          <tokens>
            <token id="26" string="TB" />
            <token id="27" string="bacteria" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">believe</governor>
          <dependent id="1">Experts</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">believe</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">decline</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">leveled</governor>
          <dependent id="4">decline</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">leveled</governor>
          <dependent id="5">has</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">believe</governor>
          <dependent id="6">leveled</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="6">leveled</governor>
          <dependent id="7">off</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">part</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">leveled</governor>
          <dependent id="9">part</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">emergence</governor>
          <dependent id="10">because</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="10">because</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">emergence</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">leveled</governor>
          <dependent id="13">emergence</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">virus</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">virus</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">virus</governor>
          <dependent id="16">AIDS</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">emergence</governor>
          <dependent id="17">virus</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">weaken</governor>
          <dependent id="19">which</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="17">virus</governor>
          <dependent id="20">weaken</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">body</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="24">resistance</governor>
          <dependent id="22">body</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">body</governor>
          <dependent id="23">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">weaken</governor>
          <dependent id="24">resistance</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">bacteria</governor>
          <dependent id="25">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">bacteria</governor>
          <dependent id="26">TB</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">weaken</governor>
          <dependent id="27">bacteria</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="AIDS" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="16" string="AIDS" />
          </tokens>
        </entity>
        <entity id="2" string="TB" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="26" string="TB" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="35" has_coreference="true">
      <content>Others possible factors include homelessness and immigration of people from areas where the disease is still common.</content>
      <tokens>
        <token id="1" string="Others" lemma="other" stem="other" pos="NNS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="possible" lemma="possible" stem="possibl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="factors" lemma="factor" stem="factor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="include" lemma="include" stem="includ" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="homelessness" lemma="homelessness" stem="homeless" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="immigration" lemma="immigration" stem="immigr" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="areas" lemma="area" stem="area" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="15" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="still" lemma="still" stem="still" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="common" lemma="common" stem="common" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNS Others)) (NP (JJ possible) (NNS factors))) (VP (VBP include) (NP (NP (NN homelessness) (CC and) (NN immigration)) (PP (IN of) (NP (NNS people)))) (PP (IN from) (NP (NP (NNS areas)) (SBAR (WHADVP (WRB where)) (S (NP (DT the) (NN disease)) (VP (VBZ is) (ADVP (RB still)) (ADJP (JJ common)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Others" type="NP">
          <tokens>
            <token id="1" string="Others" />
          </tokens>
        </chunking>
        <chunking id="2" string="homelessness and immigration of people" type="NP">
          <tokens>
            <token id="5" string="homelessness" />
            <token id="6" string="and" />
            <token id="7" string="immigration" />
            <token id="8" string="of" />
            <token id="9" string="people" />
          </tokens>
        </chunking>
        <chunking id="3" string="areas" type="NP">
          <tokens>
            <token id="11" string="areas" />
          </tokens>
        </chunking>
        <chunking id="4" string="is still common" type="VP">
          <tokens>
            <token id="15" string="is" />
            <token id="16" string="still" />
            <token id="17" string="common" />
          </tokens>
        </chunking>
        <chunking id="5" string="people" type="NP">
          <tokens>
            <token id="9" string="people" />
          </tokens>
        </chunking>
        <chunking id="6" string="include homelessness and immigration of people from areas where the disease is still common" type="VP">
          <tokens>
            <token id="4" string="include" />
            <token id="5" string="homelessness" />
            <token id="6" string="and" />
            <token id="7" string="immigration" />
            <token id="8" string="of" />
            <token id="9" string="people" />
            <token id="10" string="from" />
            <token id="11" string="areas" />
            <token id="12" string="where" />
            <token id="13" string="the" />
            <token id="14" string="disease" />
            <token id="15" string="is" />
            <token id="16" string="still" />
            <token id="17" string="common" />
          </tokens>
        </chunking>
        <chunking id="7" string="the disease" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="disease" />
          </tokens>
        </chunking>
        <chunking id="8" string="where the disease is still common" type="SBAR">
          <tokens>
            <token id="12" string="where" />
            <token id="13" string="the" />
            <token id="14" string="disease" />
            <token id="15" string="is" />
            <token id="16" string="still" />
            <token id="17" string="common" />
          </tokens>
        </chunking>
        <chunking id="9" string="possible factors" type="NP">
          <tokens>
            <token id="2" string="possible" />
            <token id="3" string="factors" />
          </tokens>
        </chunking>
        <chunking id="10" string="homelessness and immigration" type="NP">
          <tokens>
            <token id="5" string="homelessness" />
            <token id="6" string="and" />
            <token id="7" string="immigration" />
          </tokens>
        </chunking>
        <chunking id="11" string="areas where the disease is still common" type="NP">
          <tokens>
            <token id="11" string="areas" />
            <token id="12" string="where" />
            <token id="13" string="the" />
            <token id="14" string="disease" />
            <token id="15" string="is" />
            <token id="16" string="still" />
            <token id="17" string="common" />
          </tokens>
        </chunking>
        <chunking id="12" string="common" type="ADJP">
          <tokens>
            <token id="17" string="common" />
          </tokens>
        </chunking>
        <chunking id="13" string="where" type="WHADVP">
          <tokens>
            <token id="12" string="where" />
          </tokens>
        </chunking>
        <chunking id="14" string="Others possible factors" type="NP">
          <tokens>
            <token id="1" string="Others" />
            <token id="2" string="possible" />
            <token id="3" string="factors" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">include</governor>
          <dependent id="1">Others</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">factors</governor>
          <dependent id="2">possible</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="1">Others</governor>
          <dependent id="3">factors</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">include</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">include</governor>
          <dependent id="5">homelessness</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">homelessness</governor>
          <dependent id="6">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">homelessness</governor>
          <dependent id="7">immigration</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">people</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">homelessness</governor>
          <dependent id="9">people</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">areas</governor>
          <dependent id="10">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">include</governor>
          <dependent id="11">areas</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">common</governor>
          <dependent id="12">where</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">disease</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">common</governor>
          <dependent id="14">disease</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="17">common</governor>
          <dependent id="15">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">common</governor>
          <dependent id="16">still</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="11">areas</governor>
          <dependent id="17">common</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="14" string="disease" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="2" type="PROPER">
      <referenced ids_tokens="11-12" string="this one" id_sentence="10" />
      <mentions>
        <mention ids_tokens="13" string="one" id_sentence="1" />
      </mentions>
    </coreference>
    <coreference id="5" type="NOMINAL">
      <referenced ids_tokens="11-12" string="black people" id_sentence="2" />
      <mentions>
        <mention ids_tokens="13" string="people" id_sentence="12" />
        <mention ids_tokens="9" string="people" id_sentence="35" />
      </mentions>
    </coreference>
    <coreference id="6" type="NOMINAL">
      <referenced ids_tokens="23-24-25" string="the TB bacteria" id_sentence="2" />
      <mentions>
        <mention ids_tokens="21-22" string="the bacteria" id_sentence="17" />
        <mention ids_tokens="19-35" string="the TB bacteria , which could help explain why blacks seem to be more prone to tuberculosis" id_sentence="18" />
        <mention ids_tokens="12-13" string="the bacteria" id_sentence="21" />
        <mention ids_tokens="18-19" string="the bacteria" id_sentence="25" />
        <mention ids_tokens="13-14" string="the bacteria" id_sentence="27" />
        <mention ids_tokens="26-27" string="TB bacteria" id_sentence="34" />
      </mentions>
    </coreference>
    <coreference id="7" type="NOMINAL">
      <referenced ids_tokens="8" string="blacks" id_sentence="3" />
      <mentions>
        <mention ids_tokens="2" string="We" id_sentence="5" />
      </mentions>
    </coreference>
    <coreference id="11" type="PROPER">
      <referenced ids_tokens="1-2" string="Stead 's" id_sentence="15" />
      <mentions>
        <mention ids_tokens="1-11" string="Stead , a tuberculosis specialist at the Arkansas Department of Health" id_sentence="7" />
      </mentions>
    </coreference>
    <coreference id="12" type="NOMINAL">
      <referenced ids_tokens="4-5-6-7" string="a very intriguing finding" id_sentence="8" />
      <mentions>
        <mention ids_tokens="3-11" string="a tuberculosis specialist at the Arkansas Department of Health" id_sentence="7" />
        <mention ids_tokens="2" string="I" id_sentence="9" />
        <mention ids_tokens="2" string="I" id_sentence="10" />
      </mentions>
    </coreference>
    <coreference id="13" type="PROPER">
      <referenced ids_tokens="15-16-17" string="Johns Hopkins University" id_sentence="8" />
      <mentions>
        <mention ids_tokens="10" string="it" id_sentence="9" />
      </mentions>
    </coreference>
    <coreference id="14" type="PROPER">
      <referenced ids_tokens="11-12-13" string="Dr. George Curlin" id_sentence="11" />
      <mentions>
        <mention ids_tokens="3" string="he" id_sentence="12" />
        <mention ids_tokens="7" string="I" id_sentence="12" />
        <mention ids_tokens="1" string="I" id_sentence="14" />
      </mentions>
    </coreference>
    <coreference id="16" type="NOMINAL">
      <referenced ids_tokens="15" string="what" id_sentence="13" />
      <mentions>
        <mention ids_tokens="31" string="they" id_sentence="15" />
      </mentions>
    </coreference>
    <coreference id="17" type="PROPER">
      <referenced ids_tokens="28-29" string="TB infection" id_sentence="15" />
      <mentions>
        <mention ids_tokens="24-25" string="the infection" id_sentence="23" />
        <mention ids_tokens="23-24" string="the infection" id_sentence="24" />
      </mentions>
    </coreference>
    <coreference id="20" type="NOMINAL">
      <referenced ids_tokens="21-22-23-24-25-26-27-28-29-30-31-32-33-34-35-36-37" string="25,398 elderly people who were free of TB infection when they were admitted to Arkansas nursing homes" id_sentence="15" />
      <mentions>
        <mention ids_tokens="2" string="they" id_sentence="16" />
      </mentions>
    </coreference>
    <coreference id="21" type="NOMINAL">
      <referenced ids_tokens="15-16-17" string="blacks as whites" id_sentence="20" />
      <mentions>
        <mention ids_tokens="14-19" string="blacks and 7 percent of whites" id_sentence="16" />
      </mentions>
    </coreference>
    <coreference id="22" type="PROPER">
      <referenced ids_tokens="35-36" string="sub-Saharan Africa" id_sentence="27" />
      <mentions>
        <mention ids_tokens="18" string="Africa" id_sentence="28" />
      </mentions>
    </coreference>
    <coreference id="23" type="PROPER">
      <referenced ids_tokens="6-7-8-9-10-11-12-13-14-15-16-17" string="Dr. Alfred Crowle of Webb-Waring Lung Institute at the University of Colorado" id_sentence="29" />
      <mentions>
        <mention ids_tokens="20" string="Crowle" id_sentence="31" />
      </mentions>
    </coreference>
    <coreference id="24" type="NOMINAL">
      <referenced ids_tokens="24-25-26-27-28" string="germ-eating blood cells called macrophages" id_sentence="29" />
      <mentions>
        <mention ids_tokens="4-5" string="these cells" id_sentence="30" />
      </mentions>
    </coreference>
  </coreferences>
</document>
