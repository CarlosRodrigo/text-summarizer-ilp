<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="LA092490-0095">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>It was a scene that recalled the golden days for Ben Johnson.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="scene" lemma="scene" stem="scene" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="recalled" lemma="recall" stem="recal" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="8" string="golden" lemma="golden" stem="golden" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="9" string="days" lemma="day" stem="dai" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="10" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="Ben" lemma="Ben" stem="ben" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="12" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBD was) (NP (NP (DT a) (NN scene)) (SBAR (WHNP (WDT that)) (S (VP (VBD recalled) (NP (DT the) (JJ golden) (NNS days)) (PP (IN for) (NP (NNP Ben) (NNP Johnson)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Ben Johnson" type="NP">
          <tokens>
            <token id="11" string="Ben" />
            <token id="12" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="2" string="a scene" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="scene" />
          </tokens>
        </chunking>
        <chunking id="3" string="recalled the golden days for Ben Johnson" type="VP">
          <tokens>
            <token id="6" string="recalled" />
            <token id="7" string="the" />
            <token id="8" string="golden" />
            <token id="9" string="days" />
            <token id="10" string="for" />
            <token id="11" string="Ben" />
            <token id="12" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="4" string="the golden days" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="golden" />
            <token id="9" string="days" />
          </tokens>
        </chunking>
        <chunking id="5" string="was a scene that recalled the golden days for Ben Johnson" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="a" />
            <token id="4" string="scene" />
            <token id="5" string="that" />
            <token id="6" string="recalled" />
            <token id="7" string="the" />
            <token id="8" string="golden" />
            <token id="9" string="days" />
            <token id="10" string="for" />
            <token id="11" string="Ben" />
            <token id="12" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="6" string="a scene that recalled the golden days for Ben Johnson" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="scene" />
            <token id="5" string="that" />
            <token id="6" string="recalled" />
            <token id="7" string="the" />
            <token id="8" string="golden" />
            <token id="9" string="days" />
            <token id="10" string="for" />
            <token id="11" string="Ben" />
            <token id="12" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="7" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="8" string="that recalled the golden days for Ben Johnson" type="SBAR">
          <tokens>
            <token id="5" string="that" />
            <token id="6" string="recalled" />
            <token id="7" string="the" />
            <token id="8" string="golden" />
            <token id="9" string="days" />
            <token id="10" string="for" />
            <token id="11" string="Ben" />
            <token id="12" string="Johnson" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">scene</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">scene</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">scene</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">scene</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">recalled</governor>
          <dependent id="5">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="4">scene</governor>
          <dependent id="6">recalled</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">days</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">days</governor>
          <dependent id="8">golden</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="6">recalled</governor>
          <dependent id="9">days</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Johnson</governor>
          <dependent id="10">for</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Johnson</governor>
          <dependent id="11">Ben</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">recalled</governor>
          <dependent id="12">Johnson</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ben Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Ben" />
            <token id="12" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="the golden days" type="DURATION" score="0.0">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="golden" />
            <token id="9" string="days" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="false">
      <content>Almost.</content>
      <tokens>
        <token id="1" string="Almost" lemma="almost" stem="almost" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (ADVP (RB Almost) (. .)))</syntactictree>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">Almost</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="3" has_coreference="false">
      <content>The media were there, as before, chronicling a news conference.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="media" lemma="media" stem="media" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="there" lemma="there" stem="there" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="before" lemma="before" stem="befor" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="chronicling" lemma="chronicle" stem="chronicl" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="news" lemma="news" stem="new" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="conference" lemma="conference" stem="confer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNS media)) (VP (VBD were) (ADVP (RB there)) (, ,) (PP (IN as) (ADVP (RB before))) (, ,) (VP (VBG chronicling) (NP (DT a) (NN news) (NN conference)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a news conference" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="news" />
            <token id="12" string="conference" />
          </tokens>
        </chunking>
        <chunking id="2" string="were there , as before , chronicling a news conference" type="VP">
          <tokens>
            <token id="3" string="were" />
            <token id="4" string="there" />
            <token id="5" string="," />
            <token id="6" string="as" />
            <token id="7" string="before" />
            <token id="8" string="," />
            <token id="9" string="chronicling" />
            <token id="10" string="a" />
            <token id="11" string="news" />
            <token id="12" string="conference" />
          </tokens>
        </chunking>
        <chunking id="3" string="The media" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="media" />
          </tokens>
        </chunking>
        <chunking id="4" string="chronicling a news conference" type="VP">
          <tokens>
            <token id="9" string="chronicling" />
            <token id="10" string="a" />
            <token id="11" string="news" />
            <token id="12" string="conference" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">media</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">chronicling</governor>
          <dependent id="2">media</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="9">chronicling</governor>
          <dependent id="3">were</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">chronicling</governor>
          <dependent id="4">there</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">before</governor>
          <dependent id="6">as</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">chronicling</governor>
          <dependent id="7">before</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">chronicling</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">conference</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">conference</governor>
          <dependent id="11">news</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">chronicling</governor>
          <dependent id="12">conference</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>Johnson was as before, shy and yet brimming with confidence.</content>
      <tokens>
        <token id="1" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="before" lemma="before" stem="befor" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="shy" lemma="shy" stem="shy" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="yet" lemma="yet" stem="yet" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="brimming" lemma="brim" stem="brim" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="confidence" lemma="confidence" stem="confid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Johnson)) (VP (VBD was) (UCP (ADJP (IN as) (ADVP (RB before))) (, ,) (ADJP (JJ shy)) (CC and) (VP (ADVP (RB yet)) (VBG brimming) (PP (IN with) (NP (NN confidence)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="yet brimming with confidence" type="VP">
          <tokens>
            <token id="8" string="yet" />
            <token id="9" string="brimming" />
            <token id="10" string="with" />
            <token id="11" string="confidence" />
          </tokens>
        </chunking>
        <chunking id="2" string="Johnson" type="NP">
          <tokens>
            <token id="1" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="3" string="shy" type="ADJP">
          <tokens>
            <token id="6" string="shy" />
          </tokens>
        </chunking>
        <chunking id="4" string="confidence" type="NP">
          <tokens>
            <token id="11" string="confidence" />
          </tokens>
        </chunking>
        <chunking id="5" string="was as before , shy and yet brimming with confidence" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="as" />
            <token id="4" string="before" />
            <token id="5" string="," />
            <token id="6" string="shy" />
            <token id="7" string="and" />
            <token id="8" string="yet" />
            <token id="9" string="brimming" />
            <token id="10" string="with" />
            <token id="11" string="confidence" />
          </tokens>
        </chunking>
        <chunking id="6" string="as before" type="ADJP">
          <tokens>
            <token id="3" string="as" />
            <token id="4" string="before" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">as</governor>
          <dependent id="1">Johnson</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="3">as</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">as</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">as</governor>
          <dependent id="4">before</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">as</governor>
          <dependent id="6">shy</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">as</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">brimming</governor>
          <dependent id="8">yet</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">as</governor>
          <dependent id="9">brimming</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">confidence</governor>
          <dependent id="10">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">brimming</governor>
          <dependent id="11">confidence</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Johnson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="false">
      <content>There was the bluster, the bragging, the promise of big things to come.</content>
      <tokens>
        <token id="1" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="bluster" lemma="bluster" stem="bluster" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="bragging" lemma="bragging" stem="brag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="promise" lemma="promise" stem="promis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="big" lemma="big" stem="big" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="things" lemma="thing" stem="thing" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="come" lemma="come" stem="come" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (EX There)) (VP (VBD was) (NP (NP (DT the) (NN bluster)) (, ,) (NP (DT the) (NN bragging))) (, ,) (S (NP (NP (DT the) (NN promise)) (PP (IN of) (NP (JJ big) (NNS things)))) (VP (TO to) (VP (VB come))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was the bluster , the bragging , the promise of big things to come" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="the" />
            <token id="4" string="bluster" />
            <token id="5" string="," />
            <token id="6" string="the" />
            <token id="7" string="bragging" />
            <token id="8" string="," />
            <token id="9" string="the" />
            <token id="10" string="promise" />
            <token id="11" string="of" />
            <token id="12" string="big" />
            <token id="13" string="things" />
            <token id="14" string="to" />
            <token id="15" string="come" />
          </tokens>
        </chunking>
        <chunking id="2" string="There" type="NP">
          <tokens>
            <token id="1" string="There" />
          </tokens>
        </chunking>
        <chunking id="3" string="the bragging" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="bragging" />
          </tokens>
        </chunking>
        <chunking id="4" string="the promise" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="promise" />
          </tokens>
        </chunking>
        <chunking id="5" string="the promise of big things" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="promise" />
            <token id="11" string="of" />
            <token id="12" string="big" />
            <token id="13" string="things" />
          </tokens>
        </chunking>
        <chunking id="6" string="to come" type="VP">
          <tokens>
            <token id="14" string="to" />
            <token id="15" string="come" />
          </tokens>
        </chunking>
        <chunking id="7" string="the bluster , the bragging" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="bluster" />
            <token id="5" string="," />
            <token id="6" string="the" />
            <token id="7" string="bragging" />
          </tokens>
        </chunking>
        <chunking id="8" string="the bluster" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="bluster" />
          </tokens>
        </chunking>
        <chunking id="9" string="big things" type="NP">
          <tokens>
            <token id="12" string="big" />
            <token id="13" string="things" />
          </tokens>
        </chunking>
        <chunking id="10" string="come" type="VP">
          <tokens>
            <token id="15" string="come" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="2">was</governor>
          <dependent id="1">There</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">bluster</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="2">was</governor>
          <dependent id="4">bluster</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">bragging</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="4">bluster</governor>
          <dependent id="7">bragging</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">promise</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">was</governor>
          <dependent id="10">promise</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">things</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">things</governor>
          <dependent id="12">big</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">promise</governor>
          <dependent id="13">things</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">come</governor>
          <dependent id="14">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="2">was</governor>
          <dependent id="15">come</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>This scene, which played out two weeks ago in Italy, was familiar, with one exception.</content>
      <tokens>
        <token id="1" string="This" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="scene" lemma="scene" stem="scene" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="played" lemma="play" stem="plai" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="8" string="weeks" lemma="week" stem="week" pos="NNS" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="9" string="ago" lemma="ago" stem="ago" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="10" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Italy" lemma="Italy" stem="itali" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="familiar" lemma="familiar" stem="familiar" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="18" string="exception" lemma="exception" stem="except" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT This) (NN scene)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBD played) (PRT (RP out)) (ADVP (NP (CD two) (NNS weeks)) (RB ago)) (PP (IN in) (NP (NNP Italy)))))) (, ,)) (VP (VBD was) (ADJP (JJ familiar)) (, ,) (PP (IN with) (NP (CD one) (NN exception)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="two weeks" type="NP">
          <tokens>
            <token id="7" string="two" />
            <token id="8" string="weeks" />
          </tokens>
        </chunking>
        <chunking id="2" string="This scene" type="NP">
          <tokens>
            <token id="1" string="This" />
            <token id="2" string="scene" />
          </tokens>
        </chunking>
        <chunking id="3" string="Italy" type="NP">
          <tokens>
            <token id="11" string="Italy" />
          </tokens>
        </chunking>
        <chunking id="4" string="one exception" type="NP">
          <tokens>
            <token id="17" string="one" />
            <token id="18" string="exception" />
          </tokens>
        </chunking>
        <chunking id="5" string="familiar" type="ADJP">
          <tokens>
            <token id="14" string="familiar" />
          </tokens>
        </chunking>
        <chunking id="6" string="played out two weeks ago in Italy" type="VP">
          <tokens>
            <token id="5" string="played" />
            <token id="6" string="out" />
            <token id="7" string="two" />
            <token id="8" string="weeks" />
            <token id="9" string="ago" />
            <token id="10" string="in" />
            <token id="11" string="Italy" />
          </tokens>
        </chunking>
        <chunking id="7" string="was familiar , with one exception" type="VP">
          <tokens>
            <token id="13" string="was" />
            <token id="14" string="familiar" />
            <token id="15" string="," />
            <token id="16" string="with" />
            <token id="17" string="one" />
            <token id="18" string="exception" />
          </tokens>
        </chunking>
        <chunking id="8" string="This scene , which played out two weeks ago in Italy ," type="NP">
          <tokens>
            <token id="1" string="This" />
            <token id="2" string="scene" />
            <token id="3" string="," />
            <token id="4" string="which" />
            <token id="5" string="played" />
            <token id="6" string="out" />
            <token id="7" string="two" />
            <token id="8" string="weeks" />
            <token id="9" string="ago" />
            <token id="10" string="in" />
            <token id="11" string="Italy" />
            <token id="12" string="," />
          </tokens>
        </chunking>
        <chunking id="9" string="which played out two weeks ago in Italy" type="SBAR">
          <tokens>
            <token id="4" string="which" />
            <token id="5" string="played" />
            <token id="6" string="out" />
            <token id="7" string="two" />
            <token id="8" string="weeks" />
            <token id="9" string="ago" />
            <token id="10" string="in" />
            <token id="11" string="Italy" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">scene</governor>
          <dependent id="1">This</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">familiar</governor>
          <dependent id="2">scene</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">played</governor>
          <dependent id="4">which</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="2">scene</governor>
          <dependent id="5">played</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="5">played</governor>
          <dependent id="6">out</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="8">weeks</governor>
          <dependent id="7">two</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="9">ago</governor>
          <dependent id="8">weeks</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">played</governor>
          <dependent id="9">ago</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Italy</governor>
          <dependent id="10">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">played</governor>
          <dependent id="11">Italy</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">familiar</governor>
          <dependent id="13">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">familiar</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">exception</governor>
          <dependent id="16">with</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="18">exception</governor>
          <dependent id="17">one</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">familiar</governor>
          <dependent id="18">exception</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="two weeks ago" type="DATE" score="0.0">
          <tokens>
            <token id="7" string="two" />
            <token id="8" string="weeks" />
            <token id="9" string="ago" />
          </tokens>
        </entity>
        <entity id="2" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="17" string="one" />
          </tokens>
        </entity>
        <entity id="3" string="Italy" type="LOCATION" score="0.0">
          <tokens>
            <token id="11" string="Italy" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>The new element was the pervasive skepticism that now attends Johnson&amp;apost;s boasts.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="new" lemma="new" stem="new" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="element" lemma="element" stem="element" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="pervasive" lemma="pervasive" stem="pervas" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="skepticism" lemma="skepticism" stem="skeptic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="10" string="attends" lemma="attend" stem="attend" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="12" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="boasts" lemma="boast" stem="boast" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (JJ new) (NN element)) (VP (VBD was) (NP (NP (DT the) (JJ pervasive) (NN skepticism)) (SBAR (WHNP (WDT that)) (S (ADVP (RB now)) (VP (VBZ attends) (SBAR (S (NP (NNP Johnson) (POS 's)) (VP (VBZ boasts))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="attends Johnson 's boasts" type="VP">
          <tokens>
            <token id="10" string="attends" />
            <token id="11" string="Johnson" />
            <token id="12" string="'s" />
            <token id="13" string="boasts" />
          </tokens>
        </chunking>
        <chunking id="2" string="was the pervasive skepticism that now attends Johnson 's boasts" type="VP">
          <tokens>
            <token id="4" string="was" />
            <token id="5" string="the" />
            <token id="6" string="pervasive" />
            <token id="7" string="skepticism" />
            <token id="8" string="that" />
            <token id="9" string="now" />
            <token id="10" string="attends" />
            <token id="11" string="Johnson" />
            <token id="12" string="'s" />
            <token id="13" string="boasts" />
          </tokens>
        </chunking>
        <chunking id="3" string="Johnson 's boasts" type="SBAR">
          <tokens>
            <token id="11" string="Johnson" />
            <token id="12" string="'s" />
            <token id="13" string="boasts" />
          </tokens>
        </chunking>
        <chunking id="4" string="The new element" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="new" />
            <token id="3" string="element" />
          </tokens>
        </chunking>
        <chunking id="5" string="boasts" type="VP">
          <tokens>
            <token id="13" string="boasts" />
          </tokens>
        </chunking>
        <chunking id="6" string="that now attends Johnson 's boasts" type="SBAR">
          <tokens>
            <token id="8" string="that" />
            <token id="9" string="now" />
            <token id="10" string="attends" />
            <token id="11" string="Johnson" />
            <token id="12" string="'s" />
            <token id="13" string="boasts" />
          </tokens>
        </chunking>
        <chunking id="7" string="Johnson 's" type="NP">
          <tokens>
            <token id="11" string="Johnson" />
            <token id="12" string="'s" />
          </tokens>
        </chunking>
        <chunking id="8" string="the pervasive skepticism that now attends Johnson 's boasts" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="pervasive" />
            <token id="7" string="skepticism" />
            <token id="8" string="that" />
            <token id="9" string="now" />
            <token id="10" string="attends" />
            <token id="11" string="Johnson" />
            <token id="12" string="'s" />
            <token id="13" string="boasts" />
          </tokens>
        </chunking>
        <chunking id="9" string="the pervasive skepticism" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="pervasive" />
            <token id="7" string="skepticism" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">element</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">element</governor>
          <dependent id="2">new</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">skepticism</governor>
          <dependent id="3">element</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">skepticism</governor>
          <dependent id="4">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">skepticism</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">skepticism</governor>
          <dependent id="6">pervasive</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">skepticism</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">attends</governor>
          <dependent id="8">that</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">attends</governor>
          <dependent id="9">now</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="7">skepticism</governor>
          <dependent id="10">attends</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">boasts</governor>
          <dependent id="11">Johnson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Johnson</governor>
          <dependent id="12">'s</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">attends</governor>
          <dependent id="13">boasts</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="9" string="now" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="false">
      <content>Overweening confidence among world class athletes is well accepted -- even expected.</content>
      <tokens>
        <token id="1" string="Overweening" lemma="overweening" stem="overween" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="confidence" lemma="confidence" stem="confid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="among" lemma="among" stem="among" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="class" lemma="class" stem="class" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="athletes" lemma="athlete" stem="athlet" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="well" lemma="well" stem="well" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="accepted" lemma="accept" stem="accept" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="expected" lemma="expect" stem="expect" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (JJ Overweening) (NN confidence)) (PP (IN among) (NP (NN world) (NN class) (NNS athletes)))) (VP (VBZ is) (ADVP (RB well)) (VP (VBN accepted)))) (: --) (S (ADVP (RB even)) (VP (VBN expected))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Overweening confidence among world class athletes" type="NP">
          <tokens>
            <token id="1" string="Overweening" />
            <token id="2" string="confidence" />
            <token id="3" string="among" />
            <token id="4" string="world" />
            <token id="5" string="class" />
            <token id="6" string="athletes" />
          </tokens>
        </chunking>
        <chunking id="2" string="accepted" type="VP">
          <tokens>
            <token id="9" string="accepted" />
          </tokens>
        </chunking>
        <chunking id="3" string="expected" type="VP">
          <tokens>
            <token id="12" string="expected" />
          </tokens>
        </chunking>
        <chunking id="4" string="Overweening confidence" type="NP">
          <tokens>
            <token id="1" string="Overweening" />
            <token id="2" string="confidence" />
          </tokens>
        </chunking>
        <chunking id="5" string="world class athletes" type="NP">
          <tokens>
            <token id="4" string="world" />
            <token id="5" string="class" />
            <token id="6" string="athletes" />
          </tokens>
        </chunking>
        <chunking id="6" string="is well accepted" type="VP">
          <tokens>
            <token id="7" string="is" />
            <token id="8" string="well" />
            <token id="9" string="accepted" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">confidence</governor>
          <dependent id="1">Overweening</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="9">accepted</governor>
          <dependent id="2">confidence</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">athletes</governor>
          <dependent id="3">among</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">athletes</governor>
          <dependent id="4">world</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">athletes</governor>
          <dependent id="5">class</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">confidence</governor>
          <dependent id="6">athletes</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="9">accepted</governor>
          <dependent id="7">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">accepted</governor>
          <dependent id="8">well</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">accepted</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">expected</governor>
          <dependent id="11">even</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="9">accepted</governor>
          <dependent id="12">expected</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>However, part of the expectation includes the understanding that the athlete can back up the boasts.</content>
      <tokens>
        <token id="1" string="However" lemma="however" stem="howev" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="part" lemma="part" stem="part" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="expectation" lemma="expectation" stem="expect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="includes" lemma="include" stem="includ" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="understanding" lemma="understanding" stem="understand" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="athlete" lemma="athlete" stem="athlet" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="back" lemma="back" stem="back" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="boasts" lemma="boast" stem="boast" pos="VBZ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB However)) (, ,) (NP (NP (NN part)) (PP (IN of) (NP (DT the) (NN expectation)))) (VP (VBZ includes) (NP (DT the) (NN understanding)) (SBAR (IN that) (S (NP (DT the) (NN athlete)) (VP (MD can) (VP (VB back) (PRT (RP up)) (NP (NP (DT the)) (SBAR (S (VP (VBZ boasts)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the" type="NP">
          <tokens>
            <token id="16" string="the" />
          </tokens>
        </chunking>
        <chunking id="2" string="part" type="NP">
          <tokens>
            <token id="3" string="part" />
          </tokens>
        </chunking>
        <chunking id="3" string="the understanding" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="understanding" />
          </tokens>
        </chunking>
        <chunking id="4" string="that the athlete can back up the boasts" type="SBAR">
          <tokens>
            <token id="10" string="that" />
            <token id="11" string="the" />
            <token id="12" string="athlete" />
            <token id="13" string="can" />
            <token id="14" string="back" />
            <token id="15" string="up" />
            <token id="16" string="the" />
            <token id="17" string="boasts" />
          </tokens>
        </chunking>
        <chunking id="5" string="the athlete" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="athlete" />
          </tokens>
        </chunking>
        <chunking id="6" string="boasts" type="SBAR">
          <tokens>
            <token id="17" string="boasts" />
          </tokens>
        </chunking>
        <chunking id="7" string="the boasts" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="boasts" />
          </tokens>
        </chunking>
        <chunking id="8" string="part of the expectation" type="NP">
          <tokens>
            <token id="3" string="part" />
            <token id="4" string="of" />
            <token id="5" string="the" />
            <token id="6" string="expectation" />
          </tokens>
        </chunking>
        <chunking id="9" string="back up the boasts" type="VP">
          <tokens>
            <token id="14" string="back" />
            <token id="15" string="up" />
            <token id="16" string="the" />
            <token id="17" string="boasts" />
          </tokens>
        </chunking>
        <chunking id="10" string="the expectation" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="expectation" />
          </tokens>
        </chunking>
        <chunking id="11" string="includes the understanding that the athlete can back up the boasts" type="VP">
          <tokens>
            <token id="7" string="includes" />
            <token id="8" string="the" />
            <token id="9" string="understanding" />
            <token id="10" string="that" />
            <token id="11" string="the" />
            <token id="12" string="athlete" />
            <token id="13" string="can" />
            <token id="14" string="back" />
            <token id="15" string="up" />
            <token id="16" string="the" />
            <token id="17" string="boasts" />
          </tokens>
        </chunking>
        <chunking id="12" string="can back up the boasts" type="VP">
          <tokens>
            <token id="13" string="can" />
            <token id="14" string="back" />
            <token id="15" string="up" />
            <token id="16" string="the" />
            <token id="17" string="boasts" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="7">includes</governor>
          <dependent id="1">However</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">includes</governor>
          <dependent id="3">part</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">expectation</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">expectation</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">part</governor>
          <dependent id="6">expectation</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">includes</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">understanding</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">includes</governor>
          <dependent id="9">understanding</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">back</governor>
          <dependent id="10">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">athlete</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">back</governor>
          <dependent id="12">athlete</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">back</governor>
          <dependent id="13">can</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">includes</governor>
          <dependent id="14">back</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="14">back</governor>
          <dependent id="15">up</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">back</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="16">the</governor>
          <dependent id="17">boasts</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>Johnson will at last get his chance to do that.</content>
      <tokens>
        <token id="1" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="get" lemma="get" stem="get" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="chance" lemma="chance" stem="chanc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="do" lemma="do" stem="do" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Johnson)) (VP (MD will) (PP (IN at) (NP (JJ last))) (VP (VB get) (NP (PRP$ his) (NN chance) (S (VP (TO to) (VP (VB do) (NP (DT that)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that" type="NP">
          <tokens>
            <token id="10" string="that" />
          </tokens>
        </chunking>
        <chunking id="2" string="will at last get his chance to do that" type="VP">
          <tokens>
            <token id="2" string="will" />
            <token id="3" string="at" />
            <token id="4" string="last" />
            <token id="5" string="get" />
            <token id="6" string="his" />
            <token id="7" string="chance" />
            <token id="8" string="to" />
            <token id="9" string="do" />
            <token id="10" string="that" />
          </tokens>
        </chunking>
        <chunking id="3" string="Johnson" type="NP">
          <tokens>
            <token id="1" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="4" string="get his chance to do that" type="VP">
          <tokens>
            <token id="5" string="get" />
            <token id="6" string="his" />
            <token id="7" string="chance" />
            <token id="8" string="to" />
            <token id="9" string="do" />
            <token id="10" string="that" />
          </tokens>
        </chunking>
        <chunking id="5" string="his chance to do that" type="NP">
          <tokens>
            <token id="6" string="his" />
            <token id="7" string="chance" />
            <token id="8" string="to" />
            <token id="9" string="do" />
            <token id="10" string="that" />
          </tokens>
        </chunking>
        <chunking id="6" string="last" type="NP">
          <tokens>
            <token id="4" string="last" />
          </tokens>
        </chunking>
        <chunking id="7" string="do that" type="VP">
          <tokens>
            <token id="9" string="do" />
            <token id="10" string="that" />
          </tokens>
        </chunking>
        <chunking id="8" string="to do that" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="do" />
            <token id="10" string="that" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">get</governor>
          <dependent id="1">Johnson</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">get</governor>
          <dependent id="2">will</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">last</governor>
          <dependent id="3">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">get</governor>
          <dependent id="4">last</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">get</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">chance</governor>
          <dependent id="6">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">get</governor>
          <dependent id="7">chance</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">do</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="7">chance</governor>
          <dependent id="9">do</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">do</governor>
          <dependent id="10">that</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Johnson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>It has been two years since Johnson, then world record-holder at 100 meters, was stripped of his gold medal after testing positive for anabolic steroids at the Seoul Olympics.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="5" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="6" string="since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="record-holder" lemma="record-holder" stem="record-hold" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="100" lemma="100" stem="100" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="true" />
        <token id="14" string="meters" lemma="meter" stem="meter" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="stripped" lemma="strip" stem="strip" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="20" string="gold" lemma="gold" stem="gold" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="medal" lemma="medal" stem="medal" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="testing" lemma="test" stem="test" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="positive" lemma="positive" stem="posit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="anabolic" lemma="anabolic" stem="anabol" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="steroids" lemma="steroid" stem="steroid" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="28" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="30" string="Seoul" lemma="Seoul" stem="seoul" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="31" string="Olympics" lemma="Olympics" stem="olympic" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBZ has) (VP (VBN been) (NP (CD two) (NNS years)) (SBAR (IN since) (S (NP (NP (NNP Johnson)) (, ,) (ADVP (RB then)) (NP (NP (NN world) (NN record-holder)) (PP (IN at) (NP (CD 100) (NNS meters)))) (, ,)) (VP (VBD was) (VP (VBN stripped) (PP (IN of) (NP (PRP$ his) (NN gold) (NN medal))) (PP (IN after) (S (VP (VBG testing) (ADJP (JJ positive) (PP (IN for) (NP (JJ anabolic) (NNS steroids)))) (PP (IN at) (NP (DT the) (NNP Seoul) (NNPS Olympics)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="has been two years since Johnson , then world record-holder at 100 meters , was stripped of his gold medal after testing positive for anabolic steroids at the Seoul Olympics" type="VP">
          <tokens>
            <token id="2" string="has" />
            <token id="3" string="been" />
            <token id="4" string="two" />
            <token id="5" string="years" />
            <token id="6" string="since" />
            <token id="7" string="Johnson" />
            <token id="8" string="," />
            <token id="9" string="then" />
            <token id="10" string="world" />
            <token id="11" string="record-holder" />
            <token id="12" string="at" />
            <token id="13" string="100" />
            <token id="14" string="meters" />
            <token id="15" string="," />
            <token id="16" string="was" />
            <token id="17" string="stripped" />
            <token id="18" string="of" />
            <token id="19" string="his" />
            <token id="20" string="gold" />
            <token id="21" string="medal" />
            <token id="22" string="after" />
            <token id="23" string="testing" />
            <token id="24" string="positive" />
            <token id="25" string="for" />
            <token id="26" string="anabolic" />
            <token id="27" string="steroids" />
            <token id="28" string="at" />
            <token id="29" string="the" />
            <token id="30" string="Seoul" />
            <token id="31" string="Olympics" />
          </tokens>
        </chunking>
        <chunking id="2" string="world record-holder" type="NP">
          <tokens>
            <token id="10" string="world" />
            <token id="11" string="record-holder" />
          </tokens>
        </chunking>
        <chunking id="3" string="Johnson" type="NP">
          <tokens>
            <token id="7" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="4" string="been two years since Johnson , then world record-holder at 100 meters , was stripped of his gold medal after testing positive for anabolic steroids at the Seoul Olympics" type="VP">
          <tokens>
            <token id="3" string="been" />
            <token id="4" string="two" />
            <token id="5" string="years" />
            <token id="6" string="since" />
            <token id="7" string="Johnson" />
            <token id="8" string="," />
            <token id="9" string="then" />
            <token id="10" string="world" />
            <token id="11" string="record-holder" />
            <token id="12" string="at" />
            <token id="13" string="100" />
            <token id="14" string="meters" />
            <token id="15" string="," />
            <token id="16" string="was" />
            <token id="17" string="stripped" />
            <token id="18" string="of" />
            <token id="19" string="his" />
            <token id="20" string="gold" />
            <token id="21" string="medal" />
            <token id="22" string="after" />
            <token id="23" string="testing" />
            <token id="24" string="positive" />
            <token id="25" string="for" />
            <token id="26" string="anabolic" />
            <token id="27" string="steroids" />
            <token id="28" string="at" />
            <token id="29" string="the" />
            <token id="30" string="Seoul" />
            <token id="31" string="Olympics" />
          </tokens>
        </chunking>
        <chunking id="5" string="world record-holder at 100 meters" type="NP">
          <tokens>
            <token id="10" string="world" />
            <token id="11" string="record-holder" />
            <token id="12" string="at" />
            <token id="13" string="100" />
            <token id="14" string="meters" />
          </tokens>
        </chunking>
        <chunking id="6" string="the Seoul Olympics" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="Seoul" />
            <token id="31" string="Olympics" />
          </tokens>
        </chunking>
        <chunking id="7" string="his gold medal" type="NP">
          <tokens>
            <token id="19" string="his" />
            <token id="20" string="gold" />
            <token id="21" string="medal" />
          </tokens>
        </chunking>
        <chunking id="8" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="9" string="positive for anabolic steroids" type="ADJP">
          <tokens>
            <token id="24" string="positive" />
            <token id="25" string="for" />
            <token id="26" string="anabolic" />
            <token id="27" string="steroids" />
          </tokens>
        </chunking>
        <chunking id="10" string="was stripped of his gold medal after testing positive for anabolic steroids at the Seoul Olympics" type="VP">
          <tokens>
            <token id="16" string="was" />
            <token id="17" string="stripped" />
            <token id="18" string="of" />
            <token id="19" string="his" />
            <token id="20" string="gold" />
            <token id="21" string="medal" />
            <token id="22" string="after" />
            <token id="23" string="testing" />
            <token id="24" string="positive" />
            <token id="25" string="for" />
            <token id="26" string="anabolic" />
            <token id="27" string="steroids" />
            <token id="28" string="at" />
            <token id="29" string="the" />
            <token id="30" string="Seoul" />
            <token id="31" string="Olympics" />
          </tokens>
        </chunking>
        <chunking id="11" string="since Johnson , then world record-holder at 100 meters , was stripped of his gold medal after testing positive for anabolic steroids at the Seoul Olympics" type="SBAR">
          <tokens>
            <token id="6" string="since" />
            <token id="7" string="Johnson" />
            <token id="8" string="," />
            <token id="9" string="then" />
            <token id="10" string="world" />
            <token id="11" string="record-holder" />
            <token id="12" string="at" />
            <token id="13" string="100" />
            <token id="14" string="meters" />
            <token id="15" string="," />
            <token id="16" string="was" />
            <token id="17" string="stripped" />
            <token id="18" string="of" />
            <token id="19" string="his" />
            <token id="20" string="gold" />
            <token id="21" string="medal" />
            <token id="22" string="after" />
            <token id="23" string="testing" />
            <token id="24" string="positive" />
            <token id="25" string="for" />
            <token id="26" string="anabolic" />
            <token id="27" string="steroids" />
            <token id="28" string="at" />
            <token id="29" string="the" />
            <token id="30" string="Seoul" />
            <token id="31" string="Olympics" />
          </tokens>
        </chunking>
        <chunking id="12" string="100 meters" type="NP">
          <tokens>
            <token id="13" string="100" />
            <token id="14" string="meters" />
          </tokens>
        </chunking>
        <chunking id="13" string="Johnson , then world record-holder at 100 meters ," type="NP">
          <tokens>
            <token id="7" string="Johnson" />
            <token id="8" string="," />
            <token id="9" string="then" />
            <token id="10" string="world" />
            <token id="11" string="record-holder" />
            <token id="12" string="at" />
            <token id="13" string="100" />
            <token id="14" string="meters" />
            <token id="15" string="," />
          </tokens>
        </chunking>
        <chunking id="14" string="stripped of his gold medal after testing positive for anabolic steroids at the Seoul Olympics" type="VP">
          <tokens>
            <token id="17" string="stripped" />
            <token id="18" string="of" />
            <token id="19" string="his" />
            <token id="20" string="gold" />
            <token id="21" string="medal" />
            <token id="22" string="after" />
            <token id="23" string="testing" />
            <token id="24" string="positive" />
            <token id="25" string="for" />
            <token id="26" string="anabolic" />
            <token id="27" string="steroids" />
            <token id="28" string="at" />
            <token id="29" string="the" />
            <token id="30" string="Seoul" />
            <token id="31" string="Olympics" />
          </tokens>
        </chunking>
        <chunking id="15" string="two years" type="NP">
          <tokens>
            <token id="4" string="two" />
            <token id="5" string="years" />
          </tokens>
        </chunking>
        <chunking id="16" string="anabolic steroids" type="NP">
          <tokens>
            <token id="26" string="anabolic" />
            <token id="27" string="steroids" />
          </tokens>
        </chunking>
        <chunking id="17" string="testing positive for anabolic steroids at the Seoul Olympics" type="VP">
          <tokens>
            <token id="23" string="testing" />
            <token id="24" string="positive" />
            <token id="25" string="for" />
            <token id="26" string="anabolic" />
            <token id="27" string="steroids" />
            <token id="28" string="at" />
            <token id="29" string="the" />
            <token id="30" string="Seoul" />
            <token id="31" string="Olympics" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">years</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">years</governor>
          <dependent id="2">has</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">years</governor>
          <dependent id="3">been</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="5">years</governor>
          <dependent id="4">two</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">years</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">stripped</governor>
          <dependent id="6">since</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="17">stripped</governor>
          <dependent id="7">Johnson</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">record-holder</governor>
          <dependent id="9">then</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">record-holder</governor>
          <dependent id="10">world</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="7">Johnson</governor>
          <dependent id="11">record-holder</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">meters</governor>
          <dependent id="12">at</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="14">meters</governor>
          <dependent id="13">100</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">record-holder</governor>
          <dependent id="14">meters</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="17">stripped</governor>
          <dependent id="16">was</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">years</governor>
          <dependent id="17">stripped</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">medal</governor>
          <dependent id="18">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="21">medal</governor>
          <dependent id="19">his</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">medal</governor>
          <dependent id="20">gold</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">stripped</governor>
          <dependent id="21">medal</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">testing</governor>
          <dependent id="22">after</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="17">stripped</governor>
          <dependent id="23">testing</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="23">testing</governor>
          <dependent id="24">positive</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">steroids</governor>
          <dependent id="25">for</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">steroids</governor>
          <dependent id="26">anabolic</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">positive</governor>
          <dependent id="27">steroids</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">Olympics</governor>
          <dependent id="28">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">Olympics</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">Olympics</governor>
          <dependent id="30">Seoul</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">testing</governor>
          <dependent id="31">Olympics</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="100" type="NUMBER" score="0.0">
          <tokens>
            <token id="13" string="100" />
          </tokens>
        </entity>
        <entity id="2" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Johnson" />
          </tokens>
        </entity>
        <entity id="3" string="Seoul" type="LOCATION" score="0.0">
          <tokens>
            <token id="30" string="Seoul" />
          </tokens>
        </entity>
        <entity id="4" string="two years" type="DURATION" score="0.0">
          <tokens>
            <token id="4" string="two" />
            <token id="5" string="years" />
          </tokens>
        </entity>
        <entity id="5" string="Olympics" type="MISC" score="0.0">
          <tokens>
            <token id="31" string="Olympics" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>Johnson was also suspended from competition for two years; that suspension ends today.</content>
      <tokens>
        <token id="1" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="suspended" lemma="suspend" stem="suspend" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="competition" lemma="competition" stem="competit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="9" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="10" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="suspension" lemma="suspension" stem="suspens" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="ends" lemma="end" stem="end" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="today" lemma="today" stem="todai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Johnson)) (VP (VBD was) (ADVP (RB also)) (VP (VBN suspended) (PP (IN from) (NP (NP (NN competition)) (PP (IN for) (NP (CD two) (NNS years))))) (: ;) (SBAR (IN that) (S (NP (NN suspension)) (VP (VBZ ends) (NP-TMP (NN today))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was also suspended from competition for two years ; that suspension ends today" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="also" />
            <token id="4" string="suspended" />
            <token id="5" string="from" />
            <token id="6" string="competition" />
            <token id="7" string="for" />
            <token id="8" string="two" />
            <token id="9" string="years" />
            <token id="10" string=";" />
            <token id="11" string="that" />
            <token id="12" string="suspension" />
            <token id="13" string="ends" />
            <token id="14" string="today" />
          </tokens>
        </chunking>
        <chunking id="2" string="Johnson" type="NP">
          <tokens>
            <token id="1" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="3" string="two years" type="NP">
          <tokens>
            <token id="8" string="two" />
            <token id="9" string="years" />
          </tokens>
        </chunking>
        <chunking id="4" string="that suspension ends today" type="SBAR">
          <tokens>
            <token id="11" string="that" />
            <token id="12" string="suspension" />
            <token id="13" string="ends" />
            <token id="14" string="today" />
          </tokens>
        </chunking>
        <chunking id="5" string="competition" type="NP">
          <tokens>
            <token id="6" string="competition" />
          </tokens>
        </chunking>
        <chunking id="6" string="ends today" type="VP">
          <tokens>
            <token id="13" string="ends" />
            <token id="14" string="today" />
          </tokens>
        </chunking>
        <chunking id="7" string="competition for two years" type="NP">
          <tokens>
            <token id="6" string="competition" />
            <token id="7" string="for" />
            <token id="8" string="two" />
            <token id="9" string="years" />
          </tokens>
        </chunking>
        <chunking id="8" string="suspended from competition for two years ; that suspension ends today" type="VP">
          <tokens>
            <token id="4" string="suspended" />
            <token id="5" string="from" />
            <token id="6" string="competition" />
            <token id="7" string="for" />
            <token id="8" string="two" />
            <token id="9" string="years" />
            <token id="10" string=";" />
            <token id="11" string="that" />
            <token id="12" string="suspension" />
            <token id="13" string="ends" />
            <token id="14" string="today" />
          </tokens>
        </chunking>
        <chunking id="9" string="suspension" type="NP">
          <tokens>
            <token id="12" string="suspension" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="4">suspended</governor>
          <dependent id="1">Johnson</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">suspended</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">suspended</governor>
          <dependent id="3">also</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">suspended</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">competition</governor>
          <dependent id="5">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">suspended</governor>
          <dependent id="6">competition</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">years</governor>
          <dependent id="7">for</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="9">years</governor>
          <dependent id="8">two</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">competition</governor>
          <dependent id="9">years</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">ends</governor>
          <dependent id="11">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">ends</governor>
          <dependent id="12">suspension</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">suspended</governor>
          <dependent id="13">ends</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="13">ends</governor>
          <dependent id="14">today</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="two years" type="DURATION" score="0.0">
          <tokens>
            <token id="8" string="two" />
            <token id="9" string="years" />
          </tokens>
        </entity>
        <entity id="3" string="today" type="DATE" score="0.0">
          <tokens>
            <token id="14" string="today" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>And so the questions begin: What can Johnson do when not assisted by performance-enhancing drugs?</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="so" lemma="so" stem="so" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="questions" lemma="question" stem="question" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="begin" lemma="begin" stem="begin" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="What" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="10" string="do" lemma="do" stem="do" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="assisted" lemma="assist" stem="assist" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="performance-enhancing" lemma="performance-enhancing" stem="performance-enhanc" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="drugs" lemma="drug" stem="drug" pos="NNS" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="false" />
        <token id="17" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (UCP (S (CC And) (ADVP (IN so)) (NP (DT the) (NNS questions)) (VP (VBP begin))) (: :) (SBAR (WHNP (WP What)) (SINV (MD can) (NP (NNP Johnson)) (VP (VB do) (SBAR (WHADVP (WRB when)) (S (RB not) (VP (VBN assisted) (PP (IN by) (NP (JJ performance-enhancing) (NNS drugs))))))))) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Johnson" type="NP">
          <tokens>
            <token id="9" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="2" string="the questions" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="questions" />
          </tokens>
        </chunking>
        <chunking id="3" string="What can Johnson do when not assisted by performance-enhancing drugs" type="SBAR">
          <tokens>
            <token id="7" string="What" />
            <token id="8" string="can" />
            <token id="9" string="Johnson" />
            <token id="10" string="do" />
            <token id="11" string="when" />
            <token id="12" string="not" />
            <token id="13" string="assisted" />
            <token id="14" string="by" />
            <token id="15" string="performance-enhancing" />
            <token id="16" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="4" string="when not assisted by performance-enhancing drugs" type="SBAR">
          <tokens>
            <token id="11" string="when" />
            <token id="12" string="not" />
            <token id="13" string="assisted" />
            <token id="14" string="by" />
            <token id="15" string="performance-enhancing" />
            <token id="16" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="5" string="assisted by performance-enhancing drugs" type="VP">
          <tokens>
            <token id="13" string="assisted" />
            <token id="14" string="by" />
            <token id="15" string="performance-enhancing" />
            <token id="16" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="6" string="performance-enhancing drugs" type="NP">
          <tokens>
            <token id="15" string="performance-enhancing" />
            <token id="16" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="7" string="begin" type="VP">
          <tokens>
            <token id="5" string="begin" />
          </tokens>
        </chunking>
        <chunking id="8" string="when" type="WHADVP">
          <tokens>
            <token id="11" string="when" />
          </tokens>
        </chunking>
        <chunking id="9" string="do when not assisted by performance-enhancing drugs" type="VP">
          <tokens>
            <token id="10" string="do" />
            <token id="11" string="when" />
            <token id="12" string="not" />
            <token id="13" string="assisted" />
            <token id="14" string="by" />
            <token id="15" string="performance-enhancing" />
            <token id="16" string="drugs" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="5">begin</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">begin</governor>
          <dependent id="2">so</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">questions</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">begin</governor>
          <dependent id="4">questions</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">begin</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="10">do</governor>
          <dependent id="7">What</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">do</governor>
          <dependent id="8">can</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">do</governor>
          <dependent id="9">Johnson</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="5">begin</governor>
          <dependent id="10">do</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">assisted</governor>
          <dependent id="11">when</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="13">assisted</governor>
          <dependent id="12">not</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="10">do</governor>
          <dependent id="13">assisted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">drugs</governor>
          <dependent id="14">by</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">drugs</governor>
          <dependent id="15">performance-enhancing</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">assisted</governor>
          <dependent id="16">drugs</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="drugs" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="16" string="drugs" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>&amp;quot;Once he returns to the sport, and if he returns a winner, all is forgiven,&amp;quot; said Paul Gaines, assistant meet director for the Hamilton Spectator Indoor Games, the Canadian meet to be held Jan. 11 that will mark Johnson&amp;apost;s return to competition.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Once" lemma="once" stem="once" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="returns" lemma="return" stem="return" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="sport" lemma="sport" stem="sport" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="returns" lemma="return" stem="return" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="winner" lemma="winner" stem="winner" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="forgiven" lemma="forgive" stem="forgiven" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="Paul" lemma="Paul" stem="paul" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="23" string="Gaines" lemma="Gaines" stem="gain" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="assistant" lemma="assistant" stem="assist" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="meet" lemma="meet" stem="meet" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="director" lemma="director" stem="director" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="28" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="30" string="Hamilton" lemma="Hamilton" stem="hamilton" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="31" string="Spectator" lemma="Spectator" stem="spectat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="32" string="Indoor" lemma="Indoor" stem="indoor" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="33" string="Games" lemma="Games" stem="game" pos="NNPS" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="34" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="36" string="Canadian" lemma="canadian" stem="canadian" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="true" is_refers="false" />
        <token id="37" string="meet" lemma="meet" stem="meet" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="held" lemma="hold" stem="held" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="Jan." lemma="Jan." stem="jan." pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="42" string="11" lemma="11" stem="11" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="43" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="mark" lemma="mark" stem="mark" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="46" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="47" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="48" string="return" lemma="return" stem="return" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="49" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="50" string="competition" lemma="competition" stem="competit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="51" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (SBAR (SBAR (RB Once) (S (NP (PRP he)) (VP (VBZ returns) (PP (TO to) (NP (DT the) (NN sport)))))) (, ,) (CC and) (SBAR (IN if) (S (NP (PRP he)) (VP (VBZ returns) (NP (DT a) (NN winner)))))) (, ,) (NP (DT all)) (VP (VBZ is) (VP (VBN forgiven)))) (, ,) ('' '') (VP (VBD said) (SBAR (S (NP (NNP Paul) (NNP Gaines)) (PRN (, ,) (S (NP (JJ assistant)) (VP (VBP meet) (NP (NP (NN director)) (PP (IN for) (NP (DT the) (NNP Hamilton) (NNP Spectator) (NNP Indoor) (NNPS Games)))))) (, ,)) (NP (DT the) (JJ Canadian)) (VP (VBP meet) (S (VP (TO to) (VP (VB be) (VP (VBN held) (NP-TMP (NNP Jan.) (CD 11)))))))))) (SBAR (WHNP (WDT that)) (S (VP (MD will) (VP (VB mark) (NP (NP (NNP Johnson) (POS 's)) (NN return)) (PP (TO to) (NP (NN competition))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="director for the Hamilton Spectator Indoor Games" type="NP">
          <tokens>
            <token id="27" string="director" />
            <token id="28" string="for" />
            <token id="29" string="the" />
            <token id="30" string="Hamilton" />
            <token id="31" string="Spectator" />
            <token id="32" string="Indoor" />
            <token id="33" string="Games" />
          </tokens>
        </chunking>
        <chunking id="2" string="all" type="NP">
          <tokens>
            <token id="16" string="all" />
          </tokens>
        </chunking>
        <chunking id="3" string="director" type="NP">
          <tokens>
            <token id="27" string="director" />
          </tokens>
        </chunking>
        <chunking id="4" string="returns a winner" type="VP">
          <tokens>
            <token id="12" string="returns" />
            <token id="13" string="a" />
            <token id="14" string="winner" />
          </tokens>
        </chunking>
        <chunking id="5" string="forgiven" type="VP">
          <tokens>
            <token id="18" string="forgiven" />
          </tokens>
        </chunking>
        <chunking id="6" string="to be held Jan. 11" type="VP">
          <tokens>
            <token id="38" string="to" />
            <token id="39" string="be" />
            <token id="40" string="held" />
            <token id="41" string="Jan." />
            <token id="42" string="11" />
          </tokens>
        </chunking>
        <chunking id="7" string="assistant" type="NP">
          <tokens>
            <token id="25" string="assistant" />
          </tokens>
        </chunking>
        <chunking id="8" string="the Canadian" type="NP">
          <tokens>
            <token id="35" string="the" />
            <token id="36" string="Canadian" />
          </tokens>
        </chunking>
        <chunking id="9" string="held Jan. 11" type="VP">
          <tokens>
            <token id="40" string="held" />
            <token id="41" string="Jan." />
            <token id="42" string="11" />
          </tokens>
        </chunking>
        <chunking id="10" string="the sport" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="sport" />
          </tokens>
        </chunking>
        <chunking id="11" string="said Paul Gaines , assistant meet director for the Hamilton Spectator Indoor Games , the Canadian meet to be held Jan. 11" type="VP">
          <tokens>
            <token id="21" string="said" />
            <token id="22" string="Paul" />
            <token id="23" string="Gaines" />
            <token id="24" string="," />
            <token id="25" string="assistant" />
            <token id="26" string="meet" />
            <token id="27" string="director" />
            <token id="28" string="for" />
            <token id="29" string="the" />
            <token id="30" string="Hamilton" />
            <token id="31" string="Spectator" />
            <token id="32" string="Indoor" />
            <token id="33" string="Games" />
            <token id="34" string="," />
            <token id="35" string="the" />
            <token id="36" string="Canadian" />
            <token id="37" string="meet" />
            <token id="38" string="to" />
            <token id="39" string="be" />
            <token id="40" string="held" />
            <token id="41" string="Jan." />
            <token id="42" string="11" />
          </tokens>
        </chunking>
        <chunking id="12" string="Paul Gaines , assistant meet director for the Hamilton Spectator Indoor Games , the Canadian meet to be held Jan. 11" type="SBAR">
          <tokens>
            <token id="22" string="Paul" />
            <token id="23" string="Gaines" />
            <token id="24" string="," />
            <token id="25" string="assistant" />
            <token id="26" string="meet" />
            <token id="27" string="director" />
            <token id="28" string="for" />
            <token id="29" string="the" />
            <token id="30" string="Hamilton" />
            <token id="31" string="Spectator" />
            <token id="32" string="Indoor" />
            <token id="33" string="Games" />
            <token id="34" string="," />
            <token id="35" string="the" />
            <token id="36" string="Canadian" />
            <token id="37" string="meet" />
            <token id="38" string="to" />
            <token id="39" string="be" />
            <token id="40" string="held" />
            <token id="41" string="Jan." />
            <token id="42" string="11" />
          </tokens>
        </chunking>
        <chunking id="13" string="a winner" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="winner" />
          </tokens>
        </chunking>
        <chunking id="14" string="he" type="NP">
          <tokens>
            <token id="3" string="he" />
          </tokens>
        </chunking>
        <chunking id="15" string="Johnson 's" type="NP">
          <tokens>
            <token id="46" string="Johnson" />
            <token id="47" string="'s" />
          </tokens>
        </chunking>
        <chunking id="16" string="Johnson 's return" type="NP">
          <tokens>
            <token id="46" string="Johnson" />
            <token id="47" string="'s" />
            <token id="48" string="return" />
          </tokens>
        </chunking>
        <chunking id="17" string="is forgiven" type="VP">
          <tokens>
            <token id="17" string="is" />
            <token id="18" string="forgiven" />
          </tokens>
        </chunking>
        <chunking id="18" string="be held Jan. 11" type="VP">
          <tokens>
            <token id="39" string="be" />
            <token id="40" string="held" />
            <token id="41" string="Jan." />
            <token id="42" string="11" />
          </tokens>
        </chunking>
        <chunking id="19" string="that will mark Johnson 's return to competition" type="SBAR">
          <tokens>
            <token id="43" string="that" />
            <token id="44" string="will" />
            <token id="45" string="mark" />
            <token id="46" string="Johnson" />
            <token id="47" string="'s" />
            <token id="48" string="return" />
            <token id="49" string="to" />
            <token id="50" string="competition" />
          </tokens>
        </chunking>
        <chunking id="20" string="competition" type="NP">
          <tokens>
            <token id="50" string="competition" />
          </tokens>
        </chunking>
        <chunking id="21" string="Paul Gaines" type="NP">
          <tokens>
            <token id="22" string="Paul" />
            <token id="23" string="Gaines" />
          </tokens>
        </chunking>
        <chunking id="22" string="mark Johnson 's return to competition" type="VP">
          <tokens>
            <token id="45" string="mark" />
            <token id="46" string="Johnson" />
            <token id="47" string="'s" />
            <token id="48" string="return" />
            <token id="49" string="to" />
            <token id="50" string="competition" />
          </tokens>
        </chunking>
        <chunking id="23" string="Once he returns to the sport , and if he returns a winner" type="SBAR">
          <tokens>
            <token id="2" string="Once" />
            <token id="3" string="he" />
            <token id="4" string="returns" />
            <token id="5" string="to" />
            <token id="6" string="the" />
            <token id="7" string="sport" />
            <token id="8" string="," />
            <token id="9" string="and" />
            <token id="10" string="if" />
            <token id="11" string="he" />
            <token id="12" string="returns" />
            <token id="13" string="a" />
            <token id="14" string="winner" />
          </tokens>
        </chunking>
        <chunking id="24" string="returns to the sport" type="VP">
          <tokens>
            <token id="4" string="returns" />
            <token id="5" string="to" />
            <token id="6" string="the" />
            <token id="7" string="sport" />
          </tokens>
        </chunking>
        <chunking id="25" string="meet director for the Hamilton Spectator Indoor Games" type="VP">
          <tokens>
            <token id="26" string="meet" />
            <token id="27" string="director" />
            <token id="28" string="for" />
            <token id="29" string="the" />
            <token id="30" string="Hamilton" />
            <token id="31" string="Spectator" />
            <token id="32" string="Indoor" />
            <token id="33" string="Games" />
          </tokens>
        </chunking>
        <chunking id="26" string="will mark Johnson 's return to competition" type="VP">
          <tokens>
            <token id="44" string="will" />
            <token id="45" string="mark" />
            <token id="46" string="Johnson" />
            <token id="47" string="'s" />
            <token id="48" string="return" />
            <token id="49" string="to" />
            <token id="50" string="competition" />
          </tokens>
        </chunking>
        <chunking id="27" string="if he returns a winner" type="SBAR">
          <tokens>
            <token id="10" string="if" />
            <token id="11" string="he" />
            <token id="12" string="returns" />
            <token id="13" string="a" />
            <token id="14" string="winner" />
          </tokens>
        </chunking>
        <chunking id="28" string="Once he returns to the sport" type="SBAR">
          <tokens>
            <token id="2" string="Once" />
            <token id="3" string="he" />
            <token id="4" string="returns" />
            <token id="5" string="to" />
            <token id="6" string="the" />
            <token id="7" string="sport" />
          </tokens>
        </chunking>
        <chunking id="29" string="the Hamilton Spectator Indoor Games" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="Hamilton" />
            <token id="31" string="Spectator" />
            <token id="32" string="Indoor" />
            <token id="33" string="Games" />
          </tokens>
        </chunking>
        <chunking id="30" string="meet to be held Jan. 11" type="VP">
          <tokens>
            <token id="37" string="meet" />
            <token id="38" string="to" />
            <token id="39" string="be" />
            <token id="40" string="held" />
            <token id="41" string="Jan." />
            <token id="42" string="11" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="4">returns</governor>
          <dependent id="2">Once</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">returns</governor>
          <dependent id="3">he</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="18">forgiven</governor>
          <dependent id="4">returns</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">sport</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">sport</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">returns</governor>
          <dependent id="7">sport</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">returns</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">returns</governor>
          <dependent id="10">if</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">returns</governor>
          <dependent id="11">he</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">returns</governor>
          <dependent id="12">returns</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">winner</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">returns</governor>
          <dependent id="14">winner</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="18">forgiven</governor>
          <dependent id="16">all</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="18">forgiven</governor>
          <dependent id="17">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="21">said</governor>
          <dependent id="18">forgiven</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="21">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">Gaines</governor>
          <dependent id="22">Paul</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="37">meet</governor>
          <dependent id="23">Gaines</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">meet</governor>
          <dependent id="25">assistant</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="37">meet</governor>
          <dependent id="26">meet</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="26">meet</governor>
          <dependent id="27">director</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">Games</governor>
          <dependent id="28">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">Games</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="33">Games</governor>
          <dependent id="30">Hamilton</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="33">Games</governor>
          <dependent id="31">Spectator</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="33">Games</governor>
          <dependent id="32">Indoor</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">director</governor>
          <dependent id="33">Games</dependent>
        </dependency>
        <dependency type="det">
          <governor id="36">Canadian</governor>
          <dependent id="35">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="37">meet</governor>
          <dependent id="36">Canadian</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="21">said</governor>
          <dependent id="37">meet</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="40">held</governor>
          <dependent id="38">to</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="40">held</governor>
          <dependent id="39">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="37">meet</governor>
          <dependent id="40">held</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="40">held</governor>
          <dependent id="41">Jan.</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="41">Jan.</governor>
          <dependent id="42">11</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="45">mark</governor>
          <dependent id="43">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="45">mark</governor>
          <dependent id="44">will</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="21">said</governor>
          <dependent id="45">mark</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="48">return</governor>
          <dependent id="46">Johnson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="46">Johnson</governor>
          <dependent id="47">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="45">mark</governor>
          <dependent id="48">return</dependent>
        </dependency>
        <dependency type="case">
          <governor id="50">competition</governor>
          <dependent id="49">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="45">mark</governor>
          <dependent id="50">competition</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="46" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="Canadian" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="36" string="Canadian" />
          </tokens>
        </entity>
        <entity id="3" string="Once" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="Once" />
          </tokens>
        </entity>
        <entity id="4" string="Hamilton Spectator Indoor Games" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="30" string="Hamilton" />
            <token id="31" string="Spectator" />
            <token id="32" string="Indoor" />
            <token id="33" string="Games" />
          </tokens>
        </entity>
        <entity id="5" string="Paul Gaines" type="PERSON" score="0.0">
          <tokens>
            <token id="22" string="Paul" />
            <token id="23" string="Gaines" />
          </tokens>
        </entity>
        <entity id="6" string="Jan. 11" type="DATE" score="0.0">
          <tokens>
            <token id="41" string="Jan." />
            <token id="42" string="11" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>&amp;quot;I think that is the attitude the public will display.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="think" lemma="think" stem="think" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="attitude" lemma="attitude" stem="attitud" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="9" string="public" lemma="public" stem="public" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="10" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="display" lemma="display" stem="displai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (VBP think) (SBAR (S (NP (DT that)) (VP (VBZ is) (NP (NP (DT the) (NN attitude)) (SBAR (S (NP (DT the) (NN public)) (VP (MD will) (VP (VB display)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="think that is the attitude the public will display" type="VP">
          <tokens>
            <token id="3" string="think" />
            <token id="4" string="that" />
            <token id="5" string="is" />
            <token id="6" string="the" />
            <token id="7" string="attitude" />
            <token id="8" string="the" />
            <token id="9" string="public" />
            <token id="10" string="will" />
            <token id="11" string="display" />
          </tokens>
        </chunking>
        <chunking id="2" string="that" type="NP">
          <tokens>
            <token id="4" string="that" />
          </tokens>
        </chunking>
        <chunking id="3" string="the attitude the public will display" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="attitude" />
            <token id="8" string="the" />
            <token id="9" string="public" />
            <token id="10" string="will" />
            <token id="11" string="display" />
          </tokens>
        </chunking>
        <chunking id="4" string="that is the attitude the public will display" type="SBAR">
          <tokens>
            <token id="4" string="that" />
            <token id="5" string="is" />
            <token id="6" string="the" />
            <token id="7" string="attitude" />
            <token id="8" string="the" />
            <token id="9" string="public" />
            <token id="10" string="will" />
            <token id="11" string="display" />
          </tokens>
        </chunking>
        <chunking id="5" string="display" type="VP">
          <tokens>
            <token id="11" string="display" />
          </tokens>
        </chunking>
        <chunking id="6" string="will display" type="VP">
          <tokens>
            <token id="10" string="will" />
            <token id="11" string="display" />
          </tokens>
        </chunking>
        <chunking id="7" string="the public" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="public" />
          </tokens>
        </chunking>
        <chunking id="8" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="9" string="the public will display" type="SBAR">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="public" />
            <token id="10" string="will" />
            <token id="11" string="display" />
          </tokens>
        </chunking>
        <chunking id="10" string="is the attitude the public will display" type="VP">
          <tokens>
            <token id="5" string="is" />
            <token id="6" string="the" />
            <token id="7" string="attitude" />
            <token id="8" string="the" />
            <token id="9" string="public" />
            <token id="10" string="will" />
            <token id="11" string="display" />
          </tokens>
        </chunking>
        <chunking id="11" string="the attitude" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="attitude" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">think</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">think</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">attitude</governor>
          <dependent id="4">that</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">attitude</governor>
          <dependent id="5">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">attitude</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">think</governor>
          <dependent id="7">attitude</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">public</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">display</governor>
          <dependent id="9">public</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">display</governor>
          <dependent id="10">will</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="7">attitude</governor>
          <dependent id="11">display</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>You hear grumblings among media types and in some circles of the sport, but you have to give the guy the benefit of the doubt.</content>
      <tokens>
        <token id="1" string="You" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="hear" lemma="hear" stem="hear" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="grumblings" lemma="grumbling" stem="grumbl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="among" lemma="among" stem="among" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="media" lemma="media" stem="media" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="types" lemma="type" stem="type" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="circles" lemma="circle" stem="circl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="sport" lemma="sport" stem="sport" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="give" lemma="give" stem="give" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="guy" lemma="guy" stem="gui" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="benefit" lemma="benefit" stem="benefit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="doubt" lemma="doubt" stem="doubt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP You)) (VP (VBP hear) (NP (NNS grumblings)) (PP (PP (IN among) (NP (NNS media) (NNS types))) (CC and) (PP (IN in) (NP (NP (DT some) (NNS circles)) (PP (IN of) (NP (DT the) (NN sport)))))))) (, ,) (CC but) (S (NP (PRP you)) (VP (VBP have) (S (VP (TO to) (VP (VB give) (NP (DT the) (NN guy)) (NP (NP (DT the) (NN benefit)) (PP (IN of) (NP (DT the) (NN doubt))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="some circles of the sport" type="NP">
          <tokens>
            <token id="9" string="some" />
            <token id="10" string="circles" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="sport" />
          </tokens>
        </chunking>
        <chunking id="2" string="hear grumblings among media types and in some circles of the sport" type="VP">
          <tokens>
            <token id="2" string="hear" />
            <token id="3" string="grumblings" />
            <token id="4" string="among" />
            <token id="5" string="media" />
            <token id="6" string="types" />
            <token id="7" string="and" />
            <token id="8" string="in" />
            <token id="9" string="some" />
            <token id="10" string="circles" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="sport" />
          </tokens>
        </chunking>
        <chunking id="3" string="to give the guy the benefit of the doubt" type="VP">
          <tokens>
            <token id="18" string="to" />
            <token id="19" string="give" />
            <token id="20" string="the" />
            <token id="21" string="guy" />
            <token id="22" string="the" />
            <token id="23" string="benefit" />
            <token id="24" string="of" />
            <token id="25" string="the" />
            <token id="26" string="doubt" />
          </tokens>
        </chunking>
        <chunking id="4" string="grumblings" type="NP">
          <tokens>
            <token id="3" string="grumblings" />
          </tokens>
        </chunking>
        <chunking id="5" string="the benefit of the doubt" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="benefit" />
            <token id="24" string="of" />
            <token id="25" string="the" />
            <token id="26" string="doubt" />
          </tokens>
        </chunking>
        <chunking id="6" string="have to give the guy the benefit of the doubt" type="VP">
          <tokens>
            <token id="17" string="have" />
            <token id="18" string="to" />
            <token id="19" string="give" />
            <token id="20" string="the" />
            <token id="21" string="guy" />
            <token id="22" string="the" />
            <token id="23" string="benefit" />
            <token id="24" string="of" />
            <token id="25" string="the" />
            <token id="26" string="doubt" />
          </tokens>
        </chunking>
        <chunking id="7" string="the doubt" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="doubt" />
          </tokens>
        </chunking>
        <chunking id="8" string="give the guy the benefit of the doubt" type="VP">
          <tokens>
            <token id="19" string="give" />
            <token id="20" string="the" />
            <token id="21" string="guy" />
            <token id="22" string="the" />
            <token id="23" string="benefit" />
            <token id="24" string="of" />
            <token id="25" string="the" />
            <token id="26" string="doubt" />
          </tokens>
        </chunking>
        <chunking id="9" string="the guy" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="guy" />
          </tokens>
        </chunking>
        <chunking id="10" string="the benefit" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="benefit" />
          </tokens>
        </chunking>
        <chunking id="11" string="the sport" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="sport" />
          </tokens>
        </chunking>
        <chunking id="12" string="some circles" type="NP">
          <tokens>
            <token id="9" string="some" />
            <token id="10" string="circles" />
          </tokens>
        </chunking>
        <chunking id="13" string="You" type="NP">
          <tokens>
            <token id="1" string="You" />
          </tokens>
        </chunking>
        <chunking id="14" string="media types" type="NP">
          <tokens>
            <token id="5" string="media" />
            <token id="6" string="types" />
          </tokens>
        </chunking>
        <chunking id="15" string="you" type="NP">
          <tokens>
            <token id="16" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">hear</governor>
          <dependent id="1">You</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">hear</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">hear</governor>
          <dependent id="2">hear</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">hear</governor>
          <dependent id="3">grumblings</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">types</governor>
          <dependent id="4">among</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">types</governor>
          <dependent id="5">media</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">hear</governor>
          <dependent id="6">types</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">hear</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">circles</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">circles</governor>
          <dependent id="9">some</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">hear</governor>
          <dependent id="10">circles</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">sport</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">sport</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">circles</governor>
          <dependent id="13">sport</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">hear</governor>
          <dependent id="15">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">have</governor>
          <dependent id="16">you</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">hear</governor>
          <dependent id="17">have</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">give</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="17">have</governor>
          <dependent id="19">give</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">guy</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="iobj">
          <governor id="19">give</governor>
          <dependent id="21">guy</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">benefit</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">give</governor>
          <dependent id="23">benefit</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">doubt</governor>
          <dependent id="24">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">doubt</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">benefit</governor>
          <dependent id="26">doubt</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>&amp;quot;When this happened, it was a bitter disappointment for everyone in the sport to acknowledge that the No. 1 athlete in the sport was using drugs.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="When" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="happened" lemma="happen" stem="happen" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="bitter" lemma="bitter" stem="bitter" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="disappointment" lemma="disappointment" stem="disappoint" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="everyone" lemma="everyone" stem="everyon" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="sport" lemma="sport" stem="sport" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="acknowledge" lemma="acknowledge" stem="acknowledg" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="No." lemma="no." stem="no." pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="1" lemma="1" stem="1" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="22" string="athlete" lemma="athlete" stem="athlet" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="25" string="sport" lemma="sport" stem="sport" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="26" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="27" string="using" lemma="use" stem="us" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="28" string="drugs" lemma="drug" stem="drug" pos="NNS" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="true" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (SBAR (WHADVP (WRB When)) (S (NP (DT this)) (VP (VBD happened)))) (, ,) (NP (PRP it)) (VP (VBD was) (NP (NP (DT a) (JJ bitter) (NN disappointment)) (PP (IN for) (NP (NP (NN everyone)) (PP (IN in) (NP (DT the) (NN sport) (S (VP (TO to) (VP (VB acknowledge) (SBAR (IN that) (S (NP (NP (DT the) (NN No.) (CD 1) (NN athlete)) (PP (IN in) (NP (DT the) (NN sport)))) (VP (VBD was) (VP (VBG using) (NP (NNS drugs))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="to acknowledge that the No. 1 athlete in the sport was using drugs" type="VP">
          <tokens>
            <token id="16" string="to" />
            <token id="17" string="acknowledge" />
            <token id="18" string="that" />
            <token id="19" string="the" />
            <token id="20" string="No." />
            <token id="21" string="1" />
            <token id="22" string="athlete" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="sport" />
            <token id="26" string="was" />
            <token id="27" string="using" />
            <token id="28" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="2" string="the No. 1 athlete in the sport" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="No." />
            <token id="21" string="1" />
            <token id="22" string="athlete" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="sport" />
          </tokens>
        </chunking>
        <chunking id="3" string="everyone" type="NP">
          <tokens>
            <token id="12" string="everyone" />
          </tokens>
        </chunking>
        <chunking id="4" string="drugs" type="NP">
          <tokens>
            <token id="28" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="5" string="When this happened" type="SBAR">
          <tokens>
            <token id="2" string="When" />
            <token id="3" string="this" />
            <token id="4" string="happened" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="6" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="the sport to acknowledge that the No. 1 athlete in the sport was using drugs" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="sport" />
            <token id="16" string="to" />
            <token id="17" string="acknowledge" />
            <token id="18" string="that" />
            <token id="19" string="the" />
            <token id="20" string="No." />
            <token id="21" string="1" />
            <token id="22" string="athlete" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="sport" />
            <token id="26" string="was" />
            <token id="27" string="using" />
            <token id="28" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="8" string="this" type="NP">
          <tokens>
            <token id="3" string="this" />
          </tokens>
        </chunking>
        <chunking id="9" string="acknowledge that the No. 1 athlete in the sport was using drugs" type="VP">
          <tokens>
            <token id="17" string="acknowledge" />
            <token id="18" string="that" />
            <token id="19" string="the" />
            <token id="20" string="No." />
            <token id="21" string="1" />
            <token id="22" string="athlete" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="sport" />
            <token id="26" string="was" />
            <token id="27" string="using" />
            <token id="28" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="10" string="happened" type="VP">
          <tokens>
            <token id="4" string="happened" />
          </tokens>
        </chunking>
        <chunking id="11" string="When" type="WHADVP">
          <tokens>
            <token id="2" string="When" />
          </tokens>
        </chunking>
        <chunking id="12" string="a bitter disappointment for everyone in the sport to acknowledge that the No. 1 athlete in the sport was using drugs" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="bitter" />
            <token id="10" string="disappointment" />
            <token id="11" string="for" />
            <token id="12" string="everyone" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="sport" />
            <token id="16" string="to" />
            <token id="17" string="acknowledge" />
            <token id="18" string="that" />
            <token id="19" string="the" />
            <token id="20" string="No." />
            <token id="21" string="1" />
            <token id="22" string="athlete" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="sport" />
            <token id="26" string="was" />
            <token id="27" string="using" />
            <token id="28" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="13" string="the sport" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="sport" />
          </tokens>
        </chunking>
        <chunking id="14" string="a bitter disappointment" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="bitter" />
            <token id="10" string="disappointment" />
          </tokens>
        </chunking>
        <chunking id="15" string="everyone in the sport to acknowledge that the No. 1 athlete in the sport was using drugs" type="NP">
          <tokens>
            <token id="12" string="everyone" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="sport" />
            <token id="16" string="to" />
            <token id="17" string="acknowledge" />
            <token id="18" string="that" />
            <token id="19" string="the" />
            <token id="20" string="No." />
            <token id="21" string="1" />
            <token id="22" string="athlete" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="sport" />
            <token id="26" string="was" />
            <token id="27" string="using" />
            <token id="28" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="16" string="that the No. 1 athlete in the sport was using drugs" type="SBAR">
          <tokens>
            <token id="18" string="that" />
            <token id="19" string="the" />
            <token id="20" string="No." />
            <token id="21" string="1" />
            <token id="22" string="athlete" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="sport" />
            <token id="26" string="was" />
            <token id="27" string="using" />
            <token id="28" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="17" string="the No. 1 athlete" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="No." />
            <token id="21" string="1" />
            <token id="22" string="athlete" />
          </tokens>
        </chunking>
        <chunking id="18" string="was a bitter disappointment for everyone in the sport to acknowledge that the No. 1 athlete in the sport was using drugs" type="VP">
          <tokens>
            <token id="7" string="was" />
            <token id="8" string="a" />
            <token id="9" string="bitter" />
            <token id="10" string="disappointment" />
            <token id="11" string="for" />
            <token id="12" string="everyone" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="sport" />
            <token id="16" string="to" />
            <token id="17" string="acknowledge" />
            <token id="18" string="that" />
            <token id="19" string="the" />
            <token id="20" string="No." />
            <token id="21" string="1" />
            <token id="22" string="athlete" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="sport" />
            <token id="26" string="was" />
            <token id="27" string="using" />
            <token id="28" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="19" string="using drugs" type="VP">
          <tokens>
            <token id="27" string="using" />
            <token id="28" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="20" string="was using drugs" type="VP">
          <tokens>
            <token id="26" string="was" />
            <token id="27" string="using" />
            <token id="28" string="drugs" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="4">happened</governor>
          <dependent id="2">When</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">happened</governor>
          <dependent id="3">this</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="10">disappointment</governor>
          <dependent id="4">happened</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">disappointment</governor>
          <dependent id="6">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="10">disappointment</governor>
          <dependent id="7">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">disappointment</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">disappointment</governor>
          <dependent id="9">bitter</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">disappointment</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">everyone</governor>
          <dependent id="11">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">disappointment</governor>
          <dependent id="12">everyone</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">sport</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">sport</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">everyone</governor>
          <dependent id="15">sport</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">acknowledge</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="15">sport</governor>
          <dependent id="17">acknowledge</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="27">using</governor>
          <dependent id="18">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">athlete</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">athlete</governor>
          <dependent id="20">No.</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="22">athlete</governor>
          <dependent id="21">1</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">using</governor>
          <dependent id="22">athlete</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">sport</governor>
          <dependent id="23">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">sport</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">athlete</governor>
          <dependent id="25">sport</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="27">using</governor>
          <dependent id="26">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">acknowledge</governor>
          <dependent id="27">using</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="27">using</governor>
          <dependent id="28">drugs</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1" type="NUMBER" score="0.0">
          <tokens>
            <token id="21" string="1" />
          </tokens>
        </entity>
        <entity id="2" string="drugs" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="28" string="drugs" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>With the accolades cast upon him in the previous years, people were resentful.</content>
      <tokens>
        <token id="1" string="With" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="accolades" lemma="accolade" stem="accolad" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="cast" lemma="cast" stem="cast" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="upon" lemma="upon" stem="upon" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="9" string="previous" lemma="previous" stem="previou" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="10" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="resentful" lemma="resentful" stem="resent" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN With) (NP (NP (DT the) (NNS accolades)) (VP (VBN cast) (PP (IN upon) (NP (PRP him))) (PP (IN in) (NP (DT the) (JJ previous) (NNS years)))))) (, ,) (NP (NNS people)) (VP (VBD were) (ADJP (JJ resentful))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the previous years" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="previous" />
            <token id="10" string="years" />
          </tokens>
        </chunking>
        <chunking id="2" string="the accolades" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="accolades" />
          </tokens>
        </chunking>
        <chunking id="3" string="cast upon him in the previous years" type="VP">
          <tokens>
            <token id="4" string="cast" />
            <token id="5" string="upon" />
            <token id="6" string="him" />
            <token id="7" string="in" />
            <token id="8" string="the" />
            <token id="9" string="previous" />
            <token id="10" string="years" />
          </tokens>
        </chunking>
        <chunking id="4" string="him" type="NP">
          <tokens>
            <token id="6" string="him" />
          </tokens>
        </chunking>
        <chunking id="5" string="the accolades cast upon him in the previous years" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="accolades" />
            <token id="4" string="cast" />
            <token id="5" string="upon" />
            <token id="6" string="him" />
            <token id="7" string="in" />
            <token id="8" string="the" />
            <token id="9" string="previous" />
            <token id="10" string="years" />
          </tokens>
        </chunking>
        <chunking id="6" string="were resentful" type="VP">
          <tokens>
            <token id="13" string="were" />
            <token id="14" string="resentful" />
          </tokens>
        </chunking>
        <chunking id="7" string="resentful" type="ADJP">
          <tokens>
            <token id="14" string="resentful" />
          </tokens>
        </chunking>
        <chunking id="8" string="people" type="NP">
          <tokens>
            <token id="12" string="people" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">accolades</governor>
          <dependent id="1">With</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">accolades</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">resentful</governor>
          <dependent id="3">accolades</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="3">accolades</governor>
          <dependent id="4">cast</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">him</governor>
          <dependent id="5">upon</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">cast</governor>
          <dependent id="6">him</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">years</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">years</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">years</governor>
          <dependent id="9">previous</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">cast</governor>
          <dependent id="10">years</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">resentful</governor>
          <dependent id="12">people</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">resentful</governor>
          <dependent id="13">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">resentful</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="the previous years" type="DATE" score="0.0">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="previous" />
            <token id="10" string="years" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>With the humility and shame that has been reflected on him, people tend to be more open minded about it.</content>
      <tokens>
        <token id="1" string="With" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="humility" lemma="humility" stem="humil" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="shame" lemma="shame" stem="shame" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="reflected" lemma="reflect" stem="reflect" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="tend" lemma="tend" stem="tend" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="open" lemma="open" stem="open" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="minded" lemma="mind" stem="mind" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN With) (NP (NP (DT the) (NN humility) (CC and) (NN shame)) (SBAR (WHNP (WDT that)) (S (VP (VBZ has) (VP (VBN been) (VP (VBN reflected) (PP (IN on) (NP (PRP him)))))))))) (, ,) (NP (NNS people)) (VP (VBP tend) (S (VP (TO to) (VP (VB be) (ADJP (RBR more) (JJ open)) (PP (VBN minded) (PP (IN about) (NP (PRP it)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the humility and shame that has been reflected on him" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="humility" />
            <token id="4" string="and" />
            <token id="5" string="shame" />
            <token id="6" string="that" />
            <token id="7" string="has" />
            <token id="8" string="been" />
            <token id="9" string="reflected" />
            <token id="10" string="on" />
            <token id="11" string="him" />
          </tokens>
        </chunking>
        <chunking id="2" string="the humility and shame" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="humility" />
            <token id="4" string="and" />
            <token id="5" string="shame" />
          </tokens>
        </chunking>
        <chunking id="3" string="has been reflected on him" type="VP">
          <tokens>
            <token id="7" string="has" />
            <token id="8" string="been" />
            <token id="9" string="reflected" />
            <token id="10" string="on" />
            <token id="11" string="him" />
          </tokens>
        </chunking>
        <chunking id="4" string="that has been reflected on him" type="SBAR">
          <tokens>
            <token id="6" string="that" />
            <token id="7" string="has" />
            <token id="8" string="been" />
            <token id="9" string="reflected" />
            <token id="10" string="on" />
            <token id="11" string="him" />
          </tokens>
        </chunking>
        <chunking id="5" string="more open" type="ADJP">
          <tokens>
            <token id="17" string="more" />
            <token id="18" string="open" />
          </tokens>
        </chunking>
        <chunking id="6" string="him" type="NP">
          <tokens>
            <token id="11" string="him" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="21" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="been reflected on him" type="VP">
          <tokens>
            <token id="8" string="been" />
            <token id="9" string="reflected" />
            <token id="10" string="on" />
            <token id="11" string="him" />
          </tokens>
        </chunking>
        <chunking id="9" string="people" type="NP">
          <tokens>
            <token id="13" string="people" />
          </tokens>
        </chunking>
        <chunking id="10" string="to be more open minded about it" type="VP">
          <tokens>
            <token id="15" string="to" />
            <token id="16" string="be" />
            <token id="17" string="more" />
            <token id="18" string="open" />
            <token id="19" string="minded" />
            <token id="20" string="about" />
            <token id="21" string="it" />
          </tokens>
        </chunking>
        <chunking id="11" string="reflected on him" type="VP">
          <tokens>
            <token id="9" string="reflected" />
            <token id="10" string="on" />
            <token id="11" string="him" />
          </tokens>
        </chunking>
        <chunking id="12" string="tend to be more open minded about it" type="VP">
          <tokens>
            <token id="14" string="tend" />
            <token id="15" string="to" />
            <token id="16" string="be" />
            <token id="17" string="more" />
            <token id="18" string="open" />
            <token id="19" string="minded" />
            <token id="20" string="about" />
            <token id="21" string="it" />
          </tokens>
        </chunking>
        <chunking id="13" string="be more open minded about it" type="VP">
          <tokens>
            <token id="16" string="be" />
            <token id="17" string="more" />
            <token id="18" string="open" />
            <token id="19" string="minded" />
            <token id="20" string="about" />
            <token id="21" string="it" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">humility</governor>
          <dependent id="1">With</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">humility</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">tend</governor>
          <dependent id="3">humility</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">humility</governor>
          <dependent id="4">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">humility</governor>
          <dependent id="5">shame</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="9">reflected</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">reflected</governor>
          <dependent id="7">has</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="9">reflected</governor>
          <dependent id="8">been</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="3">humility</governor>
          <dependent id="9">reflected</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">him</governor>
          <dependent id="10">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">reflected</governor>
          <dependent id="11">him</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">tend</governor>
          <dependent id="13">people</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">tend</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">open</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="18">open</governor>
          <dependent id="16">be</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">open</governor>
          <dependent id="17">more</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="14">tend</governor>
          <dependent id="18">open</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">it</governor>
          <dependent id="19">minded</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">it</governor>
          <dependent id="20">about</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="18">open</governor>
          <dependent id="21">it</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>They hope the guy comes back clean and fast.&amp;quot;</content>
      <tokens>
        <token id="1" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="hope" lemma="hope" stem="hope" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="guy" lemma="guy" stem="gui" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="comes" lemma="come" stem="come" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="back" lemma="back" stem="back" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="clean" lemma="clean" stem="clean" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="fast" lemma="fast" stem="fast" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP They)) (VP (VBP hope) (SBAR (S (NP (DT the) (NN guy)) (VP (VBZ comes) (ADJP (RB back) (JJ clean) (CC and) (JJ fast)))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="1" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="the guy comes back clean and fast" type="SBAR">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="guy" />
            <token id="5" string="comes" />
            <token id="6" string="back" />
            <token id="7" string="clean" />
            <token id="8" string="and" />
            <token id="9" string="fast" />
          </tokens>
        </chunking>
        <chunking id="3" string="the guy" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="guy" />
          </tokens>
        </chunking>
        <chunking id="4" string="hope the guy comes back clean and fast" type="VP">
          <tokens>
            <token id="2" string="hope" />
            <token id="3" string="the" />
            <token id="4" string="guy" />
            <token id="5" string="comes" />
            <token id="6" string="back" />
            <token id="7" string="clean" />
            <token id="8" string="and" />
            <token id="9" string="fast" />
          </tokens>
        </chunking>
        <chunking id="5" string="back clean and fast" type="ADJP">
          <tokens>
            <token id="6" string="back" />
            <token id="7" string="clean" />
            <token id="8" string="and" />
            <token id="9" string="fast" />
          </tokens>
        </chunking>
        <chunking id="6" string="comes back clean and fast" type="VP">
          <tokens>
            <token id="5" string="comes" />
            <token id="6" string="back" />
            <token id="7" string="clean" />
            <token id="8" string="and" />
            <token id="9" string="fast" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">hope</governor>
          <dependent id="1">They</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">hope</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">guy</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">comes</governor>
          <dependent id="4">guy</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">hope</governor>
          <dependent id="5">comes</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">clean</governor>
          <dependent id="6">back</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">comes</governor>
          <dependent id="7">clean</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">clean</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">clean</governor>
          <dependent id="9">fast</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="21" has_coreference="false">
      <content>Clean and fast.</content>
      <tokens>
        <token id="1" string="Clean" lemma="clean" stem="clean" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="fast" lemma="fast" stem="fast" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (FRAG (ADJP (JJ Clean) (CC and) (JJ fast)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Clean and fast" type="ADJP">
          <tokens>
            <token id="1" string="Clean" />
            <token id="2" string="and" />
            <token id="3" string="fast" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">Clean</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="1">Clean</governor>
          <dependent id="2">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="1">Clean</governor>
          <dependent id="3">fast</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="22" has_coreference="false">
      <content>To some in track and field that represents a contradiction in terms.</content>
      <tokens>
        <token id="1" string="To" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="track" lemma="track" stem="track" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="field" lemma="field" stem="field" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="represents" lemma="represent" stem="repres" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="contradiction" lemma="contradiction" stem="contradict" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="terms" lemma="term" stem="term" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (TO To) (NP (NP (DT some)) (PP (IN in) (NP (NN track) (CC and) (NN field))))) (NP (WDT that)) (VP (VBZ represents) (NP (NP (DT a) (NN contradiction)) (PP (IN in) (NP (NNS terms))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that" type="NP">
          <tokens>
            <token id="7" string="that" />
          </tokens>
        </chunking>
        <chunking id="2" string="some in track and field" type="NP">
          <tokens>
            <token id="2" string="some" />
            <token id="3" string="in" />
            <token id="4" string="track" />
            <token id="5" string="and" />
            <token id="6" string="field" />
          </tokens>
        </chunking>
        <chunking id="3" string="represents a contradiction in terms" type="VP">
          <tokens>
            <token id="8" string="represents" />
            <token id="9" string="a" />
            <token id="10" string="contradiction" />
            <token id="11" string="in" />
            <token id="12" string="terms" />
          </tokens>
        </chunking>
        <chunking id="4" string="terms" type="NP">
          <tokens>
            <token id="12" string="terms" />
          </tokens>
        </chunking>
        <chunking id="5" string="a contradiction in terms" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="contradiction" />
            <token id="11" string="in" />
            <token id="12" string="terms" />
          </tokens>
        </chunking>
        <chunking id="6" string="some" type="NP">
          <tokens>
            <token id="2" string="some" />
          </tokens>
        </chunking>
        <chunking id="7" string="a contradiction" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="contradiction" />
          </tokens>
        </chunking>
        <chunking id="8" string="track and field" type="NP">
          <tokens>
            <token id="4" string="track" />
            <token id="5" string="and" />
            <token id="6" string="field" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">some</governor>
          <dependent id="1">To</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">represents</governor>
          <dependent id="2">some</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">track</governor>
          <dependent id="3">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">some</governor>
          <dependent id="4">track</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">track</governor>
          <dependent id="5">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">track</governor>
          <dependent id="6">field</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">represents</governor>
          <dependent id="7">that</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">represents</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">contradiction</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">represents</governor>
          <dependent id="10">contradiction</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">terms</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">contradiction</governor>
          <dependent id="12">terms</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>It is this apparent contradiction that Ben Johnson must overcome in his comeback.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="apparent" lemma="apparent" stem="appar" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="contradiction" lemma="contradiction" stem="contradict" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Ben" lemma="Ben" stem="ben" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="8" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="9" string="must" lemma="must" stem="must" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="overcome" lemma="overcome" stem="overcom" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="comeback" lemma="comeback" stem="comeback" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBZ is) (NP (NP (DT this) (JJ apparent) (NN contradiction)) (SBAR (WHNP (WDT that)) (S (NP (NNP Ben) (NNP Johnson)) (VP (MD must) (VP (VB overcome) (PP (IN in) (NP (PRP$ his) (NN comeback))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Ben Johnson" type="NP">
          <tokens>
            <token id="7" string="Ben" />
            <token id="8" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="2" string="his comeback" type="NP">
          <tokens>
            <token id="12" string="his" />
            <token id="13" string="comeback" />
          </tokens>
        </chunking>
        <chunking id="3" string="is this apparent contradiction that Ben Johnson must overcome in his comeback" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="this" />
            <token id="4" string="apparent" />
            <token id="5" string="contradiction" />
            <token id="6" string="that" />
            <token id="7" string="Ben" />
            <token id="8" string="Johnson" />
            <token id="9" string="must" />
            <token id="10" string="overcome" />
            <token id="11" string="in" />
            <token id="12" string="his" />
            <token id="13" string="comeback" />
          </tokens>
        </chunking>
        <chunking id="4" string="this apparent contradiction" type="NP">
          <tokens>
            <token id="3" string="this" />
            <token id="4" string="apparent" />
            <token id="5" string="contradiction" />
          </tokens>
        </chunking>
        <chunking id="5" string="that Ben Johnson must overcome in his comeback" type="SBAR">
          <tokens>
            <token id="6" string="that" />
            <token id="7" string="Ben" />
            <token id="8" string="Johnson" />
            <token id="9" string="must" />
            <token id="10" string="overcome" />
            <token id="11" string="in" />
            <token id="12" string="his" />
            <token id="13" string="comeback" />
          </tokens>
        </chunking>
        <chunking id="6" string="overcome in his comeback" type="VP">
          <tokens>
            <token id="10" string="overcome" />
            <token id="11" string="in" />
            <token id="12" string="his" />
            <token id="13" string="comeback" />
          </tokens>
        </chunking>
        <chunking id="7" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="8" string="this apparent contradiction that Ben Johnson must overcome in his comeback" type="NP">
          <tokens>
            <token id="3" string="this" />
            <token id="4" string="apparent" />
            <token id="5" string="contradiction" />
            <token id="6" string="that" />
            <token id="7" string="Ben" />
            <token id="8" string="Johnson" />
            <token id="9" string="must" />
            <token id="10" string="overcome" />
            <token id="11" string="in" />
            <token id="12" string="his" />
            <token id="13" string="comeback" />
          </tokens>
        </chunking>
        <chunking id="9" string="must overcome in his comeback" type="VP">
          <tokens>
            <token id="9" string="must" />
            <token id="10" string="overcome" />
            <token id="11" string="in" />
            <token id="12" string="his" />
            <token id="13" string="comeback" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">contradiction</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">contradiction</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">contradiction</governor>
          <dependent id="3">this</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">contradiction</governor>
          <dependent id="4">apparent</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">contradiction</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">overcome</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Johnson</governor>
          <dependent id="7">Ben</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">overcome</governor>
          <dependent id="8">Johnson</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">overcome</governor>
          <dependent id="9">must</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="5">contradiction</governor>
          <dependent id="10">overcome</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">comeback</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">comeback</governor>
          <dependent id="12">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">overcome</governor>
          <dependent id="13">comeback</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ben Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Ben" />
            <token id="8" string="Johnson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>Charlie Francis, who coached Johnson for 12 years, estimated that steroids made Johnson faster by one meter.</content>
      <tokens>
        <token id="1" string="Charlie" lemma="Charlie" stem="charli" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Francis" lemma="Francis" stem="franci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="coached" lemma="coach" stem="coach" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="7" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="12" lemma="12" stem="12" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="9" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="estimated" lemma="estimate" stem="estim" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="steroids" lemma="steroid" stem="steroid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="made" lemma="make" stem="made" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="16" string="faster" lemma="faster" stem="faster" pos="RBR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="19" string="meter" lemma="meter" stem="meter" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Charlie) (NNP Francis)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD coached) (NP (NP (NNP Johnson)) (PP (IN for) (NP (CD 12) (NNS years))))))) (, ,)) (VP (VBD estimated) (SBAR (IN that) (S (NP (NNS steroids)) (VP (VBN made) (PP (ADVP (NP (NNP Johnson)) (RBR faster)) (IN by) (NP (CD one) (NN meter))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Johnson" type="NP">
          <tokens>
            <token id="6" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="2" string="12 years" type="NP">
          <tokens>
            <token id="8" string="12" />
            <token id="9" string="years" />
          </tokens>
        </chunking>
        <chunking id="3" string="one meter" type="NP">
          <tokens>
            <token id="18" string="one" />
            <token id="19" string="meter" />
          </tokens>
        </chunking>
        <chunking id="4" string="coached Johnson for 12 years" type="VP">
          <tokens>
            <token id="5" string="coached" />
            <token id="6" string="Johnson" />
            <token id="7" string="for" />
            <token id="8" string="12" />
            <token id="9" string="years" />
          </tokens>
        </chunking>
        <chunking id="5" string="estimated that steroids made Johnson faster by one meter" type="VP">
          <tokens>
            <token id="11" string="estimated" />
            <token id="12" string="that" />
            <token id="13" string="steroids" />
            <token id="14" string="made" />
            <token id="15" string="Johnson" />
            <token id="16" string="faster" />
            <token id="17" string="by" />
            <token id="18" string="one" />
            <token id="19" string="meter" />
          </tokens>
        </chunking>
        <chunking id="6" string="made Johnson faster by one meter" type="VP">
          <tokens>
            <token id="14" string="made" />
            <token id="15" string="Johnson" />
            <token id="16" string="faster" />
            <token id="17" string="by" />
            <token id="18" string="one" />
            <token id="19" string="meter" />
          </tokens>
        </chunking>
        <chunking id="7" string="Charlie Francis" type="NP">
          <tokens>
            <token id="1" string="Charlie" />
            <token id="2" string="Francis" />
          </tokens>
        </chunking>
        <chunking id="8" string="who coached Johnson for 12 years" type="SBAR">
          <tokens>
            <token id="4" string="who" />
            <token id="5" string="coached" />
            <token id="6" string="Johnson" />
            <token id="7" string="for" />
            <token id="8" string="12" />
            <token id="9" string="years" />
          </tokens>
        </chunking>
        <chunking id="9" string="steroids" type="NP">
          <tokens>
            <token id="13" string="steroids" />
          </tokens>
        </chunking>
        <chunking id="10" string="Charlie Francis , who coached Johnson for 12 years ," type="NP">
          <tokens>
            <token id="1" string="Charlie" />
            <token id="2" string="Francis" />
            <token id="3" string="," />
            <token id="4" string="who" />
            <token id="5" string="coached" />
            <token id="6" string="Johnson" />
            <token id="7" string="for" />
            <token id="8" string="12" />
            <token id="9" string="years" />
            <token id="10" string="," />
          </tokens>
        </chunking>
        <chunking id="11" string="that steroids made Johnson faster by one meter" type="SBAR">
          <tokens>
            <token id="12" string="that" />
            <token id="13" string="steroids" />
            <token id="14" string="made" />
            <token id="15" string="Johnson" />
            <token id="16" string="faster" />
            <token id="17" string="by" />
            <token id="18" string="one" />
            <token id="19" string="meter" />
          </tokens>
        </chunking>
        <chunking id="12" string="Johnson for 12 years" type="NP">
          <tokens>
            <token id="6" string="Johnson" />
            <token id="7" string="for" />
            <token id="8" string="12" />
            <token id="9" string="years" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Francis</governor>
          <dependent id="1">Charlie</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">estimated</governor>
          <dependent id="2">Francis</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">coached</governor>
          <dependent id="4">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="2">Francis</governor>
          <dependent id="5">coached</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">coached</governor>
          <dependent id="6">Johnson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">years</governor>
          <dependent id="7">for</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="9">years</governor>
          <dependent id="8">12</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">Johnson</governor>
          <dependent id="9">years</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">estimated</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">made</governor>
          <dependent id="12">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">made</governor>
          <dependent id="13">steroids</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">estimated</governor>
          <dependent id="14">made</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="16">faster</governor>
          <dependent id="15">Johnson</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">meter</governor>
          <dependent id="16">faster</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">meter</governor>
          <dependent id="17">by</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="19">meter</governor>
          <dependent id="18">one</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">made</governor>
          <dependent id="19">meter</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="12 years" type="DURATION" score="0.0">
          <tokens>
            <token id="8" string="12" />
            <token id="9" string="years" />
          </tokens>
        </entity>
        <entity id="3" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="18" string="one" />
          </tokens>
        </entity>
        <entity id="4" string="Charlie Francis" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Charlie" />
            <token id="2" string="Francis" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>How much ground will Johnson lose as a drug-free sprinter?</content>
      <tokens>
        <token id="1" string="How" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="much" lemma="much" stem="much" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="ground" lemma="ground" stem="ground" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="6" string="lose" lemma="lose" stem="lose" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="drug-free" lemma="drug-free" stem="drug-fre" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="sprinter" lemma="sprinter" stem="sprinter" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SBARQ (WHNP (WHADJP (WRB How) (JJ much)) (NN ground)) (SQ (MD will) (NP (NNP Johnson)) (VP (VB lose) (PP (IN as) (NP (DT a) (JJ drug-free) (NN sprinter))))) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Johnson" type="NP">
          <tokens>
            <token id="5" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="2" string="lose as a drug-free sprinter" type="VP">
          <tokens>
            <token id="6" string="lose" />
            <token id="7" string="as" />
            <token id="8" string="a" />
            <token id="9" string="drug-free" />
            <token id="10" string="sprinter" />
          </tokens>
        </chunking>
        <chunking id="3" string="a drug-free sprinter" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="drug-free" />
            <token id="10" string="sprinter" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="2">much</governor>
          <dependent id="1">How</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">ground</governor>
          <dependent id="2">much</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">lose</governor>
          <dependent id="3">ground</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">lose</governor>
          <dependent id="4">will</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">lose</governor>
          <dependent id="5">Johnson</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">lose</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">sprinter</governor>
          <dependent id="7">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">sprinter</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">sprinter</governor>
          <dependent id="9">drug-free</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">lose</governor>
          <dependent id="10">sprinter</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Johnson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="26" has_coreference="true">
      <content>Johnson, speaking at a news conference in Castelfranco Veneto, Italy, expressed little doubt he can regain his form of 1988.</content>
      <tokens>
        <token id="1" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="speaking" lemma="speak" stem="speak" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="news" lemma="news" stem="new" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="conference" lemma="conference" stem="confer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Castelfranco" lemma="Castelfranco" stem="castelfranco" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="10" string="Veneto" lemma="Veneto" stem="veneto" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Italy" lemma="Italy" stem="itali" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="expressed" lemma="express" stem="express" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="little" lemma="little" stem="littl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="doubt" lemma="doubt" stem="doubt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="regain" lemma="regain" stem="regain" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="form" lemma="form" stem="form" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="1988" lemma="1988" stem="1988" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Johnson)) (, ,) (S (VP (VBG speaking) (PP (IN at) (NP (NP (DT a) (NN news) (NN conference)) (PP (IN in) (NP (NP (NNP Castelfranco) (NNP Veneto)) (, ,) (NP (NNP Italy)))))))) (, ,) (VP (VBD expressed) (NP (NP (JJ little) (NN doubt)) (SBAR (S (NP (PRP he)) (VP (MD can) (VP (VB regain) (NP (NP (PRP$ his) (NN form)) (PP (IN of) (NP (CD 1988)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="regain his form of 1988" type="VP">
          <tokens>
            <token id="19" string="regain" />
            <token id="20" string="his" />
            <token id="21" string="form" />
            <token id="22" string="of" />
            <token id="23" string="1988" />
          </tokens>
        </chunking>
        <chunking id="2" string="Johnson" type="NP">
          <tokens>
            <token id="1" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="3" string="a news conference in Castelfranco Veneto , Italy" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="news" />
            <token id="7" string="conference" />
            <token id="8" string="in" />
            <token id="9" string="Castelfranco" />
            <token id="10" string="Veneto" />
            <token id="11" string="," />
            <token id="12" string="Italy" />
          </tokens>
        </chunking>
        <chunking id="4" string="a news conference" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="news" />
            <token id="7" string="conference" />
          </tokens>
        </chunking>
        <chunking id="5" string="Castelfranco Veneto" type="NP">
          <tokens>
            <token id="9" string="Castelfranco" />
            <token id="10" string="Veneto" />
          </tokens>
        </chunking>
        <chunking id="6" string="his form" type="NP">
          <tokens>
            <token id="20" string="his" />
            <token id="21" string="form" />
          </tokens>
        </chunking>
        <chunking id="7" string="speaking at a news conference in Castelfranco Veneto , Italy" type="VP">
          <tokens>
            <token id="3" string="speaking" />
            <token id="4" string="at" />
            <token id="5" string="a" />
            <token id="6" string="news" />
            <token id="7" string="conference" />
            <token id="8" string="in" />
            <token id="9" string="Castelfranco" />
            <token id="10" string="Veneto" />
            <token id="11" string="," />
            <token id="12" string="Italy" />
          </tokens>
        </chunking>
        <chunking id="8" string="his form of 1988" type="NP">
          <tokens>
            <token id="20" string="his" />
            <token id="21" string="form" />
            <token id="22" string="of" />
            <token id="23" string="1988" />
          </tokens>
        </chunking>
        <chunking id="9" string="little doubt he can regain his form of 1988" type="NP">
          <tokens>
            <token id="15" string="little" />
            <token id="16" string="doubt" />
            <token id="17" string="he" />
            <token id="18" string="can" />
            <token id="19" string="regain" />
            <token id="20" string="his" />
            <token id="21" string="form" />
            <token id="22" string="of" />
            <token id="23" string="1988" />
          </tokens>
        </chunking>
        <chunking id="10" string="1988" type="NP">
          <tokens>
            <token id="23" string="1988" />
          </tokens>
        </chunking>
        <chunking id="11" string="Castelfranco Veneto , Italy" type="NP">
          <tokens>
            <token id="9" string="Castelfranco" />
            <token id="10" string="Veneto" />
            <token id="11" string="," />
            <token id="12" string="Italy" />
          </tokens>
        </chunking>
        <chunking id="12" string="expressed little doubt he can regain his form of 1988" type="VP">
          <tokens>
            <token id="14" string="expressed" />
            <token id="15" string="little" />
            <token id="16" string="doubt" />
            <token id="17" string="he" />
            <token id="18" string="can" />
            <token id="19" string="regain" />
            <token id="20" string="his" />
            <token id="21" string="form" />
            <token id="22" string="of" />
            <token id="23" string="1988" />
          </tokens>
        </chunking>
        <chunking id="13" string="can regain his form of 1988" type="VP">
          <tokens>
            <token id="18" string="can" />
            <token id="19" string="regain" />
            <token id="20" string="his" />
            <token id="21" string="form" />
            <token id="22" string="of" />
            <token id="23" string="1988" />
          </tokens>
        </chunking>
        <chunking id="14" string="Italy" type="NP">
          <tokens>
            <token id="12" string="Italy" />
          </tokens>
        </chunking>
        <chunking id="15" string="little doubt" type="NP">
          <tokens>
            <token id="15" string="little" />
            <token id="16" string="doubt" />
          </tokens>
        </chunking>
        <chunking id="16" string="he can regain his form of 1988" type="SBAR">
          <tokens>
            <token id="17" string="he" />
            <token id="18" string="can" />
            <token id="19" string="regain" />
            <token id="20" string="his" />
            <token id="21" string="form" />
            <token id="22" string="of" />
            <token id="23" string="1988" />
          </tokens>
        </chunking>
        <chunking id="17" string="he" type="NP">
          <tokens>
            <token id="17" string="he" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="14">expressed</governor>
          <dependent id="1">Johnson</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="14">expressed</governor>
          <dependent id="3">speaking</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">conference</governor>
          <dependent id="4">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">conference</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">conference</governor>
          <dependent id="6">news</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">speaking</governor>
          <dependent id="7">conference</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Veneto</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Veneto</governor>
          <dependent id="9">Castelfranco</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">conference</governor>
          <dependent id="10">Veneto</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="10">Veneto</governor>
          <dependent id="12">Italy</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">expressed</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">doubt</governor>
          <dependent id="15">little</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">expressed</governor>
          <dependent id="16">doubt</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">regain</governor>
          <dependent id="17">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="19">regain</governor>
          <dependent id="18">can</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="16">doubt</governor>
          <dependent id="19">regain</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="21">form</governor>
          <dependent id="20">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">regain</governor>
          <dependent id="21">form</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">1988</governor>
          <dependent id="22">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">form</governor>
          <dependent id="23">1988</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1988" type="DATE" score="0.0">
          <tokens>
            <token id="23" string="1988" />
          </tokens>
        </entity>
        <entity id="2" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Johnson" />
          </tokens>
        </entity>
        <entity id="3" string="Castelfranco Veneto" type="LOCATION" score="0.0">
          <tokens>
            <token id="9" string="Castelfranco" />
            <token id="10" string="Veneto" />
          </tokens>
        </entity>
        <entity id="4" string="Italy" type="LOCATION" score="0.0">
          <tokens>
            <token id="12" string="Italy" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>&amp;quot;I want to take back the titles and the records I have been deprived of,&amp;quot; the Associated Press quoted Johnson as saying.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="want" lemma="want" stem="want" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="take" lemma="take" stem="take" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="back" lemma="back" stem="back" pos="RP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="titles" lemma="title" stem="titl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="records" lemma="record" stem="record" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="deprived" lemma="deprive" stem="depriv" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="Associated" lemma="Associated" stem="associat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="21" string="Press" lemma="Press" stem="press" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="22" string="quoted" lemma="quote" stem="quot" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="24" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="saying" lemma="say" stem="sai" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP I)) (VP (VBP want) (S (VP (TO to) (VP (VB take) (PRT (RP back)) (NP (NP (DT the) (NNS titles)) (CC and) (NP (NP (DT the) (NNS records)) (SBAR (S (NP (PRP I)) (VP (VBP have) (VP (VBN been) (VP (VBN deprived) (PP (IN of)))))))))))))) (, ,) ('' '') (NP (DT the) (NNP Associated) (NNP Press)) (VP (VBD quoted) (NP (NNP Johnson)) (PP (IN as) (S (VP (VBG saying))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="want to take back the titles and the records I have been deprived of" type="VP">
          <tokens>
            <token id="3" string="want" />
            <token id="4" string="to" />
            <token id="5" string="take" />
            <token id="6" string="back" />
            <token id="7" string="the" />
            <token id="8" string="titles" />
            <token id="9" string="and" />
            <token id="10" string="the" />
            <token id="11" string="records" />
            <token id="12" string="I" />
            <token id="13" string="have" />
            <token id="14" string="been" />
            <token id="15" string="deprived" />
            <token id="16" string="of" />
          </tokens>
        </chunking>
        <chunking id="2" string="the Associated Press" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="Associated" />
            <token id="21" string="Press" />
          </tokens>
        </chunking>
        <chunking id="3" string="quoted Johnson as saying" type="VP">
          <tokens>
            <token id="22" string="quoted" />
            <token id="23" string="Johnson" />
            <token id="24" string="as" />
            <token id="25" string="saying" />
          </tokens>
        </chunking>
        <chunking id="4" string="Johnson" type="NP">
          <tokens>
            <token id="23" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="5" string="been deprived of" type="VP">
          <tokens>
            <token id="14" string="been" />
            <token id="15" string="deprived" />
            <token id="16" string="of" />
          </tokens>
        </chunking>
        <chunking id="6" string="take back the titles and the records I have been deprived of" type="VP">
          <tokens>
            <token id="5" string="take" />
            <token id="6" string="back" />
            <token id="7" string="the" />
            <token id="8" string="titles" />
            <token id="9" string="and" />
            <token id="10" string="the" />
            <token id="11" string="records" />
            <token id="12" string="I" />
            <token id="13" string="have" />
            <token id="14" string="been" />
            <token id="15" string="deprived" />
            <token id="16" string="of" />
          </tokens>
        </chunking>
        <chunking id="7" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="8" string="I have been deprived of" type="SBAR">
          <tokens>
            <token id="12" string="I" />
            <token id="13" string="have" />
            <token id="14" string="been" />
            <token id="15" string="deprived" />
            <token id="16" string="of" />
          </tokens>
        </chunking>
        <chunking id="9" string="deprived of" type="VP">
          <tokens>
            <token id="15" string="deprived" />
            <token id="16" string="of" />
          </tokens>
        </chunking>
        <chunking id="10" string="the titles" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="titles" />
          </tokens>
        </chunking>
        <chunking id="11" string="have been deprived of" type="VP">
          <tokens>
            <token id="13" string="have" />
            <token id="14" string="been" />
            <token id="15" string="deprived" />
            <token id="16" string="of" />
          </tokens>
        </chunking>
        <chunking id="12" string="to take back the titles and the records I have been deprived of" type="VP">
          <tokens>
            <token id="4" string="to" />
            <token id="5" string="take" />
            <token id="6" string="back" />
            <token id="7" string="the" />
            <token id="8" string="titles" />
            <token id="9" string="and" />
            <token id="10" string="the" />
            <token id="11" string="records" />
            <token id="12" string="I" />
            <token id="13" string="have" />
            <token id="14" string="been" />
            <token id="15" string="deprived" />
            <token id="16" string="of" />
          </tokens>
        </chunking>
        <chunking id="13" string="the records" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="records" />
          </tokens>
        </chunking>
        <chunking id="14" string="the records I have been deprived of" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="records" />
            <token id="12" string="I" />
            <token id="13" string="have" />
            <token id="14" string="been" />
            <token id="15" string="deprived" />
            <token id="16" string="of" />
          </tokens>
        </chunking>
        <chunking id="15" string="saying" type="VP">
          <tokens>
            <token id="25" string="saying" />
          </tokens>
        </chunking>
        <chunking id="16" string="the titles and the records I have been deprived of" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="titles" />
            <token id="9" string="and" />
            <token id="10" string="the" />
            <token id="11" string="records" />
            <token id="12" string="I" />
            <token id="13" string="have" />
            <token id="14" string="been" />
            <token id="15" string="deprived" />
            <token id="16" string="of" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">want</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="22">quoted</governor>
          <dependent id="3">want</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">take</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">want</governor>
          <dependent id="5">take</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="5">take</governor>
          <dependent id="6">back</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">titles</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">take</governor>
          <dependent id="8">titles</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">titles</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">records</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">titles</governor>
          <dependent id="11">records</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="15">deprived</governor>
          <dependent id="12">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">deprived</governor>
          <dependent id="13">have</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="15">deprived</governor>
          <dependent id="14">been</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="11">records</governor>
          <dependent id="15">deprived</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">deprived</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">Press</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">Press</governor>
          <dependent id="20">Associated</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">quoted</governor>
          <dependent id="21">Press</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="22">quoted</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">quoted</governor>
          <dependent id="23">Johnson</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="25">saying</governor>
          <dependent id="24">as</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="22">quoted</governor>
          <dependent id="25">saying</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="23" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="Associated Press" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="20" string="Associated" />
            <token id="21" string="Press" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="28" has_coreference="true">
      <content>&amp;quot;I have been training very hard recently.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="training" lemma="train" stem="train" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="hard" lemma="hard" stem="hard" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="recently" lemma="recently" stem="recent" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (VBP have) (VP (VBN been) (VP (VBG training) (ADVP (RB very) (RB hard)) (ADVP (RB recently))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="2" string="training very hard recently" type="VP">
          <tokens>
            <token id="5" string="training" />
            <token id="6" string="very" />
            <token id="7" string="hard" />
            <token id="8" string="recently" />
          </tokens>
        </chunking>
        <chunking id="3" string="been training very hard recently" type="VP">
          <tokens>
            <token id="4" string="been" />
            <token id="5" string="training" />
            <token id="6" string="very" />
            <token id="7" string="hard" />
            <token id="8" string="recently" />
          </tokens>
        </chunking>
        <chunking id="4" string="have been training very hard recently" type="VP">
          <tokens>
            <token id="3" string="have" />
            <token id="4" string="been" />
            <token id="5" string="training" />
            <token id="6" string="very" />
            <token id="7" string="hard" />
            <token id="8" string="recently" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">training</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">training</governor>
          <dependent id="3">have</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">training</governor>
          <dependent id="4">been</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">training</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">hard</governor>
          <dependent id="6">very</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">training</governor>
          <dependent id="7">hard</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">training</governor>
          <dependent id="8">recently</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="recently" type="DATE" score="0.0">
          <tokens>
            <token id="8" string="recently" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="29" has_coreference="true">
      <content>I am at 90% right now.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="am" lemma="be" stem="am" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="90" lemma="90" stem="90" pos="CD" type="Number" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="5" string="%" lemma="%" stem="%" pos="NN" type="Symbol" isStopWord="true" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="6" string="right" lemma="right" stem="right" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="7" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBP am) (PP (IN at) (NP (CD 90) (NN %))) (ADVP (RB right) (RB now))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="90 %" type="NP">
          <tokens>
            <token id="4" string="90" />
            <token id="5" string="%" />
          </tokens>
        </chunking>
        <chunking id="2" string="am at 90 % right now" type="VP">
          <tokens>
            <token id="2" string="am" />
            <token id="3" string="at" />
            <token id="4" string="90" />
            <token id="5" string="%" />
            <token id="6" string="right" />
            <token id="7" string="now" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">%</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">%</governor>
          <dependent id="2">am</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">%</governor>
          <dependent id="3">at</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="5">%</governor>
          <dependent id="4">90</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">%</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">now</governor>
          <dependent id="6">right</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">%</governor>
          <dependent id="7">now</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="right now" type="DATE" score="0.0">
          <tokens>
            <token id="6" string="right" />
            <token id="7" string="now" />
          </tokens>
        </entity>
        <entity id="2" string="90 %" type="PERCENT" score="0.0">
          <tokens>
            <token id="4" string="90" />
            <token id="5" string="%" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="30" has_coreference="true">
      <content>By strengthening training, I will be 100% by January.</content>
      <tokens>
        <token id="1" string="By" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="strengthening" lemma="strengthen" stem="strengthen" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="training" lemma="training" stem="train" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="100" lemma="100" stem="100" pos="CD" type="Number" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="9" string="%" lemma="%" stem="%" pos="NN" type="Symbol" isStopWord="true" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="10" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="January" lemma="January" stem="januari" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN By) (NP (VBG strengthening) (NN training))) (, ,) (NP (PRP I)) (VP (MD will) (VP (VB be) (NP (CD 100) (NN %)) (PP (IN by) (NP (NNP January))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="will be 100 % by January" type="VP">
          <tokens>
            <token id="6" string="will" />
            <token id="7" string="be" />
            <token id="8" string="100" />
            <token id="9" string="%" />
            <token id="10" string="by" />
            <token id="11" string="January" />
          </tokens>
        </chunking>
        <chunking id="2" string="I" type="NP">
          <tokens>
            <token id="5" string="I" />
          </tokens>
        </chunking>
        <chunking id="3" string="be 100 % by January" type="VP">
          <tokens>
            <token id="7" string="be" />
            <token id="8" string="100" />
            <token id="9" string="%" />
            <token id="10" string="by" />
            <token id="11" string="January" />
          </tokens>
        </chunking>
        <chunking id="4" string="strengthening training" type="NP">
          <tokens>
            <token id="2" string="strengthening" />
            <token id="3" string="training" />
          </tokens>
        </chunking>
        <chunking id="5" string="100 %" type="NP">
          <tokens>
            <token id="8" string="100" />
            <token id="9" string="%" />
          </tokens>
        </chunking>
        <chunking id="6" string="January" type="NP">
          <tokens>
            <token id="11" string="January" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">training</governor>
          <dependent id="1">By</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">training</governor>
          <dependent id="2">strengthening</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">%</governor>
          <dependent id="3">training</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">%</governor>
          <dependent id="5">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">%</governor>
          <dependent id="6">will</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="9">%</governor>
          <dependent id="7">be</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="9">%</governor>
          <dependent id="8">100</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">%</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">January</governor>
          <dependent id="10">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">%</governor>
          <dependent id="11">January</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="100 %" type="PERCENT" score="0.0">
          <tokens>
            <token id="8" string="100" />
            <token id="9" string="%" />
          </tokens>
        </entity>
        <entity id="2" string="January" type="DATE" score="0.0">
          <tokens>
            <token id="11" string="January" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="31" has_coreference="true">
      <content>I have decided to start again to show everybody I&amp;apost;m still the best.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="decided" lemma="decide" stem="decid" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="start" lemma="start" stem="start" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="again" lemma="again" stem="again" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="show" lemma="show" stem="show" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="everybody" lemma="everybody" stem="everybodi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="'m" lemma="be" stem="'m" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="still" lemma="still" stem="still" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="best" lemma="best" stem="best" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBP have) (VP (VBN decided) (S (VP (TO to) (VP (VB start) (ADVP (RB again)) (S (VP (TO to) (VP (VB show) (NP (NP (NN everybody)) (SBAR (S (NP (PRP I)) (VP (VBP 'm) (ADVP (RB still)) (NP (DT the) (JJS best)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="start again to show everybody I 'm still the best" type="VP">
          <tokens>
            <token id="5" string="start" />
            <token id="6" string="again" />
            <token id="7" string="to" />
            <token id="8" string="show" />
            <token id="9" string="everybody" />
            <token id="10" string="I" />
            <token id="11" string="'m" />
            <token id="12" string="still" />
            <token id="13" string="the" />
            <token id="14" string="best" />
          </tokens>
        </chunking>
        <chunking id="2" string="to start again to show everybody I 'm still the best" type="VP">
          <tokens>
            <token id="4" string="to" />
            <token id="5" string="start" />
            <token id="6" string="again" />
            <token id="7" string="to" />
            <token id="8" string="show" />
            <token id="9" string="everybody" />
            <token id="10" string="I" />
            <token id="11" string="'m" />
            <token id="12" string="still" />
            <token id="13" string="the" />
            <token id="14" string="best" />
          </tokens>
        </chunking>
        <chunking id="3" string="'m still the best" type="VP">
          <tokens>
            <token id="11" string="'m" />
            <token id="12" string="still" />
            <token id="13" string="the" />
            <token id="14" string="best" />
          </tokens>
        </chunking>
        <chunking id="4" string="everybody" type="NP">
          <tokens>
            <token id="9" string="everybody" />
          </tokens>
        </chunking>
        <chunking id="5" string="to show everybody I 'm still the best" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="show" />
            <token id="9" string="everybody" />
            <token id="10" string="I" />
            <token id="11" string="'m" />
            <token id="12" string="still" />
            <token id="13" string="the" />
            <token id="14" string="best" />
          </tokens>
        </chunking>
        <chunking id="6" string="I 'm still the best" type="SBAR">
          <tokens>
            <token id="10" string="I" />
            <token id="11" string="'m" />
            <token id="12" string="still" />
            <token id="13" string="the" />
            <token id="14" string="best" />
          </tokens>
        </chunking>
        <chunking id="7" string="everybody I 'm still the best" type="NP">
          <tokens>
            <token id="9" string="everybody" />
            <token id="10" string="I" />
            <token id="11" string="'m" />
            <token id="12" string="still" />
            <token id="13" string="the" />
            <token id="14" string="best" />
          </tokens>
        </chunking>
        <chunking id="8" string="have decided to start again to show everybody I 'm still the best" type="VP">
          <tokens>
            <token id="2" string="have" />
            <token id="3" string="decided" />
            <token id="4" string="to" />
            <token id="5" string="start" />
            <token id="6" string="again" />
            <token id="7" string="to" />
            <token id="8" string="show" />
            <token id="9" string="everybody" />
            <token id="10" string="I" />
            <token id="11" string="'m" />
            <token id="12" string="still" />
            <token id="13" string="the" />
            <token id="14" string="best" />
          </tokens>
        </chunking>
        <chunking id="9" string="decided to start again to show everybody I 'm still the best" type="VP">
          <tokens>
            <token id="3" string="decided" />
            <token id="4" string="to" />
            <token id="5" string="start" />
            <token id="6" string="again" />
            <token id="7" string="to" />
            <token id="8" string="show" />
            <token id="9" string="everybody" />
            <token id="10" string="I" />
            <token id="11" string="'m" />
            <token id="12" string="still" />
            <token id="13" string="the" />
            <token id="14" string="best" />
          </tokens>
        </chunking>
        <chunking id="10" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="11" string="the best" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="best" />
          </tokens>
        </chunking>
        <chunking id="12" string="show everybody I 'm still the best" type="VP">
          <tokens>
            <token id="8" string="show" />
            <token id="9" string="everybody" />
            <token id="10" string="I" />
            <token id="11" string="'m" />
            <token id="12" string="still" />
            <token id="13" string="the" />
            <token id="14" string="best" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">decided</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">decided</governor>
          <dependent id="2">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">decided</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">start</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">decided</governor>
          <dependent id="5">start</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">start</governor>
          <dependent id="6">again</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">show</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">start</governor>
          <dependent id="8">show</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">show</governor>
          <dependent id="9">everybody</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">best</governor>
          <dependent id="10">I</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">best</governor>
          <dependent id="11">'m</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">best</governor>
          <dependent id="12">still</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">best</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="9">everybody</governor>
          <dependent id="14">best</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="32" has_coreference="true">
      <content>I&amp;apost;m convinced I can set a new world record.&amp;quot;</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="'m" lemma="be" stem="'m" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="convinced" lemma="convinced" stem="convinc" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="set" lemma="set" stem="set" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="new" lemma="new" stem="new" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="record" lemma="record" stem="record" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBP 'm) (ADJP (JJ convinced) (SBAR (S (NP (PRP I)) (VP (MD can) (VP (VB set) (NP (DT a) (JJ new) (NN world) (NN record)))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="set a new world record" type="VP">
          <tokens>
            <token id="6" string="set" />
            <token id="7" string="a" />
            <token id="8" string="new" />
            <token id="9" string="world" />
            <token id="10" string="record" />
          </tokens>
        </chunking>
        <chunking id="2" string="a new world record" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="new" />
            <token id="9" string="world" />
            <token id="10" string="record" />
          </tokens>
        </chunking>
        <chunking id="3" string="'m convinced I can set a new world record" type="VP">
          <tokens>
            <token id="2" string="'m" />
            <token id="3" string="convinced" />
            <token id="4" string="I" />
            <token id="5" string="can" />
            <token id="6" string="set" />
            <token id="7" string="a" />
            <token id="8" string="new" />
            <token id="9" string="world" />
            <token id="10" string="record" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="can set a new world record" type="VP">
          <tokens>
            <token id="5" string="can" />
            <token id="6" string="set" />
            <token id="7" string="a" />
            <token id="8" string="new" />
            <token id="9" string="world" />
            <token id="10" string="record" />
          </tokens>
        </chunking>
        <chunking id="6" string="convinced I can set a new world record" type="ADJP">
          <tokens>
            <token id="3" string="convinced" />
            <token id="4" string="I" />
            <token id="5" string="can" />
            <token id="6" string="set" />
            <token id="7" string="a" />
            <token id="8" string="new" />
            <token id="9" string="world" />
            <token id="10" string="record" />
          </tokens>
        </chunking>
        <chunking id="7" string="I can set a new world record" type="SBAR">
          <tokens>
            <token id="4" string="I" />
            <token id="5" string="can" />
            <token id="6" string="set" />
            <token id="7" string="a" />
            <token id="8" string="new" />
            <token id="9" string="world" />
            <token id="10" string="record" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">convinced</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="3">convinced</governor>
          <dependent id="2">'m</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">convinced</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">set</governor>
          <dependent id="4">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">set</governor>
          <dependent id="5">can</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">convinced</governor>
          <dependent id="6">set</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">record</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">record</governor>
          <dependent id="8">new</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">record</governor>
          <dependent id="9">world</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">set</governor>
          <dependent id="10">record</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="33" has_coreference="true">
      <content>BIG MONEY Promoters of indoor meets this season doubt that Johnson will regain his records, but they hope that fans will turn out in huge numbers to watch him try.</content>
      <tokens>
        <token id="1" string="BIG" lemma="BIG" stem="big" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="MONEY" lemma="MONEY" stem="money" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="Promoters" lemma="Promoters" stem="promot" pos="NNPS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="indoor" lemma="indoor" stem="indoor" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="6" string="meets" lemma="meet" stem="meet" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="season" lemma="season" stem="season" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="doubt" lemma="doubt" stem="doubt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="12" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="regain" lemma="regain" stem="regain" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="records" lemma="record" stem="record" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="hope" lemma="hope" stem="hope" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="fans" lemma="fan" stem="fan" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="turn" lemma="turn" stem="turn" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="huge" lemma="huge" stem="huge" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="numbers" lemma="number" stem="number" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="watch" lemma="watch" stem="watch" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="try" lemma="try" stem="try" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (NNP BIG) (NNP MONEY) (NNPS Promoters)) (PP (IN of) (NP (JJ indoor)))) (VP (VBZ meets) (NP (NP (DT this) (NN season) (NN doubt)) (SBAR (WHNP (WDT that)) (S (NP (NNP Johnson)) (VP (MD will) (VP (VB regain) (NP (PRP$ his) (NNS records))))))))) (, ,) (CC but) (S (NP (PRP they)) (VP (VBP hope) (SBAR (IN that) (S (NP (NNS fans)) (VP (MD will) (VP (VB turn) (PRT (RP out)) (PP (IN in) (NP (JJ huge) (NNS numbers))) (S (VP (TO to) (VP (VB watch) (S (NP (PRP him)) (VP (VB try)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="his records" type="NP">
          <tokens>
            <token id="14" string="his" />
            <token id="15" string="records" />
          </tokens>
        </chunking>
        <chunking id="2" string="will turn out in huge numbers to watch him try" type="VP">
          <tokens>
            <token id="22" string="will" />
            <token id="23" string="turn" />
            <token id="24" string="out" />
            <token id="25" string="in" />
            <token id="26" string="huge" />
            <token id="27" string="numbers" />
            <token id="28" string="to" />
            <token id="29" string="watch" />
            <token id="30" string="him" />
            <token id="31" string="try" />
          </tokens>
        </chunking>
        <chunking id="3" string="Johnson" type="NP">
          <tokens>
            <token id="11" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="4" string="watch him try" type="VP">
          <tokens>
            <token id="29" string="watch" />
            <token id="30" string="him" />
            <token id="31" string="try" />
          </tokens>
        </chunking>
        <chunking id="5" string="meets this season doubt that Johnson will regain his records" type="VP">
          <tokens>
            <token id="6" string="meets" />
            <token id="7" string="this" />
            <token id="8" string="season" />
            <token id="9" string="doubt" />
            <token id="10" string="that" />
            <token id="11" string="Johnson" />
            <token id="12" string="will" />
            <token id="13" string="regain" />
            <token id="14" string="his" />
            <token id="15" string="records" />
          </tokens>
        </chunking>
        <chunking id="6" string="that Johnson will regain his records" type="SBAR">
          <tokens>
            <token id="10" string="that" />
            <token id="11" string="Johnson" />
            <token id="12" string="will" />
            <token id="13" string="regain" />
            <token id="14" string="his" />
            <token id="15" string="records" />
          </tokens>
        </chunking>
        <chunking id="7" string="this season doubt that Johnson will regain his records" type="NP">
          <tokens>
            <token id="7" string="this" />
            <token id="8" string="season" />
            <token id="9" string="doubt" />
            <token id="10" string="that" />
            <token id="11" string="Johnson" />
            <token id="12" string="will" />
            <token id="13" string="regain" />
            <token id="14" string="his" />
            <token id="15" string="records" />
          </tokens>
        </chunking>
        <chunking id="8" string="him" type="NP">
          <tokens>
            <token id="30" string="him" />
          </tokens>
        </chunking>
        <chunking id="9" string="BIG MONEY Promoters of indoor" type="NP">
          <tokens>
            <token id="1" string="BIG" />
            <token id="2" string="MONEY" />
            <token id="3" string="Promoters" />
            <token id="4" string="of" />
            <token id="5" string="indoor" />
          </tokens>
        </chunking>
        <chunking id="10" string="will regain his records" type="VP">
          <tokens>
            <token id="12" string="will" />
            <token id="13" string="regain" />
            <token id="14" string="his" />
            <token id="15" string="records" />
          </tokens>
        </chunking>
        <chunking id="11" string="hope that fans will turn out in huge numbers to watch him try" type="VP">
          <tokens>
            <token id="19" string="hope" />
            <token id="20" string="that" />
            <token id="21" string="fans" />
            <token id="22" string="will" />
            <token id="23" string="turn" />
            <token id="24" string="out" />
            <token id="25" string="in" />
            <token id="26" string="huge" />
            <token id="27" string="numbers" />
            <token id="28" string="to" />
            <token id="29" string="watch" />
            <token id="30" string="him" />
            <token id="31" string="try" />
          </tokens>
        </chunking>
        <chunking id="12" string="fans" type="NP">
          <tokens>
            <token id="21" string="fans" />
          </tokens>
        </chunking>
        <chunking id="13" string="they" type="NP">
          <tokens>
            <token id="18" string="they" />
          </tokens>
        </chunking>
        <chunking id="14" string="that fans will turn out in huge numbers to watch him try" type="SBAR">
          <tokens>
            <token id="20" string="that" />
            <token id="21" string="fans" />
            <token id="22" string="will" />
            <token id="23" string="turn" />
            <token id="24" string="out" />
            <token id="25" string="in" />
            <token id="26" string="huge" />
            <token id="27" string="numbers" />
            <token id="28" string="to" />
            <token id="29" string="watch" />
            <token id="30" string="him" />
            <token id="31" string="try" />
          </tokens>
        </chunking>
        <chunking id="15" string="huge numbers" type="NP">
          <tokens>
            <token id="26" string="huge" />
            <token id="27" string="numbers" />
          </tokens>
        </chunking>
        <chunking id="16" string="turn out in huge numbers to watch him try" type="VP">
          <tokens>
            <token id="23" string="turn" />
            <token id="24" string="out" />
            <token id="25" string="in" />
            <token id="26" string="huge" />
            <token id="27" string="numbers" />
            <token id="28" string="to" />
            <token id="29" string="watch" />
            <token id="30" string="him" />
            <token id="31" string="try" />
          </tokens>
        </chunking>
        <chunking id="17" string="this season doubt" type="NP">
          <tokens>
            <token id="7" string="this" />
            <token id="8" string="season" />
            <token id="9" string="doubt" />
          </tokens>
        </chunking>
        <chunking id="18" string="indoor" type="NP">
          <tokens>
            <token id="5" string="indoor" />
          </tokens>
        </chunking>
        <chunking id="19" string="try" type="VP">
          <tokens>
            <token id="31" string="try" />
          </tokens>
        </chunking>
        <chunking id="20" string="BIG MONEY Promoters" type="NP">
          <tokens>
            <token id="1" string="BIG" />
            <token id="2" string="MONEY" />
            <token id="3" string="Promoters" />
          </tokens>
        </chunking>
        <chunking id="21" string="to watch him try" type="VP">
          <tokens>
            <token id="28" string="to" />
            <token id="29" string="watch" />
            <token id="30" string="him" />
            <token id="31" string="try" />
          </tokens>
        </chunking>
        <chunking id="22" string="regain his records" type="VP">
          <tokens>
            <token id="13" string="regain" />
            <token id="14" string="his" />
            <token id="15" string="records" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Promoters</governor>
          <dependent id="1">BIG</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Promoters</governor>
          <dependent id="2">MONEY</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">meets</governor>
          <dependent id="3">Promoters</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">indoor</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">Promoters</governor>
          <dependent id="5">indoor</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">meets</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">doubt</governor>
          <dependent id="7">this</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">doubt</governor>
          <dependent id="8">season</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">meets</governor>
          <dependent id="9">doubt</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">regain</governor>
          <dependent id="10">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">regain</governor>
          <dependent id="11">Johnson</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">regain</governor>
          <dependent id="12">will</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="9">doubt</governor>
          <dependent id="13">regain</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">records</governor>
          <dependent id="14">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">regain</governor>
          <dependent id="15">records</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">meets</governor>
          <dependent id="17">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">hope</governor>
          <dependent id="18">they</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">meets</governor>
          <dependent id="19">hope</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">turn</governor>
          <dependent id="20">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">turn</governor>
          <dependent id="21">fans</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="23">turn</governor>
          <dependent id="22">will</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">hope</governor>
          <dependent id="23">turn</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="23">turn</governor>
          <dependent id="24">out</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">numbers</governor>
          <dependent id="25">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">numbers</governor>
          <dependent id="26">huge</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">turn</governor>
          <dependent id="27">numbers</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="29">watch</governor>
          <dependent id="28">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="23">turn</governor>
          <dependent id="29">watch</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">try</governor>
          <dependent id="30">him</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="29">watch</governor>
          <dependent id="31">try</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Johnson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="34" has_coreference="true">
      <content>Indeed, in a season that holds the promise of high performance levels in general (as athletes peak for the world indoor championships in Seville, Spain, in March), Johnson&amp;apost;s return to competition might help rejuvenate a sport in need of public interest.</content>
      <tokens>
        <token id="1" string="Indeed" lemma="indeed" stem="indeed" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="season" lemma="season" stem="season" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="holds" lemma="hold" stem="hold" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="promise" lemma="promise" stem="promis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="high" lemma="high" stem="high" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="performance" lemma="performance" stem="perform" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="levels" lemma="level" stem="level" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="general" lemma="general" stem="gener" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="athletes" lemma="athlete" stem="athlet" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="peak" lemma="peak" stem="peak" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="indoor" lemma="indoor" stem="indoor" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="championships" lemma="championship" stem="championship" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="Seville" lemma="Seville" stem="sevil" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="27" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="Spain" lemma="Spain" stem="spain" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="29" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="March" lemma="March" stem="march" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="32" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="35" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="36" string="return" lemma="return" stem="return" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="37" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="38" string="competition" lemma="competition" stem="competit" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="39" string="might" lemma="might" stem="might" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="help" lemma="help" stem="help" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="rejuvenate" lemma="rejuvenate" stem="rejuven" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="sport" lemma="sport" stem="sport" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="need" lemma="need" stem="need" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="46" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="public" lemma="public" stem="public" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="48" string="interest" lemma="interest" stem="interest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="49" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Indeed)) (, ,) (PP (IN in) (NP (NP (DT a) (NN season)) (SBAR (WHNP (WDT that)) (S (VP (VBZ holds) (NP (NP (DT the) (NN promise)) (PP (IN of) (NP (NP (JJ high) (NN performance) (NNS levels)) (PP (IN in) (NP (NP (JJ general)) (PRN (-LRB- -LRB-) (NP (PP (IN as) (NP (NP (NNS athletes) (NN peak)) (PP (IN for) (NP (DT the) (NN world))))) (NP (NP (JJ indoor) (NNS championships)) (PP (IN in) (NP (NNP Seville) (, ,) (NNP Spain) (, ,))) (PP (IN in) (NP (NNP March))))) (-RRB- -RRB-)))))))))))) (, ,) (NP (NP (NP (NNP Johnson) (POS 's)) (NN return)) (PP (TO to) (NP (NN competition)))) (VP (MD might) (VP (VB help) (VP (VB rejuvenate) (NP (DT a) (NN sport)) (PP (IN in) (NP (NP (NN need)) (PP (IN of) (NP (JJ public) (NN interest)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="athletes peak for the world" type="NP">
          <tokens>
            <token id="18" string="athletes" />
            <token id="19" string="peak" />
            <token id="20" string="for" />
            <token id="21" string="the" />
            <token id="22" string="world" />
          </tokens>
        </chunking>
        <chunking id="2" string="indoor championships" type="NP">
          <tokens>
            <token id="23" string="indoor" />
            <token id="24" string="championships" />
          </tokens>
        </chunking>
        <chunking id="3" string="need" type="NP">
          <tokens>
            <token id="45" string="need" />
          </tokens>
        </chunking>
        <chunking id="4" string="athletes peak" type="NP">
          <tokens>
            <token id="18" string="athletes" />
            <token id="19" string="peak" />
          </tokens>
        </chunking>
        <chunking id="5" string="high performance levels in general -LRB- as athletes peak for the world indoor championships in Seville , Spain , in March -RRB-" type="NP">
          <tokens>
            <token id="11" string="high" />
            <token id="12" string="performance" />
            <token id="13" string="levels" />
            <token id="14" string="in" />
            <token id="15" string="general" />
            <token id="16" string="(" />
            <token id="17" string="as" />
            <token id="18" string="athletes" />
            <token id="19" string="peak" />
            <token id="20" string="for" />
            <token id="21" string="the" />
            <token id="22" string="world" />
            <token id="23" string="indoor" />
            <token id="24" string="championships" />
            <token id="25" string="in" />
            <token id="26" string="Seville" />
            <token id="27" string="," />
            <token id="28" string="Spain" />
            <token id="29" string="," />
            <token id="30" string="in" />
            <token id="31" string="March" />
            <token id="32" string=")" />
          </tokens>
        </chunking>
        <chunking id="6" string="a season that holds the promise of high performance levels in general -LRB- as athletes peak for the world indoor championships in Seville , Spain , in March -RRB-" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="season" />
            <token id="6" string="that" />
            <token id="7" string="holds" />
            <token id="8" string="the" />
            <token id="9" string="promise" />
            <token id="10" string="of" />
            <token id="11" string="high" />
            <token id="12" string="performance" />
            <token id="13" string="levels" />
            <token id="14" string="in" />
            <token id="15" string="general" />
            <token id="16" string="(" />
            <token id="17" string="as" />
            <token id="18" string="athletes" />
            <token id="19" string="peak" />
            <token id="20" string="for" />
            <token id="21" string="the" />
            <token id="22" string="world" />
            <token id="23" string="indoor" />
            <token id="24" string="championships" />
            <token id="25" string="in" />
            <token id="26" string="Seville" />
            <token id="27" string="," />
            <token id="28" string="Spain" />
            <token id="29" string="," />
            <token id="30" string="in" />
            <token id="31" string="March" />
            <token id="32" string=")" />
          </tokens>
        </chunking>
        <chunking id="7" string="public interest" type="NP">
          <tokens>
            <token id="47" string="public" />
            <token id="48" string="interest" />
          </tokens>
        </chunking>
        <chunking id="8" string="Johnson 's" type="NP">
          <tokens>
            <token id="34" string="Johnson" />
            <token id="35" string="'s" />
          </tokens>
        </chunking>
        <chunking id="9" string="as athletes peak for the world indoor championships in Seville , Spain , in March" type="NP">
          <tokens>
            <token id="17" string="as" />
            <token id="18" string="athletes" />
            <token id="19" string="peak" />
            <token id="20" string="for" />
            <token id="21" string="the" />
            <token id="22" string="world" />
            <token id="23" string="indoor" />
            <token id="24" string="championships" />
            <token id="25" string="in" />
            <token id="26" string="Seville" />
            <token id="27" string="," />
            <token id="28" string="Spain" />
            <token id="29" string="," />
            <token id="30" string="in" />
            <token id="31" string="March" />
          </tokens>
        </chunking>
        <chunking id="10" string="Johnson 's return" type="NP">
          <tokens>
            <token id="34" string="Johnson" />
            <token id="35" string="'s" />
            <token id="36" string="return" />
          </tokens>
        </chunking>
        <chunking id="11" string="the promise" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="promise" />
          </tokens>
        </chunking>
        <chunking id="12" string="March" type="NP">
          <tokens>
            <token id="31" string="March" />
          </tokens>
        </chunking>
        <chunking id="13" string="that holds the promise of high performance levels in general -LRB- as athletes peak for the world indoor championships in Seville , Spain , in March -RRB-" type="SBAR">
          <tokens>
            <token id="6" string="that" />
            <token id="7" string="holds" />
            <token id="8" string="the" />
            <token id="9" string="promise" />
            <token id="10" string="of" />
            <token id="11" string="high" />
            <token id="12" string="performance" />
            <token id="13" string="levels" />
            <token id="14" string="in" />
            <token id="15" string="general" />
            <token id="16" string="(" />
            <token id="17" string="as" />
            <token id="18" string="athletes" />
            <token id="19" string="peak" />
            <token id="20" string="for" />
            <token id="21" string="the" />
            <token id="22" string="world" />
            <token id="23" string="indoor" />
            <token id="24" string="championships" />
            <token id="25" string="in" />
            <token id="26" string="Seville" />
            <token id="27" string="," />
            <token id="28" string="Spain" />
            <token id="29" string="," />
            <token id="30" string="in" />
            <token id="31" string="March" />
            <token id="32" string=")" />
          </tokens>
        </chunking>
        <chunking id="14" string="general -LRB- as athletes peak for the world indoor championships in Seville , Spain , in March -RRB-" type="NP">
          <tokens>
            <token id="15" string="general" />
            <token id="16" string="(" />
            <token id="17" string="as" />
            <token id="18" string="athletes" />
            <token id="19" string="peak" />
            <token id="20" string="for" />
            <token id="21" string="the" />
            <token id="22" string="world" />
            <token id="23" string="indoor" />
            <token id="24" string="championships" />
            <token id="25" string="in" />
            <token id="26" string="Seville" />
            <token id="27" string="," />
            <token id="28" string="Spain" />
            <token id="29" string="," />
            <token id="30" string="in" />
            <token id="31" string="March" />
            <token id="32" string=")" />
          </tokens>
        </chunking>
        <chunking id="15" string="competition" type="NP">
          <tokens>
            <token id="38" string="competition" />
          </tokens>
        </chunking>
        <chunking id="16" string="the world" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="world" />
          </tokens>
        </chunking>
        <chunking id="17" string="high performance levels" type="NP">
          <tokens>
            <token id="11" string="high" />
            <token id="12" string="performance" />
            <token id="13" string="levels" />
          </tokens>
        </chunking>
        <chunking id="18" string="the promise of high performance levels in general -LRB- as athletes peak for the world indoor championships in Seville , Spain , in March -RRB-" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="promise" />
            <token id="10" string="of" />
            <token id="11" string="high" />
            <token id="12" string="performance" />
            <token id="13" string="levels" />
            <token id="14" string="in" />
            <token id="15" string="general" />
            <token id="16" string="(" />
            <token id="17" string="as" />
            <token id="18" string="athletes" />
            <token id="19" string="peak" />
            <token id="20" string="for" />
            <token id="21" string="the" />
            <token id="22" string="world" />
            <token id="23" string="indoor" />
            <token id="24" string="championships" />
            <token id="25" string="in" />
            <token id="26" string="Seville" />
            <token id="27" string="," />
            <token id="28" string="Spain" />
            <token id="29" string="," />
            <token id="30" string="in" />
            <token id="31" string="March" />
            <token id="32" string=")" />
          </tokens>
        </chunking>
        <chunking id="19" string="Seville , Spain ," type="NP">
          <tokens>
            <token id="26" string="Seville" />
            <token id="27" string="," />
            <token id="28" string="Spain" />
            <token id="29" string="," />
          </tokens>
        </chunking>
        <chunking id="20" string="Johnson 's return to competition" type="NP">
          <tokens>
            <token id="34" string="Johnson" />
            <token id="35" string="'s" />
            <token id="36" string="return" />
            <token id="37" string="to" />
            <token id="38" string="competition" />
          </tokens>
        </chunking>
        <chunking id="21" string="a season" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="season" />
          </tokens>
        </chunking>
        <chunking id="22" string="help rejuvenate a sport in need of public interest" type="VP">
          <tokens>
            <token id="40" string="help" />
            <token id="41" string="rejuvenate" />
            <token id="42" string="a" />
            <token id="43" string="sport" />
            <token id="44" string="in" />
            <token id="45" string="need" />
            <token id="46" string="of" />
            <token id="47" string="public" />
            <token id="48" string="interest" />
          </tokens>
        </chunking>
        <chunking id="23" string="need of public interest" type="NP">
          <tokens>
            <token id="45" string="need" />
            <token id="46" string="of" />
            <token id="47" string="public" />
            <token id="48" string="interest" />
          </tokens>
        </chunking>
        <chunking id="24" string="a sport" type="NP">
          <tokens>
            <token id="42" string="a" />
            <token id="43" string="sport" />
          </tokens>
        </chunking>
        <chunking id="25" string="might help rejuvenate a sport in need of public interest" type="VP">
          <tokens>
            <token id="39" string="might" />
            <token id="40" string="help" />
            <token id="41" string="rejuvenate" />
            <token id="42" string="a" />
            <token id="43" string="sport" />
            <token id="44" string="in" />
            <token id="45" string="need" />
            <token id="46" string="of" />
            <token id="47" string="public" />
            <token id="48" string="interest" />
          </tokens>
        </chunking>
        <chunking id="26" string="indoor championships in Seville , Spain , in March" type="NP">
          <tokens>
            <token id="23" string="indoor" />
            <token id="24" string="championships" />
            <token id="25" string="in" />
            <token id="26" string="Seville" />
            <token id="27" string="," />
            <token id="28" string="Spain" />
            <token id="29" string="," />
            <token id="30" string="in" />
            <token id="31" string="March" />
          </tokens>
        </chunking>
        <chunking id="27" string="holds the promise of high performance levels in general -LRB- as athletes peak for the world indoor championships in Seville , Spain , in March -RRB-" type="VP">
          <tokens>
            <token id="7" string="holds" />
            <token id="8" string="the" />
            <token id="9" string="promise" />
            <token id="10" string="of" />
            <token id="11" string="high" />
            <token id="12" string="performance" />
            <token id="13" string="levels" />
            <token id="14" string="in" />
            <token id="15" string="general" />
            <token id="16" string="(" />
            <token id="17" string="as" />
            <token id="18" string="athletes" />
            <token id="19" string="peak" />
            <token id="20" string="for" />
            <token id="21" string="the" />
            <token id="22" string="world" />
            <token id="23" string="indoor" />
            <token id="24" string="championships" />
            <token id="25" string="in" />
            <token id="26" string="Seville" />
            <token id="27" string="," />
            <token id="28" string="Spain" />
            <token id="29" string="," />
            <token id="30" string="in" />
            <token id="31" string="March" />
            <token id="32" string=")" />
          </tokens>
        </chunking>
        <chunking id="28" string="general" type="NP">
          <tokens>
            <token id="15" string="general" />
          </tokens>
        </chunking>
        <chunking id="29" string="rejuvenate a sport in need of public interest" type="VP">
          <tokens>
            <token id="41" string="rejuvenate" />
            <token id="42" string="a" />
            <token id="43" string="sport" />
            <token id="44" string="in" />
            <token id="45" string="need" />
            <token id="46" string="of" />
            <token id="47" string="public" />
            <token id="48" string="interest" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="40">help</governor>
          <dependent id="1">Indeed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">season</governor>
          <dependent id="3">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">season</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="40">help</governor>
          <dependent id="5">season</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">holds</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="5">season</governor>
          <dependent id="7">holds</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">promise</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">holds</governor>
          <dependent id="9">promise</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">levels</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">levels</governor>
          <dependent id="11">high</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">levels</governor>
          <dependent id="12">performance</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">promise</governor>
          <dependent id="13">levels</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">general</governor>
          <dependent id="14">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">levels</governor>
          <dependent id="15">general</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">peak</governor>
          <dependent id="17">as</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">peak</governor>
          <dependent id="18">athletes</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">championships</governor>
          <dependent id="19">peak</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">world</governor>
          <dependent id="20">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">world</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">peak</governor>
          <dependent id="22">world</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">championships</governor>
          <dependent id="23">indoor</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="15">general</governor>
          <dependent id="24">championships</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">Spain</governor>
          <dependent id="25">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">Spain</governor>
          <dependent id="26">Seville</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">championships</governor>
          <dependent id="28">Spain</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">March</governor>
          <dependent id="30">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">championships</governor>
          <dependent id="31">March</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="36">return</governor>
          <dependent id="34">Johnson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">Johnson</governor>
          <dependent id="35">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="40">help</governor>
          <dependent id="36">return</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">competition</governor>
          <dependent id="37">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="36">return</governor>
          <dependent id="38">competition</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="40">help</governor>
          <dependent id="39">might</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="40">help</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="40">help</governor>
          <dependent id="41">rejuvenate</dependent>
        </dependency>
        <dependency type="det">
          <governor id="43">sport</governor>
          <dependent id="42">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="41">rejuvenate</governor>
          <dependent id="43">sport</dependent>
        </dependency>
        <dependency type="case">
          <governor id="45">need</governor>
          <dependent id="44">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="41">rejuvenate</governor>
          <dependent id="45">need</dependent>
        </dependency>
        <dependency type="case">
          <governor id="48">interest</governor>
          <dependent id="46">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="48">interest</governor>
          <dependent id="47">public</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="45">need</governor>
          <dependent id="48">interest</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Seville" type="LOCATION" score="0.0">
          <tokens>
            <token id="26" string="Seville" />
          </tokens>
        </entity>
        <entity id="2" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="34" string="Johnson" />
          </tokens>
        </entity>
        <entity id="3" string="March" type="DATE" score="0.0">
          <tokens>
            <token id="31" string="March" />
          </tokens>
        </entity>
        <entity id="4" string="Spain" type="LOCATION" score="0.0">
          <tokens>
            <token id="28" string="Spain" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="35" has_coreference="true">
      <content>Al Franken, promoter of the Sunkist Invitational, is close to signing Johnson for his Jan. 18 meet, saying Johnson will receive the highest appearance fee Franken has ever paid -- $30,000, compared to the $23,000 Franken paid Carl Lewis.</content>
      <tokens>
        <token id="1" string="Al" lemma="Al" stem="al" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Franken" lemma="Franken" stem="franken" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="promoter" lemma="promoter" stem="promot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Sunkist" lemma="Sunkist" stem="sunkist" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="8" string="Invitational" lemma="Invitational" stem="invitat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="close" lemma="close" stem="close" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="signing" lemma="sign" stem="sign" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="15" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="Jan." lemma="Jan." stem="jan." pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="18" string="18" lemma="18" stem="18" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="19" string="meet" lemma="meet" stem="meet" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="saying" lemma="say" stem="sai" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="23" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="receive" lemma="receive" stem="receiv" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="highest" lemma="highest" stem="highest" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="appearance" lemma="appearance" stem="appear" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="fee" lemma="fee" stem="fee" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="Franken" lemma="Franken" stem="franken" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="30" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="ever" lemma="ever" stem="ever" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="paid" lemma="pay" stem="paid" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="35" string="30,000" lemma="30,000" stem="30,000" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="36" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="compared" lemma="compare" stem="compar" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="41" string="23,000" lemma="23,000" stem="23,000" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="42" string="Franken" lemma="Franken" stem="franken" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="43" string="paid" lemma="pay" stem="paid" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="Carl" lemma="Carl" stem="carl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="45" string="Lewis" lemma="Lewis" stem="lewi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="46" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Al) (NNP Franken)) (, ,) (NP (NP (NN promoter)) (PP (IN of) (NP (DT the) (NNP Sunkist) (NNP Invitational)))) (, ,)) (VP (VBZ is) (ADJP (JJ close) (PP (TO to) (S (VP (VBG signing) (S (NP (NP (NNP Johnson)) (PP (IN for) (NP (PRP$ his))) (NP-TMP (NNP Jan.) (CD 18))) (VP (VP (VB meet) (, ,) (S (VP (VBG saying) (SBAR (S (NP (NNP Johnson)) (VP (MD will) (VP (VB receive) (NP (NP (DT the) (JJS highest) (NN appearance) (NN fee)) (SBAR (S (NP (NNP Franken)) (VP (VBZ has) (ADVP (RB ever)) (VP (VBN paid))))))))))))) (: --) (NP (NP ($ $) (CD 30,000)) (, ,) (PP (VBN compared) (PP (TO to) (NP (NP (DT the) ($ $) (CD 23,000)) (SBAR (S (NP (NNP Franken)) (VP (VBD paid) (NP (NNP Carl) (NNP Lewis)))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="promoter of the Sunkist Invitational" type="NP">
          <tokens>
            <token id="4" string="promoter" />
            <token id="5" string="of" />
            <token id="6" string="the" />
            <token id="7" string="Sunkist" />
            <token id="8" string="Invitational" />
          </tokens>
        </chunking>
        <chunking id="2" string="Johnson" type="NP">
          <tokens>
            <token id="14" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="3" string="signing Johnson for his Jan. 18 meet , saying Johnson will receive the highest appearance fee Franken has ever paid -- $ 30,000 , compared to the $ 23,000 Franken paid Carl Lewis" type="VP">
          <tokens>
            <token id="13" string="signing" />
            <token id="14" string="Johnson" />
            <token id="15" string="for" />
            <token id="16" string="his" />
            <token id="17" string="Jan." />
            <token id="18" string="18" />
            <token id="19" string="meet" />
            <token id="20" string="," />
            <token id="21" string="saying" />
            <token id="22" string="Johnson" />
            <token id="23" string="will" />
            <token id="24" string="receive" />
            <token id="25" string="the" />
            <token id="26" string="highest" />
            <token id="27" string="appearance" />
            <token id="28" string="fee" />
            <token id="29" string="Franken" />
            <token id="30" string="has" />
            <token id="31" string="ever" />
            <token id="32" string="paid" />
            <token id="33" string="--" />
            <token id="34" string="$" />
            <token id="35" string="30,000" />
            <token id="36" string="," />
            <token id="37" string="compared" />
            <token id="38" string="to" />
            <token id="39" string="the" />
            <token id="40" string="$" />
            <token id="41" string="23,000" />
            <token id="42" string="Franken" />
            <token id="43" string="paid" />
            <token id="44" string="Carl" />
            <token id="45" string="Lewis" />
          </tokens>
        </chunking>
        <chunking id="4" string="meet , saying Johnson will receive the highest appearance fee Franken has ever paid -- $ 30,000 , compared to the $ 23,000 Franken paid Carl Lewis" type="VP">
          <tokens>
            <token id="19" string="meet" />
            <token id="20" string="," />
            <token id="21" string="saying" />
            <token id="22" string="Johnson" />
            <token id="23" string="will" />
            <token id="24" string="receive" />
            <token id="25" string="the" />
            <token id="26" string="highest" />
            <token id="27" string="appearance" />
            <token id="28" string="fee" />
            <token id="29" string="Franken" />
            <token id="30" string="has" />
            <token id="31" string="ever" />
            <token id="32" string="paid" />
            <token id="33" string="--" />
            <token id="34" string="$" />
            <token id="35" string="30,000" />
            <token id="36" string="," />
            <token id="37" string="compared" />
            <token id="38" string="to" />
            <token id="39" string="the" />
            <token id="40" string="$" />
            <token id="41" string="23,000" />
            <token id="42" string="Franken" />
            <token id="43" string="paid" />
            <token id="44" string="Carl" />
            <token id="45" string="Lewis" />
          </tokens>
        </chunking>
        <chunking id="5" string="meet , saying Johnson will receive the highest appearance fee Franken has ever paid" type="VP">
          <tokens>
            <token id="19" string="meet" />
            <token id="20" string="," />
            <token id="21" string="saying" />
            <token id="22" string="Johnson" />
            <token id="23" string="will" />
            <token id="24" string="receive" />
            <token id="25" string="the" />
            <token id="26" string="highest" />
            <token id="27" string="appearance" />
            <token id="28" string="fee" />
            <token id="29" string="Franken" />
            <token id="30" string="has" />
            <token id="31" string="ever" />
            <token id="32" string="paid" />
          </tokens>
        </chunking>
        <chunking id="6" string="Franken paid Carl Lewis" type="SBAR">
          <tokens>
            <token id="42" string="Franken" />
            <token id="43" string="paid" />
            <token id="44" string="Carl" />
            <token id="45" string="Lewis" />
          </tokens>
        </chunking>
        <chunking id="7" string="$ 30,000" type="NP">
          <tokens>
            <token id="34" string="$" />
            <token id="35" string="30,000" />
          </tokens>
        </chunking>
        <chunking id="8" string="is close to signing Johnson for his Jan. 18 meet , saying Johnson will receive the highest appearance fee Franken has ever paid -- $ 30,000 , compared to the $ 23,000 Franken paid Carl Lewis" type="VP">
          <tokens>
            <token id="10" string="is" />
            <token id="11" string="close" />
            <token id="12" string="to" />
            <token id="13" string="signing" />
            <token id="14" string="Johnson" />
            <token id="15" string="for" />
            <token id="16" string="his" />
            <token id="17" string="Jan." />
            <token id="18" string="18" />
            <token id="19" string="meet" />
            <token id="20" string="," />
            <token id="21" string="saying" />
            <token id="22" string="Johnson" />
            <token id="23" string="will" />
            <token id="24" string="receive" />
            <token id="25" string="the" />
            <token id="26" string="highest" />
            <token id="27" string="appearance" />
            <token id="28" string="fee" />
            <token id="29" string="Franken" />
            <token id="30" string="has" />
            <token id="31" string="ever" />
            <token id="32" string="paid" />
            <token id="33" string="--" />
            <token id="34" string="$" />
            <token id="35" string="30,000" />
            <token id="36" string="," />
            <token id="37" string="compared" />
            <token id="38" string="to" />
            <token id="39" string="the" />
            <token id="40" string="$" />
            <token id="41" string="23,000" />
            <token id="42" string="Franken" />
            <token id="43" string="paid" />
            <token id="44" string="Carl" />
            <token id="45" string="Lewis" />
          </tokens>
        </chunking>
        <chunking id="9" string="Al Franken" type="NP">
          <tokens>
            <token id="1" string="Al" />
            <token id="2" string="Franken" />
          </tokens>
        </chunking>
        <chunking id="10" string="close to signing Johnson for his Jan. 18 meet , saying Johnson will receive the highest appearance fee Franken has ever paid -- $ 30,000 , compared to the $ 23,000 Franken paid Carl Lewis" type="ADJP">
          <tokens>
            <token id="11" string="close" />
            <token id="12" string="to" />
            <token id="13" string="signing" />
            <token id="14" string="Johnson" />
            <token id="15" string="for" />
            <token id="16" string="his" />
            <token id="17" string="Jan." />
            <token id="18" string="18" />
            <token id="19" string="meet" />
            <token id="20" string="," />
            <token id="21" string="saying" />
            <token id="22" string="Johnson" />
            <token id="23" string="will" />
            <token id="24" string="receive" />
            <token id="25" string="the" />
            <token id="26" string="highest" />
            <token id="27" string="appearance" />
            <token id="28" string="fee" />
            <token id="29" string="Franken" />
            <token id="30" string="has" />
            <token id="31" string="ever" />
            <token id="32" string="paid" />
            <token id="33" string="--" />
            <token id="34" string="$" />
            <token id="35" string="30,000" />
            <token id="36" string="," />
            <token id="37" string="compared" />
            <token id="38" string="to" />
            <token id="39" string="the" />
            <token id="40" string="$" />
            <token id="41" string="23,000" />
            <token id="42" string="Franken" />
            <token id="43" string="paid" />
            <token id="44" string="Carl" />
            <token id="45" string="Lewis" />
          </tokens>
        </chunking>
        <chunking id="11" string="$ 30,000 , compared to the $ 23,000 Franken paid Carl Lewis" type="NP">
          <tokens>
            <token id="34" string="$" />
            <token id="35" string="30,000" />
            <token id="36" string="," />
            <token id="37" string="compared" />
            <token id="38" string="to" />
            <token id="39" string="the" />
            <token id="40" string="$" />
            <token id="41" string="23,000" />
            <token id="42" string="Franken" />
            <token id="43" string="paid" />
            <token id="44" string="Carl" />
            <token id="45" string="Lewis" />
          </tokens>
        </chunking>
        <chunking id="12" string="Carl Lewis" type="NP">
          <tokens>
            <token id="44" string="Carl" />
            <token id="45" string="Lewis" />
          </tokens>
        </chunking>
        <chunking id="13" string="saying Johnson will receive the highest appearance fee Franken has ever paid" type="VP">
          <tokens>
            <token id="21" string="saying" />
            <token id="22" string="Johnson" />
            <token id="23" string="will" />
            <token id="24" string="receive" />
            <token id="25" string="the" />
            <token id="26" string="highest" />
            <token id="27" string="appearance" />
            <token id="28" string="fee" />
            <token id="29" string="Franken" />
            <token id="30" string="has" />
            <token id="31" string="ever" />
            <token id="32" string="paid" />
          </tokens>
        </chunking>
        <chunking id="14" string="paid" type="VP">
          <tokens>
            <token id="32" string="paid" />
          </tokens>
        </chunking>
        <chunking id="15" string="the $ 23,000 Franken paid Carl Lewis" type="NP">
          <tokens>
            <token id="39" string="the" />
            <token id="40" string="$" />
            <token id="41" string="23,000" />
            <token id="42" string="Franken" />
            <token id="43" string="paid" />
            <token id="44" string="Carl" />
            <token id="45" string="Lewis" />
          </tokens>
        </chunking>
        <chunking id="16" string="Franken has ever paid" type="SBAR">
          <tokens>
            <token id="29" string="Franken" />
            <token id="30" string="has" />
            <token id="31" string="ever" />
            <token id="32" string="paid" />
          </tokens>
        </chunking>
        <chunking id="17" string="the highest appearance fee" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="highest" />
            <token id="27" string="appearance" />
            <token id="28" string="fee" />
          </tokens>
        </chunking>
        <chunking id="18" string="his" type="NP">
          <tokens>
            <token id="16" string="his" />
          </tokens>
        </chunking>
        <chunking id="19" string="has ever paid" type="VP">
          <tokens>
            <token id="30" string="has" />
            <token id="31" string="ever" />
            <token id="32" string="paid" />
          </tokens>
        </chunking>
        <chunking id="20" string="paid Carl Lewis" type="VP">
          <tokens>
            <token id="43" string="paid" />
            <token id="44" string="Carl" />
            <token id="45" string="Lewis" />
          </tokens>
        </chunking>
        <chunking id="21" string="the Sunkist Invitational" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="Sunkist" />
            <token id="8" string="Invitational" />
          </tokens>
        </chunking>
        <chunking id="22" string="receive the highest appearance fee Franken has ever paid" type="VP">
          <tokens>
            <token id="24" string="receive" />
            <token id="25" string="the" />
            <token id="26" string="highest" />
            <token id="27" string="appearance" />
            <token id="28" string="fee" />
            <token id="29" string="Franken" />
            <token id="30" string="has" />
            <token id="31" string="ever" />
            <token id="32" string="paid" />
          </tokens>
        </chunking>
        <chunking id="23" string="promoter" type="NP">
          <tokens>
            <token id="4" string="promoter" />
          </tokens>
        </chunking>
        <chunking id="24" string="Johnson will receive the highest appearance fee Franken has ever paid" type="SBAR">
          <tokens>
            <token id="22" string="Johnson" />
            <token id="23" string="will" />
            <token id="24" string="receive" />
            <token id="25" string="the" />
            <token id="26" string="highest" />
            <token id="27" string="appearance" />
            <token id="28" string="fee" />
            <token id="29" string="Franken" />
            <token id="30" string="has" />
            <token id="31" string="ever" />
            <token id="32" string="paid" />
          </tokens>
        </chunking>
        <chunking id="25" string="the $ 23,000" type="NP">
          <tokens>
            <token id="39" string="the" />
            <token id="40" string="$" />
            <token id="41" string="23,000" />
          </tokens>
        </chunking>
        <chunking id="26" string="Johnson for his Jan. 18" type="NP">
          <tokens>
            <token id="14" string="Johnson" />
            <token id="15" string="for" />
            <token id="16" string="his" />
            <token id="17" string="Jan." />
            <token id="18" string="18" />
          </tokens>
        </chunking>
        <chunking id="27" string="will receive the highest appearance fee Franken has ever paid" type="VP">
          <tokens>
            <token id="23" string="will" />
            <token id="24" string="receive" />
            <token id="25" string="the" />
            <token id="26" string="highest" />
            <token id="27" string="appearance" />
            <token id="28" string="fee" />
            <token id="29" string="Franken" />
            <token id="30" string="has" />
            <token id="31" string="ever" />
            <token id="32" string="paid" />
          </tokens>
        </chunking>
        <chunking id="28" string="the highest appearance fee Franken has ever paid" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="highest" />
            <token id="27" string="appearance" />
            <token id="28" string="fee" />
            <token id="29" string="Franken" />
            <token id="30" string="has" />
            <token id="31" string="ever" />
            <token id="32" string="paid" />
          </tokens>
        </chunking>
        <chunking id="29" string="Franken" type="NP">
          <tokens>
            <token id="29" string="Franken" />
          </tokens>
        </chunking>
        <chunking id="30" string="Al Franken , promoter of the Sunkist Invitational ," type="NP">
          <tokens>
            <token id="1" string="Al" />
            <token id="2" string="Franken" />
            <token id="3" string="," />
            <token id="4" string="promoter" />
            <token id="5" string="of" />
            <token id="6" string="the" />
            <token id="7" string="Sunkist" />
            <token id="8" string="Invitational" />
            <token id="9" string="," />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Franken</governor>
          <dependent id="1">Al</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">close</governor>
          <dependent id="2">Franken</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">Franken</governor>
          <dependent id="4">promoter</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">Invitational</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">Invitational</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Invitational</governor>
          <dependent id="7">Sunkist</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">promoter</governor>
          <dependent id="8">Invitational</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">close</governor>
          <dependent id="10">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">close</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">signing</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">close</governor>
          <dependent id="13">signing</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">meet</governor>
          <dependent id="14">Johnson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">his</governor>
          <dependent id="15">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">Johnson</governor>
          <dependent id="16">his</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="14">Johnson</governor>
          <dependent id="17">Jan.</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="17">Jan.</governor>
          <dependent id="18">18</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">signing</governor>
          <dependent id="19">meet</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="19">meet</governor>
          <dependent id="21">saying</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">receive</governor>
          <dependent id="22">Johnson</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="24">receive</governor>
          <dependent id="23">will</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="21">saying</governor>
          <dependent id="24">receive</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">fee</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">fee</governor>
          <dependent id="26">highest</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">fee</governor>
          <dependent id="27">appearance</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">receive</governor>
          <dependent id="28">fee</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="32">paid</governor>
          <dependent id="29">Franken</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="32">paid</governor>
          <dependent id="30">has</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="32">paid</governor>
          <dependent id="31">ever</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="28">fee</governor>
          <dependent id="32">paid</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="35">30,000</governor>
          <dependent id="34">$</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">meet</governor>
          <dependent id="35">30,000</dependent>
        </dependency>
        <dependency type="case">
          <governor id="41">23,000</governor>
          <dependent id="37">compared</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="37">compared</governor>
          <dependent id="38">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="41">23,000</governor>
          <dependent id="39">the</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="41">23,000</governor>
          <dependent id="40">$</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="35">30,000</governor>
          <dependent id="41">23,000</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="43">paid</governor>
          <dependent id="42">Franken</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="41">23,000</governor>
          <dependent id="43">paid</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="45">Lewis</governor>
          <dependent id="44">Carl</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="43">paid</governor>
          <dependent id="45">Lewis</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="Al Franken" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Al" />
            <token id="2" string="Franken" />
          </tokens>
        </entity>
        <entity id="3" string="$ 23,000" type="MONEY" score="0.0">
          <tokens>
            <token id="40" string="$" />
            <token id="41" string="23,000" />
          </tokens>
        </entity>
        <entity id="4" string="Carl Lewis" type="PERSON" score="0.0">
          <tokens>
            <token id="44" string="Carl" />
            <token id="45" string="Lewis" />
          </tokens>
        </entity>
        <entity id="5" string="Jan. 18" type="DATE" score="0.0">
          <tokens>
            <token id="17" string="Jan." />
            <token id="18" string="18" />
          </tokens>
        </entity>
        <entity id="6" string="Franken" type="PERSON" score="0.0">
          <tokens>
            <token id="29" string="Franken" />
          </tokens>
        </entity>
        <entity id="7" string="Sunkist Invitational" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="7" string="Sunkist" />
            <token id="8" string="Invitational" />
          </tokens>
        </entity>
        <entity id="8" string="$ 30,000" type="MONEY" score="0.0">
          <tokens>
            <token id="34" string="$" />
            <token id="35" string="30,000" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="36" has_coreference="true">
      <content>And there is a bonus in the contract that rewards Johnson for high attendance figures.</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="bonus" lemma="bonus" stem="bonu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="contract" lemma="contract" stem="contract" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="rewards" lemma="reward" stem="reward" pos="VBZ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="12" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="high" lemma="high" stem="high" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="attendance" lemma="attendance" stem="attend" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="figures" lemma="figure" stem="figur" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC And) (NP (EX there)) (VP (VBZ is) (NP (NP (DT a) (NN bonus)) (PP (IN in) (NP (NP (DT the) (NN contract)) (SBAR (WHNP (WDT that)) (S (VP (VBZ rewards) (NP (NP (NNP Johnson)) (PP (IN for) (NP (JJ high) (NN attendance) (NNS figures))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="there" type="NP">
          <tokens>
            <token id="2" string="there" />
          </tokens>
        </chunking>
        <chunking id="2" string="is a bonus in the contract that rewards Johnson for high attendance figures" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="a" />
            <token id="5" string="bonus" />
            <token id="6" string="in" />
            <token id="7" string="the" />
            <token id="8" string="contract" />
            <token id="9" string="that" />
            <token id="10" string="rewards" />
            <token id="11" string="Johnson" />
            <token id="12" string="for" />
            <token id="13" string="high" />
            <token id="14" string="attendance" />
            <token id="15" string="figures" />
          </tokens>
        </chunking>
        <chunking id="3" string="high attendance figures" type="NP">
          <tokens>
            <token id="13" string="high" />
            <token id="14" string="attendance" />
            <token id="15" string="figures" />
          </tokens>
        </chunking>
        <chunking id="4" string="that rewards Johnson for high attendance figures" type="SBAR">
          <tokens>
            <token id="9" string="that" />
            <token id="10" string="rewards" />
            <token id="11" string="Johnson" />
            <token id="12" string="for" />
            <token id="13" string="high" />
            <token id="14" string="attendance" />
            <token id="15" string="figures" />
          </tokens>
        </chunking>
        <chunking id="5" string="Johnson" type="NP">
          <tokens>
            <token id="11" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="6" string="the contract" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="contract" />
          </tokens>
        </chunking>
        <chunking id="7" string="the contract that rewards Johnson for high attendance figures" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="contract" />
            <token id="9" string="that" />
            <token id="10" string="rewards" />
            <token id="11" string="Johnson" />
            <token id="12" string="for" />
            <token id="13" string="high" />
            <token id="14" string="attendance" />
            <token id="15" string="figures" />
          </tokens>
        </chunking>
        <chunking id="8" string="rewards Johnson for high attendance figures" type="VP">
          <tokens>
            <token id="10" string="rewards" />
            <token id="11" string="Johnson" />
            <token id="12" string="for" />
            <token id="13" string="high" />
            <token id="14" string="attendance" />
            <token id="15" string="figures" />
          </tokens>
        </chunking>
        <chunking id="9" string="Johnson for high attendance figures" type="NP">
          <tokens>
            <token id="11" string="Johnson" />
            <token id="12" string="for" />
            <token id="13" string="high" />
            <token id="14" string="attendance" />
            <token id="15" string="figures" />
          </tokens>
        </chunking>
        <chunking id="10" string="a bonus in the contract that rewards Johnson for high attendance figures" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="bonus" />
            <token id="6" string="in" />
            <token id="7" string="the" />
            <token id="8" string="contract" />
            <token id="9" string="that" />
            <token id="10" string="rewards" />
            <token id="11" string="Johnson" />
            <token id="12" string="for" />
            <token id="13" string="high" />
            <token id="14" string="attendance" />
            <token id="15" string="figures" />
          </tokens>
        </chunking>
        <chunking id="11" string="a bonus" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="bonus" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="3">is</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="3">is</governor>
          <dependent id="2">there</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">bonus</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">is</governor>
          <dependent id="5">bonus</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">contract</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">contract</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">bonus</governor>
          <dependent id="8">contract</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">rewards</governor>
          <dependent id="9">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="8">contract</governor>
          <dependent id="10">rewards</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">rewards</governor>
          <dependent id="11">Johnson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">figures</governor>
          <dependent id="12">for</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">figures</governor>
          <dependent id="13">high</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">figures</governor>
          <dependent id="14">attendance</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">Johnson</governor>
          <dependent id="15">figures</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Johnson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="37" has_coreference="true">
      <content>&amp;quot;I think honestly, you have to figure that a lot of it is curiosity,&amp;quot; Franken said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="think" lemma="think" stem="think" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="honestly" lemma="honestly" stem="honestli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="figure" lemma="figure" stem="figur" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="lot" lemma="lot" stem="lot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="curiosity" lemma="curiosity" stem="curios" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Franken" lemma="Franken" stem="franken" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="20" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP I)) (VP (VBP think) (SBAR (S (ADVP (RB honestly)) (, ,) (NP (PRP you)) (VP (VBP have) (S (VP (TO to) (VP (VB figure) (SBAR (IN that) (S (NP (NP (DT a) (NN lot)) (PP (IN of) (NP (PRP it)))) (VP (VBZ is) (NP (NN curiosity))))))))))))) (, ,) ('' '') (NP (NNP Franken)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="think honestly , you have to figure that a lot of it is curiosity" type="VP">
          <tokens>
            <token id="3" string="think" />
            <token id="4" string="honestly" />
            <token id="5" string="," />
            <token id="6" string="you" />
            <token id="7" string="have" />
            <token id="8" string="to" />
            <token id="9" string="figure" />
            <token id="10" string="that" />
            <token id="11" string="a" />
            <token id="12" string="lot" />
            <token id="13" string="of" />
            <token id="14" string="it" />
            <token id="15" string="is" />
            <token id="16" string="curiosity" />
          </tokens>
        </chunking>
        <chunking id="2" string="that a lot of it is curiosity" type="SBAR">
          <tokens>
            <token id="10" string="that" />
            <token id="11" string="a" />
            <token id="12" string="lot" />
            <token id="13" string="of" />
            <token id="14" string="it" />
            <token id="15" string="is" />
            <token id="16" string="curiosity" />
          </tokens>
        </chunking>
        <chunking id="3" string="curiosity" type="NP">
          <tokens>
            <token id="16" string="curiosity" />
          </tokens>
        </chunking>
        <chunking id="4" string="is curiosity" type="VP">
          <tokens>
            <token id="15" string="is" />
            <token id="16" string="curiosity" />
          </tokens>
        </chunking>
        <chunking id="5" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="14" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="have to figure that a lot of it is curiosity" type="VP">
          <tokens>
            <token id="7" string="have" />
            <token id="8" string="to" />
            <token id="9" string="figure" />
            <token id="10" string="that" />
            <token id="11" string="a" />
            <token id="12" string="lot" />
            <token id="13" string="of" />
            <token id="14" string="it" />
            <token id="15" string="is" />
            <token id="16" string="curiosity" />
          </tokens>
        </chunking>
        <chunking id="8" string="to figure that a lot of it is curiosity" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="figure" />
            <token id="10" string="that" />
            <token id="11" string="a" />
            <token id="12" string="lot" />
            <token id="13" string="of" />
            <token id="14" string="it" />
            <token id="15" string="is" />
            <token id="16" string="curiosity" />
          </tokens>
        </chunking>
        <chunking id="9" string="a lot of it" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="lot" />
            <token id="13" string="of" />
            <token id="14" string="it" />
          </tokens>
        </chunking>
        <chunking id="10" string="a lot" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="lot" />
          </tokens>
        </chunking>
        <chunking id="11" string="figure that a lot of it is curiosity" type="VP">
          <tokens>
            <token id="9" string="figure" />
            <token id="10" string="that" />
            <token id="11" string="a" />
            <token id="12" string="lot" />
            <token id="13" string="of" />
            <token id="14" string="it" />
            <token id="15" string="is" />
            <token id="16" string="curiosity" />
          </tokens>
        </chunking>
        <chunking id="12" string="Franken" type="NP">
          <tokens>
            <token id="19" string="Franken" />
          </tokens>
        </chunking>
        <chunking id="13" string="said" type="VP">
          <tokens>
            <token id="20" string="said" />
          </tokens>
        </chunking>
        <chunking id="14" string="honestly , you have to figure that a lot of it is curiosity" type="SBAR">
          <tokens>
            <token id="4" string="honestly" />
            <token id="5" string="," />
            <token id="6" string="you" />
            <token id="7" string="have" />
            <token id="8" string="to" />
            <token id="9" string="figure" />
            <token id="10" string="that" />
            <token id="11" string="a" />
            <token id="12" string="lot" />
            <token id="13" string="of" />
            <token id="14" string="it" />
            <token id="15" string="is" />
            <token id="16" string="curiosity" />
          </tokens>
        </chunking>
        <chunking id="15" string="you" type="NP">
          <tokens>
            <token id="6" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">think</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="20">said</governor>
          <dependent id="3">think</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">have</governor>
          <dependent id="4">honestly</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">have</governor>
          <dependent id="6">you</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">think</governor>
          <dependent id="7">have</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">figure</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">have</governor>
          <dependent id="9">figure</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">curiosity</governor>
          <dependent id="10">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">lot</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">curiosity</governor>
          <dependent id="12">lot</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">it</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">lot</governor>
          <dependent id="14">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="16">curiosity</governor>
          <dependent id="15">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">figure</governor>
          <dependent id="16">curiosity</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">said</governor>
          <dependent id="19">Franken</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="20">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Franken" type="PERSON" score="0.0">
          <tokens>
            <token id="19" string="Franken" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="38" has_coreference="true">
      <content>&amp;quot;You&amp;apost;ll get people who don&amp;apost;t care about track, and you may attract back people who have quit coming to track.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="You" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="'ll" lemma="will" stem="'ll" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="get" lemma="get" stem="get" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="care" lemma="care" stem="care" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="track" lemma="track" stem="track" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="attract" lemma="attract" stem="attract" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="back" lemma="back" stem="back" pos="RP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="quit" lemma="quit" stem="quit" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="coming" lemma="come" stem="come" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="23" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="track" lemma="track" stem="track" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP You)) (VP (MD 'll) (VP (VB get) (NP (NP (NNS people)) (SBAR (WHNP (WP who)) (S (VP (VBP do) (RB n't) (VP (VB care) (PP (IN about) (NP (NN track))))))))))) (, ,) (CC and) (S (NP (PRP you)) (VP (MD may) (VP (VB attract) (PRT (RP back)) (NP (NP (NNS people)) (SBAR (WHNP (WP who)) (S (VP (VBP have) (VP (VBN quit) (S (VP (VBG coming) (S (VP (TO to) (VP (VB track)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="who do n't care about track" type="SBAR">
          <tokens>
            <token id="6" string="who" />
            <token id="7" string="do" />
            <token id="8" string="n't" />
            <token id="9" string="care" />
            <token id="10" string="about" />
            <token id="11" string="track" />
          </tokens>
        </chunking>
        <chunking id="2" string="quit coming to track" type="VP">
          <tokens>
            <token id="21" string="quit" />
            <token id="22" string="coming" />
            <token id="23" string="to" />
            <token id="24" string="track" />
          </tokens>
        </chunking>
        <chunking id="3" string="do n't care about track" type="VP">
          <tokens>
            <token id="7" string="do" />
            <token id="8" string="n't" />
            <token id="9" string="care" />
            <token id="10" string="about" />
            <token id="11" string="track" />
          </tokens>
        </chunking>
        <chunking id="4" string="'ll get people who do n't care about track" type="VP">
          <tokens>
            <token id="3" string="'ll" />
            <token id="4" string="get" />
            <token id="5" string="people" />
            <token id="6" string="who" />
            <token id="7" string="do" />
            <token id="8" string="n't" />
            <token id="9" string="care" />
            <token id="10" string="about" />
            <token id="11" string="track" />
          </tokens>
        </chunking>
        <chunking id="5" string="may attract back people who have quit coming to track" type="VP">
          <tokens>
            <token id="15" string="may" />
            <token id="16" string="attract" />
            <token id="17" string="back" />
            <token id="18" string="people" />
            <token id="19" string="who" />
            <token id="20" string="have" />
            <token id="21" string="quit" />
            <token id="22" string="coming" />
            <token id="23" string="to" />
            <token id="24" string="track" />
          </tokens>
        </chunking>
        <chunking id="6" string="people who do n't care about track" type="NP">
          <tokens>
            <token id="5" string="people" />
            <token id="6" string="who" />
            <token id="7" string="do" />
            <token id="8" string="n't" />
            <token id="9" string="care" />
            <token id="10" string="about" />
            <token id="11" string="track" />
          </tokens>
        </chunking>
        <chunking id="7" string="to track" type="VP">
          <tokens>
            <token id="23" string="to" />
            <token id="24" string="track" />
          </tokens>
        </chunking>
        <chunking id="8" string="attract back people who have quit coming to track" type="VP">
          <tokens>
            <token id="16" string="attract" />
            <token id="17" string="back" />
            <token id="18" string="people" />
            <token id="19" string="who" />
            <token id="20" string="have" />
            <token id="21" string="quit" />
            <token id="22" string="coming" />
            <token id="23" string="to" />
            <token id="24" string="track" />
          </tokens>
        </chunking>
        <chunking id="9" string="people" type="NP">
          <tokens>
            <token id="5" string="people" />
          </tokens>
        </chunking>
        <chunking id="10" string="who have quit coming to track" type="SBAR">
          <tokens>
            <token id="19" string="who" />
            <token id="20" string="have" />
            <token id="21" string="quit" />
            <token id="22" string="coming" />
            <token id="23" string="to" />
            <token id="24" string="track" />
          </tokens>
        </chunking>
        <chunking id="11" string="have quit coming to track" type="VP">
          <tokens>
            <token id="20" string="have" />
            <token id="21" string="quit" />
            <token id="22" string="coming" />
            <token id="23" string="to" />
            <token id="24" string="track" />
          </tokens>
        </chunking>
        <chunking id="12" string="get people who do n't care about track" type="VP">
          <tokens>
            <token id="4" string="get" />
            <token id="5" string="people" />
            <token id="6" string="who" />
            <token id="7" string="do" />
            <token id="8" string="n't" />
            <token id="9" string="care" />
            <token id="10" string="about" />
            <token id="11" string="track" />
          </tokens>
        </chunking>
        <chunking id="13" string="people who have quit coming to track" type="NP">
          <tokens>
            <token id="18" string="people" />
            <token id="19" string="who" />
            <token id="20" string="have" />
            <token id="21" string="quit" />
            <token id="22" string="coming" />
            <token id="23" string="to" />
            <token id="24" string="track" />
          </tokens>
        </chunking>
        <chunking id="14" string="track" type="NP">
          <tokens>
            <token id="11" string="track" />
          </tokens>
        </chunking>
        <chunking id="15" string="coming to track" type="VP">
          <tokens>
            <token id="22" string="coming" />
            <token id="23" string="to" />
            <token id="24" string="track" />
          </tokens>
        </chunking>
        <chunking id="16" string="care about track" type="VP">
          <tokens>
            <token id="9" string="care" />
            <token id="10" string="about" />
            <token id="11" string="track" />
          </tokens>
        </chunking>
        <chunking id="17" string="You" type="NP">
          <tokens>
            <token id="2" string="You" />
          </tokens>
        </chunking>
        <chunking id="18" string="you" type="NP">
          <tokens>
            <token id="14" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">get</governor>
          <dependent id="2">You</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">get</governor>
          <dependent id="3">'ll</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">get</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">get</governor>
          <dependent id="5">people</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">care</governor>
          <dependent id="6">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">care</governor>
          <dependent id="7">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="9">care</governor>
          <dependent id="8">n't</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="5">people</governor>
          <dependent id="9">care</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">track</governor>
          <dependent id="10">about</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">care</governor>
          <dependent id="11">track</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">get</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">attract</governor>
          <dependent id="14">you</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">attract</governor>
          <dependent id="15">may</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">get</governor>
          <dependent id="16">attract</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="16">attract</governor>
          <dependent id="17">back</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">attract</governor>
          <dependent id="18">people</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">quit</governor>
          <dependent id="19">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">quit</governor>
          <dependent id="20">have</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="18">people</governor>
          <dependent id="21">quit</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="21">quit</governor>
          <dependent id="22">coming</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">track</governor>
          <dependent id="23">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="22">coming</governor>
          <dependent id="24">track</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="39" has_coreference="true">
      <content>We need a push in the sport.</content>
      <tokens>
        <token id="1" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="need" lemma="need" stem="need" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="push" lemma="push" stem="push" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="7" string="sport" lemma="sport" stem="sport" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP We)) (VP (VBP need) (NP (NP (DT a) (NN push)) (PP (IN in) (NP (DT the) (NN sport))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the sport" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="sport" />
          </tokens>
        </chunking>
        <chunking id="2" string="need a push in the sport" type="VP">
          <tokens>
            <token id="2" string="need" />
            <token id="3" string="a" />
            <token id="4" string="push" />
            <token id="5" string="in" />
            <token id="6" string="the" />
            <token id="7" string="sport" />
          </tokens>
        </chunking>
        <chunking id="3" string="a push" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="push" />
          </tokens>
        </chunking>
        <chunking id="4" string="a push in the sport" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="push" />
            <token id="5" string="in" />
            <token id="6" string="the" />
            <token id="7" string="sport" />
          </tokens>
        </chunking>
        <chunking id="5" string="We" type="NP">
          <tokens>
            <token id="1" string="We" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">need</governor>
          <dependent id="1">We</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">need</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">push</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">need</governor>
          <dependent id="4">push</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">sport</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">sport</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">push</governor>
          <dependent id="7">sport</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="40" has_coreference="true">
      <content>It&amp;apost;s been struggling.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="struggling" lemma="struggle" stem="struggl" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBZ 's) (VP (VBN been) (VP (VBG struggling)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="been struggling" type="VP">
          <tokens>
            <token id="3" string="been" />
            <token id="4" string="struggling" />
          </tokens>
        </chunking>
        <chunking id="2" string="'s been struggling" type="VP">
          <tokens>
            <token id="2" string="'s" />
            <token id="3" string="been" />
            <token id="4" string="struggling" />
          </tokens>
        </chunking>
        <chunking id="3" string="struggling" type="VP">
          <tokens>
            <token id="4" string="struggling" />
          </tokens>
        </chunking>
        <chunking id="4" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="4">struggling</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">struggling</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">struggling</governor>
          <dependent id="3">been</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">struggling</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="41" has_coreference="false">
      <content>We need a hype.</content>
      <tokens>
        <token id="1" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="need" lemma="need" stem="need" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="hype" lemma="hype" stem="hype" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP We)) (VP (VBP need) (NP (DT a) (NN hype))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="need a hype" type="VP">
          <tokens>
            <token id="2" string="need" />
            <token id="3" string="a" />
            <token id="4" string="hype" />
          </tokens>
        </chunking>
        <chunking id="2" string="We" type="NP">
          <tokens>
            <token id="1" string="We" />
          </tokens>
        </chunking>
        <chunking id="3" string="a hype" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="hype" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">need</governor>
          <dependent id="1">We</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">need</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">hype</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">need</governor>
          <dependent id="4">hype</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="42" has_coreference="false">
      <content>Someone who is a ticket seller.</content>
      <tokens>
        <token id="1" string="Someone" lemma="someone" stem="someon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="ticket" lemma="ticket" stem="ticket" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="seller" lemma="seller" stem="seller" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (FRAG (NP (NP (NN Someone)) (SBAR (WHNP (WP who)) (S (VP (VBZ is) (NP (DT a) (NN ticket) (NN seller)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Someone who is a ticket seller" type="NP">
          <tokens>
            <token id="1" string="Someone" />
            <token id="2" string="who" />
            <token id="3" string="is" />
            <token id="4" string="a" />
            <token id="5" string="ticket" />
            <token id="6" string="seller" />
          </tokens>
        </chunking>
        <chunking id="2" string="is a ticket seller" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="a" />
            <token id="5" string="ticket" />
            <token id="6" string="seller" />
          </tokens>
        </chunking>
        <chunking id="3" string="a ticket seller" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="ticket" />
            <token id="6" string="seller" />
          </tokens>
        </chunking>
        <chunking id="4" string="Someone" type="NP">
          <tokens>
            <token id="1" string="Someone" />
          </tokens>
        </chunking>
        <chunking id="5" string="who is a ticket seller" type="SBAR">
          <tokens>
            <token id="2" string="who" />
            <token id="3" string="is" />
            <token id="4" string="a" />
            <token id="5" string="ticket" />
            <token id="6" string="seller" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">Someone</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">seller</governor>
          <dependent id="2">who</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">seller</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">seller</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">seller</governor>
          <dependent id="5">ticket</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="1">Someone</governor>
          <dependent id="6">seller</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="43" has_coreference="true">
      <content>Ben sort of transcends the sport, and, God knows, we need someone to transcend the sport.&amp;quot;</content>
      <tokens>
        <token id="1" string="Ben" lemma="Ben" stem="ben" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="sort" lemma="sort" stem="sort" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="transcends" lemma="transcend" stem="transcend" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="sport" lemma="sport" stem="sport" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="God" lemma="God" stem="god" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="knows" lemma="know" stem="know" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="need" lemma="need" stem="need" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="someone" lemma="someone" stem="someon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="transcend" lemma="transcend" stem="transcend" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="sport" lemma="sport" stem="sport" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (NNP Ben) (NN sort)) (PP (IN of) (NP (NP (NP (NNS transcends)) (NP (DT the) (NN sport))) (, ,) (CC and) (, ,) (NP (NNP God))))) (VP (VBZ knows))) (, ,) (NP (PRP we)) (VP (VBP need) (NP (NN someone)) (S (VP (TO to) (VP (VB transcend) (NP (DT the) (NN sport)))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="Ben sort" type="NP">
          <tokens>
            <token id="1" string="Ben" />
            <token id="2" string="sort" />
          </tokens>
        </chunking>
        <chunking id="2" string="we" type="NP">
          <tokens>
            <token id="13" string="we" />
          </tokens>
        </chunking>
        <chunking id="3" string="to transcend the sport" type="VP">
          <tokens>
            <token id="16" string="to" />
            <token id="17" string="transcend" />
            <token id="18" string="the" />
            <token id="19" string="sport" />
          </tokens>
        </chunking>
        <chunking id="4" string="transcend the sport" type="VP">
          <tokens>
            <token id="17" string="transcend" />
            <token id="18" string="the" />
            <token id="19" string="sport" />
          </tokens>
        </chunking>
        <chunking id="5" string="knows" type="VP">
          <tokens>
            <token id="11" string="knows" />
          </tokens>
        </chunking>
        <chunking id="6" string="Ben sort of transcends the sport , and , God" type="NP">
          <tokens>
            <token id="1" string="Ben" />
            <token id="2" string="sort" />
            <token id="3" string="of" />
            <token id="4" string="transcends" />
            <token id="5" string="the" />
            <token id="6" string="sport" />
            <token id="7" string="," />
            <token id="8" string="and" />
            <token id="9" string="," />
            <token id="10" string="God" />
          </tokens>
        </chunking>
        <chunking id="7" string="transcends the sport , and , God" type="NP">
          <tokens>
            <token id="4" string="transcends" />
            <token id="5" string="the" />
            <token id="6" string="sport" />
            <token id="7" string="," />
            <token id="8" string="and" />
            <token id="9" string="," />
            <token id="10" string="God" />
          </tokens>
        </chunking>
        <chunking id="8" string="transcends" type="NP">
          <tokens>
            <token id="4" string="transcends" />
          </tokens>
        </chunking>
        <chunking id="9" string="the sport" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="sport" />
          </tokens>
        </chunking>
        <chunking id="10" string="someone" type="NP">
          <tokens>
            <token id="15" string="someone" />
          </tokens>
        </chunking>
        <chunking id="11" string="God" type="NP">
          <tokens>
            <token id="10" string="God" />
          </tokens>
        </chunking>
        <chunking id="12" string="transcends the sport" type="NP">
          <tokens>
            <token id="4" string="transcends" />
            <token id="5" string="the" />
            <token id="6" string="sport" />
          </tokens>
        </chunking>
        <chunking id="13" string="need someone to transcend the sport" type="VP">
          <tokens>
            <token id="14" string="need" />
            <token id="15" string="someone" />
            <token id="16" string="to" />
            <token id="17" string="transcend" />
            <token id="18" string="the" />
            <token id="19" string="sport" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">sort</governor>
          <dependent id="1">Ben</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">knows</governor>
          <dependent id="2">sort</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">transcends</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">sort</governor>
          <dependent id="4">transcends</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">sport</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">transcends</governor>
          <dependent id="6">sport</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">transcends</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">transcends</governor>
          <dependent id="10">God</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">need</governor>
          <dependent id="11">knows</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">need</governor>
          <dependent id="13">we</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">need</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">need</governor>
          <dependent id="15">someone</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">transcend</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="14">need</governor>
          <dependent id="17">transcend</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">sport</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">transcend</governor>
          <dependent id="19">sport</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ben" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Ben" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="44" has_coreference="true">
      <content>Transcendent is the word for the appearence fees Johnson will reportedly earn.</content>
      <tokens>
        <token id="1" string="Transcendent" lemma="transcendent" stem="transcend" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="word" lemma="word" stem="word" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="appearence" lemma="appearence" stem="appear" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="fees" lemma="fee" stem="fee" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="10" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="reportedly" lemma="reportedly" stem="reportedli" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="earn" lemma="earn" stem="earn" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (JJ Transcendent)) (VP (VBZ is) (NP (NP (DT the) (NN word)) (PP (IN for) (NP (DT the) (NN appearence) (NNS fees))) (SBAR (S (NP (NNP Johnson)) (VP (MD will) (ADVP (RB reportedly)) (VP (VB earn))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the appearence fees" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="appearence" />
            <token id="8" string="fees" />
          </tokens>
        </chunking>
        <chunking id="2" string="Johnson" type="NP">
          <tokens>
            <token id="9" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="3" string="the word for the appearence fees Johnson will reportedly earn" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="word" />
            <token id="5" string="for" />
            <token id="6" string="the" />
            <token id="7" string="appearence" />
            <token id="8" string="fees" />
            <token id="9" string="Johnson" />
            <token id="10" string="will" />
            <token id="11" string="reportedly" />
            <token id="12" string="earn" />
          </tokens>
        </chunking>
        <chunking id="4" string="Johnson will reportedly earn" type="SBAR">
          <tokens>
            <token id="9" string="Johnson" />
            <token id="10" string="will" />
            <token id="11" string="reportedly" />
            <token id="12" string="earn" />
          </tokens>
        </chunking>
        <chunking id="5" string="will reportedly earn" type="VP">
          <tokens>
            <token id="10" string="will" />
            <token id="11" string="reportedly" />
            <token id="12" string="earn" />
          </tokens>
        </chunking>
        <chunking id="6" string="earn" type="VP">
          <tokens>
            <token id="12" string="earn" />
          </tokens>
        </chunking>
        <chunking id="7" string="is the word for the appearence fees Johnson will reportedly earn" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="the" />
            <token id="4" string="word" />
            <token id="5" string="for" />
            <token id="6" string="the" />
            <token id="7" string="appearence" />
            <token id="8" string="fees" />
            <token id="9" string="Johnson" />
            <token id="10" string="will" />
            <token id="11" string="reportedly" />
            <token id="12" string="earn" />
          </tokens>
        </chunking>
        <chunking id="8" string="the word" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="word" />
          </tokens>
        </chunking>
        <chunking id="9" string="Transcendent" type="NP">
          <tokens>
            <token id="1" string="Transcendent" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">word</governor>
          <dependent id="1">Transcendent</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">word</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">word</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">word</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">fees</governor>
          <dependent id="5">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">fees</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">fees</governor>
          <dependent id="7">appearence</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">word</governor>
          <dependent id="8">fees</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">earn</governor>
          <dependent id="9">Johnson</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">earn</governor>
          <dependent id="10">will</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">earn</governor>
          <dependent id="11">reportedly</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="4">word</governor>
          <dependent id="12">earn</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Johnson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="45" has_coreference="true">
      <content>His value in Europe and Japan has not waned.</content>
      <tokens>
        <token id="1" string="His" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="2" string="value" lemma="value" stem="valu" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="Europe" lemma="Europe" stem="europ" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="5" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="Japan" lemma="Japan" stem="japan" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="7" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="waned" lemma="wane" stem="wane" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (PRP$ His) (NN value)) (PP (IN in) (NP (NNP Europe) (CC and) (NNP Japan)))) (VP (VBZ has) (RB not) (VP (VBN waned))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="has not waned" type="VP">
          <tokens>
            <token id="7" string="has" />
            <token id="8" string="not" />
            <token id="9" string="waned" />
          </tokens>
        </chunking>
        <chunking id="2" string="waned" type="VP">
          <tokens>
            <token id="9" string="waned" />
          </tokens>
        </chunking>
        <chunking id="3" string="Europe and Japan" type="NP">
          <tokens>
            <token id="4" string="Europe" />
            <token id="5" string="and" />
            <token id="6" string="Japan" />
          </tokens>
        </chunking>
        <chunking id="4" string="His value in Europe and Japan" type="NP">
          <tokens>
            <token id="1" string="His" />
            <token id="2" string="value" />
            <token id="3" string="in" />
            <token id="4" string="Europe" />
            <token id="5" string="and" />
            <token id="6" string="Japan" />
          </tokens>
        </chunking>
        <chunking id="5" string="His value" type="NP">
          <tokens>
            <token id="1" string="His" />
            <token id="2" string="value" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="2">value</governor>
          <dependent id="1">His</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">waned</governor>
          <dependent id="2">value</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">Europe</governor>
          <dependent id="3">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">value</governor>
          <dependent id="4">Europe</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">Europe</governor>
          <dependent id="5">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">Europe</governor>
          <dependent id="6">Japan</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">waned</governor>
          <dependent id="7">has</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="9">waned</governor>
          <dependent id="8">not</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">waned</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Europe" type="LOCATION" score="0.0">
          <tokens>
            <token id="4" string="Europe" />
          </tokens>
        </entity>
        <entity id="2" string="Japan" type="LOCATION" score="0.0">
          <tokens>
            <token id="6" string="Japan" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="46" has_coreference="true">
      <content>He will be paid $60,000 for a meet in Stockholm.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="paid" lemma="pay" stem="paid" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="6" string="60,000" lemma="60,000" stem="60,000" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="7" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="meet" lemma="meet" stem="meet" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Stockholm" lemma="Stockholm" stem="stockholm" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (MD will) (VP (VB be) (VP (VBN paid) (NP ($ $) (CD 60,000)) (SBAR (IN for) (S (NP (DT a)) (VP (VBP meet) (PP (IN in) (NP (NNP Stockholm))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="will be paid $ 60,000 for a meet in Stockholm" type="VP">
          <tokens>
            <token id="2" string="will" />
            <token id="3" string="be" />
            <token id="4" string="paid" />
            <token id="5" string="$" />
            <token id="6" string="60,000" />
            <token id="7" string="for" />
            <token id="8" string="a" />
            <token id="9" string="meet" />
            <token id="10" string="in" />
            <token id="11" string="Stockholm" />
          </tokens>
        </chunking>
        <chunking id="2" string="a" type="NP">
          <tokens>
            <token id="8" string="a" />
          </tokens>
        </chunking>
        <chunking id="3" string="be paid $ 60,000 for a meet in Stockholm" type="VP">
          <tokens>
            <token id="3" string="be" />
            <token id="4" string="paid" />
            <token id="5" string="$" />
            <token id="6" string="60,000" />
            <token id="7" string="for" />
            <token id="8" string="a" />
            <token id="9" string="meet" />
            <token id="10" string="in" />
            <token id="11" string="Stockholm" />
          </tokens>
        </chunking>
        <chunking id="4" string="for a meet in Stockholm" type="SBAR">
          <tokens>
            <token id="7" string="for" />
            <token id="8" string="a" />
            <token id="9" string="meet" />
            <token id="10" string="in" />
            <token id="11" string="Stockholm" />
          </tokens>
        </chunking>
        <chunking id="5" string="paid $ 60,000 for a meet in Stockholm" type="VP">
          <tokens>
            <token id="4" string="paid" />
            <token id="5" string="$" />
            <token id="6" string="60,000" />
            <token id="7" string="for" />
            <token id="8" string="a" />
            <token id="9" string="meet" />
            <token id="10" string="in" />
            <token id="11" string="Stockholm" />
          </tokens>
        </chunking>
        <chunking id="6" string="$ 60,000" type="NP">
          <tokens>
            <token id="5" string="$" />
            <token id="6" string="60,000" />
          </tokens>
        </chunking>
        <chunking id="7" string="meet in Stockholm" type="VP">
          <tokens>
            <token id="9" string="meet" />
            <token id="10" string="in" />
            <token id="11" string="Stockholm" />
          </tokens>
        </chunking>
        <chunking id="8" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="9" string="Stockholm" type="NP">
          <tokens>
            <token id="11" string="Stockholm" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="4">paid</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">paid</governor>
          <dependent id="2">will</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">paid</governor>
          <dependent id="3">be</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">paid</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="6">60,000</governor>
          <dependent id="5">$</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">paid</governor>
          <dependent id="6">60,000</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">meet</governor>
          <dependent id="7">for</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">meet</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">paid</governor>
          <dependent id="9">meet</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Stockholm</governor>
          <dependent id="10">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">meet</governor>
          <dependent id="11">Stockholm</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="$ 60,000" type="MONEY" score="0.0">
          <tokens>
            <token id="5" string="$" />
            <token id="6" string="60,000" />
          </tokens>
        </entity>
        <entity id="2" string="Stockholm" type="LOCATION" score="0.0">
          <tokens>
            <token id="11" string="Stockholm" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="47" has_coreference="true">
      <content>But American meet directors say they can&amp;apost;t pay that kind of money, especially for an unproven runner.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="American" lemma="American" stem="american" pos="NNP" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="3" string="meet" lemma="meet" stem="meet" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="directors" lemma="director" stem="director" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="say" lemma="say" stem="sai" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="ca" lemma="can" stem="ca" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="pay" lemma="pay" stem="pai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="kind" lemma="kind" stem="kind" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="money" lemma="money" stem="monei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="especially" lemma="especially" stem="especi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="unproven" lemma="unproven" stem="unproven" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="runner" lemma="runner" stem="runner" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (NNP American)) (VP (VBP meet) (SBAR (S (NP (NNS directors)) (VP (VBP say) (SBAR (S (NP (PRP they)) (VP (MD ca) (RB n't) (VP (VB pay) (NP (NP (DT that) (NN kind)) (PP (IN of) (NP (NN money))) (, ,) (ADVP (RB especially))) (PP (IN for) (NP (DT an) (JJ unproven) (NN runner))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="directors say they ca n't pay that kind of money , especially for an unproven runner" type="SBAR">
          <tokens>
            <token id="4" string="directors" />
            <token id="5" string="say" />
            <token id="6" string="they" />
            <token id="7" string="ca" />
            <token id="8" string="n't" />
            <token id="9" string="pay" />
            <token id="10" string="that" />
            <token id="11" string="kind" />
            <token id="12" string="of" />
            <token id="13" string="money" />
            <token id="14" string="," />
            <token id="15" string="especially" />
            <token id="16" string="for" />
            <token id="17" string="an" />
            <token id="18" string="unproven" />
            <token id="19" string="runner" />
          </tokens>
        </chunking>
        <chunking id="2" string="they ca n't pay that kind of money , especially for an unproven runner" type="SBAR">
          <tokens>
            <token id="6" string="they" />
            <token id="7" string="ca" />
            <token id="8" string="n't" />
            <token id="9" string="pay" />
            <token id="10" string="that" />
            <token id="11" string="kind" />
            <token id="12" string="of" />
            <token id="13" string="money" />
            <token id="14" string="," />
            <token id="15" string="especially" />
            <token id="16" string="for" />
            <token id="17" string="an" />
            <token id="18" string="unproven" />
            <token id="19" string="runner" />
          </tokens>
        </chunking>
        <chunking id="3" string="directors" type="NP">
          <tokens>
            <token id="4" string="directors" />
          </tokens>
        </chunking>
        <chunking id="4" string="that kind of money , especially" type="NP">
          <tokens>
            <token id="10" string="that" />
            <token id="11" string="kind" />
            <token id="12" string="of" />
            <token id="13" string="money" />
            <token id="14" string="," />
            <token id="15" string="especially" />
          </tokens>
        </chunking>
        <chunking id="5" string="an unproven runner" type="NP">
          <tokens>
            <token id="17" string="an" />
            <token id="18" string="unproven" />
            <token id="19" string="runner" />
          </tokens>
        </chunking>
        <chunking id="6" string="money" type="NP">
          <tokens>
            <token id="13" string="money" />
          </tokens>
        </chunking>
        <chunking id="7" string="that kind" type="NP">
          <tokens>
            <token id="10" string="that" />
            <token id="11" string="kind" />
          </tokens>
        </chunking>
        <chunking id="8" string="pay that kind of money , especially for an unproven runner" type="VP">
          <tokens>
            <token id="9" string="pay" />
            <token id="10" string="that" />
            <token id="11" string="kind" />
            <token id="12" string="of" />
            <token id="13" string="money" />
            <token id="14" string="," />
            <token id="15" string="especially" />
            <token id="16" string="for" />
            <token id="17" string="an" />
            <token id="18" string="unproven" />
            <token id="19" string="runner" />
          </tokens>
        </chunking>
        <chunking id="9" string="meet directors say they ca n't pay that kind of money , especially for an unproven runner" type="VP">
          <tokens>
            <token id="3" string="meet" />
            <token id="4" string="directors" />
            <token id="5" string="say" />
            <token id="6" string="they" />
            <token id="7" string="ca" />
            <token id="8" string="n't" />
            <token id="9" string="pay" />
            <token id="10" string="that" />
            <token id="11" string="kind" />
            <token id="12" string="of" />
            <token id="13" string="money" />
            <token id="14" string="," />
            <token id="15" string="especially" />
            <token id="16" string="for" />
            <token id="17" string="an" />
            <token id="18" string="unproven" />
            <token id="19" string="runner" />
          </tokens>
        </chunking>
        <chunking id="10" string="say they ca n't pay that kind of money , especially for an unproven runner" type="VP">
          <tokens>
            <token id="5" string="say" />
            <token id="6" string="they" />
            <token id="7" string="ca" />
            <token id="8" string="n't" />
            <token id="9" string="pay" />
            <token id="10" string="that" />
            <token id="11" string="kind" />
            <token id="12" string="of" />
            <token id="13" string="money" />
            <token id="14" string="," />
            <token id="15" string="especially" />
            <token id="16" string="for" />
            <token id="17" string="an" />
            <token id="18" string="unproven" />
            <token id="19" string="runner" />
          </tokens>
        </chunking>
        <chunking id="11" string="they" type="NP">
          <tokens>
            <token id="6" string="they" />
          </tokens>
        </chunking>
        <chunking id="12" string="ca n't pay that kind of money , especially for an unproven runner" type="VP">
          <tokens>
            <token id="7" string="ca" />
            <token id="8" string="n't" />
            <token id="9" string="pay" />
            <token id="10" string="that" />
            <token id="11" string="kind" />
            <token id="12" string="of" />
            <token id="13" string="money" />
            <token id="14" string="," />
            <token id="15" string="especially" />
            <token id="16" string="for" />
            <token id="17" string="an" />
            <token id="18" string="unproven" />
            <token id="19" string="runner" />
          </tokens>
        </chunking>
        <chunking id="13" string="American" type="NP">
          <tokens>
            <token id="2" string="American" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="3">meet</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">meet</governor>
          <dependent id="2">American</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">meet</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">say</governor>
          <dependent id="4">directors</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">meet</governor>
          <dependent id="5">say</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">pay</governor>
          <dependent id="6">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">pay</governor>
          <dependent id="7">ca</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="9">pay</governor>
          <dependent id="8">n't</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">say</governor>
          <dependent id="9">pay</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">kind</governor>
          <dependent id="10">that</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">pay</governor>
          <dependent id="11">kind</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">money</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">kind</governor>
          <dependent id="13">money</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">kind</governor>
          <dependent id="15">especially</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">runner</governor>
          <dependent id="16">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">runner</governor>
          <dependent id="17">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">runner</governor>
          <dependent id="18">unproven</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">pay</governor>
          <dependent id="19">runner</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="American" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="2" string="American" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="48" has_coreference="true">
      <content>&amp;quot;If he&amp;apost;s eligible to compete, to me, Ben Johnson is an attraction,&amp;quot; said Ray Lumpp, meet director for the indoor meet at the Meadowlands in East Rutherford, N.J..</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="If" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="eligible" lemma="eligible" stem="elig" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="compete" lemma="compete" stem="compet" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Ben" lemma="Ben" stem="ben" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="13" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="14" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="attraction" lemma="attraction" stem="attract" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="Ray" lemma="Ray" stem="rai" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="21" string="Lumpp" lemma="Lumpp" stem="lumpp" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="meet" lemma="meet" stem="meet" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="director" lemma="director" stem="director" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="25" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="27" string="indoor" lemma="indoor" stem="indoor" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="28" string="meet" lemma="meet" stem="meet" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="31" string="Meadowlands" lemma="Meadowlands" stem="meadowland" pos="NNPS" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="32" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="East" lemma="East" stem="east" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="34" string="Rutherford" lemma="Rutherford" stem="rutherford" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="35" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="N.J." lemma="N.J." stem="n.j." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="37" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (SBAR (IN If) (S (NP (PRP he)) (VP (VBZ 's) (ADJP (JJ eligible) (S (VP (TO to) (VP (VB compete))))) (, ,) (PP (TO to) (NP (PRP me)))))) (, ,) (NP (NNP Ben) (NNP Johnson)) (VP (VBZ is) (NP (DT an) (NN attraction)))) (, ,) ('' '') (VP (VBD said)) (NP (NNP Ray) (NNP Lumpp)) (, ,) (S (VP (VBP meet) (S (NP (NP (NN director)) (PP (IN for) (NP (DT the) (JJ indoor)))) (VP (VB meet) (PP (IN at) (NP (DT the) (NNPS Meadowlands))) (PP (IN in) (NP (NP (NNP East) (NNP Rutherford)) (, ,) (NP (NNP N.J.)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is an attraction" type="VP">
          <tokens>
            <token id="14" string="is" />
            <token id="15" string="an" />
            <token id="16" string="attraction" />
          </tokens>
        </chunking>
        <chunking id="2" string="to compete" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="compete" />
          </tokens>
        </chunking>
        <chunking id="3" string="compete" type="VP">
          <tokens>
            <token id="7" string="compete" />
          </tokens>
        </chunking>
        <chunking id="4" string="director" type="NP">
          <tokens>
            <token id="24" string="director" />
          </tokens>
        </chunking>
        <chunking id="5" string="meet at the Meadowlands in East Rutherford , N.J." type="VP">
          <tokens>
            <token id="28" string="meet" />
            <token id="29" string="at" />
            <token id="30" string="the" />
            <token id="31" string="Meadowlands" />
            <token id="32" string="in" />
            <token id="33" string="East" />
            <token id="34" string="Rutherford" />
            <token id="35" string="," />
            <token id="36" string="N.J." />
          </tokens>
        </chunking>
        <chunking id="6" string="East Rutherford , N.J." type="NP">
          <tokens>
            <token id="33" string="East" />
            <token id="34" string="Rutherford" />
            <token id="35" string="," />
            <token id="36" string="N.J." />
          </tokens>
        </chunking>
        <chunking id="7" string="the Meadowlands" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="Meadowlands" />
          </tokens>
        </chunking>
        <chunking id="8" string="N.J." type="NP">
          <tokens>
            <token id="36" string="N.J." />
          </tokens>
        </chunking>
        <chunking id="9" string="East Rutherford" type="NP">
          <tokens>
            <token id="33" string="East" />
            <token id="34" string="Rutherford" />
          </tokens>
        </chunking>
        <chunking id="10" string="If he 's eligible to compete , to me" type="SBAR">
          <tokens>
            <token id="2" string="If" />
            <token id="3" string="he" />
            <token id="4" string="'s" />
            <token id="5" string="eligible" />
            <token id="6" string="to" />
            <token id="7" string="compete" />
            <token id="8" string="," />
            <token id="9" string="to" />
            <token id="10" string="me" />
          </tokens>
        </chunking>
        <chunking id="11" string="'s eligible to compete , to me" type="VP">
          <tokens>
            <token id="4" string="'s" />
            <token id="5" string="eligible" />
            <token id="6" string="to" />
            <token id="7" string="compete" />
            <token id="8" string="," />
            <token id="9" string="to" />
            <token id="10" string="me" />
          </tokens>
        </chunking>
        <chunking id="12" string="Ben Johnson" type="NP">
          <tokens>
            <token id="12" string="Ben" />
            <token id="13" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="13" string="eligible to compete" type="ADJP">
          <tokens>
            <token id="5" string="eligible" />
            <token id="6" string="to" />
            <token id="7" string="compete" />
          </tokens>
        </chunking>
        <chunking id="14" string="me" type="NP">
          <tokens>
            <token id="10" string="me" />
          </tokens>
        </chunking>
        <chunking id="15" string="director for the indoor" type="NP">
          <tokens>
            <token id="24" string="director" />
            <token id="25" string="for" />
            <token id="26" string="the" />
            <token id="27" string="indoor" />
          </tokens>
        </chunking>
        <chunking id="16" string="he" type="NP">
          <tokens>
            <token id="3" string="he" />
          </tokens>
        </chunking>
        <chunking id="17" string="an attraction" type="NP">
          <tokens>
            <token id="15" string="an" />
            <token id="16" string="attraction" />
          </tokens>
        </chunking>
        <chunking id="18" string="said" type="VP">
          <tokens>
            <token id="19" string="said" />
          </tokens>
        </chunking>
        <chunking id="19" string="Ray Lumpp" type="NP">
          <tokens>
            <token id="20" string="Ray" />
            <token id="21" string="Lumpp" />
          </tokens>
        </chunking>
        <chunking id="20" string="the indoor" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="indoor" />
          </tokens>
        </chunking>
        <chunking id="21" string="meet director for the indoor meet at the Meadowlands in East Rutherford , N.J." type="VP">
          <tokens>
            <token id="23" string="meet" />
            <token id="24" string="director" />
            <token id="25" string="for" />
            <token id="26" string="the" />
            <token id="27" string="indoor" />
            <token id="28" string="meet" />
            <token id="29" string="at" />
            <token id="30" string="the" />
            <token id="31" string="Meadowlands" />
            <token id="32" string="in" />
            <token id="33" string="East" />
            <token id="34" string="Rutherford" />
            <token id="35" string="," />
            <token id="36" string="N.J." />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="5">eligible</governor>
          <dependent id="2">If</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">eligible</governor>
          <dependent id="3">he</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">eligible</governor>
          <dependent id="4">'s</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="16">attraction</governor>
          <dependent id="5">eligible</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">compete</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">eligible</governor>
          <dependent id="7">compete</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">me</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">eligible</governor>
          <dependent id="10">me</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Johnson</governor>
          <dependent id="12">Ben</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">attraction</governor>
          <dependent id="13">Johnson</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="16">attraction</governor>
          <dependent id="14">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">attraction</governor>
          <dependent id="15">an</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">said</governor>
          <dependent id="16">attraction</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="19">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">Lumpp</governor>
          <dependent id="20">Ray</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">said</governor>
          <dependent id="21">Lumpp</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="19">said</governor>
          <dependent id="23">meet</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">meet</governor>
          <dependent id="24">director</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">indoor</governor>
          <dependent id="25">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">indoor</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">director</governor>
          <dependent id="27">indoor</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="23">meet</governor>
          <dependent id="28">meet</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">Meadowlands</governor>
          <dependent id="29">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">Meadowlands</governor>
          <dependent id="30">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">meet</governor>
          <dependent id="31">Meadowlands</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">Rutherford</governor>
          <dependent id="32">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="34">Rutherford</governor>
          <dependent id="33">East</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">meet</governor>
          <dependent id="34">Rutherford</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="34">Rutherford</governor>
          <dependent id="36">N.J.</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ben Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Ben" />
            <token id="13" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="N.J." type="LOCATION" score="0.0">
          <tokens>
            <token id="36" string="N.J." />
          </tokens>
        </entity>
        <entity id="3" string="East Rutherford" type="LOCATION" score="0.0">
          <tokens>
            <token id="33" string="East" />
            <token id="34" string="Rutherford" />
          </tokens>
        </entity>
        <entity id="4" string="Ray Lumpp" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="Ray" />
            <token id="21" string="Lumpp" />
          </tokens>
        </entity>
        <entity id="5" string="Meadowlands" type="LOCATION" score="0.0">
          <tokens>
            <token id="31" string="Meadowlands" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="49" has_coreference="true">
      <content>&amp;quot;I&amp;apost;d like to have Ben Johnson regardless of how he runs.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'d" lemma="would" stem="'d" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="like" lemma="like" stem="like" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Ben" lemma="Ben" stem="ben" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="8" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="9" string="regardless" lemma="regardless" stem="regardless" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="how" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="13" string="runs" lemma="run" stem="run" pos="VBZ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (MD 'd) (VP (VB like) (S (VP (TO to) (VP (VB have) (NP (NP (NNP Ben) (NNP Johnson)) (ADVP (RB regardless) (PP (IN of) (SBAR (WHADVP (WRB how)) (S (NP (PRP he)) (VP (VBZ runs)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Ben Johnson" type="NP">
          <tokens>
            <token id="7" string="Ben" />
            <token id="8" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="2" string="runs" type="VP">
          <tokens>
            <token id="13" string="runs" />
          </tokens>
        </chunking>
        <chunking id="3" string="like to have Ben Johnson regardless of how he runs" type="VP">
          <tokens>
            <token id="4" string="like" />
            <token id="5" string="to" />
            <token id="6" string="have" />
            <token id="7" string="Ben" />
            <token id="8" string="Johnson" />
            <token id="9" string="regardless" />
            <token id="10" string="of" />
            <token id="11" string="how" />
            <token id="12" string="he" />
            <token id="13" string="runs" />
          </tokens>
        </chunking>
        <chunking id="4" string="how he runs" type="SBAR">
          <tokens>
            <token id="11" string="how" />
            <token id="12" string="he" />
            <token id="13" string="runs" />
          </tokens>
        </chunking>
        <chunking id="5" string="Ben Johnson regardless of how he runs" type="NP">
          <tokens>
            <token id="7" string="Ben" />
            <token id="8" string="Johnson" />
            <token id="9" string="regardless" />
            <token id="10" string="of" />
            <token id="11" string="how" />
            <token id="12" string="he" />
            <token id="13" string="runs" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="'d like to have Ben Johnson regardless of how he runs" type="VP">
          <tokens>
            <token id="3" string="'d" />
            <token id="4" string="like" />
            <token id="5" string="to" />
            <token id="6" string="have" />
            <token id="7" string="Ben" />
            <token id="8" string="Johnson" />
            <token id="9" string="regardless" />
            <token id="10" string="of" />
            <token id="11" string="how" />
            <token id="12" string="he" />
            <token id="13" string="runs" />
          </tokens>
        </chunking>
        <chunking id="8" string="to have Ben Johnson regardless of how he runs" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="have" />
            <token id="7" string="Ben" />
            <token id="8" string="Johnson" />
            <token id="9" string="regardless" />
            <token id="10" string="of" />
            <token id="11" string="how" />
            <token id="12" string="he" />
            <token id="13" string="runs" />
          </tokens>
        </chunking>
        <chunking id="9" string="he" type="NP">
          <tokens>
            <token id="12" string="he" />
          </tokens>
        </chunking>
        <chunking id="10" string="how" type="WHADVP">
          <tokens>
            <token id="11" string="how" />
          </tokens>
        </chunking>
        <chunking id="11" string="have Ben Johnson regardless of how he runs" type="VP">
          <tokens>
            <token id="6" string="have" />
            <token id="7" string="Ben" />
            <token id="8" string="Johnson" />
            <token id="9" string="regardless" />
            <token id="10" string="of" />
            <token id="11" string="how" />
            <token id="12" string="he" />
            <token id="13" string="runs" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">like</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">like</governor>
          <dependent id="3">'d</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">like</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">have</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">like</governor>
          <dependent id="6">have</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Johnson</governor>
          <dependent id="7">Ben</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">have</governor>
          <dependent id="8">Johnson</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">Johnson</governor>
          <dependent id="9">regardless</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">runs</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">runs</governor>
          <dependent id="11">how</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">runs</governor>
          <dependent id="12">he</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">regardless</governor>
          <dependent id="13">runs</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ben Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Ben" />
            <token id="8" string="Johnson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="50" has_coreference="true">
      <content>But how well he&amp;apost;s running will determine his value.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="how" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="well" lemma="well" stem="well" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="running" lemma="run" stem="run" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="determine" lemma="determine" stem="determin" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="value" lemma="value" stem="valu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (SBAR (WHADVP (WRB how) (RB well)) (S (NP (PRP he)) (VP (VBZ 's) (VP (VBG running))))) (VP (MD will) (VP (VB determine) (NP (PRP$ his) (NN value)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="running" type="VP">
          <tokens>
            <token id="6" string="running" />
          </tokens>
        </chunking>
        <chunking id="2" string="how well he 's running" type="SBAR">
          <tokens>
            <token id="2" string="how" />
            <token id="3" string="well" />
            <token id="4" string="he" />
            <token id="5" string="'s" />
            <token id="6" string="running" />
          </tokens>
        </chunking>
        <chunking id="3" string="how well" type="WHADVP">
          <tokens>
            <token id="2" string="how" />
            <token id="3" string="well" />
          </tokens>
        </chunking>
        <chunking id="4" string="'s running" type="VP">
          <tokens>
            <token id="5" string="'s" />
            <token id="6" string="running" />
          </tokens>
        </chunking>
        <chunking id="5" string="determine his value" type="VP">
          <tokens>
            <token id="8" string="determine" />
            <token id="9" string="his" />
            <token id="10" string="value" />
          </tokens>
        </chunking>
        <chunking id="6" string="will determine his value" type="VP">
          <tokens>
            <token id="7" string="will" />
            <token id="8" string="determine" />
            <token id="9" string="his" />
            <token id="10" string="value" />
          </tokens>
        </chunking>
        <chunking id="7" string="he" type="NP">
          <tokens>
            <token id="4" string="he" />
          </tokens>
        </chunking>
        <chunking id="8" string="his value" type="NP">
          <tokens>
            <token id="9" string="his" />
            <token id="10" string="value" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="8">determine</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">well</governor>
          <dependent id="2">how</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">running</governor>
          <dependent id="3">well</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">running</governor>
          <dependent id="4">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">running</governor>
          <dependent id="5">'s</dependent>
        </dependency>
        <dependency type="csubj">
          <governor id="8">determine</governor>
          <dependent id="6">running</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">determine</governor>
          <dependent id="7">will</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">determine</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">value</governor>
          <dependent id="9">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">determine</governor>
          <dependent id="10">value</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="51" has_coreference="true">
      <content>That&amp;apost;s the key.</content>
      <tokens>
        <token id="1" string="That" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="key" lemma="key" stem="kei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT That)) (VP (VBZ 's) (NP (DT the) (NN key))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="That" type="NP">
          <tokens>
            <token id="1" string="That" />
          </tokens>
        </chunking>
        <chunking id="2" string="the key" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="key" />
          </tokens>
        </chunking>
        <chunking id="3" string="'s the key" type="VP">
          <tokens>
            <token id="2" string="'s" />
            <token id="3" string="the" />
            <token id="4" string="key" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">key</governor>
          <dependent id="1">That</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">key</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">key</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">key</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="52" has_coreference="true">
      <content>Whether he is worth as much after six meets, I don&amp;apost;t know.</content>
      <tokens>
        <token id="1" string="Whether" lemma="whether" stem="whether" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="worth" lemma="worth" stem="worth" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="as" lemma="as" stem="a" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="much" lemma="much" stem="much" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="six" lemma="six" stem="six" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="9" string="meets" lemma="meet" stem="meet" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="know" lemma="know" stem="know" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN Whether) (S (NP (PRP he)) (VP (VBZ is) (ADJP (JJ worth)) (ADVP (ADVP (RB as) (RB much)) (SBAR (IN after) (S (NP (CD six)) (VP (VBZ meets)))))))) (, ,) (NP (PRP I)) (VP (VBP do) (RB n't) (VP (VB know))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="six" type="NP">
          <tokens>
            <token id="8" string="six" />
          </tokens>
        </chunking>
        <chunking id="2" string="do n't know" type="VP">
          <tokens>
            <token id="12" string="do" />
            <token id="13" string="n't" />
            <token id="14" string="know" />
          </tokens>
        </chunking>
        <chunking id="3" string="meets" type="VP">
          <tokens>
            <token id="9" string="meets" />
          </tokens>
        </chunking>
        <chunking id="4" string="after six meets" type="SBAR">
          <tokens>
            <token id="7" string="after" />
            <token id="8" string="six" />
            <token id="9" string="meets" />
          </tokens>
        </chunking>
        <chunking id="5" string="Whether he is worth as much after six meets" type="SBAR">
          <tokens>
            <token id="1" string="Whether" />
            <token id="2" string="he" />
            <token id="3" string="is" />
            <token id="4" string="worth" />
            <token id="5" string="as" />
            <token id="6" string="much" />
            <token id="7" string="after" />
            <token id="8" string="six" />
            <token id="9" string="meets" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="11" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="know" type="VP">
          <tokens>
            <token id="14" string="know" />
          </tokens>
        </chunking>
        <chunking id="8" string="he" type="NP">
          <tokens>
            <token id="2" string="he" />
          </tokens>
        </chunking>
        <chunking id="9" string="worth" type="ADJP">
          <tokens>
            <token id="4" string="worth" />
          </tokens>
        </chunking>
        <chunking id="10" string="is worth as much after six meets" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="worth" />
            <token id="5" string="as" />
            <token id="6" string="much" />
            <token id="7" string="after" />
            <token id="8" string="six" />
            <token id="9" string="meets" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="4">worth</governor>
          <dependent id="1">Whether</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">worth</governor>
          <dependent id="2">he</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">worth</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="14">know</governor>
          <dependent id="4">worth</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">much</governor>
          <dependent id="5">as</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">worth</governor>
          <dependent id="6">much</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">meets</governor>
          <dependent id="7">after</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">meets</governor>
          <dependent id="8">six</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="6">much</governor>
          <dependent id="9">meets</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">know</governor>
          <dependent id="11">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">know</governor>
          <dependent id="12">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="14">know</governor>
          <dependent id="13">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">know</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="six" type="NUMBER" score="0.0">
          <tokens>
            <token id="8" string="six" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="53" has_coreference="true">
      <content>You&amp;apost;re only as good as your last race, and the fans know that.&amp;quot;</content>
      <tokens>
        <token id="1" string="You" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="'re" lemma="be" stem="'re" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="as" lemma="as" stem="a" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="good" lemma="good" stem="good" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="your" lemma="you" stem="your" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="race" lemma="race" stem="race" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="fans" lemma="fan" stem="fan" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="know" lemma="know" stem="know" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP You)) (VP (VBP 're) (ADVP (RB only)) (ADJP (RB as) (JJ good) (PP (IN as) (NP (PRP$ your) (JJ last) (NN race)))))) (, ,) (CC and) (S (NP (DT the) (NNS fans)) (VP (VBP know) (ADVP (IN that)))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="the fans" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="fans" />
          </tokens>
        </chunking>
        <chunking id="2" string="know that" type="VP">
          <tokens>
            <token id="14" string="know" />
            <token id="15" string="that" />
          </tokens>
        </chunking>
        <chunking id="3" string="as good as your last race" type="ADJP">
          <tokens>
            <token id="4" string="as" />
            <token id="5" string="good" />
            <token id="6" string="as" />
            <token id="7" string="your" />
            <token id="8" string="last" />
            <token id="9" string="race" />
          </tokens>
        </chunking>
        <chunking id="4" string="'re only as good as your last race" type="VP">
          <tokens>
            <token id="2" string="'re" />
            <token id="3" string="only" />
            <token id="4" string="as" />
            <token id="5" string="good" />
            <token id="6" string="as" />
            <token id="7" string="your" />
            <token id="8" string="last" />
            <token id="9" string="race" />
          </tokens>
        </chunking>
        <chunking id="5" string="You" type="NP">
          <tokens>
            <token id="1" string="You" />
          </tokens>
        </chunking>
        <chunking id="6" string="your last race" type="NP">
          <tokens>
            <token id="7" string="your" />
            <token id="8" string="last" />
            <token id="9" string="race" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">good</governor>
          <dependent id="1">You</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">good</governor>
          <dependent id="2">'re</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">good</governor>
          <dependent id="3">only</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">good</governor>
          <dependent id="4">as</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">good</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">race</governor>
          <dependent id="6">as</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">race</governor>
          <dependent id="7">your</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">race</governor>
          <dependent id="8">last</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">good</governor>
          <dependent id="9">race</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">good</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">fans</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">know</governor>
          <dependent id="13">fans</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">good</governor>
          <dependent id="14">know</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">know</governor>
          <dependent id="15">that</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="54" has_coreference="true">
      <content>Howard Schmertz of the Millrose Games in New York has an interest in Johnson, but perhaps not the budget.</content>
      <tokens>
        <token id="1" string="Howard" lemma="Howard" stem="howard" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Schmertz" lemma="Schmertz" stem="schmertz" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="Millrose" lemma="Millrose" stem="millros" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="Games" lemma="Games" stem="game" pos="NNPS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="New" lemma="New" stem="new" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="9" string="York" lemma="York" stem="york" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="10" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="interest" lemma="interest" stem="interest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="perhaps" lemma="perhaps" stem="perhap" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="budget" lemma="budget" stem="budget" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Howard) (NNP Schmertz)) (PP (IN of) (NP (NP (DT the) (NNP Millrose) (NNPS Games)) (PP (IN in) (NP (NNP New) (NNP York)))))) (VP (VBZ has) (NP (NP (DT an) (NN interest)) (PP (IN in) (UCP (NP (NNP Johnson)) (, ,) (CC but) (ADVP (RB perhaps)) (RB not) (NP (DT the) (NN budget)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="New York" type="NP">
          <tokens>
            <token id="8" string="New" />
            <token id="9" string="York" />
          </tokens>
        </chunking>
        <chunking id="2" string="Johnson" type="NP">
          <tokens>
            <token id="14" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="3" string="the Millrose Games in New York" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="Millrose" />
            <token id="6" string="Games" />
            <token id="7" string="in" />
            <token id="8" string="New" />
            <token id="9" string="York" />
          </tokens>
        </chunking>
        <chunking id="4" string="Howard Schmertz" type="NP">
          <tokens>
            <token id="1" string="Howard" />
            <token id="2" string="Schmertz" />
          </tokens>
        </chunking>
        <chunking id="5" string="has an interest in Johnson , but perhaps not the budget" type="VP">
          <tokens>
            <token id="10" string="has" />
            <token id="11" string="an" />
            <token id="12" string="interest" />
            <token id="13" string="in" />
            <token id="14" string="Johnson" />
            <token id="15" string="," />
            <token id="16" string="but" />
            <token id="17" string="perhaps" />
            <token id="18" string="not" />
            <token id="19" string="the" />
            <token id="20" string="budget" />
          </tokens>
        </chunking>
        <chunking id="6" string="an interest in Johnson , but perhaps not the budget" type="NP">
          <tokens>
            <token id="11" string="an" />
            <token id="12" string="interest" />
            <token id="13" string="in" />
            <token id="14" string="Johnson" />
            <token id="15" string="," />
            <token id="16" string="but" />
            <token id="17" string="perhaps" />
            <token id="18" string="not" />
            <token id="19" string="the" />
            <token id="20" string="budget" />
          </tokens>
        </chunking>
        <chunking id="7" string="Howard Schmertz of the Millrose Games in New York" type="NP">
          <tokens>
            <token id="1" string="Howard" />
            <token id="2" string="Schmertz" />
            <token id="3" string="of" />
            <token id="4" string="the" />
            <token id="5" string="Millrose" />
            <token id="6" string="Games" />
            <token id="7" string="in" />
            <token id="8" string="New" />
            <token id="9" string="York" />
          </tokens>
        </chunking>
        <chunking id="8" string="the budget" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="budget" />
          </tokens>
        </chunking>
        <chunking id="9" string="the Millrose Games" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="Millrose" />
            <token id="6" string="Games" />
          </tokens>
        </chunking>
        <chunking id="10" string="an interest" type="NP">
          <tokens>
            <token id="11" string="an" />
            <token id="12" string="interest" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Schmertz</governor>
          <dependent id="1">Howard</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">has</governor>
          <dependent id="2">Schmertz</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Games</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">Games</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Games</governor>
          <dependent id="5">Millrose</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">Schmertz</governor>
          <dependent id="6">Games</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">York</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">York</governor>
          <dependent id="8">New</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">Games</governor>
          <dependent id="9">York</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">has</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">interest</governor>
          <dependent id="11">an</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">has</governor>
          <dependent id="12">interest</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Johnson</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">interest</governor>
          <dependent id="14">Johnson</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">Johnson</governor>
          <dependent id="16">but</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">Johnson</governor>
          <dependent id="17">perhaps</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">Johnson</governor>
          <dependent id="18">not</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">budget</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="14">Johnson</governor>
          <dependent id="20">budget</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="New York" type="LOCATION" score="0.0">
          <tokens>
            <token id="8" string="New" />
            <token id="9" string="York" />
          </tokens>
        </entity>
        <entity id="2" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Johnson" />
          </tokens>
        </entity>
        <entity id="3" string="Howard Schmertz" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Howard" />
            <token id="2" string="Schmertz" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="55" has_coreference="true">
      <content>&amp;quot;There is a lot of interest in seeing whether this fellow is a truly great runner or if he is what Carl Lewis said he is, a fair runner who got there by taking drugs,&amp;quot; Schmertz said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="lot" lemma="lot" stem="lot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="interest" lemma="interest" stem="interest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="seeing" lemma="see" stem="see" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="whether" lemma="whether" stem="whether" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="fellow" lemma="fellow" stem="fellow" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="truly" lemma="truly" stem="truli" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="great" lemma="great" stem="great" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="runner" lemma="runner" stem="runner" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="Carl" lemma="Carl" stem="carl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="24" string="Lewis" lemma="Lewis" stem="lewi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="25" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="fair" lemma="fair" stem="fair" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="runner" lemma="runner" stem="runner" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="got" lemma="get" stem="got" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="taking" lemma="take" stem="take" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="drugs" lemma="drug" stem="drug" pos="NNS" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="true" />
        <token id="38" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="Schmertz" lemma="Schmertz" stem="schmertz" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="41" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (EX There)) (VP (VBZ is) (NP (NP (DT a) (NN lot)) (PP (IN of) (NP (NP (NN interest)) (PP (IN in) (S (VP (VBG seeing) (SBAR (SBAR (IN whether) (S (NP (DT this) (NN fellow)) (VP (VBZ is) (NP (DT a) (ADJP (RB truly) (JJ great)) (NN runner))))) (CC or) (SBAR (IN if) (S (NP (PRP he)) (VP (VBZ is) (SBAR (WHNP (WP what)) (S (NP (NNP Carl) (NNP Lewis)) (VP (VBD said) (SBAR (S (NP (PRP he)) (VP (VBZ is) (, ,) (FRAG (NP (NP (DT a) (JJ fair) (NN runner)) (SBAR (WHNP (WP who)) (S (VP (VBD got) (NP (EX there)) (PP (IN by) (S (VP (VBG taking) (NP (NNS drugs)))))))))))))))))))))))))))) (, ,) ('' '') (NP (NNP Schmertz)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="what Carl Lewis said he is , a fair runner who got there by taking drugs" type="SBAR">
          <tokens>
            <token id="22" string="what" />
            <token id="23" string="Carl" />
            <token id="24" string="Lewis" />
            <token id="25" string="said" />
            <token id="26" string="he" />
            <token id="27" string="is" />
            <token id="28" string="," />
            <token id="29" string="a" />
            <token id="30" string="fair" />
            <token id="31" string="runner" />
            <token id="32" string="who" />
            <token id="33" string="got" />
            <token id="34" string="there" />
            <token id="35" string="by" />
            <token id="36" string="taking" />
            <token id="37" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="2" string="said he is , a fair runner who got there by taking drugs" type="VP">
          <tokens>
            <token id="25" string="said" />
            <token id="26" string="he" />
            <token id="27" string="is" />
            <token id="28" string="," />
            <token id="29" string="a" />
            <token id="30" string="fair" />
            <token id="31" string="runner" />
            <token id="32" string="who" />
            <token id="33" string="got" />
            <token id="34" string="there" />
            <token id="35" string="by" />
            <token id="36" string="taking" />
            <token id="37" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="3" string="a fair runner who got there by taking drugs" type="NP">
          <tokens>
            <token id="29" string="a" />
            <token id="30" string="fair" />
            <token id="31" string="runner" />
            <token id="32" string="who" />
            <token id="33" string="got" />
            <token id="34" string="there" />
            <token id="35" string="by" />
            <token id="36" string="taking" />
            <token id="37" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="4" string="is , a fair runner who got there by taking drugs" type="VP">
          <tokens>
            <token id="27" string="is" />
            <token id="28" string="," />
            <token id="29" string="a" />
            <token id="30" string="fair" />
            <token id="31" string="runner" />
            <token id="32" string="who" />
            <token id="33" string="got" />
            <token id="34" string="there" />
            <token id="35" string="by" />
            <token id="36" string="taking" />
            <token id="37" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="5" string="drugs" type="NP">
          <tokens>
            <token id="37" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="6" string="if he is what Carl Lewis said he is , a fair runner who got there by taking drugs" type="SBAR">
          <tokens>
            <token id="19" string="if" />
            <token id="20" string="he" />
            <token id="21" string="is" />
            <token id="22" string="what" />
            <token id="23" string="Carl" />
            <token id="24" string="Lewis" />
            <token id="25" string="said" />
            <token id="26" string="he" />
            <token id="27" string="is" />
            <token id="28" string="," />
            <token id="29" string="a" />
            <token id="30" string="fair" />
            <token id="31" string="runner" />
            <token id="32" string="who" />
            <token id="33" string="got" />
            <token id="34" string="there" />
            <token id="35" string="by" />
            <token id="36" string="taking" />
            <token id="37" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="7" string="interest in seeing whether this fellow is a truly great runner or if he is what Carl Lewis said he is , a fair runner who got there by taking drugs" type="NP">
          <tokens>
            <token id="7" string="interest" />
            <token id="8" string="in" />
            <token id="9" string="seeing" />
            <token id="10" string="whether" />
            <token id="11" string="this" />
            <token id="12" string="fellow" />
            <token id="13" string="is" />
            <token id="14" string="a" />
            <token id="15" string="truly" />
            <token id="16" string="great" />
            <token id="17" string="runner" />
            <token id="18" string="or" />
            <token id="19" string="if" />
            <token id="20" string="he" />
            <token id="21" string="is" />
            <token id="22" string="what" />
            <token id="23" string="Carl" />
            <token id="24" string="Lewis" />
            <token id="25" string="said" />
            <token id="26" string="he" />
            <token id="27" string="is" />
            <token id="28" string="," />
            <token id="29" string="a" />
            <token id="30" string="fair" />
            <token id="31" string="runner" />
            <token id="32" string="who" />
            <token id="33" string="got" />
            <token id="34" string="there" />
            <token id="35" string="by" />
            <token id="36" string="taking" />
            <token id="37" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="8" string="seeing whether this fellow is a truly great runner or if he is what Carl Lewis said he is , a fair runner who got there by taking drugs" type="VP">
          <tokens>
            <token id="9" string="seeing" />
            <token id="10" string="whether" />
            <token id="11" string="this" />
            <token id="12" string="fellow" />
            <token id="13" string="is" />
            <token id="14" string="a" />
            <token id="15" string="truly" />
            <token id="16" string="great" />
            <token id="17" string="runner" />
            <token id="18" string="or" />
            <token id="19" string="if" />
            <token id="20" string="he" />
            <token id="21" string="is" />
            <token id="22" string="what" />
            <token id="23" string="Carl" />
            <token id="24" string="Lewis" />
            <token id="25" string="said" />
            <token id="26" string="he" />
            <token id="27" string="is" />
            <token id="28" string="," />
            <token id="29" string="a" />
            <token id="30" string="fair" />
            <token id="31" string="runner" />
            <token id="32" string="who" />
            <token id="33" string="got" />
            <token id="34" string="there" />
            <token id="35" string="by" />
            <token id="36" string="taking" />
            <token id="37" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="9" string="taking drugs" type="VP">
          <tokens>
            <token id="36" string="taking" />
            <token id="37" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="10" string="this fellow" type="NP">
          <tokens>
            <token id="11" string="this" />
            <token id="12" string="fellow" />
          </tokens>
        </chunking>
        <chunking id="11" string="there" type="NP">
          <tokens>
            <token id="34" string="there" />
          </tokens>
        </chunking>
        <chunking id="12" string="a fair runner" type="NP">
          <tokens>
            <token id="29" string="a" />
            <token id="30" string="fair" />
            <token id="31" string="runner" />
          </tokens>
        </chunking>
        <chunking id="13" string="a lot" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="lot" />
          </tokens>
        </chunking>
        <chunking id="14" string="whether this fellow is a truly great runner or if he is what Carl Lewis said he is , a fair runner who got there by taking drugs" type="SBAR">
          <tokens>
            <token id="10" string="whether" />
            <token id="11" string="this" />
            <token id="12" string="fellow" />
            <token id="13" string="is" />
            <token id="14" string="a" />
            <token id="15" string="truly" />
            <token id="16" string="great" />
            <token id="17" string="runner" />
            <token id="18" string="or" />
            <token id="19" string="if" />
            <token id="20" string="he" />
            <token id="21" string="is" />
            <token id="22" string="what" />
            <token id="23" string="Carl" />
            <token id="24" string="Lewis" />
            <token id="25" string="said" />
            <token id="26" string="he" />
            <token id="27" string="is" />
            <token id="28" string="," />
            <token id="29" string="a" />
            <token id="30" string="fair" />
            <token id="31" string="runner" />
            <token id="32" string="who" />
            <token id="33" string="got" />
            <token id="34" string="there" />
            <token id="35" string="by" />
            <token id="36" string="taking" />
            <token id="37" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="15" string="is what Carl Lewis said he is , a fair runner who got there by taking drugs" type="VP">
          <tokens>
            <token id="21" string="is" />
            <token id="22" string="what" />
            <token id="23" string="Carl" />
            <token id="24" string="Lewis" />
            <token id="25" string="said" />
            <token id="26" string="he" />
            <token id="27" string="is" />
            <token id="28" string="," />
            <token id="29" string="a" />
            <token id="30" string="fair" />
            <token id="31" string="runner" />
            <token id="32" string="who" />
            <token id="33" string="got" />
            <token id="34" string="there" />
            <token id="35" string="by" />
            <token id="36" string="taking" />
            <token id="37" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="16" string="Carl Lewis" type="NP">
          <tokens>
            <token id="23" string="Carl" />
            <token id="24" string="Lewis" />
          </tokens>
        </chunking>
        <chunking id="17" string="whether this fellow is a truly great runner" type="SBAR">
          <tokens>
            <token id="10" string="whether" />
            <token id="11" string="this" />
            <token id="12" string="fellow" />
            <token id="13" string="is" />
            <token id="14" string="a" />
            <token id="15" string="truly" />
            <token id="16" string="great" />
            <token id="17" string="runner" />
          </tokens>
        </chunking>
        <chunking id="18" string="he" type="NP">
          <tokens>
            <token id="20" string="he" />
          </tokens>
        </chunking>
        <chunking id="19" string="a lot of interest in seeing whether this fellow is a truly great runner or if he is what Carl Lewis said he is , a fair runner who got there by taking drugs" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="lot" />
            <token id="6" string="of" />
            <token id="7" string="interest" />
            <token id="8" string="in" />
            <token id="9" string="seeing" />
            <token id="10" string="whether" />
            <token id="11" string="this" />
            <token id="12" string="fellow" />
            <token id="13" string="is" />
            <token id="14" string="a" />
            <token id="15" string="truly" />
            <token id="16" string="great" />
            <token id="17" string="runner" />
            <token id="18" string="or" />
            <token id="19" string="if" />
            <token id="20" string="he" />
            <token id="21" string="is" />
            <token id="22" string="what" />
            <token id="23" string="Carl" />
            <token id="24" string="Lewis" />
            <token id="25" string="said" />
            <token id="26" string="he" />
            <token id="27" string="is" />
            <token id="28" string="," />
            <token id="29" string="a" />
            <token id="30" string="fair" />
            <token id="31" string="runner" />
            <token id="32" string="who" />
            <token id="33" string="got" />
            <token id="34" string="there" />
            <token id="35" string="by" />
            <token id="36" string="taking" />
            <token id="37" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="20" string="he is , a fair runner who got there by taking drugs" type="SBAR">
          <tokens>
            <token id="26" string="he" />
            <token id="27" string="is" />
            <token id="28" string="," />
            <token id="29" string="a" />
            <token id="30" string="fair" />
            <token id="31" string="runner" />
            <token id="32" string="who" />
            <token id="33" string="got" />
            <token id="34" string="there" />
            <token id="35" string="by" />
            <token id="36" string="taking" />
            <token id="37" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="21" string="is a lot of interest in seeing whether this fellow is a truly great runner or if he is what Carl Lewis said he is , a fair runner who got there by taking drugs" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="a" />
            <token id="5" string="lot" />
            <token id="6" string="of" />
            <token id="7" string="interest" />
            <token id="8" string="in" />
            <token id="9" string="seeing" />
            <token id="10" string="whether" />
            <token id="11" string="this" />
            <token id="12" string="fellow" />
            <token id="13" string="is" />
            <token id="14" string="a" />
            <token id="15" string="truly" />
            <token id="16" string="great" />
            <token id="17" string="runner" />
            <token id="18" string="or" />
            <token id="19" string="if" />
            <token id="20" string="he" />
            <token id="21" string="is" />
            <token id="22" string="what" />
            <token id="23" string="Carl" />
            <token id="24" string="Lewis" />
            <token id="25" string="said" />
            <token id="26" string="he" />
            <token id="27" string="is" />
            <token id="28" string="," />
            <token id="29" string="a" />
            <token id="30" string="fair" />
            <token id="31" string="runner" />
            <token id="32" string="who" />
            <token id="33" string="got" />
            <token id="34" string="there" />
            <token id="35" string="by" />
            <token id="36" string="taking" />
            <token id="37" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="22" string="who got there by taking drugs" type="SBAR">
          <tokens>
            <token id="32" string="who" />
            <token id="33" string="got" />
            <token id="34" string="there" />
            <token id="35" string="by" />
            <token id="36" string="taking" />
            <token id="37" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="23" string="got there by taking drugs" type="VP">
          <tokens>
            <token id="33" string="got" />
            <token id="34" string="there" />
            <token id="35" string="by" />
            <token id="36" string="taking" />
            <token id="37" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="24" string="There" type="NP">
          <tokens>
            <token id="2" string="There" />
          </tokens>
        </chunking>
        <chunking id="25" string="Schmertz" type="NP">
          <tokens>
            <token id="40" string="Schmertz" />
          </tokens>
        </chunking>
        <chunking id="26" string="interest" type="NP">
          <tokens>
            <token id="7" string="interest" />
          </tokens>
        </chunking>
        <chunking id="27" string="truly great" type="ADJP">
          <tokens>
            <token id="15" string="truly" />
            <token id="16" string="great" />
          </tokens>
        </chunking>
        <chunking id="28" string="said" type="VP">
          <tokens>
            <token id="41" string="said" />
          </tokens>
        </chunking>
        <chunking id="29" string="a truly great runner" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="truly" />
            <token id="16" string="great" />
            <token id="17" string="runner" />
          </tokens>
        </chunking>
        <chunking id="30" string="is a truly great runner" type="VP">
          <tokens>
            <token id="13" string="is" />
            <token id="14" string="a" />
            <token id="15" string="truly" />
            <token id="16" string="great" />
            <token id="17" string="runner" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="3">is</governor>
          <dependent id="2">There</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="41">said</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">lot</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">is</governor>
          <dependent id="5">lot</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">interest</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">lot</governor>
          <dependent id="7">interest</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">seeing</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="7">interest</governor>
          <dependent id="9">seeing</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">runner</governor>
          <dependent id="10">whether</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">fellow</governor>
          <dependent id="11">this</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">runner</governor>
          <dependent id="12">fellow</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="17">runner</governor>
          <dependent id="13">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">runner</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">great</governor>
          <dependent id="15">truly</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">runner</governor>
          <dependent id="16">great</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">seeing</governor>
          <dependent id="17">runner</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">runner</governor>
          <dependent id="18">or</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">is</governor>
          <dependent id="19">if</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">is</governor>
          <dependent id="20">he</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">runner</governor>
          <dependent id="21">is</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">said</governor>
          <dependent id="22">what</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">Lewis</governor>
          <dependent id="23">Carl</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">said</governor>
          <dependent id="24">Lewis</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="21">is</governor>
          <dependent id="25">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">is</governor>
          <dependent id="26">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="25">said</governor>
          <dependent id="27">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">runner</governor>
          <dependent id="29">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">runner</governor>
          <dependent id="30">fair</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="27">is</governor>
          <dependent id="31">runner</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="33">got</governor>
          <dependent id="32">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="31">runner</governor>
          <dependent id="33">got</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="33">got</governor>
          <dependent id="34">there</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="36">taking</governor>
          <dependent id="35">by</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="33">got</governor>
          <dependent id="36">taking</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="36">taking</governor>
          <dependent id="37">drugs</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="41">said</governor>
          <dependent id="40">Schmertz</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="41">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="drugs" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="37" string="drugs" />
          </tokens>
        </entity>
        <entity id="2" string="Schmertz" type="PERSON" score="0.0">
          <tokens>
            <token id="40" string="Schmertz" />
          </tokens>
        </entity>
        <entity id="3" string="Carl Lewis" type="PERSON" score="0.0">
          <tokens>
            <token id="23" string="Carl" />
            <token id="24" string="Lewis" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="56" has_coreference="true">
      <content>&amp;quot;I have no way of knowing.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="way" lemma="way" stem="wai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="knowing" lemma="know" stem="know" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (VBP have) (NP (NP (DT no) (NN way)) (PP (IN of) (S (VP (VBG knowing)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="have no way of knowing" type="VP">
          <tokens>
            <token id="3" string="have" />
            <token id="4" string="no" />
            <token id="5" string="way" />
            <token id="6" string="of" />
            <token id="7" string="knowing" />
          </tokens>
        </chunking>
        <chunking id="2" string="knowing" type="VP">
          <tokens>
            <token id="7" string="knowing" />
          </tokens>
        </chunking>
        <chunking id="3" string="no way of knowing" type="NP">
          <tokens>
            <token id="4" string="no" />
            <token id="5" string="way" />
            <token id="6" string="of" />
            <token id="7" string="knowing" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="no way" type="NP">
          <tokens>
            <token id="4" string="no" />
            <token id="5" string="way" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">have</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">have</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">way</governor>
          <dependent id="4">no</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">have</governor>
          <dependent id="5">way</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">knowing</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="5">way</governor>
          <dependent id="7">knowing</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="57" has_coreference="true">
      <content>As far as the money, I expect a lot of big stars and I&amp;apost;m going to have a lot of problems giving out (big appearence fees).</content>
      <tokens>
        <token id="1" string="As" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="far" lemma="far" stem="far" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="money" lemma="money" stem="monei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="expect" lemma="expect" stem="expect" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="lot" lemma="lot" stem="lot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="big" lemma="big" stem="big" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="stars" lemma="star" stem="star" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="'m" lemma="be" stem="'m" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="lot" lemma="lot" stem="lot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="problems" lemma="problem" stem="problem" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="giving" lemma="give" stem="give" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="26" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="big" lemma="big" stem="big" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="appearence" lemma="appearence" stem="appear" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="fees" lemma="fee" stem="fee" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="30" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN As) (ADVP (RB far) (PP (IN as) (NP (DT the) (NN money))))) (, ,) (S (NP (PRP I)) (VP (VBP expect) (NP (NP (DT a) (NN lot)) (PP (IN of) (NP (JJ big) (NNS stars)))))) (CC and) (S (NP (PRP I)) (VP (VBP 'm) (VP (VBG going) (S (VP (TO to) (VP (VB have) (NP (NP (DT a) (NN lot)) (PP (IN of) (NP (NP (NNS problems)) (VP (VBG giving) (PRT (RP out))))) (PRN (-LRB- -LRB-) (NP (NP (JJ big) (NN appearence)) (NP (NNS fees))) (-RRB- -RRB-))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="problems giving out" type="NP">
          <tokens>
            <token id="23" string="problems" />
            <token id="24" string="giving" />
            <token id="25" string="out" />
          </tokens>
        </chunking>
        <chunking id="2" string="to have a lot of problems giving out -LRB- big appearence fees -RRB-" type="VP">
          <tokens>
            <token id="18" string="to" />
            <token id="19" string="have" />
            <token id="20" string="a" />
            <token id="21" string="lot" />
            <token id="22" string="of" />
            <token id="23" string="problems" />
            <token id="24" string="giving" />
            <token id="25" string="out" />
            <token id="26" string="(" />
            <token id="27" string="big" />
            <token id="28" string="appearence" />
            <token id="29" string="fees" />
            <token id="30" string=")" />
          </tokens>
        </chunking>
        <chunking id="3" string="a lot of problems giving out -LRB- big appearence fees -RRB-" type="NP">
          <tokens>
            <token id="20" string="a" />
            <token id="21" string="lot" />
            <token id="22" string="of" />
            <token id="23" string="problems" />
            <token id="24" string="giving" />
            <token id="25" string="out" />
            <token id="26" string="(" />
            <token id="27" string="big" />
            <token id="28" string="appearence" />
            <token id="29" string="fees" />
            <token id="30" string=")" />
          </tokens>
        </chunking>
        <chunking id="4" string="fees" type="NP">
          <tokens>
            <token id="29" string="fees" />
          </tokens>
        </chunking>
        <chunking id="5" string="big appearence fees" type="NP">
          <tokens>
            <token id="27" string="big" />
            <token id="28" string="appearence" />
            <token id="29" string="fees" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="7" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="going to have a lot of problems giving out -LRB- big appearence fees -RRB-" type="VP">
          <tokens>
            <token id="17" string="going" />
            <token id="18" string="to" />
            <token id="19" string="have" />
            <token id="20" string="a" />
            <token id="21" string="lot" />
            <token id="22" string="of" />
            <token id="23" string="problems" />
            <token id="24" string="giving" />
            <token id="25" string="out" />
            <token id="26" string="(" />
            <token id="27" string="big" />
            <token id="28" string="appearence" />
            <token id="29" string="fees" />
            <token id="30" string=")" />
          </tokens>
        </chunking>
        <chunking id="8" string="expect a lot of big stars" type="VP">
          <tokens>
            <token id="8" string="expect" />
            <token id="9" string="a" />
            <token id="10" string="lot" />
            <token id="11" string="of" />
            <token id="12" string="big" />
            <token id="13" string="stars" />
          </tokens>
        </chunking>
        <chunking id="9" string="the money" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="money" />
          </tokens>
        </chunking>
        <chunking id="10" string="big appearence" type="NP">
          <tokens>
            <token id="27" string="big" />
            <token id="28" string="appearence" />
          </tokens>
        </chunking>
        <chunking id="11" string="have a lot of problems giving out -LRB- big appearence fees -RRB-" type="VP">
          <tokens>
            <token id="19" string="have" />
            <token id="20" string="a" />
            <token id="21" string="lot" />
            <token id="22" string="of" />
            <token id="23" string="problems" />
            <token id="24" string="giving" />
            <token id="25" string="out" />
            <token id="26" string="(" />
            <token id="27" string="big" />
            <token id="28" string="appearence" />
            <token id="29" string="fees" />
            <token id="30" string=")" />
          </tokens>
        </chunking>
        <chunking id="12" string="big stars" type="NP">
          <tokens>
            <token id="12" string="big" />
            <token id="13" string="stars" />
          </tokens>
        </chunking>
        <chunking id="13" string="a lot" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="lot" />
          </tokens>
        </chunking>
        <chunking id="14" string="problems" type="NP">
          <tokens>
            <token id="23" string="problems" />
          </tokens>
        </chunking>
        <chunking id="15" string="'m going to have a lot of problems giving out -LRB- big appearence fees -RRB-" type="VP">
          <tokens>
            <token id="16" string="'m" />
            <token id="17" string="going" />
            <token id="18" string="to" />
            <token id="19" string="have" />
            <token id="20" string="a" />
            <token id="21" string="lot" />
            <token id="22" string="of" />
            <token id="23" string="problems" />
            <token id="24" string="giving" />
            <token id="25" string="out" />
            <token id="26" string="(" />
            <token id="27" string="big" />
            <token id="28" string="appearence" />
            <token id="29" string="fees" />
            <token id="30" string=")" />
          </tokens>
        </chunking>
        <chunking id="16" string="giving out" type="VP">
          <tokens>
            <token id="24" string="giving" />
            <token id="25" string="out" />
          </tokens>
        </chunking>
        <chunking id="17" string="a lot of big stars" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="lot" />
            <token id="11" string="of" />
            <token id="12" string="big" />
            <token id="13" string="stars" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">far</governor>
          <dependent id="1">As</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="8">expect</governor>
          <dependent id="2">far</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">money</governor>
          <dependent id="3">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">money</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">far</governor>
          <dependent id="5">money</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">expect</governor>
          <dependent id="7">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">expect</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">lot</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">expect</governor>
          <dependent id="10">lot</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">stars</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">stars</governor>
          <dependent id="12">big</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">lot</governor>
          <dependent id="13">stars</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">expect</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">going</governor>
          <dependent id="15">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="17">going</governor>
          <dependent id="16">'m</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">expect</governor>
          <dependent id="17">going</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">have</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="17">going</governor>
          <dependent id="19">have</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">lot</governor>
          <dependent id="20">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">have</governor>
          <dependent id="21">lot</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">problems</governor>
          <dependent id="22">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">lot</governor>
          <dependent id="23">problems</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="23">problems</governor>
          <dependent id="24">giving</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="24">giving</governor>
          <dependent id="25">out</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">appearence</governor>
          <dependent id="27">big</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="21">lot</governor>
          <dependent id="28">appearence</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="28">appearence</governor>
          <dependent id="29">fees</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="58" has_coreference="true">
      <content>If you give him $10,000 and people are beating him, you could have problems.&amp;quot;</content>
      <tokens>
        <token id="1" string="If" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="give" lemma="give" stem="give" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="6" string="10,000" lemma="10,000" stem="10,000" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="beating" lemma="beat" stem="beat" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="problems" lemma="problem" stem="problem" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN If) (S (S (NP (PRP you)) (VP (VBP give) (NP (PRP him)) (NP ($ $) (CD 10,000)))) (CC and) (S (NP (NNS people)) (VP (VBP are) (VP (VBG beating) (NP (PRP him))))))) (, ,) (NP (PRP you)) (VP (MD could) (VP (VB have) (NP (NNS problems)))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="If you give him $ 10,000 and people are beating him" type="SBAR">
          <tokens>
            <token id="1" string="If" />
            <token id="2" string="you" />
            <token id="3" string="give" />
            <token id="4" string="him" />
            <token id="5" string="$" />
            <token id="6" string="10,000" />
            <token id="7" string="and" />
            <token id="8" string="people" />
            <token id="9" string="are" />
            <token id="10" string="beating" />
            <token id="11" string="him" />
          </tokens>
        </chunking>
        <chunking id="2" string="are beating him" type="VP">
          <tokens>
            <token id="9" string="are" />
            <token id="10" string="beating" />
            <token id="11" string="him" />
          </tokens>
        </chunking>
        <chunking id="3" string="give him $ 10,000" type="VP">
          <tokens>
            <token id="3" string="give" />
            <token id="4" string="him" />
            <token id="5" string="$" />
            <token id="6" string="10,000" />
          </tokens>
        </chunking>
        <chunking id="4" string="$ 10,000" type="NP">
          <tokens>
            <token id="5" string="$" />
            <token id="6" string="10,000" />
          </tokens>
        </chunking>
        <chunking id="5" string="problems" type="NP">
          <tokens>
            <token id="16" string="problems" />
          </tokens>
        </chunking>
        <chunking id="6" string="him" type="NP">
          <tokens>
            <token id="4" string="him" />
          </tokens>
        </chunking>
        <chunking id="7" string="could have problems" type="VP">
          <tokens>
            <token id="14" string="could" />
            <token id="15" string="have" />
            <token id="16" string="problems" />
          </tokens>
        </chunking>
        <chunking id="8" string="people" type="NP">
          <tokens>
            <token id="8" string="people" />
          </tokens>
        </chunking>
        <chunking id="9" string="beating him" type="VP">
          <tokens>
            <token id="10" string="beating" />
            <token id="11" string="him" />
          </tokens>
        </chunking>
        <chunking id="10" string="have problems" type="VP">
          <tokens>
            <token id="15" string="have" />
            <token id="16" string="problems" />
          </tokens>
        </chunking>
        <chunking id="11" string="you" type="NP">
          <tokens>
            <token id="2" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="3">give</governor>
          <dependent id="1">If</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">give</governor>
          <dependent id="2">you</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="15">have</governor>
          <dependent id="3">give</dependent>
        </dependency>
        <dependency type="iobj">
          <governor id="3">give</governor>
          <dependent id="4">him</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="6">10,000</governor>
          <dependent id="5">$</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">give</governor>
          <dependent id="6">10,000</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">give</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">beating</governor>
          <dependent id="8">people</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">beating</governor>
          <dependent id="9">are</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">give</governor>
          <dependent id="10">beating</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">beating</governor>
          <dependent id="11">him</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">have</governor>
          <dependent id="13">you</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">have</governor>
          <dependent id="14">could</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">have</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">have</governor>
          <dependent id="16">problems</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="$ 10,000" type="MONEY" score="0.0">
          <tokens>
            <token id="5" string="$" />
            <token id="6" string="10,000" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="59" has_coreference="false">
      <content>Already the backlash has begun.</content>
      <tokens>
        <token id="1" string="Already" lemma="already" stem="alreadi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="backlash" lemma="backlash" stem="backlash" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="begun" lemma="begin" stem="begun" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Already)) (NP (DT the) (NN backlash)) (VP (VBZ has) (VP (VBN begun))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="begun" type="VP">
          <tokens>
            <token id="5" string="begun" />
          </tokens>
        </chunking>
        <chunking id="2" string="the backlash" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="backlash" />
          </tokens>
        </chunking>
        <chunking id="3" string="has begun" type="VP">
          <tokens>
            <token id="4" string="has" />
            <token id="5" string="begun" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="5">begun</governor>
          <dependent id="1">Already</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">backlash</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">begun</governor>
          <dependent id="3">backlash</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">begun</governor>
          <dependent id="4">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">begun</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="60" has_coreference="true">
      <content>There is talk of informal athlete boycotts in Canada, where indoor meets often provide car fare and little else to star athletes.</content>
      <tokens>
        <token id="1" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="talk" lemma="talk" stem="talk" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="informal" lemma="informal" stem="inform" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="athlete" lemma="athlete" stem="athlet" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="boycotts" lemma="boycott" stem="boycott" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Canada" lemma="Canada" stem="canada" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="indoor" lemma="indoor" stem="indoor" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="meets" lemma="meet" stem="meet" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="often" lemma="often" stem="often" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="provide" lemma="provide" stem="provid" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="car" lemma="car" stem="car" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="fare" lemma="fare" stem="fare" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="little" lemma="little" stem="littl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="else" lemma="else" stem="els" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="star" lemma="star" stem="star" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="athletes" lemma="athlete" stem="athlet" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (EX There)) (VP (VBZ is) (NP (NP (NN talk)) (PP (IN of) (NP (NP (JJ informal) (NN athlete) (NNS boycotts)) (PP (IN in) (NP (NNP Canada))) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (JJ indoor)) (VP (VBZ meets) (SBAR (S (S (ADVP (RB often)) (VP (VBP provide) (NP (NN car) (NN fare)))) (CC and) (ADVP (JJ little)) (S (ADJP (JJ else) (S (VP (TO to) (VP (VB star) (NP (NNS athletes)))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="informal athlete boycotts in Canada , where indoor meets often provide car fare and little else to star athletes" type="NP">
          <tokens>
            <token id="5" string="informal" />
            <token id="6" string="athlete" />
            <token id="7" string="boycotts" />
            <token id="8" string="in" />
            <token id="9" string="Canada" />
            <token id="10" string="," />
            <token id="11" string="where" />
            <token id="12" string="indoor" />
            <token id="13" string="meets" />
            <token id="14" string="often" />
            <token id="15" string="provide" />
            <token id="16" string="car" />
            <token id="17" string="fare" />
            <token id="18" string="and" />
            <token id="19" string="little" />
            <token id="20" string="else" />
            <token id="21" string="to" />
            <token id="22" string="star" />
            <token id="23" string="athletes" />
          </tokens>
        </chunking>
        <chunking id="2" string="star athletes" type="VP">
          <tokens>
            <token id="22" string="star" />
            <token id="23" string="athletes" />
          </tokens>
        </chunking>
        <chunking id="3" string="meets often provide car fare and little else to star athletes" type="VP">
          <tokens>
            <token id="13" string="meets" />
            <token id="14" string="often" />
            <token id="15" string="provide" />
            <token id="16" string="car" />
            <token id="17" string="fare" />
            <token id="18" string="and" />
            <token id="19" string="little" />
            <token id="20" string="else" />
            <token id="21" string="to" />
            <token id="22" string="star" />
            <token id="23" string="athletes" />
          </tokens>
        </chunking>
        <chunking id="4" string="provide car fare" type="VP">
          <tokens>
            <token id="15" string="provide" />
            <token id="16" string="car" />
            <token id="17" string="fare" />
          </tokens>
        </chunking>
        <chunking id="5" string="to star athletes" type="VP">
          <tokens>
            <token id="21" string="to" />
            <token id="22" string="star" />
            <token id="23" string="athletes" />
          </tokens>
        </chunking>
        <chunking id="6" string="else to star athletes" type="ADJP">
          <tokens>
            <token id="20" string="else" />
            <token id="21" string="to" />
            <token id="22" string="star" />
            <token id="23" string="athletes" />
          </tokens>
        </chunking>
        <chunking id="7" string="informal athlete boycotts" type="NP">
          <tokens>
            <token id="5" string="informal" />
            <token id="6" string="athlete" />
            <token id="7" string="boycotts" />
          </tokens>
        </chunking>
        <chunking id="8" string="athletes" type="NP">
          <tokens>
            <token id="23" string="athletes" />
          </tokens>
        </chunking>
        <chunking id="9" string="Canada" type="NP">
          <tokens>
            <token id="9" string="Canada" />
          </tokens>
        </chunking>
        <chunking id="10" string="There" type="NP">
          <tokens>
            <token id="1" string="There" />
          </tokens>
        </chunking>
        <chunking id="11" string="car fare" type="NP">
          <tokens>
            <token id="16" string="car" />
            <token id="17" string="fare" />
          </tokens>
        </chunking>
        <chunking id="12" string="often provide car fare and little else to star athletes" type="SBAR">
          <tokens>
            <token id="14" string="often" />
            <token id="15" string="provide" />
            <token id="16" string="car" />
            <token id="17" string="fare" />
            <token id="18" string="and" />
            <token id="19" string="little" />
            <token id="20" string="else" />
            <token id="21" string="to" />
            <token id="22" string="star" />
            <token id="23" string="athletes" />
          </tokens>
        </chunking>
        <chunking id="13" string="indoor" type="NP">
          <tokens>
            <token id="12" string="indoor" />
          </tokens>
        </chunking>
        <chunking id="14" string="where indoor meets often provide car fare and little else to star athletes" type="SBAR">
          <tokens>
            <token id="11" string="where" />
            <token id="12" string="indoor" />
            <token id="13" string="meets" />
            <token id="14" string="often" />
            <token id="15" string="provide" />
            <token id="16" string="car" />
            <token id="17" string="fare" />
            <token id="18" string="and" />
            <token id="19" string="little" />
            <token id="20" string="else" />
            <token id="21" string="to" />
            <token id="22" string="star" />
            <token id="23" string="athletes" />
          </tokens>
        </chunking>
        <chunking id="15" string="talk of informal athlete boycotts in Canada , where indoor meets often provide car fare and little else to star athletes" type="NP">
          <tokens>
            <token id="3" string="talk" />
            <token id="4" string="of" />
            <token id="5" string="informal" />
            <token id="6" string="athlete" />
            <token id="7" string="boycotts" />
            <token id="8" string="in" />
            <token id="9" string="Canada" />
            <token id="10" string="," />
            <token id="11" string="where" />
            <token id="12" string="indoor" />
            <token id="13" string="meets" />
            <token id="14" string="often" />
            <token id="15" string="provide" />
            <token id="16" string="car" />
            <token id="17" string="fare" />
            <token id="18" string="and" />
            <token id="19" string="little" />
            <token id="20" string="else" />
            <token id="21" string="to" />
            <token id="22" string="star" />
            <token id="23" string="athletes" />
          </tokens>
        </chunking>
        <chunking id="16" string="where" type="WHADVP">
          <tokens>
            <token id="11" string="where" />
          </tokens>
        </chunking>
        <chunking id="17" string="talk" type="NP">
          <tokens>
            <token id="3" string="talk" />
          </tokens>
        </chunking>
        <chunking id="18" string="is talk of informal athlete boycotts in Canada , where indoor meets often provide car fare and little else to star athletes" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="talk" />
            <token id="4" string="of" />
            <token id="5" string="informal" />
            <token id="6" string="athlete" />
            <token id="7" string="boycotts" />
            <token id="8" string="in" />
            <token id="9" string="Canada" />
            <token id="10" string="," />
            <token id="11" string="where" />
            <token id="12" string="indoor" />
            <token id="13" string="meets" />
            <token id="14" string="often" />
            <token id="15" string="provide" />
            <token id="16" string="car" />
            <token id="17" string="fare" />
            <token id="18" string="and" />
            <token id="19" string="little" />
            <token id="20" string="else" />
            <token id="21" string="to" />
            <token id="22" string="star" />
            <token id="23" string="athletes" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="2">is</governor>
          <dependent id="1">There</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="2">is</governor>
          <dependent id="3">talk</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">boycotts</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">boycotts</governor>
          <dependent id="5">informal</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">boycotts</governor>
          <dependent id="6">athlete</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">talk</governor>
          <dependent id="7">boycotts</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Canada</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">boycotts</governor>
          <dependent id="9">Canada</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">meets</governor>
          <dependent id="11">where</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">meets</governor>
          <dependent id="12">indoor</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="7">boycotts</governor>
          <dependent id="13">meets</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">provide</governor>
          <dependent id="14">often</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="13">meets</governor>
          <dependent id="15">provide</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">fare</governor>
          <dependent id="16">car</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">provide</governor>
          <dependent id="17">fare</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">provide</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">provide</governor>
          <dependent id="19">little</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">provide</governor>
          <dependent id="20">else</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">star</governor>
          <dependent id="21">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="20">else</governor>
          <dependent id="22">star</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">star</governor>
          <dependent id="23">athletes</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Canada" type="LOCATION" score="0.0">
          <tokens>
            <token id="9" string="Canada" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="61" has_coreference="true">
      <content>Johnson reportedly will be paid $10,000 (Canadian) for the meet in Hamilton, a figure that has caused some jealousy among his peers.</content>
      <tokens>
        <token id="1" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="reportedly" lemma="reportedly" stem="reportedli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="paid" lemma="pay" stem="paid" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="7" string="10,000" lemma="10,000" stem="10,000" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="8" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Canadian" lemma="canadian" stem="canadian" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="10" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="meet" lemma="meet" stem="meet" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Hamilton" lemma="Hamilton" stem="hamilton" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="figure" lemma="figure" stem="figur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="caused" lemma="cause" stem="caus" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="jealousy" lemma="jealousy" stem="jealousi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="among" lemma="among" stem="among" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="peers" lemma="peer" stem="peer" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Johnson)) (ADVP (RB reportedly)) (VP (MD will) (VP (VB be) (VP (VBN paid) (NP (NP ($ $) (CD 10,000)) (PRN (-LRB- -LRB-) (NP (JJ Canadian)) (-RRB- -RRB-))) (SBAR (IN for) (S (NP (DT the)) (VP (VBP meet) (PP (IN in) (NP (NP (NNP Hamilton)) (, ,) (NP (NP (DT a) (NN figure)) (SBAR (WHNP (WDT that)) (S (VP (VBZ has) (VP (VBN caused) (NP (NP (DT some) (NN jealousy)) (PP (IN among) (NP (PRP$ his) (NNS peers))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Johnson" type="NP">
          <tokens>
            <token id="1" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="2" string="caused some jealousy among his peers" type="VP">
          <tokens>
            <token id="21" string="caused" />
            <token id="22" string="some" />
            <token id="23" string="jealousy" />
            <token id="24" string="among" />
            <token id="25" string="his" />
            <token id="26" string="peers" />
          </tokens>
        </chunking>
        <chunking id="3" string="Canadian" type="NP">
          <tokens>
            <token id="9" string="Canadian" />
          </tokens>
        </chunking>
        <chunking id="4" string="for the meet in Hamilton , a figure that has caused some jealousy among his peers" type="SBAR">
          <tokens>
            <token id="11" string="for" />
            <token id="12" string="the" />
            <token id="13" string="meet" />
            <token id="14" string="in" />
            <token id="15" string="Hamilton" />
            <token id="16" string="," />
            <token id="17" string="a" />
            <token id="18" string="figure" />
            <token id="19" string="that" />
            <token id="20" string="has" />
            <token id="21" string="caused" />
            <token id="22" string="some" />
            <token id="23" string="jealousy" />
            <token id="24" string="among" />
            <token id="25" string="his" />
            <token id="26" string="peers" />
          </tokens>
        </chunking>
        <chunking id="5" string="his peers" type="NP">
          <tokens>
            <token id="25" string="his" />
            <token id="26" string="peers" />
          </tokens>
        </chunking>
        <chunking id="6" string="has caused some jealousy among his peers" type="VP">
          <tokens>
            <token id="20" string="has" />
            <token id="21" string="caused" />
            <token id="22" string="some" />
            <token id="23" string="jealousy" />
            <token id="24" string="among" />
            <token id="25" string="his" />
            <token id="26" string="peers" />
          </tokens>
        </chunking>
        <chunking id="7" string="Hamilton" type="NP">
          <tokens>
            <token id="15" string="Hamilton" />
          </tokens>
        </chunking>
        <chunking id="8" string="the" type="NP">
          <tokens>
            <token id="12" string="the" />
          </tokens>
        </chunking>
        <chunking id="9" string="meet in Hamilton , a figure that has caused some jealousy among his peers" type="VP">
          <tokens>
            <token id="13" string="meet" />
            <token id="14" string="in" />
            <token id="15" string="Hamilton" />
            <token id="16" string="," />
            <token id="17" string="a" />
            <token id="18" string="figure" />
            <token id="19" string="that" />
            <token id="20" string="has" />
            <token id="21" string="caused" />
            <token id="22" string="some" />
            <token id="23" string="jealousy" />
            <token id="24" string="among" />
            <token id="25" string="his" />
            <token id="26" string="peers" />
          </tokens>
        </chunking>
        <chunking id="10" string="that has caused some jealousy among his peers" type="SBAR">
          <tokens>
            <token id="19" string="that" />
            <token id="20" string="has" />
            <token id="21" string="caused" />
            <token id="22" string="some" />
            <token id="23" string="jealousy" />
            <token id="24" string="among" />
            <token id="25" string="his" />
            <token id="26" string="peers" />
          </tokens>
        </chunking>
        <chunking id="11" string="some jealousy" type="NP">
          <tokens>
            <token id="22" string="some" />
            <token id="23" string="jealousy" />
          </tokens>
        </chunking>
        <chunking id="12" string="$ 10,000" type="NP">
          <tokens>
            <token id="6" string="$" />
            <token id="7" string="10,000" />
          </tokens>
        </chunking>
        <chunking id="13" string="Hamilton , a figure that has caused some jealousy among his peers" type="NP">
          <tokens>
            <token id="15" string="Hamilton" />
            <token id="16" string="," />
            <token id="17" string="a" />
            <token id="18" string="figure" />
            <token id="19" string="that" />
            <token id="20" string="has" />
            <token id="21" string="caused" />
            <token id="22" string="some" />
            <token id="23" string="jealousy" />
            <token id="24" string="among" />
            <token id="25" string="his" />
            <token id="26" string="peers" />
          </tokens>
        </chunking>
        <chunking id="14" string="will be paid $ 10,000 -LRB- Canadian -RRB- for the meet in Hamilton , a figure that has caused some jealousy among his peers" type="VP">
          <tokens>
            <token id="3" string="will" />
            <token id="4" string="be" />
            <token id="5" string="paid" />
            <token id="6" string="$" />
            <token id="7" string="10,000" />
            <token id="8" string="(" />
            <token id="9" string="Canadian" />
            <token id="10" string=")" />
            <token id="11" string="for" />
            <token id="12" string="the" />
            <token id="13" string="meet" />
            <token id="14" string="in" />
            <token id="15" string="Hamilton" />
            <token id="16" string="," />
            <token id="17" string="a" />
            <token id="18" string="figure" />
            <token id="19" string="that" />
            <token id="20" string="has" />
            <token id="21" string="caused" />
            <token id="22" string="some" />
            <token id="23" string="jealousy" />
            <token id="24" string="among" />
            <token id="25" string="his" />
            <token id="26" string="peers" />
          </tokens>
        </chunking>
        <chunking id="15" string="be paid $ 10,000 -LRB- Canadian -RRB- for the meet in Hamilton , a figure that has caused some jealousy among his peers" type="VP">
          <tokens>
            <token id="4" string="be" />
            <token id="5" string="paid" />
            <token id="6" string="$" />
            <token id="7" string="10,000" />
            <token id="8" string="(" />
            <token id="9" string="Canadian" />
            <token id="10" string=")" />
            <token id="11" string="for" />
            <token id="12" string="the" />
            <token id="13" string="meet" />
            <token id="14" string="in" />
            <token id="15" string="Hamilton" />
            <token id="16" string="," />
            <token id="17" string="a" />
            <token id="18" string="figure" />
            <token id="19" string="that" />
            <token id="20" string="has" />
            <token id="21" string="caused" />
            <token id="22" string="some" />
            <token id="23" string="jealousy" />
            <token id="24" string="among" />
            <token id="25" string="his" />
            <token id="26" string="peers" />
          </tokens>
        </chunking>
        <chunking id="16" string="some jealousy among his peers" type="NP">
          <tokens>
            <token id="22" string="some" />
            <token id="23" string="jealousy" />
            <token id="24" string="among" />
            <token id="25" string="his" />
            <token id="26" string="peers" />
          </tokens>
        </chunking>
        <chunking id="17" string="a figure that has caused some jealousy among his peers" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="figure" />
            <token id="19" string="that" />
            <token id="20" string="has" />
            <token id="21" string="caused" />
            <token id="22" string="some" />
            <token id="23" string="jealousy" />
            <token id="24" string="among" />
            <token id="25" string="his" />
            <token id="26" string="peers" />
          </tokens>
        </chunking>
        <chunking id="18" string="paid $ 10,000 -LRB- Canadian -RRB- for the meet in Hamilton , a figure that has caused some jealousy among his peers" type="VP">
          <tokens>
            <token id="5" string="paid" />
            <token id="6" string="$" />
            <token id="7" string="10,000" />
            <token id="8" string="(" />
            <token id="9" string="Canadian" />
            <token id="10" string=")" />
            <token id="11" string="for" />
            <token id="12" string="the" />
            <token id="13" string="meet" />
            <token id="14" string="in" />
            <token id="15" string="Hamilton" />
            <token id="16" string="," />
            <token id="17" string="a" />
            <token id="18" string="figure" />
            <token id="19" string="that" />
            <token id="20" string="has" />
            <token id="21" string="caused" />
            <token id="22" string="some" />
            <token id="23" string="jealousy" />
            <token id="24" string="among" />
            <token id="25" string="his" />
            <token id="26" string="peers" />
          </tokens>
        </chunking>
        <chunking id="19" string="$ 10,000 -LRB- Canadian -RRB-" type="NP">
          <tokens>
            <token id="6" string="$" />
            <token id="7" string="10,000" />
            <token id="8" string="(" />
            <token id="9" string="Canadian" />
            <token id="10" string=")" />
          </tokens>
        </chunking>
        <chunking id="20" string="a figure" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="figure" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="5">paid</governor>
          <dependent id="1">Johnson</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">paid</governor>
          <dependent id="2">reportedly</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">paid</governor>
          <dependent id="3">will</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">paid</governor>
          <dependent id="4">be</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">paid</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">10,000</governor>
          <dependent id="6">$</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">paid</governor>
          <dependent id="7">10,000</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">10,000</governor>
          <dependent id="9">Canadian</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">meet</governor>
          <dependent id="11">for</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">meet</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">paid</governor>
          <dependent id="13">meet</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">Hamilton</governor>
          <dependent id="14">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">meet</governor>
          <dependent id="15">Hamilton</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">figure</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="15">Hamilton</governor>
          <dependent id="18">figure</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">caused</governor>
          <dependent id="19">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">caused</governor>
          <dependent id="20">has</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="18">figure</governor>
          <dependent id="21">caused</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">jealousy</governor>
          <dependent id="22">some</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">caused</governor>
          <dependent id="23">jealousy</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">peers</governor>
          <dependent id="24">among</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="26">peers</governor>
          <dependent id="25">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">jealousy</governor>
          <dependent id="26">peers</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Hamilton" type="LOCATION" score="0.0">
          <tokens>
            <token id="15" string="Hamilton" />
          </tokens>
        </entity>
        <entity id="2" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Johnson" />
          </tokens>
        </entity>
        <entity id="3" string="Canadian" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="9" string="Canadian" />
          </tokens>
        </entity>
        <entity id="4" string="$ 10,000" type="MONEY" score="0.0">
          <tokens>
            <token id="6" string="$" />
            <token id="7" string="10,000" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="62" has_coreference="true">
      <content>Lumpp, who traditionally has one of the largest budgets in North America, said resentment is a problem faced every season by meet directors.</content>
      <tokens>
        <token id="1" string="Lumpp" lemma="Lumpp" stem="lumpp" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="traditionally" lemma="traditionally" stem="tradition" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="largest" lemma="largest" stem="largest" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="budgets" lemma="budget" stem="budget" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="North" lemma="North" stem="north" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="13" string="America" lemma="America" stem="america" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="resentment" lemma="resentment" stem="resent" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="problem" lemma="problem" stem="problem" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="faced" lemma="face" stem="face" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="every" lemma="every" stem="everi" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="season" lemma="season" stem="season" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="meet" lemma="meet" stem="meet" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="directors" lemma="director" stem="director" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Lumpp)) (, ,) (SBAR (WHNP (WP who)) (S (ADVP (RB traditionally)) (VP (VBZ has) (NP (NP (CD one)) (PP (IN of) (NP (NP (DT the) (JJS largest) (NNS budgets)) (PP (IN in) (NP (NNP North) (NNP America))))))))) (, ,)) (VP (VBD said) (SBAR (S (NP (NN resentment)) (VP (VBZ is) (NP (NP (DT a) (NN problem)) (SBAR (S (VP (VBD faced) (NP (DT every) (NN season)) (PP (IN by) (S (VP (VB meet) (NP (NNS directors))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is a problem faced every season by meet directors" type="VP">
          <tokens>
            <token id="17" string="is" />
            <token id="18" string="a" />
            <token id="19" string="problem" />
            <token id="20" string="faced" />
            <token id="21" string="every" />
            <token id="22" string="season" />
            <token id="23" string="by" />
            <token id="24" string="meet" />
            <token id="25" string="directors" />
          </tokens>
        </chunking>
        <chunking id="2" string="one" type="NP">
          <tokens>
            <token id="6" string="one" />
          </tokens>
        </chunking>
        <chunking id="3" string="a problem faced every season by meet directors" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="problem" />
            <token id="20" string="faced" />
            <token id="21" string="every" />
            <token id="22" string="season" />
            <token id="23" string="by" />
            <token id="24" string="meet" />
            <token id="25" string="directors" />
          </tokens>
        </chunking>
        <chunking id="4" string="every season" type="NP">
          <tokens>
            <token id="21" string="every" />
            <token id="22" string="season" />
          </tokens>
        </chunking>
        <chunking id="5" string="Lumpp" type="NP">
          <tokens>
            <token id="1" string="Lumpp" />
          </tokens>
        </chunking>
        <chunking id="6" string="directors" type="NP">
          <tokens>
            <token id="25" string="directors" />
          </tokens>
        </chunking>
        <chunking id="7" string="has one of the largest budgets in North America" type="VP">
          <tokens>
            <token id="5" string="has" />
            <token id="6" string="one" />
            <token id="7" string="of" />
            <token id="8" string="the" />
            <token id="9" string="largest" />
            <token id="10" string="budgets" />
            <token id="11" string="in" />
            <token id="12" string="North" />
            <token id="13" string="America" />
          </tokens>
        </chunking>
        <chunking id="8" string="resentment is a problem faced every season by meet directors" type="SBAR">
          <tokens>
            <token id="16" string="resentment" />
            <token id="17" string="is" />
            <token id="18" string="a" />
            <token id="19" string="problem" />
            <token id="20" string="faced" />
            <token id="21" string="every" />
            <token id="22" string="season" />
            <token id="23" string="by" />
            <token id="24" string="meet" />
            <token id="25" string="directors" />
          </tokens>
        </chunking>
        <chunking id="9" string="meet directors" type="VP">
          <tokens>
            <token id="24" string="meet" />
            <token id="25" string="directors" />
          </tokens>
        </chunking>
        <chunking id="10" string="North America" type="NP">
          <tokens>
            <token id="12" string="North" />
            <token id="13" string="America" />
          </tokens>
        </chunking>
        <chunking id="11" string="Lumpp , who traditionally has one of the largest budgets in North America ," type="NP">
          <tokens>
            <token id="1" string="Lumpp" />
            <token id="2" string="," />
            <token id="3" string="who" />
            <token id="4" string="traditionally" />
            <token id="5" string="has" />
            <token id="6" string="one" />
            <token id="7" string="of" />
            <token id="8" string="the" />
            <token id="9" string="largest" />
            <token id="10" string="budgets" />
            <token id="11" string="in" />
            <token id="12" string="North" />
            <token id="13" string="America" />
            <token id="14" string="," />
          </tokens>
        </chunking>
        <chunking id="12" string="resentment" type="NP">
          <tokens>
            <token id="16" string="resentment" />
          </tokens>
        </chunking>
        <chunking id="13" string="said resentment is a problem faced every season by meet directors" type="VP">
          <tokens>
            <token id="15" string="said" />
            <token id="16" string="resentment" />
            <token id="17" string="is" />
            <token id="18" string="a" />
            <token id="19" string="problem" />
            <token id="20" string="faced" />
            <token id="21" string="every" />
            <token id="22" string="season" />
            <token id="23" string="by" />
            <token id="24" string="meet" />
            <token id="25" string="directors" />
          </tokens>
        </chunking>
        <chunking id="14" string="who traditionally has one of the largest budgets in North America" type="SBAR">
          <tokens>
            <token id="3" string="who" />
            <token id="4" string="traditionally" />
            <token id="5" string="has" />
            <token id="6" string="one" />
            <token id="7" string="of" />
            <token id="8" string="the" />
            <token id="9" string="largest" />
            <token id="10" string="budgets" />
            <token id="11" string="in" />
            <token id="12" string="North" />
            <token id="13" string="America" />
          </tokens>
        </chunking>
        <chunking id="15" string="one of the largest budgets in North America" type="NP">
          <tokens>
            <token id="6" string="one" />
            <token id="7" string="of" />
            <token id="8" string="the" />
            <token id="9" string="largest" />
            <token id="10" string="budgets" />
            <token id="11" string="in" />
            <token id="12" string="North" />
            <token id="13" string="America" />
          </tokens>
        </chunking>
        <chunking id="16" string="faced every season by meet directors" type="SBAR">
          <tokens>
            <token id="20" string="faced" />
            <token id="21" string="every" />
            <token id="22" string="season" />
            <token id="23" string="by" />
            <token id="24" string="meet" />
            <token id="25" string="directors" />
          </tokens>
        </chunking>
        <chunking id="17" string="the largest budgets" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="largest" />
            <token id="10" string="budgets" />
          </tokens>
        </chunking>
        <chunking id="18" string="the largest budgets in North America" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="largest" />
            <token id="10" string="budgets" />
            <token id="11" string="in" />
            <token id="12" string="North" />
            <token id="13" string="America" />
          </tokens>
        </chunking>
        <chunking id="19" string="a problem" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="problem" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="15">said</governor>
          <dependent id="1">Lumpp</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">has</governor>
          <dependent id="3">who</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">has</governor>
          <dependent id="4">traditionally</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="1">Lumpp</governor>
          <dependent id="5">has</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">has</governor>
          <dependent id="6">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">budgets</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">budgets</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">budgets</governor>
          <dependent id="9">largest</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">one</governor>
          <dependent id="10">budgets</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">America</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">America</governor>
          <dependent id="12">North</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">budgets</governor>
          <dependent id="13">America</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">problem</governor>
          <dependent id="16">resentment</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="19">problem</governor>
          <dependent id="17">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">problem</governor>
          <dependent id="18">a</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">said</governor>
          <dependent id="19">problem</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="19">problem</governor>
          <dependent id="20">faced</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">season</governor>
          <dependent id="21">every</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">faced</governor>
          <dependent id="22">season</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">meet</governor>
          <dependent id="23">by</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="20">faced</governor>
          <dependent id="24">meet</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">meet</governor>
          <dependent id="25">directors</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="6" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="Lumpp" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Lumpp" />
          </tokens>
        </entity>
        <entity id="3" string="North America" type="LOCATION" score="0.0">
          <tokens>
            <token id="12" string="North" />
            <token id="13" string="America" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="63" has_coreference="false">
      <content>&amp;quot;How many heavy hitters can a meet afford?&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="How" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="heavy" lemma="heavy" stem="heavi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="hitters" lemma="hitter" stem="hitter" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="meet" lemma="meet" stem="meet" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="afford" lemma="afford" stem="afford" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SBARQ (`` ``) (WHNP (WHADJP (WRB How) (JJ many)) (ADJP (JJ heavy)) (NNS hitters)) (SQ (MD can) (NP (DT a)) (VP (VB meet) (VP (VB afford)))) (. ?) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="a" type="NP">
          <tokens>
            <token id="7" string="a" />
          </tokens>
        </chunking>
        <chunking id="2" string="meet afford" type="VP">
          <tokens>
            <token id="8" string="meet" />
            <token id="9" string="afford" />
          </tokens>
        </chunking>
        <chunking id="3" string="afford" type="VP">
          <tokens>
            <token id="9" string="afford" />
          </tokens>
        </chunking>
        <chunking id="4" string="heavy" type="ADJP">
          <tokens>
            <token id="4" string="heavy" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="3">many</governor>
          <dependent id="2">How</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">hitters</governor>
          <dependent id="3">many</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">hitters</governor>
          <dependent id="4">heavy</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">meet</governor>
          <dependent id="5">hitters</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">meet</governor>
          <dependent id="6">can</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">meet</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">meet</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">meet</governor>
          <dependent id="9">afford</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="64" has_coreference="true">
      <content>he said.</content>
      <tokens>
        <token id="1" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP he)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="he" type="NP">
          <tokens>
            <token id="1" string="he" />
          </tokens>
        </chunking>
        <chunking id="2" string="said" type="VP">
          <tokens>
            <token id="2" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="65" has_coreference="true">
      <content>&amp;quot;There are very few secrets among athletes, especially when there&amp;apost;s X dollars given to one athlete.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="few" lemma="few" stem="few" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="secrets" lemma="secret" stem="secret" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="among" lemma="among" stem="among" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="athletes" lemma="athlete" stem="athlet" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="especially" lemma="especially" stem="especi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="X" lemma="x" stem="x" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="dollars" lemma="dollar" stem="dollar" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="given" lemma="give" stem="given" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="true" is_refers="true" />
        <token id="19" string="athlete" lemma="athlete" stem="athlet" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (EX There)) (VP (VBP are) (NP (NP (ADJP (RB very) (JJ few)) (NNS secrets)) (PP (IN among) (NP (NP (NNS athletes)) (, ,) (SBAR (WHADVP (RB especially) (WRB when)) (S (NP (EX there)) (VP (VBZ 's) (NP (NP (NN X) (NNS dollars)) (PP (VBN given) (PP (TO to) (NP (CD one) (NN athlete)))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="very few secrets" type="NP">
          <tokens>
            <token id="4" string="very" />
            <token id="5" string="few" />
            <token id="6" string="secrets" />
          </tokens>
        </chunking>
        <chunking id="2" string="very few secrets among athletes , especially when there 's X dollars given to one athlete" type="NP">
          <tokens>
            <token id="4" string="very" />
            <token id="5" string="few" />
            <token id="6" string="secrets" />
            <token id="7" string="among" />
            <token id="8" string="athletes" />
            <token id="9" string="," />
            <token id="10" string="especially" />
            <token id="11" string="when" />
            <token id="12" string="there" />
            <token id="13" string="'s" />
            <token id="14" string="X" />
            <token id="15" string="dollars" />
            <token id="16" string="given" />
            <token id="17" string="to" />
            <token id="18" string="one" />
            <token id="19" string="athlete" />
          </tokens>
        </chunking>
        <chunking id="3" string="especially when there 's X dollars given to one athlete" type="SBAR">
          <tokens>
            <token id="10" string="especially" />
            <token id="11" string="when" />
            <token id="12" string="there" />
            <token id="13" string="'s" />
            <token id="14" string="X" />
            <token id="15" string="dollars" />
            <token id="16" string="given" />
            <token id="17" string="to" />
            <token id="18" string="one" />
            <token id="19" string="athlete" />
          </tokens>
        </chunking>
        <chunking id="4" string="X dollars" type="NP">
          <tokens>
            <token id="14" string="X" />
            <token id="15" string="dollars" />
          </tokens>
        </chunking>
        <chunking id="5" string="'s X dollars given to one athlete" type="VP">
          <tokens>
            <token id="13" string="'s" />
            <token id="14" string="X" />
            <token id="15" string="dollars" />
            <token id="16" string="given" />
            <token id="17" string="to" />
            <token id="18" string="one" />
            <token id="19" string="athlete" />
          </tokens>
        </chunking>
        <chunking id="6" string="very few" type="ADJP">
          <tokens>
            <token id="4" string="very" />
            <token id="5" string="few" />
          </tokens>
        </chunking>
        <chunking id="7" string="athletes" type="NP">
          <tokens>
            <token id="8" string="athletes" />
          </tokens>
        </chunking>
        <chunking id="8" string="there" type="NP">
          <tokens>
            <token id="12" string="there" />
          </tokens>
        </chunking>
        <chunking id="9" string="There" type="NP">
          <tokens>
            <token id="2" string="There" />
          </tokens>
        </chunking>
        <chunking id="10" string="especially when" type="WHADVP">
          <tokens>
            <token id="10" string="especially" />
            <token id="11" string="when" />
          </tokens>
        </chunking>
        <chunking id="11" string="are very few secrets among athletes , especially when there 's X dollars given to one athlete" type="VP">
          <tokens>
            <token id="3" string="are" />
            <token id="4" string="very" />
            <token id="5" string="few" />
            <token id="6" string="secrets" />
            <token id="7" string="among" />
            <token id="8" string="athletes" />
            <token id="9" string="," />
            <token id="10" string="especially" />
            <token id="11" string="when" />
            <token id="12" string="there" />
            <token id="13" string="'s" />
            <token id="14" string="X" />
            <token id="15" string="dollars" />
            <token id="16" string="given" />
            <token id="17" string="to" />
            <token id="18" string="one" />
            <token id="19" string="athlete" />
          </tokens>
        </chunking>
        <chunking id="12" string="one athlete" type="NP">
          <tokens>
            <token id="18" string="one" />
            <token id="19" string="athlete" />
          </tokens>
        </chunking>
        <chunking id="13" string="athletes , especially when there 's X dollars given to one athlete" type="NP">
          <tokens>
            <token id="8" string="athletes" />
            <token id="9" string="," />
            <token id="10" string="especially" />
            <token id="11" string="when" />
            <token id="12" string="there" />
            <token id="13" string="'s" />
            <token id="14" string="X" />
            <token id="15" string="dollars" />
            <token id="16" string="given" />
            <token id="17" string="to" />
            <token id="18" string="one" />
            <token id="19" string="athlete" />
          </tokens>
        </chunking>
        <chunking id="14" string="X dollars given to one athlete" type="NP">
          <tokens>
            <token id="14" string="X" />
            <token id="15" string="dollars" />
            <token id="16" string="given" />
            <token id="17" string="to" />
            <token id="18" string="one" />
            <token id="19" string="athlete" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="3">are</governor>
          <dependent id="2">There</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">are</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">few</governor>
          <dependent id="4">very</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">secrets</governor>
          <dependent id="5">few</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">are</governor>
          <dependent id="6">secrets</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">athletes</governor>
          <dependent id="7">among</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">secrets</governor>
          <dependent id="8">athletes</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">when</governor>
          <dependent id="10">especially</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">'s</governor>
          <dependent id="11">when</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="13">'s</governor>
          <dependent id="12">there</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="8">athletes</governor>
          <dependent id="13">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">dollars</governor>
          <dependent id="14">X</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">'s</governor>
          <dependent id="15">dollars</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">athlete</governor>
          <dependent id="16">given</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">athlete</governor>
          <dependent id="17">to</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="19">athlete</governor>
          <dependent id="18">one</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="15">dollars</governor>
          <dependent id="19">athlete</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="18" string="one" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="66" has_coreference="true">
      <content>Hamilton promoter Gaines has heard it before, and makes no apology for paying Johnson more than other athletes.</content>
      <tokens>
        <token id="1" string="Hamilton" lemma="Hamilton" stem="hamilton" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="2" string="promoter" lemma="promoter" stem="promot" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="Gaines" lemma="Gaines" stem="gain" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="heard" lemma="hear" stem="heard" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="before" lemma="before" stem="befor" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="makes" lemma="make" stem="make" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="apology" lemma="apology" stem="apologi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="paying" lemma="pay" stem="pai" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="16" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="athletes" lemma="athlete" stem="athlet" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Hamilton) (NN promoter) (NNP Gaines)) (VP (VP (VBZ has) (VP (VBN heard) (S (NP (PRP it)) (ADVP (RB before))))) (, ,) (CC and) (VP (VBZ makes) (NP (DT no) (NN apology)) (PP (IN for) (S (VP (VBG paying) (S (NP (NNP Johnson)) (ADJP (ADJP (JJR more)) (PP (IN than) (NP (JJ other) (NNS athletes)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Johnson" type="NP">
          <tokens>
            <token id="15" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="2" string="Hamilton promoter Gaines" type="NP">
          <tokens>
            <token id="1" string="Hamilton" />
            <token id="2" string="promoter" />
            <token id="3" string="Gaines" />
          </tokens>
        </chunking>
        <chunking id="3" string="more" type="ADJP">
          <tokens>
            <token id="16" string="more" />
          </tokens>
        </chunking>
        <chunking id="4" string="makes no apology for paying Johnson more than other athletes" type="VP">
          <tokens>
            <token id="10" string="makes" />
            <token id="11" string="no" />
            <token id="12" string="apology" />
            <token id="13" string="for" />
            <token id="14" string="paying" />
            <token id="15" string="Johnson" />
            <token id="16" string="more" />
            <token id="17" string="than" />
            <token id="18" string="other" />
            <token id="19" string="athletes" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="6" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="more than other athletes" type="ADJP">
          <tokens>
            <token id="16" string="more" />
            <token id="17" string="than" />
            <token id="18" string="other" />
            <token id="19" string="athletes" />
          </tokens>
        </chunking>
        <chunking id="7" string="other athletes" type="NP">
          <tokens>
            <token id="18" string="other" />
            <token id="19" string="athletes" />
          </tokens>
        </chunking>
        <chunking id="8" string="has heard it before , and makes no apology for paying Johnson more than other athletes" type="VP">
          <tokens>
            <token id="4" string="has" />
            <token id="5" string="heard" />
            <token id="6" string="it" />
            <token id="7" string="before" />
            <token id="8" string="," />
            <token id="9" string="and" />
            <token id="10" string="makes" />
            <token id="11" string="no" />
            <token id="12" string="apology" />
            <token id="13" string="for" />
            <token id="14" string="paying" />
            <token id="15" string="Johnson" />
            <token id="16" string="more" />
            <token id="17" string="than" />
            <token id="18" string="other" />
            <token id="19" string="athletes" />
          </tokens>
        </chunking>
        <chunking id="9" string="heard it before" type="VP">
          <tokens>
            <token id="5" string="heard" />
            <token id="6" string="it" />
            <token id="7" string="before" />
          </tokens>
        </chunking>
        <chunking id="10" string="paying Johnson more than other athletes" type="VP">
          <tokens>
            <token id="14" string="paying" />
            <token id="15" string="Johnson" />
            <token id="16" string="more" />
            <token id="17" string="than" />
            <token id="18" string="other" />
            <token id="19" string="athletes" />
          </tokens>
        </chunking>
        <chunking id="11" string="has heard it before" type="VP">
          <tokens>
            <token id="4" string="has" />
            <token id="5" string="heard" />
            <token id="6" string="it" />
            <token id="7" string="before" />
          </tokens>
        </chunking>
        <chunking id="12" string="no apology" type="NP">
          <tokens>
            <token id="11" string="no" />
            <token id="12" string="apology" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Gaines</governor>
          <dependent id="1">Hamilton</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Gaines</governor>
          <dependent id="2">promoter</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">heard</governor>
          <dependent id="3">Gaines</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">heard</governor>
          <dependent id="4">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">heard</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">heard</governor>
          <dependent id="6">it</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">it</governor>
          <dependent id="7">before</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">heard</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">heard</governor>
          <dependent id="10">makes</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="12">apology</governor>
          <dependent id="11">no</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">makes</governor>
          <dependent id="12">apology</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">paying</governor>
          <dependent id="13">for</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="10">makes</governor>
          <dependent id="14">paying</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">more</governor>
          <dependent id="15">Johnson</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="14">paying</governor>
          <dependent id="16">more</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">athletes</governor>
          <dependent id="17">than</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">athletes</governor>
          <dependent id="18">other</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">more</governor>
          <dependent id="19">athletes</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Hamilton" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="1" string="Hamilton" />
          </tokens>
        </entity>
        <entity id="2" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="Johnson" />
          </tokens>
        </entity>
        <entity id="3" string="Gaines" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Gaines" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="67" has_coreference="true">
      <content>&amp;quot;My answer to that is &amp;apost;Who puts (fans) in the seats?</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="My" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="answer" lemma="answer" stem="answer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="'" lemma="`" stem="'" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="puts" lemma="put" stem="put" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="fans" lemma="fan" stem="fan" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="seats" lemma="seat" stem="seat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (NP (PRP$ My) (NN answer)) (PP (TO to) (NP (DT that)))) (VP (VBZ is) (SBARQ (`` `) (WHNP (WP Who)) (SQ (VP (VBZ puts) (NP (-LRB- -LRB-) (NNS fans) (-RRB- -RRB-)) (PP (IN in) (NP (DT the) (NNS seats))))) (. ?)))))</syntactictree>
      <chunkings>
        <chunking id="1" string="that" type="NP">
          <tokens>
            <token id="5" string="that" />
          </tokens>
        </chunking>
        <chunking id="2" string="is ` Who puts -LRB- fans -RRB- in the seats ?" type="VP">
          <tokens>
            <token id="6" string="is" />
            <token id="7" string="'" />
            <token id="8" string="Who" />
            <token id="9" string="puts" />
            <token id="10" string="(" />
            <token id="11" string="fans" />
            <token id="12" string=")" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="seats" />
            <token id="16" string="?" />
          </tokens>
        </chunking>
        <chunking id="3" string="My answer" type="NP">
          <tokens>
            <token id="2" string="My" />
            <token id="3" string="answer" />
          </tokens>
        </chunking>
        <chunking id="4" string="My answer to that" type="NP">
          <tokens>
            <token id="2" string="My" />
            <token id="3" string="answer" />
            <token id="4" string="to" />
            <token id="5" string="that" />
          </tokens>
        </chunking>
        <chunking id="5" string="puts -LRB- fans -RRB- in the seats" type="VP">
          <tokens>
            <token id="9" string="puts" />
            <token id="10" string="(" />
            <token id="11" string="fans" />
            <token id="12" string=")" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="seats" />
          </tokens>
        </chunking>
        <chunking id="6" string="-LRB- fans -RRB-" type="NP">
          <tokens>
            <token id="10" string="(" />
            <token id="11" string="fans" />
            <token id="12" string=")" />
          </tokens>
        </chunking>
        <chunking id="7" string="the seats" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="seats" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="3">answer</governor>
          <dependent id="2">My</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">is</governor>
          <dependent id="3">answer</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">that</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">answer</governor>
          <dependent id="5">that</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">is</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">puts</governor>
          <dependent id="8">Who</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">is</governor>
          <dependent id="9">puts</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">puts</governor>
          <dependent id="11">fans</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">seats</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">seats</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">puts</governor>
          <dependent id="15">seats</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="68" has_coreference="true">
      <content>Right now, I can&amp;apost;t think of anybody who would arouse as much interest as Ben Johnson.&amp;quot;</content>
      <tokens>
        <token id="1" string="Right" lemma="right" stem="right" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="2" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="ca" lemma="can" stem="ca" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="think" lemma="think" stem="think" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="anybody" lemma="anybody" stem="anybodi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="arouse" lemma="arouse" stem="arous" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="as" lemma="as" stem="a" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="much" lemma="much" stem="much" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="interest" lemma="interest" stem="interest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Ben" lemma="Ben" stem="ben" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="18" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Right) (RB now)) (, ,) (NP (PRP I)) (VP (MD ca) (RB n't) (VP (VB think) (PP (IN of) (NP (NP (NN anybody)) (SBAR (WHNP (WP who)) (S (VP (MD would) (VP (VB arouse) (NP (ADJP (RB as) (JJ much)) (NN interest)) (PP (IN as) (NP (NNP Ben) (NNP Johnson))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="Ben Johnson" type="NP">
          <tokens>
            <token id="17" string="Ben" />
            <token id="18" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="2" string="as much interest" type="NP">
          <tokens>
            <token id="13" string="as" />
            <token id="14" string="much" />
            <token id="15" string="interest" />
          </tokens>
        </chunking>
        <chunking id="3" string="anybody" type="NP">
          <tokens>
            <token id="9" string="anybody" />
          </tokens>
        </chunking>
        <chunking id="4" string="arouse as much interest as Ben Johnson" type="VP">
          <tokens>
            <token id="12" string="arouse" />
            <token id="13" string="as" />
            <token id="14" string="much" />
            <token id="15" string="interest" />
            <token id="16" string="as" />
            <token id="17" string="Ben" />
            <token id="18" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="5" string="I" type="NP">
          <tokens>
            <token id="4" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="ca n't think of anybody who would arouse as much interest as Ben Johnson" type="VP">
          <tokens>
            <token id="5" string="ca" />
            <token id="6" string="n't" />
            <token id="7" string="think" />
            <token id="8" string="of" />
            <token id="9" string="anybody" />
            <token id="10" string="who" />
            <token id="11" string="would" />
            <token id="12" string="arouse" />
            <token id="13" string="as" />
            <token id="14" string="much" />
            <token id="15" string="interest" />
            <token id="16" string="as" />
            <token id="17" string="Ben" />
            <token id="18" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="7" string="think of anybody who would arouse as much interest as Ben Johnson" type="VP">
          <tokens>
            <token id="7" string="think" />
            <token id="8" string="of" />
            <token id="9" string="anybody" />
            <token id="10" string="who" />
            <token id="11" string="would" />
            <token id="12" string="arouse" />
            <token id="13" string="as" />
            <token id="14" string="much" />
            <token id="15" string="interest" />
            <token id="16" string="as" />
            <token id="17" string="Ben" />
            <token id="18" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="8" string="who would arouse as much interest as Ben Johnson" type="SBAR">
          <tokens>
            <token id="10" string="who" />
            <token id="11" string="would" />
            <token id="12" string="arouse" />
            <token id="13" string="as" />
            <token id="14" string="much" />
            <token id="15" string="interest" />
            <token id="16" string="as" />
            <token id="17" string="Ben" />
            <token id="18" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="9" string="as much" type="ADJP">
          <tokens>
            <token id="13" string="as" />
            <token id="14" string="much" />
          </tokens>
        </chunking>
        <chunking id="10" string="would arouse as much interest as Ben Johnson" type="VP">
          <tokens>
            <token id="11" string="would" />
            <token id="12" string="arouse" />
            <token id="13" string="as" />
            <token id="14" string="much" />
            <token id="15" string="interest" />
            <token id="16" string="as" />
            <token id="17" string="Ben" />
            <token id="18" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="11" string="anybody who would arouse as much interest as Ben Johnson" type="NP">
          <tokens>
            <token id="9" string="anybody" />
            <token id="10" string="who" />
            <token id="11" string="would" />
            <token id="12" string="arouse" />
            <token id="13" string="as" />
            <token id="14" string="much" />
            <token id="15" string="interest" />
            <token id="16" string="as" />
            <token id="17" string="Ben" />
            <token id="18" string="Johnson" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="2">now</governor>
          <dependent id="1">Right</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">think</governor>
          <dependent id="2">now</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">think</governor>
          <dependent id="4">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">think</governor>
          <dependent id="5">ca</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="7">think</governor>
          <dependent id="6">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">think</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">anybody</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">think</governor>
          <dependent id="9">anybody</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">arouse</governor>
          <dependent id="10">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">arouse</governor>
          <dependent id="11">would</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="9">anybody</governor>
          <dependent id="12">arouse</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">much</governor>
          <dependent id="13">as</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">interest</governor>
          <dependent id="14">much</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">arouse</governor>
          <dependent id="15">interest</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Johnson</governor>
          <dependent id="16">as</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Johnson</governor>
          <dependent id="17">Ben</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">arouse</governor>
          <dependent id="18">Johnson</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ben Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="Ben" />
            <token id="18" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="Right now" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="Right" />
            <token id="2" string="now" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="69" has_coreference="true">
      <content>It would be ironic if Johnson becomes the star who revitalizes indoor track and field after being blamed for the steady decline of sponsor interest in outdoor track.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="ironic" lemma="ironic" stem="iron" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="becomes" lemma="become" stem="becom" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="star" lemma="star" stem="star" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="revitalizes" lemma="revitalize" stem="revit" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="indoor" lemma="indoor" stem="indoor" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="track" lemma="track" stem="track" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="field" lemma="field" stem="field" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="being" lemma="be" stem="be" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="blamed" lemma="blame" stem="blame" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="steady" lemma="steady" stem="steadi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="decline" lemma="decline" stem="declin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="sponsor" lemma="sponsor" stem="sponsor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="interest" lemma="interest" stem="interest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="outdoor" lemma="outdoor" stem="outdoor" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="track" lemma="track" stem="track" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (MD would) (VP (VB be) (ADJP (JJ ironic)) (SBAR (IN if) (S (NP (NNP Johnson)) (VP (VBZ becomes) (NP (NP (DT the) (NN star)) (SBAR (WHNP (WP who)) (S (VP (VBZ revitalizes) (NP (JJ indoor) (NN track) (CC and) (NN field)) (PP (IN after) (S (VP (VBG being) (VP (VBN blamed) (PP (IN for) (NP (NP (DT the) (JJ steady) (NN decline)) (PP (IN of) (NP (NN sponsor) (NN interest))))) (PP (IN in) (NP (JJ outdoor) (NN track)))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the star who revitalizes indoor track and field after being blamed for the steady decline of sponsor interest in outdoor track" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="star" />
            <token id="10" string="who" />
            <token id="11" string="revitalizes" />
            <token id="12" string="indoor" />
            <token id="13" string="track" />
            <token id="14" string="and" />
            <token id="15" string="field" />
            <token id="16" string="after" />
            <token id="17" string="being" />
            <token id="18" string="blamed" />
            <token id="19" string="for" />
            <token id="20" string="the" />
            <token id="21" string="steady" />
            <token id="22" string="decline" />
            <token id="23" string="of" />
            <token id="24" string="sponsor" />
            <token id="25" string="interest" />
            <token id="26" string="in" />
            <token id="27" string="outdoor" />
            <token id="28" string="track" />
          </tokens>
        </chunking>
        <chunking id="2" string="Johnson" type="NP">
          <tokens>
            <token id="6" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="3" string="the star" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="star" />
          </tokens>
        </chunking>
        <chunking id="4" string="who revitalizes indoor track and field after being blamed for the steady decline of sponsor interest in outdoor track" type="SBAR">
          <tokens>
            <token id="10" string="who" />
            <token id="11" string="revitalizes" />
            <token id="12" string="indoor" />
            <token id="13" string="track" />
            <token id="14" string="and" />
            <token id="15" string="field" />
            <token id="16" string="after" />
            <token id="17" string="being" />
            <token id="18" string="blamed" />
            <token id="19" string="for" />
            <token id="20" string="the" />
            <token id="21" string="steady" />
            <token id="22" string="decline" />
            <token id="23" string="of" />
            <token id="24" string="sponsor" />
            <token id="25" string="interest" />
            <token id="26" string="in" />
            <token id="27" string="outdoor" />
            <token id="28" string="track" />
          </tokens>
        </chunking>
        <chunking id="5" string="revitalizes indoor track and field after being blamed for the steady decline of sponsor interest in outdoor track" type="VP">
          <tokens>
            <token id="11" string="revitalizes" />
            <token id="12" string="indoor" />
            <token id="13" string="track" />
            <token id="14" string="and" />
            <token id="15" string="field" />
            <token id="16" string="after" />
            <token id="17" string="being" />
            <token id="18" string="blamed" />
            <token id="19" string="for" />
            <token id="20" string="the" />
            <token id="21" string="steady" />
            <token id="22" string="decline" />
            <token id="23" string="of" />
            <token id="24" string="sponsor" />
            <token id="25" string="interest" />
            <token id="26" string="in" />
            <token id="27" string="outdoor" />
            <token id="28" string="track" />
          </tokens>
        </chunking>
        <chunking id="6" string="ironic" type="ADJP">
          <tokens>
            <token id="4" string="ironic" />
          </tokens>
        </chunking>
        <chunking id="7" string="being blamed for the steady decline of sponsor interest in outdoor track" type="VP">
          <tokens>
            <token id="17" string="being" />
            <token id="18" string="blamed" />
            <token id="19" string="for" />
            <token id="20" string="the" />
            <token id="21" string="steady" />
            <token id="22" string="decline" />
            <token id="23" string="of" />
            <token id="24" string="sponsor" />
            <token id="25" string="interest" />
            <token id="26" string="in" />
            <token id="27" string="outdoor" />
            <token id="28" string="track" />
          </tokens>
        </chunking>
        <chunking id="8" string="the steady decline" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="steady" />
            <token id="22" string="decline" />
          </tokens>
        </chunking>
        <chunking id="9" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="10" string="would be ironic if Johnson becomes the star who revitalizes indoor track and field after being blamed for the steady decline of sponsor interest in outdoor track" type="VP">
          <tokens>
            <token id="2" string="would" />
            <token id="3" string="be" />
            <token id="4" string="ironic" />
            <token id="5" string="if" />
            <token id="6" string="Johnson" />
            <token id="7" string="becomes" />
            <token id="8" string="the" />
            <token id="9" string="star" />
            <token id="10" string="who" />
            <token id="11" string="revitalizes" />
            <token id="12" string="indoor" />
            <token id="13" string="track" />
            <token id="14" string="and" />
            <token id="15" string="field" />
            <token id="16" string="after" />
            <token id="17" string="being" />
            <token id="18" string="blamed" />
            <token id="19" string="for" />
            <token id="20" string="the" />
            <token id="21" string="steady" />
            <token id="22" string="decline" />
            <token id="23" string="of" />
            <token id="24" string="sponsor" />
            <token id="25" string="interest" />
            <token id="26" string="in" />
            <token id="27" string="outdoor" />
            <token id="28" string="track" />
          </tokens>
        </chunking>
        <chunking id="11" string="becomes the star who revitalizes indoor track and field after being blamed for the steady decline of sponsor interest in outdoor track" type="VP">
          <tokens>
            <token id="7" string="becomes" />
            <token id="8" string="the" />
            <token id="9" string="star" />
            <token id="10" string="who" />
            <token id="11" string="revitalizes" />
            <token id="12" string="indoor" />
            <token id="13" string="track" />
            <token id="14" string="and" />
            <token id="15" string="field" />
            <token id="16" string="after" />
            <token id="17" string="being" />
            <token id="18" string="blamed" />
            <token id="19" string="for" />
            <token id="20" string="the" />
            <token id="21" string="steady" />
            <token id="22" string="decline" />
            <token id="23" string="of" />
            <token id="24" string="sponsor" />
            <token id="25" string="interest" />
            <token id="26" string="in" />
            <token id="27" string="outdoor" />
            <token id="28" string="track" />
          </tokens>
        </chunking>
        <chunking id="12" string="indoor track and field" type="NP">
          <tokens>
            <token id="12" string="indoor" />
            <token id="13" string="track" />
            <token id="14" string="and" />
            <token id="15" string="field" />
          </tokens>
        </chunking>
        <chunking id="13" string="be ironic if Johnson becomes the star who revitalizes indoor track and field after being blamed for the steady decline of sponsor interest in outdoor track" type="VP">
          <tokens>
            <token id="3" string="be" />
            <token id="4" string="ironic" />
            <token id="5" string="if" />
            <token id="6" string="Johnson" />
            <token id="7" string="becomes" />
            <token id="8" string="the" />
            <token id="9" string="star" />
            <token id="10" string="who" />
            <token id="11" string="revitalizes" />
            <token id="12" string="indoor" />
            <token id="13" string="track" />
            <token id="14" string="and" />
            <token id="15" string="field" />
            <token id="16" string="after" />
            <token id="17" string="being" />
            <token id="18" string="blamed" />
            <token id="19" string="for" />
            <token id="20" string="the" />
            <token id="21" string="steady" />
            <token id="22" string="decline" />
            <token id="23" string="of" />
            <token id="24" string="sponsor" />
            <token id="25" string="interest" />
            <token id="26" string="in" />
            <token id="27" string="outdoor" />
            <token id="28" string="track" />
          </tokens>
        </chunking>
        <chunking id="14" string="blamed for the steady decline of sponsor interest in outdoor track" type="VP">
          <tokens>
            <token id="18" string="blamed" />
            <token id="19" string="for" />
            <token id="20" string="the" />
            <token id="21" string="steady" />
            <token id="22" string="decline" />
            <token id="23" string="of" />
            <token id="24" string="sponsor" />
            <token id="25" string="interest" />
            <token id="26" string="in" />
            <token id="27" string="outdoor" />
            <token id="28" string="track" />
          </tokens>
        </chunking>
        <chunking id="15" string="sponsor interest" type="NP">
          <tokens>
            <token id="24" string="sponsor" />
            <token id="25" string="interest" />
          </tokens>
        </chunking>
        <chunking id="16" string="the steady decline of sponsor interest" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="steady" />
            <token id="22" string="decline" />
            <token id="23" string="of" />
            <token id="24" string="sponsor" />
            <token id="25" string="interest" />
          </tokens>
        </chunking>
        <chunking id="17" string="if Johnson becomes the star who revitalizes indoor track and field after being blamed for the steady decline of sponsor interest in outdoor track" type="SBAR">
          <tokens>
            <token id="5" string="if" />
            <token id="6" string="Johnson" />
            <token id="7" string="becomes" />
            <token id="8" string="the" />
            <token id="9" string="star" />
            <token id="10" string="who" />
            <token id="11" string="revitalizes" />
            <token id="12" string="indoor" />
            <token id="13" string="track" />
            <token id="14" string="and" />
            <token id="15" string="field" />
            <token id="16" string="after" />
            <token id="17" string="being" />
            <token id="18" string="blamed" />
            <token id="19" string="for" />
            <token id="20" string="the" />
            <token id="21" string="steady" />
            <token id="22" string="decline" />
            <token id="23" string="of" />
            <token id="24" string="sponsor" />
            <token id="25" string="interest" />
            <token id="26" string="in" />
            <token id="27" string="outdoor" />
            <token id="28" string="track" />
          </tokens>
        </chunking>
        <chunking id="18" string="outdoor track" type="NP">
          <tokens>
            <token id="27" string="outdoor" />
            <token id="28" string="track" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">ironic</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">ironic</governor>
          <dependent id="2">would</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">ironic</governor>
          <dependent id="3">be</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">ironic</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">becomes</governor>
          <dependent id="5">if</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">becomes</governor>
          <dependent id="6">Johnson</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">ironic</governor>
          <dependent id="7">becomes</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">star</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">becomes</governor>
          <dependent id="9">star</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">revitalizes</governor>
          <dependent id="10">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="9">star</governor>
          <dependent id="11">revitalizes</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">track</governor>
          <dependent id="12">indoor</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">revitalizes</governor>
          <dependent id="13">track</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">track</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">track</governor>
          <dependent id="15">field</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">blamed</governor>
          <dependent id="16">after</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="18">blamed</governor>
          <dependent id="17">being</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">revitalizes</governor>
          <dependent id="18">blamed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">decline</governor>
          <dependent id="19">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">decline</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">decline</governor>
          <dependent id="21">steady</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">blamed</governor>
          <dependent id="22">decline</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">interest</governor>
          <dependent id="23">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">interest</governor>
          <dependent id="24">sponsor</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">decline</governor>
          <dependent id="25">interest</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">track</governor>
          <dependent id="26">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">track</governor>
          <dependent id="27">outdoor</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">blamed</governor>
          <dependent id="28">track</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Johnson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="70" has_coreference="true">
      <content>&amp;quot;There has been damage to the sport and people want to blame Ben personally for that damage,&amp;quot; Gaines said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="damage" lemma="damage" stem="damag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="sport" lemma="sport" stem="sport" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="want" lemma="want" stem="want" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="blame" lemma="blame" stem="blame" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="Ben" lemma="Ben" stem="ben" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="15" string="personally" lemma="personally" stem="person" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="damage" lemma="damage" stem="damag" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="Gaines" lemma="Gaines" stem="gain" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="22" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (S (NP (EX There)) (VP (VBZ has) (VP (VBN been) (NP (NP (NN damage)) (PP (TO to) (NP (DT the) (NN sport))))))) (CC and) (S (NP (NNS people)) (VP (VBP want) (S (VP (TO to) (VP (VB blame) (NP (NNP Ben)) (ADVP (RB personally)) (PP (IN for) (NP (DT that) (NN damage))))))))) (, ,) ('' '') (NP (NNP Gaines)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="damage" type="NP">
          <tokens>
            <token id="5" string="damage" />
          </tokens>
        </chunking>
        <chunking id="2" string="that damage" type="NP">
          <tokens>
            <token id="17" string="that" />
            <token id="18" string="damage" />
          </tokens>
        </chunking>
        <chunking id="3" string="blame Ben personally for that damage" type="VP">
          <tokens>
            <token id="13" string="blame" />
            <token id="14" string="Ben" />
            <token id="15" string="personally" />
            <token id="16" string="for" />
            <token id="17" string="that" />
            <token id="18" string="damage" />
          </tokens>
        </chunking>
        <chunking id="4" string="to blame Ben personally for that damage" type="VP">
          <tokens>
            <token id="12" string="to" />
            <token id="13" string="blame" />
            <token id="14" string="Ben" />
            <token id="15" string="personally" />
            <token id="16" string="for" />
            <token id="17" string="that" />
            <token id="18" string="damage" />
          </tokens>
        </chunking>
        <chunking id="5" string="Ben" type="NP">
          <tokens>
            <token id="14" string="Ben" />
          </tokens>
        </chunking>
        <chunking id="6" string="people" type="NP">
          <tokens>
            <token id="10" string="people" />
          </tokens>
        </chunking>
        <chunking id="7" string="has been damage to the sport" type="VP">
          <tokens>
            <token id="3" string="has" />
            <token id="4" string="been" />
            <token id="5" string="damage" />
            <token id="6" string="to" />
            <token id="7" string="the" />
            <token id="8" string="sport" />
          </tokens>
        </chunking>
        <chunking id="8" string="the sport" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="sport" />
          </tokens>
        </chunking>
        <chunking id="9" string="There" type="NP">
          <tokens>
            <token id="2" string="There" />
          </tokens>
        </chunking>
        <chunking id="10" string="damage to the sport" type="NP">
          <tokens>
            <token id="5" string="damage" />
            <token id="6" string="to" />
            <token id="7" string="the" />
            <token id="8" string="sport" />
          </tokens>
        </chunking>
        <chunking id="11" string="been damage to the sport" type="VP">
          <tokens>
            <token id="4" string="been" />
            <token id="5" string="damage" />
            <token id="6" string="to" />
            <token id="7" string="the" />
            <token id="8" string="sport" />
          </tokens>
        </chunking>
        <chunking id="12" string="want to blame Ben personally for that damage" type="VP">
          <tokens>
            <token id="11" string="want" />
            <token id="12" string="to" />
            <token id="13" string="blame" />
            <token id="14" string="Ben" />
            <token id="15" string="personally" />
            <token id="16" string="for" />
            <token id="17" string="that" />
            <token id="18" string="damage" />
          </tokens>
        </chunking>
        <chunking id="13" string="Gaines" type="NP">
          <tokens>
            <token id="21" string="Gaines" />
          </tokens>
        </chunking>
        <chunking id="14" string="said" type="VP">
          <tokens>
            <token id="22" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="5">damage</governor>
          <dependent id="2">There</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">damage</governor>
          <dependent id="3">has</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">damage</governor>
          <dependent id="4">been</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="22">said</governor>
          <dependent id="5">damage</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">sport</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">sport</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">damage</governor>
          <dependent id="8">sport</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">damage</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">want</governor>
          <dependent id="10">people</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">damage</governor>
          <dependent id="11">want</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">blame</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="11">want</governor>
          <dependent id="13">blame</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">blame</governor>
          <dependent id="14">Ben</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">blame</governor>
          <dependent id="15">personally</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">damage</governor>
          <dependent id="16">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">damage</governor>
          <dependent id="17">that</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">blame</governor>
          <dependent id="18">damage</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">said</governor>
          <dependent id="21">Gaines</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="22">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ben" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Ben" />
          </tokens>
        </entity>
        <entity id="2" string="Gaines" type="PERSON" score="0.0">
          <tokens>
            <token id="21" string="Gaines" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="71" has_coreference="true">
      <content>&amp;quot;We are very cognizant of the fact that people are looking upon his return with something like skepticism and animosity.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="cognizant" lemma="cognizant" stem="cogniz" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="fact" lemma="fact" stem="fact" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="looking" lemma="look" stem="look" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="upon" lemma="upon" stem="upon" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="return" lemma="return" stem="return" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="something" lemma="something" stem="someth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="skepticism" lemma="skepticism" stem="skeptic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="animosity" lemma="animosity" stem="animos" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP We)) (VP (VBP are) (ADJP (RB very) (JJ cognizant) (PP (IN of) (NP (DT the) (NN fact)))) (SBAR (IN that) (S (NP (NNS people)) (VP (VBP are) (VP (VBG looking) (PP (IN upon) (NP (PRP$ his) (NN return))) (PP (IN with) (NP (NP (NN something)) (PP (IN like) (NP (NN skepticism) (CC and) (NN animosity)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="are very cognizant of the fact that people are looking upon his return with something like skepticism and animosity" type="VP">
          <tokens>
            <token id="3" string="are" />
            <token id="4" string="very" />
            <token id="5" string="cognizant" />
            <token id="6" string="of" />
            <token id="7" string="the" />
            <token id="8" string="fact" />
            <token id="9" string="that" />
            <token id="10" string="people" />
            <token id="11" string="are" />
            <token id="12" string="looking" />
            <token id="13" string="upon" />
            <token id="14" string="his" />
            <token id="15" string="return" />
            <token id="16" string="with" />
            <token id="17" string="something" />
            <token id="18" string="like" />
            <token id="19" string="skepticism" />
            <token id="20" string="and" />
            <token id="21" string="animosity" />
          </tokens>
        </chunking>
        <chunking id="2" string="very cognizant of the fact" type="ADJP">
          <tokens>
            <token id="4" string="very" />
            <token id="5" string="cognizant" />
            <token id="6" string="of" />
            <token id="7" string="the" />
            <token id="8" string="fact" />
          </tokens>
        </chunking>
        <chunking id="3" string="something like skepticism and animosity" type="NP">
          <tokens>
            <token id="17" string="something" />
            <token id="18" string="like" />
            <token id="19" string="skepticism" />
            <token id="20" string="and" />
            <token id="21" string="animosity" />
          </tokens>
        </chunking>
        <chunking id="4" string="skepticism and animosity" type="NP">
          <tokens>
            <token id="19" string="skepticism" />
            <token id="20" string="and" />
            <token id="21" string="animosity" />
          </tokens>
        </chunking>
        <chunking id="5" string="the fact" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="fact" />
          </tokens>
        </chunking>
        <chunking id="6" string="looking upon his return with something like skepticism and animosity" type="VP">
          <tokens>
            <token id="12" string="looking" />
            <token id="13" string="upon" />
            <token id="14" string="his" />
            <token id="15" string="return" />
            <token id="16" string="with" />
            <token id="17" string="something" />
            <token id="18" string="like" />
            <token id="19" string="skepticism" />
            <token id="20" string="and" />
            <token id="21" string="animosity" />
          </tokens>
        </chunking>
        <chunking id="7" string="his return" type="NP">
          <tokens>
            <token id="14" string="his" />
            <token id="15" string="return" />
          </tokens>
        </chunking>
        <chunking id="8" string="that people are looking upon his return with something like skepticism and animosity" type="SBAR">
          <tokens>
            <token id="9" string="that" />
            <token id="10" string="people" />
            <token id="11" string="are" />
            <token id="12" string="looking" />
            <token id="13" string="upon" />
            <token id="14" string="his" />
            <token id="15" string="return" />
            <token id="16" string="with" />
            <token id="17" string="something" />
            <token id="18" string="like" />
            <token id="19" string="skepticism" />
            <token id="20" string="and" />
            <token id="21" string="animosity" />
          </tokens>
        </chunking>
        <chunking id="9" string="people" type="NP">
          <tokens>
            <token id="10" string="people" />
          </tokens>
        </chunking>
        <chunking id="10" string="We" type="NP">
          <tokens>
            <token id="2" string="We" />
          </tokens>
        </chunking>
        <chunking id="11" string="something" type="NP">
          <tokens>
            <token id="17" string="something" />
          </tokens>
        </chunking>
        <chunking id="12" string="are looking upon his return with something like skepticism and animosity" type="VP">
          <tokens>
            <token id="11" string="are" />
            <token id="12" string="looking" />
            <token id="13" string="upon" />
            <token id="14" string="his" />
            <token id="15" string="return" />
            <token id="16" string="with" />
            <token id="17" string="something" />
            <token id="18" string="like" />
            <token id="19" string="skepticism" />
            <token id="20" string="and" />
            <token id="21" string="animosity" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">cognizant</governor>
          <dependent id="2">We</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">cognizant</governor>
          <dependent id="3">are</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">cognizant</governor>
          <dependent id="4">very</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">cognizant</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">fact</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">fact</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">cognizant</governor>
          <dependent id="8">fact</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">looking</governor>
          <dependent id="9">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">looking</governor>
          <dependent id="10">people</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">looking</governor>
          <dependent id="11">are</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">cognizant</governor>
          <dependent id="12">looking</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">return</governor>
          <dependent id="13">upon</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">return</governor>
          <dependent id="14">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">looking</governor>
          <dependent id="15">return</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">something</governor>
          <dependent id="16">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">looking</governor>
          <dependent id="17">something</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">skepticism</governor>
          <dependent id="18">like</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">something</governor>
          <dependent id="19">skepticism</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="19">skepticism</governor>
          <dependent id="20">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">skepticism</governor>
          <dependent id="21">animosity</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="72" has_coreference="false">
      <content>To what extent, we don&amp;apost;t know.&amp;quot;</content>
      <tokens>
        <token id="1" string="To" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="extent" lemma="extent" stem="extent" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="know" lemma="know" stem="know" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (FRAG (WHPP (TO To) (WHNP (WP what) (NP (NN extent))))) (, ,) (NP (PRP we)) (VP (VBP do) (RB n't) (VP (VB know))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="extent" type="NP">
          <tokens>
            <token id="3" string="extent" />
          </tokens>
        </chunking>
        <chunking id="2" string="do n't know" type="VP">
          <tokens>
            <token id="6" string="do" />
            <token id="7" string="n't" />
            <token id="8" string="know" />
          </tokens>
        </chunking>
        <chunking id="3" string="know" type="VP">
          <tokens>
            <token id="8" string="know" />
          </tokens>
        </chunking>
        <chunking id="4" string="we" type="NP">
          <tokens>
            <token id="5" string="we" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">what</governor>
          <dependent id="1">To</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="8">know</governor>
          <dependent id="2">what</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="2">what</governor>
          <dependent id="3">extent</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">know</governor>
          <dependent id="5">we</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">know</governor>
          <dependent id="6">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="8">know</governor>
          <dependent id="7">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">know</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="73" has_coreference="true">
      <content>Some meet directors report concern that longtime sponsors will be reluctant to be associated with a meet that has Johnson as its marquee athlete, given Johnson&amp;apost;s former association with anabolic steroids.</content>
      <tokens>
        <token id="1" string="Some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="meet" lemma="meet" stem="meet" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="directors" lemma="director" stem="director" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="report" lemma="report" stem="report" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="concern" lemma="concern" stem="concern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="longtime" lemma="longtime" stem="longtim" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="sponsors" lemma="sponsor" stem="sponsor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="reluctant" lemma="reluctant" stem="reluct" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="associated" lemma="associate" stem="associ" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="meet" lemma="meet" stem="meet" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="21" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="marquee" lemma="marquee" stem="marque" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="athlete" lemma="athlete" stem="athlet" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="given" lemma="give" stem="given" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="28" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="29" string="former" lemma="former" stem="former" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="association" lemma="association" stem="associ" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="anabolic" lemma="anabolic" stem="anabol" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="steroids" lemma="steroid" stem="steroid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT Some)) (VP (VBP meet) (S (NP (NNS directors)) (VP (VB report) (NP (NN concern)) (SBAR (IN that) (S (NP (JJ longtime) (NNS sponsors)) (VP (MD will) (VP (VB be) (ADJP (JJ reluctant) (S (VP (TO to) (VP (VB be) (VP (VBN associated) (SBAR (IN with) (S (NP (DT a)) (VP (VBP meet) (SBAR (S (NP (DT that)) (VP (VBZ has) (NP (NP (NNP Johnson)) (PP (IN as) (NP (NP (PRP$ its) (JJ marquee) (NN athlete)) (, ,) (VP (VBN given) (NP (NP (NNP Johnson) (POS 's)) (JJ former) (NN association)) (PP (IN with) (NP (JJ anabolic) (NNS steroids))))))))))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a" type="NP">
          <tokens>
            <token id="16" string="a" />
          </tokens>
        </chunking>
        <chunking id="2" string="be reluctant to be associated with a meet that has Johnson as its marquee athlete , given Johnson 's former association with anabolic steroids" type="VP">
          <tokens>
            <token id="10" string="be" />
            <token id="11" string="reluctant" />
            <token id="12" string="to" />
            <token id="13" string="be" />
            <token id="14" string="associated" />
            <token id="15" string="with" />
            <token id="16" string="a" />
            <token id="17" string="meet" />
            <token id="18" string="that" />
            <token id="19" string="has" />
            <token id="20" string="Johnson" />
            <token id="21" string="as" />
            <token id="22" string="its" />
            <token id="23" string="marquee" />
            <token id="24" string="athlete" />
            <token id="25" string="," />
            <token id="26" string="given" />
            <token id="27" string="Johnson" />
            <token id="28" string="'s" />
            <token id="29" string="former" />
            <token id="30" string="association" />
            <token id="31" string="with" />
            <token id="32" string="anabolic" />
            <token id="33" string="steroids" />
          </tokens>
        </chunking>
        <chunking id="3" string="Johnson" type="NP">
          <tokens>
            <token id="20" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="4" string="its marquee athlete , given Johnson 's former association with anabolic steroids" type="NP">
          <tokens>
            <token id="22" string="its" />
            <token id="23" string="marquee" />
            <token id="24" string="athlete" />
            <token id="25" string="," />
            <token id="26" string="given" />
            <token id="27" string="Johnson" />
            <token id="28" string="'s" />
            <token id="29" string="former" />
            <token id="30" string="association" />
            <token id="31" string="with" />
            <token id="32" string="anabolic" />
            <token id="33" string="steroids" />
          </tokens>
        </chunking>
        <chunking id="5" string="to be associated with a meet that has Johnson as its marquee athlete , given Johnson 's former association with anabolic steroids" type="VP">
          <tokens>
            <token id="12" string="to" />
            <token id="13" string="be" />
            <token id="14" string="associated" />
            <token id="15" string="with" />
            <token id="16" string="a" />
            <token id="17" string="meet" />
            <token id="18" string="that" />
            <token id="19" string="has" />
            <token id="20" string="Johnson" />
            <token id="21" string="as" />
            <token id="22" string="its" />
            <token id="23" string="marquee" />
            <token id="24" string="athlete" />
            <token id="25" string="," />
            <token id="26" string="given" />
            <token id="27" string="Johnson" />
            <token id="28" string="'s" />
            <token id="29" string="former" />
            <token id="30" string="association" />
            <token id="31" string="with" />
            <token id="32" string="anabolic" />
            <token id="33" string="steroids" />
          </tokens>
        </chunking>
        <chunking id="6" string="that longtime sponsors will be reluctant to be associated with a meet that has Johnson as its marquee athlete , given Johnson 's former association with anabolic steroids" type="SBAR">
          <tokens>
            <token id="6" string="that" />
            <token id="7" string="longtime" />
            <token id="8" string="sponsors" />
            <token id="9" string="will" />
            <token id="10" string="be" />
            <token id="11" string="reluctant" />
            <token id="12" string="to" />
            <token id="13" string="be" />
            <token id="14" string="associated" />
            <token id="15" string="with" />
            <token id="16" string="a" />
            <token id="17" string="meet" />
            <token id="18" string="that" />
            <token id="19" string="has" />
            <token id="20" string="Johnson" />
            <token id="21" string="as" />
            <token id="22" string="its" />
            <token id="23" string="marquee" />
            <token id="24" string="athlete" />
            <token id="25" string="," />
            <token id="26" string="given" />
            <token id="27" string="Johnson" />
            <token id="28" string="'s" />
            <token id="29" string="former" />
            <token id="30" string="association" />
            <token id="31" string="with" />
            <token id="32" string="anabolic" />
            <token id="33" string="steroids" />
          </tokens>
        </chunking>
        <chunking id="7" string="concern" type="NP">
          <tokens>
            <token id="5" string="concern" />
          </tokens>
        </chunking>
        <chunking id="8" string="will be reluctant to be associated with a meet that has Johnson as its marquee athlete , given Johnson 's former association with anabolic steroids" type="VP">
          <tokens>
            <token id="9" string="will" />
            <token id="10" string="be" />
            <token id="11" string="reluctant" />
            <token id="12" string="to" />
            <token id="13" string="be" />
            <token id="14" string="associated" />
            <token id="15" string="with" />
            <token id="16" string="a" />
            <token id="17" string="meet" />
            <token id="18" string="that" />
            <token id="19" string="has" />
            <token id="20" string="Johnson" />
            <token id="21" string="as" />
            <token id="22" string="its" />
            <token id="23" string="marquee" />
            <token id="24" string="athlete" />
            <token id="25" string="," />
            <token id="26" string="given" />
            <token id="27" string="Johnson" />
            <token id="28" string="'s" />
            <token id="29" string="former" />
            <token id="30" string="association" />
            <token id="31" string="with" />
            <token id="32" string="anabolic" />
            <token id="33" string="steroids" />
          </tokens>
        </chunking>
        <chunking id="9" string="Some" type="NP">
          <tokens>
            <token id="1" string="Some" />
          </tokens>
        </chunking>
        <chunking id="10" string="has Johnson as its marquee athlete , given Johnson 's former association with anabolic steroids" type="VP">
          <tokens>
            <token id="19" string="has" />
            <token id="20" string="Johnson" />
            <token id="21" string="as" />
            <token id="22" string="its" />
            <token id="23" string="marquee" />
            <token id="24" string="athlete" />
            <token id="25" string="," />
            <token id="26" string="given" />
            <token id="27" string="Johnson" />
            <token id="28" string="'s" />
            <token id="29" string="former" />
            <token id="30" string="association" />
            <token id="31" string="with" />
            <token id="32" string="anabolic" />
            <token id="33" string="steroids" />
          </tokens>
        </chunking>
        <chunking id="11" string="associated with a meet that has Johnson as its marquee athlete , given Johnson 's former association with anabolic steroids" type="VP">
          <tokens>
            <token id="14" string="associated" />
            <token id="15" string="with" />
            <token id="16" string="a" />
            <token id="17" string="meet" />
            <token id="18" string="that" />
            <token id="19" string="has" />
            <token id="20" string="Johnson" />
            <token id="21" string="as" />
            <token id="22" string="its" />
            <token id="23" string="marquee" />
            <token id="24" string="athlete" />
            <token id="25" string="," />
            <token id="26" string="given" />
            <token id="27" string="Johnson" />
            <token id="28" string="'s" />
            <token id="29" string="former" />
            <token id="30" string="association" />
            <token id="31" string="with" />
            <token id="32" string="anabolic" />
            <token id="33" string="steroids" />
          </tokens>
        </chunking>
        <chunking id="12" string="its marquee athlete" type="NP">
          <tokens>
            <token id="22" string="its" />
            <token id="23" string="marquee" />
            <token id="24" string="athlete" />
          </tokens>
        </chunking>
        <chunking id="13" string="with a meet that has Johnson as its marquee athlete , given Johnson 's former association with anabolic steroids" type="SBAR">
          <tokens>
            <token id="15" string="with" />
            <token id="16" string="a" />
            <token id="17" string="meet" />
            <token id="18" string="that" />
            <token id="19" string="has" />
            <token id="20" string="Johnson" />
            <token id="21" string="as" />
            <token id="22" string="its" />
            <token id="23" string="marquee" />
            <token id="24" string="athlete" />
            <token id="25" string="," />
            <token id="26" string="given" />
            <token id="27" string="Johnson" />
            <token id="28" string="'s" />
            <token id="29" string="former" />
            <token id="30" string="association" />
            <token id="31" string="with" />
            <token id="32" string="anabolic" />
            <token id="33" string="steroids" />
          </tokens>
        </chunking>
        <chunking id="14" string="Johnson 's" type="NP">
          <tokens>
            <token id="27" string="Johnson" />
            <token id="28" string="'s" />
          </tokens>
        </chunking>
        <chunking id="15" string="Johnson as its marquee athlete , given Johnson 's former association with anabolic steroids" type="NP">
          <tokens>
            <token id="20" string="Johnson" />
            <token id="21" string="as" />
            <token id="22" string="its" />
            <token id="23" string="marquee" />
            <token id="24" string="athlete" />
            <token id="25" string="," />
            <token id="26" string="given" />
            <token id="27" string="Johnson" />
            <token id="28" string="'s" />
            <token id="29" string="former" />
            <token id="30" string="association" />
            <token id="31" string="with" />
            <token id="32" string="anabolic" />
            <token id="33" string="steroids" />
          </tokens>
        </chunking>
        <chunking id="16" string="directors" type="NP">
          <tokens>
            <token id="3" string="directors" />
          </tokens>
        </chunking>
        <chunking id="17" string="report concern that longtime sponsors will be reluctant to be associated with a meet that has Johnson as its marquee athlete , given Johnson 's former association with anabolic steroids" type="VP">
          <tokens>
            <token id="4" string="report" />
            <token id="5" string="concern" />
            <token id="6" string="that" />
            <token id="7" string="longtime" />
            <token id="8" string="sponsors" />
            <token id="9" string="will" />
            <token id="10" string="be" />
            <token id="11" string="reluctant" />
            <token id="12" string="to" />
            <token id="13" string="be" />
            <token id="14" string="associated" />
            <token id="15" string="with" />
            <token id="16" string="a" />
            <token id="17" string="meet" />
            <token id="18" string="that" />
            <token id="19" string="has" />
            <token id="20" string="Johnson" />
            <token id="21" string="as" />
            <token id="22" string="its" />
            <token id="23" string="marquee" />
            <token id="24" string="athlete" />
            <token id="25" string="," />
            <token id="26" string="given" />
            <token id="27" string="Johnson" />
            <token id="28" string="'s" />
            <token id="29" string="former" />
            <token id="30" string="association" />
            <token id="31" string="with" />
            <token id="32" string="anabolic" />
            <token id="33" string="steroids" />
          </tokens>
        </chunking>
        <chunking id="18" string="that has Johnson as its marquee athlete , given Johnson 's former association with anabolic steroids" type="SBAR">
          <tokens>
            <token id="18" string="that" />
            <token id="19" string="has" />
            <token id="20" string="Johnson" />
            <token id="21" string="as" />
            <token id="22" string="its" />
            <token id="23" string="marquee" />
            <token id="24" string="athlete" />
            <token id="25" string="," />
            <token id="26" string="given" />
            <token id="27" string="Johnson" />
            <token id="28" string="'s" />
            <token id="29" string="former" />
            <token id="30" string="association" />
            <token id="31" string="with" />
            <token id="32" string="anabolic" />
            <token id="33" string="steroids" />
          </tokens>
        </chunking>
        <chunking id="19" string="be associated with a meet that has Johnson as its marquee athlete , given Johnson 's former association with anabolic steroids" type="VP">
          <tokens>
            <token id="13" string="be" />
            <token id="14" string="associated" />
            <token id="15" string="with" />
            <token id="16" string="a" />
            <token id="17" string="meet" />
            <token id="18" string="that" />
            <token id="19" string="has" />
            <token id="20" string="Johnson" />
            <token id="21" string="as" />
            <token id="22" string="its" />
            <token id="23" string="marquee" />
            <token id="24" string="athlete" />
            <token id="25" string="," />
            <token id="26" string="given" />
            <token id="27" string="Johnson" />
            <token id="28" string="'s" />
            <token id="29" string="former" />
            <token id="30" string="association" />
            <token id="31" string="with" />
            <token id="32" string="anabolic" />
            <token id="33" string="steroids" />
          </tokens>
        </chunking>
        <chunking id="20" string="longtime sponsors" type="NP">
          <tokens>
            <token id="7" string="longtime" />
            <token id="8" string="sponsors" />
          </tokens>
        </chunking>
        <chunking id="21" string="that" type="NP">
          <tokens>
            <token id="18" string="that" />
          </tokens>
        </chunking>
        <chunking id="22" string="Johnson 's former association" type="NP">
          <tokens>
            <token id="27" string="Johnson" />
            <token id="28" string="'s" />
            <token id="29" string="former" />
            <token id="30" string="association" />
          </tokens>
        </chunking>
        <chunking id="23" string="given Johnson 's former association with anabolic steroids" type="VP">
          <tokens>
            <token id="26" string="given" />
            <token id="27" string="Johnson" />
            <token id="28" string="'s" />
            <token id="29" string="former" />
            <token id="30" string="association" />
            <token id="31" string="with" />
            <token id="32" string="anabolic" />
            <token id="33" string="steroids" />
          </tokens>
        </chunking>
        <chunking id="24" string="reluctant to be associated with a meet that has Johnson as its marquee athlete , given Johnson 's former association with anabolic steroids" type="ADJP">
          <tokens>
            <token id="11" string="reluctant" />
            <token id="12" string="to" />
            <token id="13" string="be" />
            <token id="14" string="associated" />
            <token id="15" string="with" />
            <token id="16" string="a" />
            <token id="17" string="meet" />
            <token id="18" string="that" />
            <token id="19" string="has" />
            <token id="20" string="Johnson" />
            <token id="21" string="as" />
            <token id="22" string="its" />
            <token id="23" string="marquee" />
            <token id="24" string="athlete" />
            <token id="25" string="," />
            <token id="26" string="given" />
            <token id="27" string="Johnson" />
            <token id="28" string="'s" />
            <token id="29" string="former" />
            <token id="30" string="association" />
            <token id="31" string="with" />
            <token id="32" string="anabolic" />
            <token id="33" string="steroids" />
          </tokens>
        </chunking>
        <chunking id="25" string="anabolic steroids" type="NP">
          <tokens>
            <token id="32" string="anabolic" />
            <token id="33" string="steroids" />
          </tokens>
        </chunking>
        <chunking id="26" string="meet directors report concern that longtime sponsors will be reluctant to be associated with a meet that has Johnson as its marquee athlete , given Johnson 's former association with anabolic steroids" type="VP">
          <tokens>
            <token id="2" string="meet" />
            <token id="3" string="directors" />
            <token id="4" string="report" />
            <token id="5" string="concern" />
            <token id="6" string="that" />
            <token id="7" string="longtime" />
            <token id="8" string="sponsors" />
            <token id="9" string="will" />
            <token id="10" string="be" />
            <token id="11" string="reluctant" />
            <token id="12" string="to" />
            <token id="13" string="be" />
            <token id="14" string="associated" />
            <token id="15" string="with" />
            <token id="16" string="a" />
            <token id="17" string="meet" />
            <token id="18" string="that" />
            <token id="19" string="has" />
            <token id="20" string="Johnson" />
            <token id="21" string="as" />
            <token id="22" string="its" />
            <token id="23" string="marquee" />
            <token id="24" string="athlete" />
            <token id="25" string="," />
            <token id="26" string="given" />
            <token id="27" string="Johnson" />
            <token id="28" string="'s" />
            <token id="29" string="former" />
            <token id="30" string="association" />
            <token id="31" string="with" />
            <token id="32" string="anabolic" />
            <token id="33" string="steroids" />
          </tokens>
        </chunking>
        <chunking id="27" string="meet that has Johnson as its marquee athlete , given Johnson 's former association with anabolic steroids" type="VP">
          <tokens>
            <token id="17" string="meet" />
            <token id="18" string="that" />
            <token id="19" string="has" />
            <token id="20" string="Johnson" />
            <token id="21" string="as" />
            <token id="22" string="its" />
            <token id="23" string="marquee" />
            <token id="24" string="athlete" />
            <token id="25" string="," />
            <token id="26" string="given" />
            <token id="27" string="Johnson" />
            <token id="28" string="'s" />
            <token id="29" string="former" />
            <token id="30" string="association" />
            <token id="31" string="with" />
            <token id="32" string="anabolic" />
            <token id="33" string="steroids" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">meet</governor>
          <dependent id="1">Some</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">meet</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">report</governor>
          <dependent id="3">directors</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">meet</governor>
          <dependent id="4">report</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">report</governor>
          <dependent id="5">concern</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">reluctant</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">sponsors</governor>
          <dependent id="7">longtime</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">reluctant</governor>
          <dependent id="8">sponsors</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">reluctant</governor>
          <dependent id="9">will</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">reluctant</governor>
          <dependent id="10">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">report</governor>
          <dependent id="11">reluctant</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">associated</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="14">associated</governor>
          <dependent id="13">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="11">reluctant</governor>
          <dependent id="14">associated</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">meet</governor>
          <dependent id="15">with</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">meet</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="14">associated</governor>
          <dependent id="17">meet</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">has</governor>
          <dependent id="18">that</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">meet</governor>
          <dependent id="19">has</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">has</governor>
          <dependent id="20">Johnson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">athlete</governor>
          <dependent id="21">as</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="24">athlete</governor>
          <dependent id="22">its</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">athlete</governor>
          <dependent id="23">marquee</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">Johnson</governor>
          <dependent id="24">athlete</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="24">athlete</governor>
          <dependent id="26">given</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="30">association</governor>
          <dependent id="27">Johnson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">Johnson</governor>
          <dependent id="28">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="30">association</governor>
          <dependent id="29">former</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="26">given</governor>
          <dependent id="30">association</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">steroids</governor>
          <dependent id="31">with</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="33">steroids</governor>
          <dependent id="32">anabolic</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">given</governor>
          <dependent id="33">steroids</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="Johnson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="74" has_coreference="true">
      <content>Franken said he had meetings with his sponsor, Sunkist, to discuss the possible image problem.</content>
      <tokens>
        <token id="1" string="Franken" lemma="Franken" stem="franken" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="meetings" lemma="meeting" stem="meet" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="sponsor" lemma="sponsor" stem="sponsor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Sunkist" lemma="Sunkist" stem="sunkist" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="discuss" lemma="discuss" stem="discuss" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="possible" lemma="possible" stem="possibl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="image" lemma="image" stem="imag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="problem" lemma="problem" stem="problem" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Franken)) (VP (VBD said) (SBAR (S (NP (PRP he)) (VP (VBD had) (NP (NP (NNS meetings)) (PP (IN with) (NP (NP (PRP$ his) (NN sponsor)) (, ,) (NP (NNP Sunkist))))) (, ,) (S (VP (TO to) (VP (VB discuss) (NP (DT the) (JJ possible) (NN image) (NN problem))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="he had meetings with his sponsor , Sunkist , to discuss the possible image problem" type="SBAR">
          <tokens>
            <token id="3" string="he" />
            <token id="4" string="had" />
            <token id="5" string="meetings" />
            <token id="6" string="with" />
            <token id="7" string="his" />
            <token id="8" string="sponsor" />
            <token id="9" string="," />
            <token id="10" string="Sunkist" />
            <token id="11" string="," />
            <token id="12" string="to" />
            <token id="13" string="discuss" />
            <token id="14" string="the" />
            <token id="15" string="possible" />
            <token id="16" string="image" />
            <token id="17" string="problem" />
          </tokens>
        </chunking>
        <chunking id="2" string="had meetings with his sponsor , Sunkist , to discuss the possible image problem" type="VP">
          <tokens>
            <token id="4" string="had" />
            <token id="5" string="meetings" />
            <token id="6" string="with" />
            <token id="7" string="his" />
            <token id="8" string="sponsor" />
            <token id="9" string="," />
            <token id="10" string="Sunkist" />
            <token id="11" string="," />
            <token id="12" string="to" />
            <token id="13" string="discuss" />
            <token id="14" string="the" />
            <token id="15" string="possible" />
            <token id="16" string="image" />
            <token id="17" string="problem" />
          </tokens>
        </chunking>
        <chunking id="3" string="said he had meetings with his sponsor , Sunkist , to discuss the possible image problem" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="he" />
            <token id="4" string="had" />
            <token id="5" string="meetings" />
            <token id="6" string="with" />
            <token id="7" string="his" />
            <token id="8" string="sponsor" />
            <token id="9" string="," />
            <token id="10" string="Sunkist" />
            <token id="11" string="," />
            <token id="12" string="to" />
            <token id="13" string="discuss" />
            <token id="14" string="the" />
            <token id="15" string="possible" />
            <token id="16" string="image" />
            <token id="17" string="problem" />
          </tokens>
        </chunking>
        <chunking id="4" string="Sunkist" type="NP">
          <tokens>
            <token id="10" string="Sunkist" />
          </tokens>
        </chunking>
        <chunking id="5" string="the possible image problem" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="possible" />
            <token id="16" string="image" />
            <token id="17" string="problem" />
          </tokens>
        </chunking>
        <chunking id="6" string="his sponsor" type="NP">
          <tokens>
            <token id="7" string="his" />
            <token id="8" string="sponsor" />
          </tokens>
        </chunking>
        <chunking id="7" string="to discuss the possible image problem" type="VP">
          <tokens>
            <token id="12" string="to" />
            <token id="13" string="discuss" />
            <token id="14" string="the" />
            <token id="15" string="possible" />
            <token id="16" string="image" />
            <token id="17" string="problem" />
          </tokens>
        </chunking>
        <chunking id="8" string="meetings with his sponsor , Sunkist" type="NP">
          <tokens>
            <token id="5" string="meetings" />
            <token id="6" string="with" />
            <token id="7" string="his" />
            <token id="8" string="sponsor" />
            <token id="9" string="," />
            <token id="10" string="Sunkist" />
          </tokens>
        </chunking>
        <chunking id="9" string="meetings" type="NP">
          <tokens>
            <token id="5" string="meetings" />
          </tokens>
        </chunking>
        <chunking id="10" string="his sponsor , Sunkist" type="NP">
          <tokens>
            <token id="7" string="his" />
            <token id="8" string="sponsor" />
            <token id="9" string="," />
            <token id="10" string="Sunkist" />
          </tokens>
        </chunking>
        <chunking id="11" string="discuss the possible image problem" type="VP">
          <tokens>
            <token id="13" string="discuss" />
            <token id="14" string="the" />
            <token id="15" string="possible" />
            <token id="16" string="image" />
            <token id="17" string="problem" />
          </tokens>
        </chunking>
        <chunking id="12" string="he" type="NP">
          <tokens>
            <token id="3" string="he" />
          </tokens>
        </chunking>
        <chunking id="13" string="Franken" type="NP">
          <tokens>
            <token id="1" string="Franken" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">Franken</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">had</governor>
          <dependent id="3">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="4">had</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">had</governor>
          <dependent id="5">meetings</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">sponsor</governor>
          <dependent id="6">with</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">sponsor</governor>
          <dependent id="7">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">meetings</governor>
          <dependent id="8">sponsor</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="8">sponsor</governor>
          <dependent id="10">Sunkist</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">discuss</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">had</governor>
          <dependent id="13">discuss</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">problem</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">problem</governor>
          <dependent id="15">possible</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">problem</governor>
          <dependent id="16">image</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">discuss</governor>
          <dependent id="17">problem</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Sunkist" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="10" string="Sunkist" />
          </tokens>
        </entity>
        <entity id="2" string="Franken" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Franken" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="75" has_coreference="true">
      <content>Schmertz, too, has given the matter some thought.</content>
      <tokens>
        <token id="1" string="Schmertz" lemma="Schmertz" stem="schmertz" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="too" lemma="too" stem="too" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="given" lemma="give" stem="given" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="matter" lemma="matter" stem="matter" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="thought" lemma="thought" stem="thought" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Schmertz)) (, ,) (ADVP (RB too)) (, ,) (VP (VBZ has) (VP (VBN given) (NP (DT the) (NN matter)) (NP (DT some) (NN thought)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="given the matter some thought" type="VP">
          <tokens>
            <token id="6" string="given" />
            <token id="7" string="the" />
            <token id="8" string="matter" />
            <token id="9" string="some" />
            <token id="10" string="thought" />
          </tokens>
        </chunking>
        <chunking id="2" string="some thought" type="NP">
          <tokens>
            <token id="9" string="some" />
            <token id="10" string="thought" />
          </tokens>
        </chunking>
        <chunking id="3" string="Schmertz" type="NP">
          <tokens>
            <token id="1" string="Schmertz" />
          </tokens>
        </chunking>
        <chunking id="4" string="has given the matter some thought" type="VP">
          <tokens>
            <token id="5" string="has" />
            <token id="6" string="given" />
            <token id="7" string="the" />
            <token id="8" string="matter" />
            <token id="9" string="some" />
            <token id="10" string="thought" />
          </tokens>
        </chunking>
        <chunking id="5" string="the matter" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="matter" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">given</governor>
          <dependent id="1">Schmertz</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">given</governor>
          <dependent id="3">too</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">given</governor>
          <dependent id="5">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">given</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">matter</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="iobj">
          <governor id="6">given</governor>
          <dependent id="8">matter</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">thought</governor>
          <dependent id="9">some</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">given</governor>
          <dependent id="10">thought</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Schmertz" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Schmertz" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="76" has_coreference="true">
      <content>&amp;quot;I&amp;apost;ve had that thought myself, paying him that much money,&amp;quot; he said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'ve" lemma="have" stem="'ve" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="thought" lemma="think" stem="thought" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="myself" lemma="myself" stem="myself" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="paying" lemma="pay" stem="pai" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="much" lemma="much" stem="much" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="money" lemma="money" stem="monei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP I)) (VP (VBP 've) (VP (VBD had) (S (NP (DT that)) (VP (VBD thought) (NP (PRP myself)) (, ,) (S (VP (VBG paying) (NP (NP (PRP him)) (SBAR (WHNP (WDT that) (JJ much) (NN money))))))))))) (, ,) ('' '') (NP (PRP he)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that" type="NP">
          <tokens>
            <token id="5" string="that" />
          </tokens>
        </chunking>
        <chunking id="2" string="'ve had that thought myself , paying him that much money" type="VP">
          <tokens>
            <token id="3" string="'ve" />
            <token id="4" string="had" />
            <token id="5" string="that" />
            <token id="6" string="thought" />
            <token id="7" string="myself" />
            <token id="8" string="," />
            <token id="9" string="paying" />
            <token id="10" string="him" />
            <token id="11" string="that" />
            <token id="12" string="much" />
            <token id="13" string="money" />
          </tokens>
        </chunking>
        <chunking id="3" string="had that thought myself , paying him that much money" type="VP">
          <tokens>
            <token id="4" string="had" />
            <token id="5" string="that" />
            <token id="6" string="thought" />
            <token id="7" string="myself" />
            <token id="8" string="," />
            <token id="9" string="paying" />
            <token id="10" string="him" />
            <token id="11" string="that" />
            <token id="12" string="much" />
            <token id="13" string="money" />
          </tokens>
        </chunking>
        <chunking id="4" string="him that much money" type="NP">
          <tokens>
            <token id="10" string="him" />
            <token id="11" string="that" />
            <token id="12" string="much" />
            <token id="13" string="money" />
          </tokens>
        </chunking>
        <chunking id="5" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="myself" type="NP">
          <tokens>
            <token id="7" string="myself" />
          </tokens>
        </chunking>
        <chunking id="7" string="him" type="NP">
          <tokens>
            <token id="10" string="him" />
          </tokens>
        </chunking>
        <chunking id="8" string="he" type="NP">
          <tokens>
            <token id="16" string="he" />
          </tokens>
        </chunking>
        <chunking id="9" string="paying him that much money" type="VP">
          <tokens>
            <token id="9" string="paying" />
            <token id="10" string="him" />
            <token id="11" string="that" />
            <token id="12" string="much" />
            <token id="13" string="money" />
          </tokens>
        </chunking>
        <chunking id="10" string="that much money" type="SBAR">
          <tokens>
            <token id="11" string="that" />
            <token id="12" string="much" />
            <token id="13" string="money" />
          </tokens>
        </chunking>
        <chunking id="11" string="said" type="VP">
          <tokens>
            <token id="17" string="said" />
          </tokens>
        </chunking>
        <chunking id="12" string="thought myself , paying him that much money" type="VP">
          <tokens>
            <token id="6" string="thought" />
            <token id="7" string="myself" />
            <token id="8" string="," />
            <token id="9" string="paying" />
            <token id="10" string="him" />
            <token id="11" string="that" />
            <token id="12" string="much" />
            <token id="13" string="money" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">had</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">had</governor>
          <dependent id="3">'ve</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">said</governor>
          <dependent id="4">had</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">thought</governor>
          <dependent id="5">that</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">had</governor>
          <dependent id="6">thought</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">thought</governor>
          <dependent id="7">myself</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="6">thought</governor>
          <dependent id="9">paying</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">paying</governor>
          <dependent id="10">him</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">money</governor>
          <dependent id="11">that</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">money</governor>
          <dependent id="12">much</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="10">him</governor>
          <dependent id="13">money</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">said</governor>
          <dependent id="16">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">said</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="77" has_coreference="true">
      <content>&amp;quot;He was the greatest sprinter in history, then he was caught.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="greatest" lemma="greatest" stem="greatest" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="sprinter" lemma="sprinter" stem="sprinter" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="history" lemma="history" stem="histori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="caught" lemma="catch" stem="caught" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP He)) (VP (VBD was) (NP (NP (DT the) (JJS greatest) (NN sprinter)) (PP (IN in) (NP (NN history)))))) (, ,) (RB then) (S (NP (PRP he)) (VP (VBD was) (VP (VBN caught)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the greatest sprinter in history" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="greatest" />
            <token id="6" string="sprinter" />
            <token id="7" string="in" />
            <token id="8" string="history" />
          </tokens>
        </chunking>
        <chunking id="2" string="caught" type="VP">
          <tokens>
            <token id="13" string="caught" />
          </tokens>
        </chunking>
        <chunking id="3" string="the greatest sprinter" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="greatest" />
            <token id="6" string="sprinter" />
          </tokens>
        </chunking>
        <chunking id="4" string="was the greatest sprinter in history" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="the" />
            <token id="5" string="greatest" />
            <token id="6" string="sprinter" />
            <token id="7" string="in" />
            <token id="8" string="history" />
          </tokens>
        </chunking>
        <chunking id="5" string="He" type="NP">
          <tokens>
            <token id="2" string="He" />
          </tokens>
        </chunking>
        <chunking id="6" string="history" type="NP">
          <tokens>
            <token id="8" string="history" />
          </tokens>
        </chunking>
        <chunking id="7" string="he" type="NP">
          <tokens>
            <token id="11" string="he" />
          </tokens>
        </chunking>
        <chunking id="8" string="was caught" type="VP">
          <tokens>
            <token id="12" string="was" />
            <token id="13" string="caught" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">sprinter</governor>
          <dependent id="2">He</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">sprinter</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">sprinter</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">sprinter</governor>
          <dependent id="5">greatest</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">sprinter</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">history</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">sprinter</governor>
          <dependent id="8">history</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">caught</governor>
          <dependent id="10">then</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="13">caught</governor>
          <dependent id="11">he</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="13">caught</governor>
          <dependent id="12">was</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="6">sprinter</governor>
          <dependent id="13">caught</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="78" has_coreference="true">
      <content>Now he&amp;apost;s got a lot of notoriety.</content>
      <tokens>
        <token id="1" string="Now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="2" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="got" lemma="get" stem="got" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="lot" lemma="lot" stem="lot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="notoriety" lemma="notoriety" stem="notorieti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Now)) (NP (PRP he)) (VP (VBZ 's) (VP (VBD got) (NP (NP (DT a) (NN lot)) (PP (IN of) (NP (NN notoriety)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="'s got a lot of notoriety" type="VP">
          <tokens>
            <token id="3" string="'s" />
            <token id="4" string="got" />
            <token id="5" string="a" />
            <token id="6" string="lot" />
            <token id="7" string="of" />
            <token id="8" string="notoriety" />
          </tokens>
        </chunking>
        <chunking id="2" string="a lot" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="lot" />
          </tokens>
        </chunking>
        <chunking id="3" string="notoriety" type="NP">
          <tokens>
            <token id="8" string="notoriety" />
          </tokens>
        </chunking>
        <chunking id="4" string="a lot of notoriety" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="lot" />
            <token id="7" string="of" />
            <token id="8" string="notoriety" />
          </tokens>
        </chunking>
        <chunking id="5" string="he" type="NP">
          <tokens>
            <token id="2" string="he" />
          </tokens>
        </chunking>
        <chunking id="6" string="got a lot of notoriety" type="VP">
          <tokens>
            <token id="4" string="got" />
            <token id="5" string="a" />
            <token id="6" string="lot" />
            <token id="7" string="of" />
            <token id="8" string="notoriety" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="4">got</governor>
          <dependent id="1">Now</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="4">got</governor>
          <dependent id="2">he</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">got</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">got</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">lot</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">got</governor>
          <dependent id="6">lot</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">notoriety</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">lot</governor>
          <dependent id="8">notoriety</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Now" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="Now" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="79" has_coreference="true">
      <content>He probably thinks he can be paid more because of the notoriety.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="probably" lemma="probably" stem="probabl" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="thinks" lemma="think" stem="think" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="paid" lemma="pay" stem="paid" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="notoriety" lemma="notoriety" stem="notorieti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (ADVP (RB probably)) (VP (VBZ thinks) (SBAR (S (NP (PRP he)) (VP (MD can) (VP (VB be) (VP (VBN paid) (PP (ADVP (RBR more)) (IN because) (IN of) (NP (DT the) (NN notoriety))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="can be paid more because of the notoriety" type="VP">
          <tokens>
            <token id="5" string="can" />
            <token id="6" string="be" />
            <token id="7" string="paid" />
            <token id="8" string="more" />
            <token id="9" string="because" />
            <token id="10" string="of" />
            <token id="11" string="the" />
            <token id="12" string="notoriety" />
          </tokens>
        </chunking>
        <chunking id="2" string="be paid more because of the notoriety" type="VP">
          <tokens>
            <token id="6" string="be" />
            <token id="7" string="paid" />
            <token id="8" string="more" />
            <token id="9" string="because" />
            <token id="10" string="of" />
            <token id="11" string="the" />
            <token id="12" string="notoriety" />
          </tokens>
        </chunking>
        <chunking id="3" string="the notoriety" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="notoriety" />
          </tokens>
        </chunking>
        <chunking id="4" string="he can be paid more because of the notoriety" type="SBAR">
          <tokens>
            <token id="4" string="he" />
            <token id="5" string="can" />
            <token id="6" string="be" />
            <token id="7" string="paid" />
            <token id="8" string="more" />
            <token id="9" string="because" />
            <token id="10" string="of" />
            <token id="11" string="the" />
            <token id="12" string="notoriety" />
          </tokens>
        </chunking>
        <chunking id="5" string="thinks he can be paid more because of the notoriety" type="VP">
          <tokens>
            <token id="3" string="thinks" />
            <token id="4" string="he" />
            <token id="5" string="can" />
            <token id="6" string="be" />
            <token id="7" string="paid" />
            <token id="8" string="more" />
            <token id="9" string="because" />
            <token id="10" string="of" />
            <token id="11" string="the" />
            <token id="12" string="notoriety" />
          </tokens>
        </chunking>
        <chunking id="6" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="7" string="he" type="NP">
          <tokens>
            <token id="4" string="he" />
          </tokens>
        </chunking>
        <chunking id="8" string="paid more because of the notoriety" type="VP">
          <tokens>
            <token id="7" string="paid" />
            <token id="8" string="more" />
            <token id="9" string="because" />
            <token id="10" string="of" />
            <token id="11" string="the" />
            <token id="12" string="notoriety" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">thinks</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">thinks</governor>
          <dependent id="2">probably</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">thinks</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="7">paid</governor>
          <dependent id="4">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">paid</governor>
          <dependent id="5">can</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="7">paid</governor>
          <dependent id="6">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">thinks</governor>
          <dependent id="7">paid</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">notoriety</governor>
          <dependent id="8">more</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">notoriety</governor>
          <dependent id="9">because</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="9">because</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">notoriety</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">paid</governor>
          <dependent id="12">notoriety</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="80" has_coreference="true">
      <content>It&amp;apost;s a very complicated issue.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="complicated" lemma="complicated" stem="complic" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="issue" lemma="issue" stem="issu" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBZ 's) (NP (DT a) (ADJP (RB very) (JJ complicated)) (NN issue))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="'s a very complicated issue" type="VP">
          <tokens>
            <token id="2" string="'s" />
            <token id="3" string="a" />
            <token id="4" string="very" />
            <token id="5" string="complicated" />
            <token id="6" string="issue" />
          </tokens>
        </chunking>
        <chunking id="2" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="3" string="very complicated" type="ADJP">
          <tokens>
            <token id="4" string="very" />
            <token id="5" string="complicated" />
          </tokens>
        </chunking>
        <chunking id="4" string="a very complicated issue" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="very" />
            <token id="5" string="complicated" />
            <token id="6" string="issue" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">issue</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">issue</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">issue</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">complicated</governor>
          <dependent id="4">very</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">issue</governor>
          <dependent id="5">complicated</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">issue</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="81" has_coreference="true">
      <content>I don&amp;apost;t know how the public is going to react.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="know" lemma="know" stem="know" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="how" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="public" lemma="public" stem="public" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="react" lemma="react" stem="react" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBP do) (RB n't) (VP (VB know) (SBAR (WHADVP (WRB how)) (S (NP (DT the) (NN public)) (VP (VBZ is) (VP (VBG going) (S (VP (TO to) (VP (VB react)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is going to react" type="VP">
          <tokens>
            <token id="8" string="is" />
            <token id="9" string="going" />
            <token id="10" string="to" />
            <token id="11" string="react" />
          </tokens>
        </chunking>
        <chunking id="2" string="do n't know how the public is going to react" type="VP">
          <tokens>
            <token id="2" string="do" />
            <token id="3" string="n't" />
            <token id="4" string="know" />
            <token id="5" string="how" />
            <token id="6" string="the" />
            <token id="7" string="public" />
            <token id="8" string="is" />
            <token id="9" string="going" />
            <token id="10" string="to" />
            <token id="11" string="react" />
          </tokens>
        </chunking>
        <chunking id="3" string="how the public is going to react" type="SBAR">
          <tokens>
            <token id="5" string="how" />
            <token id="6" string="the" />
            <token id="7" string="public" />
            <token id="8" string="is" />
            <token id="9" string="going" />
            <token id="10" string="to" />
            <token id="11" string="react" />
          </tokens>
        </chunking>
        <chunking id="4" string="to react" type="VP">
          <tokens>
            <token id="10" string="to" />
            <token id="11" string="react" />
          </tokens>
        </chunking>
        <chunking id="5" string="know how the public is going to react" type="VP">
          <tokens>
            <token id="4" string="know" />
            <token id="5" string="how" />
            <token id="6" string="the" />
            <token id="7" string="public" />
            <token id="8" string="is" />
            <token id="9" string="going" />
            <token id="10" string="to" />
            <token id="11" string="react" />
          </tokens>
        </chunking>
        <chunking id="6" string="the public" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="public" />
          </tokens>
        </chunking>
        <chunking id="7" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="8" string="going to react" type="VP">
          <tokens>
            <token id="9" string="going" />
            <token id="10" string="to" />
            <token id="11" string="react" />
          </tokens>
        </chunking>
        <chunking id="9" string="react" type="VP">
          <tokens>
            <token id="11" string="react" />
          </tokens>
        </chunking>
        <chunking id="10" string="how" type="WHADVP">
          <tokens>
            <token id="5" string="how" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">know</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">know</governor>
          <dependent id="2">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">know</governor>
          <dependent id="3">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">know</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">going</governor>
          <dependent id="5">how</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">public</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">going</governor>
          <dependent id="7">public</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">going</governor>
          <dependent id="8">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">know</governor>
          <dependent id="9">going</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">react</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">going</governor>
          <dependent id="11">react</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="82" has_coreference="true">
      <content>Are they going to treat him as someone who has paid his penalty and now he&amp;apost;s clean?</content>
      <tokens>
        <token id="1" string="Are" lemma="be" stem="are" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="treat" lemma="treat" stem="treat" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="someone" lemma="someone" stem="someon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="paid" lemma="pay" stem="paid" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="penalty" lemma="penalty" stem="penalti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="16" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="clean" lemma="clean" stem="clean" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SQ (VBP Are) (NP (PRP they)) (VP (VBG going) (S (VP (TO to) (VP (VB treat) (NP (PRP him)) (PP (IN as) (NP (NN someone))) (SBAR (SBAR (WHNP (WP who)) (S (VP (VBZ has) (VP (VBN paid) (NP (PRP$ his) (NN penalty)))))) (CC and) (SBAR (RB now) (S (NP (PRP he)) (VP (VBZ 's) (ADJP (JJ clean)))))))))) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="his penalty" type="NP">
          <tokens>
            <token id="12" string="his" />
            <token id="13" string="penalty" />
          </tokens>
        </chunking>
        <chunking id="2" string="going to treat him as someone who has paid his penalty and now he 's clean" type="VP">
          <tokens>
            <token id="3" string="going" />
            <token id="4" string="to" />
            <token id="5" string="treat" />
            <token id="6" string="him" />
            <token id="7" string="as" />
            <token id="8" string="someone" />
            <token id="9" string="who" />
            <token id="10" string="has" />
            <token id="11" string="paid" />
            <token id="12" string="his" />
            <token id="13" string="penalty" />
            <token id="14" string="and" />
            <token id="15" string="now" />
            <token id="16" string="he" />
            <token id="17" string="'s" />
            <token id="18" string="clean" />
          </tokens>
        </chunking>
        <chunking id="3" string="him" type="NP">
          <tokens>
            <token id="6" string="him" />
          </tokens>
        </chunking>
        <chunking id="4" string="clean" type="ADJP">
          <tokens>
            <token id="18" string="clean" />
          </tokens>
        </chunking>
        <chunking id="5" string="paid his penalty" type="VP">
          <tokens>
            <token id="11" string="paid" />
            <token id="12" string="his" />
            <token id="13" string="penalty" />
          </tokens>
        </chunking>
        <chunking id="6" string="'s clean" type="VP">
          <tokens>
            <token id="17" string="'s" />
            <token id="18" string="clean" />
          </tokens>
        </chunking>
        <chunking id="7" string="has paid his penalty" type="VP">
          <tokens>
            <token id="10" string="has" />
            <token id="11" string="paid" />
            <token id="12" string="his" />
            <token id="13" string="penalty" />
          </tokens>
        </chunking>
        <chunking id="8" string="they" type="NP">
          <tokens>
            <token id="2" string="they" />
          </tokens>
        </chunking>
        <chunking id="9" string="treat him as someone who has paid his penalty and now he 's clean" type="VP">
          <tokens>
            <token id="5" string="treat" />
            <token id="6" string="him" />
            <token id="7" string="as" />
            <token id="8" string="someone" />
            <token id="9" string="who" />
            <token id="10" string="has" />
            <token id="11" string="paid" />
            <token id="12" string="his" />
            <token id="13" string="penalty" />
            <token id="14" string="and" />
            <token id="15" string="now" />
            <token id="16" string="he" />
            <token id="17" string="'s" />
            <token id="18" string="clean" />
          </tokens>
        </chunking>
        <chunking id="10" string="someone" type="NP">
          <tokens>
            <token id="8" string="someone" />
          </tokens>
        </chunking>
        <chunking id="11" string="now he 's clean" type="SBAR">
          <tokens>
            <token id="15" string="now" />
            <token id="16" string="he" />
            <token id="17" string="'s" />
            <token id="18" string="clean" />
          </tokens>
        </chunking>
        <chunking id="12" string="who has paid his penalty" type="SBAR">
          <tokens>
            <token id="9" string="who" />
            <token id="10" string="has" />
            <token id="11" string="paid" />
            <token id="12" string="his" />
            <token id="13" string="penalty" />
          </tokens>
        </chunking>
        <chunking id="13" string="he" type="NP">
          <tokens>
            <token id="16" string="he" />
          </tokens>
        </chunking>
        <chunking id="14" string="who has paid his penalty and now he 's clean" type="SBAR">
          <tokens>
            <token id="9" string="who" />
            <token id="10" string="has" />
            <token id="11" string="paid" />
            <token id="12" string="his" />
            <token id="13" string="penalty" />
            <token id="14" string="and" />
            <token id="15" string="now" />
            <token id="16" string="he" />
            <token id="17" string="'s" />
            <token id="18" string="clean" />
          </tokens>
        </chunking>
        <chunking id="15" string="to treat him as someone who has paid his penalty and now he 's clean" type="VP">
          <tokens>
            <token id="4" string="to" />
            <token id="5" string="treat" />
            <token id="6" string="him" />
            <token id="7" string="as" />
            <token id="8" string="someone" />
            <token id="9" string="who" />
            <token id="10" string="has" />
            <token id="11" string="paid" />
            <token id="12" string="his" />
            <token id="13" string="penalty" />
            <token id="14" string="and" />
            <token id="15" string="now" />
            <token id="16" string="he" />
            <token id="17" string="'s" />
            <token id="18" string="clean" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="aux">
          <governor id="3">going</governor>
          <dependent id="1">Are</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">going</governor>
          <dependent id="2">they</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">going</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">treat</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">going</governor>
          <dependent id="5">treat</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">treat</governor>
          <dependent id="6">him</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">someone</governor>
          <dependent id="7">as</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">treat</governor>
          <dependent id="8">someone</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">paid</governor>
          <dependent id="9">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">paid</governor>
          <dependent id="10">has</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="5">treat</governor>
          <dependent id="11">paid</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">penalty</governor>
          <dependent id="12">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">paid</governor>
          <dependent id="13">penalty</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">paid</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">clean</governor>
          <dependent id="15">now</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">clean</governor>
          <dependent id="16">he</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="18">clean</governor>
          <dependent id="17">'s</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">paid</governor>
          <dependent id="18">clean</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="15" string="now" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="83" has_coreference="true">
      <content>I don&amp;apost;t know.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="know" lemma="know" stem="know" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBP do) (RB n't) (VP (VB know))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="do n't know" type="VP">
          <tokens>
            <token id="2" string="do" />
            <token id="3" string="n't" />
            <token id="4" string="know" />
          </tokens>
        </chunking>
        <chunking id="2" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="3" string="know" type="VP">
          <tokens>
            <token id="4" string="know" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">know</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">know</governor>
          <dependent id="2">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">know</governor>
          <dependent id="3">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">know</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="84" has_coreference="true">
      <content>These questions have gone through my mind.&amp;quot;</content>
      <tokens>
        <token id="1" string="These" lemma="these" stem="these" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="questions" lemma="question" stem="question" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="gone" lemma="go" stem="gone" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="mind" lemma="mind" stem="mind" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT These) (NNS questions)) (VP (VBP have) (VP (VBN gone) (PP (IN through) (NP (PRP$ my) (NN mind))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="have gone through my mind" type="VP">
          <tokens>
            <token id="3" string="have" />
            <token id="4" string="gone" />
            <token id="5" string="through" />
            <token id="6" string="my" />
            <token id="7" string="mind" />
          </tokens>
        </chunking>
        <chunking id="2" string="my mind" type="NP">
          <tokens>
            <token id="6" string="my" />
            <token id="7" string="mind" />
          </tokens>
        </chunking>
        <chunking id="3" string="gone through my mind" type="VP">
          <tokens>
            <token id="4" string="gone" />
            <token id="5" string="through" />
            <token id="6" string="my" />
            <token id="7" string="mind" />
          </tokens>
        </chunking>
        <chunking id="4" string="These questions" type="NP">
          <tokens>
            <token id="1" string="These" />
            <token id="2" string="questions" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">questions</governor>
          <dependent id="1">These</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">gone</governor>
          <dependent id="2">questions</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">gone</governor>
          <dependent id="3">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">gone</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">mind</governor>
          <dependent id="5">through</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">mind</governor>
          <dependent id="6">my</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">gone</governor>
          <dependent id="7">mind</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="85" has_coreference="true">
      <content>Will Kern, meet director for the Times Indoor Games, hesitates at considering it a moral issue.</content>
      <tokens>
        <token id="1" string="Will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Kern" lemma="Kern" stem="kern" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="meet" lemma="meet" stem="meet" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="director" lemma="director" stem="director" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Times" lemma="Times" stem="time" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="9" string="Indoor" lemma="Indoor" stem="indoor" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="10" string="Games" lemma="Games" stem="game" pos="NNPS" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="hesitates" lemma="hesitate" stem="hesit" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="considering" lemma="consider" stem="consid" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="moral" lemma="moral" stem="moral" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="issue" lemma="issue" stem="issu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (SINV (VP (MD Will)) (NP (NNP Kern))) (, ,) (VP (VBP meet) (SBAR (S (NP (NP (NN director)) (PP (IN for) (NP (DT the) (NNP Times) (NNP Indoor) (NNPS Games)))) (, ,) (VP (VBZ hesitates) (PP (IN at) (S (VP (VBG considering) (NP (PRP it))))))))) (NP (DT a) (JJ moral) (NN issue)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="meet director for the Times Indoor Games , hesitates at considering it" type="VP">
          <tokens>
            <token id="4" string="meet" />
            <token id="5" string="director" />
            <token id="6" string="for" />
            <token id="7" string="the" />
            <token id="8" string="Times" />
            <token id="9" string="Indoor" />
            <token id="10" string="Games" />
            <token id="11" string="," />
            <token id="12" string="hesitates" />
            <token id="13" string="at" />
            <token id="14" string="considering" />
            <token id="15" string="it" />
          </tokens>
        </chunking>
        <chunking id="2" string="director for the Times Indoor Games" type="NP">
          <tokens>
            <token id="5" string="director" />
            <token id="6" string="for" />
            <token id="7" string="the" />
            <token id="8" string="Times" />
            <token id="9" string="Indoor" />
            <token id="10" string="Games" />
          </tokens>
        </chunking>
        <chunking id="3" string="director" type="NP">
          <tokens>
            <token id="5" string="director" />
          </tokens>
        </chunking>
        <chunking id="4" string="the Times Indoor Games" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="Times" />
            <token id="9" string="Indoor" />
            <token id="10" string="Games" />
          </tokens>
        </chunking>
        <chunking id="5" string="hesitates at considering it" type="VP">
          <tokens>
            <token id="12" string="hesitates" />
            <token id="13" string="at" />
            <token id="14" string="considering" />
            <token id="15" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="a moral issue" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="moral" />
            <token id="18" string="issue" />
          </tokens>
        </chunking>
        <chunking id="7" string="Kern" type="NP">
          <tokens>
            <token id="2" string="Kern" />
          </tokens>
        </chunking>
        <chunking id="8" string="director for the Times Indoor Games , hesitates at considering it" type="SBAR">
          <tokens>
            <token id="5" string="director" />
            <token id="6" string="for" />
            <token id="7" string="the" />
            <token id="8" string="Times" />
            <token id="9" string="Indoor" />
            <token id="10" string="Games" />
            <token id="11" string="," />
            <token id="12" string="hesitates" />
            <token id="13" string="at" />
            <token id="14" string="considering" />
            <token id="15" string="it" />
          </tokens>
        </chunking>
        <chunking id="9" string="Will" type="VP">
          <tokens>
            <token id="1" string="Will" />
          </tokens>
        </chunking>
        <chunking id="10" string="considering it" type="VP">
          <tokens>
            <token id="14" string="considering" />
            <token id="15" string="it" />
          </tokens>
        </chunking>
        <chunking id="11" string="it" type="NP">
          <tokens>
            <token id="15" string="it" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="dep">
          <governor id="4">meet</governor>
          <dependent id="1">Will</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="1">Will</governor>
          <dependent id="2">Kern</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">meet</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">hesitates</governor>
          <dependent id="5">director</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Games</governor>
          <dependent id="6">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">Games</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Games</governor>
          <dependent id="8">Times</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Games</governor>
          <dependent id="9">Indoor</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">director</governor>
          <dependent id="10">Games</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">meet</governor>
          <dependent id="12">hesitates</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">considering</governor>
          <dependent id="13">at</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">hesitates</governor>
          <dependent id="14">considering</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">considering</governor>
          <dependent id="15">it</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">issue</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">issue</governor>
          <dependent id="17">moral</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">meet</governor>
          <dependent id="18">issue</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Times Indoor Games" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="8" string="Times" />
            <token id="9" string="Indoor" />
            <token id="10" string="Games" />
          </tokens>
        </entity>
        <entity id="2" string="Will Kern" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Will" />
            <token id="2" string="Kern" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="86" has_coreference="true">
      <content>&amp;quot;It&amp;apost;s kind of perplexing, isn&amp;apost;t it?</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="kind" lemma="kind" stem="kind" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="perplexing" lemma="perplexing" stem="perplex" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP It)) (VP (VBZ 's) (ADJP (ADVP (NN kind) (IN of)) (JJ perplexing)))) (, ,) (VP (VBZ is) (RB n't) (NP (PRP it))) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="kind of perplexing" type="ADJP">
          <tokens>
            <token id="4" string="kind" />
            <token id="5" string="of" />
            <token id="6" string="perplexing" />
          </tokens>
        </chunking>
        <chunking id="2" string="is n't it" type="VP">
          <tokens>
            <token id="8" string="is" />
            <token id="9" string="n't" />
            <token id="10" string="it" />
          </tokens>
        </chunking>
        <chunking id="3" string="'s kind of perplexing" type="VP">
          <tokens>
            <token id="3" string="'s" />
            <token id="4" string="kind" />
            <token id="5" string="of" />
            <token id="6" string="perplexing" />
          </tokens>
        </chunking>
        <chunking id="4" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="10" string="it" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">perplexing</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">perplexing</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">perplexing</governor>
          <dependent id="4">kind</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="4">kind</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">it</governor>
          <dependent id="6">perplexing</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="10">it</governor>
          <dependent id="8">is</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="10">it</governor>
          <dependent id="9">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">it</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="87" has_coreference="false">
      <content>,&amp;quot; Kern said.</content>
      <tokens>
        <token id="1" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Kern" lemma="Kern" stem="kern" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="4" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (, ,) ('' '') (NNP Kern)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="said" type="VP">
          <tokens>
            <token id="4" string="said" />
          </tokens>
        </chunking>
        <chunking id="2" string=", '' Kern" type="NP">
          <tokens>
            <token id="1" string="," />
            <token id="2" string="&quot;" />
            <token id="3" string="Kern" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">said</governor>
          <dependent id="3">Kern</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Kern" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Kern" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="88" has_coreference="true">
      <content>&amp;quot;I&amp;apost;m not God.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'m" lemma="be" stem="'m" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="God" lemma="God" stem="god" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (VBP 'm) (RB not) (NP (NNP God))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="'m not God" type="VP">
          <tokens>
            <token id="3" string="'m" />
            <token id="4" string="not" />
            <token id="5" string="God" />
          </tokens>
        </chunking>
        <chunking id="2" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="3" string="God" type="NP">
          <tokens>
            <token id="5" string="God" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">God</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">God</governor>
          <dependent id="3">'m</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">God</governor>
          <dependent id="4">not</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">God</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="89" has_coreference="true">
      <content>I can&amp;apost;t say that it&amp;apost;s wrong, especially when deep down I know Johnson&amp;apost;s not the only one who&amp;apost;s ever taken drugs.&amp;quot;</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="ca" lemma="can" stem="ca" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="say" lemma="say" stem="sai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="wrong" lemma="wrong" stem="wrong" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="especially" lemma="especially" stem="especi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="deep" lemma="deep" stem="deep" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="down" lemma="down" stem="down" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="know" lemma="know" stem="know" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="17" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="only" lemma="only" stem="onli" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="one" lemma="one" stem="on" pos="NN" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="22" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="ever" lemma="ever" stem="ever" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="taken" lemma="take" stem="taken" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="drugs" lemma="drug" stem="drug" pos="NNS" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="true" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (MD ca) (RB n't) (VP (VB say) (SBAR (IN that) (S (NP (PRP it)) (VP (VBZ 's) (ADJP (JJ wrong)) (, ,) (ADVP (RB especially)) (SBAR (WHADVP (WRB when)) (S (ADVP (RB deep) (IN down)) (NP (PRP I)) (VP (VBP know) (NP (NNP Johnson) (POS 's)) (PP (RB not) (NP (NP (DT the) (JJ only) (NN one)) (SBAR (WHNP (WP who)) (S (VP (VBZ 's) (ADVP (RB ever)) (VP (VBN taken) (NP (NNS drugs)))))))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="who 's ever taken drugs" type="SBAR">
          <tokens>
            <token id="22" string="who" />
            <token id="23" string="'s" />
            <token id="24" string="ever" />
            <token id="25" string="taken" />
            <token id="26" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="2" string="the only one" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="only" />
            <token id="21" string="one" />
          </tokens>
        </chunking>
        <chunking id="3" string="drugs" type="NP">
          <tokens>
            <token id="26" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="4" string="that it 's wrong , especially when deep down I know Johnson 's not the only one who 's ever taken drugs" type="SBAR">
          <tokens>
            <token id="5" string="that" />
            <token id="6" string="it" />
            <token id="7" string="'s" />
            <token id="8" string="wrong" />
            <token id="9" string="," />
            <token id="10" string="especially" />
            <token id="11" string="when" />
            <token id="12" string="deep" />
            <token id="13" string="down" />
            <token id="14" string="I" />
            <token id="15" string="know" />
            <token id="16" string="Johnson" />
            <token id="17" string="'s" />
            <token id="18" string="not" />
            <token id="19" string="the" />
            <token id="20" string="only" />
            <token id="21" string="one" />
            <token id="22" string="who" />
            <token id="23" string="'s" />
            <token id="24" string="ever" />
            <token id="25" string="taken" />
            <token id="26" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="5" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="say that it 's wrong , especially when deep down I know Johnson 's not the only one who 's ever taken drugs" type="VP">
          <tokens>
            <token id="4" string="say" />
            <token id="5" string="that" />
            <token id="6" string="it" />
            <token id="7" string="'s" />
            <token id="8" string="wrong" />
            <token id="9" string="," />
            <token id="10" string="especially" />
            <token id="11" string="when" />
            <token id="12" string="deep" />
            <token id="13" string="down" />
            <token id="14" string="I" />
            <token id="15" string="know" />
            <token id="16" string="Johnson" />
            <token id="17" string="'s" />
            <token id="18" string="not" />
            <token id="19" string="the" />
            <token id="20" string="only" />
            <token id="21" string="one" />
            <token id="22" string="who" />
            <token id="23" string="'s" />
            <token id="24" string="ever" />
            <token id="25" string="taken" />
            <token id="26" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="6" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="ca n't say that it 's wrong , especially when deep down I know Johnson 's not the only one who 's ever taken drugs" type="VP">
          <tokens>
            <token id="2" string="ca" />
            <token id="3" string="n't" />
            <token id="4" string="say" />
            <token id="5" string="that" />
            <token id="6" string="it" />
            <token id="7" string="'s" />
            <token id="8" string="wrong" />
            <token id="9" string="," />
            <token id="10" string="especially" />
            <token id="11" string="when" />
            <token id="12" string="deep" />
            <token id="13" string="down" />
            <token id="14" string="I" />
            <token id="15" string="know" />
            <token id="16" string="Johnson" />
            <token id="17" string="'s" />
            <token id="18" string="not" />
            <token id="19" string="the" />
            <token id="20" string="only" />
            <token id="21" string="one" />
            <token id="22" string="who" />
            <token id="23" string="'s" />
            <token id="24" string="ever" />
            <token id="25" string="taken" />
            <token id="26" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="9" string="wrong" type="ADJP">
          <tokens>
            <token id="8" string="wrong" />
          </tokens>
        </chunking>
        <chunking id="10" string="when" type="WHADVP">
          <tokens>
            <token id="11" string="when" />
          </tokens>
        </chunking>
        <chunking id="11" string="know Johnson 's not the only one who 's ever taken drugs" type="VP">
          <tokens>
            <token id="15" string="know" />
            <token id="16" string="Johnson" />
            <token id="17" string="'s" />
            <token id="18" string="not" />
            <token id="19" string="the" />
            <token id="20" string="only" />
            <token id="21" string="one" />
            <token id="22" string="who" />
            <token id="23" string="'s" />
            <token id="24" string="ever" />
            <token id="25" string="taken" />
            <token id="26" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="12" string="'s ever taken drugs" type="VP">
          <tokens>
            <token id="23" string="'s" />
            <token id="24" string="ever" />
            <token id="25" string="taken" />
            <token id="26" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="13" string="when deep down I know Johnson 's not the only one who 's ever taken drugs" type="SBAR">
          <tokens>
            <token id="11" string="when" />
            <token id="12" string="deep" />
            <token id="13" string="down" />
            <token id="14" string="I" />
            <token id="15" string="know" />
            <token id="16" string="Johnson" />
            <token id="17" string="'s" />
            <token id="18" string="not" />
            <token id="19" string="the" />
            <token id="20" string="only" />
            <token id="21" string="one" />
            <token id="22" string="who" />
            <token id="23" string="'s" />
            <token id="24" string="ever" />
            <token id="25" string="taken" />
            <token id="26" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="14" string="taken drugs" type="VP">
          <tokens>
            <token id="25" string="taken" />
            <token id="26" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="15" string="Johnson 's" type="NP">
          <tokens>
            <token id="16" string="Johnson" />
            <token id="17" string="'s" />
          </tokens>
        </chunking>
        <chunking id="16" string="'s wrong , especially when deep down I know Johnson 's not the only one who 's ever taken drugs" type="VP">
          <tokens>
            <token id="7" string="'s" />
            <token id="8" string="wrong" />
            <token id="9" string="," />
            <token id="10" string="especially" />
            <token id="11" string="when" />
            <token id="12" string="deep" />
            <token id="13" string="down" />
            <token id="14" string="I" />
            <token id="15" string="know" />
            <token id="16" string="Johnson" />
            <token id="17" string="'s" />
            <token id="18" string="not" />
            <token id="19" string="the" />
            <token id="20" string="only" />
            <token id="21" string="one" />
            <token id="22" string="who" />
            <token id="23" string="'s" />
            <token id="24" string="ever" />
            <token id="25" string="taken" />
            <token id="26" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="17" string="the only one who 's ever taken drugs" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="only" />
            <token id="21" string="one" />
            <token id="22" string="who" />
            <token id="23" string="'s" />
            <token id="24" string="ever" />
            <token id="25" string="taken" />
            <token id="26" string="drugs" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">say</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">say</governor>
          <dependent id="2">ca</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">say</governor>
          <dependent id="3">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">say</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">wrong</governor>
          <dependent id="5">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">wrong</governor>
          <dependent id="6">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">wrong</governor>
          <dependent id="7">'s</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">say</governor>
          <dependent id="8">wrong</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">wrong</governor>
          <dependent id="10">especially</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">know</governor>
          <dependent id="11">when</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">know</governor>
          <dependent id="12">deep</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">deep</governor>
          <dependent id="13">down</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">know</governor>
          <dependent id="14">I</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="8">wrong</governor>
          <dependent id="15">know</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">know</governor>
          <dependent id="16">Johnson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">Johnson</governor>
          <dependent id="17">'s</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="21">one</governor>
          <dependent id="18">not</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">one</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">one</governor>
          <dependent id="20">only</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">know</governor>
          <dependent id="21">one</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="25">taken</governor>
          <dependent id="22">who</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="25">taken</governor>
          <dependent id="23">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="25">taken</governor>
          <dependent id="24">ever</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="21">one</governor>
          <dependent id="25">taken</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">taken</governor>
          <dependent id="26">drugs</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="16" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="21" string="one" />
          </tokens>
        </entity>
        <entity id="3" string="drugs" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="26" string="drugs" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="90" has_coreference="true">
      <content>One thing that may not happen is a much-discussed lucrative match race between Johnson and Lewis.</content>
      <tokens>
        <token id="1" string="One" lemma="one" stem="one" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="2" string="thing" lemma="thing" stem="thing" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="happen" lemma="happen" stem="happen" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="much-discussed" lemma="much-discussed" stem="much-discuss" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="lucrative" lemma="lucrative" stem="lucr" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="match" lemma="match" stem="match" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="race" lemma="race" stem="race" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="between" lemma="between" stem="between" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="Lewis" lemma="Lewis" stem="lewi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (CD One) (NN thing) (SBAR (WHNP (WDT that)) (S (VP (MD may) (RB not) (VP (VB happen)))))) (VP (VBZ is) (NP (NP (DT a) (JJ much-discussed) (JJ lucrative) (NN match) (NN race)) (PP (IN between) (NP (NNP Johnson) (CC and) (NNP Lewis))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a much-discussed lucrative match race" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="much-discussed" />
            <token id="10" string="lucrative" />
            <token id="11" string="match" />
            <token id="12" string="race" />
          </tokens>
        </chunking>
        <chunking id="2" string="happen" type="VP">
          <tokens>
            <token id="6" string="happen" />
          </tokens>
        </chunking>
        <chunking id="3" string="Johnson and Lewis" type="NP">
          <tokens>
            <token id="14" string="Johnson" />
            <token id="15" string="and" />
            <token id="16" string="Lewis" />
          </tokens>
        </chunking>
        <chunking id="4" string="One thing that may not happen" type="NP">
          <tokens>
            <token id="1" string="One" />
            <token id="2" string="thing" />
            <token id="3" string="that" />
            <token id="4" string="may" />
            <token id="5" string="not" />
            <token id="6" string="happen" />
          </tokens>
        </chunking>
        <chunking id="5" string="a much-discussed lucrative match race between Johnson and Lewis" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="much-discussed" />
            <token id="10" string="lucrative" />
            <token id="11" string="match" />
            <token id="12" string="race" />
            <token id="13" string="between" />
            <token id="14" string="Johnson" />
            <token id="15" string="and" />
            <token id="16" string="Lewis" />
          </tokens>
        </chunking>
        <chunking id="6" string="may not happen" type="VP">
          <tokens>
            <token id="4" string="may" />
            <token id="5" string="not" />
            <token id="6" string="happen" />
          </tokens>
        </chunking>
        <chunking id="7" string="is a much-discussed lucrative match race between Johnson and Lewis" type="VP">
          <tokens>
            <token id="7" string="is" />
            <token id="8" string="a" />
            <token id="9" string="much-discussed" />
            <token id="10" string="lucrative" />
            <token id="11" string="match" />
            <token id="12" string="race" />
            <token id="13" string="between" />
            <token id="14" string="Johnson" />
            <token id="15" string="and" />
            <token id="16" string="Lewis" />
          </tokens>
        </chunking>
        <chunking id="8" string="that may not happen" type="SBAR">
          <tokens>
            <token id="3" string="that" />
            <token id="4" string="may" />
            <token id="5" string="not" />
            <token id="6" string="happen" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nummod">
          <governor id="2">thing</governor>
          <dependent id="1">One</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">race</governor>
          <dependent id="2">thing</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">happen</governor>
          <dependent id="3">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">happen</governor>
          <dependent id="4">may</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">happen</governor>
          <dependent id="5">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">thing</governor>
          <dependent id="6">happen</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">race</governor>
          <dependent id="7">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">race</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">race</governor>
          <dependent id="9">much-discussed</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">race</governor>
          <dependent id="10">lucrative</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">race</governor>
          <dependent id="11">match</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">race</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Johnson</governor>
          <dependent id="13">between</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">race</governor>
          <dependent id="14">Johnson</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">Johnson</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">Johnson</governor>
          <dependent id="16">Lewis</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="One" type="NUMBER" score="0.0">
          <tokens>
            <token id="1" string="One" />
          </tokens>
        </entity>
        <entity id="3" string="Lewis" type="PERSON" score="0.0">
          <tokens>
            <token id="16" string="Lewis" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="91" has_coreference="true">
      <content>&amp;quot;I will never allow it to happen,&amp;quot; Primo Nebiolo, president of the International Amateur Atheltic Federation, said Sunday.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="allow" lemma="allow" stem="allow" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="happen" lemma="happen" stem="happen" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Primo" lemma="Primo" stem="primo" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="12" string="Nebiolo" lemma="Nebiolo" stem="nebiolo" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="president" lemma="president" stem="presid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="International" lemma="International" stem="internat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="18" string="Amateur" lemma="amateur" stem="amateur" pos="JJ" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="19" string="Atheltic" lemma="Atheltic" stem="atheltic" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="20" string="Federation" lemma="Federation" stem="feder" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="Sunday" lemma="Sunday" stem="sundai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP I)) (VP (MD will) (ADVP (RB never)) (VP (VB allow) (S (NP (PRP it)) (VP (TO to) (VP (VB happen))))))) (, ,) ('' '') (NP (NP (NNP Primo) (NNP Nebiolo)) (, ,) (NP (NP (NN president)) (PP (IN of) (NP (DT the) (NNP International) (JJ Amateur) (NNP Atheltic) (NNP Federation)))) (, ,)) (VP (VBD said) (NP-TMP (NNP Sunday))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="president" type="NP">
          <tokens>
            <token id="14" string="president" />
          </tokens>
        </chunking>
        <chunking id="2" string="happen" type="VP">
          <tokens>
            <token id="8" string="happen" />
          </tokens>
        </chunking>
        <chunking id="3" string="president of the International Amateur Atheltic Federation" type="NP">
          <tokens>
            <token id="14" string="president" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="International" />
            <token id="18" string="Amateur" />
            <token id="19" string="Atheltic" />
            <token id="20" string="Federation" />
          </tokens>
        </chunking>
        <chunking id="4" string="said Sunday" type="VP">
          <tokens>
            <token id="22" string="said" />
            <token id="23" string="Sunday" />
          </tokens>
        </chunking>
        <chunking id="5" string="the International Amateur Atheltic Federation" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="International" />
            <token id="18" string="Amateur" />
            <token id="19" string="Atheltic" />
            <token id="20" string="Federation" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="to happen" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="happen" />
          </tokens>
        </chunking>
        <chunking id="8" string="allow it to happen" type="VP">
          <tokens>
            <token id="5" string="allow" />
            <token id="6" string="it" />
            <token id="7" string="to" />
            <token id="8" string="happen" />
          </tokens>
        </chunking>
        <chunking id="9" string="it" type="NP">
          <tokens>
            <token id="6" string="it" />
          </tokens>
        </chunking>
        <chunking id="10" string="Primo Nebiolo" type="NP">
          <tokens>
            <token id="11" string="Primo" />
            <token id="12" string="Nebiolo" />
          </tokens>
        </chunking>
        <chunking id="11" string="will never allow it to happen" type="VP">
          <tokens>
            <token id="3" string="will" />
            <token id="4" string="never" />
            <token id="5" string="allow" />
            <token id="6" string="it" />
            <token id="7" string="to" />
            <token id="8" string="happen" />
          </tokens>
        </chunking>
        <chunking id="12" string="Primo Nebiolo , president of the International Amateur Atheltic Federation ," type="NP">
          <tokens>
            <token id="11" string="Primo" />
            <token id="12" string="Nebiolo" />
            <token id="13" string="," />
            <token id="14" string="president" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="International" />
            <token id="18" string="Amateur" />
            <token id="19" string="Atheltic" />
            <token id="20" string="Federation" />
            <token id="21" string="," />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">allow</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">allow</governor>
          <dependent id="3">will</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">allow</governor>
          <dependent id="4">never</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="22">said</governor>
          <dependent id="5">allow</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">allow</governor>
          <dependent id="6">it</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">happen</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">allow</governor>
          <dependent id="8">happen</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Nebiolo</governor>
          <dependent id="11">Primo</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">said</governor>
          <dependent id="12">Nebiolo</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="12">Nebiolo</governor>
          <dependent id="14">president</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">Federation</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">Federation</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Federation</governor>
          <dependent id="17">International</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">Federation</governor>
          <dependent id="18">Amateur</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Federation</governor>
          <dependent id="19">Atheltic</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">president</governor>
          <dependent id="20">Federation</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="22">said</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="22">said</governor>
          <dependent id="23">Sunday</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Sunday" type="DATE" score="0.0">
          <tokens>
            <token id="23" string="Sunday" />
          </tokens>
        </entity>
        <entity id="2" string="Primo Nebiolo" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Primo" />
            <token id="12" string="Nebiolo" />
          </tokens>
        </entity>
        <entity id="3" string="International Amateur Atheltic Federation" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="17" string="International" />
            <token id="18" string="Amateur" />
            <token id="19" string="Atheltic" />
            <token id="20" string="Federation" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="92" has_coreference="true">
      <content>&amp;quot;We do not allow two-horse races.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="allow" lemma="allow" stem="allow" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="two-horse" lemma="two-horse" stem="two-hors" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="races" lemma="race" stem="race" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP We)) (VP (VBP do) (RB not) (VP (VB allow) (NP (JJ two-horse) (NNS races)))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="allow two-horse races" type="VP">
          <tokens>
            <token id="5" string="allow" />
            <token id="6" string="two-horse" />
            <token id="7" string="races" />
          </tokens>
        </chunking>
        <chunking id="2" string="two-horse races" type="NP">
          <tokens>
            <token id="6" string="two-horse" />
            <token id="7" string="races" />
          </tokens>
        </chunking>
        <chunking id="3" string="We" type="NP">
          <tokens>
            <token id="2" string="We" />
          </tokens>
        </chunking>
        <chunking id="4" string="do not allow two-horse races" type="VP">
          <tokens>
            <token id="3" string="do" />
            <token id="4" string="not" />
            <token id="5" string="allow" />
            <token id="6" string="two-horse" />
            <token id="7" string="races" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">allow</governor>
          <dependent id="2">We</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">allow</governor>
          <dependent id="3">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">allow</governor>
          <dependent id="4">not</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">allow</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">races</governor>
          <dependent id="6">two-horse</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">allow</governor>
          <dependent id="7">races</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="93" has_coreference="true">
      <content>A NEW CAST Johnson, 28, has passed at least four drug tests during his suspension.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="NEW" lemma="NEW" stem="new" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="CAST" lemma="CAST" stem="cast" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="28" lemma="28" stem="28" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="passed" lemma="pass" stem="pass" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="least" lemma="least" stem="least" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="four" lemma="four" stem="four" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="13" string="drug" lemma="drug" stem="drug" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="tests" lemma="test" stem="test" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="during" lemma="during" stem="dure" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="suspension" lemma="suspension" stem="suspens" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT A) (NNP NEW) (NNP CAST) (NNP Johnson)) (, ,) (NP (CD 28)) (, ,)) (VP (VBZ has) (VP (VBN passed) (NP (QP (IN at) (JJS least) (CD four)) (NN drug) (NNS tests)) (PP (IN during) (NP (PRP$ his) (NN suspension))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="A NEW CAST Johnson , 28 ," type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="NEW" />
            <token id="3" string="CAST" />
            <token id="4" string="Johnson" />
            <token id="5" string="," />
            <token id="6" string="28" />
            <token id="7" string="," />
          </tokens>
        </chunking>
        <chunking id="2" string="at least four drug tests" type="NP">
          <tokens>
            <token id="10" string="at" />
            <token id="11" string="least" />
            <token id="12" string="four" />
            <token id="13" string="drug" />
            <token id="14" string="tests" />
          </tokens>
        </chunking>
        <chunking id="3" string="his suspension" type="NP">
          <tokens>
            <token id="16" string="his" />
            <token id="17" string="suspension" />
          </tokens>
        </chunking>
        <chunking id="4" string="28" type="NP">
          <tokens>
            <token id="6" string="28" />
          </tokens>
        </chunking>
        <chunking id="5" string="passed at least four drug tests during his suspension" type="VP">
          <tokens>
            <token id="9" string="passed" />
            <token id="10" string="at" />
            <token id="11" string="least" />
            <token id="12" string="four" />
            <token id="13" string="drug" />
            <token id="14" string="tests" />
            <token id="15" string="during" />
            <token id="16" string="his" />
            <token id="17" string="suspension" />
          </tokens>
        </chunking>
        <chunking id="6" string="has passed at least four drug tests during his suspension" type="VP">
          <tokens>
            <token id="8" string="has" />
            <token id="9" string="passed" />
            <token id="10" string="at" />
            <token id="11" string="least" />
            <token id="12" string="four" />
            <token id="13" string="drug" />
            <token id="14" string="tests" />
            <token id="15" string="during" />
            <token id="16" string="his" />
            <token id="17" string="suspension" />
          </tokens>
        </chunking>
        <chunking id="7" string="A NEW CAST Johnson" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="NEW" />
            <token id="3" string="CAST" />
            <token id="4" string="Johnson" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">Johnson</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Johnson</governor>
          <dependent id="2">NEW</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Johnson</governor>
          <dependent id="3">CAST</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">passed</governor>
          <dependent id="4">Johnson</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">Johnson</governor>
          <dependent id="6">28</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">passed</governor>
          <dependent id="8">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">passed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">least</governor>
          <dependent id="10">at</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="12">four</governor>
          <dependent id="11">least</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="14">tests</governor>
          <dependent id="12">four</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">tests</governor>
          <dependent id="13">drug</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">passed</governor>
          <dependent id="14">tests</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">suspension</governor>
          <dependent id="15">during</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="17">suspension</governor>
          <dependent id="16">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">passed</governor>
          <dependent id="17">suspension</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="28" type="NUMBER" score="0.0">
          <tokens>
            <token id="6" string="28" />
          </tokens>
        </entity>
        <entity id="3" string="four" type="NUMBER" score="0.0">
          <tokens>
            <token id="12" string="four" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="94" has_coreference="true">
      <content>He has been an outspoken opponent of drug use and has spent the last year speaking to children, warning them against performance-enhancing drugs.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="outspoken" lemma="outspoken" stem="outspoken" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="opponent" lemma="opponent" stem="oppon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="drug" lemma="drug" stem="drug" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="use" lemma="use" stem="us" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="spent" lemma="spend" stem="spent" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="14" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="15" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="16" string="speaking" lemma="speak" stem="speak" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="warning" lemma="warn" stem="warn" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="performance-enhancing" lemma="performance-enhancing" stem="performance-enhanc" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="drugs" lemma="drug" stem="drug" pos="NNS" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VP (VBZ has) (VP (VBN been) (NP (NP (DT an) (JJ outspoken) (NN opponent)) (PP (IN of) (NP (NN drug) (NN use)))))) (CC and) (VP (VBZ has) (VP (VBN spent) (NP (NP (DT the) (JJ last) (NN year)) (VP (VBG speaking) (PP (TO to) (NP (NNS children))) (, ,) (S (VP (VBG warning) (NP (PRP them)) (PP (IN against) (NP (JJ performance-enhancing) (NNS drugs)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the last year" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="last" />
            <token id="15" string="year" />
          </tokens>
        </chunking>
        <chunking id="2" string="has been an outspoken opponent of drug use and has spent the last year speaking to children , warning them against performance-enhancing drugs" type="VP">
          <tokens>
            <token id="2" string="has" />
            <token id="3" string="been" />
            <token id="4" string="an" />
            <token id="5" string="outspoken" />
            <token id="6" string="opponent" />
            <token id="7" string="of" />
            <token id="8" string="drug" />
            <token id="9" string="use" />
            <token id="10" string="and" />
            <token id="11" string="has" />
            <token id="12" string="spent" />
            <token id="13" string="the" />
            <token id="14" string="last" />
            <token id="15" string="year" />
            <token id="16" string="speaking" />
            <token id="17" string="to" />
            <token id="18" string="children" />
            <token id="19" string="," />
            <token id="20" string="warning" />
            <token id="21" string="them" />
            <token id="22" string="against" />
            <token id="23" string="performance-enhancing" />
            <token id="24" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="3" string="an outspoken opponent" type="NP">
          <tokens>
            <token id="4" string="an" />
            <token id="5" string="outspoken" />
            <token id="6" string="opponent" />
          </tokens>
        </chunking>
        <chunking id="4" string="them" type="NP">
          <tokens>
            <token id="21" string="them" />
          </tokens>
        </chunking>
        <chunking id="5" string="been an outspoken opponent of drug use" type="VP">
          <tokens>
            <token id="3" string="been" />
            <token id="4" string="an" />
            <token id="5" string="outspoken" />
            <token id="6" string="opponent" />
            <token id="7" string="of" />
            <token id="8" string="drug" />
            <token id="9" string="use" />
          </tokens>
        </chunking>
        <chunking id="6" string="speaking to children , warning them against performance-enhancing drugs" type="VP">
          <tokens>
            <token id="16" string="speaking" />
            <token id="17" string="to" />
            <token id="18" string="children" />
            <token id="19" string="," />
            <token id="20" string="warning" />
            <token id="21" string="them" />
            <token id="22" string="against" />
            <token id="23" string="performance-enhancing" />
            <token id="24" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="7" string="spent the last year speaking to children , warning them against performance-enhancing drugs" type="VP">
          <tokens>
            <token id="12" string="spent" />
            <token id="13" string="the" />
            <token id="14" string="last" />
            <token id="15" string="year" />
            <token id="16" string="speaking" />
            <token id="17" string="to" />
            <token id="18" string="children" />
            <token id="19" string="," />
            <token id="20" string="warning" />
            <token id="21" string="them" />
            <token id="22" string="against" />
            <token id="23" string="performance-enhancing" />
            <token id="24" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="8" string="children" type="NP">
          <tokens>
            <token id="18" string="children" />
          </tokens>
        </chunking>
        <chunking id="9" string="has been an outspoken opponent of drug use" type="VP">
          <tokens>
            <token id="2" string="has" />
            <token id="3" string="been" />
            <token id="4" string="an" />
            <token id="5" string="outspoken" />
            <token id="6" string="opponent" />
            <token id="7" string="of" />
            <token id="8" string="drug" />
            <token id="9" string="use" />
          </tokens>
        </chunking>
        <chunking id="10" string="drug use" type="NP">
          <tokens>
            <token id="8" string="drug" />
            <token id="9" string="use" />
          </tokens>
        </chunking>
        <chunking id="11" string="performance-enhancing drugs" type="NP">
          <tokens>
            <token id="23" string="performance-enhancing" />
            <token id="24" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="12" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="13" string="warning them against performance-enhancing drugs" type="VP">
          <tokens>
            <token id="20" string="warning" />
            <token id="21" string="them" />
            <token id="22" string="against" />
            <token id="23" string="performance-enhancing" />
            <token id="24" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="14" string="an outspoken opponent of drug use" type="NP">
          <tokens>
            <token id="4" string="an" />
            <token id="5" string="outspoken" />
            <token id="6" string="opponent" />
            <token id="7" string="of" />
            <token id="8" string="drug" />
            <token id="9" string="use" />
          </tokens>
        </chunking>
        <chunking id="15" string="the last year speaking to children , warning them against performance-enhancing drugs" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="last" />
            <token id="15" string="year" />
            <token id="16" string="speaking" />
            <token id="17" string="to" />
            <token id="18" string="children" />
            <token id="19" string="," />
            <token id="20" string="warning" />
            <token id="21" string="them" />
            <token id="22" string="against" />
            <token id="23" string="performance-enhancing" />
            <token id="24" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="16" string="has spent the last year speaking to children , warning them against performance-enhancing drugs" type="VP">
          <tokens>
            <token id="11" string="has" />
            <token id="12" string="spent" />
            <token id="13" string="the" />
            <token id="14" string="last" />
            <token id="15" string="year" />
            <token id="16" string="speaking" />
            <token id="17" string="to" />
            <token id="18" string="children" />
            <token id="19" string="," />
            <token id="20" string="warning" />
            <token id="21" string="them" />
            <token id="22" string="against" />
            <token id="23" string="performance-enhancing" />
            <token id="24" string="drugs" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">opponent</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">opponent</governor>
          <dependent id="2">has</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">opponent</governor>
          <dependent id="3">been</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">opponent</governor>
          <dependent id="4">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">opponent</governor>
          <dependent id="5">outspoken</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">opponent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">use</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">use</governor>
          <dependent id="8">drug</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">opponent</governor>
          <dependent id="9">use</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">opponent</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">spent</governor>
          <dependent id="11">has</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">opponent</governor>
          <dependent id="12">spent</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">year</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">year</governor>
          <dependent id="14">last</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">spent</governor>
          <dependent id="15">year</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="15">year</governor>
          <dependent id="16">speaking</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">children</governor>
          <dependent id="17">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">speaking</governor>
          <dependent id="18">children</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="16">speaking</governor>
          <dependent id="20">warning</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">warning</governor>
          <dependent id="21">them</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">drugs</governor>
          <dependent id="22">against</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">drugs</governor>
          <dependent id="23">performance-enhancing</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">warning</governor>
          <dependent id="24">drugs</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="drugs" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="24" string="drugs" />
          </tokens>
        </entity>
        <entity id="2" string="the last year" type="DATE" score="0.0">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="last" />
            <token id="15" string="year" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="95" has_coreference="true">
      <content>Many of those around Johnson have changed, too.</content>
      <tokens>
        <token id="1" string="Many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="around" lemma="around" stem="around" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="6" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="changed" lemma="change" stem="chang" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="too" lemma="too" stem="too" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (JJ Many)) (PP (IN of) (NP (NP (DT those)) (PP (IN around) (NP (NNP Johnson)))))) (VP (VBP have) (VP (VBN changed) (, ,) (ADVP (RB too)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="have changed , too" type="VP">
          <tokens>
            <token id="6" string="have" />
            <token id="7" string="changed" />
            <token id="8" string="," />
            <token id="9" string="too" />
          </tokens>
        </chunking>
        <chunking id="2" string="changed , too" type="VP">
          <tokens>
            <token id="7" string="changed" />
            <token id="8" string="," />
            <token id="9" string="too" />
          </tokens>
        </chunking>
        <chunking id="3" string="Johnson" type="NP">
          <tokens>
            <token id="5" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="4" string="Many" type="NP">
          <tokens>
            <token id="1" string="Many" />
          </tokens>
        </chunking>
        <chunking id="5" string="Many of those around Johnson" type="NP">
          <tokens>
            <token id="1" string="Many" />
            <token id="2" string="of" />
            <token id="3" string="those" />
            <token id="4" string="around" />
            <token id="5" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="6" string="those around Johnson" type="NP">
          <tokens>
            <token id="3" string="those" />
            <token id="4" string="around" />
            <token id="5" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="7" string="those" type="NP">
          <tokens>
            <token id="3" string="those" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="7">changed</governor>
          <dependent id="1">Many</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">those</governor>
          <dependent id="2">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Many</governor>
          <dependent id="3">those</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">Johnson</governor>
          <dependent id="4">around</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">those</governor>
          <dependent id="5">Johnson</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">changed</governor>
          <dependent id="6">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">changed</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">changed</governor>
          <dependent id="9">too</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Johnson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="96" has_coreference="true">
      <content>Francis is no longer his coach, having been replaced by Loren Seagrave, former women&amp;apost;s coach at Louisiana State University.</content>
      <tokens>
        <token id="1" string="Francis" lemma="Francis" stem="franci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="no" lemma="no" stem="no" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="longer" lemma="longer" stem="longer" pos="RBR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="coach" lemma="coach" stem="coach" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="having" lemma="have" stem="have" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="replaced" lemma="replace" stem="replac" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Loren" lemma="Loren" stem="loren" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="13" string="Seagrave" lemma="Seagrave" stem="seagrav" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="former" lemma="former" stem="former" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="women" lemma="woman" stem="women" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="coach" lemma="coach" stem="coach" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Louisiana" lemma="Louisiana" stem="louisiana" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="21" string="State" lemma="State" stem="state" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="22" string="University" lemma="University" stem="univers" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Francis)) (VP (VBZ is) (ADVP (RB no) (RBR longer)) (NP (PRP$ his) (NN coach)) (, ,) (S (VP (VBG having) (VP (VBN been) (VP (VBN replaced) (PP (IN by) (NP (NP (NNP Loren) (NNP Seagrave)) (, ,) (NP (NP (JJ former) (NNS women) (POS 's)) (NN coach)))) (PP (IN at) (NP (NNP Louisiana) (NNP State) (NNP University)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is no longer his coach , having been replaced by Loren Seagrave , former women 's coach at Louisiana State University" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="no" />
            <token id="4" string="longer" />
            <token id="5" string="his" />
            <token id="6" string="coach" />
            <token id="7" string="," />
            <token id="8" string="having" />
            <token id="9" string="been" />
            <token id="10" string="replaced" />
            <token id="11" string="by" />
            <token id="12" string="Loren" />
            <token id="13" string="Seagrave" />
            <token id="14" string="," />
            <token id="15" string="former" />
            <token id="16" string="women" />
            <token id="17" string="'s" />
            <token id="18" string="coach" />
            <token id="19" string="at" />
            <token id="20" string="Louisiana" />
            <token id="21" string="State" />
            <token id="22" string="University" />
          </tokens>
        </chunking>
        <chunking id="2" string="Louisiana State University" type="NP">
          <tokens>
            <token id="20" string="Louisiana" />
            <token id="21" string="State" />
            <token id="22" string="University" />
          </tokens>
        </chunking>
        <chunking id="3" string="Francis" type="NP">
          <tokens>
            <token id="1" string="Francis" />
          </tokens>
        </chunking>
        <chunking id="4" string="replaced by Loren Seagrave , former women 's coach at Louisiana State University" type="VP">
          <tokens>
            <token id="10" string="replaced" />
            <token id="11" string="by" />
            <token id="12" string="Loren" />
            <token id="13" string="Seagrave" />
            <token id="14" string="," />
            <token id="15" string="former" />
            <token id="16" string="women" />
            <token id="17" string="'s" />
            <token id="18" string="coach" />
            <token id="19" string="at" />
            <token id="20" string="Louisiana" />
            <token id="21" string="State" />
            <token id="22" string="University" />
          </tokens>
        </chunking>
        <chunking id="5" string="Loren Seagrave" type="NP">
          <tokens>
            <token id="12" string="Loren" />
            <token id="13" string="Seagrave" />
          </tokens>
        </chunking>
        <chunking id="6" string="former women 's coach" type="NP">
          <tokens>
            <token id="15" string="former" />
            <token id="16" string="women" />
            <token id="17" string="'s" />
            <token id="18" string="coach" />
          </tokens>
        </chunking>
        <chunking id="7" string="Loren Seagrave , former women 's coach" type="NP">
          <tokens>
            <token id="12" string="Loren" />
            <token id="13" string="Seagrave" />
            <token id="14" string="," />
            <token id="15" string="former" />
            <token id="16" string="women" />
            <token id="17" string="'s" />
            <token id="18" string="coach" />
          </tokens>
        </chunking>
        <chunking id="8" string="having been replaced by Loren Seagrave , former women 's coach at Louisiana State University" type="VP">
          <tokens>
            <token id="8" string="having" />
            <token id="9" string="been" />
            <token id="10" string="replaced" />
            <token id="11" string="by" />
            <token id="12" string="Loren" />
            <token id="13" string="Seagrave" />
            <token id="14" string="," />
            <token id="15" string="former" />
            <token id="16" string="women" />
            <token id="17" string="'s" />
            <token id="18" string="coach" />
            <token id="19" string="at" />
            <token id="20" string="Louisiana" />
            <token id="21" string="State" />
            <token id="22" string="University" />
          </tokens>
        </chunking>
        <chunking id="9" string="his coach" type="NP">
          <tokens>
            <token id="5" string="his" />
            <token id="6" string="coach" />
          </tokens>
        </chunking>
        <chunking id="10" string="been replaced by Loren Seagrave , former women 's coach at Louisiana State University" type="VP">
          <tokens>
            <token id="9" string="been" />
            <token id="10" string="replaced" />
            <token id="11" string="by" />
            <token id="12" string="Loren" />
            <token id="13" string="Seagrave" />
            <token id="14" string="," />
            <token id="15" string="former" />
            <token id="16" string="women" />
            <token id="17" string="'s" />
            <token id="18" string="coach" />
            <token id="19" string="at" />
            <token id="20" string="Louisiana" />
            <token id="21" string="State" />
            <token id="22" string="University" />
          </tokens>
        </chunking>
        <chunking id="11" string="former women 's" type="NP">
          <tokens>
            <token id="15" string="former" />
            <token id="16" string="women" />
            <token id="17" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">coach</governor>
          <dependent id="1">Francis</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">coach</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">longer</governor>
          <dependent id="3">no</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">coach</governor>
          <dependent id="4">longer</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">coach</governor>
          <dependent id="5">his</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">coach</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">replaced</governor>
          <dependent id="8">having</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="10">replaced</governor>
          <dependent id="9">been</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="6">coach</governor>
          <dependent id="10">replaced</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Seagrave</governor>
          <dependent id="11">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Seagrave</governor>
          <dependent id="12">Loren</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">replaced</governor>
          <dependent id="13">Seagrave</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">women</governor>
          <dependent id="15">former</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="18">coach</governor>
          <dependent id="16">women</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">women</governor>
          <dependent id="17">'s</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="13">Seagrave</governor>
          <dependent id="18">coach</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">University</governor>
          <dependent id="19">at</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">University</governor>
          <dependent id="20">Louisiana</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">University</governor>
          <dependent id="21">State</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">replaced</governor>
          <dependent id="22">University</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Louisiana State University" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="20" string="Louisiana" />
            <token id="21" string="State" />
            <token id="22" string="University" />
          </tokens>
        </entity>
        <entity id="2" string="Francis" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Francis" />
          </tokens>
        </entity>
        <entity id="3" string="Loren Seagrave" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Loren" />
            <token id="13" string="Seagrave" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="97" has_coreference="true">
      <content>Others in Johnson&amp;apost;s inner circle are Larry Heidebrecht, his agent; Kameel Azan, a Jamaican-born Toronto businessman and former hairdresser who is Johnson&amp;apost;s adviser; and Ed Futerman, Johnson&amp;apost;s attorney.</content>
      <tokens>
        <token id="1" string="Others" lemma="other" stem="other" pos="NNS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="inner" lemma="inner" stem="inner" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="circle" lemma="circle" stem="circl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Larry" lemma="Larry" stem="larri" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="9" string="Heidebrecht" lemma="Heidebrecht" stem="heidebrecht" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="agent" lemma="agent" stem="agent" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Kameel" lemma="Kameel" stem="kameel" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="15" string="Azan" lemma="Azan" stem="azan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Jamaican-born" lemma="jamaican-born" stem="jamaican-born" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="Toronto" lemma="Toronto" stem="toronto" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="20" string="businessman" lemma="businessman" stem="businessman" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="former" lemma="former" stem="former" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="hairdresser" lemma="hairdresser" stem="hairdress" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="27" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="28" string="adviser" lemma="adviser" stem="advis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="Ed" lemma="Ed" stem="ed" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="32" string="Futerman" lemma="Futerman" stem="futerman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="33" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="35" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="36" string="attorney" lemma="attorney" stem="attornei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNS Others)) (PP (IN in) (NP (NP (NNP Johnson) (POS 's)) (JJ inner) (NN circle)))) (VP (VBP are) (NP (NP (NP (NNP Larry) (NNP Heidebrecht)) (, ,) (NP (PRP$ his) (NN agent))) (: ;) (NP (NP (NNP Kameel) (NNP Azan)) (, ,) (NP (DT a) (JJ Jamaican-born) (NNP Toronto) (NN businessman)) (CC and) (NP (NP (JJ former) (NN hairdresser)) (SBAR (WHNP (WP who)) (S (VP (VBZ is) (NP (NP (NNP Johnson) (POS 's)) (NN adviser))))))) (: ;) (CC and) (NP (NP (NNP Ed) (NNP Futerman)) (, ,) (NP (NP (NNP Johnson) (POS 's)) (NN attorney))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Others" type="NP">
          <tokens>
            <token id="1" string="Others" />
          </tokens>
        </chunking>
        <chunking id="2" string="his agent" type="NP">
          <tokens>
            <token id="11" string="his" />
            <token id="12" string="agent" />
          </tokens>
        </chunking>
        <chunking id="3" string="Kameel Azan" type="NP">
          <tokens>
            <token id="14" string="Kameel" />
            <token id="15" string="Azan" />
          </tokens>
        </chunking>
        <chunking id="4" string="Johnson 's attorney" type="NP">
          <tokens>
            <token id="34" string="Johnson" />
            <token id="35" string="'s" />
            <token id="36" string="attorney" />
          </tokens>
        </chunking>
        <chunking id="5" string="are Larry Heidebrecht , his agent ; Kameel Azan , a Jamaican-born Toronto businessman and former hairdresser who is Johnson 's adviser ; and Ed Futerman , Johnson 's attorney" type="VP">
          <tokens>
            <token id="7" string="are" />
            <token id="8" string="Larry" />
            <token id="9" string="Heidebrecht" />
            <token id="10" string="," />
            <token id="11" string="his" />
            <token id="12" string="agent" />
            <token id="13" string=";" />
            <token id="14" string="Kameel" />
            <token id="15" string="Azan" />
            <token id="16" string="," />
            <token id="17" string="a" />
            <token id="18" string="Jamaican-born" />
            <token id="19" string="Toronto" />
            <token id="20" string="businessman" />
            <token id="21" string="and" />
            <token id="22" string="former" />
            <token id="23" string="hairdresser" />
            <token id="24" string="who" />
            <token id="25" string="is" />
            <token id="26" string="Johnson" />
            <token id="27" string="'s" />
            <token id="28" string="adviser" />
            <token id="29" string=";" />
            <token id="30" string="and" />
            <token id="31" string="Ed" />
            <token id="32" string="Futerman" />
            <token id="33" string="," />
            <token id="34" string="Johnson" />
            <token id="35" string="'s" />
            <token id="36" string="attorney" />
          </tokens>
        </chunking>
        <chunking id="6" string="Others in Johnson 's inner circle" type="NP">
          <tokens>
            <token id="1" string="Others" />
            <token id="2" string="in" />
            <token id="3" string="Johnson" />
            <token id="4" string="'s" />
            <token id="5" string="inner" />
            <token id="6" string="circle" />
          </tokens>
        </chunking>
        <chunking id="7" string="Johnson 's inner circle" type="NP">
          <tokens>
            <token id="3" string="Johnson" />
            <token id="4" string="'s" />
            <token id="5" string="inner" />
            <token id="6" string="circle" />
          </tokens>
        </chunking>
        <chunking id="8" string="Larry Heidebrecht , his agent ; Kameel Azan , a Jamaican-born Toronto businessman and former hairdresser who is Johnson 's adviser ; and Ed Futerman , Johnson 's attorney" type="NP">
          <tokens>
            <token id="8" string="Larry" />
            <token id="9" string="Heidebrecht" />
            <token id="10" string="," />
            <token id="11" string="his" />
            <token id="12" string="agent" />
            <token id="13" string=";" />
            <token id="14" string="Kameel" />
            <token id="15" string="Azan" />
            <token id="16" string="," />
            <token id="17" string="a" />
            <token id="18" string="Jamaican-born" />
            <token id="19" string="Toronto" />
            <token id="20" string="businessman" />
            <token id="21" string="and" />
            <token id="22" string="former" />
            <token id="23" string="hairdresser" />
            <token id="24" string="who" />
            <token id="25" string="is" />
            <token id="26" string="Johnson" />
            <token id="27" string="'s" />
            <token id="28" string="adviser" />
            <token id="29" string=";" />
            <token id="30" string="and" />
            <token id="31" string="Ed" />
            <token id="32" string="Futerman" />
            <token id="33" string="," />
            <token id="34" string="Johnson" />
            <token id="35" string="'s" />
            <token id="36" string="attorney" />
          </tokens>
        </chunking>
        <chunking id="9" string="who is Johnson 's adviser" type="SBAR">
          <tokens>
            <token id="24" string="who" />
            <token id="25" string="is" />
            <token id="26" string="Johnson" />
            <token id="27" string="'s" />
            <token id="28" string="adviser" />
          </tokens>
        </chunking>
        <chunking id="10" string="Ed Futerman" type="NP">
          <tokens>
            <token id="31" string="Ed" />
            <token id="32" string="Futerman" />
          </tokens>
        </chunking>
        <chunking id="11" string="Larry Heidebrecht" type="NP">
          <tokens>
            <token id="8" string="Larry" />
            <token id="9" string="Heidebrecht" />
          </tokens>
        </chunking>
        <chunking id="12" string="Johnson 's adviser" type="NP">
          <tokens>
            <token id="26" string="Johnson" />
            <token id="27" string="'s" />
            <token id="28" string="adviser" />
          </tokens>
        </chunking>
        <chunking id="13" string="former hairdresser who is Johnson 's adviser" type="NP">
          <tokens>
            <token id="22" string="former" />
            <token id="23" string="hairdresser" />
            <token id="24" string="who" />
            <token id="25" string="is" />
            <token id="26" string="Johnson" />
            <token id="27" string="'s" />
            <token id="28" string="adviser" />
          </tokens>
        </chunking>
        <chunking id="14" string="Ed Futerman , Johnson 's attorney" type="NP">
          <tokens>
            <token id="31" string="Ed" />
            <token id="32" string="Futerman" />
            <token id="33" string="," />
            <token id="34" string="Johnson" />
            <token id="35" string="'s" />
            <token id="36" string="attorney" />
          </tokens>
        </chunking>
        <chunking id="15" string="former hairdresser" type="NP">
          <tokens>
            <token id="22" string="former" />
            <token id="23" string="hairdresser" />
          </tokens>
        </chunking>
        <chunking id="16" string="Kameel Azan , a Jamaican-born Toronto businessman and former hairdresser who is Johnson 's adviser" type="NP">
          <tokens>
            <token id="14" string="Kameel" />
            <token id="15" string="Azan" />
            <token id="16" string="," />
            <token id="17" string="a" />
            <token id="18" string="Jamaican-born" />
            <token id="19" string="Toronto" />
            <token id="20" string="businessman" />
            <token id="21" string="and" />
            <token id="22" string="former" />
            <token id="23" string="hairdresser" />
            <token id="24" string="who" />
            <token id="25" string="is" />
            <token id="26" string="Johnson" />
            <token id="27" string="'s" />
            <token id="28" string="adviser" />
          </tokens>
        </chunking>
        <chunking id="17" string="Larry Heidebrecht , his agent" type="NP">
          <tokens>
            <token id="8" string="Larry" />
            <token id="9" string="Heidebrecht" />
            <token id="10" string="," />
            <token id="11" string="his" />
            <token id="12" string="agent" />
          </tokens>
        </chunking>
        <chunking id="18" string="a Jamaican-born Toronto businessman" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="Jamaican-born" />
            <token id="19" string="Toronto" />
            <token id="20" string="businessman" />
          </tokens>
        </chunking>
        <chunking id="19" string="Johnson 's" type="NP">
          <tokens>
            <token id="3" string="Johnson" />
            <token id="4" string="'s" />
          </tokens>
        </chunking>
        <chunking id="20" string="is Johnson 's adviser" type="VP">
          <tokens>
            <token id="25" string="is" />
            <token id="26" string="Johnson" />
            <token id="27" string="'s" />
            <token id="28" string="adviser" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="9">Heidebrecht</governor>
          <dependent id="1">Others</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">circle</governor>
          <dependent id="2">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">circle</governor>
          <dependent id="3">Johnson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">Johnson</governor>
          <dependent id="4">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">circle</governor>
          <dependent id="5">inner</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Others</governor>
          <dependent id="6">circle</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="9">Heidebrecht</governor>
          <dependent id="7">are</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Heidebrecht</governor>
          <dependent id="8">Larry</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">Heidebrecht</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">agent</governor>
          <dependent id="11">his</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="9">Heidebrecht</governor>
          <dependent id="12">agent</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Azan</governor>
          <dependent id="14">Kameel</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">Heidebrecht</governor>
          <dependent id="15">Azan</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">businessman</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">businessman</governor>
          <dependent id="18">Jamaican-born</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">businessman</governor>
          <dependent id="19">Toronto</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">Azan</governor>
          <dependent id="20">businessman</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">Azan</governor>
          <dependent id="21">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">hairdresser</governor>
          <dependent id="22">former</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">Azan</governor>
          <dependent id="23">hairdresser</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">adviser</governor>
          <dependent id="24">who</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="28">adviser</governor>
          <dependent id="25">is</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="28">adviser</governor>
          <dependent id="26">Johnson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">Johnson</governor>
          <dependent id="27">'s</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="23">hairdresser</governor>
          <dependent id="28">adviser</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">Heidebrecht</governor>
          <dependent id="30">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="32">Futerman</governor>
          <dependent id="31">Ed</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">Heidebrecht</governor>
          <dependent id="32">Futerman</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="36">attorney</governor>
          <dependent id="34">Johnson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">Johnson</governor>
          <dependent id="35">'s</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="32">Futerman</governor>
          <dependent id="36">attorney</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Kameel Azan" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Kameel" />
            <token id="15" string="Azan" />
          </tokens>
        </entity>
        <entity id="2" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Johnson" />
          </tokens>
        </entity>
        <entity id="3" string="Ed Futerman" type="PERSON" score="0.0">
          <tokens>
            <token id="31" string="Ed" />
            <token id="32" string="Futerman" />
          </tokens>
        </entity>
        <entity id="4" string="Larry Heidebrecht" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Larry" />
            <token id="9" string="Heidebrecht" />
          </tokens>
        </entity>
        <entity id="5" string="Toronto" type="LOCATION" score="0.0">
          <tokens>
            <token id="19" string="Toronto" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="98" has_coreference="true">
      <content>The key words in the Johnson camp are Damage Control, or more simply, control.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="key" lemma="key" stem="kei" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="words" lemma="word" stem="word" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="camp" lemma="camp" stem="camp" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Damage" lemma="damage" stem="damag" pos="NN" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="10" string="Control" lemma="control" stem="control" pos="NN" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="simply" lemma="simply" stem="simpli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="control" lemma="control" stem="control" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (JJ key) (NNS words)) (PP (IN in) (NP (DT the) (NNP Johnson) (NN camp)))) (VP (VBP are) (NP (NP (NN Damage) (NN Control)) (, ,) (NP (NP (QP (CC or) (JJR more))) (ADVP (RB simply))) (, ,) (NP (NN control)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="or more" type="NP">
          <tokens>
            <token id="12" string="or" />
            <token id="13" string="more" />
          </tokens>
        </chunking>
        <chunking id="2" string="The key words in the Johnson camp" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="key" />
            <token id="3" string="words" />
            <token id="4" string="in" />
            <token id="5" string="the" />
            <token id="6" string="Johnson" />
            <token id="7" string="camp" />
          </tokens>
        </chunking>
        <chunking id="3" string="the Johnson camp" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="Johnson" />
            <token id="7" string="camp" />
          </tokens>
        </chunking>
        <chunking id="4" string="Damage Control" type="NP">
          <tokens>
            <token id="9" string="Damage" />
            <token id="10" string="Control" />
          </tokens>
        </chunking>
        <chunking id="5" string="are Damage Control , or more simply , control" type="VP">
          <tokens>
            <token id="8" string="are" />
            <token id="9" string="Damage" />
            <token id="10" string="Control" />
            <token id="11" string="," />
            <token id="12" string="or" />
            <token id="13" string="more" />
            <token id="14" string="simply" />
            <token id="15" string="," />
            <token id="16" string="control" />
          </tokens>
        </chunking>
        <chunking id="6" string="The key words" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="key" />
            <token id="3" string="words" />
          </tokens>
        </chunking>
        <chunking id="7" string="control" type="NP">
          <tokens>
            <token id="16" string="control" />
          </tokens>
        </chunking>
        <chunking id="8" string="Damage Control , or more simply , control" type="NP">
          <tokens>
            <token id="9" string="Damage" />
            <token id="10" string="Control" />
            <token id="11" string="," />
            <token id="12" string="or" />
            <token id="13" string="more" />
            <token id="14" string="simply" />
            <token id="15" string="," />
            <token id="16" string="control" />
          </tokens>
        </chunking>
        <chunking id="9" string="or more simply" type="NP">
          <tokens>
            <token id="12" string="or" />
            <token id="13" string="more" />
            <token id="14" string="simply" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">words</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">words</governor>
          <dependent id="2">key</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">Control</governor>
          <dependent id="3">words</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">camp</governor>
          <dependent id="4">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">camp</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">camp</governor>
          <dependent id="6">Johnson</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">words</governor>
          <dependent id="7">camp</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="10">Control</governor>
          <dependent id="8">are</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Control</governor>
          <dependent id="9">Damage</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">Control</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">more</governor>
          <dependent id="12">or</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="10">Control</governor>
          <dependent id="13">more</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">more</governor>
          <dependent id="14">simply</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="10">Control</governor>
          <dependent id="16">control</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="Damage Control" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="9" string="Damage" />
            <token id="10" string="Control" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="99" has_coreference="true">
      <content>Futerman limits Johnson&amp;apost;s contact with the media, saying &amp;quot;Ben has said all he has to say.</content>
      <tokens>
        <token id="1" string="Futerman" lemma="Futerman" stem="futerman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="limits" lemma="limit" stem="limit" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="contact" lemma="contact" stem="contact" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="media" lemma="media" stem="media" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="saying" lemma="say" stem="sai" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Ben" lemma="Ben" stem="ben" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="13" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="said" lemma="say" stem="said" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="say" lemma="say" stem="sai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Futerman)) (VP (VBZ limits) (NP (NP (NNP Johnson) (POS 's)) (NN contact)) (PP (IN with) (NP (DT the) (NNS media))) (, ,) (S (VP (VBG saying) (S (`` ``) (NP (NNP Ben)) (VP (VBZ has) (VP (VBN said) (NP (NP (DT all)) (SBAR (S (NP (PRP he)) (VP (VBZ has) (S (VP (TO to) (VP (VB say)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Johnson 's contact" type="NP">
          <tokens>
            <token id="3" string="Johnson" />
            <token id="4" string="'s" />
            <token id="5" string="contact" />
          </tokens>
        </chunking>
        <chunking id="2" string="all" type="NP">
          <tokens>
            <token id="15" string="all" />
          </tokens>
        </chunking>
        <chunking id="3" string="said all he has to say" type="VP">
          <tokens>
            <token id="14" string="said" />
            <token id="15" string="all" />
            <token id="16" string="he" />
            <token id="17" string="has" />
            <token id="18" string="to" />
            <token id="19" string="say" />
          </tokens>
        </chunking>
        <chunking id="4" string="Futerman" type="NP">
          <tokens>
            <token id="1" string="Futerman" />
          </tokens>
        </chunking>
        <chunking id="5" string="all he has to say" type="NP">
          <tokens>
            <token id="15" string="all" />
            <token id="16" string="he" />
            <token id="17" string="has" />
            <token id="18" string="to" />
            <token id="19" string="say" />
          </tokens>
        </chunking>
        <chunking id="6" string="has said all he has to say" type="VP">
          <tokens>
            <token id="13" string="has" />
            <token id="14" string="said" />
            <token id="15" string="all" />
            <token id="16" string="he" />
            <token id="17" string="has" />
            <token id="18" string="to" />
            <token id="19" string="say" />
          </tokens>
        </chunking>
        <chunking id="7" string="the media" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="media" />
          </tokens>
        </chunking>
        <chunking id="8" string="Ben" type="NP">
          <tokens>
            <token id="12" string="Ben" />
          </tokens>
        </chunking>
        <chunking id="9" string="say" type="VP">
          <tokens>
            <token id="19" string="say" />
          </tokens>
        </chunking>
        <chunking id="10" string="limits Johnson 's contact with the media , saying `` Ben has said all he has to say" type="VP">
          <tokens>
            <token id="2" string="limits" />
            <token id="3" string="Johnson" />
            <token id="4" string="'s" />
            <token id="5" string="contact" />
            <token id="6" string="with" />
            <token id="7" string="the" />
            <token id="8" string="media" />
            <token id="9" string="," />
            <token id="10" string="saying" />
            <token id="11" string="&quot;" />
            <token id="12" string="Ben" />
            <token id="13" string="has" />
            <token id="14" string="said" />
            <token id="15" string="all" />
            <token id="16" string="he" />
            <token id="17" string="has" />
            <token id="18" string="to" />
            <token id="19" string="say" />
          </tokens>
        </chunking>
        <chunking id="11" string="saying `` Ben has said all he has to say" type="VP">
          <tokens>
            <token id="10" string="saying" />
            <token id="11" string="&quot;" />
            <token id="12" string="Ben" />
            <token id="13" string="has" />
            <token id="14" string="said" />
            <token id="15" string="all" />
            <token id="16" string="he" />
            <token id="17" string="has" />
            <token id="18" string="to" />
            <token id="19" string="say" />
          </tokens>
        </chunking>
        <chunking id="12" string="he has to say" type="SBAR">
          <tokens>
            <token id="16" string="he" />
            <token id="17" string="has" />
            <token id="18" string="to" />
            <token id="19" string="say" />
          </tokens>
        </chunking>
        <chunking id="13" string="has to say" type="VP">
          <tokens>
            <token id="17" string="has" />
            <token id="18" string="to" />
            <token id="19" string="say" />
          </tokens>
        </chunking>
        <chunking id="14" string="to say" type="VP">
          <tokens>
            <token id="18" string="to" />
            <token id="19" string="say" />
          </tokens>
        </chunking>
        <chunking id="15" string="he" type="NP">
          <tokens>
            <token id="16" string="he" />
          </tokens>
        </chunking>
        <chunking id="16" string="Johnson 's" type="NP">
          <tokens>
            <token id="3" string="Johnson" />
            <token id="4" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">limits</governor>
          <dependent id="1">Futerman</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">limits</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">contact</governor>
          <dependent id="3">Johnson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">Johnson</governor>
          <dependent id="4">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">limits</governor>
          <dependent id="5">contact</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">media</governor>
          <dependent id="6">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">media</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">limits</governor>
          <dependent id="8">media</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="2">limits</governor>
          <dependent id="10">saying</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">said</governor>
          <dependent id="12">Ben</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">said</governor>
          <dependent id="13">has</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">saying</governor>
          <dependent id="14">said</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">said</governor>
          <dependent id="15">all</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">has</governor>
          <dependent id="16">he</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="15">all</governor>
          <dependent id="17">has</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">say</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="17">has</governor>
          <dependent id="19">say</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="Futerman" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Futerman" />
          </tokens>
        </entity>
        <entity id="3" string="Ben" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Ben" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="100" has_coreference="true">
      <content>We don&amp;apost;t need any more media.&amp;quot;</content>
      <tokens>
        <token id="1" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="need" lemma="need" stem="need" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="media" lemma="media" stem="media" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP We)) (VP (VBP do) (RB n't) (VP (VB need) (NP (DT any) (JJR more) (NNS media)))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="do n't need any more media" type="VP">
          <tokens>
            <token id="2" string="do" />
            <token id="3" string="n't" />
            <token id="4" string="need" />
            <token id="5" string="any" />
            <token id="6" string="more" />
            <token id="7" string="media" />
          </tokens>
        </chunking>
        <chunking id="2" string="any more media" type="NP">
          <tokens>
            <token id="5" string="any" />
            <token id="6" string="more" />
            <token id="7" string="media" />
          </tokens>
        </chunking>
        <chunking id="3" string="We" type="NP">
          <tokens>
            <token id="1" string="We" />
          </tokens>
        </chunking>
        <chunking id="4" string="need any more media" type="VP">
          <tokens>
            <token id="4" string="need" />
            <token id="5" string="any" />
            <token id="6" string="more" />
            <token id="7" string="media" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">need</governor>
          <dependent id="1">We</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">need</governor>
          <dependent id="2">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">need</governor>
          <dependent id="3">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">need</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">media</governor>
          <dependent id="5">any</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">media</governor>
          <dependent id="6">more</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">need</governor>
          <dependent id="7">media</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="101" has_coreference="true">
      <content>However, it was Futerman who offered to permit a British journalist to interview Johnson -- if he paid $10,000 and submitted his questions in advance.</content>
      <tokens>
        <token id="1" string="However" lemma="however" stem="howev" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Futerman" lemma="Futerman" stem="futerman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="6" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="offered" lemma="offer" stem="offer" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="permit" lemma="permit" stem="permit" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="British" lemma="british" stem="british" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="true" />
        <token id="12" string="journalist" lemma="journalist" stem="journalist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="interview" lemma="interview" stem="interview" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="16" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="paid" lemma="pay" stem="paid" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="true" />
        <token id="21" string="10,000" lemma="10,000" stem="10,000" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="true" />
        <token id="22" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="submitted" lemma="submit" stem="submit" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="24" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="questions" lemma="question" stem="question" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="26" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="advance" lemma="advance" stem="advanc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB However)) (, ,) (NP (PRP it)) (VP (VBD was) (NP (NP (NNP Futerman)) (SBAR (WHNP (WP who)) (S (VP (VBD offered) (S (VP (TO to) (VP (VB permit) (NP (DT a) (JJ British) (NN journalist)) (S (VP (TO to) (VP (VB interview) (NP (NNP Johnson)) (: --) (SBAR (IN if) (S (NP (PRP he)) (VP (VP (VBD paid) (NP ($ $) (CD 10,000))) (CC and) (VP (VBD submitted) (NP (PRP$ his) (NNS questions)) (PP (IN in) (NP (NN advance)))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Johnson" type="NP">
          <tokens>
            <token id="15" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="2" string="if he paid $ 10,000 and submitted his questions in advance" type="SBAR">
          <tokens>
            <token id="17" string="if" />
            <token id="18" string="he" />
            <token id="19" string="paid" />
            <token id="20" string="$" />
            <token id="21" string="10,000" />
            <token id="22" string="and" />
            <token id="23" string="submitted" />
            <token id="24" string="his" />
            <token id="25" string="questions" />
            <token id="26" string="in" />
            <token id="27" string="advance" />
          </tokens>
        </chunking>
        <chunking id="3" string="interview Johnson -- if he paid $ 10,000 and submitted his questions in advance" type="VP">
          <tokens>
            <token id="14" string="interview" />
            <token id="15" string="Johnson" />
            <token id="16" string="--" />
            <token id="17" string="if" />
            <token id="18" string="he" />
            <token id="19" string="paid" />
            <token id="20" string="$" />
            <token id="21" string="10,000" />
            <token id="22" string="and" />
            <token id="23" string="submitted" />
            <token id="24" string="his" />
            <token id="25" string="questions" />
            <token id="26" string="in" />
            <token id="27" string="advance" />
          </tokens>
        </chunking>
        <chunking id="4" string="paid $ 10,000" type="VP">
          <tokens>
            <token id="19" string="paid" />
            <token id="20" string="$" />
            <token id="21" string="10,000" />
          </tokens>
        </chunking>
        <chunking id="5" string="Futerman" type="NP">
          <tokens>
            <token id="5" string="Futerman" />
          </tokens>
        </chunking>
        <chunking id="6" string="paid $ 10,000 and submitted his questions in advance" type="VP">
          <tokens>
            <token id="19" string="paid" />
            <token id="20" string="$" />
            <token id="21" string="10,000" />
            <token id="22" string="and" />
            <token id="23" string="submitted" />
            <token id="24" string="his" />
            <token id="25" string="questions" />
            <token id="26" string="in" />
            <token id="27" string="advance" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="3" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="advance" type="NP">
          <tokens>
            <token id="27" string="advance" />
          </tokens>
        </chunking>
        <chunking id="9" string="was Futerman who offered to permit a British journalist to interview Johnson -- if he paid $ 10,000 and submitted his questions in advance" type="VP">
          <tokens>
            <token id="4" string="was" />
            <token id="5" string="Futerman" />
            <token id="6" string="who" />
            <token id="7" string="offered" />
            <token id="8" string="to" />
            <token id="9" string="permit" />
            <token id="10" string="a" />
            <token id="11" string="British" />
            <token id="12" string="journalist" />
            <token id="13" string="to" />
            <token id="14" string="interview" />
            <token id="15" string="Johnson" />
            <token id="16" string="--" />
            <token id="17" string="if" />
            <token id="18" string="he" />
            <token id="19" string="paid" />
            <token id="20" string="$" />
            <token id="21" string="10,000" />
            <token id="22" string="and" />
            <token id="23" string="submitted" />
            <token id="24" string="his" />
            <token id="25" string="questions" />
            <token id="26" string="in" />
            <token id="27" string="advance" />
          </tokens>
        </chunking>
        <chunking id="10" string="to permit a British journalist to interview Johnson -- if he paid $ 10,000 and submitted his questions in advance" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="permit" />
            <token id="10" string="a" />
            <token id="11" string="British" />
            <token id="12" string="journalist" />
            <token id="13" string="to" />
            <token id="14" string="interview" />
            <token id="15" string="Johnson" />
            <token id="16" string="--" />
            <token id="17" string="if" />
            <token id="18" string="he" />
            <token id="19" string="paid" />
            <token id="20" string="$" />
            <token id="21" string="10,000" />
            <token id="22" string="and" />
            <token id="23" string="submitted" />
            <token id="24" string="his" />
            <token id="25" string="questions" />
            <token id="26" string="in" />
            <token id="27" string="advance" />
          </tokens>
        </chunking>
        <chunking id="11" string="offered to permit a British journalist to interview Johnson -- if he paid $ 10,000 and submitted his questions in advance" type="VP">
          <tokens>
            <token id="7" string="offered" />
            <token id="8" string="to" />
            <token id="9" string="permit" />
            <token id="10" string="a" />
            <token id="11" string="British" />
            <token id="12" string="journalist" />
            <token id="13" string="to" />
            <token id="14" string="interview" />
            <token id="15" string="Johnson" />
            <token id="16" string="--" />
            <token id="17" string="if" />
            <token id="18" string="he" />
            <token id="19" string="paid" />
            <token id="20" string="$" />
            <token id="21" string="10,000" />
            <token id="22" string="and" />
            <token id="23" string="submitted" />
            <token id="24" string="his" />
            <token id="25" string="questions" />
            <token id="26" string="in" />
            <token id="27" string="advance" />
          </tokens>
        </chunking>
        <chunking id="12" string="submitted his questions in advance" type="VP">
          <tokens>
            <token id="23" string="submitted" />
            <token id="24" string="his" />
            <token id="25" string="questions" />
            <token id="26" string="in" />
            <token id="27" string="advance" />
          </tokens>
        </chunking>
        <chunking id="13" string="permit a British journalist to interview Johnson -- if he paid $ 10,000 and submitted his questions in advance" type="VP">
          <tokens>
            <token id="9" string="permit" />
            <token id="10" string="a" />
            <token id="11" string="British" />
            <token id="12" string="journalist" />
            <token id="13" string="to" />
            <token id="14" string="interview" />
            <token id="15" string="Johnson" />
            <token id="16" string="--" />
            <token id="17" string="if" />
            <token id="18" string="he" />
            <token id="19" string="paid" />
            <token id="20" string="$" />
            <token id="21" string="10,000" />
            <token id="22" string="and" />
            <token id="23" string="submitted" />
            <token id="24" string="his" />
            <token id="25" string="questions" />
            <token id="26" string="in" />
            <token id="27" string="advance" />
          </tokens>
        </chunking>
        <chunking id="14" string="a British journalist" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="British" />
            <token id="12" string="journalist" />
          </tokens>
        </chunking>
        <chunking id="15" string="$ 10,000" type="NP">
          <tokens>
            <token id="20" string="$" />
            <token id="21" string="10,000" />
          </tokens>
        </chunking>
        <chunking id="16" string="his questions" type="NP">
          <tokens>
            <token id="24" string="his" />
            <token id="25" string="questions" />
          </tokens>
        </chunking>
        <chunking id="17" string="Futerman who offered to permit a British journalist to interview Johnson -- if he paid $ 10,000 and submitted his questions in advance" type="NP">
          <tokens>
            <token id="5" string="Futerman" />
            <token id="6" string="who" />
            <token id="7" string="offered" />
            <token id="8" string="to" />
            <token id="9" string="permit" />
            <token id="10" string="a" />
            <token id="11" string="British" />
            <token id="12" string="journalist" />
            <token id="13" string="to" />
            <token id="14" string="interview" />
            <token id="15" string="Johnson" />
            <token id="16" string="--" />
            <token id="17" string="if" />
            <token id="18" string="he" />
            <token id="19" string="paid" />
            <token id="20" string="$" />
            <token id="21" string="10,000" />
            <token id="22" string="and" />
            <token id="23" string="submitted" />
            <token id="24" string="his" />
            <token id="25" string="questions" />
            <token id="26" string="in" />
            <token id="27" string="advance" />
          </tokens>
        </chunking>
        <chunking id="18" string="he" type="NP">
          <tokens>
            <token id="18" string="he" />
          </tokens>
        </chunking>
        <chunking id="19" string="to interview Johnson -- if he paid $ 10,000 and submitted his questions in advance" type="VP">
          <tokens>
            <token id="13" string="to" />
            <token id="14" string="interview" />
            <token id="15" string="Johnson" />
            <token id="16" string="--" />
            <token id="17" string="if" />
            <token id="18" string="he" />
            <token id="19" string="paid" />
            <token id="20" string="$" />
            <token id="21" string="10,000" />
            <token id="22" string="and" />
            <token id="23" string="submitted" />
            <token id="24" string="his" />
            <token id="25" string="questions" />
            <token id="26" string="in" />
            <token id="27" string="advance" />
          </tokens>
        </chunking>
        <chunking id="20" string="who offered to permit a British journalist to interview Johnson -- if he paid $ 10,000 and submitted his questions in advance" type="SBAR">
          <tokens>
            <token id="6" string="who" />
            <token id="7" string="offered" />
            <token id="8" string="to" />
            <token id="9" string="permit" />
            <token id="10" string="a" />
            <token id="11" string="British" />
            <token id="12" string="journalist" />
            <token id="13" string="to" />
            <token id="14" string="interview" />
            <token id="15" string="Johnson" />
            <token id="16" string="--" />
            <token id="17" string="if" />
            <token id="18" string="he" />
            <token id="19" string="paid" />
            <token id="20" string="$" />
            <token id="21" string="10,000" />
            <token id="22" string="and" />
            <token id="23" string="submitted" />
            <token id="24" string="his" />
            <token id="25" string="questions" />
            <token id="26" string="in" />
            <token id="27" string="advance" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="5">Futerman</governor>
          <dependent id="1">However</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">Futerman</governor>
          <dependent id="3">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">Futerman</governor>
          <dependent id="4">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">Futerman</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">offered</governor>
          <dependent id="6">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="5">Futerman</governor>
          <dependent id="7">offered</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">permit</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">offered</governor>
          <dependent id="9">permit</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">journalist</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">journalist</governor>
          <dependent id="11">British</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">permit</governor>
          <dependent id="12">journalist</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">interview</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">permit</governor>
          <dependent id="14">interview</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">interview</governor>
          <dependent id="15">Johnson</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">paid</governor>
          <dependent id="17">if</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">paid</governor>
          <dependent id="18">he</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="14">interview</governor>
          <dependent id="19">paid</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="21">10,000</governor>
          <dependent id="20">$</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">paid</governor>
          <dependent id="21">10,000</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="19">paid</governor>
          <dependent id="22">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">paid</governor>
          <dependent id="23">submitted</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="25">questions</governor>
          <dependent id="24">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">submitted</governor>
          <dependent id="25">questions</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">advance</governor>
          <dependent id="26">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">submitted</governor>
          <dependent id="27">advance</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="11" string="British" />
          </tokens>
        </entity>
        <entity id="3" string="Futerman" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Futerman" />
          </tokens>
        </entity>
        <entity id="4" string="$ 10,000" type="MONEY" score="0.0">
          <tokens>
            <token id="20" string="$" />
            <token id="21" string="10,000" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="102" has_coreference="true">
      <content>Johnson gave an in-depth interview to the German magazine, Sport, but only after being paid.</content>
      <tokens>
        <token id="1" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="gave" lemma="give" stem="gave" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="in-depth" lemma="in-depth" stem="in-depth" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="interview" lemma="interview" stem="interview" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="German" lemma="german" stem="german" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="9" string="magazine" lemma="magazine" stem="magazin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Sport" lemma="Sport" stem="sport" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="being" lemma="be" stem="be" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="paid" lemma="pay" stem="paid" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Johnson)) (VP (VBD gave) (NP (DT an) (JJ in-depth) (NN interview)) (PP (PP (TO to) (NP (NP (DT the) (JJ German) (NN magazine)) (, ,) (NP (NNP Sport)))) (, ,) (CC but) (RB only) (PP (IN after) (S (VP (VBG being) (VP (VBN paid))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Johnson" type="NP">
          <tokens>
            <token id="1" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="2" string="an in-depth interview" type="NP">
          <tokens>
            <token id="3" string="an" />
            <token id="4" string="in-depth" />
            <token id="5" string="interview" />
          </tokens>
        </chunking>
        <chunking id="3" string="Sport" type="NP">
          <tokens>
            <token id="11" string="Sport" />
          </tokens>
        </chunking>
        <chunking id="4" string="the German magazine , Sport" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="German" />
            <token id="9" string="magazine" />
            <token id="10" string="," />
            <token id="11" string="Sport" />
          </tokens>
        </chunking>
        <chunking id="5" string="gave an in-depth interview to the German magazine , Sport , but only after being paid" type="VP">
          <tokens>
            <token id="2" string="gave" />
            <token id="3" string="an" />
            <token id="4" string="in-depth" />
            <token id="5" string="interview" />
            <token id="6" string="to" />
            <token id="7" string="the" />
            <token id="8" string="German" />
            <token id="9" string="magazine" />
            <token id="10" string="," />
            <token id="11" string="Sport" />
            <token id="12" string="," />
            <token id="13" string="but" />
            <token id="14" string="only" />
            <token id="15" string="after" />
            <token id="16" string="being" />
            <token id="17" string="paid" />
          </tokens>
        </chunking>
        <chunking id="6" string="being paid" type="VP">
          <tokens>
            <token id="16" string="being" />
            <token id="17" string="paid" />
          </tokens>
        </chunking>
        <chunking id="7" string="the German magazine" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="German" />
            <token id="9" string="magazine" />
          </tokens>
        </chunking>
        <chunking id="8" string="paid" type="VP">
          <tokens>
            <token id="17" string="paid" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">gave</governor>
          <dependent id="1">Johnson</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">gave</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">interview</governor>
          <dependent id="3">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">interview</governor>
          <dependent id="4">in-depth</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">gave</governor>
          <dependent id="5">interview</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">magazine</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">magazine</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">magazine</governor>
          <dependent id="8">German</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">gave</governor>
          <dependent id="9">magazine</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="9">magazine</governor>
          <dependent id="11">Sport</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">magazine</governor>
          <dependent id="13">but</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">magazine</governor>
          <dependent id="14">only</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">paid</governor>
          <dependent id="15">after</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="17">paid</governor>
          <dependent id="16">being</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">magazine</governor>
          <dependent id="17">paid</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="German" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="8" string="German" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="103" has_coreference="true">
      <content>Other than that, he has had a low profile.</content>
      <tokens>
        <token id="1" string="Other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="low" lemma="low" stem="low" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="profile" lemma="profile" stem="profil" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (JJ Other)) (PP (IN than) (NP (DT that))))) (, ,) (NP (PRP he)) (VP (VBZ has) (VP (VBD had) (NP (DT a) (JJ low) (NN profile)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Other" type="NP">
          <tokens>
            <token id="1" string="Other" />
          </tokens>
        </chunking>
        <chunking id="2" string="that" type="NP">
          <tokens>
            <token id="3" string="that" />
          </tokens>
        </chunking>
        <chunking id="3" string="has had a low profile" type="VP">
          <tokens>
            <token id="6" string="has" />
            <token id="7" string="had" />
            <token id="8" string="a" />
            <token id="9" string="low" />
            <token id="10" string="profile" />
          </tokens>
        </chunking>
        <chunking id="4" string="Other than that" type="NP">
          <tokens>
            <token id="1" string="Other" />
            <token id="2" string="than" />
            <token id="3" string="that" />
          </tokens>
        </chunking>
        <chunking id="5" string="he" type="NP">
          <tokens>
            <token id="5" string="he" />
          </tokens>
        </chunking>
        <chunking id="6" string="a low profile" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="low" />
            <token id="10" string="profile" />
          </tokens>
        </chunking>
        <chunking id="7" string="had a low profile" type="VP">
          <tokens>
            <token id="7" string="had" />
            <token id="8" string="a" />
            <token id="9" string="low" />
            <token id="10" string="profile" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="ccomp">
          <governor id="7">had</governor>
          <dependent id="1">Other</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">that</governor>
          <dependent id="2">than</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Other</governor>
          <dependent id="3">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">had</governor>
          <dependent id="5">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">had</governor>
          <dependent id="6">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">had</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">profile</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">profile</governor>
          <dependent id="9">low</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">had</governor>
          <dependent id="10">profile</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="104" has_coreference="true">
      <content>He still is awaiting word from the Canadian Olympic Assn., which placed a lifetime ban on Johnson that prohibited him from representing Canada in the Olympic Games.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="still" lemma="still" stem="still" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="awaiting" lemma="await" stem="await" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="word" lemma="word" stem="word" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Canadian" lemma="Canadian" stem="canadian" pos="NNP" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="9" string="Olympic" lemma="Olympic" stem="olympic" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="10" string="Assn." lemma="Assn." stem="assn." pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="placed" lemma="place" stem="place" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="lifetime" lemma="lifetime" stem="lifetim" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="ban" lemma="ban" stem="ban" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="19" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="prohibited" lemma="prohibit" stem="prohibit" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="22" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="representing" lemma="represent" stem="repres" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="Canada" lemma="Canada" stem="canada" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="25" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="27" string="Olympic" lemma="Olympic" stem="olympic" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="28" string="Games" lemma="Games" stem="game" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (ADVP (RB still)) (VP (VBZ is) (VP (VBG awaiting) (NP (NN word)) (PP (IN from) (NP (NP (DT the) (NNP Canadian) (NNP Olympic) (NNP Assn.)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBD placed) (NP (NP (DT a) (NN lifetime) (NN ban)) (PP (IN on) (NP (NNP Johnson))) (SBAR (WHNP (WDT that)) (S (VP (VBD prohibited) (NP (PRP him)) (PP (IN from) (S (VP (VBG representing) (NP (NP (NNP Canada)) (PP (IN in) (NP (DT the) (NNP Olympic) (NNPS Games)))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Johnson" type="NP">
          <tokens>
            <token id="18" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="2" string="placed a lifetime ban on Johnson that prohibited him from representing Canada in the Olympic Games" type="VP">
          <tokens>
            <token id="13" string="placed" />
            <token id="14" string="a" />
            <token id="15" string="lifetime" />
            <token id="16" string="ban" />
            <token id="17" string="on" />
            <token id="18" string="Johnson" />
            <token id="19" string="that" />
            <token id="20" string="prohibited" />
            <token id="21" string="him" />
            <token id="22" string="from" />
            <token id="23" string="representing" />
            <token id="24" string="Canada" />
            <token id="25" string="in" />
            <token id="26" string="the" />
            <token id="27" string="Olympic" />
            <token id="28" string="Games" />
          </tokens>
        </chunking>
        <chunking id="3" string="the Olympic Games" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="Olympic" />
            <token id="28" string="Games" />
          </tokens>
        </chunking>
        <chunking id="4" string="representing Canada in the Olympic Games" type="VP">
          <tokens>
            <token id="23" string="representing" />
            <token id="24" string="Canada" />
            <token id="25" string="in" />
            <token id="26" string="the" />
            <token id="27" string="Olympic" />
            <token id="28" string="Games" />
          </tokens>
        </chunking>
        <chunking id="5" string="that prohibited him from representing Canada in the Olympic Games" type="SBAR">
          <tokens>
            <token id="19" string="that" />
            <token id="20" string="prohibited" />
            <token id="21" string="him" />
            <token id="22" string="from" />
            <token id="23" string="representing" />
            <token id="24" string="Canada" />
            <token id="25" string="in" />
            <token id="26" string="the" />
            <token id="27" string="Olympic" />
            <token id="28" string="Games" />
          </tokens>
        </chunking>
        <chunking id="6" string="which placed a lifetime ban on Johnson that prohibited him from representing Canada in the Olympic Games" type="SBAR">
          <tokens>
            <token id="12" string="which" />
            <token id="13" string="placed" />
            <token id="14" string="a" />
            <token id="15" string="lifetime" />
            <token id="16" string="ban" />
            <token id="17" string="on" />
            <token id="18" string="Johnson" />
            <token id="19" string="that" />
            <token id="20" string="prohibited" />
            <token id="21" string="him" />
            <token id="22" string="from" />
            <token id="23" string="representing" />
            <token id="24" string="Canada" />
            <token id="25" string="in" />
            <token id="26" string="the" />
            <token id="27" string="Olympic" />
            <token id="28" string="Games" />
          </tokens>
        </chunking>
        <chunking id="7" string="him" type="NP">
          <tokens>
            <token id="21" string="him" />
          </tokens>
        </chunking>
        <chunking id="8" string="the Canadian Olympic Assn. , which placed a lifetime ban on Johnson that prohibited him from representing Canada in the Olympic Games" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="Canadian" />
            <token id="9" string="Olympic" />
            <token id="10" string="Assn." />
            <token id="11" string="," />
            <token id="12" string="which" />
            <token id="13" string="placed" />
            <token id="14" string="a" />
            <token id="15" string="lifetime" />
            <token id="16" string="ban" />
            <token id="17" string="on" />
            <token id="18" string="Johnson" />
            <token id="19" string="that" />
            <token id="20" string="prohibited" />
            <token id="21" string="him" />
            <token id="22" string="from" />
            <token id="23" string="representing" />
            <token id="24" string="Canada" />
            <token id="25" string="in" />
            <token id="26" string="the" />
            <token id="27" string="Olympic" />
            <token id="28" string="Games" />
          </tokens>
        </chunking>
        <chunking id="9" string="Canada in the Olympic Games" type="NP">
          <tokens>
            <token id="24" string="Canada" />
            <token id="25" string="in" />
            <token id="26" string="the" />
            <token id="27" string="Olympic" />
            <token id="28" string="Games" />
          </tokens>
        </chunking>
        <chunking id="10" string="Canada" type="NP">
          <tokens>
            <token id="24" string="Canada" />
          </tokens>
        </chunking>
        <chunking id="11" string="a lifetime ban" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="lifetime" />
            <token id="16" string="ban" />
          </tokens>
        </chunking>
        <chunking id="12" string="is awaiting word from the Canadian Olympic Assn. , which placed a lifetime ban on Johnson that prohibited him from representing Canada in the Olympic Games" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="awaiting" />
            <token id="5" string="word" />
            <token id="6" string="from" />
            <token id="7" string="the" />
            <token id="8" string="Canadian" />
            <token id="9" string="Olympic" />
            <token id="10" string="Assn." />
            <token id="11" string="," />
            <token id="12" string="which" />
            <token id="13" string="placed" />
            <token id="14" string="a" />
            <token id="15" string="lifetime" />
            <token id="16" string="ban" />
            <token id="17" string="on" />
            <token id="18" string="Johnson" />
            <token id="19" string="that" />
            <token id="20" string="prohibited" />
            <token id="21" string="him" />
            <token id="22" string="from" />
            <token id="23" string="representing" />
            <token id="24" string="Canada" />
            <token id="25" string="in" />
            <token id="26" string="the" />
            <token id="27" string="Olympic" />
            <token id="28" string="Games" />
          </tokens>
        </chunking>
        <chunking id="13" string="the Canadian Olympic Assn." type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="Canadian" />
            <token id="9" string="Olympic" />
            <token id="10" string="Assn." />
          </tokens>
        </chunking>
        <chunking id="14" string="a lifetime ban on Johnson that prohibited him from representing Canada in the Olympic Games" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="lifetime" />
            <token id="16" string="ban" />
            <token id="17" string="on" />
            <token id="18" string="Johnson" />
            <token id="19" string="that" />
            <token id="20" string="prohibited" />
            <token id="21" string="him" />
            <token id="22" string="from" />
            <token id="23" string="representing" />
            <token id="24" string="Canada" />
            <token id="25" string="in" />
            <token id="26" string="the" />
            <token id="27" string="Olympic" />
            <token id="28" string="Games" />
          </tokens>
        </chunking>
        <chunking id="15" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="16" string="prohibited him from representing Canada in the Olympic Games" type="VP">
          <tokens>
            <token id="20" string="prohibited" />
            <token id="21" string="him" />
            <token id="22" string="from" />
            <token id="23" string="representing" />
            <token id="24" string="Canada" />
            <token id="25" string="in" />
            <token id="26" string="the" />
            <token id="27" string="Olympic" />
            <token id="28" string="Games" />
          </tokens>
        </chunking>
        <chunking id="17" string="word" type="NP">
          <tokens>
            <token id="5" string="word" />
          </tokens>
        </chunking>
        <chunking id="18" string="awaiting word from the Canadian Olympic Assn. , which placed a lifetime ban on Johnson that prohibited him from representing Canada in the Olympic Games" type="VP">
          <tokens>
            <token id="4" string="awaiting" />
            <token id="5" string="word" />
            <token id="6" string="from" />
            <token id="7" string="the" />
            <token id="8" string="Canadian" />
            <token id="9" string="Olympic" />
            <token id="10" string="Assn." />
            <token id="11" string="," />
            <token id="12" string="which" />
            <token id="13" string="placed" />
            <token id="14" string="a" />
            <token id="15" string="lifetime" />
            <token id="16" string="ban" />
            <token id="17" string="on" />
            <token id="18" string="Johnson" />
            <token id="19" string="that" />
            <token id="20" string="prohibited" />
            <token id="21" string="him" />
            <token id="22" string="from" />
            <token id="23" string="representing" />
            <token id="24" string="Canada" />
            <token id="25" string="in" />
            <token id="26" string="the" />
            <token id="27" string="Olympic" />
            <token id="28" string="Games" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">awaiting</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">awaiting</governor>
          <dependent id="2">still</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">awaiting</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">awaiting</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">awaiting</governor>
          <dependent id="5">word</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Assn.</governor>
          <dependent id="6">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">Assn.</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Assn.</governor>
          <dependent id="8">Canadian</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Assn.</governor>
          <dependent id="9">Olympic</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">awaiting</governor>
          <dependent id="10">Assn.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">placed</governor>
          <dependent id="12">which</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="10">Assn.</governor>
          <dependent id="13">placed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">ban</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">ban</governor>
          <dependent id="15">lifetime</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">placed</governor>
          <dependent id="16">ban</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Johnson</governor>
          <dependent id="17">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">ban</governor>
          <dependent id="18">Johnson</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">prohibited</governor>
          <dependent id="19">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="16">ban</governor>
          <dependent id="20">prohibited</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">prohibited</governor>
          <dependent id="21">him</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">representing</governor>
          <dependent id="22">from</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="20">prohibited</governor>
          <dependent id="23">representing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">representing</governor>
          <dependent id="24">Canada</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">Games</governor>
          <dependent id="25">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">Games</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">Games</governor>
          <dependent id="27">Olympic</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">Canada</governor>
          <dependent id="28">Games</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Olympic Assn." type="MISC" score="0.0">
          <tokens>
            <token id="9" string="Olympic" />
            <token id="10" string="Assn." />
          </tokens>
        </entity>
        <entity id="2" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Johnson" />
          </tokens>
        </entity>
        <entity id="3" string="Canada" type="LOCATION" score="0.0">
          <tokens>
            <token id="24" string="Canada" />
          </tokens>
        </entity>
        <entity id="4" string="Canadian" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="8" string="Canadian" />
          </tokens>
        </entity>
        <entity id="5" string="Olympic Games" type="MISC" score="0.0">
          <tokens>
            <token id="27" string="Olympic" />
            <token id="28" string="Games" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="105" has_coreference="true">
      <content>The COA will meet on Friday and is expected to lift the ban.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="COA" lemma="COA" stem="coa" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="meet" lemma="meet" stem="meet" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Friday" lemma="Friday" stem="fridai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="expected" lemma="expect" stem="expect" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="lift" lemma="lift" stem="lift" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="ban" lemma="ban" stem="ban" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNP COA)) (VP (VP (MD will) (VP (VB meet) (PP (IN on) (NP (NNP Friday))))) (CC and) (VP (VBZ is) (VP (VBN expected) (S (VP (TO to) (VP (VB lift) (NP (DT the) (NN ban)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is expected to lift the ban" type="VP">
          <tokens>
            <token id="8" string="is" />
            <token id="9" string="expected" />
            <token id="10" string="to" />
            <token id="11" string="lift" />
            <token id="12" string="the" />
            <token id="13" string="ban" />
          </tokens>
        </chunking>
        <chunking id="2" string="meet on Friday" type="VP">
          <tokens>
            <token id="4" string="meet" />
            <token id="5" string="on" />
            <token id="6" string="Friday" />
          </tokens>
        </chunking>
        <chunking id="3" string="Friday" type="NP">
          <tokens>
            <token id="6" string="Friday" />
          </tokens>
        </chunking>
        <chunking id="4" string="to lift the ban" type="VP">
          <tokens>
            <token id="10" string="to" />
            <token id="11" string="lift" />
            <token id="12" string="the" />
            <token id="13" string="ban" />
          </tokens>
        </chunking>
        <chunking id="5" string="expected to lift the ban" type="VP">
          <tokens>
            <token id="9" string="expected" />
            <token id="10" string="to" />
            <token id="11" string="lift" />
            <token id="12" string="the" />
            <token id="13" string="ban" />
          </tokens>
        </chunking>
        <chunking id="6" string="the ban" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="ban" />
          </tokens>
        </chunking>
        <chunking id="7" string="The COA" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="COA" />
          </tokens>
        </chunking>
        <chunking id="8" string="will meet on Friday and is expected to lift the ban" type="VP">
          <tokens>
            <token id="3" string="will" />
            <token id="4" string="meet" />
            <token id="5" string="on" />
            <token id="6" string="Friday" />
            <token id="7" string="and" />
            <token id="8" string="is" />
            <token id="9" string="expected" />
            <token id="10" string="to" />
            <token id="11" string="lift" />
            <token id="12" string="the" />
            <token id="13" string="ban" />
          </tokens>
        </chunking>
        <chunking id="9" string="will meet on Friday" type="VP">
          <tokens>
            <token id="3" string="will" />
            <token id="4" string="meet" />
            <token id="5" string="on" />
            <token id="6" string="Friday" />
          </tokens>
        </chunking>
        <chunking id="10" string="lift the ban" type="VP">
          <tokens>
            <token id="11" string="lift" />
            <token id="12" string="the" />
            <token id="13" string="ban" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">COA</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">meet</governor>
          <dependent id="2">COA</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">meet</governor>
          <dependent id="3">will</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">meet</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Friday</governor>
          <dependent id="5">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">meet</governor>
          <dependent id="6">Friday</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">meet</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="9">expected</governor>
          <dependent id="8">is</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">meet</governor>
          <dependent id="9">expected</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">lift</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">expected</governor>
          <dependent id="11">lift</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">ban</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">lift</governor>
          <dependent id="13">ban</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Friday" type="DATE" score="0.0">
          <tokens>
            <token id="6" string="Friday" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="106" has_coreference="true">
      <content>That may go a long way to easing Johnson back into a sport that disowned him almost as swiftly as he burst on the scene.</content>
      <tokens>
        <token id="1" string="That" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="go" lemma="go" stem="go" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="long" lemma="long" stem="long" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="way" lemma="way" stem="wai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="easing" lemma="ease" stem="eas" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="10" string="back" lemma="back" stem="back" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="sport" lemma="sport" stem="sport" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="disowned" lemma="disown" stem="disown" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="almost" lemma="almost" stem="almost" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="swiftly" lemma="swiftly" stem="swiftli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="burst" lemma="burst" stem="burst" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="scene" lemma="scene" stem="scene" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT That)) (VP (MD may) (VP (VB go) (NP (DT a) (JJ long) (NN way)) (PP (TO to) (S (VP (VBG easing) (NP (NNP Johnson)) (ADVP (RB back)) (PP (IN into) (NP (NP (DT a) (NN sport)) (SBAR (WHNP (WDT that)) (S (VP (VBD disowned) (NP (PRP him)) (ADVP (RB almost) (PP (IN as) (ADVP (RB swiftly)))) (SBAR (IN as) (S (NP (PRP he)) (VP (VB burst) (PP (IN on) (NP (DT the) (NN scene)))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a sport that disowned him almost as swiftly as he burst on the scene" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="sport" />
            <token id="14" string="that" />
            <token id="15" string="disowned" />
            <token id="16" string="him" />
            <token id="17" string="almost" />
            <token id="18" string="as" />
            <token id="19" string="swiftly" />
            <token id="20" string="as" />
            <token id="21" string="he" />
            <token id="22" string="burst" />
            <token id="23" string="on" />
            <token id="24" string="the" />
            <token id="25" string="scene" />
          </tokens>
        </chunking>
        <chunking id="2" string="That" type="NP">
          <tokens>
            <token id="1" string="That" />
          </tokens>
        </chunking>
        <chunking id="3" string="Johnson" type="NP">
          <tokens>
            <token id="9" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="4" string="easing Johnson back into a sport that disowned him almost as swiftly as he burst on the scene" type="VP">
          <tokens>
            <token id="8" string="easing" />
            <token id="9" string="Johnson" />
            <token id="10" string="back" />
            <token id="11" string="into" />
            <token id="12" string="a" />
            <token id="13" string="sport" />
            <token id="14" string="that" />
            <token id="15" string="disowned" />
            <token id="16" string="him" />
            <token id="17" string="almost" />
            <token id="18" string="as" />
            <token id="19" string="swiftly" />
            <token id="20" string="as" />
            <token id="21" string="he" />
            <token id="22" string="burst" />
            <token id="23" string="on" />
            <token id="24" string="the" />
            <token id="25" string="scene" />
          </tokens>
        </chunking>
        <chunking id="5" string="go a long way to easing Johnson back into a sport that disowned him almost as swiftly as he burst on the scene" type="VP">
          <tokens>
            <token id="3" string="go" />
            <token id="4" string="a" />
            <token id="5" string="long" />
            <token id="6" string="way" />
            <token id="7" string="to" />
            <token id="8" string="easing" />
            <token id="9" string="Johnson" />
            <token id="10" string="back" />
            <token id="11" string="into" />
            <token id="12" string="a" />
            <token id="13" string="sport" />
            <token id="14" string="that" />
            <token id="15" string="disowned" />
            <token id="16" string="him" />
            <token id="17" string="almost" />
            <token id="18" string="as" />
            <token id="19" string="swiftly" />
            <token id="20" string="as" />
            <token id="21" string="he" />
            <token id="22" string="burst" />
            <token id="23" string="on" />
            <token id="24" string="the" />
            <token id="25" string="scene" />
          </tokens>
        </chunking>
        <chunking id="6" string="disowned him almost as swiftly as he burst on the scene" type="VP">
          <tokens>
            <token id="15" string="disowned" />
            <token id="16" string="him" />
            <token id="17" string="almost" />
            <token id="18" string="as" />
            <token id="19" string="swiftly" />
            <token id="20" string="as" />
            <token id="21" string="he" />
            <token id="22" string="burst" />
            <token id="23" string="on" />
            <token id="24" string="the" />
            <token id="25" string="scene" />
          </tokens>
        </chunking>
        <chunking id="7" string="him" type="NP">
          <tokens>
            <token id="16" string="him" />
          </tokens>
        </chunking>
        <chunking id="8" string="may go a long way to easing Johnson back into a sport that disowned him almost as swiftly as he burst on the scene" type="VP">
          <tokens>
            <token id="2" string="may" />
            <token id="3" string="go" />
            <token id="4" string="a" />
            <token id="5" string="long" />
            <token id="6" string="way" />
            <token id="7" string="to" />
            <token id="8" string="easing" />
            <token id="9" string="Johnson" />
            <token id="10" string="back" />
            <token id="11" string="into" />
            <token id="12" string="a" />
            <token id="13" string="sport" />
            <token id="14" string="that" />
            <token id="15" string="disowned" />
            <token id="16" string="him" />
            <token id="17" string="almost" />
            <token id="18" string="as" />
            <token id="19" string="swiftly" />
            <token id="20" string="as" />
            <token id="21" string="he" />
            <token id="22" string="burst" />
            <token id="23" string="on" />
            <token id="24" string="the" />
            <token id="25" string="scene" />
          </tokens>
        </chunking>
        <chunking id="9" string="a long way" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="long" />
            <token id="6" string="way" />
          </tokens>
        </chunking>
        <chunking id="10" string="the scene" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="scene" />
          </tokens>
        </chunking>
        <chunking id="11" string="burst on the scene" type="VP">
          <tokens>
            <token id="22" string="burst" />
            <token id="23" string="on" />
            <token id="24" string="the" />
            <token id="25" string="scene" />
          </tokens>
        </chunking>
        <chunking id="12" string="a sport" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="sport" />
          </tokens>
        </chunking>
        <chunking id="13" string="that disowned him almost as swiftly as he burst on the scene" type="SBAR">
          <tokens>
            <token id="14" string="that" />
            <token id="15" string="disowned" />
            <token id="16" string="him" />
            <token id="17" string="almost" />
            <token id="18" string="as" />
            <token id="19" string="swiftly" />
            <token id="20" string="as" />
            <token id="21" string="he" />
            <token id="22" string="burst" />
            <token id="23" string="on" />
            <token id="24" string="the" />
            <token id="25" string="scene" />
          </tokens>
        </chunking>
        <chunking id="14" string="as he burst on the scene" type="SBAR">
          <tokens>
            <token id="20" string="as" />
            <token id="21" string="he" />
            <token id="22" string="burst" />
            <token id="23" string="on" />
            <token id="24" string="the" />
            <token id="25" string="scene" />
          </tokens>
        </chunking>
        <chunking id="15" string="he" type="NP">
          <tokens>
            <token id="21" string="he" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">go</governor>
          <dependent id="1">That</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">go</governor>
          <dependent id="2">may</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">go</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">way</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">way</governor>
          <dependent id="5">long</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">go</governor>
          <dependent id="6">way</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">easing</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">go</governor>
          <dependent id="8">easing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">easing</governor>
          <dependent id="9">Johnson</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">easing</governor>
          <dependent id="10">back</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">sport</governor>
          <dependent id="11">into</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">sport</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">easing</governor>
          <dependent id="13">sport</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">disowned</governor>
          <dependent id="14">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="13">sport</governor>
          <dependent id="15">disowned</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">disowned</governor>
          <dependent id="16">him</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">disowned</governor>
          <dependent id="17">almost</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">swiftly</governor>
          <dependent id="18">as</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="17">almost</governor>
          <dependent id="19">swiftly</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">burst</governor>
          <dependent id="20">as</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">burst</governor>
          <dependent id="21">he</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="15">disowned</governor>
          <dependent id="22">burst</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">scene</governor>
          <dependent id="23">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">scene</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">burst</governor>
          <dependent id="25">scene</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Johnson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="107" has_coreference="true">
      <content>What happened to Johnson after his positive test in Seoul is similar to what used to happen to famous East Europeans after defection.</content>
      <tokens>
        <token id="1" string="What" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="happened" lemma="happen" stem="happen" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="5" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="positive" lemma="positive" stem="posit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="test" lemma="test" stem="test" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Seoul" lemma="Seoul" stem="seoul" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="11" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="similar" lemma="similar" stem="similar" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="used" lemma="use" stem="us" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="happen" lemma="happen" stem="happen" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="famous" lemma="famous" stem="famou" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="East" lemma="East" stem="east" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="21" string="Europeans" lemma="Europeans" stem="european" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="22" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="defection" lemma="defection" stem="defect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (WHNP (WP What)) (S (VP (VBD happened) (PP (TO to) (NP (NNP Johnson))) (PP (IN after) (NP (NP (PRP$ his) (JJ positive) (NN test)) (PP (IN in) (NP (NNP Seoul)))))))) (VP (VBZ is) (ADJP (JJ similar) (PP (TO to) (SBAR (WHNP (WP what)) (S (VP (VBD used) (S (VP (TO to) (VP (VB happen) (PP (TO to) (NP (JJ famous) (NNP East) (NNPS Europeans))) (PP (IN after) (NP (NN defection)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Johnson" type="NP">
          <tokens>
            <token id="4" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="2" string="is similar to what used to happen to famous East Europeans after defection" type="VP">
          <tokens>
            <token id="11" string="is" />
            <token id="12" string="similar" />
            <token id="13" string="to" />
            <token id="14" string="what" />
            <token id="15" string="used" />
            <token id="16" string="to" />
            <token id="17" string="happen" />
            <token id="18" string="to" />
            <token id="19" string="famous" />
            <token id="20" string="East" />
            <token id="21" string="Europeans" />
            <token id="22" string="after" />
            <token id="23" string="defection" />
          </tokens>
        </chunking>
        <chunking id="3" string="happen to famous East Europeans after defection" type="VP">
          <tokens>
            <token id="17" string="happen" />
            <token id="18" string="to" />
            <token id="19" string="famous" />
            <token id="20" string="East" />
            <token id="21" string="Europeans" />
            <token id="22" string="after" />
            <token id="23" string="defection" />
          </tokens>
        </chunking>
        <chunking id="4" string="defection" type="NP">
          <tokens>
            <token id="23" string="defection" />
          </tokens>
        </chunking>
        <chunking id="5" string="what used to happen to famous East Europeans after defection" type="SBAR">
          <tokens>
            <token id="14" string="what" />
            <token id="15" string="used" />
            <token id="16" string="to" />
            <token id="17" string="happen" />
            <token id="18" string="to" />
            <token id="19" string="famous" />
            <token id="20" string="East" />
            <token id="21" string="Europeans" />
            <token id="22" string="after" />
            <token id="23" string="defection" />
          </tokens>
        </chunking>
        <chunking id="6" string="What happened to Johnson after his positive test in Seoul" type="SBAR">
          <tokens>
            <token id="1" string="What" />
            <token id="2" string="happened" />
            <token id="3" string="to" />
            <token id="4" string="Johnson" />
            <token id="5" string="after" />
            <token id="6" string="his" />
            <token id="7" string="positive" />
            <token id="8" string="test" />
            <token id="9" string="in" />
            <token id="10" string="Seoul" />
          </tokens>
        </chunking>
        <chunking id="7" string="similar to what used to happen to famous East Europeans after defection" type="ADJP">
          <tokens>
            <token id="12" string="similar" />
            <token id="13" string="to" />
            <token id="14" string="what" />
            <token id="15" string="used" />
            <token id="16" string="to" />
            <token id="17" string="happen" />
            <token id="18" string="to" />
            <token id="19" string="famous" />
            <token id="20" string="East" />
            <token id="21" string="Europeans" />
            <token id="22" string="after" />
            <token id="23" string="defection" />
          </tokens>
        </chunking>
        <chunking id="8" string="his positive test in Seoul" type="NP">
          <tokens>
            <token id="6" string="his" />
            <token id="7" string="positive" />
            <token id="8" string="test" />
            <token id="9" string="in" />
            <token id="10" string="Seoul" />
          </tokens>
        </chunking>
        <chunking id="9" string="used to happen to famous East Europeans after defection" type="VP">
          <tokens>
            <token id="15" string="used" />
            <token id="16" string="to" />
            <token id="17" string="happen" />
            <token id="18" string="to" />
            <token id="19" string="famous" />
            <token id="20" string="East" />
            <token id="21" string="Europeans" />
            <token id="22" string="after" />
            <token id="23" string="defection" />
          </tokens>
        </chunking>
        <chunking id="10" string="his positive test" type="NP">
          <tokens>
            <token id="6" string="his" />
            <token id="7" string="positive" />
            <token id="8" string="test" />
          </tokens>
        </chunking>
        <chunking id="11" string="famous East Europeans" type="NP">
          <tokens>
            <token id="19" string="famous" />
            <token id="20" string="East" />
            <token id="21" string="Europeans" />
          </tokens>
        </chunking>
        <chunking id="12" string="Seoul" type="NP">
          <tokens>
            <token id="10" string="Seoul" />
          </tokens>
        </chunking>
        <chunking id="13" string="happened to Johnson after his positive test in Seoul" type="VP">
          <tokens>
            <token id="2" string="happened" />
            <token id="3" string="to" />
            <token id="4" string="Johnson" />
            <token id="5" string="after" />
            <token id="6" string="his" />
            <token id="7" string="positive" />
            <token id="8" string="test" />
            <token id="9" string="in" />
            <token id="10" string="Seoul" />
          </tokens>
        </chunking>
        <chunking id="14" string="to happen to famous East Europeans after defection" type="VP">
          <tokens>
            <token id="16" string="to" />
            <token id="17" string="happen" />
            <token id="18" string="to" />
            <token id="19" string="famous" />
            <token id="20" string="East" />
            <token id="21" string="Europeans" />
            <token id="22" string="after" />
            <token id="23" string="defection" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">happened</governor>
          <dependent id="1">What</dependent>
        </dependency>
        <dependency type="csubj">
          <governor id="12">similar</governor>
          <dependent id="2">happened</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">Johnson</governor>
          <dependent id="3">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">happened</governor>
          <dependent id="4">Johnson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">test</governor>
          <dependent id="5">after</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">test</governor>
          <dependent id="6">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">test</governor>
          <dependent id="7">positive</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">happened</governor>
          <dependent id="8">test</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Seoul</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">test</governor>
          <dependent id="10">Seoul</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">similar</governor>
          <dependent id="11">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">similar</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">used</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">used</governor>
          <dependent id="14">what</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">similar</governor>
          <dependent id="15">used</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">happen</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="15">used</governor>
          <dependent id="17">happen</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">Europeans</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">Europeans</governor>
          <dependent id="19">famous</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">Europeans</governor>
          <dependent id="20">East</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">happen</governor>
          <dependent id="21">Europeans</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">defection</governor>
          <dependent id="22">after</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">happen</governor>
          <dependent id="23">defection</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="Seoul" type="LOCATION" score="0.0">
          <tokens>
            <token id="10" string="Seoul" />
          </tokens>
        </entity>
        <entity id="3" string="East Europeans" type="MISC" score="0.0">
          <tokens>
            <token id="20" string="East" />
            <token id="21" string="Europeans" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="108" has_coreference="true">
      <content>Any trace of them in their former countries disappeared.</content>
      <tokens>
        <token id="1" string="Any" lemma="any" stem="any" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="trace" lemma="trace" stem="trace" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="former" lemma="former" stem="former" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="countries" lemma="country" stem="countri" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="disappeared" lemma="disappear" stem="disappear" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT Any) (NN trace)) (PP (IN of) (NP (NP (PRP them)) (PP (IN in) (NP (PRP$ their) (JJ former) (NNS countries)))))) (VP (VBD disappeared)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Any trace" type="NP">
          <tokens>
            <token id="1" string="Any" />
            <token id="2" string="trace" />
          </tokens>
        </chunking>
        <chunking id="2" string="disappeared" type="VP">
          <tokens>
            <token id="9" string="disappeared" />
          </tokens>
        </chunking>
        <chunking id="3" string="them in their former countries" type="NP">
          <tokens>
            <token id="4" string="them" />
            <token id="5" string="in" />
            <token id="6" string="their" />
            <token id="7" string="former" />
            <token id="8" string="countries" />
          </tokens>
        </chunking>
        <chunking id="4" string="them" type="NP">
          <tokens>
            <token id="4" string="them" />
          </tokens>
        </chunking>
        <chunking id="5" string="Any trace of them in their former countries" type="NP">
          <tokens>
            <token id="1" string="Any" />
            <token id="2" string="trace" />
            <token id="3" string="of" />
            <token id="4" string="them" />
            <token id="5" string="in" />
            <token id="6" string="their" />
            <token id="7" string="former" />
            <token id="8" string="countries" />
          </tokens>
        </chunking>
        <chunking id="6" string="their former countries" type="NP">
          <tokens>
            <token id="6" string="their" />
            <token id="7" string="former" />
            <token id="8" string="countries" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">trace</governor>
          <dependent id="1">Any</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">disappeared</governor>
          <dependent id="2">trace</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">them</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">trace</governor>
          <dependent id="4">them</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">countries</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">countries</governor>
          <dependent id="6">their</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">countries</governor>
          <dependent id="7">former</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">them</governor>
          <dependent id="8">countries</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">disappeared</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="109" has_coreference="true">
      <content>They no longer existed.</content>
      <tokens>
        <token id="1" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="no" lemma="no" stem="no" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="longer" lemma="longer" stem="longer" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="existed" lemma="exist" stem="exist" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP They)) (ADVP (RB no) (RB longer)) (VP (VBD existed)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="1" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="existed" type="VP">
          <tokens>
            <token id="4" string="existed" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">existed</governor>
          <dependent id="1">They</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="3">longer</governor>
          <dependent id="2">no</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">existed</governor>
          <dependent id="3">longer</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">existed</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="110" has_coreference="true">
      <content>Similarly, Johnson was erased from track and field&amp;apost;s record books.</content>
      <tokens>
        <token id="1" string="Similarly" lemma="similarly" stem="similarli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="erased" lemma="erase" stem="eras" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="track" lemma="track" stem="track" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="field" lemma="field" stem="field" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="record" lemma="record" stem="record" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="books" lemma="book" stem="book" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Similarly)) (, ,) (NP (NNP Johnson)) (VP (VBD was) (VP (VBN erased) (PP (IN from) (NP (NP (NN track)) (CC and) (NP (NP (NN field) (POS 's)) (NN record) (NNS books)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Johnson" type="NP">
          <tokens>
            <token id="3" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="2" string="field 's record books" type="NP">
          <tokens>
            <token id="9" string="field" />
            <token id="10" string="'s" />
            <token id="11" string="record" />
            <token id="12" string="books" />
          </tokens>
        </chunking>
        <chunking id="3" string="was erased from track and field 's record books" type="VP">
          <tokens>
            <token id="4" string="was" />
            <token id="5" string="erased" />
            <token id="6" string="from" />
            <token id="7" string="track" />
            <token id="8" string="and" />
            <token id="9" string="field" />
            <token id="10" string="'s" />
            <token id="11" string="record" />
            <token id="12" string="books" />
          </tokens>
        </chunking>
        <chunking id="4" string="erased from track and field 's record books" type="VP">
          <tokens>
            <token id="5" string="erased" />
            <token id="6" string="from" />
            <token id="7" string="track" />
            <token id="8" string="and" />
            <token id="9" string="field" />
            <token id="10" string="'s" />
            <token id="11" string="record" />
            <token id="12" string="books" />
          </tokens>
        </chunking>
        <chunking id="5" string="track" type="NP">
          <tokens>
            <token id="7" string="track" />
          </tokens>
        </chunking>
        <chunking id="6" string="field 's" type="NP">
          <tokens>
            <token id="9" string="field" />
            <token id="10" string="'s" />
          </tokens>
        </chunking>
        <chunking id="7" string="track and field 's record books" type="NP">
          <tokens>
            <token id="7" string="track" />
            <token id="8" string="and" />
            <token id="9" string="field" />
            <token id="10" string="'s" />
            <token id="11" string="record" />
            <token id="12" string="books" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="5">erased</governor>
          <dependent id="1">Similarly</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="5">erased</governor>
          <dependent id="3">Johnson</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">erased</governor>
          <dependent id="4">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">erased</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">track</governor>
          <dependent id="6">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">erased</governor>
          <dependent id="7">track</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">track</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">books</governor>
          <dependent id="9">field</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">field</governor>
          <dependent id="10">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">books</governor>
          <dependent id="11">record</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">track</governor>
          <dependent id="12">books</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Johnson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="111" has_coreference="true">
      <content>Not only did he have to give back the gold medal, but he lost two world records, causing the sport to change its rules in order to take them.</content>
      <tokens>
        <token id="1" string="Not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="give" lemma="give" stem="give" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="back" lemma="back" stem="back" pos="RP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="gold" lemma="gold" stem="gold" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="medal" lemma="medal" stem="medal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="lost" lemma="lose" stem="lost" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="17" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="records" lemma="record" stem="record" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="causing" lemma="cause" stem="caus" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="sport" lemma="sport" stem="sport" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="change" lemma="change" stem="chang" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="rules" lemma="rule" stem="rule" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="order" lemma="order" stem="order" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="take" lemma="take" stem="take" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CONJP (RB Not) (RB only)) (SINV (VBD did) (NP (PRP he)) (VP (VB have) (S (VP (TO to) (VP (VB give) (PRT (RP back)) (NP (DT the) (NN gold) (NN medal))))))) (, ,) (CC but) (S (NP (PRP he)) (VP (VBD lost) (NP (CD two) (NN world) (NNS records)) (, ,) (S (VP (VBG causing) (NP (DT the) (NN sport) (S (VP (TO to) (VP (VB change) (NP (PRP$ its) (NNS rules)) (SBAR (IN in) (NN order) (S (VP (TO to) (VP (VB take) (NP (PRP them)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="change its rules in order to take them" type="VP">
          <tokens>
            <token id="24" string="change" />
            <token id="25" string="its" />
            <token id="26" string="rules" />
            <token id="27" string="in" />
            <token id="28" string="order" />
            <token id="29" string="to" />
            <token id="30" string="take" />
            <token id="31" string="them" />
          </tokens>
        </chunking>
        <chunking id="2" string="its rules" type="NP">
          <tokens>
            <token id="25" string="its" />
            <token id="26" string="rules" />
          </tokens>
        </chunking>
        <chunking id="3" string="lost two world records , causing the sport to change its rules in order to take them" type="VP">
          <tokens>
            <token id="15" string="lost" />
            <token id="16" string="two" />
            <token id="17" string="world" />
            <token id="18" string="records" />
            <token id="19" string="," />
            <token id="20" string="causing" />
            <token id="21" string="the" />
            <token id="22" string="sport" />
            <token id="23" string="to" />
            <token id="24" string="change" />
            <token id="25" string="its" />
            <token id="26" string="rules" />
            <token id="27" string="in" />
            <token id="28" string="order" />
            <token id="29" string="to" />
            <token id="30" string="take" />
            <token id="31" string="them" />
          </tokens>
        </chunking>
        <chunking id="4" string="to change its rules in order to take them" type="VP">
          <tokens>
            <token id="23" string="to" />
            <token id="24" string="change" />
            <token id="25" string="its" />
            <token id="26" string="rules" />
            <token id="27" string="in" />
            <token id="28" string="order" />
            <token id="29" string="to" />
            <token id="30" string="take" />
            <token id="31" string="them" />
          </tokens>
        </chunking>
        <chunking id="5" string="to give back the gold medal" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="give" />
            <token id="8" string="back" />
            <token id="9" string="the" />
            <token id="10" string="gold" />
            <token id="11" string="medal" />
          </tokens>
        </chunking>
        <chunking id="6" string="them" type="NP">
          <tokens>
            <token id="31" string="them" />
          </tokens>
        </chunking>
        <chunking id="7" string="give back the gold medal" type="VP">
          <tokens>
            <token id="7" string="give" />
            <token id="8" string="back" />
            <token id="9" string="the" />
            <token id="10" string="gold" />
            <token id="11" string="medal" />
          </tokens>
        </chunking>
        <chunking id="8" string="the gold medal" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="gold" />
            <token id="11" string="medal" />
          </tokens>
        </chunking>
        <chunking id="9" string="two world records" type="NP">
          <tokens>
            <token id="16" string="two" />
            <token id="17" string="world" />
            <token id="18" string="records" />
          </tokens>
        </chunking>
        <chunking id="10" string="the sport to change its rules in order to take them" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="sport" />
            <token id="23" string="to" />
            <token id="24" string="change" />
            <token id="25" string="its" />
            <token id="26" string="rules" />
            <token id="27" string="in" />
            <token id="28" string="order" />
            <token id="29" string="to" />
            <token id="30" string="take" />
            <token id="31" string="them" />
          </tokens>
        </chunking>
        <chunking id="11" string="have to give back the gold medal" type="VP">
          <tokens>
            <token id="5" string="have" />
            <token id="6" string="to" />
            <token id="7" string="give" />
            <token id="8" string="back" />
            <token id="9" string="the" />
            <token id="10" string="gold" />
            <token id="11" string="medal" />
          </tokens>
        </chunking>
        <chunking id="12" string="take them" type="VP">
          <tokens>
            <token id="30" string="take" />
            <token id="31" string="them" />
          </tokens>
        </chunking>
        <chunking id="13" string="causing the sport to change its rules in order to take them" type="VP">
          <tokens>
            <token id="20" string="causing" />
            <token id="21" string="the" />
            <token id="22" string="sport" />
            <token id="23" string="to" />
            <token id="24" string="change" />
            <token id="25" string="its" />
            <token id="26" string="rules" />
            <token id="27" string="in" />
            <token id="28" string="order" />
            <token id="29" string="to" />
            <token id="30" string="take" />
            <token id="31" string="them" />
          </tokens>
        </chunking>
        <chunking id="14" string="to take them" type="VP">
          <tokens>
            <token id="29" string="to" />
            <token id="30" string="take" />
            <token id="31" string="them" />
          </tokens>
        </chunking>
        <chunking id="15" string="he" type="NP">
          <tokens>
            <token id="4" string="he" />
          </tokens>
        </chunking>
        <chunking id="16" string="in order to take them" type="SBAR">
          <tokens>
            <token id="27" string="in" />
            <token id="28" string="order" />
            <token id="29" string="to" />
            <token id="30" string="take" />
            <token id="31" string="them" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="neg">
          <governor id="2">only</governor>
          <dependent id="1">Not</dependent>
        </dependency>
        <dependency type="cc:preconj">
          <governor id="5">have</governor>
          <dependent id="2">only</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">have</governor>
          <dependent id="3">did</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">have</governor>
          <dependent id="4">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">have</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">give</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">have</governor>
          <dependent id="7">give</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="7">give</governor>
          <dependent id="8">back</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">medal</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">medal</governor>
          <dependent id="10">gold</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">give</governor>
          <dependent id="11">medal</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">have</governor>
          <dependent id="13">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">lost</governor>
          <dependent id="14">he</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">have</governor>
          <dependent id="15">lost</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="18">records</governor>
          <dependent id="16">two</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">records</governor>
          <dependent id="17">world</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">lost</governor>
          <dependent id="18">records</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="15">lost</governor>
          <dependent id="20">causing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">sport</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">causing</governor>
          <dependent id="22">sport</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">change</governor>
          <dependent id="23">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="22">sport</governor>
          <dependent id="24">change</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="26">rules</governor>
          <dependent id="25">its</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">change</governor>
          <dependent id="26">rules</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="30">take</governor>
          <dependent id="27">in</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="27">in</governor>
          <dependent id="28">order</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="30">take</governor>
          <dependent id="29">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="24">change</governor>
          <dependent id="30">take</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="30">take</governor>
          <dependent id="31">them</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="16" string="two" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="112" has_coreference="true">
      <content>The IAAF voted last September to adopt the controversial &amp;quot;Ben Johnson Rule&amp;quot; allowing the IAAF Council to decertify an athlete&amp;apost;s records, titles and results if he or she later is shown to have used a banned substance before those performances.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="IAAF" lemma="iaaf" stem="iaaf" pos="NN" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="3" string="voted" lemma="vote" stem="vote" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="September" lemma="September" stem="septemb" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="adopt" lemma="adopt" stem="adopt" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="controversial" lemma="controversial" stem="controversi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Ben" lemma="Ben" stem="ben" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="Rule" lemma="Rule" stem="rule" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="allowing" lemma="allow" stem="allow" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="IAAF" lemma="IAAF" stem="iaaf" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="18" string="Council" lemma="Council" stem="council" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="19" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="decertify" lemma="decertify" stem="decertifi" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="athlete" lemma="athlete" stem="athlet" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="records" lemma="record" stem="record" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="titles" lemma="title" stem="titl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="results" lemma="result" stem="result" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="32" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="33" string="later" lemma="later" stem="later" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="shown" lemma="show" stem="shown" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="used" lemma="use" stem="us" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="banned" lemma="ban" stem="ban" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="substance" lemma="substance" stem="substanc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="performances" lemma="performance" stem="perform" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN IAAF)) (VP (VP (VBD voted) (NP-TMP (JJ last) (NNP September)) (S (VP (TO to) (VP (VB adopt) (NP (NP (DT the) (JJ controversial)) (`` ``) (NP (NNP Ben) (NNP Johnson) (NNP Rule)) ('' '')) (S (VP (VBG allowing) (S (NP (DT the) (NNP IAAF) (NNP Council)) (VP (TO to) (VP (VB decertify) (NP (NP (NP (DT an) (NN athlete) (POS 's)) (NNS records)) (, ,) (NP (NNS titles)))))))))))) (CC and) (VP (VBZ results) (SBAR (IN if) (S (NP (PRP he) (CC or) (PRP she)) (ADVP (RB later)) (VP (VBZ is) (VP (VBN shown) (S (VP (TO to) (VP (VB have) (VP (VBN used) (NP (DT a) (VBN banned) (NN substance)) (PP (IN before) (NP (DT those) (NNS performances))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="to have used a banned substance before those performances" type="VP">
          <tokens>
            <token id="36" string="to" />
            <token id="37" string="have" />
            <token id="38" string="used" />
            <token id="39" string="a" />
            <token id="40" string="banned" />
            <token id="41" string="substance" />
            <token id="42" string="before" />
            <token id="43" string="those" />
            <token id="44" string="performances" />
          </tokens>
        </chunking>
        <chunking id="2" string="an athlete 's records" type="NP">
          <tokens>
            <token id="21" string="an" />
            <token id="22" string="athlete" />
            <token id="23" string="'s" />
            <token id="24" string="records" />
          </tokens>
        </chunking>
        <chunking id="3" string="titles" type="NP">
          <tokens>
            <token id="26" string="titles" />
          </tokens>
        </chunking>
        <chunking id="4" string="voted last September to adopt the controversial `` Ben Johnson Rule '' allowing the IAAF Council to decertify an athlete 's records , titles and results if he or she later is shown to have used a banned substance before those performances" type="VP">
          <tokens>
            <token id="3" string="voted" />
            <token id="4" string="last" />
            <token id="5" string="September" />
            <token id="6" string="to" />
            <token id="7" string="adopt" />
            <token id="8" string="the" />
            <token id="9" string="controversial" />
            <token id="10" string="&quot;" />
            <token id="11" string="Ben" />
            <token id="12" string="Johnson" />
            <token id="13" string="Rule" />
            <token id="14" string="&quot;" />
            <token id="15" string="allowing" />
            <token id="16" string="the" />
            <token id="17" string="IAAF" />
            <token id="18" string="Council" />
            <token id="19" string="to" />
            <token id="20" string="decertify" />
            <token id="21" string="an" />
            <token id="22" string="athlete" />
            <token id="23" string="'s" />
            <token id="24" string="records" />
            <token id="25" string="," />
            <token id="26" string="titles" />
            <token id="27" string="and" />
            <token id="28" string="results" />
            <token id="29" string="if" />
            <token id="30" string="he" />
            <token id="31" string="or" />
            <token id="32" string="she" />
            <token id="33" string="later" />
            <token id="34" string="is" />
            <token id="35" string="shown" />
            <token id="36" string="to" />
            <token id="37" string="have" />
            <token id="38" string="used" />
            <token id="39" string="a" />
            <token id="40" string="banned" />
            <token id="41" string="substance" />
            <token id="42" string="before" />
            <token id="43" string="those" />
            <token id="44" string="performances" />
          </tokens>
        </chunking>
        <chunking id="5" string="to adopt the controversial `` Ben Johnson Rule '' allowing the IAAF Council to decertify an athlete 's records , titles" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="adopt" />
            <token id="8" string="the" />
            <token id="9" string="controversial" />
            <token id="10" string="&quot;" />
            <token id="11" string="Ben" />
            <token id="12" string="Johnson" />
            <token id="13" string="Rule" />
            <token id="14" string="&quot;" />
            <token id="15" string="allowing" />
            <token id="16" string="the" />
            <token id="17" string="IAAF" />
            <token id="18" string="Council" />
            <token id="19" string="to" />
            <token id="20" string="decertify" />
            <token id="21" string="an" />
            <token id="22" string="athlete" />
            <token id="23" string="'s" />
            <token id="24" string="records" />
            <token id="25" string="," />
            <token id="26" string="titles" />
          </tokens>
        </chunking>
        <chunking id="6" string="the controversial" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="controversial" />
          </tokens>
        </chunking>
        <chunking id="7" string="used a banned substance before those performances" type="VP">
          <tokens>
            <token id="38" string="used" />
            <token id="39" string="a" />
            <token id="40" string="banned" />
            <token id="41" string="substance" />
            <token id="42" string="before" />
            <token id="43" string="those" />
            <token id="44" string="performances" />
          </tokens>
        </chunking>
        <chunking id="8" string="to decertify an athlete 's records , titles" type="VP">
          <tokens>
            <token id="19" string="to" />
            <token id="20" string="decertify" />
            <token id="21" string="an" />
            <token id="22" string="athlete" />
            <token id="23" string="'s" />
            <token id="24" string="records" />
            <token id="25" string="," />
            <token id="26" string="titles" />
          </tokens>
        </chunking>
        <chunking id="9" string="is shown to have used a banned substance before those performances" type="VP">
          <tokens>
            <token id="34" string="is" />
            <token id="35" string="shown" />
            <token id="36" string="to" />
            <token id="37" string="have" />
            <token id="38" string="used" />
            <token id="39" string="a" />
            <token id="40" string="banned" />
            <token id="41" string="substance" />
            <token id="42" string="before" />
            <token id="43" string="those" />
            <token id="44" string="performances" />
          </tokens>
        </chunking>
        <chunking id="10" string="adopt the controversial `` Ben Johnson Rule '' allowing the IAAF Council to decertify an athlete 's records , titles" type="VP">
          <tokens>
            <token id="7" string="adopt" />
            <token id="8" string="the" />
            <token id="9" string="controversial" />
            <token id="10" string="&quot;" />
            <token id="11" string="Ben" />
            <token id="12" string="Johnson" />
            <token id="13" string="Rule" />
            <token id="14" string="&quot;" />
            <token id="15" string="allowing" />
            <token id="16" string="the" />
            <token id="17" string="IAAF" />
            <token id="18" string="Council" />
            <token id="19" string="to" />
            <token id="20" string="decertify" />
            <token id="21" string="an" />
            <token id="22" string="athlete" />
            <token id="23" string="'s" />
            <token id="24" string="records" />
            <token id="25" string="," />
            <token id="26" string="titles" />
          </tokens>
        </chunking>
        <chunking id="11" string="The IAAF" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="IAAF" />
          </tokens>
        </chunking>
        <chunking id="12" string="have used a banned substance before those performances" type="VP">
          <tokens>
            <token id="37" string="have" />
            <token id="38" string="used" />
            <token id="39" string="a" />
            <token id="40" string="banned" />
            <token id="41" string="substance" />
            <token id="42" string="before" />
            <token id="43" string="those" />
            <token id="44" string="performances" />
          </tokens>
        </chunking>
        <chunking id="13" string="a banned substance" type="NP">
          <tokens>
            <token id="39" string="a" />
            <token id="40" string="banned" />
            <token id="41" string="substance" />
          </tokens>
        </chunking>
        <chunking id="14" string="decertify an athlete 's records , titles" type="VP">
          <tokens>
            <token id="20" string="decertify" />
            <token id="21" string="an" />
            <token id="22" string="athlete" />
            <token id="23" string="'s" />
            <token id="24" string="records" />
            <token id="25" string="," />
            <token id="26" string="titles" />
          </tokens>
        </chunking>
        <chunking id="15" string="allowing the IAAF Council to decertify an athlete 's records , titles" type="VP">
          <tokens>
            <token id="15" string="allowing" />
            <token id="16" string="the" />
            <token id="17" string="IAAF" />
            <token id="18" string="Council" />
            <token id="19" string="to" />
            <token id="20" string="decertify" />
            <token id="21" string="an" />
            <token id="22" string="athlete" />
            <token id="23" string="'s" />
            <token id="24" string="records" />
            <token id="25" string="," />
            <token id="26" string="titles" />
          </tokens>
        </chunking>
        <chunking id="16" string="results if he or she later is shown to have used a banned substance before those performances" type="VP">
          <tokens>
            <token id="28" string="results" />
            <token id="29" string="if" />
            <token id="30" string="he" />
            <token id="31" string="or" />
            <token id="32" string="she" />
            <token id="33" string="later" />
            <token id="34" string="is" />
            <token id="35" string="shown" />
            <token id="36" string="to" />
            <token id="37" string="have" />
            <token id="38" string="used" />
            <token id="39" string="a" />
            <token id="40" string="banned" />
            <token id="41" string="substance" />
            <token id="42" string="before" />
            <token id="43" string="those" />
            <token id="44" string="performances" />
          </tokens>
        </chunking>
        <chunking id="17" string="the IAAF Council" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="IAAF" />
            <token id="18" string="Council" />
          </tokens>
        </chunking>
        <chunking id="18" string="an athlete 's" type="NP">
          <tokens>
            <token id="21" string="an" />
            <token id="22" string="athlete" />
            <token id="23" string="'s" />
          </tokens>
        </chunking>
        <chunking id="19" string="voted last September to adopt the controversial `` Ben Johnson Rule '' allowing the IAAF Council to decertify an athlete 's records , titles" type="VP">
          <tokens>
            <token id="3" string="voted" />
            <token id="4" string="last" />
            <token id="5" string="September" />
            <token id="6" string="to" />
            <token id="7" string="adopt" />
            <token id="8" string="the" />
            <token id="9" string="controversial" />
            <token id="10" string="&quot;" />
            <token id="11" string="Ben" />
            <token id="12" string="Johnson" />
            <token id="13" string="Rule" />
            <token id="14" string="&quot;" />
            <token id="15" string="allowing" />
            <token id="16" string="the" />
            <token id="17" string="IAAF" />
            <token id="18" string="Council" />
            <token id="19" string="to" />
            <token id="20" string="decertify" />
            <token id="21" string="an" />
            <token id="22" string="athlete" />
            <token id="23" string="'s" />
            <token id="24" string="records" />
            <token id="25" string="," />
            <token id="26" string="titles" />
          </tokens>
        </chunking>
        <chunking id="20" string="shown to have used a banned substance before those performances" type="VP">
          <tokens>
            <token id="35" string="shown" />
            <token id="36" string="to" />
            <token id="37" string="have" />
            <token id="38" string="used" />
            <token id="39" string="a" />
            <token id="40" string="banned" />
            <token id="41" string="substance" />
            <token id="42" string="before" />
            <token id="43" string="those" />
            <token id="44" string="performances" />
          </tokens>
        </chunking>
        <chunking id="21" string="an athlete 's records , titles" type="NP">
          <tokens>
            <token id="21" string="an" />
            <token id="22" string="athlete" />
            <token id="23" string="'s" />
            <token id="24" string="records" />
            <token id="25" string="," />
            <token id="26" string="titles" />
          </tokens>
        </chunking>
        <chunking id="22" string="if he or she later is shown to have used a banned substance before those performances" type="SBAR">
          <tokens>
            <token id="29" string="if" />
            <token id="30" string="he" />
            <token id="31" string="or" />
            <token id="32" string="she" />
            <token id="33" string="later" />
            <token id="34" string="is" />
            <token id="35" string="shown" />
            <token id="36" string="to" />
            <token id="37" string="have" />
            <token id="38" string="used" />
            <token id="39" string="a" />
            <token id="40" string="banned" />
            <token id="41" string="substance" />
            <token id="42" string="before" />
            <token id="43" string="those" />
            <token id="44" string="performances" />
          </tokens>
        </chunking>
        <chunking id="23" string="those performances" type="NP">
          <tokens>
            <token id="43" string="those" />
            <token id="44" string="performances" />
          </tokens>
        </chunking>
        <chunking id="24" string="Ben Johnson Rule" type="NP">
          <tokens>
            <token id="11" string="Ben" />
            <token id="12" string="Johnson" />
            <token id="13" string="Rule" />
          </tokens>
        </chunking>
        <chunking id="25" string="he or she" type="NP">
          <tokens>
            <token id="30" string="he" />
            <token id="31" string="or" />
            <token id="32" string="she" />
          </tokens>
        </chunking>
        <chunking id="26" string="the controversial `` Ben Johnson Rule ''" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="controversial" />
            <token id="10" string="&quot;" />
            <token id="11" string="Ben" />
            <token id="12" string="Johnson" />
            <token id="13" string="Rule" />
            <token id="14" string="&quot;" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">IAAF</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">voted</governor>
          <dependent id="2">IAAF</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">voted</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">September</governor>
          <dependent id="4">last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="3">voted</governor>
          <dependent id="5">September</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">adopt</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">voted</governor>
          <dependent id="7">adopt</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">controversial</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">adopt</governor>
          <dependent id="9">controversial</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Rule</governor>
          <dependent id="11">Ben</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Rule</governor>
          <dependent id="12">Johnson</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="9">controversial</governor>
          <dependent id="13">Rule</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">adopt</governor>
          <dependent id="15">allowing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">Council</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Council</governor>
          <dependent id="17">IAAF</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">allowing</governor>
          <dependent id="18">Council</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">decertify</governor>
          <dependent id="19">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="15">allowing</governor>
          <dependent id="20">decertify</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">athlete</governor>
          <dependent id="21">an</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="24">records</governor>
          <dependent id="22">athlete</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">athlete</governor>
          <dependent id="23">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">decertify</governor>
          <dependent id="24">records</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="24">records</governor>
          <dependent id="26">titles</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">voted</governor>
          <dependent id="27">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">voted</governor>
          <dependent id="28">results</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="35">shown</governor>
          <dependent id="29">if</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="35">shown</governor>
          <dependent id="30">he</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="30">he</governor>
          <dependent id="31">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="30">he</governor>
          <dependent id="32">she</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="35">shown</governor>
          <dependent id="33">later</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="35">shown</governor>
          <dependent id="34">is</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="28">results</governor>
          <dependent id="35">shown</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="38">used</governor>
          <dependent id="36">to</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="38">used</governor>
          <dependent id="37">have</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="35">shown</governor>
          <dependent id="38">used</dependent>
        </dependency>
        <dependency type="det">
          <governor id="41">substance</governor>
          <dependent id="39">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="41">substance</governor>
          <dependent id="40">banned</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="38">used</governor>
          <dependent id="41">substance</dependent>
        </dependency>
        <dependency type="case">
          <governor id="44">performances</governor>
          <dependent id="42">before</dependent>
        </dependency>
        <dependency type="det">
          <governor id="44">performances</governor>
          <dependent id="43">those</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="38">used</governor>
          <dependent id="44">performances</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="IAAF Council" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="17" string="IAAF" />
            <token id="18" string="Council" />
          </tokens>
        </entity>
        <entity id="2" string="IAAF" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="2" string="IAAF" />
          </tokens>
        </entity>
        <entity id="3" string="last September" type="DATE" score="0.0">
          <tokens>
            <token id="4" string="last" />
            <token id="5" string="September" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="113" has_coreference="false">
      <content>The action gave the IAAF power to erase all of Johnson&amp;apost;s results between June 12, 1983, and June 12, 1989.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="action" lemma="action" stem="action" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="gave" lemma="give" stem="gave" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="IAAF" lemma="iaaf" stem="iaaf" pos="NN" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="6" string="power" lemma="power" stem="power" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="erase" lemma="erase" stem="eras" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="12" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="results" lemma="result" stem="result" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="between" lemma="between" stem="between" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="June" lemma="June" stem="june" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="16" string="12" lemma="12" stem="12" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="18" string="1983" lemma="1983" stem="1983" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="June" lemma="June" stem="june" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="22" string="12" lemma="12" stem="12" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="24" string="1989" lemma="1989" stem="1989" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN action)) (VP (VBD gave) (NP (DT the) (NN IAAF) (NN power)) (S (VP (TO to) (VP (VB erase) (NP (NP (DT all)) (PP (IN of) (NP (NP (NNP Johnson) (POS 's)) (NNS results)))) (PP (IN between) (NP (NP (NNP June) (CD 12) (, ,) (CD 1983) (, ,)) (CC and) (NP (NNP June) (CD 12) (, ,) (CD 1989)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="all" type="NP">
          <tokens>
            <token id="9" string="all" />
          </tokens>
        </chunking>
        <chunking id="2" string="the IAAF power" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="IAAF" />
            <token id="6" string="power" />
          </tokens>
        </chunking>
        <chunking id="3" string="to erase all of Johnson 's results between June 12 , 1983 , and June 12 , 1989" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="erase" />
            <token id="9" string="all" />
            <token id="10" string="of" />
            <token id="11" string="Johnson" />
            <token id="12" string="'s" />
            <token id="13" string="results" />
            <token id="14" string="between" />
            <token id="15" string="June" />
            <token id="16" string="12" />
            <token id="17" string="," />
            <token id="18" string="1983" />
            <token id="19" string="," />
            <token id="20" string="and" />
            <token id="21" string="June" />
            <token id="22" string="12" />
            <token id="23" string="," />
            <token id="24" string="1989" />
          </tokens>
        </chunking>
        <chunking id="4" string="Johnson 's results" type="NP">
          <tokens>
            <token id="11" string="Johnson" />
            <token id="12" string="'s" />
            <token id="13" string="results" />
          </tokens>
        </chunking>
        <chunking id="5" string="June 12 , 1983 , and June 12 , 1989" type="NP">
          <tokens>
            <token id="15" string="June" />
            <token id="16" string="12" />
            <token id="17" string="," />
            <token id="18" string="1983" />
            <token id="19" string="," />
            <token id="20" string="and" />
            <token id="21" string="June" />
            <token id="22" string="12" />
            <token id="23" string="," />
            <token id="24" string="1989" />
          </tokens>
        </chunking>
        <chunking id="6" string="June 12 , 1983 ," type="NP">
          <tokens>
            <token id="15" string="June" />
            <token id="16" string="12" />
            <token id="17" string="," />
            <token id="18" string="1983" />
            <token id="19" string="," />
          </tokens>
        </chunking>
        <chunking id="7" string="The action" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="action" />
          </tokens>
        </chunking>
        <chunking id="8" string="June 12 , 1989" type="NP">
          <tokens>
            <token id="21" string="June" />
            <token id="22" string="12" />
            <token id="23" string="," />
            <token id="24" string="1989" />
          </tokens>
        </chunking>
        <chunking id="9" string="gave the IAAF power to erase all of Johnson 's results between June 12 , 1983 , and June 12 , 1989" type="VP">
          <tokens>
            <token id="3" string="gave" />
            <token id="4" string="the" />
            <token id="5" string="IAAF" />
            <token id="6" string="power" />
            <token id="7" string="to" />
            <token id="8" string="erase" />
            <token id="9" string="all" />
            <token id="10" string="of" />
            <token id="11" string="Johnson" />
            <token id="12" string="'s" />
            <token id="13" string="results" />
            <token id="14" string="between" />
            <token id="15" string="June" />
            <token id="16" string="12" />
            <token id="17" string="," />
            <token id="18" string="1983" />
            <token id="19" string="," />
            <token id="20" string="and" />
            <token id="21" string="June" />
            <token id="22" string="12" />
            <token id="23" string="," />
            <token id="24" string="1989" />
          </tokens>
        </chunking>
        <chunking id="10" string="erase all of Johnson 's results between June 12 , 1983 , and June 12 , 1989" type="VP">
          <tokens>
            <token id="8" string="erase" />
            <token id="9" string="all" />
            <token id="10" string="of" />
            <token id="11" string="Johnson" />
            <token id="12" string="'s" />
            <token id="13" string="results" />
            <token id="14" string="between" />
            <token id="15" string="June" />
            <token id="16" string="12" />
            <token id="17" string="," />
            <token id="18" string="1983" />
            <token id="19" string="," />
            <token id="20" string="and" />
            <token id="21" string="June" />
            <token id="22" string="12" />
            <token id="23" string="," />
            <token id="24" string="1989" />
          </tokens>
        </chunking>
        <chunking id="11" string="Johnson 's" type="NP">
          <tokens>
            <token id="11" string="Johnson" />
            <token id="12" string="'s" />
          </tokens>
        </chunking>
        <chunking id="12" string="all of Johnson 's results" type="NP">
          <tokens>
            <token id="9" string="all" />
            <token id="10" string="of" />
            <token id="11" string="Johnson" />
            <token id="12" string="'s" />
            <token id="13" string="results" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">action</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">gave</governor>
          <dependent id="2">action</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">gave</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">power</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">power</governor>
          <dependent id="5">IAAF</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">gave</governor>
          <dependent id="6">power</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">erase</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">gave</governor>
          <dependent id="8">erase</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">erase</governor>
          <dependent id="9">all</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">results</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">results</governor>
          <dependent id="11">Johnson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Johnson</governor>
          <dependent id="12">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">all</governor>
          <dependent id="13">results</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">June</governor>
          <dependent id="14">between</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">erase</governor>
          <dependent id="15">June</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="15">June</governor>
          <dependent id="16">12</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="15">June</governor>
          <dependent id="18">1983</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">June</governor>
          <dependent id="20">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">June</governor>
          <dependent id="21">June</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="21">June</governor>
          <dependent id="22">12</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="21">June</governor>
          <dependent id="24">1989</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="June 12 , 1983" type="DATE" score="0.0">
          <tokens>
            <token id="15" string="June" />
            <token id="16" string="12" />
            <token id="17" string="," />
            <token id="18" string="1983" />
          </tokens>
        </entity>
        <entity id="2" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Johnson" />
          </tokens>
        </entity>
        <entity id="3" string="June 12 , 1989" type="DATE" score="0.0">
          <tokens>
            <token id="21" string="June" />
            <token id="22" string="12" />
            <token id="23" string="," />
            <token id="24" string="1989" />
          </tokens>
        </entity>
        <entity id="4" string="IAAF" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="5" string="IAAF" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="114" has_coreference="true">
      <content>Even though Johnson admitted to having taken drugs since 1981, the rule carries a six-year statue of limitations.</content>
      <tokens>
        <token id="1" string="Even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="though" lemma="though" stem="though" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="admitted" lemma="admit" stem="admit" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="having" lemma="have" stem="have" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="taken" lemma="take" stem="taken" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="drugs" lemma="drug" stem="drug" pos="NNS" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="true" />
        <token id="9" string="since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="1981" lemma="1981" stem="1981" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="rule" lemma="rule" stem="rule" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="carries" lemma="carry" stem="carri" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="six-year" lemma="six-year" stem="six-year" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="17" string="statue" lemma="statue" stem="statu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="limitations" lemma="limitation" stem="limit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (RB Even) (IN though) (S (NP (NNP Johnson)) (VP (VBD admitted) (PP (TO to) (S (VP (VBG having) (VP (VBN taken) (NP (NNS drugs)) (PP (IN since) (NP (CD 1981)))))))))) (, ,) (NP (DT the) (NN rule)) (VP (VBZ carries) (NP (NP (DT a) (JJ six-year) (NN statue)) (PP (IN of) (NP (NNS limitations))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Johnson" type="NP">
          <tokens>
            <token id="3" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="2" string="Even though Johnson admitted to having taken drugs since 1981" type="SBAR">
          <tokens>
            <token id="1" string="Even" />
            <token id="2" string="though" />
            <token id="3" string="Johnson" />
            <token id="4" string="admitted" />
            <token id="5" string="to" />
            <token id="6" string="having" />
            <token id="7" string="taken" />
            <token id="8" string="drugs" />
            <token id="9" string="since" />
            <token id="10" string="1981" />
          </tokens>
        </chunking>
        <chunking id="3" string="drugs" type="NP">
          <tokens>
            <token id="8" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="4" string="carries a six-year statue of limitations" type="VP">
          <tokens>
            <token id="14" string="carries" />
            <token id="15" string="a" />
            <token id="16" string="six-year" />
            <token id="17" string="statue" />
            <token id="18" string="of" />
            <token id="19" string="limitations" />
          </tokens>
        </chunking>
        <chunking id="5" string="taken drugs since 1981" type="VP">
          <tokens>
            <token id="7" string="taken" />
            <token id="8" string="drugs" />
            <token id="9" string="since" />
            <token id="10" string="1981" />
          </tokens>
        </chunking>
        <chunking id="6" string="1981" type="NP">
          <tokens>
            <token id="10" string="1981" />
          </tokens>
        </chunking>
        <chunking id="7" string="the rule" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="rule" />
          </tokens>
        </chunking>
        <chunking id="8" string="admitted to having taken drugs since 1981" type="VP">
          <tokens>
            <token id="4" string="admitted" />
            <token id="5" string="to" />
            <token id="6" string="having" />
            <token id="7" string="taken" />
            <token id="8" string="drugs" />
            <token id="9" string="since" />
            <token id="10" string="1981" />
          </tokens>
        </chunking>
        <chunking id="9" string="a six-year statue of limitations" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="six-year" />
            <token id="17" string="statue" />
            <token id="18" string="of" />
            <token id="19" string="limitations" />
          </tokens>
        </chunking>
        <chunking id="10" string="a six-year statue" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="six-year" />
            <token id="17" string="statue" />
          </tokens>
        </chunking>
        <chunking id="11" string="having taken drugs since 1981" type="VP">
          <tokens>
            <token id="6" string="having" />
            <token id="7" string="taken" />
            <token id="8" string="drugs" />
            <token id="9" string="since" />
            <token id="10" string="1981" />
          </tokens>
        </chunking>
        <chunking id="12" string="limitations" type="NP">
          <tokens>
            <token id="19" string="limitations" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="4">admitted</governor>
          <dependent id="1">Even</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="4">admitted</governor>
          <dependent id="2">though</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">admitted</governor>
          <dependent id="3">Johnson</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="14">carries</governor>
          <dependent id="4">admitted</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">taken</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">taken</governor>
          <dependent id="6">having</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">admitted</governor>
          <dependent id="7">taken</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">taken</governor>
          <dependent id="8">drugs</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">1981</governor>
          <dependent id="9">since</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">taken</governor>
          <dependent id="10">1981</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">rule</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">carries</governor>
          <dependent id="13">rule</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">carries</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">statue</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">statue</governor>
          <dependent id="16">six-year</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">carries</governor>
          <dependent id="17">statue</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">limitations</governor>
          <dependent id="18">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">statue</governor>
          <dependent id="19">limitations</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="drugs" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="8" string="drugs" />
          </tokens>
        </entity>
        <entity id="3" string="1981" type="DATE" score="0.0">
          <tokens>
            <token id="10" string="1981" />
          </tokens>
        </entity>
        <entity id="4" string="six-year" type="DURATION" score="0.0">
          <tokens>
            <token id="16" string="six-year" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="115" has_coreference="true">
      <content>The rule stripped Johnson of his world record of 9.83 in the 100 meters and 6.41 in the indoor 60 meters.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="rule" lemma="rule" stem="rule" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="stripped" lemma="strip" stem="strip" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="record" lemma="record" stem="record" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="9.83" lemma="9.83" stem="9.83" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="100" lemma="100" stem="100" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="14" string="meters" lemma="meter" stem="meter" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="6.41" lemma="6.41" stem="6.41" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="17" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="indoor" lemma="indoor" stem="indoor" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="60" lemma="60" stem="60" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="21" string="meters" lemma="meter" stem="meter" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN rule)) (VP (VBD stripped) (NP (NP (NNP Johnson)) (PP (IN of) (NP (NP (PRP$ his) (NN world) (NN record)) (PP (IN of) (NP (CD 9.83)))))) (PP (IN in) (NP (NP (DT the) (CD 100) (NNS meters)) (CC and) (NP (CD 6.41)))) (PP (IN in) (NP (DT the) (JJ indoor) (CD 60) (NNS meters)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="his world record of 9.83" type="NP">
          <tokens>
            <token id="6" string="his" />
            <token id="7" string="world" />
            <token id="8" string="record" />
            <token id="9" string="of" />
            <token id="10" string="9.83" />
          </tokens>
        </chunking>
        <chunking id="2" string="Johnson" type="NP">
          <tokens>
            <token id="4" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="3" string="9.83" type="NP">
          <tokens>
            <token id="10" string="9.83" />
          </tokens>
        </chunking>
        <chunking id="4" string="The rule" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="rule" />
          </tokens>
        </chunking>
        <chunking id="5" string="the 100 meters and 6.41" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="100" />
            <token id="14" string="meters" />
            <token id="15" string="and" />
            <token id="16" string="6.41" />
          </tokens>
        </chunking>
        <chunking id="6" string="the indoor 60 meters" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="indoor" />
            <token id="20" string="60" />
            <token id="21" string="meters" />
          </tokens>
        </chunking>
        <chunking id="7" string="the 100 meters" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="100" />
            <token id="14" string="meters" />
          </tokens>
        </chunking>
        <chunking id="8" string="Johnson of his world record of 9.83" type="NP">
          <tokens>
            <token id="4" string="Johnson" />
            <token id="5" string="of" />
            <token id="6" string="his" />
            <token id="7" string="world" />
            <token id="8" string="record" />
            <token id="9" string="of" />
            <token id="10" string="9.83" />
          </tokens>
        </chunking>
        <chunking id="9" string="stripped Johnson of his world record of 9.83 in the 100 meters and 6.41 in the indoor 60 meters" type="VP">
          <tokens>
            <token id="3" string="stripped" />
            <token id="4" string="Johnson" />
            <token id="5" string="of" />
            <token id="6" string="his" />
            <token id="7" string="world" />
            <token id="8" string="record" />
            <token id="9" string="of" />
            <token id="10" string="9.83" />
            <token id="11" string="in" />
            <token id="12" string="the" />
            <token id="13" string="100" />
            <token id="14" string="meters" />
            <token id="15" string="and" />
            <token id="16" string="6.41" />
            <token id="17" string="in" />
            <token id="18" string="the" />
            <token id="19" string="indoor" />
            <token id="20" string="60" />
            <token id="21" string="meters" />
          </tokens>
        </chunking>
        <chunking id="10" string="his world record" type="NP">
          <tokens>
            <token id="6" string="his" />
            <token id="7" string="world" />
            <token id="8" string="record" />
          </tokens>
        </chunking>
        <chunking id="11" string="6.41" type="NP">
          <tokens>
            <token id="16" string="6.41" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">rule</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">stripped</governor>
          <dependent id="2">rule</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">stripped</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">stripped</governor>
          <dependent id="4">Johnson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">record</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">record</governor>
          <dependent id="6">his</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">record</governor>
          <dependent id="7">world</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">Johnson</governor>
          <dependent id="8">record</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">9.83</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">record</governor>
          <dependent id="10">9.83</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">meters</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">meters</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="14">meters</governor>
          <dependent id="13">100</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">stripped</governor>
          <dependent id="14">meters</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">meters</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">meters</governor>
          <dependent id="16">6.41</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">meters</governor>
          <dependent id="17">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">meters</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">meters</governor>
          <dependent id="19">indoor</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="21">meters</governor>
          <dependent id="20">60</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">stripped</governor>
          <dependent id="21">meters</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="100" type="NUMBER" score="0.0">
          <tokens>
            <token id="13" string="100" />
          </tokens>
        </entity>
        <entity id="2" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Johnson" />
          </tokens>
        </entity>
        <entity id="3" string="9.83" type="NUMBER" score="0.0">
          <tokens>
            <token id="10" string="9.83" />
          </tokens>
        </entity>
        <entity id="4" string="60" type="NUMBER" score="0.0">
          <tokens>
            <token id="20" string="60" />
          </tokens>
        </entity>
        <entity id="5" string="6.41" type="NUMBER" score="0.0">
          <tokens>
            <token id="16" string="6.41" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="116" has_coreference="true">
      <content>Already gone was the 9.79 race from the Olympics.</content>
      <tokens>
        <token id="1" string="Already" lemma="already" stem="alreadi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="gone" lemma="go" stem="gone" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="9.79" lemma="9.79" stem="9.79" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="6" string="race" lemma="race" stem="race" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="Olympics" lemma="Olympics" stem="olympic" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (ADVP (RB Already)) (VBN gone))) (VP (VBD was) (NP (NP (DT the) (CD 9.79) (NN race)) (PP (IN from) (NP (DT the) (NNPS Olympics))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the 9.79 race from the Olympics" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="9.79" />
            <token id="6" string="race" />
            <token id="7" string="from" />
            <token id="8" string="the" />
            <token id="9" string="Olympics" />
          </tokens>
        </chunking>
        <chunking id="2" string="the 9.79 race" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="9.79" />
            <token id="6" string="race" />
          </tokens>
        </chunking>
        <chunking id="3" string="the Olympics" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="Olympics" />
          </tokens>
        </chunking>
        <chunking id="4" string="was the 9.79 race from the Olympics" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="the" />
            <token id="5" string="9.79" />
            <token id="6" string="race" />
            <token id="7" string="from" />
            <token id="8" string="the" />
            <token id="9" string="Olympics" />
          </tokens>
        </chunking>
        <chunking id="5" string="Already gone" type="VP">
          <tokens>
            <token id="1" string="Already" />
            <token id="2" string="gone" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="2">gone</governor>
          <dependent id="1">Already</dependent>
        </dependency>
        <dependency type="csubj">
          <governor id="6">race</governor>
          <dependent id="2">gone</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">race</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">race</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="6">race</governor>
          <dependent id="5">9.79</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">race</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Olympics</governor>
          <dependent id="7">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">Olympics</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">race</governor>
          <dependent id="9">Olympics</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Olympics" type="MISC" score="0.0">
          <tokens>
            <token id="9" string="Olympics" />
          </tokens>
        </entity>
        <entity id="2" string="9.79" type="NUMBER" score="0.0">
          <tokens>
            <token id="5" string="9.79" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="117" has_coreference="true">
      <content>The records are gone but not forgotten.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="records" lemma="record" stem="record" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="gone" lemma="go" stem="gone" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="forgotten" lemma="forget" stem="forgotten" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNS records)) (VP (VBP are) (VP (VBN gone) (CONJP (CC but) (RB not)) (VBN forgotten))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="gone but not forgotten" type="VP">
          <tokens>
            <token id="4" string="gone" />
            <token id="5" string="but" />
            <token id="6" string="not" />
            <token id="7" string="forgotten" />
          </tokens>
        </chunking>
        <chunking id="2" string="The records" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="records" />
          </tokens>
        </chunking>
        <chunking id="3" string="are gone but not forgotten" type="VP">
          <tokens>
            <token id="3" string="are" />
            <token id="4" string="gone" />
            <token id="5" string="but" />
            <token id="6" string="not" />
            <token id="7" string="forgotten" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">records</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="4">gone</governor>
          <dependent id="2">records</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">gone</governor>
          <dependent id="3">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">gone</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">not</governor>
          <dependent id="5">but</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">gone</governor>
          <dependent id="6">not</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">gone</governor>
          <dependent id="7">forgotten</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="118" has_coreference="false">
      <content>The question remains, is Ben Johnson capable of running at that brilliant level again?</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="question" lemma="question" stem="question" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="remains" lemma="remain" stem="remain" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Ben" lemma="Ben" stem="ben" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="7" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="8" string="capable" lemma="capable" stem="capabl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="running" lemma="run" stem="run" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="brilliant" lemma="brilliant" stem="brilliant" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="level" lemma="level" stem="level" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="again" lemma="again" stem="again" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SQ (S (NP (DT The) (NN question)) (VP (VBZ remains))) (, ,) (SQ (VBZ is) (NP (NNP Ben) (NNP Johnson)) (ADJP (JJ capable) (PP (IN of) (S (VP (VBG running) (PP (IN at) (NP (DT that) (JJ brilliant) (NN level))) (ADVP (RB again))))))) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Ben Johnson" type="NP">
          <tokens>
            <token id="6" string="Ben" />
            <token id="7" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="2" string="that brilliant level" type="NP">
          <tokens>
            <token id="12" string="that" />
            <token id="13" string="brilliant" />
            <token id="14" string="level" />
          </tokens>
        </chunking>
        <chunking id="3" string="The question" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="question" />
          </tokens>
        </chunking>
        <chunking id="4" string="running at that brilliant level again" type="VP">
          <tokens>
            <token id="10" string="running" />
            <token id="11" string="at" />
            <token id="12" string="that" />
            <token id="13" string="brilliant" />
            <token id="14" string="level" />
            <token id="15" string="again" />
          </tokens>
        </chunking>
        <chunking id="5" string="remains" type="VP">
          <tokens>
            <token id="3" string="remains" />
          </tokens>
        </chunking>
        <chunking id="6" string="capable of running at that brilliant level again" type="ADJP">
          <tokens>
            <token id="8" string="capable" />
            <token id="9" string="of" />
            <token id="10" string="running" />
            <token id="11" string="at" />
            <token id="12" string="that" />
            <token id="13" string="brilliant" />
            <token id="14" string="level" />
            <token id="15" string="again" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">question</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">remains</governor>
          <dependent id="2">question</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="8">capable</governor>
          <dependent id="3">remains</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">capable</governor>
          <dependent id="5">is</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Johnson</governor>
          <dependent id="6">Ben</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">capable</governor>
          <dependent id="7">Johnson</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">capable</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">running</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="8">capable</governor>
          <dependent id="10">running</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">level</governor>
          <dependent id="11">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">level</governor>
          <dependent id="12">that</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">level</governor>
          <dependent id="13">brilliant</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">running</governor>
          <dependent id="14">level</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">running</governor>
          <dependent id="15">again</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ben Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Ben" />
            <token id="7" string="Johnson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="119" has_coreference="false">
      <content>Meet promoters are willing to pay to find out.</content>
      <tokens>
        <token id="1" string="Meet" lemma="Meet" stem="meet" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="promoters" lemma="promoter" stem="promot" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="willing" lemma="willing" stem="will" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="pay" lemma="pay" stem="pai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="find" lemma="find" stem="find" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Meet) (NNS promoters)) (VP (VBP are) (ADJP (JJ willing) (S (VP (TO to) (VP (VB pay) (S (VP (TO to) (VP (VB find) (PRT (RP out)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="to pay to find out" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="pay" />
            <token id="7" string="to" />
            <token id="8" string="find" />
            <token id="9" string="out" />
          </tokens>
        </chunking>
        <chunking id="2" string="are willing to pay to find out" type="VP">
          <tokens>
            <token id="3" string="are" />
            <token id="4" string="willing" />
            <token id="5" string="to" />
            <token id="6" string="pay" />
            <token id="7" string="to" />
            <token id="8" string="find" />
            <token id="9" string="out" />
          </tokens>
        </chunking>
        <chunking id="3" string="to find out" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="find" />
            <token id="9" string="out" />
          </tokens>
        </chunking>
        <chunking id="4" string="find out" type="VP">
          <tokens>
            <token id="8" string="find" />
            <token id="9" string="out" />
          </tokens>
        </chunking>
        <chunking id="5" string="willing to pay to find out" type="ADJP">
          <tokens>
            <token id="4" string="willing" />
            <token id="5" string="to" />
            <token id="6" string="pay" />
            <token id="7" string="to" />
            <token id="8" string="find" />
            <token id="9" string="out" />
          </tokens>
        </chunking>
        <chunking id="6" string="pay to find out" type="VP">
          <tokens>
            <token id="6" string="pay" />
            <token id="7" string="to" />
            <token id="8" string="find" />
            <token id="9" string="out" />
          </tokens>
        </chunking>
        <chunking id="7" string="Meet promoters" type="NP">
          <tokens>
            <token id="1" string="Meet" />
            <token id="2" string="promoters" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">promoters</governor>
          <dependent id="1">Meet</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">willing</governor>
          <dependent id="2">promoters</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">willing</governor>
          <dependent id="3">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">willing</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">pay</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">willing</governor>
          <dependent id="6">pay</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">find</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">pay</governor>
          <dependent id="8">find</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="8">find</governor>
          <dependent id="9">out</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="120" has_coreference="true">
      <content>If the public will pay to watch Johnson is another question.</content>
      <tokens>
        <token id="1" string="If" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="public" lemma="public" stem="public" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="pay" lemma="pay" stem="pai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="watch" lemma="watch" stem="watch" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="9" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="another" lemma="another" stem="anoth" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="question" lemma="question" stem="question" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN If) (S (NP (DT the) (NN public)) (VP (MD will) (VP (VB pay) (S (VP (TO to) (VP (VB watch) (NP (NNP Johnson))))))))) (VP (VBZ is) (NP (DT another) (NN question))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="If the public will pay to watch Johnson" type="SBAR">
          <tokens>
            <token id="1" string="If" />
            <token id="2" string="the" />
            <token id="3" string="public" />
            <token id="4" string="will" />
            <token id="5" string="pay" />
            <token id="6" string="to" />
            <token id="7" string="watch" />
            <token id="8" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="2" string="Johnson" type="NP">
          <tokens>
            <token id="8" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="3" string="another question" type="NP">
          <tokens>
            <token id="10" string="another" />
            <token id="11" string="question" />
          </tokens>
        </chunking>
        <chunking id="4" string="will pay to watch Johnson" type="VP">
          <tokens>
            <token id="4" string="will" />
            <token id="5" string="pay" />
            <token id="6" string="to" />
            <token id="7" string="watch" />
            <token id="8" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="5" string="watch Johnson" type="VP">
          <tokens>
            <token id="7" string="watch" />
            <token id="8" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="6" string="the public" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="public" />
          </tokens>
        </chunking>
        <chunking id="7" string="to watch Johnson" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="watch" />
            <token id="8" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="8" string="is another question" type="VP">
          <tokens>
            <token id="9" string="is" />
            <token id="10" string="another" />
            <token id="11" string="question" />
          </tokens>
        </chunking>
        <chunking id="9" string="pay to watch Johnson" type="VP">
          <tokens>
            <token id="5" string="pay" />
            <token id="6" string="to" />
            <token id="7" string="watch" />
            <token id="8" string="Johnson" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="5">pay</governor>
          <dependent id="1">If</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">public</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">pay</governor>
          <dependent id="3">public</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">pay</governor>
          <dependent id="4">will</dependent>
        </dependency>
        <dependency type="csubj">
          <governor id="11">question</governor>
          <dependent id="5">pay</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">watch</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">pay</governor>
          <dependent id="7">watch</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">watch</governor>
          <dependent id="8">Johnson</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">question</governor>
          <dependent id="9">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">question</governor>
          <dependent id="10">another</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">question</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Johnson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="121" has_coreference="true">
      <content>Said Lumpp of the Meadowlands, &amp;quot;You don&amp;apost;t have just a track and field story here, you have a human interest story.</content>
      <tokens>
        <token id="1" string="Said" lemma="Said" stem="said" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="Lumpp" lemma="Lumpp" stem="lumpp" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="Meadowlands" lemma="Meadowlands" stem="meadowland" pos="NNPS" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="You" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="9" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="14" string="track" lemma="track" stem="track" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="field" lemma="field" stem="field" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="story" lemma="story" stem="stori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="here" lemma="here" stem="here" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="human" lemma="human" stem="human" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="24" string="interest" lemma="interest" stem="interest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="25" string="story" lemma="story" stem="stori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (NNP Said) (NNP Lumpp)) (PP (IN of) (NP (DT the) (NNPS Meadowlands))) (, ,) (S (`` ``) (NP (PRP You)) (VP (VBP do) (RB n't) (VP (VB have) (NP (NP (RB just) (DT a) (NN track)) (CC and) (NP (NN field) (NN story))) (ADVP (RB here))))) (, ,) (S (NP (PRP you)) (VP (VBP have) (NP (DT a) (JJ human) (NN interest) (NN story)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="just a track and field story" type="NP">
          <tokens>
            <token id="12" string="just" />
            <token id="13" string="a" />
            <token id="14" string="track" />
            <token id="15" string="and" />
            <token id="16" string="field" />
            <token id="17" string="story" />
          </tokens>
        </chunking>
        <chunking id="2" string="the Meadowlands" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="Meadowlands" />
          </tokens>
        </chunking>
        <chunking id="3" string="have a human interest story" type="VP">
          <tokens>
            <token id="21" string="have" />
            <token id="22" string="a" />
            <token id="23" string="human" />
            <token id="24" string="interest" />
            <token id="25" string="story" />
          </tokens>
        </chunking>
        <chunking id="4" string="Said Lumpp" type="NP">
          <tokens>
            <token id="1" string="Said" />
            <token id="2" string="Lumpp" />
          </tokens>
        </chunking>
        <chunking id="5" string="do n't have just a track and field story here" type="VP">
          <tokens>
            <token id="9" string="do" />
            <token id="10" string="n't" />
            <token id="11" string="have" />
            <token id="12" string="just" />
            <token id="13" string="a" />
            <token id="14" string="track" />
            <token id="15" string="and" />
            <token id="16" string="field" />
            <token id="17" string="story" />
            <token id="18" string="here" />
          </tokens>
        </chunking>
        <chunking id="6" string="Said Lumpp of the Meadowlands , `` You do n't have just a track and field story here , you have a human interest story ." type="NP">
          <tokens>
            <token id="1" string="Said" />
            <token id="2" string="Lumpp" />
            <token id="3" string="of" />
            <token id="4" string="the" />
            <token id="5" string="Meadowlands" />
            <token id="6" string="," />
            <token id="7" string="&quot;" />
            <token id="8" string="You" />
            <token id="9" string="do" />
            <token id="10" string="n't" />
            <token id="11" string="have" />
            <token id="12" string="just" />
            <token id="13" string="a" />
            <token id="14" string="track" />
            <token id="15" string="and" />
            <token id="16" string="field" />
            <token id="17" string="story" />
            <token id="18" string="here" />
            <token id="19" string="," />
            <token id="20" string="you" />
            <token id="21" string="have" />
            <token id="22" string="a" />
            <token id="23" string="human" />
            <token id="24" string="interest" />
            <token id="25" string="story" />
            <token id="26" string="." />
          </tokens>
        </chunking>
        <chunking id="7" string="have just a track and field story here" type="VP">
          <tokens>
            <token id="11" string="have" />
            <token id="12" string="just" />
            <token id="13" string="a" />
            <token id="14" string="track" />
            <token id="15" string="and" />
            <token id="16" string="field" />
            <token id="17" string="story" />
            <token id="18" string="here" />
          </tokens>
        </chunking>
        <chunking id="8" string="field story" type="NP">
          <tokens>
            <token id="16" string="field" />
            <token id="17" string="story" />
          </tokens>
        </chunking>
        <chunking id="9" string="just a track" type="NP">
          <tokens>
            <token id="12" string="just" />
            <token id="13" string="a" />
            <token id="14" string="track" />
          </tokens>
        </chunking>
        <chunking id="10" string="You" type="NP">
          <tokens>
            <token id="8" string="You" />
          </tokens>
        </chunking>
        <chunking id="11" string="you" type="NP">
          <tokens>
            <token id="20" string="you" />
          </tokens>
        </chunking>
        <chunking id="12" string="a human interest story" type="NP">
          <tokens>
            <token id="22" string="a" />
            <token id="23" string="human" />
            <token id="24" string="interest" />
            <token id="25" string="story" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Lumpp</governor>
          <dependent id="1">Said</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">Lumpp</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">Meadowlands</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">Meadowlands</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">Lumpp</governor>
          <dependent id="5">Meadowlands</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">have</governor>
          <dependent id="8">You</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">have</governor>
          <dependent id="9">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="11">have</governor>
          <dependent id="10">n't</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="2">Lumpp</governor>
          <dependent id="11">have</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">track</governor>
          <dependent id="12">just</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">track</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">have</governor>
          <dependent id="14">track</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">track</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">story</governor>
          <dependent id="16">field</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">track</governor>
          <dependent id="17">story</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">have</governor>
          <dependent id="18">here</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">have</governor>
          <dependent id="20">you</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="2">Lumpp</governor>
          <dependent id="21">have</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">story</governor>
          <dependent id="22">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">story</governor>
          <dependent id="23">human</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">story</governor>
          <dependent id="24">interest</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">have</governor>
          <dependent id="25">story</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Said Lumpp" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Said" />
            <token id="2" string="Lumpp" />
          </tokens>
        </entity>
        <entity id="2" string="Meadowlands" type="LOCATION" score="0.0">
          <tokens>
            <token id="5" string="Meadowlands" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="122" has_coreference="true">
      <content>Here&amp;apost;s a person who has reached the top of everything, lost it all, and now he&amp;apost;s coming back to run.</content>
      <tokens>
        <token id="1" string="Here" lemma="here" stem="here" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="person" lemma="person" stem="person" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="reached" lemma="reach" stem="reach" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="top" lemma="top" stem="top" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="everything" lemma="everything" stem="everyth" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="lost" lemma="lose" stem="lost" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="all" lemma="all" stem="all" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="19" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="coming" lemma="come" stem="come" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="back" lemma="back" stem="back" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="run" lemma="run" stem="run" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (RB Here)) (VP (VBZ 's) (NP (NP (DT a) (NN person)) (SBAR (WHNP (WP who)) (S (VP (VBZ has) (VP (VBN reached) (NP (NP (DT the) (NN top)) (PP (IN of) (NP (NN everything))))))))))) (PRN (, ,) (SINV (VP (VBD lost) (NP (PRP it))) (NP (RB all))) (, ,)) (CC and) (ADVP (RB now)) (S (NP (PRP he)) (VP (VBZ 's) (VP (VBG coming) (ADVP (RB back)) (S (VP (TO to) (VP (VB run))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="coming back to run" type="VP">
          <tokens>
            <token id="21" string="coming" />
            <token id="22" string="back" />
            <token id="23" string="to" />
            <token id="24" string="run" />
          </tokens>
        </chunking>
        <chunking id="2" string="reached the top of everything" type="VP">
          <tokens>
            <token id="7" string="reached" />
            <token id="8" string="the" />
            <token id="9" string="top" />
            <token id="10" string="of" />
            <token id="11" string="everything" />
          </tokens>
        </chunking>
        <chunking id="3" string="all" type="NP">
          <tokens>
            <token id="15" string="all" />
          </tokens>
        </chunking>
        <chunking id="4" string="'s a person who has reached the top of everything" type="VP">
          <tokens>
            <token id="2" string="'s" />
            <token id="3" string="a" />
            <token id="4" string="person" />
            <token id="5" string="who" />
            <token id="6" string="has" />
            <token id="7" string="reached" />
            <token id="8" string="the" />
            <token id="9" string="top" />
            <token id="10" string="of" />
            <token id="11" string="everything" />
          </tokens>
        </chunking>
        <chunking id="5" string="who has reached the top of everything" type="SBAR">
          <tokens>
            <token id="5" string="who" />
            <token id="6" string="has" />
            <token id="7" string="reached" />
            <token id="8" string="the" />
            <token id="9" string="top" />
            <token id="10" string="of" />
            <token id="11" string="everything" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="14" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="has reached the top of everything" type="VP">
          <tokens>
            <token id="6" string="has" />
            <token id="7" string="reached" />
            <token id="8" string="the" />
            <token id="9" string="top" />
            <token id="10" string="of" />
            <token id="11" string="everything" />
          </tokens>
        </chunking>
        <chunking id="8" string="run" type="VP">
          <tokens>
            <token id="24" string="run" />
          </tokens>
        </chunking>
        <chunking id="9" string="Here" type="NP">
          <tokens>
            <token id="1" string="Here" />
          </tokens>
        </chunking>
        <chunking id="10" string="a person" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="person" />
          </tokens>
        </chunking>
        <chunking id="11" string="the top" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="top" />
          </tokens>
        </chunking>
        <chunking id="12" string="a person who has reached the top of everything" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="person" />
            <token id="5" string="who" />
            <token id="6" string="has" />
            <token id="7" string="reached" />
            <token id="8" string="the" />
            <token id="9" string="top" />
            <token id="10" string="of" />
            <token id="11" string="everything" />
          </tokens>
        </chunking>
        <chunking id="13" string="the top of everything" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="top" />
            <token id="10" string="of" />
            <token id="11" string="everything" />
          </tokens>
        </chunking>
        <chunking id="14" string="lost it" type="VP">
          <tokens>
            <token id="13" string="lost" />
            <token id="14" string="it" />
          </tokens>
        </chunking>
        <chunking id="15" string="to run" type="VP">
          <tokens>
            <token id="23" string="to" />
            <token id="24" string="run" />
          </tokens>
        </chunking>
        <chunking id="16" string="he" type="NP">
          <tokens>
            <token id="19" string="he" />
          </tokens>
        </chunking>
        <chunking id="17" string="everything" type="NP">
          <tokens>
            <token id="11" string="everything" />
          </tokens>
        </chunking>
        <chunking id="18" string="'s coming back to run" type="VP">
          <tokens>
            <token id="20" string="'s" />
            <token id="21" string="coming" />
            <token id="22" string="back" />
            <token id="23" string="to" />
            <token id="24" string="run" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">person</governor>
          <dependent id="1">Here</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">person</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">person</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">person</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">reached</governor>
          <dependent id="5">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">reached</governor>
          <dependent id="6">has</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="4">person</governor>
          <dependent id="7">reached</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">top</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">reached</governor>
          <dependent id="9">top</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">everything</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">top</governor>
          <dependent id="11">everything</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">person</governor>
          <dependent id="13">lost</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">lost</governor>
          <dependent id="14">it</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">lost</governor>
          <dependent id="15">all</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">person</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="21">coming</governor>
          <dependent id="18">now</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">coming</governor>
          <dependent id="19">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">coming</governor>
          <dependent id="20">'s</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">person</governor>
          <dependent id="21">coming</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="21">coming</governor>
          <dependent id="22">back</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">run</governor>
          <dependent id="23">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="21">coming</governor>
          <dependent id="24">run</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="18" string="now" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="123" has_coreference="true">
      <content>Will he be the same Johnson?</content>
      <tokens>
        <token id="1" string="Will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="same" lemma="same" stem="same" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SQ (MD Will) (NP (PRP he)) (VP (VB be) (NP (DT the) (JJ same) (NNP Johnson))) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the same Johnson" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="same" />
            <token id="6" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="2" string="he" type="NP">
          <tokens>
            <token id="2" string="he" />
          </tokens>
        </chunking>
        <chunking id="3" string="be the same Johnson" type="VP">
          <tokens>
            <token id="3" string="be" />
            <token id="4" string="the" />
            <token id="5" string="same" />
            <token id="6" string="Johnson" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="aux">
          <governor id="6">Johnson</governor>
          <dependent id="1">Will</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">Johnson</governor>
          <dependent id="2">he</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">Johnson</governor>
          <dependent id="3">be</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">Johnson</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">Johnson</governor>
          <dependent id="5">same</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">Johnson</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Johnson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="124" has_coreference="true">
      <content>I don&amp;apost;t know, but people are willing to find out.&amp;quot;</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="know" lemma="know" stem="know" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="willing" lemma="willing" stem="will" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="find" lemma="find" stem="find" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP I)) (VP (VBP do) (RB n't) (VP (VB know)))) (, ,) (CC but) (S (NP (NNS people)) (VP (VBP are) (ADJP (JJ willing) (S (VP (TO to) (VP (VB find) (PRT (RP out)))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="do n't know" type="VP">
          <tokens>
            <token id="2" string="do" />
            <token id="3" string="n't" />
            <token id="4" string="know" />
          </tokens>
        </chunking>
        <chunking id="2" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="3" string="know" type="VP">
          <tokens>
            <token id="4" string="know" />
          </tokens>
        </chunking>
        <chunking id="4" string="to find out" type="VP">
          <tokens>
            <token id="10" string="to" />
            <token id="11" string="find" />
            <token id="12" string="out" />
          </tokens>
        </chunking>
        <chunking id="5" string="find out" type="VP">
          <tokens>
            <token id="11" string="find" />
            <token id="12" string="out" />
          </tokens>
        </chunking>
        <chunking id="6" string="people" type="NP">
          <tokens>
            <token id="7" string="people" />
          </tokens>
        </chunking>
        <chunking id="7" string="are willing to find out" type="VP">
          <tokens>
            <token id="8" string="are" />
            <token id="9" string="willing" />
            <token id="10" string="to" />
            <token id="11" string="find" />
            <token id="12" string="out" />
          </tokens>
        </chunking>
        <chunking id="8" string="willing to find out" type="ADJP">
          <tokens>
            <token id="9" string="willing" />
            <token id="10" string="to" />
            <token id="11" string="find" />
            <token id="12" string="out" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">know</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">know</governor>
          <dependent id="2">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">know</governor>
          <dependent id="3">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">know</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">know</governor>
          <dependent id="6">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">willing</governor>
          <dependent id="7">people</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="9">willing</governor>
          <dependent id="8">are</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">know</governor>
          <dependent id="9">willing</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">find</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">willing</governor>
          <dependent id="11">find</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="11">find</governor>
          <dependent id="12">out</dependent>
        </dependency>
      </dependencies>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="11-12" string="Ben Johnson" id_sentence="1" />
      <mentions>
        <mention ids_tokens="1" string="Johnson" id_sentence="4" />
        <mention ids_tokens="11-12" string="Johnson's" id_sentence="7" />
        <mention ids_tokens="1" string="Johnson" id_sentence="10" />
        <mention ids_tokens="6" string="his" id_sentence="10" />
        <mention ids_tokens="7-14" string="Johnson , then world record-holder at 100 meters" id_sentence="11" />
        <mention ids_tokens="7" string="Johnson" id_sentence="11" />
        <mention ids_tokens="10-14" string="world record-holder at 100 meters" id_sentence="11" />
        <mention ids_tokens="19" string="his" id_sentence="11" />
        <mention ids_tokens="1" string="Johnson" id_sentence="12" />
        <mention ids_tokens="9" string="Johnson" id_sentence="13" />
        <mention ids_tokens="3" string="he" id_sentence="14" />
        <mention ids_tokens="11" string="he" id_sentence="14" />
        <mention ids_tokens="46-47" string="Johnson's" id_sentence="14" />
        <mention ids_tokens="12" string="his" id_sentence="23" />
        <mention ids_tokens="1" string="Ben" id_sentence="43" />
        <mention ids_tokens="14" string="Ben" id_sentence="70" />
        <mention ids_tokens="12" string="Ben" id_sentence="99" />
        <mention ids_tokens="16" string="he" id_sentence="99" />
      </mentions>
    </coreference>
    <coreference id="2" type="NOMINAL">
      <referenced ids_tokens="3-4-5-6-7-8-9-10-11-12" string="a scene that recalled the golden days for Ben Johnson" id_sentence="1" />
      <mentions>
        <mention ids_tokens="1-2" string="This scene" id_sentence="6" />
        <mention ids_tokens="24-25" string="the scene" id_sentence="106" />
      </mentions>
    </coreference>
    <coreference id="5" type="PRONOMINAL">
      <referenced ids_tokens="4-5-6-7-8" string="them in their former countries" id_sentence="108" />
      <mentions>
        <mention ids_tokens="1" string="They" id_sentence="109" />
        <mention ids_tokens="31" string="them" id_sentence="111" />
      </mentions>
    </coreference>
    <coreference id="7" type="NOMINAL">
      <referenced ids_tokens="12-13-14" string="just a track" id_sentence="121" />
      <mentions>
        <mention ids_tokens="7-12" string="track and field's record books" id_sentence="110" />
      </mentions>
    </coreference>
    <coreference id="10" type="NOMINAL">
      <referenced ids_tokens="16-17" string="the boasts" id_sentence="9" />
      <mentions>
        <mention ids_tokens="12" string="the" id_sentence="61" />
      </mentions>
    </coreference>
    <coreference id="11" type="PROPER">
      <referenced ids_tokens="4-5" string="two years" id_sentence="11" />
      <mentions>
        <mention ids_tokens="4" string="last" id_sentence="10" />
        <mention ids_tokens="10" string="that" id_sentence="10" />
      </mentions>
    </coreference>
    <coreference id="12" type="PROPER">
      <referenced ids_tokens="11-12-13" string="Ben Johnson Rule" id_sentence="112" />
      <mentions>
        <mention ids_tokens="12-13" string="the rule" id_sentence="114" />
        <mention ids_tokens="1-2" string="The rule" id_sentence="115" />
      </mentions>
    </coreference>
    <coreference id="13" type="NOMINAL">
      <referenced ids_tokens="21-22-23-24" string="an athlete 's records" id_sentence="112" />
      <mentions>
        <mention ids_tokens="1-2" string="The records" id_sentence="117" />
      </mentions>
    </coreference>
    <coreference id="17" type="NOMINAL">
      <referenced ids_tokens="12-13-14" string="the 100 meters" id_sentence="115" />
      <mentions>
        <mention ids_tokens="13-14" string="100 meters" id_sentence="11" />
      </mentions>
    </coreference>
    <coreference id="18" type="NOMINAL">
      <referenced ids_tokens="19-20-21" string="his gold medal" id_sentence="11" />
      <mentions>
        <mention ids_tokens="9-11" string="the gold medal" id_sentence="111" />
      </mentions>
    </coreference>
    <coreference id="19" type="NOMINAL">
      <referenced ids_tokens="26-27" string="anabolic steroids" id_sentence="11" />
      <mentions>
        <mention ids_tokens="13" string="steroids" id_sentence="24" />
      </mentions>
    </coreference>
    <coreference id="20" type="PROPER">
      <referenced ids_tokens="29-30-31" string="the Seoul Olympics" id_sentence="11" />
      <mentions>
        <mention ids_tokens="8-9" string="the Olympics" id_sentence="116" />
      </mentions>
    </coreference>
    <coreference id="22" type="NOMINAL">
      <referenced ids_tokens="3-4" string="the questions" id_sentence="13" />
      <mentions>
        <mention ids_tokens="1-2" string="These questions" id_sentence="84" />
        <mention ids_tokens="24-25" string="his questions" id_sentence="101" />
      </mentions>
    </coreference>
    <coreference id="23" type="PROPER">
      <referenced ids_tokens="15-16" string="performance-enhancing drugs" id_sentence="13" />
      <mentions>
        <mention ids_tokens="2" string="I" id_sentence="15" />
        <mention ids_tokens="28" string="drugs" id_sentence="17" />
        <mention ids_tokens="37" string="drugs" id_sentence="55" />
        <mention ids_tokens="26" string="drugs" id_sentence="89" />
        <mention ids_tokens="8" string="drugs" id_sentence="114" />
      </mentions>
    </coreference>
    <coreference id="24" type="PROPER">
      <referenced ids_tokens="1-2-3" string="Hamilton promoter Gaines" id_sentence="66" />
      <mentions>
        <mention ids_tokens="22-23" string="Paul Gaines" id_sentence="14" />
        <mention ids_tokens="2" string="My" id_sentence="67" />
        <mention ids_tokens="4" string="I" id_sentence="68" />
        <mention ids_tokens="21" string="Gaines" id_sentence="70" />
        <mention ids_tokens="14" string="his" id_sentence="71" />
      </mentions>
    </coreference>
    <coreference id="25" type="PROPER">
      <referenced ids_tokens="11" string="Sport" id_sentence="102" />
      <mentions>
        <mention ids_tokens="6-7" string="the sport" id_sentence="14" />
        <mention ids_tokens="4" string="that" id_sentence="15" />
        <mention ids_tokens="6-11" string="the attitude the public will display" id_sentence="15" />
        <mention ids_tokens="12-13" string="the sport" id_sentence="16" />
        <mention ids_tokens="24-25" string="the sport" id_sentence="17" />
        <mention ids_tokens="6-7" string="the sport" id_sentence="39" />
        <mention ids_tokens="5-6" string="the sport" id_sentence="43" />
        <mention ids_tokens="18-19" string="the sport" id_sentence="43" />
        <mention ids_tokens="7-8" string="the sport" id_sentence="70" />
        <mention ids_tokens="3" string="that" id_sentence="103" />
      </mentions>
    </coreference>
    <coreference id="26" type="NOMINAL">
      <referenced ids_tokens="27-28-29-30-31-32-33" string="director for the Hamilton Spectator Indoor Games" id_sentence="14" />
      <mentions>
        <mention ids_tokens="24-27" string="director for the indoor" id_sentence="48" />
      </mentions>
    </coreference>
    <coreference id="27" type="PROPER">
      <referenced ids_tokens="35-36" string="the Canadian" id_sentence="14" />
      <mentions>
        <mention ids_tokens="9" string="Canada" id_sentence="60" />
      </mentions>
    </coreference>
    <coreference id="33" type="NOMINAL">
      <referenced ids_tokens="12-13-14-15-16-17-18-19-20-21-22-23-24-25-26-27-28" string="everyone in the sport to acknowledge that the No. 1 athlete in the sport was using drugs" id_sentence="17" />
      <mentions>
        <mention ids_tokens="6" string="him" id_sentence="18" />
        <mention ids_tokens="11" string="him" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="34" type="NOMINAL">
      <referenced ids_tokens="3-4-5-6-7-8-9-10-11" string="a person who has reached the top of everything" id_sentence="122" />
      <mentions>
        <mention ids_tokens="2" string="he" id_sentence="123" />
      </mentions>
    </coreference>
    <coreference id="36" type="PROPER">
      <referenced ids_tokens="8-9-10" string="the previous years" id_sentence="18" />
      <mentions>
        <mention ids_tokens="21" string="it" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="37" type="NOMINAL">
      <referenced ids_tokens="12" string="people" id_sentence="18" />
      <mentions>
        <mention ids_tokens="1" string="They" id_sentence="20" />
        <mention ids_tokens="5-11" string="people who do n't care about track" id_sentence="38" />
        <mention ids_tokens="18-24" string="people who have quit coming to track" id_sentence="38" />
      </mentions>
    </coreference>
    <coreference id="39" type="PROPER">
      <referenced ids_tokens="1-2" string="Charlie Francis" id_sentence="24" />
      <mentions>
        <mention ids_tokens="1" string="Francis" id_sentence="96" />
        <mention ids_tokens="5-6" string="his coach" id_sentence="96" />
        <mention ids_tokens="5" string="his" id_sentence="96" />
      </mentions>
    </coreference>
    <coreference id="40" type="PROPER">
      <referenced ids_tokens="6-7-8-9" string="Johnson for 12 years" id_sentence="24" />
      <mentions>
        <mention ids_tokens="5" string="Johnson" id_sentence="25" />
        <mention ids_tokens="1" string="Johnson" id_sentence="26" />
        <mention ids_tokens="17" string="he" id_sentence="26" />
        <mention ids_tokens="20" string="his" id_sentence="26" />
        <mention ids_tokens="23" string="Johnson" id_sentence="27" />
        <mention ids_tokens="11" string="Johnson" id_sentence="33" />
        <mention ids_tokens="14" string="his" id_sentence="33" />
        <mention ids_tokens="34-35" string="Johnson's" id_sentence="34" />
      </mentions>
    </coreference>
    <coreference id="41" type="PROPER">
      <referenced ids_tokens="19-20-21" string="the Associated Press" id_sentence="27" />
      <mentions>
        <mention ids_tokens="2" string="I" id_sentence="28" />
        <mention ids_tokens="1" string="I" id_sentence="29" />
        <mention ids_tokens="5" string="I" id_sentence="30" />
        <mention ids_tokens="1" string="I" id_sentence="31" />
        <mention ids_tokens="10" string="I" id_sentence="31" />
        <mention ids_tokens="13-14" string="the best" id_sentence="31" />
        <mention ids_tokens="1" string="I" id_sentence="32" />
        <mention ids_tokens="4" string="I" id_sentence="32" />
      </mentions>
    </coreference>
    <coreference id="42" type="NOMINAL">
      <referenced ids_tokens="10-11-12-13-14-15-16" string="the records I have been deprived of" id_sentence="27" />
      <mentions>
        <mention ids_tokens="14-15" string="his records" id_sentence="33" />
      </mentions>
    </coreference>
    <coreference id="44" type="NOMINAL">
      <referenced ids_tokens="26-27" string="the indoor" id_sentence="48" />
      <mentions>
        <mention ids_tokens="5" string="indoor" id_sentence="33" />
        <mention ids_tokens="30" string="him" id_sentence="33" />
        <mention ids_tokens="12" string="indoor" id_sentence="60" />
      </mentions>
    </coreference>
    <coreference id="45" type="NOMINAL">
      <referenced ids_tokens="12-13" string="the fans" id_sentence="53" />
      <mentions>
        <mention ids_tokens="21" string="fans" id_sentence="33" />
        <mention ids_tokens="10-12" string="( fans )" id_sentence="67" />
      </mentions>
    </coreference>
    <coreference id="46" type="NOMINAL">
      <referenced ids_tokens="34-35-36-37-38" string="Johnson 's return to competition" id_sentence="34" />
      <mentions>
        <mention ids_tokens="14-15" string="his return" id_sentence="71" />
      </mentions>
    </coreference>
    <coreference id="47" type="PROPER">
      <referenced ids_tokens="1-2" string="Al Franken" id_sentence="35" />
      <mentions>
        <mention ids_tokens="2" string="I" id_sentence="37" />
        <mention ids_tokens="19" string="Franken" id_sentence="37" />
        <mention ids_tokens="1" string="Franken" id_sentence="74" />
        <mention ids_tokens="3" string="he" id_sentence="74" />
        <mention ids_tokens="7" string="his" id_sentence="74" />
        <mention ids_tokens="2" string="He" id_sentence="77" />
        <mention ids_tokens="4-8" string="the greatest sprinter in history" id_sentence="77" />
        <mention ids_tokens="11" string="he" id_sentence="77" />
        <mention ids_tokens="2" string="he" id_sentence="78" />
        <mention ids_tokens="1" string="He" id_sentence="79" />
        <mention ids_tokens="4" string="he" id_sentence="79" />
        <mention ids_tokens="6" string="him" id_sentence="82" />
        <mention ids_tokens="12" string="his" id_sentence="82" />
        <mention ids_tokens="16" string="he" id_sentence="82" />
        <mention ids_tokens="30-32" string="he or she" id_sentence="112" />
      </mentions>
    </coreference>
    <coreference id="48" type="PROPER">
      <referenced ids_tokens="7-8" string="Sunkist Invitational" id_sentence="35" />
      <mentions>
        <mention ids_tokens="10" string="Sunkist" id_sentence="74" />
      </mentions>
    </coreference>
    <coreference id="49" type="PROPER">
      <referenced ids_tokens="44-45" string="Carl Lewis" id_sentence="35" />
      <mentions>
        <mention ids_tokens="26" string="he" id_sentence="55" />
        <mention ids_tokens="16" string="Lewis" id_sentence="90" />
      </mentions>
    </coreference>
    <coreference id="50" type="PROPER">
      <referenced ids_tokens="14-15-16-17-18" string="Johnson for his Jan. 18" id_sentence="35" />
      <mentions>
        <mention ids_tokens="9" string="Johnson" id_sentence="44" />
        <mention ids_tokens="1" string="His" id_sentence="45" />
        <mention ids_tokens="1" string="He" id_sentence="46" />
        <mention ids_tokens="14" string="Johnson" id_sentence="54" />
        <mention ids_tokens="1" string="Johnson" id_sentence="61" />
        <mention ids_tokens="25" string="his" id_sentence="61" />
        <mention ids_tokens="15" string="Johnson" id_sentence="66" />
        <mention ids_tokens="6" string="Johnson" id_sentence="69" />
        <mention ids_tokens="27-28" string="Johnson's" id_sentence="73" />
        <mention ids_tokens="16-17" string="Johnson's" id_sentence="89" />
        <mention ids_tokens="14" string="Johnson" id_sentence="90" />
        <mention ids_tokens="4" string="Johnson" id_sentence="93" />
        <mention ids_tokens="16" string="his" id_sentence="93" />
        <mention ids_tokens="1" string="He" id_sentence="94" />
        <mention ids_tokens="5" string="Johnson" id_sentence="95" />
        <mention ids_tokens="3-4" string="Johnson's" id_sentence="97" />
        <mention ids_tokens="26-27" string="Johnson's" id_sentence="97" />
        <mention ids_tokens="34-35" string="Johnson's" id_sentence="97" />
        <mention ids_tokens="6" string="Johnson" id_sentence="98" />
        <mention ids_tokens="3-4" string="Johnson's" id_sentence="99" />
        <mention ids_tokens="15" string="Johnson" id_sentence="101" />
        <mention ids_tokens="18" string="he" id_sentence="101" />
        <mention ids_tokens="24" string="his" id_sentence="101" />
        <mention ids_tokens="1" string="Johnson" id_sentence="102" />
        <mention ids_tokens="5" string="he" id_sentence="103" />
        <mention ids_tokens="1" string="He" id_sentence="104" />
        <mention ids_tokens="18" string="Johnson" id_sentence="104" />
        <mention ids_tokens="21" string="him" id_sentence="104" />
        <mention ids_tokens="9" string="Johnson" id_sentence="106" />
        <mention ids_tokens="16" string="him" id_sentence="106" />
        <mention ids_tokens="21" string="he" id_sentence="106" />
        <mention ids_tokens="4" string="Johnson" id_sentence="107" />
        <mention ids_tokens="6" string="his" id_sentence="107" />
        <mention ids_tokens="3" string="Johnson" id_sentence="110" />
        <mention ids_tokens="4" string="he" id_sentence="111" />
        <mention ids_tokens="14" string="he" id_sentence="111" />
        <mention ids_tokens="3" string="Johnson" id_sentence="114" />
        <mention ids_tokens="6" string="his" id_sentence="115" />
        <mention ids_tokens="8" string="Johnson" id_sentence="120" />
      </mentions>
    </coreference>
    <coreference id="51" type="NOMINAL">
      <referenced ids_tokens="7-8-9-10-11-12-13-14-15" string="the contract that rewards Johnson for high attendance figures" id_sentence="36" />
      <mentions>
        <mention ids_tokens="14" string="it" id_sentence="37" />
      </mentions>
    </coreference>
    <coreference id="54" type="NOMINAL">
      <referenced ids_tokens="3-4-5-6-7" string="a push in the sport" id_sentence="39" />
      <mentions>
        <mention ids_tokens="1" string="It" id_sentence="40" />
      </mentions>
    </coreference>
    <coreference id="57" type="NOMINAL">
      <referenced ids_tokens="6-7-8" string="the appearence fees" id_sentence="44" />
      <mentions>
        <mention ids_tokens="29" string="fees" id_sentence="57" />
      </mentions>
    </coreference>
    <coreference id="58" type="NOMINAL">
      <referenced ids_tokens="1-2-3-4-5-6" string="His value in Europe and Japan" id_sentence="45" />
      <mentions>
        <mention ids_tokens="9-10" string="his value" id_sentence="50" />
        <mention ids_tokens="1" string="That" id_sentence="51" />
        <mention ids_tokens="3-4" string="the key" id_sentence="51" />
      </mentions>
    </coreference>
    <coreference id="59" type="NOMINAL">
      <referenced ids_tokens="8" string="a" id_sentence="46" />
      <mentions>
        <mention ids_tokens="1" string="he" id_sentence="64" />
      </mentions>
    </coreference>
    <coreference id="61" type="NOMINAL">
      <referenced ids_tokens="17-18-19" string="an unproven runner" id_sentence="47" />
      <mentions>
        <mention ids_tokens="3" string="he" id_sentence="48" />
        <mention ids_tokens="12" string="he" id_sentence="49" />
      </mentions>
    </coreference>
    <coreference id="62" type="PROPER">
      <referenced ids_tokens="20-21" string="Ray Lumpp" id_sentence="48" />
      <mentions>
        <mention ids_tokens="2" string="I" id_sentence="49" />
        <mention ids_tokens="11" string="I" id_sentence="52" />
        <mention ids_tokens="1-13" string="Lumpp , who traditionally has one of the largest budgets in North America" id_sentence="62" />
        <mention ids_tokens="1" string="Lumpp" id_sentence="62" />
        <mention ids_tokens="1-26" string="Said Lumpp of the Meadowlands , &quot; You do n't have just a track and field story here , you have a human interest story ." id_sentence="121" />
        <mention ids_tokens="1" string="I" id_sentence="124" />
      </mentions>
    </coreference>
    <coreference id="63" type="PROPER">
      <referenced ids_tokens="30-31" string="the Meadowlands" id_sentence="48" />
      <mentions>
        <mention ids_tokens="5" string="Meadowlands" id_sentence="121" />
      </mentions>
    </coreference>
    <coreference id="64" type="PROPER">
      <referenced ids_tokens="7-8-9-10-11-12-13" string="Ben Johnson regardless of how he runs" id_sentence="49" />
      <mentions>
        <mention ids_tokens="4" string="he" id_sentence="50" />
        <mention ids_tokens="9" string="his" id_sentence="50" />
        <mention ids_tokens="2" string="he" id_sentence="52" />
      </mentions>
    </coreference>
    <coreference id="66" type="PROPER">
      <referenced ids_tokens="1-2-3-4-5-6-7-8-9" string="Howard Schmertz of the Millrose Games in New York" id_sentence="54" />
      <mentions>
        <mention ids_tokens="40" string="Schmertz" id_sentence="55" />
        <mention ids_tokens="2" string="I" id_sentence="56" />
        <mention ids_tokens="7" string="I" id_sentence="57" />
        <mention ids_tokens="15" string="I" id_sentence="57" />
        <mention ids_tokens="1" string="Schmertz" id_sentence="75" />
        <mention ids_tokens="2" string="I" id_sentence="76" />
        <mention ids_tokens="7" string="myself" id_sentence="76" />
        <mention ids_tokens="10-13" string="him that much money" id_sentence="76" />
        <mention ids_tokens="16" string="he" id_sentence="76" />
        <mention ids_tokens="1" string="I" id_sentence="81" />
        <mention ids_tokens="1" string="I" id_sentence="83" />
        <mention ids_tokens="6" string="my" id_sentence="84" />
      </mentions>
    </coreference>
    <coreference id="67" type="NOMINAL">
      <referenced ids_tokens="14-15-16-17" string="a truly great runner" id_sentence="55" />
      <mentions>
        <mention ids_tokens="4" string="him" id_sentence="58" />
        <mention ids_tokens="11" string="him" id_sentence="58" />
      </mentions>
    </coreference>
    <coreference id="68" type="NOMINAL">
      <referenced ids_tokens="23-24-25" string="problems giving out" id_sentence="57" />
      <mentions>
        <mention ids_tokens="16" string="problems" id_sentence="58" />
      </mentions>
    </coreference>
    <coreference id="70" type="NOMINAL">
      <referenced ids_tokens="23" string="athletes" id_sentence="60" />
      <mentions>
        <mention ids_tokens="8-19" string="athletes , especially when there's X dollars given to one athlete" id_sentence="65" />
      </mentions>
    </coreference>
    <coreference id="72" type="PROPER">
      <referenced ids_tokens="18" string="one" id_sentence="65" />
      <mentions>
        <mention ids_tokens="6" string="it" id_sentence="66" />
        <mention ids_tokens="5" string="that" id_sentence="67" />
      </mentions>
    </coreference>
    <coreference id="76" type="NOMINAL">
      <referenced ids_tokens="7-8" string="the matter" id_sentence="75" />
      <mentions>
        <mention ids_tokens="5" string="that" id_sentence="76" />
      </mentions>
    </coreference>
    <coreference id="77" type="NOMINAL">
      <referenced ids_tokens="3-4-5-6" string="a very complicated issue" id_sentence="80" />
      <mentions>
        <mention ids_tokens="11-12" string="the notoriety" id_sentence="79" />
      </mentions>
    </coreference>
    <coreference id="78" type="PROPER">
      <referenced ids_tokens="1-2" string="Will Kern" id_sentence="85" />
      <mentions>
        <mention ids_tokens="10" string="it" id_sentence="86" />
        <mention ids_tokens="2" string="I" id_sentence="88" />
        <mention ids_tokens="1" string="I" id_sentence="89" />
        <mention ids_tokens="14" string="I" id_sentence="89" />
      </mentions>
    </coreference>
    <coreference id="79" type="PROPER">
      <referenced ids_tokens="8-9-10" string="Times Indoor Games" id_sentence="85" />
      <mentions>
        <mention ids_tokens="2" string="It" id_sentence="86" />
        <mention ids_tokens="6" string="it" id_sentence="89" />
      </mentions>
    </coreference>
    <coreference id="80" type="NOMINAL">
      <referenced ids_tokens="8-9-10-11-12-13-14-15-16" string="a much-discussed lucrative match race between Johnson and Lewis" id_sentence="90" />
      <mentions>
        <mention ids_tokens="2" string="I" id_sentence="91" />
        <mention ids_tokens="6" string="it" id_sentence="91" />
      </mentions>
    </coreference>
    <coreference id="81" type="LIST">
      <referenced ids_tokens="14-15-16" string="Johnson and Lewis" id_sentence="90" />
      <mentions>
        <mention ids_tokens="2" string="We" id_sentence="92" />
      </mentions>
    </coreference>
    <coreference id="83" type="PROPER">
      <referenced ids_tokens="1-2-3-4" string="A NEW CAST Johnson" id_sentence="93" />
      <mentions>
        <mention ids_tokens="4-6" string="the same Johnson" id_sentence="123" />
      </mentions>
    </coreference>
    <coreference id="85" type="PROPER">
      <referenced ids_tokens="31-32" string="Ed Futerman" id_sentence="97" />
      <mentions>
        <mention ids_tokens="1" string="Futerman" id_sentence="99" />
        <mention ids_tokens="5-27" string="Futerman who offered to permit a British journalist to interview Johnson -- if he paid $ 10,000 and submitted his questions in advance" id_sentence="101" />
      </mentions>
    </coreference>
    <coreference id="86" type="PROPER">
      <referenced ids_tokens="8-9" string="Larry Heidebrecht" id_sentence="97" />
      <mentions>
        <mention ids_tokens="1" string="We" id_sentence="100" />
      </mentions>
    </coreference>
    <coreference id="88" type="NOMINAL">
      <referenced ids_tokens="14-15-16-17-18-19-20-21-22-23-24-25-26-27-28" string="a lifetime ban on Johnson that prohibited him from representing Canada in the Olympic Games" id_sentence="104" />
      <mentions>
        <mention ids_tokens="12-13" string="the ban" id_sentence="105" />
      </mentions>
    </coreference>
    <coreference id="89" type="PROPER">
      <referenced ids_tokens="1-2" string="The COA" id_sentence="105" />
      <mentions>
        <mention ids_tokens="1" string="That" id_sentence="106" />
      </mentions>
    </coreference>
  </coreferences>
</document>
