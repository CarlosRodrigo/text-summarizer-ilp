<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="LA093089-0126">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>In a blow to California and other states with large immigrant populations, the Senate voted Friday to bar the Census Bureau from counting illegal aliens in the 1990 population count.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="blow" lemma="blow" stem="blow" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="California" lemma="California" stem="california" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="6" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="states" lemma="state" stem="state" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="large" lemma="large" stem="larg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="immigrant" lemma="immigrant" stem="immigr" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="populations" lemma="population" stem="popul" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="Senate" lemma="Senate" stem="senat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="16" string="voted" lemma="vote" stem="vote" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="Friday" lemma="Friday" stem="fridai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="bar" lemma="bar" stem="bar" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="Census" lemma="Census" stem="censu" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="22" string="Bureau" lemma="Bureau" stem="bureau" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="23" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="counting" lemma="count" stem="count" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="aliens" lemma="alien" stem="alien" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="29" string="1990" lemma="1990" stem="1990" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="30" string="population" lemma="population" stem="popul" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="31" string="count" lemma="count" stem="count" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (NP (NP (DT a) (NN blow)) (PP (TO to) (NP (NNP California)))) (CC and) (NP (NP (JJ other) (NNS states)) (PP (IN with) (NP (JJ large) (JJ immigrant) (NNS populations)))))) (, ,) (NP (DT the) (NNP Senate)) (VP (VBD voted) (NP-TMP (NNP Friday)) (S (VP (TO to) (VP (VB bar) (NP (DT the) (NNP Census) (NNP Bureau)) (PP (IN from) (S (VP (VBG counting) (NP (JJ illegal) (NNS aliens)) (PP (IN in) (NP (DT the) (CD 1990) (NN population) (NN count)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="illegal aliens" type="NP">
          <tokens>
            <token id="25" string="illegal" />
            <token id="26" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="2" string="California" type="NP">
          <tokens>
            <token id="5" string="California" />
          </tokens>
        </chunking>
        <chunking id="3" string="a blow to California and other states with large immigrant populations" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="blow" />
            <token id="4" string="to" />
            <token id="5" string="California" />
            <token id="6" string="and" />
            <token id="7" string="other" />
            <token id="8" string="states" />
            <token id="9" string="with" />
            <token id="10" string="large" />
            <token id="11" string="immigrant" />
            <token id="12" string="populations" />
          </tokens>
        </chunking>
        <chunking id="4" string="the Census Bureau" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="Census" />
            <token id="22" string="Bureau" />
          </tokens>
        </chunking>
        <chunking id="5" string="a blow" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="blow" />
          </tokens>
        </chunking>
        <chunking id="6" string="other states" type="NP">
          <tokens>
            <token id="7" string="other" />
            <token id="8" string="states" />
          </tokens>
        </chunking>
        <chunking id="7" string="a blow to California" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="blow" />
            <token id="4" string="to" />
            <token id="5" string="California" />
          </tokens>
        </chunking>
        <chunking id="8" string="the 1990 population count" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="1990" />
            <token id="30" string="population" />
            <token id="31" string="count" />
          </tokens>
        </chunking>
        <chunking id="9" string="bar the Census Bureau from counting illegal aliens in the 1990 population count" type="VP">
          <tokens>
            <token id="19" string="bar" />
            <token id="20" string="the" />
            <token id="21" string="Census" />
            <token id="22" string="Bureau" />
            <token id="23" string="from" />
            <token id="24" string="counting" />
            <token id="25" string="illegal" />
            <token id="26" string="aliens" />
            <token id="27" string="in" />
            <token id="28" string="the" />
            <token id="29" string="1990" />
            <token id="30" string="population" />
            <token id="31" string="count" />
          </tokens>
        </chunking>
        <chunking id="10" string="voted Friday to bar the Census Bureau from counting illegal aliens in the 1990 population count" type="VP">
          <tokens>
            <token id="16" string="voted" />
            <token id="17" string="Friday" />
            <token id="18" string="to" />
            <token id="19" string="bar" />
            <token id="20" string="the" />
            <token id="21" string="Census" />
            <token id="22" string="Bureau" />
            <token id="23" string="from" />
            <token id="24" string="counting" />
            <token id="25" string="illegal" />
            <token id="26" string="aliens" />
            <token id="27" string="in" />
            <token id="28" string="the" />
            <token id="29" string="1990" />
            <token id="30" string="population" />
            <token id="31" string="count" />
          </tokens>
        </chunking>
        <chunking id="11" string="the Senate" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="Senate" />
          </tokens>
        </chunking>
        <chunking id="12" string="large immigrant populations" type="NP">
          <tokens>
            <token id="10" string="large" />
            <token id="11" string="immigrant" />
            <token id="12" string="populations" />
          </tokens>
        </chunking>
        <chunking id="13" string="other states with large immigrant populations" type="NP">
          <tokens>
            <token id="7" string="other" />
            <token id="8" string="states" />
            <token id="9" string="with" />
            <token id="10" string="large" />
            <token id="11" string="immigrant" />
            <token id="12" string="populations" />
          </tokens>
        </chunking>
        <chunking id="14" string="to bar the Census Bureau from counting illegal aliens in the 1990 population count" type="VP">
          <tokens>
            <token id="18" string="to" />
            <token id="19" string="bar" />
            <token id="20" string="the" />
            <token id="21" string="Census" />
            <token id="22" string="Bureau" />
            <token id="23" string="from" />
            <token id="24" string="counting" />
            <token id="25" string="illegal" />
            <token id="26" string="aliens" />
            <token id="27" string="in" />
            <token id="28" string="the" />
            <token id="29" string="1990" />
            <token id="30" string="population" />
            <token id="31" string="count" />
          </tokens>
        </chunking>
        <chunking id="15" string="counting illegal aliens in the 1990 population count" type="VP">
          <tokens>
            <token id="24" string="counting" />
            <token id="25" string="illegal" />
            <token id="26" string="aliens" />
            <token id="27" string="in" />
            <token id="28" string="the" />
            <token id="29" string="1990" />
            <token id="30" string="population" />
            <token id="31" string="count" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">blow</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">blow</governor>
          <dependent id="2">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">voted</governor>
          <dependent id="3">blow</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">California</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">blow</governor>
          <dependent id="5">California</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">blow</governor>
          <dependent id="6">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">states</governor>
          <dependent id="7">other</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">blow</governor>
          <dependent id="8">states</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">populations</governor>
          <dependent id="9">with</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">populations</governor>
          <dependent id="10">large</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">populations</governor>
          <dependent id="11">immigrant</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">states</governor>
          <dependent id="12">populations</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">Senate</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">voted</governor>
          <dependent id="15">Senate</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">voted</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="16">voted</governor>
          <dependent id="17">Friday</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">bar</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="16">voted</governor>
          <dependent id="19">bar</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">Bureau</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Bureau</governor>
          <dependent id="21">Census</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">bar</governor>
          <dependent id="22">Bureau</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">counting</governor>
          <dependent id="23">from</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="19">bar</governor>
          <dependent id="24">counting</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">aliens</governor>
          <dependent id="25">illegal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">counting</governor>
          <dependent id="26">aliens</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">count</governor>
          <dependent id="27">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">count</governor>
          <dependent id="28">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="31">count</governor>
          <dependent id="29">1990</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">count</governor>
          <dependent id="30">population</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">counting</governor>
          <dependent id="31">count</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Senate" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="15" string="Senate" />
          </tokens>
        </entity>
        <entity id="2" string="California" type="LOCATION" score="0.0">
          <tokens>
            <token id="5" string="California" />
          </tokens>
        </entity>
        <entity id="3" string="Friday" type="DATE" score="0.0">
          <tokens>
            <token id="17" string="Friday" />
          </tokens>
        </entity>
        <entity id="4" string="1990" type="DATE" score="0.0">
          <tokens>
            <token id="29" string="1990" />
          </tokens>
        </entity>
        <entity id="5" string="Census Bureau" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="21" string="Census" />
            <token id="22" string="Bureau" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>&amp;quot;I&amp;apost;m stunned,&amp;quot; said Santa Ana City Council member Miguel A. Pulido.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="'m" lemma="be" stem="'m" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="stunned" lemma="stunned" stem="stun" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="Santa" lemma="Santa" stem="santa" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="9" string="Ana" lemma="Ana" stem="ana" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="10" string="City" lemma="City" stem="citi" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="11" string="Council" lemma="Council" stem="council" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="12" string="member" lemma="member" stem="member" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="Miguel" lemma="Miguel" stem="miguel" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="14" string="A." lemma="A." stem="a." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="15" string="Pulido" lemma="Pulido" stem="pulido" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (PRP I)) (VP (VBP 'm) (ADJP (JJ stunned)))) (, ,) ('' '') (VP (VBD said)) (NP (NNP Santa) (NNP Ana) (NNP City) (NNP Council) (NN member) (NNP Miguel) (NNP A.) (NNP Pulido)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="stunned" type="ADJP">
          <tokens>
            <token id="4" string="stunned" />
          </tokens>
        </chunking>
        <chunking id="2" string="'m stunned" type="VP">
          <tokens>
            <token id="3" string="'m" />
            <token id="4" string="stunned" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="Santa Ana City Council member Miguel A. Pulido" type="NP">
          <tokens>
            <token id="8" string="Santa" />
            <token id="9" string="Ana" />
            <token id="10" string="City" />
            <token id="11" string="Council" />
            <token id="12" string="member" />
            <token id="13" string="Miguel" />
            <token id="14" string="A." />
            <token id="15" string="Pulido" />
          </tokens>
        </chunking>
        <chunking id="5" string="said" type="VP">
          <tokens>
            <token id="7" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">stunned</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">stunned</governor>
          <dependent id="3">'m</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">said</governor>
          <dependent id="4">stunned</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Pulido</governor>
          <dependent id="8">Santa</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Pulido</governor>
          <dependent id="9">Ana</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Pulido</governor>
          <dependent id="10">City</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Pulido</governor>
          <dependent id="11">Council</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Pulido</governor>
          <dependent id="12">member</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Pulido</governor>
          <dependent id="13">Miguel</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Pulido</governor>
          <dependent id="14">A.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">said</governor>
          <dependent id="15">Pulido</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Miguel A. Pulido" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Miguel" />
            <token id="14" string="A." />
            <token id="15" string="Pulido" />
          </tokens>
        </entity>
        <entity id="2" string="Santa Ana City Council" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="8" string="Santa" />
            <token id="9" string="Ana" />
            <token id="10" string="City" />
            <token id="11" string="Council" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>Pulido and other Santa Ana council members say that the 1980 census substantially under-counted its population at 215,000.</content>
      <tokens>
        <token id="1" string="Pulido" lemma="Pulido" stem="pulido" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Santa" lemma="Santa" stem="santa" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="5" string="Ana" lemma="Ana" stem="ana" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="6" string="council" lemma="council" stem="council" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="members" lemma="member" stem="member" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="say" lemma="say" stem="sai" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="1980" lemma="1980" stem="1980" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="12" string="census" lemma="census" stem="censu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="substantially" lemma="substantially" stem="substanti" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="under-counted" lemma="under-count" stem="under-count" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="population" lemma="population" stem="popul" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="215,000" lemma="215,000" stem="215,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Pulido)) (CC and) (NP (JJ other) (NNP Santa) (NNP Ana) (NN council) (NNS members))) (VP (VBP say) (SBAR (IN that) (S (NP (DT the) (CD 1980) (NN census)) (ADVP (RB substantially)) (VP (VBD under-counted) (NP (PRP$ its) (NN population)) (PP (IN at) (NP (CD 215,000))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that the 1980 census substantially under-counted its population at 215,000" type="SBAR">
          <tokens>
            <token id="9" string="that" />
            <token id="10" string="the" />
            <token id="11" string="1980" />
            <token id="12" string="census" />
            <token id="13" string="substantially" />
            <token id="14" string="under-counted" />
            <token id="15" string="its" />
            <token id="16" string="population" />
            <token id="17" string="at" />
            <token id="18" string="215,000" />
          </tokens>
        </chunking>
        <chunking id="2" string="the 1980 census" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="1980" />
            <token id="12" string="census" />
          </tokens>
        </chunking>
        <chunking id="3" string="other Santa Ana council members" type="NP">
          <tokens>
            <token id="3" string="other" />
            <token id="4" string="Santa" />
            <token id="5" string="Ana" />
            <token id="6" string="council" />
            <token id="7" string="members" />
          </tokens>
        </chunking>
        <chunking id="4" string="say that the 1980 census substantially under-counted its population at 215,000" type="VP">
          <tokens>
            <token id="8" string="say" />
            <token id="9" string="that" />
            <token id="10" string="the" />
            <token id="11" string="1980" />
            <token id="12" string="census" />
            <token id="13" string="substantially" />
            <token id="14" string="under-counted" />
            <token id="15" string="its" />
            <token id="16" string="population" />
            <token id="17" string="at" />
            <token id="18" string="215,000" />
          </tokens>
        </chunking>
        <chunking id="5" string="its population" type="NP">
          <tokens>
            <token id="15" string="its" />
            <token id="16" string="population" />
          </tokens>
        </chunking>
        <chunking id="6" string="under-counted its population at 215,000" type="VP">
          <tokens>
            <token id="14" string="under-counted" />
            <token id="15" string="its" />
            <token id="16" string="population" />
            <token id="17" string="at" />
            <token id="18" string="215,000" />
          </tokens>
        </chunking>
        <chunking id="7" string="Pulido" type="NP">
          <tokens>
            <token id="1" string="Pulido" />
          </tokens>
        </chunking>
        <chunking id="8" string="215,000" type="NP">
          <tokens>
            <token id="18" string="215,000" />
          </tokens>
        </chunking>
        <chunking id="9" string="Pulido and other Santa Ana council members" type="NP">
          <tokens>
            <token id="1" string="Pulido" />
            <token id="2" string="and" />
            <token id="3" string="other" />
            <token id="4" string="Santa" />
            <token id="5" string="Ana" />
            <token id="6" string="council" />
            <token id="7" string="members" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="8">say</governor>
          <dependent id="1">Pulido</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="1">Pulido</governor>
          <dependent id="2">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">members</governor>
          <dependent id="3">other</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">members</governor>
          <dependent id="4">Santa</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">members</governor>
          <dependent id="5">Ana</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">members</governor>
          <dependent id="6">council</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="1">Pulido</governor>
          <dependent id="7">members</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">say</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">under-counted</governor>
          <dependent id="9">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">census</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="12">census</governor>
          <dependent id="11">1980</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">under-counted</governor>
          <dependent id="12">census</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">under-counted</governor>
          <dependent id="13">substantially</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">say</governor>
          <dependent id="14">under-counted</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">population</governor>
          <dependent id="15">its</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">under-counted</governor>
          <dependent id="16">population</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">215,000</governor>
          <dependent id="17">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">under-counted</governor>
          <dependent id="18">215,000</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Santa Ana" type="LOCATION" score="0.0">
          <tokens>
            <token id="4" string="Santa" />
            <token id="5" string="Ana" />
          </tokens>
        </entity>
        <entity id="2" string="1980" type="DATE" score="0.0">
          <tokens>
            <token id="11" string="1980" />
          </tokens>
        </entity>
        <entity id="3" string="Pulido" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Pulido" />
          </tokens>
        </entity>
        <entity id="4" string="215,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="18" string="215,000" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>The city has been lobbying hard to have its illegal alien population -- estimated at 50,000 -- included in the 1990 count.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="city" lemma="city" stem="citi" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="lobbying" lemma="lobby" stem="lobbi" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="hard" lemma="hard" stem="hard" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="alien" lemma="alien" stem="alien" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="population" lemma="population" stem="popul" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="estimated" lemma="estimate" stem="estim" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="50,000" lemma="50,000" stem="50,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="17" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="included" lemma="include" stem="includ" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="1990" lemma="1990" stem="1990" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="22" string="count" lemma="count" stem="count" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN city)) (VP (VBZ has) (VP (VBN been) (VP (VBG lobbying) (ADJP (JJ hard) (S (VP (TO to) (VP (VB have) (NP (NP (PRP$ its) (JJ illegal) (JJ alien) (NN population)) (PRN (: --) (VP (VBN estimated) (PP (IN at) (NP (CD 50,000)))) (: --)) (VP (VBN included) (PP (IN in) (NP (DT the) (CD 1990) (NN count)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="lobbying hard to have its illegal alien population -- estimated at 50,000 -- included in the 1990 count" type="VP">
          <tokens>
            <token id="5" string="lobbying" />
            <token id="6" string="hard" />
            <token id="7" string="to" />
            <token id="8" string="have" />
            <token id="9" string="its" />
            <token id="10" string="illegal" />
            <token id="11" string="alien" />
            <token id="12" string="population" />
            <token id="13" string="--" />
            <token id="14" string="estimated" />
            <token id="15" string="at" />
            <token id="16" string="50,000" />
            <token id="17" string="--" />
            <token id="18" string="included" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="1990" />
            <token id="22" string="count" />
          </tokens>
        </chunking>
        <chunking id="2" string="estimated at 50,000" type="VP">
          <tokens>
            <token id="14" string="estimated" />
            <token id="15" string="at" />
            <token id="16" string="50,000" />
          </tokens>
        </chunking>
        <chunking id="3" string="its illegal alien population -- estimated at 50,000 -- included in the 1990 count" type="NP">
          <tokens>
            <token id="9" string="its" />
            <token id="10" string="illegal" />
            <token id="11" string="alien" />
            <token id="12" string="population" />
            <token id="13" string="--" />
            <token id="14" string="estimated" />
            <token id="15" string="at" />
            <token id="16" string="50,000" />
            <token id="17" string="--" />
            <token id="18" string="included" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="1990" />
            <token id="22" string="count" />
          </tokens>
        </chunking>
        <chunking id="4" string="included in the 1990 count" type="VP">
          <tokens>
            <token id="18" string="included" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="1990" />
            <token id="22" string="count" />
          </tokens>
        </chunking>
        <chunking id="5" string="The city" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="city" />
          </tokens>
        </chunking>
        <chunking id="6" string="been lobbying hard to have its illegal alien population -- estimated at 50,000 -- included in the 1990 count" type="VP">
          <tokens>
            <token id="4" string="been" />
            <token id="5" string="lobbying" />
            <token id="6" string="hard" />
            <token id="7" string="to" />
            <token id="8" string="have" />
            <token id="9" string="its" />
            <token id="10" string="illegal" />
            <token id="11" string="alien" />
            <token id="12" string="population" />
            <token id="13" string="--" />
            <token id="14" string="estimated" />
            <token id="15" string="at" />
            <token id="16" string="50,000" />
            <token id="17" string="--" />
            <token id="18" string="included" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="1990" />
            <token id="22" string="count" />
          </tokens>
        </chunking>
        <chunking id="7" string="its illegal alien population" type="NP">
          <tokens>
            <token id="9" string="its" />
            <token id="10" string="illegal" />
            <token id="11" string="alien" />
            <token id="12" string="population" />
          </tokens>
        </chunking>
        <chunking id="8" string="have its illegal alien population -- estimated at 50,000 -- included in the 1990 count" type="VP">
          <tokens>
            <token id="8" string="have" />
            <token id="9" string="its" />
            <token id="10" string="illegal" />
            <token id="11" string="alien" />
            <token id="12" string="population" />
            <token id="13" string="--" />
            <token id="14" string="estimated" />
            <token id="15" string="at" />
            <token id="16" string="50,000" />
            <token id="17" string="--" />
            <token id="18" string="included" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="1990" />
            <token id="22" string="count" />
          </tokens>
        </chunking>
        <chunking id="9" string="to have its illegal alien population -- estimated at 50,000 -- included in the 1990 count" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="have" />
            <token id="9" string="its" />
            <token id="10" string="illegal" />
            <token id="11" string="alien" />
            <token id="12" string="population" />
            <token id="13" string="--" />
            <token id="14" string="estimated" />
            <token id="15" string="at" />
            <token id="16" string="50,000" />
            <token id="17" string="--" />
            <token id="18" string="included" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="1990" />
            <token id="22" string="count" />
          </tokens>
        </chunking>
        <chunking id="10" string="hard to have its illegal alien population -- estimated at 50,000 -- included in the 1990 count" type="ADJP">
          <tokens>
            <token id="6" string="hard" />
            <token id="7" string="to" />
            <token id="8" string="have" />
            <token id="9" string="its" />
            <token id="10" string="illegal" />
            <token id="11" string="alien" />
            <token id="12" string="population" />
            <token id="13" string="--" />
            <token id="14" string="estimated" />
            <token id="15" string="at" />
            <token id="16" string="50,000" />
            <token id="17" string="--" />
            <token id="18" string="included" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="1990" />
            <token id="22" string="count" />
          </tokens>
        </chunking>
        <chunking id="11" string="50,000" type="NP">
          <tokens>
            <token id="16" string="50,000" />
          </tokens>
        </chunking>
        <chunking id="12" string="has been lobbying hard to have its illegal alien population -- estimated at 50,000 -- included in the 1990 count" type="VP">
          <tokens>
            <token id="3" string="has" />
            <token id="4" string="been" />
            <token id="5" string="lobbying" />
            <token id="6" string="hard" />
            <token id="7" string="to" />
            <token id="8" string="have" />
            <token id="9" string="its" />
            <token id="10" string="illegal" />
            <token id="11" string="alien" />
            <token id="12" string="population" />
            <token id="13" string="--" />
            <token id="14" string="estimated" />
            <token id="15" string="at" />
            <token id="16" string="50,000" />
            <token id="17" string="--" />
            <token id="18" string="included" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="1990" />
            <token id="22" string="count" />
          </tokens>
        </chunking>
        <chunking id="13" string="the 1990 count" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="1990" />
            <token id="22" string="count" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">city</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">lobbying</governor>
          <dependent id="2">city</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">lobbying</governor>
          <dependent id="3">has</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">lobbying</governor>
          <dependent id="4">been</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">lobbying</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">lobbying</governor>
          <dependent id="6">hard</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">have</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">hard</governor>
          <dependent id="8">have</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">population</governor>
          <dependent id="9">its</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">population</governor>
          <dependent id="10">illegal</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">population</governor>
          <dependent id="11">alien</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">have</governor>
          <dependent id="12">population</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="12">population</governor>
          <dependent id="14">estimated</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">50,000</governor>
          <dependent id="15">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">estimated</governor>
          <dependent id="16">50,000</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="12">population</governor>
          <dependent id="18">included</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">count</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">count</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="22">count</governor>
          <dependent id="21">1990</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">included</governor>
          <dependent id="22">count</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="50,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="16" string="50,000" />
          </tokens>
        </entity>
        <entity id="2" string="1990" type="DATE" score="0.0">
          <tokens>
            <token id="21" string="1990" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>The Senate&amp;apost;s action came on a voice vote, despite arguments from the Bush Administration and other opponents that it is both unconstitutional and unworkable.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="2" string="Senate" lemma="Senate" stem="senat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="3" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="4" string="action" lemma="action" stem="action" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="came" lemma="come" stem="came" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="voice" lemma="voice" stem="voic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="vote" lemma="vote" stem="vote" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="despite" lemma="despite" stem="despit" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="arguments" lemma="argument" stem="argument" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Bush" lemma="Bush" stem="bush" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="16" string="Administration" lemma="Administration" stem="administr" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="opponents" lemma="opponent" stem="oppon" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="both" lemma="both" stem="both" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="unconstitutional" lemma="unconstitutional" stem="unconstitut" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="unworkable" lemma="unworkable" stem="unwork" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NNP Senate) (POS 's)) (NN action)) (VP (VBD came) (PP (IN on) (NP (DT a) (NN voice) (NN vote))) (, ,) (PP (IN despite) (NP (NP (NP (NNS arguments)) (PP (IN from) (NP (DT the) (NNP Bush) (NNP Administration)))) (CC and) (NP (NP (JJ other) (NNS opponents)) (SBAR (IN that) (S (NP (PRP it)) (VP (VBZ is) (ADJP (DT both) (JJ unconstitutional) (CC and) (JJ unworkable))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is both unconstitutional and unworkable" type="VP">
          <tokens>
            <token id="22" string="is" />
            <token id="23" string="both" />
            <token id="24" string="unconstitutional" />
            <token id="25" string="and" />
            <token id="26" string="unworkable" />
          </tokens>
        </chunking>
        <chunking id="2" string="both unconstitutional and unworkable" type="ADJP">
          <tokens>
            <token id="23" string="both" />
            <token id="24" string="unconstitutional" />
            <token id="25" string="and" />
            <token id="26" string="unworkable" />
          </tokens>
        </chunking>
        <chunking id="3" string="it" type="NP">
          <tokens>
            <token id="21" string="it" />
          </tokens>
        </chunking>
        <chunking id="4" string="other opponents" type="NP">
          <tokens>
            <token id="18" string="other" />
            <token id="19" string="opponents" />
          </tokens>
        </chunking>
        <chunking id="5" string="the Bush Administration" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="Bush" />
            <token id="16" string="Administration" />
          </tokens>
        </chunking>
        <chunking id="6" string="that it is both unconstitutional and unworkable" type="SBAR">
          <tokens>
            <token id="20" string="that" />
            <token id="21" string="it" />
            <token id="22" string="is" />
            <token id="23" string="both" />
            <token id="24" string="unconstitutional" />
            <token id="25" string="and" />
            <token id="26" string="unworkable" />
          </tokens>
        </chunking>
        <chunking id="7" string="The Senate 's action" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Senate" />
            <token id="3" string="'s" />
            <token id="4" string="action" />
          </tokens>
        </chunking>
        <chunking id="8" string="a voice vote" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="voice" />
            <token id="9" string="vote" />
          </tokens>
        </chunking>
        <chunking id="9" string="arguments from the Bush Administration" type="NP">
          <tokens>
            <token id="12" string="arguments" />
            <token id="13" string="from" />
            <token id="14" string="the" />
            <token id="15" string="Bush" />
            <token id="16" string="Administration" />
          </tokens>
        </chunking>
        <chunking id="10" string="other opponents that it is both unconstitutional and unworkable" type="NP">
          <tokens>
            <token id="18" string="other" />
            <token id="19" string="opponents" />
            <token id="20" string="that" />
            <token id="21" string="it" />
            <token id="22" string="is" />
            <token id="23" string="both" />
            <token id="24" string="unconstitutional" />
            <token id="25" string="and" />
            <token id="26" string="unworkable" />
          </tokens>
        </chunking>
        <chunking id="11" string="arguments" type="NP">
          <tokens>
            <token id="12" string="arguments" />
          </tokens>
        </chunking>
        <chunking id="12" string="came on a voice vote , despite arguments from the Bush Administration and other opponents that it is both unconstitutional and unworkable" type="VP">
          <tokens>
            <token id="5" string="came" />
            <token id="6" string="on" />
            <token id="7" string="a" />
            <token id="8" string="voice" />
            <token id="9" string="vote" />
            <token id="10" string="," />
            <token id="11" string="despite" />
            <token id="12" string="arguments" />
            <token id="13" string="from" />
            <token id="14" string="the" />
            <token id="15" string="Bush" />
            <token id="16" string="Administration" />
            <token id="17" string="and" />
            <token id="18" string="other" />
            <token id="19" string="opponents" />
            <token id="20" string="that" />
            <token id="21" string="it" />
            <token id="22" string="is" />
            <token id="23" string="both" />
            <token id="24" string="unconstitutional" />
            <token id="25" string="and" />
            <token id="26" string="unworkable" />
          </tokens>
        </chunking>
        <chunking id="13" string="The Senate 's" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Senate" />
            <token id="3" string="'s" />
          </tokens>
        </chunking>
        <chunking id="14" string="arguments from the Bush Administration and other opponents that it is both unconstitutional and unworkable" type="NP">
          <tokens>
            <token id="12" string="arguments" />
            <token id="13" string="from" />
            <token id="14" string="the" />
            <token id="15" string="Bush" />
            <token id="16" string="Administration" />
            <token id="17" string="and" />
            <token id="18" string="other" />
            <token id="19" string="opponents" />
            <token id="20" string="that" />
            <token id="21" string="it" />
            <token id="22" string="is" />
            <token id="23" string="both" />
            <token id="24" string="unconstitutional" />
            <token id="25" string="and" />
            <token id="26" string="unworkable" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">Senate</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">action</governor>
          <dependent id="2">Senate</dependent>
        </dependency>
        <dependency type="case">
          <governor id="2">Senate</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">came</governor>
          <dependent id="4">action</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">came</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">vote</governor>
          <dependent id="6">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">vote</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">vote</governor>
          <dependent id="8">voice</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">came</governor>
          <dependent id="9">vote</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">arguments</governor>
          <dependent id="11">despite</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">came</governor>
          <dependent id="12">arguments</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">Administration</governor>
          <dependent id="13">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">Administration</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Administration</governor>
          <dependent id="15">Bush</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">arguments</governor>
          <dependent id="16">Administration</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">arguments</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">opponents</governor>
          <dependent id="18">other</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">arguments</governor>
          <dependent id="19">opponents</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">unconstitutional</governor>
          <dependent id="20">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">unconstitutional</governor>
          <dependent id="21">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="24">unconstitutional</governor>
          <dependent id="22">is</dependent>
        </dependency>
        <dependency type="cc:preconj">
          <governor id="24">unconstitutional</governor>
          <dependent id="23">both</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="19">opponents</governor>
          <dependent id="24">unconstitutional</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="24">unconstitutional</governor>
          <dependent id="25">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="24">unconstitutional</governor>
          <dependent id="26">unworkable</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Senate" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="2" string="Senate" />
          </tokens>
        </entity>
        <entity id="2" string="Bush" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="Bush" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>Just before the voice vote, the senators voted, 50 to 41, against killing the proposal to bar aliens from the count.</content>
      <tokens>
        <token id="1" string="Just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="voice" lemma="voice" stem="voic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="vote" lemma="vote" stem="vote" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="senators" lemma="senator" stem="senat" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="voted" lemma="vote" stem="vote" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="50" lemma="50" stem="50" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="41" lemma="41" stem="41" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="killing" lemma="kill" stem="kill" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="proposal" lemma="proposal" stem="propos" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="bar" lemma="bar" stem="bar" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="aliens" lemma="alien" stem="alien" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="count" lemma="count" stem="count" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (RB Just) (IN before) (NP (DT the) (NN voice) (NN vote))) (, ,) (NP (DT the) (NNS senators)) (VP (VP (VBD voted)) (, ,) (NP (NP (QP (CD 50) (TO to) (CD 41))) (, ,) (PP (IN against) (S (VP (VBG killing) (NP (DT the) (NN proposal)) (PP (TO to) (NP (NN bar) (NNS aliens))) (PP (IN from) (NP (DT the) (NN count)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the proposal" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="proposal" />
          </tokens>
        </chunking>
        <chunking id="2" string="the voice vote" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="voice" />
            <token id="5" string="vote" />
          </tokens>
        </chunking>
        <chunking id="3" string="the senators" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="senators" />
          </tokens>
        </chunking>
        <chunking id="4" string="voted , 50 to 41 , against killing the proposal to bar aliens from the count" type="VP">
          <tokens>
            <token id="9" string="voted" />
            <token id="10" string="," />
            <token id="11" string="50" />
            <token id="12" string="to" />
            <token id="13" string="41" />
            <token id="14" string="," />
            <token id="15" string="against" />
            <token id="16" string="killing" />
            <token id="17" string="the" />
            <token id="18" string="proposal" />
            <token id="19" string="to" />
            <token id="20" string="bar" />
            <token id="21" string="aliens" />
            <token id="22" string="from" />
            <token id="23" string="the" />
            <token id="24" string="count" />
          </tokens>
        </chunking>
        <chunking id="5" string="50 to 41" type="NP">
          <tokens>
            <token id="11" string="50" />
            <token id="12" string="to" />
            <token id="13" string="41" />
          </tokens>
        </chunking>
        <chunking id="6" string="voted" type="VP">
          <tokens>
            <token id="9" string="voted" />
          </tokens>
        </chunking>
        <chunking id="7" string="bar aliens" type="NP">
          <tokens>
            <token id="20" string="bar" />
            <token id="21" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="8" string="killing the proposal to bar aliens from the count" type="VP">
          <tokens>
            <token id="16" string="killing" />
            <token id="17" string="the" />
            <token id="18" string="proposal" />
            <token id="19" string="to" />
            <token id="20" string="bar" />
            <token id="21" string="aliens" />
            <token id="22" string="from" />
            <token id="23" string="the" />
            <token id="24" string="count" />
          </tokens>
        </chunking>
        <chunking id="9" string="the count" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="count" />
          </tokens>
        </chunking>
        <chunking id="10" string="50 to 41 , against killing the proposal to bar aliens from the count" type="NP">
          <tokens>
            <token id="11" string="50" />
            <token id="12" string="to" />
            <token id="13" string="41" />
            <token id="14" string="," />
            <token id="15" string="against" />
            <token id="16" string="killing" />
            <token id="17" string="the" />
            <token id="18" string="proposal" />
            <token id="19" string="to" />
            <token id="20" string="bar" />
            <token id="21" string="aliens" />
            <token id="22" string="from" />
            <token id="23" string="the" />
            <token id="24" string="count" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="5">vote</governor>
          <dependent id="1">Just</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">vote</governor>
          <dependent id="2">before</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">vote</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">vote</governor>
          <dependent id="4">voice</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">voted</governor>
          <dependent id="5">vote</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">senators</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">voted</governor>
          <dependent id="8">senators</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">voted</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">41</governor>
          <dependent id="11">50</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="13">41</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">voted</governor>
          <dependent id="13">41</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">killing</governor>
          <dependent id="15">against</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="13">41</governor>
          <dependent id="16">killing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">proposal</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">killing</governor>
          <dependent id="18">proposal</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">aliens</governor>
          <dependent id="19">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">aliens</governor>
          <dependent id="20">bar</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">killing</governor>
          <dependent id="21">aliens</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">count</governor>
          <dependent id="22">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">count</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">killing</governor>
          <dependent id="24">count</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="50" type="NUMBER" score="0.0">
          <tokens>
            <token id="11" string="50" />
          </tokens>
        </entity>
        <entity id="2" string="41" type="NUMBER" score="0.0">
          <tokens>
            <token id="13" string="41" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>A Senate-House conference committee will decide whether the prohibition against including illegal immigrants in the census totals will be retained or dropped from a $17.4-billion appropriations bill for the State, Justice and Commerce departments.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Senate-House" lemma="senate-house" stem="senate-hous" pos="JJ" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="3" string="conference" lemma="conference" stem="confer" pos="NN" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="4" string="committee" lemma="committee" stem="committe" pos="NN" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="5" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="decide" lemma="decide" stem="decid" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="whether" lemma="whether" stem="whether" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="prohibition" lemma="prohibition" stem="prohibit" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="including" lemma="include" stem="includ" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="immigrants" lemma="immigrant" stem="immigr" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="census" lemma="census" stem="censu" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="totals" lemma="total" stem="total" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="retained" lemma="retain" stem="retain" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="dropped" lemma="drop" stem="drop" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="26" string="17.4-billion" lemma="17.4-billion" stem="17.4-billion" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="27" string="appropriations" lemma="appropriation" stem="appropri" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="bill" lemma="bill" stem="bill" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="State" lemma="State" stem="state" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="32" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="Justice" lemma="Justice" stem="justic" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="34" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="Commerce" lemma="Commerce" stem="commerc" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="36" string="departments" lemma="department" stem="depart" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT A) (JJ Senate-House) (NN conference) (NN committee)) (VP (MD will) (VP (VB decide) (SBAR (IN whether) (S (NP (NP (DT the) (NN prohibition)) (PP (IN against) (S (VP (VBG including) (NP (JJ illegal) (NNS immigrants)) (PP (IN in) (NP (DT the) (NN census) (NNS totals))))))) (VP (MD will) (VP (VB be) (VP (VBN retained) (CC or) (VBN dropped) (PP (IN from) (NP (NP (DT a) ($ $) (CD 17.4-billion) (NNS appropriations) (NN bill)) (PP (IN for) (NP (DT the) (NNP State) (, ,) (NNP Justice) (CC and) (NNP Commerce) (NNS departments)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a $ 17.4-billion appropriations bill" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="$" />
            <token id="26" string="17.4-billion" />
            <token id="27" string="appropriations" />
            <token id="28" string="bill" />
          </tokens>
        </chunking>
        <chunking id="2" string="the prohibition" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="prohibition" />
          </tokens>
        </chunking>
        <chunking id="3" string="the prohibition against including illegal immigrants in the census totals" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="prohibition" />
            <token id="10" string="against" />
            <token id="11" string="including" />
            <token id="12" string="illegal" />
            <token id="13" string="immigrants" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="census" />
            <token id="17" string="totals" />
          </tokens>
        </chunking>
        <chunking id="4" string="retained or dropped from a $ 17.4-billion appropriations bill for the State , Justice and Commerce departments" type="VP">
          <tokens>
            <token id="20" string="retained" />
            <token id="21" string="or" />
            <token id="22" string="dropped" />
            <token id="23" string="from" />
            <token id="24" string="a" />
            <token id="25" string="$" />
            <token id="26" string="17.4-billion" />
            <token id="27" string="appropriations" />
            <token id="28" string="bill" />
            <token id="29" string="for" />
            <token id="30" string="the" />
            <token id="31" string="State" />
            <token id="32" string="," />
            <token id="33" string="Justice" />
            <token id="34" string="and" />
            <token id="35" string="Commerce" />
            <token id="36" string="departments" />
          </tokens>
        </chunking>
        <chunking id="5" string="including illegal immigrants in the census totals" type="VP">
          <tokens>
            <token id="11" string="including" />
            <token id="12" string="illegal" />
            <token id="13" string="immigrants" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="census" />
            <token id="17" string="totals" />
          </tokens>
        </chunking>
        <chunking id="6" string="be retained or dropped from a $ 17.4-billion appropriations bill for the State , Justice and Commerce departments" type="VP">
          <tokens>
            <token id="19" string="be" />
            <token id="20" string="retained" />
            <token id="21" string="or" />
            <token id="22" string="dropped" />
            <token id="23" string="from" />
            <token id="24" string="a" />
            <token id="25" string="$" />
            <token id="26" string="17.4-billion" />
            <token id="27" string="appropriations" />
            <token id="28" string="bill" />
            <token id="29" string="for" />
            <token id="30" string="the" />
            <token id="31" string="State" />
            <token id="32" string="," />
            <token id="33" string="Justice" />
            <token id="34" string="and" />
            <token id="35" string="Commerce" />
            <token id="36" string="departments" />
          </tokens>
        </chunking>
        <chunking id="7" string="illegal immigrants" type="NP">
          <tokens>
            <token id="12" string="illegal" />
            <token id="13" string="immigrants" />
          </tokens>
        </chunking>
        <chunking id="8" string="will decide whether the prohibition against including illegal immigrants in the census totals will be retained or dropped from a $ 17.4-billion appropriations bill for the State , Justice and Commerce departments" type="VP">
          <tokens>
            <token id="5" string="will" />
            <token id="6" string="decide" />
            <token id="7" string="whether" />
            <token id="8" string="the" />
            <token id="9" string="prohibition" />
            <token id="10" string="against" />
            <token id="11" string="including" />
            <token id="12" string="illegal" />
            <token id="13" string="immigrants" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="census" />
            <token id="17" string="totals" />
            <token id="18" string="will" />
            <token id="19" string="be" />
            <token id="20" string="retained" />
            <token id="21" string="or" />
            <token id="22" string="dropped" />
            <token id="23" string="from" />
            <token id="24" string="a" />
            <token id="25" string="$" />
            <token id="26" string="17.4-billion" />
            <token id="27" string="appropriations" />
            <token id="28" string="bill" />
            <token id="29" string="for" />
            <token id="30" string="the" />
            <token id="31" string="State" />
            <token id="32" string="," />
            <token id="33" string="Justice" />
            <token id="34" string="and" />
            <token id="35" string="Commerce" />
            <token id="36" string="departments" />
          </tokens>
        </chunking>
        <chunking id="9" string="will be retained or dropped from a $ 17.4-billion appropriations bill for the State , Justice and Commerce departments" type="VP">
          <tokens>
            <token id="18" string="will" />
            <token id="19" string="be" />
            <token id="20" string="retained" />
            <token id="21" string="or" />
            <token id="22" string="dropped" />
            <token id="23" string="from" />
            <token id="24" string="a" />
            <token id="25" string="$" />
            <token id="26" string="17.4-billion" />
            <token id="27" string="appropriations" />
            <token id="28" string="bill" />
            <token id="29" string="for" />
            <token id="30" string="the" />
            <token id="31" string="State" />
            <token id="32" string="," />
            <token id="33" string="Justice" />
            <token id="34" string="and" />
            <token id="35" string="Commerce" />
            <token id="36" string="departments" />
          </tokens>
        </chunking>
        <chunking id="10" string="a $ 17.4-billion appropriations bill for the State , Justice and Commerce departments" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="$" />
            <token id="26" string="17.4-billion" />
            <token id="27" string="appropriations" />
            <token id="28" string="bill" />
            <token id="29" string="for" />
            <token id="30" string="the" />
            <token id="31" string="State" />
            <token id="32" string="," />
            <token id="33" string="Justice" />
            <token id="34" string="and" />
            <token id="35" string="Commerce" />
            <token id="36" string="departments" />
          </tokens>
        </chunking>
        <chunking id="11" string="decide whether the prohibition against including illegal immigrants in the census totals will be retained or dropped from a $ 17.4-billion appropriations bill for the State , Justice and Commerce departments" type="VP">
          <tokens>
            <token id="6" string="decide" />
            <token id="7" string="whether" />
            <token id="8" string="the" />
            <token id="9" string="prohibition" />
            <token id="10" string="against" />
            <token id="11" string="including" />
            <token id="12" string="illegal" />
            <token id="13" string="immigrants" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="census" />
            <token id="17" string="totals" />
            <token id="18" string="will" />
            <token id="19" string="be" />
            <token id="20" string="retained" />
            <token id="21" string="or" />
            <token id="22" string="dropped" />
            <token id="23" string="from" />
            <token id="24" string="a" />
            <token id="25" string="$" />
            <token id="26" string="17.4-billion" />
            <token id="27" string="appropriations" />
            <token id="28" string="bill" />
            <token id="29" string="for" />
            <token id="30" string="the" />
            <token id="31" string="State" />
            <token id="32" string="," />
            <token id="33" string="Justice" />
            <token id="34" string="and" />
            <token id="35" string="Commerce" />
            <token id="36" string="departments" />
          </tokens>
        </chunking>
        <chunking id="12" string="A Senate-House conference committee" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="Senate-House" />
            <token id="3" string="conference" />
            <token id="4" string="committee" />
          </tokens>
        </chunking>
        <chunking id="13" string="the census totals" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="census" />
            <token id="17" string="totals" />
          </tokens>
        </chunking>
        <chunking id="14" string="the State , Justice and Commerce departments" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="State" />
            <token id="32" string="," />
            <token id="33" string="Justice" />
            <token id="34" string="and" />
            <token id="35" string="Commerce" />
            <token id="36" string="departments" />
          </tokens>
        </chunking>
        <chunking id="15" string="whether the prohibition against including illegal immigrants in the census totals will be retained or dropped from a $ 17.4-billion appropriations bill for the State , Justice and Commerce departments" type="SBAR">
          <tokens>
            <token id="7" string="whether" />
            <token id="8" string="the" />
            <token id="9" string="prohibition" />
            <token id="10" string="against" />
            <token id="11" string="including" />
            <token id="12" string="illegal" />
            <token id="13" string="immigrants" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="census" />
            <token id="17" string="totals" />
            <token id="18" string="will" />
            <token id="19" string="be" />
            <token id="20" string="retained" />
            <token id="21" string="or" />
            <token id="22" string="dropped" />
            <token id="23" string="from" />
            <token id="24" string="a" />
            <token id="25" string="$" />
            <token id="26" string="17.4-billion" />
            <token id="27" string="appropriations" />
            <token id="28" string="bill" />
            <token id="29" string="for" />
            <token id="30" string="the" />
            <token id="31" string="State" />
            <token id="32" string="," />
            <token id="33" string="Justice" />
            <token id="34" string="and" />
            <token id="35" string="Commerce" />
            <token id="36" string="departments" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">committee</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">committee</governor>
          <dependent id="2">Senate-House</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">committee</governor>
          <dependent id="3">conference</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">decide</governor>
          <dependent id="4">committee</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">decide</governor>
          <dependent id="5">will</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">decide</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">retained</governor>
          <dependent id="7">whether</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">prohibition</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="20">retained</governor>
          <dependent id="9">prohibition</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">including</governor>
          <dependent id="10">against</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="9">prohibition</governor>
          <dependent id="11">including</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">immigrants</governor>
          <dependent id="12">illegal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">including</governor>
          <dependent id="13">immigrants</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">totals</governor>
          <dependent id="14">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">totals</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">totals</governor>
          <dependent id="16">census</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">including</governor>
          <dependent id="17">totals</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="20">retained</governor>
          <dependent id="18">will</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="20">retained</governor>
          <dependent id="19">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">decide</governor>
          <dependent id="20">retained</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="20">retained</governor>
          <dependent id="21">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="20">retained</governor>
          <dependent id="22">dropped</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">bill</governor>
          <dependent id="23">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">bill</governor>
          <dependent id="24">a</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="28">bill</governor>
          <dependent id="25">$</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="28">bill</governor>
          <dependent id="26">17.4-billion</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">bill</governor>
          <dependent id="27">appropriations</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">retained</governor>
          <dependent id="28">bill</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">departments</governor>
          <dependent id="29">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="36">departments</governor>
          <dependent id="30">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="36">departments</governor>
          <dependent id="31">State</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="31">State</governor>
          <dependent id="33">Justice</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="31">State</governor>
          <dependent id="34">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="31">State</governor>
          <dependent id="35">Commerce</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">bill</governor>
          <dependent id="36">departments</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Justice" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="33" string="Justice" />
          </tokens>
        </entity>
        <entity id="2" string="State" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="31" string="State" />
          </tokens>
        </entity>
        <entity id="3" string="Senate-House conference committee" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="2" string="Senate-House" />
            <token id="3" string="conference" />
            <token id="4" string="committee" />
          </tokens>
        </entity>
        <entity id="4" string="Commerce" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="35" string="Commerce" />
          </tokens>
        </entity>
        <entity id="5" string="$ 17.4-billion" type="MONEY" score="0.0">
          <tokens>
            <token id="25" string="$" />
            <token id="26" string="17.4-billion" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>Would Urge Veto Even if the prohibition survives, Secretary of Commerce Robert A. Mosbacher has said that he would ask President Bush to veto any bill that comes to his desk with such a provision.</content>
      <tokens>
        <token id="1" string="Would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="Urge" lemma="urge" stem="urge" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Veto" lemma="Veto" stem="veto" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="Even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="prohibition" lemma="prohibition" stem="prohibit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="survives" lemma="survive" stem="surviv" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Secretary" lemma="Secretary" stem="secretari" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="Commerce" lemma="Commerce" stem="commerc" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="Robert" lemma="Robert" stem="robert" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="14" string="A." lemma="A." stem="a." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="15" string="Mosbacher" lemma="Mosbacher" stem="mosbach" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="16" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="ask" lemma="ask" stem="ask" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="President" lemma="President" stem="presid" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="true" is_refers="false" />
        <token id="23" string="Bush" lemma="Bush" stem="bush" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="24" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="veto" lemma="veto" stem="veto" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="bill" lemma="bill" stem="bill" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="comes" lemma="come" stem="come" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="desk" lemma="desk" stem="desk" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="provision" lemma="provision" stem="provis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (MD Would) (VP (VB Urge) (NP (NNP Veto)) (SBAR (RB Even) (IN if) (S (NP (DT the) (NN prohibition)) (VP (VBZ survives))))))) (, ,) (NP (NAC (NNP Secretary) (PP (IN of) (NP (NNP Commerce) (NNP Robert)))) (NNP A.) (NNP Mosbacher)) (VP (VBZ has) (VP (VBD said) (SBAR (IN that) (S (NP (PRP he)) (VP (MD would) (VP (VB ask) (S (NP (NNP President) (NNP Bush)) (VP (TO to) (VP (VB veto) (NP (NP (DT any) (NN bill)) (SBAR (WHNP (WDT that)) (S (VP (VBZ comes) (PP (TO to) (NP (PRP$ his) (NN desk))) (PP (IN with) (NP (JJ such) (DT a) (NN provision)))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Veto" type="NP">
          <tokens>
            <token id="3" string="Veto" />
          </tokens>
        </chunking>
        <chunking id="2" string="Would Urge Veto Even if the prohibition survives" type="VP">
          <tokens>
            <token id="1" string="Would" />
            <token id="2" string="Urge" />
            <token id="3" string="Veto" />
            <token id="4" string="Even" />
            <token id="5" string="if" />
            <token id="6" string="the" />
            <token id="7" string="prohibition" />
            <token id="8" string="survives" />
          </tokens>
        </chunking>
        <chunking id="3" string="the prohibition" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="prohibition" />
          </tokens>
        </chunking>
        <chunking id="4" string="Commerce Robert" type="NP">
          <tokens>
            <token id="12" string="Commerce" />
            <token id="13" string="Robert" />
          </tokens>
        </chunking>
        <chunking id="5" string="such a provision" type="NP">
          <tokens>
            <token id="34" string="such" />
            <token id="35" string="a" />
            <token id="36" string="provision" />
          </tokens>
        </chunking>
        <chunking id="6" string="President Bush" type="NP">
          <tokens>
            <token id="22" string="President" />
            <token id="23" string="Bush" />
          </tokens>
        </chunking>
        <chunking id="7" string="has said that he would ask President Bush to veto any bill that comes to his desk with such a provision" type="VP">
          <tokens>
            <token id="16" string="has" />
            <token id="17" string="said" />
            <token id="18" string="that" />
            <token id="19" string="he" />
            <token id="20" string="would" />
            <token id="21" string="ask" />
            <token id="22" string="President" />
            <token id="23" string="Bush" />
            <token id="24" string="to" />
            <token id="25" string="veto" />
            <token id="26" string="any" />
            <token id="27" string="bill" />
            <token id="28" string="that" />
            <token id="29" string="comes" />
            <token id="30" string="to" />
            <token id="31" string="his" />
            <token id="32" string="desk" />
            <token id="33" string="with" />
            <token id="34" string="such" />
            <token id="35" string="a" />
            <token id="36" string="provision" />
          </tokens>
        </chunking>
        <chunking id="8" string="ask President Bush to veto any bill that comes to his desk with such a provision" type="VP">
          <tokens>
            <token id="21" string="ask" />
            <token id="22" string="President" />
            <token id="23" string="Bush" />
            <token id="24" string="to" />
            <token id="25" string="veto" />
            <token id="26" string="any" />
            <token id="27" string="bill" />
            <token id="28" string="that" />
            <token id="29" string="comes" />
            <token id="30" string="to" />
            <token id="31" string="his" />
            <token id="32" string="desk" />
            <token id="33" string="with" />
            <token id="34" string="such" />
            <token id="35" string="a" />
            <token id="36" string="provision" />
          </tokens>
        </chunking>
        <chunking id="9" string="to veto any bill that comes to his desk with such a provision" type="VP">
          <tokens>
            <token id="24" string="to" />
            <token id="25" string="veto" />
            <token id="26" string="any" />
            <token id="27" string="bill" />
            <token id="28" string="that" />
            <token id="29" string="comes" />
            <token id="30" string="to" />
            <token id="31" string="his" />
            <token id="32" string="desk" />
            <token id="33" string="with" />
            <token id="34" string="such" />
            <token id="35" string="a" />
            <token id="36" string="provision" />
          </tokens>
        </chunking>
        <chunking id="10" string="veto any bill that comes to his desk with such a provision" type="VP">
          <tokens>
            <token id="25" string="veto" />
            <token id="26" string="any" />
            <token id="27" string="bill" />
            <token id="28" string="that" />
            <token id="29" string="comes" />
            <token id="30" string="to" />
            <token id="31" string="his" />
            <token id="32" string="desk" />
            <token id="33" string="with" />
            <token id="34" string="such" />
            <token id="35" string="a" />
            <token id="36" string="provision" />
          </tokens>
        </chunking>
        <chunking id="11" string="any bill" type="NP">
          <tokens>
            <token id="26" string="any" />
            <token id="27" string="bill" />
          </tokens>
        </chunking>
        <chunking id="12" string="said that he would ask President Bush to veto any bill that comes to his desk with such a provision" type="VP">
          <tokens>
            <token id="17" string="said" />
            <token id="18" string="that" />
            <token id="19" string="he" />
            <token id="20" string="would" />
            <token id="21" string="ask" />
            <token id="22" string="President" />
            <token id="23" string="Bush" />
            <token id="24" string="to" />
            <token id="25" string="veto" />
            <token id="26" string="any" />
            <token id="27" string="bill" />
            <token id="28" string="that" />
            <token id="29" string="comes" />
            <token id="30" string="to" />
            <token id="31" string="his" />
            <token id="32" string="desk" />
            <token id="33" string="with" />
            <token id="34" string="such" />
            <token id="35" string="a" />
            <token id="36" string="provision" />
          </tokens>
        </chunking>
        <chunking id="13" string="his desk" type="NP">
          <tokens>
            <token id="31" string="his" />
            <token id="32" string="desk" />
          </tokens>
        </chunking>
        <chunking id="14" string="that comes to his desk with such a provision" type="SBAR">
          <tokens>
            <token id="28" string="that" />
            <token id="29" string="comes" />
            <token id="30" string="to" />
            <token id="31" string="his" />
            <token id="32" string="desk" />
            <token id="33" string="with" />
            <token id="34" string="such" />
            <token id="35" string="a" />
            <token id="36" string="provision" />
          </tokens>
        </chunking>
        <chunking id="15" string="any bill that comes to his desk with such a provision" type="NP">
          <tokens>
            <token id="26" string="any" />
            <token id="27" string="bill" />
            <token id="28" string="that" />
            <token id="29" string="comes" />
            <token id="30" string="to" />
            <token id="31" string="his" />
            <token id="32" string="desk" />
            <token id="33" string="with" />
            <token id="34" string="such" />
            <token id="35" string="a" />
            <token id="36" string="provision" />
          </tokens>
        </chunking>
        <chunking id="16" string="that he would ask President Bush to veto any bill that comes to his desk with such a provision" type="SBAR">
          <tokens>
            <token id="18" string="that" />
            <token id="19" string="he" />
            <token id="20" string="would" />
            <token id="21" string="ask" />
            <token id="22" string="President" />
            <token id="23" string="Bush" />
            <token id="24" string="to" />
            <token id="25" string="veto" />
            <token id="26" string="any" />
            <token id="27" string="bill" />
            <token id="28" string="that" />
            <token id="29" string="comes" />
            <token id="30" string="to" />
            <token id="31" string="his" />
            <token id="32" string="desk" />
            <token id="33" string="with" />
            <token id="34" string="such" />
            <token id="35" string="a" />
            <token id="36" string="provision" />
          </tokens>
        </chunking>
        <chunking id="17" string="Even if the prohibition survives" type="SBAR">
          <tokens>
            <token id="4" string="Even" />
            <token id="5" string="if" />
            <token id="6" string="the" />
            <token id="7" string="prohibition" />
            <token id="8" string="survives" />
          </tokens>
        </chunking>
        <chunking id="18" string="survives" type="VP">
          <tokens>
            <token id="8" string="survives" />
          </tokens>
        </chunking>
        <chunking id="19" string="comes to his desk with such a provision" type="VP">
          <tokens>
            <token id="29" string="comes" />
            <token id="30" string="to" />
            <token id="31" string="his" />
            <token id="32" string="desk" />
            <token id="33" string="with" />
            <token id="34" string="such" />
            <token id="35" string="a" />
            <token id="36" string="provision" />
          </tokens>
        </chunking>
        <chunking id="20" string="he" type="NP">
          <tokens>
            <token id="19" string="he" />
          </tokens>
        </chunking>
        <chunking id="21" string="Urge Veto Even if the prohibition survives" type="VP">
          <tokens>
            <token id="2" string="Urge" />
            <token id="3" string="Veto" />
            <token id="4" string="Even" />
            <token id="5" string="if" />
            <token id="6" string="the" />
            <token id="7" string="prohibition" />
            <token id="8" string="survives" />
          </tokens>
        </chunking>
        <chunking id="22" string="would ask President Bush to veto any bill that comes to his desk with such a provision" type="VP">
          <tokens>
            <token id="20" string="would" />
            <token id="21" string="ask" />
            <token id="22" string="President" />
            <token id="23" string="Bush" />
            <token id="24" string="to" />
            <token id="25" string="veto" />
            <token id="26" string="any" />
            <token id="27" string="bill" />
            <token id="28" string="that" />
            <token id="29" string="comes" />
            <token id="30" string="to" />
            <token id="31" string="his" />
            <token id="32" string="desk" />
            <token id="33" string="with" />
            <token id="34" string="such" />
            <token id="35" string="a" />
            <token id="36" string="provision" />
          </tokens>
        </chunking>
        <chunking id="23" string="Secretary of Commerce Robert A. Mosbacher" type="NP">
          <tokens>
            <token id="10" string="Secretary" />
            <token id="11" string="of" />
            <token id="12" string="Commerce" />
            <token id="13" string="Robert" />
            <token id="14" string="A." />
            <token id="15" string="Mosbacher" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="aux">
          <governor id="2">Urge</governor>
          <dependent id="1">Would</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">said</governor>
          <dependent id="2">Urge</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">Urge</governor>
          <dependent id="3">Veto</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">survives</governor>
          <dependent id="4">Even</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">survives</governor>
          <dependent id="5">if</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">prohibition</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">survives</governor>
          <dependent id="7">prohibition</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="2">Urge</governor>
          <dependent id="8">survives</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="15">Mosbacher</governor>
          <dependent id="10">Secretary</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Robert</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Robert</governor>
          <dependent id="12">Commerce</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">Secretary</governor>
          <dependent id="13">Robert</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Mosbacher</governor>
          <dependent id="14">A.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">said</governor>
          <dependent id="15">Mosbacher</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="17">said</governor>
          <dependent id="16">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">said</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">ask</governor>
          <dependent id="18">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">ask</governor>
          <dependent id="19">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">ask</governor>
          <dependent id="20">would</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">said</governor>
          <dependent id="21">ask</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">Bush</governor>
          <dependent id="22">President</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">ask</governor>
          <dependent id="23">Bush</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="25">veto</governor>
          <dependent id="24">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="21">ask</governor>
          <dependent id="25">veto</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">bill</governor>
          <dependent id="26">any</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">veto</governor>
          <dependent id="27">bill</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">comes</governor>
          <dependent id="28">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="27">bill</governor>
          <dependent id="29">comes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">desk</governor>
          <dependent id="30">to</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="32">desk</governor>
          <dependent id="31">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">comes</governor>
          <dependent id="32">desk</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">provision</governor>
          <dependent id="33">with</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="36">provision</governor>
          <dependent id="34">such</dependent>
        </dependency>
        <dependency type="det">
          <governor id="36">provision</governor>
          <dependent id="35">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">comes</governor>
          <dependent id="36">provision</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Bush" type="PERSON" score="0.0">
          <tokens>
            <token id="23" string="Bush" />
          </tokens>
        </entity>
        <entity id="2" string="President" type="TITLE" score="0.0">
          <tokens>
            <token id="22" string="President" />
          </tokens>
        </entity>
        <entity id="3" string="Robert A. Mosbacher" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Robert" />
            <token id="14" string="A." />
            <token id="15" string="Mosbacher" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>At stake are the number of seats in Congress for California, Florida, New York, Illinois, Pennsylvania and other states that will be reapportioned on the basis of next year&amp;apost;s census.</content>
      <tokens>
        <token id="1" string="At" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="stake" lemma="stake" stem="stake" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="number" lemma="number" stem="number" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="seats" lemma="seat" stem="seat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Congress" lemma="Congress" stem="congress" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="10" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="California" lemma="California" stem="california" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Florida" lemma="Florida" stem="florida" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="New" lemma="New" stem="new" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="16" string="York" lemma="York" stem="york" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Illinois" lemma="Illinois" stem="illinoi" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Pennsylvania" lemma="Pennsylvania" stem="pennsylvania" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="21" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="states" lemma="state" stem="state" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="reapportioned" lemma="reapportion" stem="reapport" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="basis" lemma="basis" stem="basi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="next" lemma="next" stem="next" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="33" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="34" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="census" lemma="census" stem="censu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (PP (IN At) (NP (NN stake))) (VP (VBP are)) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NP (NNS seats)) (PP (IN in) (NP (NNP Congress))))) (PP (IN for) (NP (NP (NNP California)) (, ,) (NP (NNP Florida)) (, ,) (NP (NNP New) (NNP York)) (, ,) (NP (NNP Illinois)) (, ,) (NP (NNP Pennsylvania)) (CC and) (NP (JJ other) (NNS states)))) (SBAR (WHNP (WDT that)) (S (VP (MD will) (VP (VB be) (VP (VBN reapportioned) (PP (IN on) (NP (NP (DT the) (NN basis)) (PP (IN of) (NP (NP-TMP (JJ next) (NN year) (POS 's)) (NN census))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="New York" type="NP">
          <tokens>
            <token id="15" string="New" />
            <token id="16" string="York" />
          </tokens>
        </chunking>
        <chunking id="2" string="California" type="NP">
          <tokens>
            <token id="11" string="California" />
          </tokens>
        </chunking>
        <chunking id="3" string="that will be reapportioned on the basis of next year 's census" type="SBAR">
          <tokens>
            <token id="24" string="that" />
            <token id="25" string="will" />
            <token id="26" string="be" />
            <token id="27" string="reapportioned" />
            <token id="28" string="on" />
            <token id="29" string="the" />
            <token id="30" string="basis" />
            <token id="31" string="of" />
            <token id="32" string="next" />
            <token id="33" string="year" />
            <token id="34" string="'s" />
            <token id="35" string="census" />
          </tokens>
        </chunking>
        <chunking id="4" string="the number of seats in Congress for California , Florida , New York , Illinois , Pennsylvania and other states that will be reapportioned on the basis of next year 's census" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="number" />
            <token id="6" string="of" />
            <token id="7" string="seats" />
            <token id="8" string="in" />
            <token id="9" string="Congress" />
            <token id="10" string="for" />
            <token id="11" string="California" />
            <token id="12" string="," />
            <token id="13" string="Florida" />
            <token id="14" string="," />
            <token id="15" string="New" />
            <token id="16" string="York" />
            <token id="17" string="," />
            <token id="18" string="Illinois" />
            <token id="19" string="," />
            <token id="20" string="Pennsylvania" />
            <token id="21" string="and" />
            <token id="22" string="other" />
            <token id="23" string="states" />
            <token id="24" string="that" />
            <token id="25" string="will" />
            <token id="26" string="be" />
            <token id="27" string="reapportioned" />
            <token id="28" string="on" />
            <token id="29" string="the" />
            <token id="30" string="basis" />
            <token id="31" string="of" />
            <token id="32" string="next" />
            <token id="33" string="year" />
            <token id="34" string="'s" />
            <token id="35" string="census" />
          </tokens>
        </chunking>
        <chunking id="5" string="other states" type="NP">
          <tokens>
            <token id="22" string="other" />
            <token id="23" string="states" />
          </tokens>
        </chunking>
        <chunking id="6" string="Pennsylvania" type="NP">
          <tokens>
            <token id="20" string="Pennsylvania" />
          </tokens>
        </chunking>
        <chunking id="7" string="be reapportioned on the basis of next year 's census" type="VP">
          <tokens>
            <token id="26" string="be" />
            <token id="27" string="reapportioned" />
            <token id="28" string="on" />
            <token id="29" string="the" />
            <token id="30" string="basis" />
            <token id="31" string="of" />
            <token id="32" string="next" />
            <token id="33" string="year" />
            <token id="34" string="'s" />
            <token id="35" string="census" />
          </tokens>
        </chunking>
        <chunking id="8" string="Florida" type="NP">
          <tokens>
            <token id="13" string="Florida" />
          </tokens>
        </chunking>
        <chunking id="9" string="seats" type="NP">
          <tokens>
            <token id="7" string="seats" />
          </tokens>
        </chunking>
        <chunking id="10" string="Congress" type="NP">
          <tokens>
            <token id="9" string="Congress" />
          </tokens>
        </chunking>
        <chunking id="11" string="seats in Congress" type="NP">
          <tokens>
            <token id="7" string="seats" />
            <token id="8" string="in" />
            <token id="9" string="Congress" />
          </tokens>
        </chunking>
        <chunking id="12" string="the basis" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="basis" />
          </tokens>
        </chunking>
        <chunking id="13" string="next year 's census" type="NP">
          <tokens>
            <token id="32" string="next" />
            <token id="33" string="year" />
            <token id="34" string="'s" />
            <token id="35" string="census" />
          </tokens>
        </chunking>
        <chunking id="14" string="are" type="VP">
          <tokens>
            <token id="3" string="are" />
          </tokens>
        </chunking>
        <chunking id="15" string="stake" type="NP">
          <tokens>
            <token id="2" string="stake" />
          </tokens>
        </chunking>
        <chunking id="16" string="the basis of next year 's census" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="basis" />
            <token id="31" string="of" />
            <token id="32" string="next" />
            <token id="33" string="year" />
            <token id="34" string="'s" />
            <token id="35" string="census" />
          </tokens>
        </chunking>
        <chunking id="17" string="reapportioned on the basis of next year 's census" type="VP">
          <tokens>
            <token id="27" string="reapportioned" />
            <token id="28" string="on" />
            <token id="29" string="the" />
            <token id="30" string="basis" />
            <token id="31" string="of" />
            <token id="32" string="next" />
            <token id="33" string="year" />
            <token id="34" string="'s" />
            <token id="35" string="census" />
          </tokens>
        </chunking>
        <chunking id="18" string="Illinois" type="NP">
          <tokens>
            <token id="18" string="Illinois" />
          </tokens>
        </chunking>
        <chunking id="19" string="will be reapportioned on the basis of next year 's census" type="VP">
          <tokens>
            <token id="25" string="will" />
            <token id="26" string="be" />
            <token id="27" string="reapportioned" />
            <token id="28" string="on" />
            <token id="29" string="the" />
            <token id="30" string="basis" />
            <token id="31" string="of" />
            <token id="32" string="next" />
            <token id="33" string="year" />
            <token id="34" string="'s" />
            <token id="35" string="census" />
          </tokens>
        </chunking>
        <chunking id="20" string="the number" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="number" />
          </tokens>
        </chunking>
        <chunking id="21" string="California , Florida , New York , Illinois , Pennsylvania and other states" type="NP">
          <tokens>
            <token id="11" string="California" />
            <token id="12" string="," />
            <token id="13" string="Florida" />
            <token id="14" string="," />
            <token id="15" string="New" />
            <token id="16" string="York" />
            <token id="17" string="," />
            <token id="18" string="Illinois" />
            <token id="19" string="," />
            <token id="20" string="Pennsylvania" />
            <token id="21" string="and" />
            <token id="22" string="other" />
            <token id="23" string="states" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">stake</governor>
          <dependent id="1">At</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">are</governor>
          <dependent id="2">stake</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">are</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">number</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">are</governor>
          <dependent id="5">number</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">seats</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">number</governor>
          <dependent id="7">seats</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Congress</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">seats</governor>
          <dependent id="9">Congress</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">California</governor>
          <dependent id="10">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">number</governor>
          <dependent id="11">California</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">California</governor>
          <dependent id="13">Florida</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">York</governor>
          <dependent id="15">New</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">California</governor>
          <dependent id="16">York</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">California</governor>
          <dependent id="18">Illinois</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">California</governor>
          <dependent id="20">Pennsylvania</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">California</governor>
          <dependent id="21">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">states</governor>
          <dependent id="22">other</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">California</governor>
          <dependent id="23">states</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="27">reapportioned</governor>
          <dependent id="24">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="27">reapportioned</governor>
          <dependent id="25">will</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="27">reapportioned</governor>
          <dependent id="26">be</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="5">number</governor>
          <dependent id="27">reapportioned</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">basis</governor>
          <dependent id="28">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">basis</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">reapportioned</governor>
          <dependent id="30">basis</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">census</governor>
          <dependent id="31">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="33">year</governor>
          <dependent id="32">next</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="35">census</governor>
          <dependent id="33">year</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">year</governor>
          <dependent id="34">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">basis</governor>
          <dependent id="35">census</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="New York" type="LOCATION" score="0.0">
          <tokens>
            <token id="15" string="New" />
            <token id="16" string="York" />
          </tokens>
        </entity>
        <entity id="2" string="California" type="LOCATION" score="0.0">
          <tokens>
            <token id="11" string="California" />
          </tokens>
        </entity>
        <entity id="3" string="Illinois" type="LOCATION" score="0.0">
          <tokens>
            <token id="18" string="Illinois" />
          </tokens>
        </entity>
        <entity id="4" string="Pennsylvania" type="LOCATION" score="0.0">
          <tokens>
            <token id="20" string="Pennsylvania" />
          </tokens>
        </entity>
        <entity id="5" string="Florida" type="LOCATION" score="0.0">
          <tokens>
            <token id="13" string="Florida" />
          </tokens>
        </entity>
        <entity id="6" string="next year" type="DATE" score="0.0">
          <tokens>
            <token id="32" string="next" />
            <token id="33" string="year" />
          </tokens>
        </entity>
        <entity id="7" string="Congress" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="9" string="Congress" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>Federal aid to states also is frequently based on population counts, so millions of dollars in grants and other funds made available on a per capita basis would be affected.</content>
      <tokens>
        <token id="1" string="Federal" lemma="Federal" stem="feder" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="aid" lemma="aid" stem="aid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="states" lemma="state" stem="state" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="frequently" lemma="frequently" stem="frequent" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="based" lemma="base" stem="base" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="population" lemma="population" stem="popul" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="counts" lemma="count" stem="count" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="millions" lemma="million" stem="million" pos="NNS" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="16" string="dollars" lemma="dollar" stem="dollar" pos="NNS" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="17" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="grants" lemma="grant" stem="grant" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="funds" lemma="fund" stem="fund" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="made" lemma="make" stem="made" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="available" lemma="available" stem="avail" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="per" lemma="per" stem="per" pos="FW" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="capita" lemma="capita" stem="capita" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="basis" lemma="basis" stem="basi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="affected" lemma="affect" stem="affect" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Federal) (NN aid)) (PP (TO to) (NP (NNS states)))) (ADVP (RB also)) (VP (VBZ is) (ADVP (RB frequently)) (VP (VBN based) (PP (IN on) (NP (NP (NN population) (NNS counts)) (, ,) (NP (NP (QP (RB so) (NNS millions))) (PP (IN of) (NP (NP (NNS dollars)) (PP (IN in) (NP (NP (NNS grants)) (CC and) (NP (JJ other) (NNS funds)))))) (VP (VBN made) (ADJP (JJ available)) (PP (IN on) (NP (NP (DT a) (FW per) (NN capita) (NN basis)) (SBAR (S (VP (MD would) (VP (VB be) (VP (VBN affected)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="grants" type="NP">
          <tokens>
            <token id="18" string="grants" />
          </tokens>
        </chunking>
        <chunking id="2" string="Federal aid to states" type="NP">
          <tokens>
            <token id="1" string="Federal" />
            <token id="2" string="aid" />
            <token id="3" string="to" />
            <token id="4" string="states" />
          </tokens>
        </chunking>
        <chunking id="3" string="population counts , so millions of dollars in grants and other funds made available on a per capita basis would be affected" type="NP">
          <tokens>
            <token id="10" string="population" />
            <token id="11" string="counts" />
            <token id="12" string="," />
            <token id="13" string="so" />
            <token id="14" string="millions" />
            <token id="15" string="of" />
            <token id="16" string="dollars" />
            <token id="17" string="in" />
            <token id="18" string="grants" />
            <token id="19" string="and" />
            <token id="20" string="other" />
            <token id="21" string="funds" />
            <token id="22" string="made" />
            <token id="23" string="available" />
            <token id="24" string="on" />
            <token id="25" string="a" />
            <token id="26" string="per" />
            <token id="27" string="capita" />
            <token id="28" string="basis" />
            <token id="29" string="would" />
            <token id="30" string="be" />
            <token id="31" string="affected" />
          </tokens>
        </chunking>
        <chunking id="4" string="so millions of dollars in grants and other funds made available on a per capita basis would be affected" type="NP">
          <tokens>
            <token id="13" string="so" />
            <token id="14" string="millions" />
            <token id="15" string="of" />
            <token id="16" string="dollars" />
            <token id="17" string="in" />
            <token id="18" string="grants" />
            <token id="19" string="and" />
            <token id="20" string="other" />
            <token id="21" string="funds" />
            <token id="22" string="made" />
            <token id="23" string="available" />
            <token id="24" string="on" />
            <token id="25" string="a" />
            <token id="26" string="per" />
            <token id="27" string="capita" />
            <token id="28" string="basis" />
            <token id="29" string="would" />
            <token id="30" string="be" />
            <token id="31" string="affected" />
          </tokens>
        </chunking>
        <chunking id="5" string="a per capita basis would be affected" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="per" />
            <token id="27" string="capita" />
            <token id="28" string="basis" />
            <token id="29" string="would" />
            <token id="30" string="be" />
            <token id="31" string="affected" />
          </tokens>
        </chunking>
        <chunking id="6" string="available" type="ADJP">
          <tokens>
            <token id="23" string="available" />
          </tokens>
        </chunking>
        <chunking id="7" string="a per capita basis" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="per" />
            <token id="27" string="capita" />
            <token id="28" string="basis" />
          </tokens>
        </chunking>
        <chunking id="8" string="affected" type="VP">
          <tokens>
            <token id="31" string="affected" />
          </tokens>
        </chunking>
        <chunking id="9" string="is frequently based on population counts , so millions of dollars in grants and other funds made available on a per capita basis would be affected" type="VP">
          <tokens>
            <token id="6" string="is" />
            <token id="7" string="frequently" />
            <token id="8" string="based" />
            <token id="9" string="on" />
            <token id="10" string="population" />
            <token id="11" string="counts" />
            <token id="12" string="," />
            <token id="13" string="so" />
            <token id="14" string="millions" />
            <token id="15" string="of" />
            <token id="16" string="dollars" />
            <token id="17" string="in" />
            <token id="18" string="grants" />
            <token id="19" string="and" />
            <token id="20" string="other" />
            <token id="21" string="funds" />
            <token id="22" string="made" />
            <token id="23" string="available" />
            <token id="24" string="on" />
            <token id="25" string="a" />
            <token id="26" string="per" />
            <token id="27" string="capita" />
            <token id="28" string="basis" />
            <token id="29" string="would" />
            <token id="30" string="be" />
            <token id="31" string="affected" />
          </tokens>
        </chunking>
        <chunking id="10" string="dollars" type="NP">
          <tokens>
            <token id="16" string="dollars" />
          </tokens>
        </chunking>
        <chunking id="11" string="states" type="NP">
          <tokens>
            <token id="4" string="states" />
          </tokens>
        </chunking>
        <chunking id="12" string="population counts" type="NP">
          <tokens>
            <token id="10" string="population" />
            <token id="11" string="counts" />
          </tokens>
        </chunking>
        <chunking id="13" string="dollars in grants and other funds" type="NP">
          <tokens>
            <token id="16" string="dollars" />
            <token id="17" string="in" />
            <token id="18" string="grants" />
            <token id="19" string="and" />
            <token id="20" string="other" />
            <token id="21" string="funds" />
          </tokens>
        </chunking>
        <chunking id="14" string="based on population counts , so millions of dollars in grants and other funds made available on a per capita basis would be affected" type="VP">
          <tokens>
            <token id="8" string="based" />
            <token id="9" string="on" />
            <token id="10" string="population" />
            <token id="11" string="counts" />
            <token id="12" string="," />
            <token id="13" string="so" />
            <token id="14" string="millions" />
            <token id="15" string="of" />
            <token id="16" string="dollars" />
            <token id="17" string="in" />
            <token id="18" string="grants" />
            <token id="19" string="and" />
            <token id="20" string="other" />
            <token id="21" string="funds" />
            <token id="22" string="made" />
            <token id="23" string="available" />
            <token id="24" string="on" />
            <token id="25" string="a" />
            <token id="26" string="per" />
            <token id="27" string="capita" />
            <token id="28" string="basis" />
            <token id="29" string="would" />
            <token id="30" string="be" />
            <token id="31" string="affected" />
          </tokens>
        </chunking>
        <chunking id="15" string="made available on a per capita basis would be affected" type="VP">
          <tokens>
            <token id="22" string="made" />
            <token id="23" string="available" />
            <token id="24" string="on" />
            <token id="25" string="a" />
            <token id="26" string="per" />
            <token id="27" string="capita" />
            <token id="28" string="basis" />
            <token id="29" string="would" />
            <token id="30" string="be" />
            <token id="31" string="affected" />
          </tokens>
        </chunking>
        <chunking id="16" string="so millions" type="NP">
          <tokens>
            <token id="13" string="so" />
            <token id="14" string="millions" />
          </tokens>
        </chunking>
        <chunking id="17" string="other funds" type="NP">
          <tokens>
            <token id="20" string="other" />
            <token id="21" string="funds" />
          </tokens>
        </chunking>
        <chunking id="18" string="Federal aid" type="NP">
          <tokens>
            <token id="1" string="Federal" />
            <token id="2" string="aid" />
          </tokens>
        </chunking>
        <chunking id="19" string="would be affected" type="SBAR">
          <tokens>
            <token id="29" string="would" />
            <token id="30" string="be" />
            <token id="31" string="affected" />
          </tokens>
        </chunking>
        <chunking id="20" string="be affected" type="VP">
          <tokens>
            <token id="30" string="be" />
            <token id="31" string="affected" />
          </tokens>
        </chunking>
        <chunking id="21" string="grants and other funds" type="NP">
          <tokens>
            <token id="18" string="grants" />
            <token id="19" string="and" />
            <token id="20" string="other" />
            <token id="21" string="funds" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">aid</governor>
          <dependent id="1">Federal</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="8">based</governor>
          <dependent id="2">aid</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">states</governor>
          <dependent id="3">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">aid</governor>
          <dependent id="4">states</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">based</governor>
          <dependent id="5">also</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="8">based</governor>
          <dependent id="6">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">based</governor>
          <dependent id="7">frequently</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">based</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">counts</governor>
          <dependent id="9">on</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">counts</governor>
          <dependent id="10">population</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">based</governor>
          <dependent id="11">counts</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">millions</governor>
          <dependent id="13">so</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="11">counts</governor>
          <dependent id="14">millions</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">dollars</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">millions</governor>
          <dependent id="16">dollars</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">grants</governor>
          <dependent id="17">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">dollars</governor>
          <dependent id="18">grants</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="18">grants</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">funds</governor>
          <dependent id="20">other</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">grants</governor>
          <dependent id="21">funds</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="14">millions</governor>
          <dependent id="22">made</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="22">made</governor>
          <dependent id="23">available</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">basis</governor>
          <dependent id="24">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">basis</governor>
          <dependent id="25">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">basis</governor>
          <dependent id="26">per</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">basis</governor>
          <dependent id="27">capita</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">made</governor>
          <dependent id="28">basis</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="31">affected</governor>
          <dependent id="29">would</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="31">affected</governor>
          <dependent id="30">be</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="28">basis</governor>
          <dependent id="31">affected</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="millions of dollars" type="MONEY" score="0.0">
          <tokens>
            <token id="14" string="millions" />
            <token id="15" string="of" />
            <token id="16" string="dollars" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="false">
      <content>State officials have said California could lose up to $300 million in federal aid if illegal aliens were uncounted.</content>
      <tokens>
        <token id="1" string="State" lemma="state" stem="state" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="officials" lemma="official" stem="offici" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="said" lemma="say" stem="said" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="California" lemma="California" stem="california" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="6" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="lose" lemma="lose" stem="lose" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="11" string="300" lemma="300" stem="300" pos="CD" type="Number" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="12" string="million" lemma="million" stem="million" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="federal" lemma="federal" stem="feder" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="aid" lemma="aid" stem="aid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="aliens" lemma="alien" stem="alien" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="uncounted" lemma="uncounted" stem="uncount" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NN State) (NNS officials)) (VP (VBP have) (VP (VBN said) (SBAR (S (NP (NNP California)) (VP (MD could) (VP (VB lose) (PRT (RP up)) (PP (TO to) (NP (NP (QP ($ $) (CD 300) (CD million))) (PP (IN in) (NP (JJ federal) (NN aid))))) (SBAR (IN if) (S (NP (JJ illegal) (NNS aliens)) (VP (VBD were) (ADJP (JJ uncounted))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="federal aid" type="NP">
          <tokens>
            <token id="14" string="federal" />
            <token id="15" string="aid" />
          </tokens>
        </chunking>
        <chunking id="2" string="illegal aliens" type="NP">
          <tokens>
            <token id="17" string="illegal" />
            <token id="18" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="3" string="California" type="NP">
          <tokens>
            <token id="5" string="California" />
          </tokens>
        </chunking>
        <chunking id="4" string="$ 300 million in federal aid" type="NP">
          <tokens>
            <token id="10" string="$" />
            <token id="11" string="300" />
            <token id="12" string="million" />
            <token id="13" string="in" />
            <token id="14" string="federal" />
            <token id="15" string="aid" />
          </tokens>
        </chunking>
        <chunking id="5" string="if illegal aliens were uncounted" type="SBAR">
          <tokens>
            <token id="16" string="if" />
            <token id="17" string="illegal" />
            <token id="18" string="aliens" />
            <token id="19" string="were" />
            <token id="20" string="uncounted" />
          </tokens>
        </chunking>
        <chunking id="6" string="said California could lose up to $ 300 million in federal aid if illegal aliens were uncounted" type="VP">
          <tokens>
            <token id="4" string="said" />
            <token id="5" string="California" />
            <token id="6" string="could" />
            <token id="7" string="lose" />
            <token id="8" string="up" />
            <token id="9" string="to" />
            <token id="10" string="$" />
            <token id="11" string="300" />
            <token id="12" string="million" />
            <token id="13" string="in" />
            <token id="14" string="federal" />
            <token id="15" string="aid" />
            <token id="16" string="if" />
            <token id="17" string="illegal" />
            <token id="18" string="aliens" />
            <token id="19" string="were" />
            <token id="20" string="uncounted" />
          </tokens>
        </chunking>
        <chunking id="7" string="could lose up to $ 300 million in federal aid if illegal aliens were uncounted" type="VP">
          <tokens>
            <token id="6" string="could" />
            <token id="7" string="lose" />
            <token id="8" string="up" />
            <token id="9" string="to" />
            <token id="10" string="$" />
            <token id="11" string="300" />
            <token id="12" string="million" />
            <token id="13" string="in" />
            <token id="14" string="federal" />
            <token id="15" string="aid" />
            <token id="16" string="if" />
            <token id="17" string="illegal" />
            <token id="18" string="aliens" />
            <token id="19" string="were" />
            <token id="20" string="uncounted" />
          </tokens>
        </chunking>
        <chunking id="8" string="$ 300 million" type="NP">
          <tokens>
            <token id="10" string="$" />
            <token id="11" string="300" />
            <token id="12" string="million" />
          </tokens>
        </chunking>
        <chunking id="9" string="uncounted" type="ADJP">
          <tokens>
            <token id="20" string="uncounted" />
          </tokens>
        </chunking>
        <chunking id="10" string="California could lose up to $ 300 million in federal aid if illegal aliens were uncounted" type="SBAR">
          <tokens>
            <token id="5" string="California" />
            <token id="6" string="could" />
            <token id="7" string="lose" />
            <token id="8" string="up" />
            <token id="9" string="to" />
            <token id="10" string="$" />
            <token id="11" string="300" />
            <token id="12" string="million" />
            <token id="13" string="in" />
            <token id="14" string="federal" />
            <token id="15" string="aid" />
            <token id="16" string="if" />
            <token id="17" string="illegal" />
            <token id="18" string="aliens" />
            <token id="19" string="were" />
            <token id="20" string="uncounted" />
          </tokens>
        </chunking>
        <chunking id="11" string="lose up to $ 300 million in federal aid if illegal aliens were uncounted" type="VP">
          <tokens>
            <token id="7" string="lose" />
            <token id="8" string="up" />
            <token id="9" string="to" />
            <token id="10" string="$" />
            <token id="11" string="300" />
            <token id="12" string="million" />
            <token id="13" string="in" />
            <token id="14" string="federal" />
            <token id="15" string="aid" />
            <token id="16" string="if" />
            <token id="17" string="illegal" />
            <token id="18" string="aliens" />
            <token id="19" string="were" />
            <token id="20" string="uncounted" />
          </tokens>
        </chunking>
        <chunking id="12" string="State officials" type="NP">
          <tokens>
            <token id="1" string="State" />
            <token id="2" string="officials" />
          </tokens>
        </chunking>
        <chunking id="13" string="were uncounted" type="VP">
          <tokens>
            <token id="19" string="were" />
            <token id="20" string="uncounted" />
          </tokens>
        </chunking>
        <chunking id="14" string="have said California could lose up to $ 300 million in federal aid if illegal aliens were uncounted" type="VP">
          <tokens>
            <token id="3" string="have" />
            <token id="4" string="said" />
            <token id="5" string="California" />
            <token id="6" string="could" />
            <token id="7" string="lose" />
            <token id="8" string="up" />
            <token id="9" string="to" />
            <token id="10" string="$" />
            <token id="11" string="300" />
            <token id="12" string="million" />
            <token id="13" string="in" />
            <token id="14" string="federal" />
            <token id="15" string="aid" />
            <token id="16" string="if" />
            <token id="17" string="illegal" />
            <token id="18" string="aliens" />
            <token id="19" string="were" />
            <token id="20" string="uncounted" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">officials</governor>
          <dependent id="1">State</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">said</governor>
          <dependent id="2">officials</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">said</governor>
          <dependent id="3">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">lose</governor>
          <dependent id="5">California</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">lose</governor>
          <dependent id="6">could</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">said</governor>
          <dependent id="7">lose</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="7">lose</governor>
          <dependent id="8">up</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">$</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">lose</governor>
          <dependent id="10">$</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">million</governor>
          <dependent id="11">300</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="10">$</governor>
          <dependent id="12">million</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">aid</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">aid</governor>
          <dependent id="14">federal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">$</governor>
          <dependent id="15">aid</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">uncounted</governor>
          <dependent id="16">if</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">aliens</governor>
          <dependent id="17">illegal</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">uncounted</governor>
          <dependent id="18">aliens</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="20">uncounted</governor>
          <dependent id="19">were</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">lose</governor>
          <dependent id="20">uncounted</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="California" type="LOCATION" score="0.0">
          <tokens>
            <token id="5" string="California" />
          </tokens>
        </entity>
        <entity id="2" string="$ 300 million" type="MONEY" score="0.0">
          <tokens>
            <token id="10" string="$" />
            <token id="11" string="300" />
            <token id="12" string="million" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>Santa Ana has estimated its potential loss at $2 million a year.</content>
      <tokens>
        <token id="1" string="Santa" lemma="Santa" stem="santa" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="2" string="Ana" lemma="Ana" stem="ana" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="3" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="estimated" lemma="estimate" stem="estim" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="potential" lemma="potential" stem="potenti" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="loss" lemma="loss" stem="loss" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="10" string="2" lemma="2" stem="2" pos="CD" type="Number" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="11" string="million" lemma="million" stem="million" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="13" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Santa) (NNP Ana)) (VP (VBZ has) (VP (VBN estimated) (NP (PRP$ its) (JJ potential) (NN loss)) (PP (IN at) (NP (NP (QP ($ $) (CD 2) (CD million))) (NP (DT a) (NN year)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="$ 2 million a year" type="NP">
          <tokens>
            <token id="9" string="$" />
            <token id="10" string="2" />
            <token id="11" string="million" />
            <token id="12" string="a" />
            <token id="13" string="year" />
          </tokens>
        </chunking>
        <chunking id="2" string="its potential loss" type="NP">
          <tokens>
            <token id="5" string="its" />
            <token id="6" string="potential" />
            <token id="7" string="loss" />
          </tokens>
        </chunking>
        <chunking id="3" string="$ 2 million" type="NP">
          <tokens>
            <token id="9" string="$" />
            <token id="10" string="2" />
            <token id="11" string="million" />
          </tokens>
        </chunking>
        <chunking id="4" string="has estimated its potential loss at $ 2 million a year" type="VP">
          <tokens>
            <token id="3" string="has" />
            <token id="4" string="estimated" />
            <token id="5" string="its" />
            <token id="6" string="potential" />
            <token id="7" string="loss" />
            <token id="8" string="at" />
            <token id="9" string="$" />
            <token id="10" string="2" />
            <token id="11" string="million" />
            <token id="12" string="a" />
            <token id="13" string="year" />
          </tokens>
        </chunking>
        <chunking id="5" string="Santa Ana" type="NP">
          <tokens>
            <token id="1" string="Santa" />
            <token id="2" string="Ana" />
          </tokens>
        </chunking>
        <chunking id="6" string="estimated its potential loss at $ 2 million a year" type="VP">
          <tokens>
            <token id="4" string="estimated" />
            <token id="5" string="its" />
            <token id="6" string="potential" />
            <token id="7" string="loss" />
            <token id="8" string="at" />
            <token id="9" string="$" />
            <token id="10" string="2" />
            <token id="11" string="million" />
            <token id="12" string="a" />
            <token id="13" string="year" />
          </tokens>
        </chunking>
        <chunking id="7" string="a year" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="year" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Ana</governor>
          <dependent id="1">Santa</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">estimated</governor>
          <dependent id="2">Ana</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">estimated</governor>
          <dependent id="3">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">estimated</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">loss</governor>
          <dependent id="5">its</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">loss</governor>
          <dependent id="6">potential</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">estimated</governor>
          <dependent id="7">loss</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">$</governor>
          <dependent id="8">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">estimated</governor>
          <dependent id="9">$</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">million</governor>
          <dependent id="10">2</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="9">$</governor>
          <dependent id="11">million</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">year</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="9">$</governor>
          <dependent id="13">year</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="$ 2 million" type="MONEY" score="0.0">
          <tokens>
            <token id="9" string="$" />
            <token id="10" string="2" />
            <token id="11" string="million" />
          </tokens>
        </entity>
        <entity id="2" string="Santa Ana" type="LOCATION" score="0.0">
          <tokens>
            <token id="1" string="Santa" />
            <token id="2" string="Ana" />
          </tokens>
        </entity>
        <entity id="3" string="a year" type="DURATION" score="0.0">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="year" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>In addition, Pulido and county advocates for poor Latino residents expressed concern that the decision would promote fear and intimidation in the community.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="addition" lemma="addition" stem="addit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Pulido" lemma="Pulido" stem="pulido" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="5" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="county" lemma="county" stem="counti" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="advocates" lemma="advocate" stem="advoc" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="poor" lemma="poor" stem="poor" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="Latino" lemma="latino" stem="latino" pos="NN" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="11" string="residents" lemma="resident" stem="resid" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="expressed" lemma="express" stem="express" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="concern" lemma="concern" stem="concern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="decision" lemma="decision" stem="decis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="promote" lemma="promote" stem="promot" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="fear" lemma="fear" stem="fear" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="intimidation" lemma="intimidation" stem="intimid" pos="NN" type="Word" isStopWord="false" ner="CRIMINAL_CHARGE" is_referenced="false" is_refers="false" />
        <token id="22" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="community" lemma="community" stem="commun" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (NN addition))) (, ,) (NP (NP (NNP Pulido)) (CC and) (NP (NP (NN county) (NNS advocates)) (PP (IN for) (NP (JJ poor) (NN Latino) (NNS residents))))) (VP (VBD expressed) (NP (NN concern)) (SBAR (IN that) (S (NP (DT the) (NN decision)) (VP (MD would) (VP (VB promote) (NP (NN fear) (CC and) (NN intimidation)) (PP (IN in) (NP (DT the) (NN community)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that the decision would promote fear and intimidation in the community" type="SBAR">
          <tokens>
            <token id="14" string="that" />
            <token id="15" string="the" />
            <token id="16" string="decision" />
            <token id="17" string="would" />
            <token id="18" string="promote" />
            <token id="19" string="fear" />
            <token id="20" string="and" />
            <token id="21" string="intimidation" />
            <token id="22" string="in" />
            <token id="23" string="the" />
            <token id="24" string="community" />
          </tokens>
        </chunking>
        <chunking id="2" string="fear and intimidation" type="NP">
          <tokens>
            <token id="19" string="fear" />
            <token id="20" string="and" />
            <token id="21" string="intimidation" />
          </tokens>
        </chunking>
        <chunking id="3" string="promote fear and intimidation in the community" type="VP">
          <tokens>
            <token id="18" string="promote" />
            <token id="19" string="fear" />
            <token id="20" string="and" />
            <token id="21" string="intimidation" />
            <token id="22" string="in" />
            <token id="23" string="the" />
            <token id="24" string="community" />
          </tokens>
        </chunking>
        <chunking id="4" string="Pulido" type="NP">
          <tokens>
            <token id="4" string="Pulido" />
          </tokens>
        </chunking>
        <chunking id="5" string="the decision" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="decision" />
          </tokens>
        </chunking>
        <chunking id="6" string="the community" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="community" />
          </tokens>
        </chunking>
        <chunking id="7" string="Pulido and county advocates for poor Latino residents" type="NP">
          <tokens>
            <token id="4" string="Pulido" />
            <token id="5" string="and" />
            <token id="6" string="county" />
            <token id="7" string="advocates" />
            <token id="8" string="for" />
            <token id="9" string="poor" />
            <token id="10" string="Latino" />
            <token id="11" string="residents" />
          </tokens>
        </chunking>
        <chunking id="8" string="county advocates for poor Latino residents" type="NP">
          <tokens>
            <token id="6" string="county" />
            <token id="7" string="advocates" />
            <token id="8" string="for" />
            <token id="9" string="poor" />
            <token id="10" string="Latino" />
            <token id="11" string="residents" />
          </tokens>
        </chunking>
        <chunking id="9" string="concern" type="NP">
          <tokens>
            <token id="13" string="concern" />
          </tokens>
        </chunking>
        <chunking id="10" string="poor Latino residents" type="NP">
          <tokens>
            <token id="9" string="poor" />
            <token id="10" string="Latino" />
            <token id="11" string="residents" />
          </tokens>
        </chunking>
        <chunking id="11" string="addition" type="NP">
          <tokens>
            <token id="2" string="addition" />
          </tokens>
        </chunking>
        <chunking id="12" string="county advocates" type="NP">
          <tokens>
            <token id="6" string="county" />
            <token id="7" string="advocates" />
          </tokens>
        </chunking>
        <chunking id="13" string="expressed concern that the decision would promote fear and intimidation in the community" type="VP">
          <tokens>
            <token id="12" string="expressed" />
            <token id="13" string="concern" />
            <token id="14" string="that" />
            <token id="15" string="the" />
            <token id="16" string="decision" />
            <token id="17" string="would" />
            <token id="18" string="promote" />
            <token id="19" string="fear" />
            <token id="20" string="and" />
            <token id="21" string="intimidation" />
            <token id="22" string="in" />
            <token id="23" string="the" />
            <token id="24" string="community" />
          </tokens>
        </chunking>
        <chunking id="14" string="would promote fear and intimidation in the community" type="VP">
          <tokens>
            <token id="17" string="would" />
            <token id="18" string="promote" />
            <token id="19" string="fear" />
            <token id="20" string="and" />
            <token id="21" string="intimidation" />
            <token id="22" string="in" />
            <token id="23" string="the" />
            <token id="24" string="community" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">addition</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">expressed</governor>
          <dependent id="2">addition</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">expressed</governor>
          <dependent id="4">Pulido</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">Pulido</governor>
          <dependent id="5">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">advocates</governor>
          <dependent id="6">county</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">Pulido</governor>
          <dependent id="7">advocates</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">residents</governor>
          <dependent id="8">for</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">residents</governor>
          <dependent id="9">poor</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">residents</governor>
          <dependent id="10">Latino</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">advocates</governor>
          <dependent id="11">residents</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">expressed</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">expressed</governor>
          <dependent id="13">concern</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">promote</governor>
          <dependent id="14">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">decision</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">promote</governor>
          <dependent id="16">decision</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">promote</governor>
          <dependent id="17">would</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">expressed</governor>
          <dependent id="18">promote</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">promote</governor>
          <dependent id="19">fear</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="19">fear</governor>
          <dependent id="20">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">fear</governor>
          <dependent id="21">intimidation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">community</governor>
          <dependent id="22">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">community</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">promote</governor>
          <dependent id="24">community</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Latino" type="MISC" score="0.0">
          <tokens>
            <token id="10" string="Latino" />
          </tokens>
        </entity>
        <entity id="2" string="Pulido" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Pulido" />
          </tokens>
        </entity>
        <entity id="3" string="intimidation" type="CRIMINAL_CHARGE" score="0.0">
          <tokens>
            <token id="21" string="intimidation" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="false">
      <content>In 1985, before the federal immigration reform act, the number of illegal aliens in Orange County was estimated at 229,000, ranking it just behind Los Angeles County in California, a county official said.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="1985" lemma="1985" stem="1985" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="federal" lemma="federal" stem="feder" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="immigration" lemma="immigration" stem="immigr" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="reform" lemma="reform" stem="reform" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="act" lemma="act" stem="act" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="number" lemma="number" stem="number" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="aliens" lemma="alien" stem="alien" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Orange" lemma="Orange" stem="orang" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="18" string="County" lemma="County" stem="counti" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="19" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="estimated" lemma="estimate" stem="estim" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="229,000" lemma="229,000" stem="229,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="ranking" lemma="rank" stem="rank" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="behind" lemma="behind" stem="behind" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="Los" lemma="Los" stem="lo" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="29" string="Angeles" lemma="Angeles" stem="angele" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="30" string="County" lemma="County" stem="counti" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="31" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="California" lemma="California" stem="california" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="33" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="county" lemma="county" stem="counti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="official" lemma="official" stem="offici" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (CD 1985))) (, ,) (SBAR (IN before) (S (NP (NP (DT the) (JJ federal) (NN immigration) (NN reform) (NN act)) (, ,) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NP (JJ illegal) (NNS aliens)) (PP (IN in) (NP (NNP Orange) (NNP County))))))) (VP (VBD was) (VP (VBN estimated) (PP (IN at) (NP (CD 229,000))) (, ,) (S (VP (VBG ranking) (NP (PRP it)) (ADVP (RB just)) (PP (IN behind) (NP (NP (NNP Los) (NNP Angeles) (NNP County)) (PP (IN in) (NP (NNP California))))))))))) (, ,) (NP (DT a) (NN county) (NN official)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="illegal aliens" type="NP">
          <tokens>
            <token id="14" string="illegal" />
            <token id="15" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="2" string="California" type="NP">
          <tokens>
            <token id="32" string="California" />
          </tokens>
        </chunking>
        <chunking id="3" string="the number of illegal aliens in Orange County" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="number" />
            <token id="13" string="of" />
            <token id="14" string="illegal" />
            <token id="15" string="aliens" />
            <token id="16" string="in" />
            <token id="17" string="Orange" />
            <token id="18" string="County" />
          </tokens>
        </chunking>
        <chunking id="4" string="Los Angeles County" type="NP">
          <tokens>
            <token id="28" string="Los" />
            <token id="29" string="Angeles" />
            <token id="30" string="County" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="25" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="ranking it just behind Los Angeles County in California" type="VP">
          <tokens>
            <token id="24" string="ranking" />
            <token id="25" string="it" />
            <token id="26" string="just" />
            <token id="27" string="behind" />
            <token id="28" string="Los" />
            <token id="29" string="Angeles" />
            <token id="30" string="County" />
            <token id="31" string="in" />
            <token id="32" string="California" />
          </tokens>
        </chunking>
        <chunking id="7" string="before the federal immigration reform act , the number of illegal aliens in Orange County was estimated at 229,000 , ranking it just behind Los Angeles County in California" type="SBAR">
          <tokens>
            <token id="4" string="before" />
            <token id="5" string="the" />
            <token id="6" string="federal" />
            <token id="7" string="immigration" />
            <token id="8" string="reform" />
            <token id="9" string="act" />
            <token id="10" string="," />
            <token id="11" string="the" />
            <token id="12" string="number" />
            <token id="13" string="of" />
            <token id="14" string="illegal" />
            <token id="15" string="aliens" />
            <token id="16" string="in" />
            <token id="17" string="Orange" />
            <token id="18" string="County" />
            <token id="19" string="was" />
            <token id="20" string="estimated" />
            <token id="21" string="at" />
            <token id="22" string="229,000" />
            <token id="23" string="," />
            <token id="24" string="ranking" />
            <token id="25" string="it" />
            <token id="26" string="just" />
            <token id="27" string="behind" />
            <token id="28" string="Los" />
            <token id="29" string="Angeles" />
            <token id="30" string="County" />
            <token id="31" string="in" />
            <token id="32" string="California" />
          </tokens>
        </chunking>
        <chunking id="8" string="1985" type="NP">
          <tokens>
            <token id="2" string="1985" />
          </tokens>
        </chunking>
        <chunking id="9" string="Orange County" type="NP">
          <tokens>
            <token id="17" string="Orange" />
            <token id="18" string="County" />
          </tokens>
        </chunking>
        <chunking id="10" string="was estimated at 229,000 , ranking it just behind Los Angeles County in California" type="VP">
          <tokens>
            <token id="19" string="was" />
            <token id="20" string="estimated" />
            <token id="21" string="at" />
            <token id="22" string="229,000" />
            <token id="23" string="," />
            <token id="24" string="ranking" />
            <token id="25" string="it" />
            <token id="26" string="just" />
            <token id="27" string="behind" />
            <token id="28" string="Los" />
            <token id="29" string="Angeles" />
            <token id="30" string="County" />
            <token id="31" string="in" />
            <token id="32" string="California" />
          </tokens>
        </chunking>
        <chunking id="11" string="the federal immigration reform act" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="federal" />
            <token id="7" string="immigration" />
            <token id="8" string="reform" />
            <token id="9" string="act" />
          </tokens>
        </chunking>
        <chunking id="12" string="Los Angeles County in California" type="NP">
          <tokens>
            <token id="28" string="Los" />
            <token id="29" string="Angeles" />
            <token id="30" string="County" />
            <token id="31" string="in" />
            <token id="32" string="California" />
          </tokens>
        </chunking>
        <chunking id="13" string="illegal aliens in Orange County" type="NP">
          <tokens>
            <token id="14" string="illegal" />
            <token id="15" string="aliens" />
            <token id="16" string="in" />
            <token id="17" string="Orange" />
            <token id="18" string="County" />
          </tokens>
        </chunking>
        <chunking id="14" string="estimated at 229,000 , ranking it just behind Los Angeles County in California" type="VP">
          <tokens>
            <token id="20" string="estimated" />
            <token id="21" string="at" />
            <token id="22" string="229,000" />
            <token id="23" string="," />
            <token id="24" string="ranking" />
            <token id="25" string="it" />
            <token id="26" string="just" />
            <token id="27" string="behind" />
            <token id="28" string="Los" />
            <token id="29" string="Angeles" />
            <token id="30" string="County" />
            <token id="31" string="in" />
            <token id="32" string="California" />
          </tokens>
        </chunking>
        <chunking id="15" string="the number" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="number" />
          </tokens>
        </chunking>
        <chunking id="16" string="229,000" type="NP">
          <tokens>
            <token id="22" string="229,000" />
          </tokens>
        </chunking>
        <chunking id="17" string="a county official" type="NP">
          <tokens>
            <token id="34" string="a" />
            <token id="35" string="county" />
            <token id="36" string="official" />
          </tokens>
        </chunking>
        <chunking id="18" string="said" type="VP">
          <tokens>
            <token id="37" string="said" />
          </tokens>
        </chunking>
        <chunking id="19" string="the federal immigration reform act , the number of illegal aliens in Orange County" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="federal" />
            <token id="7" string="immigration" />
            <token id="8" string="reform" />
            <token id="9" string="act" />
            <token id="10" string="," />
            <token id="11" string="the" />
            <token id="12" string="number" />
            <token id="13" string="of" />
            <token id="14" string="illegal" />
            <token id="15" string="aliens" />
            <token id="16" string="in" />
            <token id="17" string="Orange" />
            <token id="18" string="County" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">1985</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="37">said</governor>
          <dependent id="2">1985</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">estimated</governor>
          <dependent id="4">before</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">act</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">act</governor>
          <dependent id="6">federal</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">act</governor>
          <dependent id="7">immigration</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">act</governor>
          <dependent id="8">reform</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="20">estimated</governor>
          <dependent id="9">act</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">number</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="9">act</governor>
          <dependent id="12">number</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">aliens</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">aliens</governor>
          <dependent id="14">illegal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">number</governor>
          <dependent id="15">aliens</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">County</governor>
          <dependent id="16">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">County</governor>
          <dependent id="17">Orange</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">aliens</governor>
          <dependent id="18">County</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="20">estimated</governor>
          <dependent id="19">was</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="37">said</governor>
          <dependent id="20">estimated</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">229,000</governor>
          <dependent id="21">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">estimated</governor>
          <dependent id="22">229,000</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="20">estimated</governor>
          <dependent id="24">ranking</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">ranking</governor>
          <dependent id="25">it</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="24">ranking</governor>
          <dependent id="26">just</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">County</governor>
          <dependent id="27">behind</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">County</governor>
          <dependent id="28">Los</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">County</governor>
          <dependent id="29">Angeles</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">ranking</governor>
          <dependent id="30">County</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">California</governor>
          <dependent id="31">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">County</governor>
          <dependent id="32">California</dependent>
        </dependency>
        <dependency type="det">
          <governor id="36">official</governor>
          <dependent id="34">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="36">official</governor>
          <dependent id="35">county</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="37">said</governor>
          <dependent id="36">official</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="37">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1985" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="1985" />
          </tokens>
        </entity>
        <entity id="2" string="Orange County" type="LOCATION" score="0.0">
          <tokens>
            <token id="17" string="Orange" />
            <token id="18" string="County" />
          </tokens>
        </entity>
        <entity id="3" string="California" type="LOCATION" score="0.0">
          <tokens>
            <token id="32" string="California" />
          </tokens>
        </entity>
        <entity id="4" string="Los Angeles County" type="LOCATION" score="0.0">
          <tokens>
            <token id="28" string="Los" />
            <token id="29" string="Angeles" />
            <token id="30" string="County" />
          </tokens>
        </entity>
        <entity id="5" string="229,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="22" string="229,000" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="false">
      <content>There are no current estimates.</content>
      <tokens>
        <token id="1" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="current" lemma="current" stem="current" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="estimates" lemma="estimate" stem="estim" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (DT no) (JJ current) (NNS estimates))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="no current estimates" type="NP">
          <tokens>
            <token id="3" string="no" />
            <token id="4" string="current" />
            <token id="5" string="estimates" />
          </tokens>
        </chunking>
        <chunking id="2" string="There" type="NP">
          <tokens>
            <token id="1" string="There" />
          </tokens>
        </chunking>
        <chunking id="3" string="are no current estimates" type="VP">
          <tokens>
            <token id="2" string="are" />
            <token id="3" string="no" />
            <token id="4" string="current" />
            <token id="5" string="estimates" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="2">are</governor>
          <dependent id="1">There</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">are</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">estimates</governor>
          <dependent id="3">no</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">estimates</governor>
          <dependent id="4">current</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="2">are</governor>
          <dependent id="5">estimates</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="current" type="DATE" score="0.0">
          <tokens>
            <token id="4" string="current" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>&amp;quot;For example, we have close to 50,000 people in the city that have qualified through the amnesty process for legal residency,&amp;quot; Pulido said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="For" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="example" lemma="example" stem="exampl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="close" lemma="close" stem="close" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="50,000" lemma="50,000" stem="50,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="10" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="city" lemma="city" stem="citi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="qualified" lemma="qualify" stem="qualifi" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="amnesty" lemma="amnesty" stem="amnesti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="process" lemma="process" stem="process" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="legal" lemma="legal" stem="legal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="residency" lemma="residency" stem="resid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="Pulido" lemma="Pulido" stem="pulido" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="27" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (PP (IN For) (NP (NN example))) (, ,) (NP (PRP we)) (VP (VBP have) (NP (NP (QP (RB close) (TO to) (CD 50,000)) (NNS people)) (PP (IN in) (NP (NP (DT the) (NN city)) (SBAR (WHNP (WDT that)) (S (VP (VBP have) (VP (VBN qualified) (PP (IN through) (NP (NP (DT the) (NN amnesty) (NN process)) (PP (IN for) (NP (JJ legal) (NN residency)))))))))))))) (, ,) ('' '') (NP (NNP Pulido)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the city" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="city" />
          </tokens>
        </chunking>
        <chunking id="2" string="qualified through the amnesty process for legal residency" type="VP">
          <tokens>
            <token id="16" string="qualified" />
            <token id="17" string="through" />
            <token id="18" string="the" />
            <token id="19" string="amnesty" />
            <token id="20" string="process" />
            <token id="21" string="for" />
            <token id="22" string="legal" />
            <token id="23" string="residency" />
          </tokens>
        </chunking>
        <chunking id="3" string="the amnesty process for legal residency" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="amnesty" />
            <token id="20" string="process" />
            <token id="21" string="for" />
            <token id="22" string="legal" />
            <token id="23" string="residency" />
          </tokens>
        </chunking>
        <chunking id="4" string="close to 50,000 people in the city that have qualified through the amnesty process for legal residency" type="NP">
          <tokens>
            <token id="7" string="close" />
            <token id="8" string="to" />
            <token id="9" string="50,000" />
            <token id="10" string="people" />
            <token id="11" string="in" />
            <token id="12" string="the" />
            <token id="13" string="city" />
            <token id="14" string="that" />
            <token id="15" string="have" />
            <token id="16" string="qualified" />
            <token id="17" string="through" />
            <token id="18" string="the" />
            <token id="19" string="amnesty" />
            <token id="20" string="process" />
            <token id="21" string="for" />
            <token id="22" string="legal" />
            <token id="23" string="residency" />
          </tokens>
        </chunking>
        <chunking id="5" string="have qualified through the amnesty process for legal residency" type="VP">
          <tokens>
            <token id="15" string="have" />
            <token id="16" string="qualified" />
            <token id="17" string="through" />
            <token id="18" string="the" />
            <token id="19" string="amnesty" />
            <token id="20" string="process" />
            <token id="21" string="for" />
            <token id="22" string="legal" />
            <token id="23" string="residency" />
          </tokens>
        </chunking>
        <chunking id="6" string="the amnesty process" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="amnesty" />
            <token id="20" string="process" />
          </tokens>
        </chunking>
        <chunking id="7" string="the city that have qualified through the amnesty process for legal residency" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="city" />
            <token id="14" string="that" />
            <token id="15" string="have" />
            <token id="16" string="qualified" />
            <token id="17" string="through" />
            <token id="18" string="the" />
            <token id="19" string="amnesty" />
            <token id="20" string="process" />
            <token id="21" string="for" />
            <token id="22" string="legal" />
            <token id="23" string="residency" />
          </tokens>
        </chunking>
        <chunking id="8" string="Pulido" type="NP">
          <tokens>
            <token id="26" string="Pulido" />
          </tokens>
        </chunking>
        <chunking id="9" string="example" type="NP">
          <tokens>
            <token id="3" string="example" />
          </tokens>
        </chunking>
        <chunking id="10" string="we" type="NP">
          <tokens>
            <token id="5" string="we" />
          </tokens>
        </chunking>
        <chunking id="11" string="legal residency" type="NP">
          <tokens>
            <token id="22" string="legal" />
            <token id="23" string="residency" />
          </tokens>
        </chunking>
        <chunking id="12" string="have close to 50,000 people in the city that have qualified through the amnesty process for legal residency" type="VP">
          <tokens>
            <token id="6" string="have" />
            <token id="7" string="close" />
            <token id="8" string="to" />
            <token id="9" string="50,000" />
            <token id="10" string="people" />
            <token id="11" string="in" />
            <token id="12" string="the" />
            <token id="13" string="city" />
            <token id="14" string="that" />
            <token id="15" string="have" />
            <token id="16" string="qualified" />
            <token id="17" string="through" />
            <token id="18" string="the" />
            <token id="19" string="amnesty" />
            <token id="20" string="process" />
            <token id="21" string="for" />
            <token id="22" string="legal" />
            <token id="23" string="residency" />
          </tokens>
        </chunking>
        <chunking id="13" string="said" type="VP">
          <tokens>
            <token id="27" string="said" />
          </tokens>
        </chunking>
        <chunking id="14" string="that have qualified through the amnesty process for legal residency" type="SBAR">
          <tokens>
            <token id="14" string="that" />
            <token id="15" string="have" />
            <token id="16" string="qualified" />
            <token id="17" string="through" />
            <token id="18" string="the" />
            <token id="19" string="amnesty" />
            <token id="20" string="process" />
            <token id="21" string="for" />
            <token id="22" string="legal" />
            <token id="23" string="residency" />
          </tokens>
        </chunking>
        <chunking id="15" string="close to 50,000 people" type="NP">
          <tokens>
            <token id="7" string="close" />
            <token id="8" string="to" />
            <token id="9" string="50,000" />
            <token id="10" string="people" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">example</governor>
          <dependent id="2">For</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">have</governor>
          <dependent id="3">example</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">have</governor>
          <dependent id="5">we</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="27">said</governor>
          <dependent id="6">have</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">50,000</governor>
          <dependent id="7">close</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="9">50,000</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="10">people</governor>
          <dependent id="9">50,000</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">have</governor>
          <dependent id="10">people</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">city</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">city</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">people</governor>
          <dependent id="13">city</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">qualified</governor>
          <dependent id="14">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">qualified</governor>
          <dependent id="15">have</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="13">city</governor>
          <dependent id="16">qualified</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">process</governor>
          <dependent id="17">through</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">process</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">process</governor>
          <dependent id="19">amnesty</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">qualified</governor>
          <dependent id="20">process</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">residency</governor>
          <dependent id="21">for</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">residency</governor>
          <dependent id="22">legal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">process</governor>
          <dependent id="23">residency</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">said</governor>
          <dependent id="26">Pulido</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="27">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="50,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="9" string="50,000" />
          </tokens>
        </entity>
        <entity id="2" string="Pulido" type="PERSON" score="0.0">
          <tokens>
            <token id="26" string="Pulido" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>&amp;quot;Those individuals, when asked or challenged about their status, can be legitimately concerned.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="individuals" lemma="individual" stem="individu" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="asked" lemma="ask" stem="ask" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="challenged" lemma="challenge" stem="challeng" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="status" lemma="status" stem="statu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="legitimately" lemma="legitimately" stem="legitim" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="concerned" lemma="concern" stem="concern" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (DT Those) (NNS individuals)) (PRN (, ,) (SBAR (WHADVP (WRB when)) (S (VP (VBN asked) (CC or) (VBN challenged) (PP (IN about) (NP (PRP$ their) (NN status)))))) (, ,)) (VP (MD can) (VP (VB be) (VP (ADVP (RB legitimately)) (VBN concerned)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Those individuals" type="NP">
          <tokens>
            <token id="2" string="Those" />
            <token id="3" string="individuals" />
          </tokens>
        </chunking>
        <chunking id="2" string="be legitimately concerned" type="VP">
          <tokens>
            <token id="14" string="be" />
            <token id="15" string="legitimately" />
            <token id="16" string="concerned" />
          </tokens>
        </chunking>
        <chunking id="3" string="when asked or challenged about their status" type="SBAR">
          <tokens>
            <token id="5" string="when" />
            <token id="6" string="asked" />
            <token id="7" string="or" />
            <token id="8" string="challenged" />
            <token id="9" string="about" />
            <token id="10" string="their" />
            <token id="11" string="status" />
          </tokens>
        </chunking>
        <chunking id="4" string="asked or challenged about their status" type="VP">
          <tokens>
            <token id="6" string="asked" />
            <token id="7" string="or" />
            <token id="8" string="challenged" />
            <token id="9" string="about" />
            <token id="10" string="their" />
            <token id="11" string="status" />
          </tokens>
        </chunking>
        <chunking id="5" string="their status" type="NP">
          <tokens>
            <token id="10" string="their" />
            <token id="11" string="status" />
          </tokens>
        </chunking>
        <chunking id="6" string="legitimately concerned" type="VP">
          <tokens>
            <token id="15" string="legitimately" />
            <token id="16" string="concerned" />
          </tokens>
        </chunking>
        <chunking id="7" string="when" type="WHADVP">
          <tokens>
            <token id="5" string="when" />
          </tokens>
        </chunking>
        <chunking id="8" string="can be legitimately concerned" type="VP">
          <tokens>
            <token id="13" string="can" />
            <token id="14" string="be" />
            <token id="15" string="legitimately" />
            <token id="16" string="concerned" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">individuals</governor>
          <dependent id="2">Those</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="16">concerned</governor>
          <dependent id="3">individuals</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">asked</governor>
          <dependent id="5">when</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="16">concerned</governor>
          <dependent id="6">asked</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">asked</governor>
          <dependent id="7">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">asked</governor>
          <dependent id="8">challenged</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">status</governor>
          <dependent id="9">about</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">status</governor>
          <dependent id="10">their</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">asked</governor>
          <dependent id="11">status</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">concerned</governor>
          <dependent id="13">can</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="16">concerned</governor>
          <dependent id="14">be</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">concerned</governor>
          <dependent id="15">legitimately</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">concerned</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>I think the census&amp;apost;s attempt to question them could be misconstrued as an attempt by the immigration service to get information.&amp;quot;</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="think" lemma="think" stem="think" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="census" lemma="census" stem="censu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="attempt" lemma="attempt" stem="attempt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="question" lemma="question" stem="question" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="misconstrued" lemma="misconstrue" stem="misconstru" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="attempt" lemma="attempt" stem="attempt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="immigration" lemma="immigration" stem="immigr" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="service" lemma="service" stem="servic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="get" lemma="get" stem="get" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="information" lemma="information" stem="inform" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBP think) (SBAR (S (NP (NP (DT the) (NN census) (POS 's)) (NN attempt) (S (VP (TO to) (VP (VB question) (NP (PRP them)))))) (VP (MD could) (VP (VB be) (VP (VBN misconstrued) (PP (IN as) (NP (DT an) (NN attempt))) (PP (IN by) (NP (DT the) (NN immigration) (NN service))) (S (VP (TO to) (VP (VB get) (NP (NN information))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="the census 's attempt to question them" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="census" />
            <token id="5" string="'s" />
            <token id="6" string="attempt" />
            <token id="7" string="to" />
            <token id="8" string="question" />
            <token id="9" string="them" />
          </tokens>
        </chunking>
        <chunking id="2" string="the immigration service" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="immigration" />
            <token id="19" string="service" />
          </tokens>
        </chunking>
        <chunking id="3" string="the census 's attempt to question them could be misconstrued as an attempt by the immigration service to get information" type="SBAR">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="census" />
            <token id="5" string="'s" />
            <token id="6" string="attempt" />
            <token id="7" string="to" />
            <token id="8" string="question" />
            <token id="9" string="them" />
            <token id="10" string="could" />
            <token id="11" string="be" />
            <token id="12" string="misconstrued" />
            <token id="13" string="as" />
            <token id="14" string="an" />
            <token id="15" string="attempt" />
            <token id="16" string="by" />
            <token id="17" string="the" />
            <token id="18" string="immigration" />
            <token id="19" string="service" />
            <token id="20" string="to" />
            <token id="21" string="get" />
            <token id="22" string="information" />
          </tokens>
        </chunking>
        <chunking id="4" string="to question them" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="question" />
            <token id="9" string="them" />
          </tokens>
        </chunking>
        <chunking id="5" string="the census 's" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="census" />
            <token id="5" string="'s" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="question them" type="VP">
          <tokens>
            <token id="8" string="question" />
            <token id="9" string="them" />
          </tokens>
        </chunking>
        <chunking id="8" string="them" type="NP">
          <tokens>
            <token id="9" string="them" />
          </tokens>
        </chunking>
        <chunking id="9" string="could be misconstrued as an attempt by the immigration service to get information" type="VP">
          <tokens>
            <token id="10" string="could" />
            <token id="11" string="be" />
            <token id="12" string="misconstrued" />
            <token id="13" string="as" />
            <token id="14" string="an" />
            <token id="15" string="attempt" />
            <token id="16" string="by" />
            <token id="17" string="the" />
            <token id="18" string="immigration" />
            <token id="19" string="service" />
            <token id="20" string="to" />
            <token id="21" string="get" />
            <token id="22" string="information" />
          </tokens>
        </chunking>
        <chunking id="10" string="misconstrued as an attempt by the immigration service to get information" type="VP">
          <tokens>
            <token id="12" string="misconstrued" />
            <token id="13" string="as" />
            <token id="14" string="an" />
            <token id="15" string="attempt" />
            <token id="16" string="by" />
            <token id="17" string="the" />
            <token id="18" string="immigration" />
            <token id="19" string="service" />
            <token id="20" string="to" />
            <token id="21" string="get" />
            <token id="22" string="information" />
          </tokens>
        </chunking>
        <chunking id="11" string="to get information" type="VP">
          <tokens>
            <token id="20" string="to" />
            <token id="21" string="get" />
            <token id="22" string="information" />
          </tokens>
        </chunking>
        <chunking id="12" string="get information" type="VP">
          <tokens>
            <token id="21" string="get" />
            <token id="22" string="information" />
          </tokens>
        </chunking>
        <chunking id="13" string="an attempt" type="NP">
          <tokens>
            <token id="14" string="an" />
            <token id="15" string="attempt" />
          </tokens>
        </chunking>
        <chunking id="14" string="be misconstrued as an attempt by the immigration service to get information" type="VP">
          <tokens>
            <token id="11" string="be" />
            <token id="12" string="misconstrued" />
            <token id="13" string="as" />
            <token id="14" string="an" />
            <token id="15" string="attempt" />
            <token id="16" string="by" />
            <token id="17" string="the" />
            <token id="18" string="immigration" />
            <token id="19" string="service" />
            <token id="20" string="to" />
            <token id="21" string="get" />
            <token id="22" string="information" />
          </tokens>
        </chunking>
        <chunking id="15" string="information" type="NP">
          <tokens>
            <token id="22" string="information" />
          </tokens>
        </chunking>
        <chunking id="16" string="think the census 's attempt to question them could be misconstrued as an attempt by the immigration service to get information" type="VP">
          <tokens>
            <token id="2" string="think" />
            <token id="3" string="the" />
            <token id="4" string="census" />
            <token id="5" string="'s" />
            <token id="6" string="attempt" />
            <token id="7" string="to" />
            <token id="8" string="question" />
            <token id="9" string="them" />
            <token id="10" string="could" />
            <token id="11" string="be" />
            <token id="12" string="misconstrued" />
            <token id="13" string="as" />
            <token id="14" string="an" />
            <token id="15" string="attempt" />
            <token id="16" string="by" />
            <token id="17" string="the" />
            <token id="18" string="immigration" />
            <token id="19" string="service" />
            <token id="20" string="to" />
            <token id="21" string="get" />
            <token id="22" string="information" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">think</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">think</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">census</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">attempt</governor>
          <dependent id="4">census</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">census</governor>
          <dependent id="5">'s</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="12">misconstrued</governor>
          <dependent id="6">attempt</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">question</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="6">attempt</governor>
          <dependent id="8">question</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">question</governor>
          <dependent id="9">them</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">misconstrued</governor>
          <dependent id="10">could</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="12">misconstrued</governor>
          <dependent id="11">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">think</governor>
          <dependent id="12">misconstrued</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">attempt</governor>
          <dependent id="13">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">attempt</governor>
          <dependent id="14">an</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">misconstrued</governor>
          <dependent id="15">attempt</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">service</governor>
          <dependent id="16">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">service</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">service</governor>
          <dependent id="18">immigration</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">misconstrued</governor>
          <dependent id="19">service</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">get</governor>
          <dependent id="20">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="12">misconstrued</governor>
          <dependent id="21">get</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">get</governor>
          <dependent id="22">information</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>Councilman John Acosta said he &amp;quot;was saddened&amp;quot; by the Senate&amp;apost;s action because the city was determined &amp;quot;to count every single person, and I know that (now) we&amp;apost;re going to to suffer from this monetarily.&amp;quot;</content>
      <tokens>
        <token id="1" string="Councilman" lemma="councilman" stem="councilman" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="Acosta" lemma="Acosta" stem="acosta" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="saddened" lemma="saddened" stem="sadden" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="Senate" lemma="Senate" stem="senat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="13" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="action" lemma="action" stem="action" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="city" lemma="city" stem="citi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="determined" lemma="determine" stem="determin" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="count" lemma="count" stem="count" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="every" lemma="every" stem="everi" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="single" lemma="single" stem="singl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="person" lemma="person" stem="person" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="29" string="know" lemma="know" stem="know" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="33" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="35" string="'re" lemma="be" stem="'re" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="suffer" lemma="suffer" stem="suffer" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="monetarily" lemma="monetarily" stem="monetarili" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NN Councilman) (NNP John) (NNP Acosta)) (VP (VBD said) (SBAR (S (NP (PRP he)) (`` ``) (VP (VBD was) (ADJP (JJ saddened) ('' '') (PP (IN by) (NP (NP (DT the) (NNP Senate) (POS 's)) (NN action)))) (SBAR (IN because) (S (NP (DT the) (NN city)) (VP (VBD was) (VP (VBN determined) (`` ``) (S (VP (TO to) (VP (VB count) (NP (DT every) (JJ single) (NN person)))))))))))))) (, ,) (CC and) (S (NP (PRP I)) (VP (VBP know) (SBAR (WHNP (IN that)) (PRN (-LRB- -LRB-) (ADVP (RB now)) (-RRB- -RRB-)) (S (NP (PRP we)) (VP (VBP 're) (VP (VBG going) (S (VP (TO to) (S (VP (TO to) (VP (VB suffer) (PP (IN from) (NP (DT this))) (ADVP (RB monetarily))))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="said he `` was saddened '' by the Senate 's action because the city was determined `` to count every single person" type="VP">
          <tokens>
            <token id="4" string="said" />
            <token id="5" string="he" />
            <token id="6" string="&quot;" />
            <token id="7" string="was" />
            <token id="8" string="saddened" />
            <token id="9" string="&quot;" />
            <token id="10" string="by" />
            <token id="11" string="the" />
            <token id="12" string="Senate" />
            <token id="13" string="'s" />
            <token id="14" string="action" />
            <token id="15" string="because" />
            <token id="16" string="the" />
            <token id="17" string="city" />
            <token id="18" string="was" />
            <token id="19" string="determined" />
            <token id="20" string="&quot;" />
            <token id="21" string="to" />
            <token id="22" string="count" />
            <token id="23" string="every" />
            <token id="24" string="single" />
            <token id="25" string="person" />
          </tokens>
        </chunking>
        <chunking id="2" string="the city" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="city" />
          </tokens>
        </chunking>
        <chunking id="3" string="to count every single person" type="VP">
          <tokens>
            <token id="21" string="to" />
            <token id="22" string="count" />
            <token id="23" string="every" />
            <token id="24" string="single" />
            <token id="25" string="person" />
          </tokens>
        </chunking>
        <chunking id="4" string="this" type="NP">
          <tokens>
            <token id="41" string="this" />
          </tokens>
        </chunking>
        <chunking id="5" string="every single person" type="NP">
          <tokens>
            <token id="23" string="every" />
            <token id="24" string="single" />
            <token id="25" string="person" />
          </tokens>
        </chunking>
        <chunking id="6" string="'re going to to suffer from this monetarily" type="VP">
          <tokens>
            <token id="35" string="'re" />
            <token id="36" string="going" />
            <token id="37" string="to" />
            <token id="38" string="to" />
            <token id="39" string="suffer" />
            <token id="40" string="from" />
            <token id="41" string="this" />
            <token id="42" string="monetarily" />
          </tokens>
        </chunking>
        <chunking id="7" string="Councilman John Acosta" type="NP">
          <tokens>
            <token id="1" string="Councilman" />
            <token id="2" string="John" />
            <token id="3" string="Acosta" />
          </tokens>
        </chunking>
        <chunking id="8" string="was determined `` to count every single person" type="VP">
          <tokens>
            <token id="18" string="was" />
            <token id="19" string="determined" />
            <token id="20" string="&quot;" />
            <token id="21" string="to" />
            <token id="22" string="count" />
            <token id="23" string="every" />
            <token id="24" string="single" />
            <token id="25" string="person" />
          </tokens>
        </chunking>
        <chunking id="9" string="suffer from this monetarily" type="VP">
          <tokens>
            <token id="39" string="suffer" />
            <token id="40" string="from" />
            <token id="41" string="this" />
            <token id="42" string="monetarily" />
          </tokens>
        </chunking>
        <chunking id="10" string="the Senate 's" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="Senate" />
            <token id="13" string="'s" />
          </tokens>
        </chunking>
        <chunking id="11" string="the Senate 's action" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="Senate" />
            <token id="13" string="'s" />
            <token id="14" string="action" />
          </tokens>
        </chunking>
        <chunking id="12" string="because the city was determined `` to count every single person" type="SBAR">
          <tokens>
            <token id="15" string="because" />
            <token id="16" string="the" />
            <token id="17" string="city" />
            <token id="18" string="was" />
            <token id="19" string="determined" />
            <token id="20" string="&quot;" />
            <token id="21" string="to" />
            <token id="22" string="count" />
            <token id="23" string="every" />
            <token id="24" string="single" />
            <token id="25" string="person" />
          </tokens>
        </chunking>
        <chunking id="13" string="he" type="NP">
          <tokens>
            <token id="5" string="he" />
          </tokens>
        </chunking>
        <chunking id="14" string="that -LRB- now -RRB- we 're going to to suffer from this monetarily" type="SBAR">
          <tokens>
            <token id="30" string="that" />
            <token id="31" string="(" />
            <token id="32" string="now" />
            <token id="33" string=")" />
            <token id="34" string="we" />
            <token id="35" string="'re" />
            <token id="36" string="going" />
            <token id="37" string="to" />
            <token id="38" string="to" />
            <token id="39" string="suffer" />
            <token id="40" string="from" />
            <token id="41" string="this" />
            <token id="42" string="monetarily" />
          </tokens>
        </chunking>
        <chunking id="15" string="I" type="NP">
          <tokens>
            <token id="28" string="I" />
          </tokens>
        </chunking>
        <chunking id="16" string="know that -LRB- now -RRB- we 're going to to suffer from this monetarily" type="VP">
          <tokens>
            <token id="29" string="know" />
            <token id="30" string="that" />
            <token id="31" string="(" />
            <token id="32" string="now" />
            <token id="33" string=")" />
            <token id="34" string="we" />
            <token id="35" string="'re" />
            <token id="36" string="going" />
            <token id="37" string="to" />
            <token id="38" string="to" />
            <token id="39" string="suffer" />
            <token id="40" string="from" />
            <token id="41" string="this" />
            <token id="42" string="monetarily" />
          </tokens>
        </chunking>
        <chunking id="17" string="saddened '' by the Senate 's action" type="ADJP">
          <tokens>
            <token id="8" string="saddened" />
            <token id="9" string="&quot;" />
            <token id="10" string="by" />
            <token id="11" string="the" />
            <token id="12" string="Senate" />
            <token id="13" string="'s" />
            <token id="14" string="action" />
          </tokens>
        </chunking>
        <chunking id="18" string="we" type="NP">
          <tokens>
            <token id="34" string="we" />
          </tokens>
        </chunking>
        <chunking id="19" string="determined `` to count every single person" type="VP">
          <tokens>
            <token id="19" string="determined" />
            <token id="20" string="&quot;" />
            <token id="21" string="to" />
            <token id="22" string="count" />
            <token id="23" string="every" />
            <token id="24" string="single" />
            <token id="25" string="person" />
          </tokens>
        </chunking>
        <chunking id="20" string="to suffer from this monetarily" type="VP">
          <tokens>
            <token id="38" string="to" />
            <token id="39" string="suffer" />
            <token id="40" string="from" />
            <token id="41" string="this" />
            <token id="42" string="monetarily" />
          </tokens>
        </chunking>
        <chunking id="21" string="he `` was saddened '' by the Senate 's action because the city was determined `` to count every single person" type="SBAR">
          <tokens>
            <token id="5" string="he" />
            <token id="6" string="&quot;" />
            <token id="7" string="was" />
            <token id="8" string="saddened" />
            <token id="9" string="&quot;" />
            <token id="10" string="by" />
            <token id="11" string="the" />
            <token id="12" string="Senate" />
            <token id="13" string="'s" />
            <token id="14" string="action" />
            <token id="15" string="because" />
            <token id="16" string="the" />
            <token id="17" string="city" />
            <token id="18" string="was" />
            <token id="19" string="determined" />
            <token id="20" string="&quot;" />
            <token id="21" string="to" />
            <token id="22" string="count" />
            <token id="23" string="every" />
            <token id="24" string="single" />
            <token id="25" string="person" />
          </tokens>
        </chunking>
        <chunking id="22" string="was saddened '' by the Senate 's action because the city was determined `` to count every single person" type="VP">
          <tokens>
            <token id="7" string="was" />
            <token id="8" string="saddened" />
            <token id="9" string="&quot;" />
            <token id="10" string="by" />
            <token id="11" string="the" />
            <token id="12" string="Senate" />
            <token id="13" string="'s" />
            <token id="14" string="action" />
            <token id="15" string="because" />
            <token id="16" string="the" />
            <token id="17" string="city" />
            <token id="18" string="was" />
            <token id="19" string="determined" />
            <token id="20" string="&quot;" />
            <token id="21" string="to" />
            <token id="22" string="count" />
            <token id="23" string="every" />
            <token id="24" string="single" />
            <token id="25" string="person" />
          </tokens>
        </chunking>
        <chunking id="23" string="count every single person" type="VP">
          <tokens>
            <token id="22" string="count" />
            <token id="23" string="every" />
            <token id="24" string="single" />
            <token id="25" string="person" />
          </tokens>
        </chunking>
        <chunking id="24" string="to to suffer from this monetarily" type="VP">
          <tokens>
            <token id="37" string="to" />
            <token id="38" string="to" />
            <token id="39" string="suffer" />
            <token id="40" string="from" />
            <token id="41" string="this" />
            <token id="42" string="monetarily" />
          </tokens>
        </chunking>
        <chunking id="25" string="going to to suffer from this monetarily" type="VP">
          <tokens>
            <token id="36" string="going" />
            <token id="37" string="to" />
            <token id="38" string="to" />
            <token id="39" string="suffer" />
            <token id="40" string="from" />
            <token id="41" string="this" />
            <token id="42" string="monetarily" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Acosta</governor>
          <dependent id="1">Councilman</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Acosta</governor>
          <dependent id="2">John</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">said</governor>
          <dependent id="3">Acosta</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">saddened</governor>
          <dependent id="5">he</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">saddened</governor>
          <dependent id="7">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">said</governor>
          <dependent id="8">saddened</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">action</governor>
          <dependent id="10">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">Senate</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">action</governor>
          <dependent id="12">Senate</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Senate</governor>
          <dependent id="13">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">saddened</governor>
          <dependent id="14">action</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">determined</governor>
          <dependent id="15">because</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">city</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="19">determined</governor>
          <dependent id="17">city</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="19">determined</governor>
          <dependent id="18">was</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="8">saddened</governor>
          <dependent id="19">determined</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">count</governor>
          <dependent id="21">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="19">determined</governor>
          <dependent id="22">count</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">person</governor>
          <dependent id="23">every</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">person</governor>
          <dependent id="24">single</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">count</governor>
          <dependent id="25">person</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">said</governor>
          <dependent id="27">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">know</governor>
          <dependent id="28">I</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">said</governor>
          <dependent id="29">know</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="36">going</governor>
          <dependent id="30">that</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="36">going</governor>
          <dependent id="32">now</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="36">going</governor>
          <dependent id="34">we</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="36">going</governor>
          <dependent id="35">'re</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="29">know</governor>
          <dependent id="36">going</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="36">going</governor>
          <dependent id="37">to</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="39">suffer</governor>
          <dependent id="38">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="37">to</governor>
          <dependent id="39">suffer</dependent>
        </dependency>
        <dependency type="case">
          <governor id="41">this</governor>
          <dependent id="40">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="39">suffer</governor>
          <dependent id="41">this</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="39">suffer</governor>
          <dependent id="42">monetarily</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Senate" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="12" string="Senate" />
          </tokens>
        </entity>
        <entity id="2" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="32" string="now" />
          </tokens>
        </entity>
        <entity id="3" string="John Acosta" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="John" />
            <token id="3" string="Acosta" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>But Pulido said he believes the House of Representatives will not allow the prohibition to survive, especially since it killed an earlier, similar effort.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Pulido" lemma="Pulido" stem="pulido" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="believes" lemma="believe" stem="believ" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="House" lemma="House" stem="hous" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="9" string="Representatives" lemma="Representatives" stem="repres" pos="NNPS" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="10" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="allow" lemma="allow" stem="allow" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="prohibition" lemma="prohibition" stem="prohibit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="survive" lemma="survive" stem="surviv" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="especially" lemma="especially" stem="especi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="killed" lemma="kill" stem="kill" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="earlier" lemma="earlier" stem="earlier" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="similar" lemma="similar" stem="similar" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="effort" lemma="effort" stem="effort" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (NNP Pulido)) (VP (VBD said) (SBAR (S (NP (PRP he)) (VP (VBZ believes) (SBAR (S (NP (NP (DT the) (NNP House)) (PP (IN of) (NP (NNPS Representatives)))) (VP (MD will) (RB not) (VP (VB allow) (NP (DT the) (NN prohibition) (S (VP (TO to) (VP (VB survive) (, ,) (ADVP (RB especially)) (SBAR (IN since) (S (NP (PRP it)) (VP (VBD killed) (NP (DT an) (JJR earlier) (, ,) (JJ similar) (NN effort))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="to survive , especially since it killed an earlier , similar effort" type="VP">
          <tokens>
            <token id="15" string="to" />
            <token id="16" string="survive" />
            <token id="17" string="," />
            <token id="18" string="especially" />
            <token id="19" string="since" />
            <token id="20" string="it" />
            <token id="21" string="killed" />
            <token id="22" string="an" />
            <token id="23" string="earlier" />
            <token id="24" string="," />
            <token id="25" string="similar" />
            <token id="26" string="effort" />
          </tokens>
        </chunking>
        <chunking id="2" string="the House of Representatives will not allow the prohibition to survive , especially since it killed an earlier , similar effort" type="SBAR">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="House" />
            <token id="8" string="of" />
            <token id="9" string="Representatives" />
            <token id="10" string="will" />
            <token id="11" string="not" />
            <token id="12" string="allow" />
            <token id="13" string="the" />
            <token id="14" string="prohibition" />
            <token id="15" string="to" />
            <token id="16" string="survive" />
            <token id="17" string="," />
            <token id="18" string="especially" />
            <token id="19" string="since" />
            <token id="20" string="it" />
            <token id="21" string="killed" />
            <token id="22" string="an" />
            <token id="23" string="earlier" />
            <token id="24" string="," />
            <token id="25" string="similar" />
            <token id="26" string="effort" />
          </tokens>
        </chunking>
        <chunking id="3" string="killed an earlier , similar effort" type="VP">
          <tokens>
            <token id="21" string="killed" />
            <token id="22" string="an" />
            <token id="23" string="earlier" />
            <token id="24" string="," />
            <token id="25" string="similar" />
            <token id="26" string="effort" />
          </tokens>
        </chunking>
        <chunking id="4" string="the House" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="House" />
          </tokens>
        </chunking>
        <chunking id="5" string="Representatives" type="NP">
          <tokens>
            <token id="9" string="Representatives" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="20" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="Pulido" type="NP">
          <tokens>
            <token id="2" string="Pulido" />
          </tokens>
        </chunking>
        <chunking id="8" string="since it killed an earlier , similar effort" type="SBAR">
          <tokens>
            <token id="19" string="since" />
            <token id="20" string="it" />
            <token id="21" string="killed" />
            <token id="22" string="an" />
            <token id="23" string="earlier" />
            <token id="24" string="," />
            <token id="25" string="similar" />
            <token id="26" string="effort" />
          </tokens>
        </chunking>
        <chunking id="9" string="will not allow the prohibition to survive , especially since it killed an earlier , similar effort" type="VP">
          <tokens>
            <token id="10" string="will" />
            <token id="11" string="not" />
            <token id="12" string="allow" />
            <token id="13" string="the" />
            <token id="14" string="prohibition" />
            <token id="15" string="to" />
            <token id="16" string="survive" />
            <token id="17" string="," />
            <token id="18" string="especially" />
            <token id="19" string="since" />
            <token id="20" string="it" />
            <token id="21" string="killed" />
            <token id="22" string="an" />
            <token id="23" string="earlier" />
            <token id="24" string="," />
            <token id="25" string="similar" />
            <token id="26" string="effort" />
          </tokens>
        </chunking>
        <chunking id="10" string="said he believes the House of Representatives will not allow the prohibition to survive , especially since it killed an earlier , similar effort" type="VP">
          <tokens>
            <token id="3" string="said" />
            <token id="4" string="he" />
            <token id="5" string="believes" />
            <token id="6" string="the" />
            <token id="7" string="House" />
            <token id="8" string="of" />
            <token id="9" string="Representatives" />
            <token id="10" string="will" />
            <token id="11" string="not" />
            <token id="12" string="allow" />
            <token id="13" string="the" />
            <token id="14" string="prohibition" />
            <token id="15" string="to" />
            <token id="16" string="survive" />
            <token id="17" string="," />
            <token id="18" string="especially" />
            <token id="19" string="since" />
            <token id="20" string="it" />
            <token id="21" string="killed" />
            <token id="22" string="an" />
            <token id="23" string="earlier" />
            <token id="24" string="," />
            <token id="25" string="similar" />
            <token id="26" string="effort" />
          </tokens>
        </chunking>
        <chunking id="11" string="allow the prohibition to survive , especially since it killed an earlier , similar effort" type="VP">
          <tokens>
            <token id="12" string="allow" />
            <token id="13" string="the" />
            <token id="14" string="prohibition" />
            <token id="15" string="to" />
            <token id="16" string="survive" />
            <token id="17" string="," />
            <token id="18" string="especially" />
            <token id="19" string="since" />
            <token id="20" string="it" />
            <token id="21" string="killed" />
            <token id="22" string="an" />
            <token id="23" string="earlier" />
            <token id="24" string="," />
            <token id="25" string="similar" />
            <token id="26" string="effort" />
          </tokens>
        </chunking>
        <chunking id="12" string="survive , especially since it killed an earlier , similar effort" type="VP">
          <tokens>
            <token id="16" string="survive" />
            <token id="17" string="," />
            <token id="18" string="especially" />
            <token id="19" string="since" />
            <token id="20" string="it" />
            <token id="21" string="killed" />
            <token id="22" string="an" />
            <token id="23" string="earlier" />
            <token id="24" string="," />
            <token id="25" string="similar" />
            <token id="26" string="effort" />
          </tokens>
        </chunking>
        <chunking id="13" string="he believes the House of Representatives will not allow the prohibition to survive , especially since it killed an earlier , similar effort" type="SBAR">
          <tokens>
            <token id="4" string="he" />
            <token id="5" string="believes" />
            <token id="6" string="the" />
            <token id="7" string="House" />
            <token id="8" string="of" />
            <token id="9" string="Representatives" />
            <token id="10" string="will" />
            <token id="11" string="not" />
            <token id="12" string="allow" />
            <token id="13" string="the" />
            <token id="14" string="prohibition" />
            <token id="15" string="to" />
            <token id="16" string="survive" />
            <token id="17" string="," />
            <token id="18" string="especially" />
            <token id="19" string="since" />
            <token id="20" string="it" />
            <token id="21" string="killed" />
            <token id="22" string="an" />
            <token id="23" string="earlier" />
            <token id="24" string="," />
            <token id="25" string="similar" />
            <token id="26" string="effort" />
          </tokens>
        </chunking>
        <chunking id="14" string="believes the House of Representatives will not allow the prohibition to survive , especially since it killed an earlier , similar effort" type="VP">
          <tokens>
            <token id="5" string="believes" />
            <token id="6" string="the" />
            <token id="7" string="House" />
            <token id="8" string="of" />
            <token id="9" string="Representatives" />
            <token id="10" string="will" />
            <token id="11" string="not" />
            <token id="12" string="allow" />
            <token id="13" string="the" />
            <token id="14" string="prohibition" />
            <token id="15" string="to" />
            <token id="16" string="survive" />
            <token id="17" string="," />
            <token id="18" string="especially" />
            <token id="19" string="since" />
            <token id="20" string="it" />
            <token id="21" string="killed" />
            <token id="22" string="an" />
            <token id="23" string="earlier" />
            <token id="24" string="," />
            <token id="25" string="similar" />
            <token id="26" string="effort" />
          </tokens>
        </chunking>
        <chunking id="15" string="the House of Representatives" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="House" />
            <token id="8" string="of" />
            <token id="9" string="Representatives" />
          </tokens>
        </chunking>
        <chunking id="16" string="the prohibition to survive , especially since it killed an earlier , similar effort" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="prohibition" />
            <token id="15" string="to" />
            <token id="16" string="survive" />
            <token id="17" string="," />
            <token id="18" string="especially" />
            <token id="19" string="since" />
            <token id="20" string="it" />
            <token id="21" string="killed" />
            <token id="22" string="an" />
            <token id="23" string="earlier" />
            <token id="24" string="," />
            <token id="25" string="similar" />
            <token id="26" string="effort" />
          </tokens>
        </chunking>
        <chunking id="17" string="he" type="NP">
          <tokens>
            <token id="4" string="he" />
          </tokens>
        </chunking>
        <chunking id="18" string="an earlier , similar effort" type="NP">
          <tokens>
            <token id="22" string="an" />
            <token id="23" string="earlier" />
            <token id="24" string="," />
            <token id="25" string="similar" />
            <token id="26" string="effort" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="3">said</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">said</governor>
          <dependent id="2">Pulido</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">believes</governor>
          <dependent id="4">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">said</governor>
          <dependent id="5">believes</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">House</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">allow</governor>
          <dependent id="7">House</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Representatives</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">House</governor>
          <dependent id="9">Representatives</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">allow</governor>
          <dependent id="10">will</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="12">allow</governor>
          <dependent id="11">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">believes</governor>
          <dependent id="12">allow</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">prohibition</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">allow</governor>
          <dependent id="14">prohibition</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">survive</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="14">prohibition</governor>
          <dependent id="16">survive</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">survive</governor>
          <dependent id="18">especially</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">killed</governor>
          <dependent id="19">since</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">killed</governor>
          <dependent id="20">it</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="16">survive</governor>
          <dependent id="21">killed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">effort</governor>
          <dependent id="22">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">effort</governor>
          <dependent id="23">earlier</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">effort</governor>
          <dependent id="25">similar</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">killed</governor>
          <dependent id="26">effort</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="House of Representatives" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="7" string="House" />
            <token id="8" string="of" />
            <token id="9" string="Representatives" />
          </tokens>
        </entity>
        <entity id="2" string="Pulido" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Pulido" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>The issue cuts across partisan lines in the Senate, with Minority Leader Bob Dole (R-Kan.)</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="issue" lemma="issue" stem="issu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="cuts" lemma="cut" stem="cut" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="across" lemma="across" stem="across" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="partisan" lemma="partisan" stem="partisan" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="lines" lemma="line" stem="line" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Senate" lemma="Senate" stem="senat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Minority" lemma="Minority" stem="minor" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="Leader" lemma="Leader" stem="leader" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="true" is_refers="false" />
        <token id="14" string="Bob" lemma="Bob" stem="bob" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="15" string="Dole" lemma="Dole" stem="dole" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="16" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="R-Kan" lemma="R-Kan" stem="r-kan" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN issue)) (VP (VBZ cuts) (PP (IN across) (NP (NP (JJ partisan) (NNS lines)) (PP (IN in) (NP (DT the) (NNP Senate))))) (, ,) (PP (IN with) (NP (NP (NNP Minority) (NNP Leader) (NNP Bob) (NNP Dole)) (PRN (-LRB- -LRB-) (NP (NNP R-Kan) (. .)) (-RRB- -RRB-)))))))</syntactictree>
      <chunkings>
        <chunking id="1" string="cuts across partisan lines in the Senate , with Minority Leader Bob Dole -LRB- R-Kan . -RRB-" type="VP">
          <tokens>
            <token id="3" string="cuts" />
            <token id="4" string="across" />
            <token id="5" string="partisan" />
            <token id="6" string="lines" />
            <token id="7" string="in" />
            <token id="8" string="the" />
            <token id="9" string="Senate" />
            <token id="10" string="," />
            <token id="11" string="with" />
            <token id="12" string="Minority" />
            <token id="13" string="Leader" />
            <token id="14" string="Bob" />
            <token id="15" string="Dole" />
            <token id="16" string="(" />
            <token id="17" string="R-Kan" />
            <token id="18" string="." />
            <token id="19" string=")" />
          </tokens>
        </chunking>
        <chunking id="2" string="partisan lines in the Senate" type="NP">
          <tokens>
            <token id="5" string="partisan" />
            <token id="6" string="lines" />
            <token id="7" string="in" />
            <token id="8" string="the" />
            <token id="9" string="Senate" />
          </tokens>
        </chunking>
        <chunking id="3" string="the Senate" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="Senate" />
          </tokens>
        </chunking>
        <chunking id="4" string="The issue" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="issue" />
          </tokens>
        </chunking>
        <chunking id="5" string="Minority Leader Bob Dole" type="NP">
          <tokens>
            <token id="12" string="Minority" />
            <token id="13" string="Leader" />
            <token id="14" string="Bob" />
            <token id="15" string="Dole" />
          </tokens>
        </chunking>
        <chunking id="6" string="Minority Leader Bob Dole -LRB- R-Kan . -RRB-" type="NP">
          <tokens>
            <token id="12" string="Minority" />
            <token id="13" string="Leader" />
            <token id="14" string="Bob" />
            <token id="15" string="Dole" />
            <token id="16" string="(" />
            <token id="17" string="R-Kan" />
            <token id="18" string="." />
            <token id="19" string=")" />
          </tokens>
        </chunking>
        <chunking id="7" string="partisan lines" type="NP">
          <tokens>
            <token id="5" string="partisan" />
            <token id="6" string="lines" />
          </tokens>
        </chunking>
        <chunking id="8" string="R-Kan ." type="NP">
          <tokens>
            <token id="17" string="R-Kan" />
            <token id="18" string="." />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">issue</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">cuts</governor>
          <dependent id="2">issue</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">cuts</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">lines</governor>
          <dependent id="4">across</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">lines</governor>
          <dependent id="5">partisan</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">cuts</governor>
          <dependent id="6">lines</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Senate</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">Senate</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">lines</governor>
          <dependent id="9">Senate</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">Dole</governor>
          <dependent id="11">with</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Dole</governor>
          <dependent id="12">Minority</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Dole</governor>
          <dependent id="13">Leader</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Dole</governor>
          <dependent id="14">Bob</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">cuts</governor>
          <dependent id="15">Dole</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="15">Dole</governor>
          <dependent id="17">R-Kan</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Senate" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="9" string="Senate" />
          </tokens>
        </entity>
        <entity id="2" string="Bob Dole" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Bob" />
            <token id="15" string="Dole" />
          </tokens>
        </entity>
        <entity id="3" string="Leader" type="TITLE" score="0.0">
          <tokens>
            <token id="13" string="Leader" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>arguing against the White House position on grounds that including illegal aliens in the census is unfair to American citizens.</content>
      <tokens>
        <token id="1" string="arguing" lemma="argue" stem="argu" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="White" lemma="White" stem="white" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="5" string="House" lemma="House" stem="hous" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="6" string="position" lemma="position" stem="posit" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="grounds" lemma="grounds" stem="ground" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="including" lemma="include" stem="includ" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="aliens" lemma="alien" stem="alien" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="census" lemma="census" stem="censu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="unfair" lemma="unfair" stem="unfair" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="American" lemma="american" stem="american" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="20" string="citizens" lemma="citizen" stem="citizen" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VBG arguing) (PP (IN against) (NP (DT the) (NNP White) (NNP House) (NN position))) (PP (IN on) (NP (NP (NNS grounds)) (SBAR (WHNP (WDT that)) (S (VP (VBG including) (NP (JJ illegal) (NNS aliens)) (PP (IN in) (NP (DT the) (NN census)))))))))) (VP (VBZ is) (ADJP (JJ unfair) (PP (TO to) (NP (JJ American) (NNS citizens))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="illegal aliens" type="NP">
          <tokens>
            <token id="11" string="illegal" />
            <token id="12" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="2" string="American citizens" type="NP">
          <tokens>
            <token id="19" string="American" />
            <token id="20" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="3" string="that including illegal aliens in the census" type="SBAR">
          <tokens>
            <token id="9" string="that" />
            <token id="10" string="including" />
            <token id="11" string="illegal" />
            <token id="12" string="aliens" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="census" />
          </tokens>
        </chunking>
        <chunking id="4" string="grounds" type="NP">
          <tokens>
            <token id="8" string="grounds" />
          </tokens>
        </chunking>
        <chunking id="5" string="the census" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="census" />
          </tokens>
        </chunking>
        <chunking id="6" string="arguing against the White House position on grounds that including illegal aliens in the census" type="VP">
          <tokens>
            <token id="1" string="arguing" />
            <token id="2" string="against" />
            <token id="3" string="the" />
            <token id="4" string="White" />
            <token id="5" string="House" />
            <token id="6" string="position" />
            <token id="7" string="on" />
            <token id="8" string="grounds" />
            <token id="9" string="that" />
            <token id="10" string="including" />
            <token id="11" string="illegal" />
            <token id="12" string="aliens" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="census" />
          </tokens>
        </chunking>
        <chunking id="7" string="including illegal aliens in the census" type="VP">
          <tokens>
            <token id="10" string="including" />
            <token id="11" string="illegal" />
            <token id="12" string="aliens" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="census" />
          </tokens>
        </chunking>
        <chunking id="8" string="the White House position" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="White" />
            <token id="5" string="House" />
            <token id="6" string="position" />
          </tokens>
        </chunking>
        <chunking id="9" string="unfair to American citizens" type="ADJP">
          <tokens>
            <token id="17" string="unfair" />
            <token id="18" string="to" />
            <token id="19" string="American" />
            <token id="20" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="10" string="grounds that including illegal aliens in the census" type="NP">
          <tokens>
            <token id="8" string="grounds" />
            <token id="9" string="that" />
            <token id="10" string="including" />
            <token id="11" string="illegal" />
            <token id="12" string="aliens" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="census" />
          </tokens>
        </chunking>
        <chunking id="11" string="is unfair to American citizens" type="VP">
          <tokens>
            <token id="16" string="is" />
            <token id="17" string="unfair" />
            <token id="18" string="to" />
            <token id="19" string="American" />
            <token id="20" string="citizens" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="csubj">
          <governor id="17">unfair</governor>
          <dependent id="1">arguing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">position</governor>
          <dependent id="2">against</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">position</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">position</governor>
          <dependent id="4">White</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">position</governor>
          <dependent id="5">House</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">arguing</governor>
          <dependent id="6">position</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">grounds</governor>
          <dependent id="7">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">arguing</governor>
          <dependent id="8">grounds</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">including</governor>
          <dependent id="9">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="8">grounds</governor>
          <dependent id="10">including</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">aliens</governor>
          <dependent id="11">illegal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">including</governor>
          <dependent id="12">aliens</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">census</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">census</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">including</governor>
          <dependent id="15">census</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="17">unfair</governor>
          <dependent id="16">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">unfair</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">citizens</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">citizens</governor>
          <dependent id="19">American</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">unfair</governor>
          <dependent id="20">citizens</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="White House" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="4" string="White" />
            <token id="5" string="House" />
          </tokens>
        </entity>
        <entity id="2" string="American" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="19" string="American" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>Loss of Seats Cited &amp;quot;Some states will lose congressional seats because of illegal aliens,&amp;quot; Dole argued.</content>
      <tokens>
        <token id="1" string="Loss" lemma="loss" stem="loss" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Seats" lemma="seat" stem="seat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="Cited" lemma="cite" stem="cite" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="states" lemma="state" stem="state" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="lose" lemma="lose" stem="lose" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="congressional" lemma="congressional" stem="congression" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="seats" lemma="seat" stem="seat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="aliens" lemma="alien" stem="alien" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Dole" lemma="Dole" stem="dole" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="19" string="argued" lemma="argue" stem="argu" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (NN Loss)) (PP (IN of) (NP (NP (NNS Seats)) (VP (VBN Cited) (S (`` ``) (NP (DT Some) (NNS states))))))) (VP (MD will) (VP (VB lose) (NP (JJ congressional) (NNS seats)) (PP (IN because) (PP (IN of) (NP (JJ illegal) (NNS aliens))))))) (, ,) ('' '') (NP (NNP Dole)) (VP (VBD argued)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Some states" type="NP">
          <tokens>
            <token id="6" string="Some" />
            <token id="7" string="states" />
          </tokens>
        </chunking>
        <chunking id="2" string="argued" type="VP">
          <tokens>
            <token id="19" string="argued" />
          </tokens>
        </chunking>
        <chunking id="3" string="illegal aliens" type="NP">
          <tokens>
            <token id="14" string="illegal" />
            <token id="15" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="4" string="Dole" type="NP">
          <tokens>
            <token id="18" string="Dole" />
          </tokens>
        </chunking>
        <chunking id="5" string="Cited `` Some states" type="VP">
          <tokens>
            <token id="4" string="Cited" />
            <token id="5" string="&quot;" />
            <token id="6" string="Some" />
            <token id="7" string="states" />
          </tokens>
        </chunking>
        <chunking id="6" string="Loss" type="NP">
          <tokens>
            <token id="1" string="Loss" />
          </tokens>
        </chunking>
        <chunking id="7" string="Loss of Seats Cited `` Some states" type="NP">
          <tokens>
            <token id="1" string="Loss" />
            <token id="2" string="of" />
            <token id="3" string="Seats" />
            <token id="4" string="Cited" />
            <token id="5" string="&quot;" />
            <token id="6" string="Some" />
            <token id="7" string="states" />
          </tokens>
        </chunking>
        <chunking id="8" string="Seats Cited `` Some states" type="NP">
          <tokens>
            <token id="3" string="Seats" />
            <token id="4" string="Cited" />
            <token id="5" string="&quot;" />
            <token id="6" string="Some" />
            <token id="7" string="states" />
          </tokens>
        </chunking>
        <chunking id="9" string="congressional seats" type="NP">
          <tokens>
            <token id="10" string="congressional" />
            <token id="11" string="seats" />
          </tokens>
        </chunking>
        <chunking id="10" string="Seats" type="NP">
          <tokens>
            <token id="3" string="Seats" />
          </tokens>
        </chunking>
        <chunking id="11" string="will lose congressional seats because of illegal aliens" type="VP">
          <tokens>
            <token id="8" string="will" />
            <token id="9" string="lose" />
            <token id="10" string="congressional" />
            <token id="11" string="seats" />
            <token id="12" string="because" />
            <token id="13" string="of" />
            <token id="14" string="illegal" />
            <token id="15" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="12" string="lose congressional seats because of illegal aliens" type="VP">
          <tokens>
            <token id="9" string="lose" />
            <token id="10" string="congressional" />
            <token id="11" string="seats" />
            <token id="12" string="because" />
            <token id="13" string="of" />
            <token id="14" string="illegal" />
            <token id="15" string="aliens" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="9">lose</governor>
          <dependent id="1">Loss</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">Seats</governor>
          <dependent id="2">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Loss</governor>
          <dependent id="3">Seats</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="3">Seats</governor>
          <dependent id="4">Cited</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">states</governor>
          <dependent id="6">Some</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">Cited</governor>
          <dependent id="7">states</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">lose</governor>
          <dependent id="8">will</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">argued</governor>
          <dependent id="9">lose</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">seats</governor>
          <dependent id="10">congressional</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">lose</governor>
          <dependent id="11">seats</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">aliens</governor>
          <dependent id="12">because</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">aliens</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">aliens</governor>
          <dependent id="14">illegal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">lose</governor>
          <dependent id="15">aliens</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">argued</governor>
          <dependent id="18">Dole</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="19">argued</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Dole" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Dole" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>Sen. Thad Cochran (R-Miss.)</content>
      <tokens>
        <token id="1" string="Sen." lemma="Sen." stem="sen." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="Thad" lemma="Thad" stem="thad" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="Cochran" lemma="Cochran" stem="cochran" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="R-Miss" lemma="R-Miss" stem="r-miss" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (NNP Sen.) (NNP Thad) (NNP Cochran)) (PRN (-LRB- -LRB-) (NP (NNP R-Miss) (. .)) (-RRB- -RRB-))))</syntactictree>
      <chunkings>
        <chunking id="1" string="Sen. Thad Cochran -LRB- R-Miss . -RRB-" type="NP">
          <tokens>
            <token id="1" string="Sen." />
            <token id="2" string="Thad" />
            <token id="3" string="Cochran" />
            <token id="4" string="(" />
            <token id="5" string="R-Miss" />
            <token id="6" string="." />
            <token id="7" string=")" />
          </tokens>
        </chunking>
        <chunking id="2" string="Sen. Thad Cochran" type="NP">
          <tokens>
            <token id="1" string="Sen." />
            <token id="2" string="Thad" />
            <token id="3" string="Cochran" />
          </tokens>
        </chunking>
        <chunking id="3" string="R-Miss ." type="NP">
          <tokens>
            <token id="5" string="R-Miss" />
            <token id="6" string="." />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Cochran</governor>
          <dependent id="1">Sen.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Cochran</governor>
          <dependent id="2">Thad</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">Cochran</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="3">Cochran</governor>
          <dependent id="5">R-Miss</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Thad Cochran" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Thad" />
            <token id="3" string="Cochran" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>said that Georgia and Indiana both lost House seats after the 1980 Census, and that California and New York -- centers of illegal immigration -- each gained seats.</content>
      <tokens>
        <token id="1" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Georgia" lemma="Georgia" stem="georgia" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="4" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Indiana" lemma="Indiana" stem="indiana" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="6" string="both" lemma="both" stem="both" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="lost" lemma="lose" stem="lost" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="House" lemma="House" stem="hous" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="9" string="seats" lemma="seat" stem="seat" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="1980" lemma="1980" stem="1980" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="13" string="Census" lemma="Census" stem="censu" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="California" lemma="California" stem="california" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="New" lemma="New" stem="new" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="20" string="York" lemma="York" stem="york" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="21" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="centers" lemma="center" stem="center" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="immigration" lemma="immigration" stem="immigr" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="each" lemma="each" stem="each" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="gained" lemma="gain" stem="gain" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="seats" lemma="seat" stem="seat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (VP (VBD said) (SBAR (SBAR (IN that) (S (NP (NNP Georgia) (CC and) (NNP Indiana)) (ADVP (CC both)) (VP (VBD lost) (NP (NNP House) (NNS seats)) (PP (IN after) (NP (NP (DT the) (CD 1980)) (NP (NNP Census))))))) (, ,) (CC and) (SBAR (IN that) (S (NP (NP (NNP California)) (CC and) (NP (NP (NNP New) (NNP York)) (PRN (: --) (NP (NP (NNS centers)) (PP (IN of) (NP (JJ illegal) (NN immigration)))) (: --)) (NP (DT each)))) (VP (VBD gained) (NP (NNS seats))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="New York" type="NP">
          <tokens>
            <token id="19" string="New" />
            <token id="20" string="York" />
          </tokens>
        </chunking>
        <chunking id="2" string="House seats" type="NP">
          <tokens>
            <token id="8" string="House" />
            <token id="9" string="seats" />
          </tokens>
        </chunking>
        <chunking id="3" string="lost House seats after the 1980 Census" type="VP">
          <tokens>
            <token id="7" string="lost" />
            <token id="8" string="House" />
            <token id="9" string="seats" />
            <token id="10" string="after" />
            <token id="11" string="the" />
            <token id="12" string="1980" />
            <token id="13" string="Census" />
          </tokens>
        </chunking>
        <chunking id="4" string="California" type="NP">
          <tokens>
            <token id="17" string="California" />
          </tokens>
        </chunking>
        <chunking id="5" string="gained seats" type="VP">
          <tokens>
            <token id="28" string="gained" />
            <token id="29" string="seats" />
          </tokens>
        </chunking>
        <chunking id="6" string="that Georgia and Indiana both lost House seats after the 1980 Census , and that California and New York -- centers of illegal immigration -- each gained seats" type="SBAR">
          <tokens>
            <token id="2" string="that" />
            <token id="3" string="Georgia" />
            <token id="4" string="and" />
            <token id="5" string="Indiana" />
            <token id="6" string="both" />
            <token id="7" string="lost" />
            <token id="8" string="House" />
            <token id="9" string="seats" />
            <token id="10" string="after" />
            <token id="11" string="the" />
            <token id="12" string="1980" />
            <token id="13" string="Census" />
            <token id="14" string="," />
            <token id="15" string="and" />
            <token id="16" string="that" />
            <token id="17" string="California" />
            <token id="18" string="and" />
            <token id="19" string="New" />
            <token id="20" string="York" />
            <token id="21" string="--" />
            <token id="22" string="centers" />
            <token id="23" string="of" />
            <token id="24" string="illegal" />
            <token id="25" string="immigration" />
            <token id="26" string="--" />
            <token id="27" string="each" />
            <token id="28" string="gained" />
            <token id="29" string="seats" />
          </tokens>
        </chunking>
        <chunking id="7" string="illegal immigration" type="NP">
          <tokens>
            <token id="24" string="illegal" />
            <token id="25" string="immigration" />
          </tokens>
        </chunking>
        <chunking id="8" string="the 1980 Census" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="1980" />
            <token id="13" string="Census" />
          </tokens>
        </chunking>
        <chunking id="9" string="the 1980" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="1980" />
          </tokens>
        </chunking>
        <chunking id="10" string="that California and New York -- centers of illegal immigration -- each gained seats" type="SBAR">
          <tokens>
            <token id="16" string="that" />
            <token id="17" string="California" />
            <token id="18" string="and" />
            <token id="19" string="New" />
            <token id="20" string="York" />
            <token id="21" string="--" />
            <token id="22" string="centers" />
            <token id="23" string="of" />
            <token id="24" string="illegal" />
            <token id="25" string="immigration" />
            <token id="26" string="--" />
            <token id="27" string="each" />
            <token id="28" string="gained" />
            <token id="29" string="seats" />
          </tokens>
        </chunking>
        <chunking id="11" string="seats" type="NP">
          <tokens>
            <token id="29" string="seats" />
          </tokens>
        </chunking>
        <chunking id="12" string="each" type="NP">
          <tokens>
            <token id="27" string="each" />
          </tokens>
        </chunking>
        <chunking id="13" string="that Georgia and Indiana both lost House seats after the 1980 Census" type="SBAR">
          <tokens>
            <token id="2" string="that" />
            <token id="3" string="Georgia" />
            <token id="4" string="and" />
            <token id="5" string="Indiana" />
            <token id="6" string="both" />
            <token id="7" string="lost" />
            <token id="8" string="House" />
            <token id="9" string="seats" />
            <token id="10" string="after" />
            <token id="11" string="the" />
            <token id="12" string="1980" />
            <token id="13" string="Census" />
          </tokens>
        </chunking>
        <chunking id="14" string="California and New York -- centers of illegal immigration -- each" type="NP">
          <tokens>
            <token id="17" string="California" />
            <token id="18" string="and" />
            <token id="19" string="New" />
            <token id="20" string="York" />
            <token id="21" string="--" />
            <token id="22" string="centers" />
            <token id="23" string="of" />
            <token id="24" string="illegal" />
            <token id="25" string="immigration" />
            <token id="26" string="--" />
            <token id="27" string="each" />
          </tokens>
        </chunking>
        <chunking id="15" string="said that Georgia and Indiana both lost House seats after the 1980 Census , and that California and New York -- centers of illegal immigration -- each gained seats" type="VP">
          <tokens>
            <token id="1" string="said" />
            <token id="2" string="that" />
            <token id="3" string="Georgia" />
            <token id="4" string="and" />
            <token id="5" string="Indiana" />
            <token id="6" string="both" />
            <token id="7" string="lost" />
            <token id="8" string="House" />
            <token id="9" string="seats" />
            <token id="10" string="after" />
            <token id="11" string="the" />
            <token id="12" string="1980" />
            <token id="13" string="Census" />
            <token id="14" string="," />
            <token id="15" string="and" />
            <token id="16" string="that" />
            <token id="17" string="California" />
            <token id="18" string="and" />
            <token id="19" string="New" />
            <token id="20" string="York" />
            <token id="21" string="--" />
            <token id="22" string="centers" />
            <token id="23" string="of" />
            <token id="24" string="illegal" />
            <token id="25" string="immigration" />
            <token id="26" string="--" />
            <token id="27" string="each" />
            <token id="28" string="gained" />
            <token id="29" string="seats" />
          </tokens>
        </chunking>
        <chunking id="16" string="Census" type="NP">
          <tokens>
            <token id="13" string="Census" />
          </tokens>
        </chunking>
        <chunking id="17" string="Georgia and Indiana" type="NP">
          <tokens>
            <token id="3" string="Georgia" />
            <token id="4" string="and" />
            <token id="5" string="Indiana" />
          </tokens>
        </chunking>
        <chunking id="18" string="centers of illegal immigration" type="NP">
          <tokens>
            <token id="22" string="centers" />
            <token id="23" string="of" />
            <token id="24" string="illegal" />
            <token id="25" string="immigration" />
          </tokens>
        </chunking>
        <chunking id="19" string="New York -- centers of illegal immigration -- each" type="NP">
          <tokens>
            <token id="19" string="New" />
            <token id="20" string="York" />
            <token id="21" string="--" />
            <token id="22" string="centers" />
            <token id="23" string="of" />
            <token id="24" string="illegal" />
            <token id="25" string="immigration" />
            <token id="26" string="--" />
            <token id="27" string="each" />
          </tokens>
        </chunking>
        <chunking id="20" string="centers" type="NP">
          <tokens>
            <token id="22" string="centers" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">said</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">lost</governor>
          <dependent id="2">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">lost</governor>
          <dependent id="3">Georgia</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">Georgia</governor>
          <dependent id="4">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">Georgia</governor>
          <dependent id="5">Indiana</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">lost</governor>
          <dependent id="6">both</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="1">said</governor>
          <dependent id="7">lost</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">seats</governor>
          <dependent id="8">House</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">lost</governor>
          <dependent id="9">seats</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">1980</governor>
          <dependent id="10">after</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">1980</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">lost</governor>
          <dependent id="12">1980</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="12">1980</governor>
          <dependent id="13">Census</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">lost</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="28">gained</governor>
          <dependent id="16">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">gained</governor>
          <dependent id="17">California</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">California</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">York</governor>
          <dependent id="19">New</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">California</governor>
          <dependent id="20">York</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="20">York</governor>
          <dependent id="22">centers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">immigration</governor>
          <dependent id="23">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">immigration</governor>
          <dependent id="24">illegal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">centers</governor>
          <dependent id="25">immigration</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="20">York</governor>
          <dependent id="27">each</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">lost</governor>
          <dependent id="28">gained</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="28">gained</governor>
          <dependent id="29">seats</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="New York" type="LOCATION" score="0.0">
          <tokens>
            <token id="19" string="New" />
            <token id="20" string="York" />
          </tokens>
        </entity>
        <entity id="2" string="California" type="LOCATION" score="0.0">
          <tokens>
            <token id="17" string="California" />
          </tokens>
        </entity>
        <entity id="3" string="House" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="8" string="House" />
          </tokens>
        </entity>
        <entity id="4" string="Indiana" type="LOCATION" score="0.0">
          <tokens>
            <token id="5" string="Indiana" />
          </tokens>
        </entity>
        <entity id="5" string="Georgia" type="LOCATION" score="0.0">
          <tokens>
            <token id="3" string="Georgia" />
          </tokens>
        </entity>
        <entity id="6" string="1980" type="DATE" score="0.0">
          <tokens>
            <token id="12" string="1980" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="26" has_coreference="true">
      <content>&amp;quot;The bottom line is illegal aliens ought to be deported, not counted,&amp;quot; Cochran said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="bottom" lemma="bottom" stem="bottom" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="line" lemma="line" stem="line" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="aliens" lemma="alien" stem="alien" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="ought" lemma="ought" stem="ought" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="deported" lemma="deport" stem="deport" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="counted" lemma="count" stem="count" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Cochran" lemma="Cochran" stem="cochran" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="18" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (DT The) (JJ bottom) (NN line)) (VP (VBZ is) (ADJP (JJ illegal) (SBAR (S (NP (NNS aliens)) (VP (MD ought) (S (VP (TO to) (VP (VB be) (VP (VBN deported))))) (, ,) (VP (RB not) (VBN counted)))))))) (, ,) ('' '') (NP (NNP Cochran)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="aliens" type="NP">
          <tokens>
            <token id="7" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="2" string="be deported" type="VP">
          <tokens>
            <token id="10" string="be" />
            <token id="11" string="deported" />
          </tokens>
        </chunking>
        <chunking id="3" string="Cochran" type="NP">
          <tokens>
            <token id="17" string="Cochran" />
          </tokens>
        </chunking>
        <chunking id="4" string="aliens ought to be deported , not counted" type="SBAR">
          <tokens>
            <token id="7" string="aliens" />
            <token id="8" string="ought" />
            <token id="9" string="to" />
            <token id="10" string="be" />
            <token id="11" string="deported" />
            <token id="12" string="," />
            <token id="13" string="not" />
            <token id="14" string="counted" />
          </tokens>
        </chunking>
        <chunking id="5" string="ought to be deported , not counted" type="VP">
          <tokens>
            <token id="8" string="ought" />
            <token id="9" string="to" />
            <token id="10" string="be" />
            <token id="11" string="deported" />
            <token id="12" string="," />
            <token id="13" string="not" />
            <token id="14" string="counted" />
          </tokens>
        </chunking>
        <chunking id="6" string="illegal aliens ought to be deported , not counted" type="ADJP">
          <tokens>
            <token id="6" string="illegal" />
            <token id="7" string="aliens" />
            <token id="8" string="ought" />
            <token id="9" string="to" />
            <token id="10" string="be" />
            <token id="11" string="deported" />
            <token id="12" string="," />
            <token id="13" string="not" />
            <token id="14" string="counted" />
          </tokens>
        </chunking>
        <chunking id="7" string="is illegal aliens ought to be deported , not counted" type="VP">
          <tokens>
            <token id="5" string="is" />
            <token id="6" string="illegal" />
            <token id="7" string="aliens" />
            <token id="8" string="ought" />
            <token id="9" string="to" />
            <token id="10" string="be" />
            <token id="11" string="deported" />
            <token id="12" string="," />
            <token id="13" string="not" />
            <token id="14" string="counted" />
          </tokens>
        </chunking>
        <chunking id="8" string="to be deported" type="VP">
          <tokens>
            <token id="9" string="to" />
            <token id="10" string="be" />
            <token id="11" string="deported" />
          </tokens>
        </chunking>
        <chunking id="9" string="deported" type="VP">
          <tokens>
            <token id="11" string="deported" />
          </tokens>
        </chunking>
        <chunking id="10" string="not counted" type="VP">
          <tokens>
            <token id="13" string="not" />
            <token id="14" string="counted" />
          </tokens>
        </chunking>
        <chunking id="11" string="said" type="VP">
          <tokens>
            <token id="18" string="said" />
          </tokens>
        </chunking>
        <chunking id="12" string="The bottom line" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="bottom" />
            <token id="4" string="line" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">line</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">line</governor>
          <dependent id="3">bottom</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">illegal</governor>
          <dependent id="4">line</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">illegal</governor>
          <dependent id="5">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="18">said</governor>
          <dependent id="6">illegal</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">counted</governor>
          <dependent id="7">aliens</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">counted</governor>
          <dependent id="8">ought</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">deported</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="11">deported</governor>
          <dependent id="10">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="14">counted</governor>
          <dependent id="11">deported</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="14">counted</governor>
          <dependent id="13">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">illegal</governor>
          <dependent id="14">counted</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">said</governor>
          <dependent id="17">Cochran</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Cochran" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="Cochran" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>Sen. Pete Wilson (R-Calif.)</content>
      <tokens>
        <token id="1" string="Sen." lemma="Sen." stem="sen." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="Pete" lemma="Pete" stem="pete" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="Wilson" lemma="Wilson" stem="wilson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="R-Calif" lemma="R-Calif" stem="r-calif" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (NNP Sen.) (NNP Pete) (NNP Wilson)) (PRN (-LRB- -LRB-) (NP (NNP R-Calif) (. .)) (-RRB- -RRB-))))</syntactictree>
      <chunkings>
        <chunking id="1" string="Sen. Pete Wilson -LRB- R-Calif . -RRB-" type="NP">
          <tokens>
            <token id="1" string="Sen." />
            <token id="2" string="Pete" />
            <token id="3" string="Wilson" />
            <token id="4" string="(" />
            <token id="5" string="R-Calif" />
            <token id="6" string="." />
            <token id="7" string=")" />
          </tokens>
        </chunking>
        <chunking id="2" string="R-Calif ." type="NP">
          <tokens>
            <token id="5" string="R-Calif" />
            <token id="6" string="." />
          </tokens>
        </chunking>
        <chunking id="3" string="Sen. Pete Wilson" type="NP">
          <tokens>
            <token id="1" string="Sen." />
            <token id="2" string="Pete" />
            <token id="3" string="Wilson" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Wilson</governor>
          <dependent id="1">Sen.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Wilson</governor>
          <dependent id="2">Pete</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">Wilson</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="3">Wilson</governor>
          <dependent id="5">R-Calif</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Pete Wilson" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Pete" />
            <token id="3" string="Wilson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="28" has_coreference="false">
      <content>countered that excluding illegal residents from the decennial census is unfair to the states that have suffered from a huge influx of immigration beyond the legal limits.</content>
      <tokens>
        <token id="1" string="countered" lemma="counter" stem="counter" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="excluding" lemma="exclude" stem="exclud" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="residents" lemma="resident" stem="resid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="decennial" lemma="decennial" stem="decenni" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="census" lemma="census" stem="censu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="unfair" lemma="unfair" stem="unfair" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="states" lemma="state" stem="state" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="suffered" lemma="suffer" stem="suffer" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="huge" lemma="huge" stem="huge" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="influx" lemma="influx" stem="influx" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="immigration" lemma="immigration" stem="immigr" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="beyond" lemma="beyond" stem="beyond" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="legal" lemma="legal" stem="legal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="limits" lemma="limit" stem="limit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (VP (VBD countered) (SBAR (IN that) (S (S (VP (VBG excluding) (NP (JJ illegal) (NNS residents)) (PP (IN from) (NP (DT the) (JJ decennial) (NN census))))) (VP (VBZ is) (ADJP (JJ unfair) (PP (TO to) (NP (NP (DT the) (NNS states)) (SBAR (WHNP (WDT that)) (S (VP (VBP have) (VP (VBN suffered) (PP (IN from) (NP (NP (DT a) (JJ huge) (NN influx)) (PP (IN of) (NP (NN immigration))))) (PP (IN beyond) (NP (DT the) (JJ legal) (NNS limits)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a huge influx of immigration" type="NP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="huge" />
            <token id="21" string="influx" />
            <token id="22" string="of" />
            <token id="23" string="immigration" />
          </tokens>
        </chunking>
        <chunking id="2" string="immigration" type="NP">
          <tokens>
            <token id="23" string="immigration" />
          </tokens>
        </chunking>
        <chunking id="3" string="a huge influx" type="NP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="huge" />
            <token id="21" string="influx" />
          </tokens>
        </chunking>
        <chunking id="4" string="the states that have suffered from a huge influx of immigration beyond the legal limits" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="states" />
            <token id="15" string="that" />
            <token id="16" string="have" />
            <token id="17" string="suffered" />
            <token id="18" string="from" />
            <token id="19" string="a" />
            <token id="20" string="huge" />
            <token id="21" string="influx" />
            <token id="22" string="of" />
            <token id="23" string="immigration" />
            <token id="24" string="beyond" />
            <token id="25" string="the" />
            <token id="26" string="legal" />
            <token id="27" string="limits" />
          </tokens>
        </chunking>
        <chunking id="5" string="illegal residents" type="NP">
          <tokens>
            <token id="4" string="illegal" />
            <token id="5" string="residents" />
          </tokens>
        </chunking>
        <chunking id="6" string="excluding illegal residents from the decennial census" type="VP">
          <tokens>
            <token id="3" string="excluding" />
            <token id="4" string="illegal" />
            <token id="5" string="residents" />
            <token id="6" string="from" />
            <token id="7" string="the" />
            <token id="8" string="decennial" />
            <token id="9" string="census" />
          </tokens>
        </chunking>
        <chunking id="7" string="unfair to the states that have suffered from a huge influx of immigration beyond the legal limits" type="ADJP">
          <tokens>
            <token id="11" string="unfair" />
            <token id="12" string="to" />
            <token id="13" string="the" />
            <token id="14" string="states" />
            <token id="15" string="that" />
            <token id="16" string="have" />
            <token id="17" string="suffered" />
            <token id="18" string="from" />
            <token id="19" string="a" />
            <token id="20" string="huge" />
            <token id="21" string="influx" />
            <token id="22" string="of" />
            <token id="23" string="immigration" />
            <token id="24" string="beyond" />
            <token id="25" string="the" />
            <token id="26" string="legal" />
            <token id="27" string="limits" />
          </tokens>
        </chunking>
        <chunking id="8" string="the states" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="states" />
          </tokens>
        </chunking>
        <chunking id="9" string="suffered from a huge influx of immigration beyond the legal limits" type="VP">
          <tokens>
            <token id="17" string="suffered" />
            <token id="18" string="from" />
            <token id="19" string="a" />
            <token id="20" string="huge" />
            <token id="21" string="influx" />
            <token id="22" string="of" />
            <token id="23" string="immigration" />
            <token id="24" string="beyond" />
            <token id="25" string="the" />
            <token id="26" string="legal" />
            <token id="27" string="limits" />
          </tokens>
        </chunking>
        <chunking id="10" string="that excluding illegal residents from the decennial census is unfair to the states that have suffered from a huge influx of immigration beyond the legal limits" type="SBAR">
          <tokens>
            <token id="2" string="that" />
            <token id="3" string="excluding" />
            <token id="4" string="illegal" />
            <token id="5" string="residents" />
            <token id="6" string="from" />
            <token id="7" string="the" />
            <token id="8" string="decennial" />
            <token id="9" string="census" />
            <token id="10" string="is" />
            <token id="11" string="unfair" />
            <token id="12" string="to" />
            <token id="13" string="the" />
            <token id="14" string="states" />
            <token id="15" string="that" />
            <token id="16" string="have" />
            <token id="17" string="suffered" />
            <token id="18" string="from" />
            <token id="19" string="a" />
            <token id="20" string="huge" />
            <token id="21" string="influx" />
            <token id="22" string="of" />
            <token id="23" string="immigration" />
            <token id="24" string="beyond" />
            <token id="25" string="the" />
            <token id="26" string="legal" />
            <token id="27" string="limits" />
          </tokens>
        </chunking>
        <chunking id="11" string="that have suffered from a huge influx of immigration beyond the legal limits" type="SBAR">
          <tokens>
            <token id="15" string="that" />
            <token id="16" string="have" />
            <token id="17" string="suffered" />
            <token id="18" string="from" />
            <token id="19" string="a" />
            <token id="20" string="huge" />
            <token id="21" string="influx" />
            <token id="22" string="of" />
            <token id="23" string="immigration" />
            <token id="24" string="beyond" />
            <token id="25" string="the" />
            <token id="26" string="legal" />
            <token id="27" string="limits" />
          </tokens>
        </chunking>
        <chunking id="12" string="countered that excluding illegal residents from the decennial census is unfair to the states that have suffered from a huge influx of immigration beyond the legal limits" type="VP">
          <tokens>
            <token id="1" string="countered" />
            <token id="2" string="that" />
            <token id="3" string="excluding" />
            <token id="4" string="illegal" />
            <token id="5" string="residents" />
            <token id="6" string="from" />
            <token id="7" string="the" />
            <token id="8" string="decennial" />
            <token id="9" string="census" />
            <token id="10" string="is" />
            <token id="11" string="unfair" />
            <token id="12" string="to" />
            <token id="13" string="the" />
            <token id="14" string="states" />
            <token id="15" string="that" />
            <token id="16" string="have" />
            <token id="17" string="suffered" />
            <token id="18" string="from" />
            <token id="19" string="a" />
            <token id="20" string="huge" />
            <token id="21" string="influx" />
            <token id="22" string="of" />
            <token id="23" string="immigration" />
            <token id="24" string="beyond" />
            <token id="25" string="the" />
            <token id="26" string="legal" />
            <token id="27" string="limits" />
          </tokens>
        </chunking>
        <chunking id="13" string="have suffered from a huge influx of immigration beyond the legal limits" type="VP">
          <tokens>
            <token id="16" string="have" />
            <token id="17" string="suffered" />
            <token id="18" string="from" />
            <token id="19" string="a" />
            <token id="20" string="huge" />
            <token id="21" string="influx" />
            <token id="22" string="of" />
            <token id="23" string="immigration" />
            <token id="24" string="beyond" />
            <token id="25" string="the" />
            <token id="26" string="legal" />
            <token id="27" string="limits" />
          </tokens>
        </chunking>
        <chunking id="14" string="is unfair to the states that have suffered from a huge influx of immigration beyond the legal limits" type="VP">
          <tokens>
            <token id="10" string="is" />
            <token id="11" string="unfair" />
            <token id="12" string="to" />
            <token id="13" string="the" />
            <token id="14" string="states" />
            <token id="15" string="that" />
            <token id="16" string="have" />
            <token id="17" string="suffered" />
            <token id="18" string="from" />
            <token id="19" string="a" />
            <token id="20" string="huge" />
            <token id="21" string="influx" />
            <token id="22" string="of" />
            <token id="23" string="immigration" />
            <token id="24" string="beyond" />
            <token id="25" string="the" />
            <token id="26" string="legal" />
            <token id="27" string="limits" />
          </tokens>
        </chunking>
        <chunking id="15" string="the decennial census" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="decennial" />
            <token id="9" string="census" />
          </tokens>
        </chunking>
        <chunking id="16" string="the legal limits" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="legal" />
            <token id="27" string="limits" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">countered</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">unfair</governor>
          <dependent id="2">that</dependent>
        </dependency>
        <dependency type="csubj">
          <governor id="11">unfair</governor>
          <dependent id="3">excluding</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">residents</governor>
          <dependent id="4">illegal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">excluding</governor>
          <dependent id="5">residents</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">census</governor>
          <dependent id="6">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">census</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">census</governor>
          <dependent id="8">decennial</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">excluding</governor>
          <dependent id="9">census</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">unfair</governor>
          <dependent id="10">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="1">countered</governor>
          <dependent id="11">unfair</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">states</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">states</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">unfair</governor>
          <dependent id="14">states</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">suffered</governor>
          <dependent id="15">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="17">suffered</governor>
          <dependent id="16">have</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="14">states</governor>
          <dependent id="17">suffered</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">influx</governor>
          <dependent id="18">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">influx</governor>
          <dependent id="19">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">influx</governor>
          <dependent id="20">huge</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">suffered</governor>
          <dependent id="21">influx</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">immigration</governor>
          <dependent id="22">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">influx</governor>
          <dependent id="23">immigration</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">limits</governor>
          <dependent id="24">beyond</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">limits</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">limits</governor>
          <dependent id="26">legal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">suffered</governor>
          <dependent id="27">limits</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="29" has_coreference="true">
      <content>&amp;quot;There are enormous additional costs for states who have had a surge of population,&amp;quot; Wilson said, adding that those states should receive additional federal aid to cope with the added problems.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="enormous" lemma="enormous" stem="enorm" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="additional" lemma="additional" stem="addit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="costs" lemma="cost" stem="cost" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="states" lemma="state" stem="state" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="had" lemma="have" stem="had" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="surge" lemma="surge" stem="surg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="population" lemma="population" stem="popul" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Wilson" lemma="Wilson" stem="wilson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="19" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="adding" lemma="add" stem="ad" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="states" lemma="state" stem="state" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="should" lemma="should" stem="should" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="receive" lemma="receive" stem="receiv" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="additional" lemma="additional" stem="addit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="federal" lemma="federal" stem="feder" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="aid" lemma="aid" stem="aid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="cope" lemma="cope" stem="cope" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="added" lemma="add" stem="ad" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="problems" lemma="problem" stem="problem" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (EX There)) (VP (VBP are) (NP (NP (JJ enormous) (JJ additional) (NNS costs)) (PP (IN for) (NP (NP (NNS states)) (SBAR (WHNP (WP who)) (S (VP (VBP have) (VP (VBN had) (NP (NP (DT a) (NN surge)) (PP (IN of) (NP (NN population))))))))))))) (, ,) ('' '') (NP (NNP Wilson)) (VP (VBD said) (, ,) (S (VP (VBG adding) (SBAR (IN that) (S (NP (DT those) (NNS states)) (VP (MD should) (VP (VB receive) (NP (JJ additional) (JJ federal) (NN aid)) (S (VP (TO to) (VP (VB cope) (PP (IN with) (NP (DT the) (VBN added) (NNS problems))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="who have had a surge of population" type="SBAR">
          <tokens>
            <token id="9" string="who" />
            <token id="10" string="have" />
            <token id="11" string="had" />
            <token id="12" string="a" />
            <token id="13" string="surge" />
            <token id="14" string="of" />
            <token id="15" string="population" />
          </tokens>
        </chunking>
        <chunking id="2" string="said , adding that those states should receive additional federal aid to cope with the added problems" type="VP">
          <tokens>
            <token id="19" string="said" />
            <token id="20" string="," />
            <token id="21" string="adding" />
            <token id="22" string="that" />
            <token id="23" string="those" />
            <token id="24" string="states" />
            <token id="25" string="should" />
            <token id="26" string="receive" />
            <token id="27" string="additional" />
            <token id="28" string="federal" />
            <token id="29" string="aid" />
            <token id="30" string="to" />
            <token id="31" string="cope" />
            <token id="32" string="with" />
            <token id="33" string="the" />
            <token id="34" string="added" />
            <token id="35" string="problems" />
          </tokens>
        </chunking>
        <chunking id="3" string="enormous additional costs for states who have had a surge of population" type="NP">
          <tokens>
            <token id="4" string="enormous" />
            <token id="5" string="additional" />
            <token id="6" string="costs" />
            <token id="7" string="for" />
            <token id="8" string="states" />
            <token id="9" string="who" />
            <token id="10" string="have" />
            <token id="11" string="had" />
            <token id="12" string="a" />
            <token id="13" string="surge" />
            <token id="14" string="of" />
            <token id="15" string="population" />
          </tokens>
        </chunking>
        <chunking id="4" string="receive additional federal aid to cope with the added problems" type="VP">
          <tokens>
            <token id="26" string="receive" />
            <token id="27" string="additional" />
            <token id="28" string="federal" />
            <token id="29" string="aid" />
            <token id="30" string="to" />
            <token id="31" string="cope" />
            <token id="32" string="with" />
            <token id="33" string="the" />
            <token id="34" string="added" />
            <token id="35" string="problems" />
          </tokens>
        </chunking>
        <chunking id="5" string="Wilson" type="NP">
          <tokens>
            <token id="18" string="Wilson" />
          </tokens>
        </chunking>
        <chunking id="6" string="that those states should receive additional federal aid to cope with the added problems" type="SBAR">
          <tokens>
            <token id="22" string="that" />
            <token id="23" string="those" />
            <token id="24" string="states" />
            <token id="25" string="should" />
            <token id="26" string="receive" />
            <token id="27" string="additional" />
            <token id="28" string="federal" />
            <token id="29" string="aid" />
            <token id="30" string="to" />
            <token id="31" string="cope" />
            <token id="32" string="with" />
            <token id="33" string="the" />
            <token id="34" string="added" />
            <token id="35" string="problems" />
          </tokens>
        </chunking>
        <chunking id="7" string="should receive additional federal aid to cope with the added problems" type="VP">
          <tokens>
            <token id="25" string="should" />
            <token id="26" string="receive" />
            <token id="27" string="additional" />
            <token id="28" string="federal" />
            <token id="29" string="aid" />
            <token id="30" string="to" />
            <token id="31" string="cope" />
            <token id="32" string="with" />
            <token id="33" string="the" />
            <token id="34" string="added" />
            <token id="35" string="problems" />
          </tokens>
        </chunking>
        <chunking id="8" string="states" type="NP">
          <tokens>
            <token id="8" string="states" />
          </tokens>
        </chunking>
        <chunking id="9" string="had a surge of population" type="VP">
          <tokens>
            <token id="11" string="had" />
            <token id="12" string="a" />
            <token id="13" string="surge" />
            <token id="14" string="of" />
            <token id="15" string="population" />
          </tokens>
        </chunking>
        <chunking id="10" string="a surge" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="surge" />
          </tokens>
        </chunking>
        <chunking id="11" string="are enormous additional costs for states who have had a surge of population" type="VP">
          <tokens>
            <token id="3" string="are" />
            <token id="4" string="enormous" />
            <token id="5" string="additional" />
            <token id="6" string="costs" />
            <token id="7" string="for" />
            <token id="8" string="states" />
            <token id="9" string="who" />
            <token id="10" string="have" />
            <token id="11" string="had" />
            <token id="12" string="a" />
            <token id="13" string="surge" />
            <token id="14" string="of" />
            <token id="15" string="population" />
          </tokens>
        </chunking>
        <chunking id="12" string="population" type="NP">
          <tokens>
            <token id="15" string="population" />
          </tokens>
        </chunking>
        <chunking id="13" string="additional federal aid" type="NP">
          <tokens>
            <token id="27" string="additional" />
            <token id="28" string="federal" />
            <token id="29" string="aid" />
          </tokens>
        </chunking>
        <chunking id="14" string="a surge of population" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="surge" />
            <token id="14" string="of" />
            <token id="15" string="population" />
          </tokens>
        </chunking>
        <chunking id="15" string="There" type="NP">
          <tokens>
            <token id="2" string="There" />
          </tokens>
        </chunking>
        <chunking id="16" string="enormous additional costs" type="NP">
          <tokens>
            <token id="4" string="enormous" />
            <token id="5" string="additional" />
            <token id="6" string="costs" />
          </tokens>
        </chunking>
        <chunking id="17" string="the added problems" type="NP">
          <tokens>
            <token id="33" string="the" />
            <token id="34" string="added" />
            <token id="35" string="problems" />
          </tokens>
        </chunking>
        <chunking id="18" string="states who have had a surge of population" type="NP">
          <tokens>
            <token id="8" string="states" />
            <token id="9" string="who" />
            <token id="10" string="have" />
            <token id="11" string="had" />
            <token id="12" string="a" />
            <token id="13" string="surge" />
            <token id="14" string="of" />
            <token id="15" string="population" />
          </tokens>
        </chunking>
        <chunking id="19" string="cope with the added problems" type="VP">
          <tokens>
            <token id="31" string="cope" />
            <token id="32" string="with" />
            <token id="33" string="the" />
            <token id="34" string="added" />
            <token id="35" string="problems" />
          </tokens>
        </chunking>
        <chunking id="20" string="have had a surge of population" type="VP">
          <tokens>
            <token id="10" string="have" />
            <token id="11" string="had" />
            <token id="12" string="a" />
            <token id="13" string="surge" />
            <token id="14" string="of" />
            <token id="15" string="population" />
          </tokens>
        </chunking>
        <chunking id="21" string="those states" type="NP">
          <tokens>
            <token id="23" string="those" />
            <token id="24" string="states" />
          </tokens>
        </chunking>
        <chunking id="22" string="to cope with the added problems" type="VP">
          <tokens>
            <token id="30" string="to" />
            <token id="31" string="cope" />
            <token id="32" string="with" />
            <token id="33" string="the" />
            <token id="34" string="added" />
            <token id="35" string="problems" />
          </tokens>
        </chunking>
        <chunking id="23" string="adding that those states should receive additional federal aid to cope with the added problems" type="VP">
          <tokens>
            <token id="21" string="adding" />
            <token id="22" string="that" />
            <token id="23" string="those" />
            <token id="24" string="states" />
            <token id="25" string="should" />
            <token id="26" string="receive" />
            <token id="27" string="additional" />
            <token id="28" string="federal" />
            <token id="29" string="aid" />
            <token id="30" string="to" />
            <token id="31" string="cope" />
            <token id="32" string="with" />
            <token id="33" string="the" />
            <token id="34" string="added" />
            <token id="35" string="problems" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="3">are</governor>
          <dependent id="2">There</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">said</governor>
          <dependent id="3">are</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">costs</governor>
          <dependent id="4">enormous</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">costs</governor>
          <dependent id="5">additional</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">are</governor>
          <dependent id="6">costs</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">states</governor>
          <dependent id="7">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">costs</governor>
          <dependent id="8">states</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">had</governor>
          <dependent id="9">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">had</governor>
          <dependent id="10">have</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="8">states</governor>
          <dependent id="11">had</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">surge</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">had</governor>
          <dependent id="13">surge</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">population</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">surge</governor>
          <dependent id="15">population</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">said</governor>
          <dependent id="18">Wilson</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="19">said</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="19">said</governor>
          <dependent id="21">adding</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="26">receive</governor>
          <dependent id="22">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">states</governor>
          <dependent id="23">those</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">receive</governor>
          <dependent id="24">states</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="26">receive</governor>
          <dependent id="25">should</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="21">adding</governor>
          <dependent id="26">receive</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">aid</governor>
          <dependent id="27">additional</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">aid</governor>
          <dependent id="28">federal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="26">receive</governor>
          <dependent id="29">aid</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="31">cope</governor>
          <dependent id="30">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="26">receive</governor>
          <dependent id="31">cope</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">problems</governor>
          <dependent id="32">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">problems</governor>
          <dependent id="33">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="35">problems</governor>
          <dependent id="34">added</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">cope</governor>
          <dependent id="35">problems</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Wilson" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Wilson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="30" has_coreference="true">
      <content>The Senate&amp;apost;s action would also have an impact on smaller California cities without substantial Latino populations because census population figures play an important role in Community Development Block Grant formulas, said Don Vestal, Westminster city planner.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="Senate" lemma="Senate" stem="senat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="3" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="action" lemma="action" stem="action" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="impact" lemma="impact" stem="impact" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="smaller" lemma="smaller" stem="smaller" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="California" lemma="California" stem="california" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="13" string="cities" lemma="city" stem="citi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="without" lemma="without" stem="without" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="substantial" lemma="substantial" stem="substanti" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="Latino" lemma="latino" stem="latino" pos="NN" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="17" string="populations" lemma="population" stem="popul" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="census" lemma="census" stem="censu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="population" lemma="population" stem="popul" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="figures" lemma="figure" stem="figur" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="play" lemma="play" stem="plai" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="important" lemma="important" stem="import" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="role" lemma="role" stem="role" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="Community" lemma="Community" stem="commun" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="Development" lemma="Development" stem="develop" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="Block" lemma="Block" stem="block" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="Grant" lemma="Grant" stem="grant" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="formulas" lemma="formula" stem="formula" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="Don" lemma="Don" stem="don" pos="NNP" type="Word" isStopWord="true" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="35" string="Vestal" lemma="Vestal" stem="vestal" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="36" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="Westminster" lemma="Westminster" stem="westminst" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="city" lemma="city" stem="citi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="planner" lemma="planner" stem="planner" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (S (NP (NP (DT The) (NNP Senate) (POS 's)) (NN action)) (VP (MD would) (ADVP (RB also)) (VP (VB have) (NP (DT an) (NN impact)) (PP (IN on) (NP (NP (JJR smaller) (NNP California) (NNS cities)) (PP (IN without) (NP (JJ substantial) (NN Latino) (NNS populations))))) (SBAR (IN because) (S (NP (NN census) (NN population) (NNS figures)) (VP (VBP play) (NP (NP (DT an) (JJ important) (NN role)) (PP (IN in) (NP (NNP Community) (NNP Development) (NNP Block) (NNP Grant) (NNS formulas)))))))))) (, ,) (VP (VBD said)) (NP (NP (NNP Don) (NNP Vestal)) (, ,) (NP (NNP Westminster) (NN city) (NN planner))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="an important role in Community Development Block Grant formulas" type="NP">
          <tokens>
            <token id="23" string="an" />
            <token id="24" string="important" />
            <token id="25" string="role" />
            <token id="26" string="in" />
            <token id="27" string="Community" />
            <token id="28" string="Development" />
            <token id="29" string="Block" />
            <token id="30" string="Grant" />
            <token id="31" string="formulas" />
          </tokens>
        </chunking>
        <chunking id="2" string="substantial Latino populations" type="NP">
          <tokens>
            <token id="15" string="substantial" />
            <token id="16" string="Latino" />
            <token id="17" string="populations" />
          </tokens>
        </chunking>
        <chunking id="3" string="Community Development Block Grant formulas" type="NP">
          <tokens>
            <token id="27" string="Community" />
            <token id="28" string="Development" />
            <token id="29" string="Block" />
            <token id="30" string="Grant" />
            <token id="31" string="formulas" />
          </tokens>
        </chunking>
        <chunking id="4" string="smaller California cities" type="NP">
          <tokens>
            <token id="11" string="smaller" />
            <token id="12" string="California" />
            <token id="13" string="cities" />
          </tokens>
        </chunking>
        <chunking id="5" string="because census population figures play an important role in Community Development Block Grant formulas" type="SBAR">
          <tokens>
            <token id="18" string="because" />
            <token id="19" string="census" />
            <token id="20" string="population" />
            <token id="21" string="figures" />
            <token id="22" string="play" />
            <token id="23" string="an" />
            <token id="24" string="important" />
            <token id="25" string="role" />
            <token id="26" string="in" />
            <token id="27" string="Community" />
            <token id="28" string="Development" />
            <token id="29" string="Block" />
            <token id="30" string="Grant" />
            <token id="31" string="formulas" />
          </tokens>
        </chunking>
        <chunking id="6" string="Don Vestal , Westminster city planner" type="NP">
          <tokens>
            <token id="34" string="Don" />
            <token id="35" string="Vestal" />
            <token id="36" string="," />
            <token id="37" string="Westminster" />
            <token id="38" string="city" />
            <token id="39" string="planner" />
          </tokens>
        </chunking>
        <chunking id="7" string="Don Vestal" type="NP">
          <tokens>
            <token id="34" string="Don" />
            <token id="35" string="Vestal" />
          </tokens>
        </chunking>
        <chunking id="8" string="census population figures" type="NP">
          <tokens>
            <token id="19" string="census" />
            <token id="20" string="population" />
            <token id="21" string="figures" />
          </tokens>
        </chunking>
        <chunking id="9" string="Westminster city planner" type="NP">
          <tokens>
            <token id="37" string="Westminster" />
            <token id="38" string="city" />
            <token id="39" string="planner" />
          </tokens>
        </chunking>
        <chunking id="10" string="an impact" type="NP">
          <tokens>
            <token id="8" string="an" />
            <token id="9" string="impact" />
          </tokens>
        </chunking>
        <chunking id="11" string="The Senate 's action" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Senate" />
            <token id="3" string="'s" />
            <token id="4" string="action" />
          </tokens>
        </chunking>
        <chunking id="12" string="would also have an impact on smaller California cities without substantial Latino populations because census population figures play an important role in Community Development Block Grant formulas" type="VP">
          <tokens>
            <token id="5" string="would" />
            <token id="6" string="also" />
            <token id="7" string="have" />
            <token id="8" string="an" />
            <token id="9" string="impact" />
            <token id="10" string="on" />
            <token id="11" string="smaller" />
            <token id="12" string="California" />
            <token id="13" string="cities" />
            <token id="14" string="without" />
            <token id="15" string="substantial" />
            <token id="16" string="Latino" />
            <token id="17" string="populations" />
            <token id="18" string="because" />
            <token id="19" string="census" />
            <token id="20" string="population" />
            <token id="21" string="figures" />
            <token id="22" string="play" />
            <token id="23" string="an" />
            <token id="24" string="important" />
            <token id="25" string="role" />
            <token id="26" string="in" />
            <token id="27" string="Community" />
            <token id="28" string="Development" />
            <token id="29" string="Block" />
            <token id="30" string="Grant" />
            <token id="31" string="formulas" />
          </tokens>
        </chunking>
        <chunking id="13" string="play an important role in Community Development Block Grant formulas" type="VP">
          <tokens>
            <token id="22" string="play" />
            <token id="23" string="an" />
            <token id="24" string="important" />
            <token id="25" string="role" />
            <token id="26" string="in" />
            <token id="27" string="Community" />
            <token id="28" string="Development" />
            <token id="29" string="Block" />
            <token id="30" string="Grant" />
            <token id="31" string="formulas" />
          </tokens>
        </chunking>
        <chunking id="14" string="smaller California cities without substantial Latino populations" type="NP">
          <tokens>
            <token id="11" string="smaller" />
            <token id="12" string="California" />
            <token id="13" string="cities" />
            <token id="14" string="without" />
            <token id="15" string="substantial" />
            <token id="16" string="Latino" />
            <token id="17" string="populations" />
          </tokens>
        </chunking>
        <chunking id="15" string="The Senate 's" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Senate" />
            <token id="3" string="'s" />
          </tokens>
        </chunking>
        <chunking id="16" string="an important role" type="NP">
          <tokens>
            <token id="23" string="an" />
            <token id="24" string="important" />
            <token id="25" string="role" />
          </tokens>
        </chunking>
        <chunking id="17" string="said" type="VP">
          <tokens>
            <token id="33" string="said" />
          </tokens>
        </chunking>
        <chunking id="18" string="have an impact on smaller California cities without substantial Latino populations because census population figures play an important role in Community Development Block Grant formulas" type="VP">
          <tokens>
            <token id="7" string="have" />
            <token id="8" string="an" />
            <token id="9" string="impact" />
            <token id="10" string="on" />
            <token id="11" string="smaller" />
            <token id="12" string="California" />
            <token id="13" string="cities" />
            <token id="14" string="without" />
            <token id="15" string="substantial" />
            <token id="16" string="Latino" />
            <token id="17" string="populations" />
            <token id="18" string="because" />
            <token id="19" string="census" />
            <token id="20" string="population" />
            <token id="21" string="figures" />
            <token id="22" string="play" />
            <token id="23" string="an" />
            <token id="24" string="important" />
            <token id="25" string="role" />
            <token id="26" string="in" />
            <token id="27" string="Community" />
            <token id="28" string="Development" />
            <token id="29" string="Block" />
            <token id="30" string="Grant" />
            <token id="31" string="formulas" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">Senate</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">action</governor>
          <dependent id="2">Senate</dependent>
        </dependency>
        <dependency type="case">
          <governor id="2">Senate</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">have</governor>
          <dependent id="4">action</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">have</governor>
          <dependent id="5">would</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">have</governor>
          <dependent id="6">also</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="33">said</governor>
          <dependent id="7">have</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">impact</governor>
          <dependent id="8">an</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">have</governor>
          <dependent id="9">impact</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">cities</governor>
          <dependent id="10">on</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">cities</governor>
          <dependent id="11">smaller</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">cities</governor>
          <dependent id="12">California</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">have</governor>
          <dependent id="13">cities</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">populations</governor>
          <dependent id="14">without</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">populations</governor>
          <dependent id="15">substantial</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">populations</governor>
          <dependent id="16">Latino</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">cities</governor>
          <dependent id="17">populations</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">play</governor>
          <dependent id="18">because</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">figures</governor>
          <dependent id="19">census</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">figures</governor>
          <dependent id="20">population</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">play</governor>
          <dependent id="21">figures</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">have</governor>
          <dependent id="22">play</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">role</governor>
          <dependent id="23">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">role</governor>
          <dependent id="24">important</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">play</governor>
          <dependent id="25">role</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">formulas</governor>
          <dependent id="26">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">formulas</governor>
          <dependent id="27">Community</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">formulas</governor>
          <dependent id="28">Development</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">formulas</governor>
          <dependent id="29">Block</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">formulas</governor>
          <dependent id="30">Grant</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">role</governor>
          <dependent id="31">formulas</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="33">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">Vestal</governor>
          <dependent id="34">Don</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="33">said</governor>
          <dependent id="35">Vestal</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="39">planner</governor>
          <dependent id="37">Westminster</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="39">planner</governor>
          <dependent id="38">city</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="35">Vestal</governor>
          <dependent id="39">planner</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Senate" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="2" string="Senate" />
          </tokens>
        </entity>
        <entity id="2" string="California" type="LOCATION" score="0.0">
          <tokens>
            <token id="12" string="California" />
          </tokens>
        </entity>
        <entity id="3" string="Latino" type="MISC" score="0.0">
          <tokens>
            <token id="16" string="Latino" />
          </tokens>
        </entity>
        <entity id="4" string="Don Vestal" type="PERSON" score="0.0">
          <tokens>
            <token id="34" string="Don" />
            <token id="35" string="Vestal" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="31" has_coreference="true">
      <content>Westminster is following a recommendation by the Census Bureau to form a Complete Count Committee of officials and community leaders to help ensure cooperation from all city residents.</content>
      <tokens>
        <token id="1" string="Westminster" lemma="Westminster" stem="westminst" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="following" lemma="follow" stem="follow" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="recommendation" lemma="recommendation" stem="recommend" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Census" lemma="Census" stem="censu" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="9" string="Bureau" lemma="Bureau" stem="bureau" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="form" lemma="form" stem="form" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Complete" lemma="complete" stem="complet" pos="JJ" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="14" string="Count" lemma="Count" stem="count" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="15" string="Committee" lemma="Committee" stem="committe" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="officials" lemma="official" stem="offici" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="community" lemma="community" stem="commun" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="leaders" lemma="leader" stem="leader" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="help" lemma="help" stem="help" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="ensure" lemma="ensure" stem="ensur" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="cooperation" lemma="cooperation" stem="cooper" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="city" lemma="city" stem="citi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="residents" lemma="resident" stem="resid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Westminster)) (VP (VBZ is) (VP (VBG following) (NP (DT a) (NN recommendation)) (PP (IN by) (NP (DT the) (NNP Census) (NNP Bureau))) (S (VP (TO to) (VP (VB form) (NP (NP (DT a) (JJ Complete) (NNP Count) (NNP Committee)) (PP (IN of) (NP (NNS officials) (CC and) (NN community) (NNS leaders)))) (S (VP (TO to) (VP (VB help) (VP (VB ensure) (NP (NN cooperation)) (PP (IN from) (NP (DT all) (NN city) (NNS residents)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Westminster" type="NP">
          <tokens>
            <token id="1" string="Westminster" />
          </tokens>
        </chunking>
        <chunking id="2" string="all city residents" type="NP">
          <tokens>
            <token id="26" string="all" />
            <token id="27" string="city" />
            <token id="28" string="residents" />
          </tokens>
        </chunking>
        <chunking id="3" string="following a recommendation by the Census Bureau to form a Complete Count Committee of officials and community leaders to help ensure cooperation from all city residents" type="VP">
          <tokens>
            <token id="3" string="following" />
            <token id="4" string="a" />
            <token id="5" string="recommendation" />
            <token id="6" string="by" />
            <token id="7" string="the" />
            <token id="8" string="Census" />
            <token id="9" string="Bureau" />
            <token id="10" string="to" />
            <token id="11" string="form" />
            <token id="12" string="a" />
            <token id="13" string="Complete" />
            <token id="14" string="Count" />
            <token id="15" string="Committee" />
            <token id="16" string="of" />
            <token id="17" string="officials" />
            <token id="18" string="and" />
            <token id="19" string="community" />
            <token id="20" string="leaders" />
            <token id="21" string="to" />
            <token id="22" string="help" />
            <token id="23" string="ensure" />
            <token id="24" string="cooperation" />
            <token id="25" string="from" />
            <token id="26" string="all" />
            <token id="27" string="city" />
            <token id="28" string="residents" />
          </tokens>
        </chunking>
        <chunking id="4" string="the Census Bureau" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="Census" />
            <token id="9" string="Bureau" />
          </tokens>
        </chunking>
        <chunking id="5" string="to form a Complete Count Committee of officials and community leaders to help ensure cooperation from all city residents" type="VP">
          <tokens>
            <token id="10" string="to" />
            <token id="11" string="form" />
            <token id="12" string="a" />
            <token id="13" string="Complete" />
            <token id="14" string="Count" />
            <token id="15" string="Committee" />
            <token id="16" string="of" />
            <token id="17" string="officials" />
            <token id="18" string="and" />
            <token id="19" string="community" />
            <token id="20" string="leaders" />
            <token id="21" string="to" />
            <token id="22" string="help" />
            <token id="23" string="ensure" />
            <token id="24" string="cooperation" />
            <token id="25" string="from" />
            <token id="26" string="all" />
            <token id="27" string="city" />
            <token id="28" string="residents" />
          </tokens>
        </chunking>
        <chunking id="6" string="ensure cooperation from all city residents" type="VP">
          <tokens>
            <token id="23" string="ensure" />
            <token id="24" string="cooperation" />
            <token id="25" string="from" />
            <token id="26" string="all" />
            <token id="27" string="city" />
            <token id="28" string="residents" />
          </tokens>
        </chunking>
        <chunking id="7" string="officials and community leaders" type="NP">
          <tokens>
            <token id="17" string="officials" />
            <token id="18" string="and" />
            <token id="19" string="community" />
            <token id="20" string="leaders" />
          </tokens>
        </chunking>
        <chunking id="8" string="help ensure cooperation from all city residents" type="VP">
          <tokens>
            <token id="22" string="help" />
            <token id="23" string="ensure" />
            <token id="24" string="cooperation" />
            <token id="25" string="from" />
            <token id="26" string="all" />
            <token id="27" string="city" />
            <token id="28" string="residents" />
          </tokens>
        </chunking>
        <chunking id="9" string="form a Complete Count Committee of officials and community leaders to help ensure cooperation from all city residents" type="VP">
          <tokens>
            <token id="11" string="form" />
            <token id="12" string="a" />
            <token id="13" string="Complete" />
            <token id="14" string="Count" />
            <token id="15" string="Committee" />
            <token id="16" string="of" />
            <token id="17" string="officials" />
            <token id="18" string="and" />
            <token id="19" string="community" />
            <token id="20" string="leaders" />
            <token id="21" string="to" />
            <token id="22" string="help" />
            <token id="23" string="ensure" />
            <token id="24" string="cooperation" />
            <token id="25" string="from" />
            <token id="26" string="all" />
            <token id="27" string="city" />
            <token id="28" string="residents" />
          </tokens>
        </chunking>
        <chunking id="10" string="to help ensure cooperation from all city residents" type="VP">
          <tokens>
            <token id="21" string="to" />
            <token id="22" string="help" />
            <token id="23" string="ensure" />
            <token id="24" string="cooperation" />
            <token id="25" string="from" />
            <token id="26" string="all" />
            <token id="27" string="city" />
            <token id="28" string="residents" />
          </tokens>
        </chunking>
        <chunking id="11" string="a Complete Count Committee" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="Complete" />
            <token id="14" string="Count" />
            <token id="15" string="Committee" />
          </tokens>
        </chunking>
        <chunking id="12" string="a recommendation" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="recommendation" />
          </tokens>
        </chunking>
        <chunking id="13" string="a Complete Count Committee of officials and community leaders" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="Complete" />
            <token id="14" string="Count" />
            <token id="15" string="Committee" />
            <token id="16" string="of" />
            <token id="17" string="officials" />
            <token id="18" string="and" />
            <token id="19" string="community" />
            <token id="20" string="leaders" />
          </tokens>
        </chunking>
        <chunking id="14" string="is following a recommendation by the Census Bureau to form a Complete Count Committee of officials and community leaders to help ensure cooperation from all city residents" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="following" />
            <token id="4" string="a" />
            <token id="5" string="recommendation" />
            <token id="6" string="by" />
            <token id="7" string="the" />
            <token id="8" string="Census" />
            <token id="9" string="Bureau" />
            <token id="10" string="to" />
            <token id="11" string="form" />
            <token id="12" string="a" />
            <token id="13" string="Complete" />
            <token id="14" string="Count" />
            <token id="15" string="Committee" />
            <token id="16" string="of" />
            <token id="17" string="officials" />
            <token id="18" string="and" />
            <token id="19" string="community" />
            <token id="20" string="leaders" />
            <token id="21" string="to" />
            <token id="22" string="help" />
            <token id="23" string="ensure" />
            <token id="24" string="cooperation" />
            <token id="25" string="from" />
            <token id="26" string="all" />
            <token id="27" string="city" />
            <token id="28" string="residents" />
          </tokens>
        </chunking>
        <chunking id="15" string="cooperation" type="NP">
          <tokens>
            <token id="24" string="cooperation" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">following</governor>
          <dependent id="1">Westminster</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">following</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">following</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">recommendation</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">following</governor>
          <dependent id="5">recommendation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Bureau</governor>
          <dependent id="6">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">Bureau</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Bureau</governor>
          <dependent id="8">Census</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">following</governor>
          <dependent id="9">Bureau</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">form</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">following</governor>
          <dependent id="11">form</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">Committee</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">Committee</governor>
          <dependent id="13">Complete</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Committee</governor>
          <dependent id="14">Count</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">form</governor>
          <dependent id="15">Committee</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">officials</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">Committee</governor>
          <dependent id="17">officials</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">officials</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">leaders</governor>
          <dependent id="19">community</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">officials</governor>
          <dependent id="20">leaders</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">help</governor>
          <dependent id="21">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">form</governor>
          <dependent id="22">help</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="22">help</governor>
          <dependent id="23">ensure</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">ensure</governor>
          <dependent id="24">cooperation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">residents</governor>
          <dependent id="25">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">residents</governor>
          <dependent id="26">all</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">residents</governor>
          <dependent id="27">city</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">ensure</governor>
          <dependent id="28">residents</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Complete Count Committee" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="13" string="Complete" />
            <token id="14" string="Count" />
            <token id="15" string="Committee" />
          </tokens>
        </entity>
        <entity id="2" string="Census Bureau" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="8" string="Census" />
            <token id="9" string="Bureau" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="32" has_coreference="true">
      <content>&amp;quot;We feel that it&amp;apost;s in our best interest to get as complete a count as we can,&amp;quot; he said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="feel" lemma="feel" stem="feel" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="our" lemma="we" stem="our" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="best" lemma="best" stem="best" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="interest" lemma="interest" stem="interest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="get" lemma="get" stem="get" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="complete" lemma="complete" stem="complet" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="count" lemma="count" stem="count" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP We)) (VP (VBP feel) (SBAR (IN that) (S (NP (PRP it)) (VP (VBZ 's) (PP (IN in) (NP (PRP$ our) (JJS best) (NN interest))) (S (VP (TO to) (VP (VB get) (PP (IN as) (NP (JJ complete) (DT a) (NN count))) (SBAR (IN as) (S (NP (PRP we)) (VP (MD can)))))))))))) (, ,) ('' '') (NP (PRP he)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="our best interest" type="NP">
          <tokens>
            <token id="8" string="our" />
            <token id="9" string="best" />
            <token id="10" string="interest" />
          </tokens>
        </chunking>
        <chunking id="2" string="feel that it 's in our best interest to get as complete a count as we can" type="VP">
          <tokens>
            <token id="3" string="feel" />
            <token id="4" string="that" />
            <token id="5" string="it" />
            <token id="6" string="'s" />
            <token id="7" string="in" />
            <token id="8" string="our" />
            <token id="9" string="best" />
            <token id="10" string="interest" />
            <token id="11" string="to" />
            <token id="12" string="get" />
            <token id="13" string="as" />
            <token id="14" string="complete" />
            <token id="15" string="a" />
            <token id="16" string="count" />
            <token id="17" string="as" />
            <token id="18" string="we" />
            <token id="19" string="can" />
          </tokens>
        </chunking>
        <chunking id="3" string="as we can" type="SBAR">
          <tokens>
            <token id="17" string="as" />
            <token id="18" string="we" />
            <token id="19" string="can" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="5" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="We" type="NP">
          <tokens>
            <token id="2" string="We" />
          </tokens>
        </chunking>
        <chunking id="6" string="complete a count" type="NP">
          <tokens>
            <token id="14" string="complete" />
            <token id="15" string="a" />
            <token id="16" string="count" />
          </tokens>
        </chunking>
        <chunking id="7" string="we" type="NP">
          <tokens>
            <token id="18" string="we" />
          </tokens>
        </chunking>
        <chunking id="8" string="can" type="VP">
          <tokens>
            <token id="19" string="can" />
          </tokens>
        </chunking>
        <chunking id="9" string="that it 's in our best interest to get as complete a count as we can" type="SBAR">
          <tokens>
            <token id="4" string="that" />
            <token id="5" string="it" />
            <token id="6" string="'s" />
            <token id="7" string="in" />
            <token id="8" string="our" />
            <token id="9" string="best" />
            <token id="10" string="interest" />
            <token id="11" string="to" />
            <token id="12" string="get" />
            <token id="13" string="as" />
            <token id="14" string="complete" />
            <token id="15" string="a" />
            <token id="16" string="count" />
            <token id="17" string="as" />
            <token id="18" string="we" />
            <token id="19" string="can" />
          </tokens>
        </chunking>
        <chunking id="10" string="'s in our best interest to get as complete a count as we can" type="VP">
          <tokens>
            <token id="6" string="'s" />
            <token id="7" string="in" />
            <token id="8" string="our" />
            <token id="9" string="best" />
            <token id="10" string="interest" />
            <token id="11" string="to" />
            <token id="12" string="get" />
            <token id="13" string="as" />
            <token id="14" string="complete" />
            <token id="15" string="a" />
            <token id="16" string="count" />
            <token id="17" string="as" />
            <token id="18" string="we" />
            <token id="19" string="can" />
          </tokens>
        </chunking>
        <chunking id="11" string="get as complete a count as we can" type="VP">
          <tokens>
            <token id="12" string="get" />
            <token id="13" string="as" />
            <token id="14" string="complete" />
            <token id="15" string="a" />
            <token id="16" string="count" />
            <token id="17" string="as" />
            <token id="18" string="we" />
            <token id="19" string="can" />
          </tokens>
        </chunking>
        <chunking id="12" string="to get as complete a count as we can" type="VP">
          <tokens>
            <token id="11" string="to" />
            <token id="12" string="get" />
            <token id="13" string="as" />
            <token id="14" string="complete" />
            <token id="15" string="a" />
            <token id="16" string="count" />
            <token id="17" string="as" />
            <token id="18" string="we" />
            <token id="19" string="can" />
          </tokens>
        </chunking>
        <chunking id="13" string="he" type="NP">
          <tokens>
            <token id="22" string="he" />
          </tokens>
        </chunking>
        <chunking id="14" string="said" type="VP">
          <tokens>
            <token id="23" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">feel</governor>
          <dependent id="2">We</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="23">said</governor>
          <dependent id="3">feel</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">interest</governor>
          <dependent id="4">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">interest</governor>
          <dependent id="5">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="10">interest</governor>
          <dependent id="6">'s</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">interest</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">interest</governor>
          <dependent id="8">our</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">interest</governor>
          <dependent id="9">best</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">feel</governor>
          <dependent id="10">interest</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">get</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="10">interest</governor>
          <dependent id="12">get</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">count</governor>
          <dependent id="13">as</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">count</governor>
          <dependent id="14">complete</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">count</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">get</governor>
          <dependent id="16">count</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">can</governor>
          <dependent id="17">as</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">can</governor>
          <dependent id="18">we</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">get</governor>
          <dependent id="19">can</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">said</governor>
          <dependent id="22">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="23">said</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="33" has_coreference="true">
      <content>The Community Development Block Grant formula, among other things, Vestal said, includes use of income figures and percentage of lower income residents in the city.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Community" lemma="Community" stem="commun" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Development" lemma="Development" stem="develop" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="Block" lemma="Block" stem="block" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="Grant" lemma="Grant" stem="grant" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="formula" lemma="formula" stem="formula" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="among" lemma="among" stem="among" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="things" lemma="thing" stem="thing" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Vestal" lemma="Vestal" stem="vestal" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="13" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="includes" lemma="include" stem="includ" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="use" lemma="use" stem="us" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="income" lemma="income" stem="incom" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="figures" lemma="figure" stem="figur" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="percentage" lemma="percentage" stem="percentag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="lower" lemma="lower" stem="lower" pos="JJR" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="income" lemma="income" stem="incom" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="residents" lemma="resident" stem="resid" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="27" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="28" string="city" lemma="city" stem="citi" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNP Community) (NNP Development) (NNP Block) (NNP Grant) (NN formula)) (PRN (, ,) (S (PP (IN among) (NP (JJ other) (NNS things))) (, ,) (NP (NNP Vestal)) (VP (VBD said))) (, ,)) (VP (VBZ includes) (NP (NP (NP (NN use)) (PP (IN of) (NP (NN income) (NNS figures)))) (CC and) (NP (NP (NN percentage)) (PP (IN of) (NP (NP (JJR lower) (NN income) (NNS residents)) (PP (IN in) (NP (DT the) (NN city)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="income figures" type="NP">
          <tokens>
            <token id="18" string="income" />
            <token id="19" string="figures" />
          </tokens>
        </chunking>
        <chunking id="2" string="the city" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="city" />
          </tokens>
        </chunking>
        <chunking id="3" string="use" type="NP">
          <tokens>
            <token id="16" string="use" />
          </tokens>
        </chunking>
        <chunking id="4" string="percentage of lower income residents in the city" type="NP">
          <tokens>
            <token id="21" string="percentage" />
            <token id="22" string="of" />
            <token id="23" string="lower" />
            <token id="24" string="income" />
            <token id="25" string="residents" />
            <token id="26" string="in" />
            <token id="27" string="the" />
            <token id="28" string="city" />
          </tokens>
        </chunking>
        <chunking id="5" string="lower income residents in the city" type="NP">
          <tokens>
            <token id="23" string="lower" />
            <token id="24" string="income" />
            <token id="25" string="residents" />
            <token id="26" string="in" />
            <token id="27" string="the" />
            <token id="28" string="city" />
          </tokens>
        </chunking>
        <chunking id="6" string="use of income figures and percentage of lower income residents in the city" type="NP">
          <tokens>
            <token id="16" string="use" />
            <token id="17" string="of" />
            <token id="18" string="income" />
            <token id="19" string="figures" />
            <token id="20" string="and" />
            <token id="21" string="percentage" />
            <token id="22" string="of" />
            <token id="23" string="lower" />
            <token id="24" string="income" />
            <token id="25" string="residents" />
            <token id="26" string="in" />
            <token id="27" string="the" />
            <token id="28" string="city" />
          </tokens>
        </chunking>
        <chunking id="7" string="other things" type="NP">
          <tokens>
            <token id="9" string="other" />
            <token id="10" string="things" />
          </tokens>
        </chunking>
        <chunking id="8" string="lower income residents" type="NP">
          <tokens>
            <token id="23" string="lower" />
            <token id="24" string="income" />
            <token id="25" string="residents" />
          </tokens>
        </chunking>
        <chunking id="9" string="percentage" type="NP">
          <tokens>
            <token id="21" string="percentage" />
          </tokens>
        </chunking>
        <chunking id="10" string="includes use of income figures and percentage of lower income residents in the city" type="VP">
          <tokens>
            <token id="15" string="includes" />
            <token id="16" string="use" />
            <token id="17" string="of" />
            <token id="18" string="income" />
            <token id="19" string="figures" />
            <token id="20" string="and" />
            <token id="21" string="percentage" />
            <token id="22" string="of" />
            <token id="23" string="lower" />
            <token id="24" string="income" />
            <token id="25" string="residents" />
            <token id="26" string="in" />
            <token id="27" string="the" />
            <token id="28" string="city" />
          </tokens>
        </chunking>
        <chunking id="11" string="The Community Development Block Grant formula" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Community" />
            <token id="3" string="Development" />
            <token id="4" string="Block" />
            <token id="5" string="Grant" />
            <token id="6" string="formula" />
          </tokens>
        </chunking>
        <chunking id="12" string="Vestal" type="NP">
          <tokens>
            <token id="12" string="Vestal" />
          </tokens>
        </chunking>
        <chunking id="13" string="said" type="VP">
          <tokens>
            <token id="13" string="said" />
          </tokens>
        </chunking>
        <chunking id="14" string="use of income figures" type="NP">
          <tokens>
            <token id="16" string="use" />
            <token id="17" string="of" />
            <token id="18" string="income" />
            <token id="19" string="figures" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="6">formula</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">formula</governor>
          <dependent id="2">Community</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">formula</governor>
          <dependent id="3">Development</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">formula</governor>
          <dependent id="4">Block</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">formula</governor>
          <dependent id="5">Grant</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">includes</governor>
          <dependent id="6">formula</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">things</governor>
          <dependent id="8">among</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">things</governor>
          <dependent id="9">other</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">said</governor>
          <dependent id="10">things</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">said</governor>
          <dependent id="12">Vestal</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="15">includes</governor>
          <dependent id="13">said</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">includes</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">includes</governor>
          <dependent id="16">use</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">figures</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">figures</governor>
          <dependent id="18">income</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">use</governor>
          <dependent id="19">figures</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">use</governor>
          <dependent id="20">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">use</governor>
          <dependent id="21">percentage</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">residents</governor>
          <dependent id="22">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">residents</governor>
          <dependent id="23">lower</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">residents</governor>
          <dependent id="24">income</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">percentage</governor>
          <dependent id="25">residents</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">city</governor>
          <dependent id="26">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">city</governor>
          <dependent id="27">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">residents</governor>
          <dependent id="28">city</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Vestal" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Vestal" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="34" has_coreference="true">
      <content>&amp;quot;In addition to just counting heads, they&amp;apost;re getting economic information of the city that will affect us in the future,&amp;quot; he added.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="addition" lemma="addition" stem="addit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="counting" lemma="count" stem="count" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="heads" lemma="head" stem="head" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="'re" lemma="be" stem="'re" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="getting" lemma="get" stem="get" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="economic" lemma="economic" stem="econom" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="information" lemma="information" stem="inform" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="city" lemma="city" stem="citi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="affect" lemma="affect" stem="affect" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="us" lemma="we" stem="u" pos="PRP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="23" string="future" lemma="future" stem="futur" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="added" lemma="add" stem="ad" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (PP (IN In) (NP (NP (NN addition)) (PP (TO to) (S (VP (ADVP (RB just)) (VBG counting) (NP (NNS heads))))))) (, ,) (NP (PRP they)) (VP (VBP 're) (VP (VBG getting) (NP (NP (JJ economic) (NN information)) (PP (IN of) (NP (NP (DT the) (NN city)) (SBAR (WHNP (WDT that)) (S (VP (MD will) (VP (VB affect) (NP (PRP us)) (PP (IN in) (NP (DT the) (NN future))))))))))))) (, ,) ('' '') (NP (PRP he)) (VP (VBD added)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the city" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="city" />
          </tokens>
        </chunking>
        <chunking id="2" string="economic information of the city that will affect us in the future" type="NP">
          <tokens>
            <token id="12" string="economic" />
            <token id="13" string="information" />
            <token id="14" string="of" />
            <token id="15" string="the" />
            <token id="16" string="city" />
            <token id="17" string="that" />
            <token id="18" string="will" />
            <token id="19" string="affect" />
            <token id="20" string="us" />
            <token id="21" string="in" />
            <token id="22" string="the" />
            <token id="23" string="future" />
          </tokens>
        </chunking>
        <chunking id="3" string="affect us in the future" type="VP">
          <tokens>
            <token id="19" string="affect" />
            <token id="20" string="us" />
            <token id="21" string="in" />
            <token id="22" string="the" />
            <token id="23" string="future" />
          </tokens>
        </chunking>
        <chunking id="4" string="just counting heads" type="VP">
          <tokens>
            <token id="5" string="just" />
            <token id="6" string="counting" />
            <token id="7" string="heads" />
          </tokens>
        </chunking>
        <chunking id="5" string="will affect us in the future" type="VP">
          <tokens>
            <token id="18" string="will" />
            <token id="19" string="affect" />
            <token id="20" string="us" />
            <token id="21" string="in" />
            <token id="22" string="the" />
            <token id="23" string="future" />
          </tokens>
        </chunking>
        <chunking id="6" string="they" type="NP">
          <tokens>
            <token id="9" string="they" />
          </tokens>
        </chunking>
        <chunking id="7" string="the city that will affect us in the future" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="city" />
            <token id="17" string="that" />
            <token id="18" string="will" />
            <token id="19" string="affect" />
            <token id="20" string="us" />
            <token id="21" string="in" />
            <token id="22" string="the" />
            <token id="23" string="future" />
          </tokens>
        </chunking>
        <chunking id="8" string="that will affect us in the future" type="SBAR">
          <tokens>
            <token id="17" string="that" />
            <token id="18" string="will" />
            <token id="19" string="affect" />
            <token id="20" string="us" />
            <token id="21" string="in" />
            <token id="22" string="the" />
            <token id="23" string="future" />
          </tokens>
        </chunking>
        <chunking id="9" string="economic information" type="NP">
          <tokens>
            <token id="12" string="economic" />
            <token id="13" string="information" />
          </tokens>
        </chunking>
        <chunking id="10" string="'re getting economic information of the city that will affect us in the future" type="VP">
          <tokens>
            <token id="10" string="'re" />
            <token id="11" string="getting" />
            <token id="12" string="economic" />
            <token id="13" string="information" />
            <token id="14" string="of" />
            <token id="15" string="the" />
            <token id="16" string="city" />
            <token id="17" string="that" />
            <token id="18" string="will" />
            <token id="19" string="affect" />
            <token id="20" string="us" />
            <token id="21" string="in" />
            <token id="22" string="the" />
            <token id="23" string="future" />
          </tokens>
        </chunking>
        <chunking id="11" string="addition" type="NP">
          <tokens>
            <token id="3" string="addition" />
          </tokens>
        </chunking>
        <chunking id="12" string="the future" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="future" />
          </tokens>
        </chunking>
        <chunking id="13" string="heads" type="NP">
          <tokens>
            <token id="7" string="heads" />
          </tokens>
        </chunking>
        <chunking id="14" string="added" type="VP">
          <tokens>
            <token id="27" string="added" />
          </tokens>
        </chunking>
        <chunking id="15" string="addition to just counting heads" type="NP">
          <tokens>
            <token id="3" string="addition" />
            <token id="4" string="to" />
            <token id="5" string="just" />
            <token id="6" string="counting" />
            <token id="7" string="heads" />
          </tokens>
        </chunking>
        <chunking id="16" string="he" type="NP">
          <tokens>
            <token id="26" string="he" />
          </tokens>
        </chunking>
        <chunking id="17" string="us" type="NP">
          <tokens>
            <token id="20" string="us" />
          </tokens>
        </chunking>
        <chunking id="18" string="getting economic information of the city that will affect us in the future" type="VP">
          <tokens>
            <token id="11" string="getting" />
            <token id="12" string="economic" />
            <token id="13" string="information" />
            <token id="14" string="of" />
            <token id="15" string="the" />
            <token id="16" string="city" />
            <token id="17" string="that" />
            <token id="18" string="will" />
            <token id="19" string="affect" />
            <token id="20" string="us" />
            <token id="21" string="in" />
            <token id="22" string="the" />
            <token id="23" string="future" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="6">counting</governor>
          <dependent id="2">In</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="2">In</governor>
          <dependent id="3">addition</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="2">In</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">counting</governor>
          <dependent id="5">just</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="11">getting</governor>
          <dependent id="6">counting</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">counting</governor>
          <dependent id="7">heads</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">getting</governor>
          <dependent id="9">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">getting</governor>
          <dependent id="10">'re</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="27">added</governor>
          <dependent id="11">getting</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">information</governor>
          <dependent id="12">economic</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">getting</governor>
          <dependent id="13">information</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">city</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">city</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">information</governor>
          <dependent id="16">city</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">affect</governor>
          <dependent id="17">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="19">affect</governor>
          <dependent id="18">will</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="16">city</governor>
          <dependent id="19">affect</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">affect</governor>
          <dependent id="20">us</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">future</governor>
          <dependent id="21">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">future</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">affect</governor>
          <dependent id="23">future</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">added</governor>
          <dependent id="26">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="27">added</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="the future" type="DATE" score="0.0">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="future" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="35" has_coreference="true">
      <content>Gloria McDonough, director of Abrazar Center, an elderly-assistance center for Latinos in Westminster, said the senators&amp;apost; action shows they have no understanding of the impact of illegal immigration to California communities.</content>
      <tokens>
        <token id="1" string="Gloria" lemma="Gloria" stem="gloria" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="McDonough" lemma="McDonough" stem="mcdonough" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="director" lemma="director" stem="director" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Abrazar" lemma="Abrazar" stem="abrazar" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="7" string="Center" lemma="Center" stem="center" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="elderly-assistance" lemma="elderly-assistance" stem="elderly-assist" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="center" lemma="center" stem="center" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Latinos" lemma="Latinos" stem="latino" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="14" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Westminster" lemma="Westminster" stem="westminst" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="senators" lemma="senator" stem="senat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="action" lemma="action" stem="action" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="shows" lemma="show" stem="show" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="understanding" lemma="understanding" stem="understand" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="impact" lemma="impact" stem="impact" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="immigration" lemma="immigration" stem="immigr" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="California" lemma="California" stem="california" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="35" string="communities" lemma="community" stem="commun" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Gloria) (NNP McDonough)) (, ,) (NP (NP (NN director)) (PP (IN of) (NP (NP (NNP Abrazar) (NNP Center)) (, ,) (NP (NP (DT an) (JJ elderly-assistance) (NN center)) (PP (IN for) (NP (NP (NNP Latinos)) (PP (IN in) (NP (NNP Westminster))))))))) (, ,)) (VP (VBD said) (SBAR (S (NP (NP (DT the) (NNS senators) (POS ')) (NN action)) (VP (VBZ shows) (SBAR (S (NP (PRP they)) (VP (VBP have) (NP (NP (DT no) (NN understanding)) (PP (IN of) (NP (NP (DT the) (NN impact)) (PP (IN of) (NP (JJ illegal) (NN immigration)))))) (PP (TO to) (NP (NNP California) (NNS communities)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="director" type="NP">
          <tokens>
            <token id="4" string="director" />
          </tokens>
        </chunking>
        <chunking id="2" string="the senators ' action" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="senators" />
            <token id="20" string="'" />
            <token id="21" string="action" />
          </tokens>
        </chunking>
        <chunking id="3" string="no understanding of the impact of illegal immigration" type="NP">
          <tokens>
            <token id="25" string="no" />
            <token id="26" string="understanding" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="impact" />
            <token id="30" string="of" />
            <token id="31" string="illegal" />
            <token id="32" string="immigration" />
          </tokens>
        </chunking>
        <chunking id="4" string="Gloria McDonough , director of Abrazar Center , an elderly-assistance center for Latinos in Westminster ," type="NP">
          <tokens>
            <token id="1" string="Gloria" />
            <token id="2" string="McDonough" />
            <token id="3" string="," />
            <token id="4" string="director" />
            <token id="5" string="of" />
            <token id="6" string="Abrazar" />
            <token id="7" string="Center" />
            <token id="8" string="," />
            <token id="9" string="an" />
            <token id="10" string="elderly-assistance" />
            <token id="11" string="center" />
            <token id="12" string="for" />
            <token id="13" string="Latinos" />
            <token id="14" string="in" />
            <token id="15" string="Westminster" />
            <token id="16" string="," />
          </tokens>
        </chunking>
        <chunking id="5" string="Gloria McDonough" type="NP">
          <tokens>
            <token id="1" string="Gloria" />
            <token id="2" string="McDonough" />
          </tokens>
        </chunking>
        <chunking id="6" string="have no understanding of the impact of illegal immigration to California communities" type="VP">
          <tokens>
            <token id="24" string="have" />
            <token id="25" string="no" />
            <token id="26" string="understanding" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="impact" />
            <token id="30" string="of" />
            <token id="31" string="illegal" />
            <token id="32" string="immigration" />
            <token id="33" string="to" />
            <token id="34" string="California" />
            <token id="35" string="communities" />
          </tokens>
        </chunking>
        <chunking id="7" string="an elderly-assistance center" type="NP">
          <tokens>
            <token id="9" string="an" />
            <token id="10" string="elderly-assistance" />
            <token id="11" string="center" />
          </tokens>
        </chunking>
        <chunking id="8" string="the impact of illegal immigration" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="impact" />
            <token id="30" string="of" />
            <token id="31" string="illegal" />
            <token id="32" string="immigration" />
          </tokens>
        </chunking>
        <chunking id="9" string="the senators '" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="senators" />
            <token id="20" string="'" />
          </tokens>
        </chunking>
        <chunking id="10" string="Latinos" type="NP">
          <tokens>
            <token id="13" string="Latinos" />
          </tokens>
        </chunking>
        <chunking id="11" string="the senators ' action shows they have no understanding of the impact of illegal immigration to California communities" type="SBAR">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="senators" />
            <token id="20" string="'" />
            <token id="21" string="action" />
            <token id="22" string="shows" />
            <token id="23" string="they" />
            <token id="24" string="have" />
            <token id="25" string="no" />
            <token id="26" string="understanding" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="impact" />
            <token id="30" string="of" />
            <token id="31" string="illegal" />
            <token id="32" string="immigration" />
            <token id="33" string="to" />
            <token id="34" string="California" />
            <token id="35" string="communities" />
          </tokens>
        </chunking>
        <chunking id="12" string="Abrazar Center" type="NP">
          <tokens>
            <token id="6" string="Abrazar" />
            <token id="7" string="Center" />
          </tokens>
        </chunking>
        <chunking id="13" string="an elderly-assistance center for Latinos in Westminster" type="NP">
          <tokens>
            <token id="9" string="an" />
            <token id="10" string="elderly-assistance" />
            <token id="11" string="center" />
            <token id="12" string="for" />
            <token id="13" string="Latinos" />
            <token id="14" string="in" />
            <token id="15" string="Westminster" />
          </tokens>
        </chunking>
        <chunking id="14" string="Westminster" type="NP">
          <tokens>
            <token id="15" string="Westminster" />
          </tokens>
        </chunking>
        <chunking id="15" string="no understanding" type="NP">
          <tokens>
            <token id="25" string="no" />
            <token id="26" string="understanding" />
          </tokens>
        </chunking>
        <chunking id="16" string="the impact" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="impact" />
          </tokens>
        </chunking>
        <chunking id="17" string="illegal immigration" type="NP">
          <tokens>
            <token id="31" string="illegal" />
            <token id="32" string="immigration" />
          </tokens>
        </chunking>
        <chunking id="18" string="director of Abrazar Center , an elderly-assistance center for Latinos in Westminster" type="NP">
          <tokens>
            <token id="4" string="director" />
            <token id="5" string="of" />
            <token id="6" string="Abrazar" />
            <token id="7" string="Center" />
            <token id="8" string="," />
            <token id="9" string="an" />
            <token id="10" string="elderly-assistance" />
            <token id="11" string="center" />
            <token id="12" string="for" />
            <token id="13" string="Latinos" />
            <token id="14" string="in" />
            <token id="15" string="Westminster" />
          </tokens>
        </chunking>
        <chunking id="19" string="Abrazar Center , an elderly-assistance center for Latinos in Westminster" type="NP">
          <tokens>
            <token id="6" string="Abrazar" />
            <token id="7" string="Center" />
            <token id="8" string="," />
            <token id="9" string="an" />
            <token id="10" string="elderly-assistance" />
            <token id="11" string="center" />
            <token id="12" string="for" />
            <token id="13" string="Latinos" />
            <token id="14" string="in" />
            <token id="15" string="Westminster" />
          </tokens>
        </chunking>
        <chunking id="20" string="said the senators ' action shows they have no understanding of the impact of illegal immigration to California communities" type="VP">
          <tokens>
            <token id="17" string="said" />
            <token id="18" string="the" />
            <token id="19" string="senators" />
            <token id="20" string="'" />
            <token id="21" string="action" />
            <token id="22" string="shows" />
            <token id="23" string="they" />
            <token id="24" string="have" />
            <token id="25" string="no" />
            <token id="26" string="understanding" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="impact" />
            <token id="30" string="of" />
            <token id="31" string="illegal" />
            <token id="32" string="immigration" />
            <token id="33" string="to" />
            <token id="34" string="California" />
            <token id="35" string="communities" />
          </tokens>
        </chunking>
        <chunking id="21" string="they" type="NP">
          <tokens>
            <token id="23" string="they" />
          </tokens>
        </chunking>
        <chunking id="22" string="they have no understanding of the impact of illegal immigration to California communities" type="SBAR">
          <tokens>
            <token id="23" string="they" />
            <token id="24" string="have" />
            <token id="25" string="no" />
            <token id="26" string="understanding" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="impact" />
            <token id="30" string="of" />
            <token id="31" string="illegal" />
            <token id="32" string="immigration" />
            <token id="33" string="to" />
            <token id="34" string="California" />
            <token id="35" string="communities" />
          </tokens>
        </chunking>
        <chunking id="23" string="California communities" type="NP">
          <tokens>
            <token id="34" string="California" />
            <token id="35" string="communities" />
          </tokens>
        </chunking>
        <chunking id="24" string="shows they have no understanding of the impact of illegal immigration to California communities" type="VP">
          <tokens>
            <token id="22" string="shows" />
            <token id="23" string="they" />
            <token id="24" string="have" />
            <token id="25" string="no" />
            <token id="26" string="understanding" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="impact" />
            <token id="30" string="of" />
            <token id="31" string="illegal" />
            <token id="32" string="immigration" />
            <token id="33" string="to" />
            <token id="34" string="California" />
            <token id="35" string="communities" />
          </tokens>
        </chunking>
        <chunking id="25" string="Latinos in Westminster" type="NP">
          <tokens>
            <token id="13" string="Latinos" />
            <token id="14" string="in" />
            <token id="15" string="Westminster" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">McDonough</governor>
          <dependent id="1">Gloria</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">said</governor>
          <dependent id="2">McDonough</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">McDonough</governor>
          <dependent id="4">director</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Center</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Center</governor>
          <dependent id="6">Abrazar</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">director</governor>
          <dependent id="7">Center</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">center</governor>
          <dependent id="9">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">center</governor>
          <dependent id="10">elderly-assistance</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="7">Center</governor>
          <dependent id="11">center</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Latinos</governor>
          <dependent id="12">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">center</governor>
          <dependent id="13">Latinos</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">Westminster</governor>
          <dependent id="14">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">Latinos</governor>
          <dependent id="15">Westminster</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">senators</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="21">action</governor>
          <dependent id="19">senators</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">senators</governor>
          <dependent id="20">'</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">shows</governor>
          <dependent id="21">action</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">said</governor>
          <dependent id="22">shows</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">have</governor>
          <dependent id="23">they</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="22">shows</governor>
          <dependent id="24">have</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="26">understanding</governor>
          <dependent id="25">no</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">have</governor>
          <dependent id="26">understanding</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">impact</governor>
          <dependent id="27">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">impact</governor>
          <dependent id="28">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">understanding</governor>
          <dependent id="29">impact</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">immigration</governor>
          <dependent id="30">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="32">immigration</governor>
          <dependent id="31">illegal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">impact</governor>
          <dependent id="32">immigration</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">communities</governor>
          <dependent id="33">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">communities</governor>
          <dependent id="34">California</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">have</governor>
          <dependent id="35">communities</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Latinos" type="MISC" score="0.0">
          <tokens>
            <token id="13" string="Latinos" />
          </tokens>
        </entity>
        <entity id="2" string="California" type="LOCATION" score="0.0">
          <tokens>
            <token id="34" string="California" />
          </tokens>
        </entity>
        <entity id="3" string="Abrazar Center" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="6" string="Abrazar" />
            <token id="7" string="Center" />
          </tokens>
        </entity>
        <entity id="4" string="Gloria McDonough" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Gloria" />
            <token id="2" string="McDonough" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="36" has_coreference="true">
      <content>&amp;quot;Whether you count them or not, the undocumented residents are still going to impact federal dollars in our community.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Whether" lemma="whether" stem="whether" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="count" lemma="count" stem="count" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="undocumented" lemma="undocumented" stem="undocu" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="residents" lemma="resident" stem="resid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="still" lemma="still" stem="still" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="impact" lemma="impact" stem="impact" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="federal" lemma="federal" stem="feder" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="dollars" lemma="dollar" stem="dollar" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="our" lemma="we" stem="our" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="community" lemma="community" stem="commun" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (SBAR (IN Whether) (S (NP (PRP you)) (VP (VBP count) (NP (NP (PRP them)) (CC or) (NP (RB not)))))) (, ,) (NP (DT the) (JJ undocumented) (NNS residents)) (VP (VBP are) (ADVP (RB still)) (VP (VBG going) (S (VP (TO to) (VP (VB impact) (NP (JJ federal) (NNS dollars)) (PP (IN in) (NP (PRP$ our) (NN community)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Whether you count them or not" type="SBAR">
          <tokens>
            <token id="2" string="Whether" />
            <token id="3" string="you" />
            <token id="4" string="count" />
            <token id="5" string="them" />
            <token id="6" string="or" />
            <token id="7" string="not" />
          </tokens>
        </chunking>
        <chunking id="2" string="them or not" type="NP">
          <tokens>
            <token id="5" string="them" />
            <token id="6" string="or" />
            <token id="7" string="not" />
          </tokens>
        </chunking>
        <chunking id="3" string="are still going to impact federal dollars in our community" type="VP">
          <tokens>
            <token id="12" string="are" />
            <token id="13" string="still" />
            <token id="14" string="going" />
            <token id="15" string="to" />
            <token id="16" string="impact" />
            <token id="17" string="federal" />
            <token id="18" string="dollars" />
            <token id="19" string="in" />
            <token id="20" string="our" />
            <token id="21" string="community" />
          </tokens>
        </chunking>
        <chunking id="4" string="going to impact federal dollars in our community" type="VP">
          <tokens>
            <token id="14" string="going" />
            <token id="15" string="to" />
            <token id="16" string="impact" />
            <token id="17" string="federal" />
            <token id="18" string="dollars" />
            <token id="19" string="in" />
            <token id="20" string="our" />
            <token id="21" string="community" />
          </tokens>
        </chunking>
        <chunking id="5" string="impact federal dollars in our community" type="VP">
          <tokens>
            <token id="16" string="impact" />
            <token id="17" string="federal" />
            <token id="18" string="dollars" />
            <token id="19" string="in" />
            <token id="20" string="our" />
            <token id="21" string="community" />
          </tokens>
        </chunking>
        <chunking id="6" string="federal dollars" type="NP">
          <tokens>
            <token id="17" string="federal" />
            <token id="18" string="dollars" />
          </tokens>
        </chunking>
        <chunking id="7" string="them" type="NP">
          <tokens>
            <token id="5" string="them" />
          </tokens>
        </chunking>
        <chunking id="8" string="not" type="NP">
          <tokens>
            <token id="7" string="not" />
          </tokens>
        </chunking>
        <chunking id="9" string="the undocumented residents" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="undocumented" />
            <token id="11" string="residents" />
          </tokens>
        </chunking>
        <chunking id="10" string="to impact federal dollars in our community" type="VP">
          <tokens>
            <token id="15" string="to" />
            <token id="16" string="impact" />
            <token id="17" string="federal" />
            <token id="18" string="dollars" />
            <token id="19" string="in" />
            <token id="20" string="our" />
            <token id="21" string="community" />
          </tokens>
        </chunking>
        <chunking id="11" string="count them or not" type="VP">
          <tokens>
            <token id="4" string="count" />
            <token id="5" string="them" />
            <token id="6" string="or" />
            <token id="7" string="not" />
          </tokens>
        </chunking>
        <chunking id="12" string="you" type="NP">
          <tokens>
            <token id="3" string="you" />
          </tokens>
        </chunking>
        <chunking id="13" string="our community" type="NP">
          <tokens>
            <token id="20" string="our" />
            <token id="21" string="community" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="4">count</governor>
          <dependent id="2">Whether</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">count</governor>
          <dependent id="3">you</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="14">going</governor>
          <dependent id="4">count</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">count</governor>
          <dependent id="5">them</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">them</governor>
          <dependent id="6">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">them</governor>
          <dependent id="7">not</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">residents</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">residents</governor>
          <dependent id="10">undocumented</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">going</governor>
          <dependent id="11">residents</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">going</governor>
          <dependent id="12">are</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">going</governor>
          <dependent id="13">still</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">going</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">impact</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="14">going</governor>
          <dependent id="16">impact</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">dollars</governor>
          <dependent id="17">federal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">impact</governor>
          <dependent id="18">dollars</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">community</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="21">community</governor>
          <dependent id="20">our</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">impact</governor>
          <dependent id="21">community</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="37" has_coreference="true">
      <content>And whether we like it or not they&amp;apost;re here and here to stay,&amp;quot; McDonough said.</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="whether" lemma="whether" stem="whether" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="like" lemma="like" stem="like" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="'re" lemma="be" stem="'re" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="here" lemma="here" stem="here" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="here" lemma="here" stem="here" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="stay" lemma="stay" stem="stai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="McDonough" lemma="McDonough" stem="mcdonough" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="18" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC And) (SBAR (IN whether) (S (S (NP (PRP we)) (VP (VBP like) (NP (PRP it)))) (CC or) (S (RB not) (NP (PRP they)) (VP (VBP 're) (ADVP (RB here) (CC and) (RB here)) (S (VP (TO to) (VP (VB stay)))))))) (, ,) ('' '') (NP (NNP McDonough)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="they" type="NP">
          <tokens>
            <token id="8" string="they" />
          </tokens>
        </chunking>
        <chunking id="2" string="whether we like it or not they 're here and here to stay" type="SBAR">
          <tokens>
            <token id="2" string="whether" />
            <token id="3" string="we" />
            <token id="4" string="like" />
            <token id="5" string="it" />
            <token id="6" string="or" />
            <token id="7" string="not" />
            <token id="8" string="they" />
            <token id="9" string="'re" />
            <token id="10" string="here" />
            <token id="11" string="and" />
            <token id="12" string="here" />
            <token id="13" string="to" />
            <token id="14" string="stay" />
          </tokens>
        </chunking>
        <chunking id="3" string="'re here and here to stay" type="VP">
          <tokens>
            <token id="9" string="'re" />
            <token id="10" string="here" />
            <token id="11" string="and" />
            <token id="12" string="here" />
            <token id="13" string="to" />
            <token id="14" string="stay" />
          </tokens>
        </chunking>
        <chunking id="4" string="like it" type="VP">
          <tokens>
            <token id="4" string="like" />
            <token id="5" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="to stay" type="VP">
          <tokens>
            <token id="13" string="to" />
            <token id="14" string="stay" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="5" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="we" type="NP">
          <tokens>
            <token id="3" string="we" />
          </tokens>
        </chunking>
        <chunking id="8" string="said" type="VP">
          <tokens>
            <token id="18" string="said" />
          </tokens>
        </chunking>
        <chunking id="9" string="stay" type="VP">
          <tokens>
            <token id="14" string="stay" />
          </tokens>
        </chunking>
        <chunking id="10" string="McDonough" type="NP">
          <tokens>
            <token id="17" string="McDonough" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="18">said</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="4">like</governor>
          <dependent id="2">whether</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">like</governor>
          <dependent id="3">we</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="18">said</governor>
          <dependent id="4">like</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">like</governor>
          <dependent id="5">it</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">like</governor>
          <dependent id="6">or</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="9">'re</governor>
          <dependent id="7">not</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">'re</governor>
          <dependent id="8">they</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">like</governor>
          <dependent id="9">'re</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">'re</governor>
          <dependent id="10">here</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">here</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">here</governor>
          <dependent id="12">here</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">stay</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">'re</governor>
          <dependent id="14">stay</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">said</governor>
          <dependent id="17">McDonough</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="McDonough" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="McDonough" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="38" has_coreference="true">
      <content>In recent weeks, representatives from the census office in Santa Ana have visited such social centers as Abrazar and others and told center staff people that they intend to count &amp;quot;everyone, regardless of where they came from,&amp;quot; McDonough said.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="recent" lemma="recent" stem="recent" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="3" string="weeks" lemma="week" stem="week" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="representatives" lemma="representative" stem="repres" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="census" lemma="census" stem="censu" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="office" lemma="office" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="Santa" lemma="Santa" stem="santa" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="12" string="Ana" lemma="Ana" stem="ana" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="13" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="visited" lemma="visit" stem="visit" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="social" lemma="social" stem="social" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="centers" lemma="center" stem="center" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Abrazar" lemma="Abrazar" stem="abrazar" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="20" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="others" lemma="other" stem="other" pos="NNS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="told" lemma="tell" stem="told" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="center" lemma="center" stem="center" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="staff" lemma="staff" stem="staff" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="intend" lemma="intend" stem="intend" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="count" lemma="count" stem="count" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="everyone" lemma="everyone" stem="everyon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="regardless" lemma="regardless" stem="regardless" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="came" lemma="come" stem="came" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="McDonough" lemma="McDonough" stem="mcdonough" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="44" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (PP (IN In) (NP (JJ recent) (NNS weeks))) (, ,) (NP (NP (NNS representatives)) (PP (IN from) (NP (NP (DT the) (NN census) (NN office)) (PP (IN in) (NP (NNP Santa) (NNP Ana)))))) (VP (VP (VBP have) (VP (VBN visited) (NP (JJ such) (JJ social) (NNS centers)) (PP (IN as) (NP (NP (NNP Abrazar)) (CC and) (NP (NNS others)))))) (CC and) (VP (VBD told) (NP (NN center) (NN staff) (NNS people)) (SBAR (IN that) (S (NP (PRP they)) (VP (VBP intend) (S (VP (TO to) (VP (VB count) (`` ``) (NP (NN everyone)) (, ,) (ADVP (RB regardless)) (PP (IN of) (SBAR (WHADVP (WRB where)) (S (NP (PRP they)) (VP (VBD came) (PP (IN from))))))))))))))) (, ,) ('' '') (NP (NNP McDonough)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the census office in Santa Ana" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="census" />
            <token id="9" string="office" />
            <token id="10" string="in" />
            <token id="11" string="Santa" />
            <token id="12" string="Ana" />
          </tokens>
        </chunking>
        <chunking id="2" string="everyone" type="NP">
          <tokens>
            <token id="33" string="everyone" />
          </tokens>
        </chunking>
        <chunking id="3" string="where they came from" type="SBAR">
          <tokens>
            <token id="37" string="where" />
            <token id="38" string="they" />
            <token id="39" string="came" />
            <token id="40" string="from" />
          </tokens>
        </chunking>
        <chunking id="4" string="told center staff people that they intend to count `` everyone , regardless of where they came from" type="VP">
          <tokens>
            <token id="23" string="told" />
            <token id="24" string="center" />
            <token id="25" string="staff" />
            <token id="26" string="people" />
            <token id="27" string="that" />
            <token id="28" string="they" />
            <token id="29" string="intend" />
            <token id="30" string="to" />
            <token id="31" string="count" />
            <token id="32" string="&quot;" />
            <token id="33" string="everyone" />
            <token id="34" string="," />
            <token id="35" string="regardless" />
            <token id="36" string="of" />
            <token id="37" string="where" />
            <token id="38" string="they" />
            <token id="39" string="came" />
            <token id="40" string="from" />
          </tokens>
        </chunking>
        <chunking id="5" string="the census office" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="census" />
            <token id="9" string="office" />
          </tokens>
        </chunking>
        <chunking id="6" string="intend to count `` everyone , regardless of where they came from" type="VP">
          <tokens>
            <token id="29" string="intend" />
            <token id="30" string="to" />
            <token id="31" string="count" />
            <token id="32" string="&quot;" />
            <token id="33" string="everyone" />
            <token id="34" string="," />
            <token id="35" string="regardless" />
            <token id="36" string="of" />
            <token id="37" string="where" />
            <token id="38" string="they" />
            <token id="39" string="came" />
            <token id="40" string="from" />
          </tokens>
        </chunking>
        <chunking id="7" string="Abrazar and others" type="NP">
          <tokens>
            <token id="19" string="Abrazar" />
            <token id="20" string="and" />
            <token id="21" string="others" />
          </tokens>
        </chunking>
        <chunking id="8" string="that they intend to count `` everyone , regardless of where they came from" type="SBAR">
          <tokens>
            <token id="27" string="that" />
            <token id="28" string="they" />
            <token id="29" string="intend" />
            <token id="30" string="to" />
            <token id="31" string="count" />
            <token id="32" string="&quot;" />
            <token id="33" string="everyone" />
            <token id="34" string="," />
            <token id="35" string="regardless" />
            <token id="36" string="of" />
            <token id="37" string="where" />
            <token id="38" string="they" />
            <token id="39" string="came" />
            <token id="40" string="from" />
          </tokens>
        </chunking>
        <chunking id="9" string="representatives from the census office in Santa Ana" type="NP">
          <tokens>
            <token id="5" string="representatives" />
            <token id="6" string="from" />
            <token id="7" string="the" />
            <token id="8" string="census" />
            <token id="9" string="office" />
            <token id="10" string="in" />
            <token id="11" string="Santa" />
            <token id="12" string="Ana" />
          </tokens>
        </chunking>
        <chunking id="10" string="visited such social centers as Abrazar and others" type="VP">
          <tokens>
            <token id="14" string="visited" />
            <token id="15" string="such" />
            <token id="16" string="social" />
            <token id="17" string="centers" />
            <token id="18" string="as" />
            <token id="19" string="Abrazar" />
            <token id="20" string="and" />
            <token id="21" string="others" />
          </tokens>
        </chunking>
        <chunking id="11" string="representatives" type="NP">
          <tokens>
            <token id="5" string="representatives" />
          </tokens>
        </chunking>
        <chunking id="12" string="such social centers" type="NP">
          <tokens>
            <token id="15" string="such" />
            <token id="16" string="social" />
            <token id="17" string="centers" />
          </tokens>
        </chunking>
        <chunking id="13" string="Santa Ana" type="NP">
          <tokens>
            <token id="11" string="Santa" />
            <token id="12" string="Ana" />
          </tokens>
        </chunking>
        <chunking id="14" string="have visited such social centers as Abrazar and others and told center staff people that they intend to count `` everyone , regardless of where they came from" type="VP">
          <tokens>
            <token id="13" string="have" />
            <token id="14" string="visited" />
            <token id="15" string="such" />
            <token id="16" string="social" />
            <token id="17" string="centers" />
            <token id="18" string="as" />
            <token id="19" string="Abrazar" />
            <token id="20" string="and" />
            <token id="21" string="others" />
            <token id="22" string="and" />
            <token id="23" string="told" />
            <token id="24" string="center" />
            <token id="25" string="staff" />
            <token id="26" string="people" />
            <token id="27" string="that" />
            <token id="28" string="they" />
            <token id="29" string="intend" />
            <token id="30" string="to" />
            <token id="31" string="count" />
            <token id="32" string="&quot;" />
            <token id="33" string="everyone" />
            <token id="34" string="," />
            <token id="35" string="regardless" />
            <token id="36" string="of" />
            <token id="37" string="where" />
            <token id="38" string="they" />
            <token id="39" string="came" />
            <token id="40" string="from" />
          </tokens>
        </chunking>
        <chunking id="15" string="McDonough" type="NP">
          <tokens>
            <token id="43" string="McDonough" />
          </tokens>
        </chunking>
        <chunking id="16" string="came from" type="VP">
          <tokens>
            <token id="39" string="came" />
            <token id="40" string="from" />
          </tokens>
        </chunking>
        <chunking id="17" string="to count `` everyone , regardless of where they came from" type="VP">
          <tokens>
            <token id="30" string="to" />
            <token id="31" string="count" />
            <token id="32" string="&quot;" />
            <token id="33" string="everyone" />
            <token id="34" string="," />
            <token id="35" string="regardless" />
            <token id="36" string="of" />
            <token id="37" string="where" />
            <token id="38" string="they" />
            <token id="39" string="came" />
            <token id="40" string="from" />
          </tokens>
        </chunking>
        <chunking id="18" string="recent weeks" type="NP">
          <tokens>
            <token id="2" string="recent" />
            <token id="3" string="weeks" />
          </tokens>
        </chunking>
        <chunking id="19" string="they" type="NP">
          <tokens>
            <token id="28" string="they" />
          </tokens>
        </chunking>
        <chunking id="20" string="count `` everyone , regardless of where they came from" type="VP">
          <tokens>
            <token id="31" string="count" />
            <token id="32" string="&quot;" />
            <token id="33" string="everyone" />
            <token id="34" string="," />
            <token id="35" string="regardless" />
            <token id="36" string="of" />
            <token id="37" string="where" />
            <token id="38" string="they" />
            <token id="39" string="came" />
            <token id="40" string="from" />
          </tokens>
        </chunking>
        <chunking id="21" string="where" type="WHADVP">
          <tokens>
            <token id="37" string="where" />
          </tokens>
        </chunking>
        <chunking id="22" string="center staff people" type="NP">
          <tokens>
            <token id="24" string="center" />
            <token id="25" string="staff" />
            <token id="26" string="people" />
          </tokens>
        </chunking>
        <chunking id="23" string="have visited such social centers as Abrazar and others" type="VP">
          <tokens>
            <token id="13" string="have" />
            <token id="14" string="visited" />
            <token id="15" string="such" />
            <token id="16" string="social" />
            <token id="17" string="centers" />
            <token id="18" string="as" />
            <token id="19" string="Abrazar" />
            <token id="20" string="and" />
            <token id="21" string="others" />
          </tokens>
        </chunking>
        <chunking id="24" string="said" type="VP">
          <tokens>
            <token id="44" string="said" />
          </tokens>
        </chunking>
        <chunking id="25" string="Abrazar" type="NP">
          <tokens>
            <token id="19" string="Abrazar" />
          </tokens>
        </chunking>
        <chunking id="26" string="others" type="NP">
          <tokens>
            <token id="21" string="others" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">weeks</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">weeks</governor>
          <dependent id="2">recent</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">visited</governor>
          <dependent id="3">weeks</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">visited</governor>
          <dependent id="5">representatives</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">office</governor>
          <dependent id="6">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">office</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">office</governor>
          <dependent id="8">census</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">representatives</governor>
          <dependent id="9">office</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Ana</governor>
          <dependent id="10">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Ana</governor>
          <dependent id="11">Santa</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">office</governor>
          <dependent id="12">Ana</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">visited</governor>
          <dependent id="13">have</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="44">said</governor>
          <dependent id="14">visited</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">centers</governor>
          <dependent id="15">such</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">centers</governor>
          <dependent id="16">social</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">visited</governor>
          <dependent id="17">centers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">Abrazar</governor>
          <dependent id="18">as</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">visited</governor>
          <dependent id="19">Abrazar</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="19">Abrazar</governor>
          <dependent id="20">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">Abrazar</governor>
          <dependent id="21">others</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">visited</governor>
          <dependent id="22">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">visited</governor>
          <dependent id="23">told</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">people</governor>
          <dependent id="24">center</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">people</governor>
          <dependent id="25">staff</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">told</governor>
          <dependent id="26">people</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="29">intend</governor>
          <dependent id="27">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">intend</governor>
          <dependent id="28">they</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="23">told</governor>
          <dependent id="29">intend</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="31">count</governor>
          <dependent id="30">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="29">intend</governor>
          <dependent id="31">count</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="31">count</governor>
          <dependent id="33">everyone</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="39">came</governor>
          <dependent id="35">regardless</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="39">came</governor>
          <dependent id="36">of</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="39">came</governor>
          <dependent id="37">where</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="39">came</governor>
          <dependent id="38">they</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="31">count</governor>
          <dependent id="39">came</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="39">came</governor>
          <dependent id="40">from</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="44">said</governor>
          <dependent id="43">McDonough</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="44">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="recent weeks" type="DURATION" score="0.0">
          <tokens>
            <token id="2" string="recent" />
            <token id="3" string="weeks" />
          </tokens>
        </entity>
        <entity id="2" string="Santa Ana" type="LOCATION" score="0.0">
          <tokens>
            <token id="11" string="Santa" />
            <token id="12" string="Ana" />
          </tokens>
        </entity>
        <entity id="3" string="Abrazar" type="LOCATION" score="0.0">
          <tokens>
            <token id="19" string="Abrazar" />
          </tokens>
        </entity>
        <entity id="4" string="McDonough" type="PERSON" score="0.0">
          <tokens>
            <token id="43" string="McDonough" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="39" has_coreference="true">
      <content>&amp;quot;Their big thing was, &amp;apost;We do not care about the origins of where these people are from, but, more importantly, their impact to local economies,&amp;apost; &amp;quot; she said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="big" lemma="big" stem="big" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="thing" lemma="thing" stem="thing" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="'" lemma="`" stem="'" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="care" lemma="care" stem="care" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="origins" lemma="origin" stem="origin" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="these" lemma="these" stem="these" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="importantly" lemma="importantly" stem="importantli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="28" string="impact" lemma="impact" stem="impact" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="local" lemma="local" stem="local" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="economies" lemma="economy" stem="economi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="36" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP$ Their) (JJ big) (NN thing)) (VP (VBD was) (, ,) (`` `) (S (NP (PRP We)) (VP (VBP do) (RB not) (VP (VB care) (PP (IN about) (NP (NP (DT the) (NNS origins)) (PP (IN of) (SBAR (WHADVP (WRB where)) (S (NP (DT these) (NNS people)) (VP (VBP are) (PP (IN from)) (, ,) (ADVP (CC but)))))))) (, ,) (ADVP (RBR more) (RB importantly)) (, ,) (NP (NP (PRP$ their) (NN impact)) (PP (TO to) (NP (JJ local) (NNS economies))))))))) (, ,) ('' ') ('' '') (NP (PRP she)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was , ` We do not care about the origins of where these people are from , but , more importantly , their impact to local economies" type="VP">
          <tokens>
            <token id="5" string="was" />
            <token id="6" string="," />
            <token id="7" string="'" />
            <token id="8" string="We" />
            <token id="9" string="do" />
            <token id="10" string="not" />
            <token id="11" string="care" />
            <token id="12" string="about" />
            <token id="13" string="the" />
            <token id="14" string="origins" />
            <token id="15" string="of" />
            <token id="16" string="where" />
            <token id="17" string="these" />
            <token id="18" string="people" />
            <token id="19" string="are" />
            <token id="20" string="from" />
            <token id="21" string="," />
            <token id="22" string="but" />
            <token id="23" string="," />
            <token id="24" string="more" />
            <token id="25" string="importantly" />
            <token id="26" string="," />
            <token id="27" string="their" />
            <token id="28" string="impact" />
            <token id="29" string="to" />
            <token id="30" string="local" />
            <token id="31" string="economies" />
          </tokens>
        </chunking>
        <chunking id="2" string="do not care about the origins of where these people are from , but , more importantly , their impact to local economies" type="VP">
          <tokens>
            <token id="9" string="do" />
            <token id="10" string="not" />
            <token id="11" string="care" />
            <token id="12" string="about" />
            <token id="13" string="the" />
            <token id="14" string="origins" />
            <token id="15" string="of" />
            <token id="16" string="where" />
            <token id="17" string="these" />
            <token id="18" string="people" />
            <token id="19" string="are" />
            <token id="20" string="from" />
            <token id="21" string="," />
            <token id="22" string="but" />
            <token id="23" string="," />
            <token id="24" string="more" />
            <token id="25" string="importantly" />
            <token id="26" string="," />
            <token id="27" string="their" />
            <token id="28" string="impact" />
            <token id="29" string="to" />
            <token id="30" string="local" />
            <token id="31" string="economies" />
          </tokens>
        </chunking>
        <chunking id="3" string="where these people are from , but" type="SBAR">
          <tokens>
            <token id="16" string="where" />
            <token id="17" string="these" />
            <token id="18" string="people" />
            <token id="19" string="are" />
            <token id="20" string="from" />
            <token id="21" string="," />
            <token id="22" string="but" />
          </tokens>
        </chunking>
        <chunking id="4" string="their impact" type="NP">
          <tokens>
            <token id="27" string="their" />
            <token id="28" string="impact" />
          </tokens>
        </chunking>
        <chunking id="5" string="local economies" type="NP">
          <tokens>
            <token id="30" string="local" />
            <token id="31" string="economies" />
          </tokens>
        </chunking>
        <chunking id="6" string="Their big thing" type="NP">
          <tokens>
            <token id="2" string="Their" />
            <token id="3" string="big" />
            <token id="4" string="thing" />
          </tokens>
        </chunking>
        <chunking id="7" string="We" type="NP">
          <tokens>
            <token id="8" string="We" />
          </tokens>
        </chunking>
        <chunking id="8" string="the origins" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="origins" />
          </tokens>
        </chunking>
        <chunking id="9" string="are from , but" type="VP">
          <tokens>
            <token id="19" string="are" />
            <token id="20" string="from" />
            <token id="21" string="," />
            <token id="22" string="but" />
          </tokens>
        </chunking>
        <chunking id="10" string="she" type="NP">
          <tokens>
            <token id="35" string="she" />
          </tokens>
        </chunking>
        <chunking id="11" string="these people" type="NP">
          <tokens>
            <token id="17" string="these" />
            <token id="18" string="people" />
          </tokens>
        </chunking>
        <chunking id="12" string="the origins of where these people are from , but" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="origins" />
            <token id="15" string="of" />
            <token id="16" string="where" />
            <token id="17" string="these" />
            <token id="18" string="people" />
            <token id="19" string="are" />
            <token id="20" string="from" />
            <token id="21" string="," />
            <token id="22" string="but" />
          </tokens>
        </chunking>
        <chunking id="13" string="their impact to local economies" type="NP">
          <tokens>
            <token id="27" string="their" />
            <token id="28" string="impact" />
            <token id="29" string="to" />
            <token id="30" string="local" />
            <token id="31" string="economies" />
          </tokens>
        </chunking>
        <chunking id="14" string="care about the origins of where these people are from , but , more importantly , their impact to local economies" type="VP">
          <tokens>
            <token id="11" string="care" />
            <token id="12" string="about" />
            <token id="13" string="the" />
            <token id="14" string="origins" />
            <token id="15" string="of" />
            <token id="16" string="where" />
            <token id="17" string="these" />
            <token id="18" string="people" />
            <token id="19" string="are" />
            <token id="20" string="from" />
            <token id="21" string="," />
            <token id="22" string="but" />
            <token id="23" string="," />
            <token id="24" string="more" />
            <token id="25" string="importantly" />
            <token id="26" string="," />
            <token id="27" string="their" />
            <token id="28" string="impact" />
            <token id="29" string="to" />
            <token id="30" string="local" />
            <token id="31" string="economies" />
          </tokens>
        </chunking>
        <chunking id="15" string="where" type="WHADVP">
          <tokens>
            <token id="16" string="where" />
          </tokens>
        </chunking>
        <chunking id="16" string="said" type="VP">
          <tokens>
            <token id="36" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="4">thing</governor>
          <dependent id="2">Their</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">thing</governor>
          <dependent id="3">big</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">was</governor>
          <dependent id="4">thing</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="36">said</governor>
          <dependent id="5">was</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">care</governor>
          <dependent id="8">We</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">care</governor>
          <dependent id="9">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="11">care</governor>
          <dependent id="10">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">was</governor>
          <dependent id="11">care</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">origins</governor>
          <dependent id="12">about</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">origins</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">care</governor>
          <dependent id="14">origins</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">from</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">from</governor>
          <dependent id="16">where</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">people</governor>
          <dependent id="17">these</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">from</governor>
          <dependent id="18">people</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="20">from</governor>
          <dependent id="19">are</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="14">origins</governor>
          <dependent id="20">from</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">from</governor>
          <dependent id="22">but</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="25">importantly</governor>
          <dependent id="24">more</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">care</governor>
          <dependent id="25">importantly</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="28">impact</governor>
          <dependent id="27">their</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">care</governor>
          <dependent id="28">impact</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">economies</governor>
          <dependent id="29">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">economies</governor>
          <dependent id="30">local</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">impact</governor>
          <dependent id="31">economies</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="36">said</governor>
          <dependent id="35">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="36">said</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="40" has_coreference="true">
      <content>When asked to comment, census officials in Santa Ana referred media inquiries to the regional office in Van Nuys.</content>
      <tokens>
        <token id="1" string="When" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="asked" lemma="ask" stem="ask" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="comment" lemma="comment" stem="comment" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="census" lemma="census" stem="censu" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="officials" lemma="official" stem="offici" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="Santa" lemma="Santa" stem="santa" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="10" string="Ana" lemma="Ana" stem="ana" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="11" string="referred" lemma="refer" stem="refer" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="media" lemma="media" stem="media" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="inquiries" lemma="inquiry" stem="inquiri" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="regional" lemma="regional" stem="region" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="office" lemma="office" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Van" lemma="Van" stem="van" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="20" string="Nuys" lemma="Nuys" stem="nui" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (WHADVP (WRB When)) (S (VP (VBN asked) (S (VP (TO to) (VP (VB comment))))))) (, ,) (NP (NP (NN census) (NNS officials)) (PP (IN in) (NP (NNP Santa) (NNP Ana)))) (VP (VBD referred) (NP (NNS media) (NNS inquiries)) (PP (TO to) (NP (DT the) (JJ regional) (NN office))) (PP (IN in) (NP (NNP Van) (NNP Nuys)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="When" type="WHADVP">
          <tokens>
            <token id="1" string="When" />
          </tokens>
        </chunking>
        <chunking id="2" string="census officials" type="NP">
          <tokens>
            <token id="6" string="census" />
            <token id="7" string="officials" />
          </tokens>
        </chunking>
        <chunking id="3" string="Van Nuys" type="NP">
          <tokens>
            <token id="19" string="Van" />
            <token id="20" string="Nuys" />
          </tokens>
        </chunking>
        <chunking id="4" string="When asked to comment" type="SBAR">
          <tokens>
            <token id="1" string="When" />
            <token id="2" string="asked" />
            <token id="3" string="to" />
            <token id="4" string="comment" />
          </tokens>
        </chunking>
        <chunking id="5" string="asked to comment" type="VP">
          <tokens>
            <token id="2" string="asked" />
            <token id="3" string="to" />
            <token id="4" string="comment" />
          </tokens>
        </chunking>
        <chunking id="6" string="referred media inquiries to the regional office in Van Nuys" type="VP">
          <tokens>
            <token id="11" string="referred" />
            <token id="12" string="media" />
            <token id="13" string="inquiries" />
            <token id="14" string="to" />
            <token id="15" string="the" />
            <token id="16" string="regional" />
            <token id="17" string="office" />
            <token id="18" string="in" />
            <token id="19" string="Van" />
            <token id="20" string="Nuys" />
          </tokens>
        </chunking>
        <chunking id="7" string="census officials in Santa Ana" type="NP">
          <tokens>
            <token id="6" string="census" />
            <token id="7" string="officials" />
            <token id="8" string="in" />
            <token id="9" string="Santa" />
            <token id="10" string="Ana" />
          </tokens>
        </chunking>
        <chunking id="8" string="to comment" type="VP">
          <tokens>
            <token id="3" string="to" />
            <token id="4" string="comment" />
          </tokens>
        </chunking>
        <chunking id="9" string="Santa Ana" type="NP">
          <tokens>
            <token id="9" string="Santa" />
            <token id="10" string="Ana" />
          </tokens>
        </chunking>
        <chunking id="10" string="comment" type="VP">
          <tokens>
            <token id="4" string="comment" />
          </tokens>
        </chunking>
        <chunking id="11" string="the regional office" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="regional" />
            <token id="17" string="office" />
          </tokens>
        </chunking>
        <chunking id="12" string="media inquiries" type="NP">
          <tokens>
            <token id="12" string="media" />
            <token id="13" string="inquiries" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="2">asked</governor>
          <dependent id="1">When</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">referred</governor>
          <dependent id="2">asked</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="4">comment</governor>
          <dependent id="3">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="2">asked</governor>
          <dependent id="4">comment</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">officials</governor>
          <dependent id="6">census</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">referred</governor>
          <dependent id="7">officials</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Ana</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Ana</governor>
          <dependent id="9">Santa</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">officials</governor>
          <dependent id="10">Ana</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">referred</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">inquiries</governor>
          <dependent id="12">media</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">referred</governor>
          <dependent id="13">inquiries</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">office</governor>
          <dependent id="14">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">office</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">office</governor>
          <dependent id="16">regional</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">referred</governor>
          <dependent id="17">office</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">Nuys</governor>
          <dependent id="18">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Nuys</governor>
          <dependent id="19">Van</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">referred</governor>
          <dependent id="20">Nuys</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Van Nuys" type="LOCATION" score="0.0">
          <tokens>
            <token id="19" string="Van" />
            <token id="20" string="Nuys" />
          </tokens>
        </entity>
        <entity id="2" string="Santa Ana" type="LOCATION" score="0.0">
          <tokens>
            <token id="9" string="Santa" />
            <token id="10" string="Ana" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="41" has_coreference="true">
      <content>Adrian Dove, assistant regional director for the U.S. Census in charge of outreach, said that despite the Senate&amp;apost;s decision, the census bureau &amp;quot;really doesn&amp;apost;t know how to go about finding who was legal or illegal.&amp;quot;</content>
      <tokens>
        <token id="1" string="Adrian" lemma="Adrian" stem="adrian" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Dove" lemma="dove" stem="dove" pos="NN" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="assistant" lemma="assistant" stem="assist" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="regional" lemma="regional" stem="region" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="director" lemma="director" stem="director" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="U.S." lemma="U.S." stem="u.s." pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="10" string="Census" lemma="Census" stem="censu" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="charge" lemma="charge" stem="charg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="outreach" lemma="outreach" stem="outreach" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="despite" lemma="despite" stem="despit" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="20" string="Senate" lemma="Senate" stem="senat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="21" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="22" string="decision" lemma="decision" stem="decis" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="census" lemma="census" stem="censu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="bureau" lemma="bureau" stem="bureau" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="really" lemma="really" stem="realli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="does" lemma="do" stem="doe" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="know" lemma="know" stem="know" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="how" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="go" lemma="go" stem="go" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="about" lemma="about" stem="about" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="finding" lemma="find" stem="find" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="legal" lemma="legal" stem="legal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Adrian) (NN Dove)) (, ,) (NP (NP (JJ assistant) (JJ regional) (NN director)) (PP (IN for) (NP (NP (DT the) (NNP U.S.) (NNP Census)) (PP (IN in) (NP (NP (NN charge)) (PP (IN of) (NP (NN outreach)))))))) (, ,)) (VP (VBD said) (SBAR (IN that) (S (PP (IN despite) (NP (NP (DT the) (NNP Senate) (POS 's)) (NN decision))) (, ,) (NP (DT the) (NN census) (NN bureau)) (`` ``) (ADVP (RB really)) (VP (VBZ does) (RB n't) (VP (VB know) (SBAR (WHADVP (WRB how)) (S (VP (TO to) (VP (VB go) (S (VP (RB about) (VBG finding) (SBAR (WHNP (WP who)) (S (VP (VBD was) (ADJP (JJ legal) (CC or) (JJ illegal)))))))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="that despite the Senate 's decision , the census bureau `` really does n't know how to go about finding who was legal or illegal" type="SBAR">
          <tokens>
            <token id="17" string="that" />
            <token id="18" string="despite" />
            <token id="19" string="the" />
            <token id="20" string="Senate" />
            <token id="21" string="'s" />
            <token id="22" string="decision" />
            <token id="23" string="," />
            <token id="24" string="the" />
            <token id="25" string="census" />
            <token id="26" string="bureau" />
            <token id="27" string="&quot;" />
            <token id="28" string="really" />
            <token id="29" string="does" />
            <token id="30" string="n't" />
            <token id="31" string="know" />
            <token id="32" string="how" />
            <token id="33" string="to" />
            <token id="34" string="go" />
            <token id="35" string="about" />
            <token id="36" string="finding" />
            <token id="37" string="who" />
            <token id="38" string="was" />
            <token id="39" string="legal" />
            <token id="40" string="or" />
            <token id="41" string="illegal" />
          </tokens>
        </chunking>
        <chunking id="2" string="to go about finding who was legal or illegal" type="VP">
          <tokens>
            <token id="33" string="to" />
            <token id="34" string="go" />
            <token id="35" string="about" />
            <token id="36" string="finding" />
            <token id="37" string="who" />
            <token id="38" string="was" />
            <token id="39" string="legal" />
            <token id="40" string="or" />
            <token id="41" string="illegal" />
          </tokens>
        </chunking>
        <chunking id="3" string="charge" type="NP">
          <tokens>
            <token id="12" string="charge" />
          </tokens>
        </chunking>
        <chunking id="4" string="about finding who was legal or illegal" type="VP">
          <tokens>
            <token id="35" string="about" />
            <token id="36" string="finding" />
            <token id="37" string="who" />
            <token id="38" string="was" />
            <token id="39" string="legal" />
            <token id="40" string="or" />
            <token id="41" string="illegal" />
          </tokens>
        </chunking>
        <chunking id="5" string="assistant regional director" type="NP">
          <tokens>
            <token id="4" string="assistant" />
            <token id="5" string="regional" />
            <token id="6" string="director" />
          </tokens>
        </chunking>
        <chunking id="6" string="said that despite the Senate 's decision , the census bureau `` really does n't know how to go about finding who was legal or illegal" type="VP">
          <tokens>
            <token id="16" string="said" />
            <token id="17" string="that" />
            <token id="18" string="despite" />
            <token id="19" string="the" />
            <token id="20" string="Senate" />
            <token id="21" string="'s" />
            <token id="22" string="decision" />
            <token id="23" string="," />
            <token id="24" string="the" />
            <token id="25" string="census" />
            <token id="26" string="bureau" />
            <token id="27" string="&quot;" />
            <token id="28" string="really" />
            <token id="29" string="does" />
            <token id="30" string="n't" />
            <token id="31" string="know" />
            <token id="32" string="how" />
            <token id="33" string="to" />
            <token id="34" string="go" />
            <token id="35" string="about" />
            <token id="36" string="finding" />
            <token id="37" string="who" />
            <token id="38" string="was" />
            <token id="39" string="legal" />
            <token id="40" string="or" />
            <token id="41" string="illegal" />
          </tokens>
        </chunking>
        <chunking id="7" string="charge of outreach" type="NP">
          <tokens>
            <token id="12" string="charge" />
            <token id="13" string="of" />
            <token id="14" string="outreach" />
          </tokens>
        </chunking>
        <chunking id="8" string="who was legal or illegal" type="SBAR">
          <tokens>
            <token id="37" string="who" />
            <token id="38" string="was" />
            <token id="39" string="legal" />
            <token id="40" string="or" />
            <token id="41" string="illegal" />
          </tokens>
        </chunking>
        <chunking id="9" string="outreach" type="NP">
          <tokens>
            <token id="14" string="outreach" />
          </tokens>
        </chunking>
        <chunking id="10" string="Adrian Dove , assistant regional director for the U.S. Census in charge of outreach ," type="NP">
          <tokens>
            <token id="1" string="Adrian" />
            <token id="2" string="Dove" />
            <token id="3" string="," />
            <token id="4" string="assistant" />
            <token id="5" string="regional" />
            <token id="6" string="director" />
            <token id="7" string="for" />
            <token id="8" string="the" />
            <token id="9" string="U.S." />
            <token id="10" string="Census" />
            <token id="11" string="in" />
            <token id="12" string="charge" />
            <token id="13" string="of" />
            <token id="14" string="outreach" />
            <token id="15" string="," />
          </tokens>
        </chunking>
        <chunking id="11" string="legal or illegal" type="ADJP">
          <tokens>
            <token id="39" string="legal" />
            <token id="40" string="or" />
            <token id="41" string="illegal" />
          </tokens>
        </chunking>
        <chunking id="12" string="the U.S. Census in charge of outreach" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="U.S." />
            <token id="10" string="Census" />
            <token id="11" string="in" />
            <token id="12" string="charge" />
            <token id="13" string="of" />
            <token id="14" string="outreach" />
          </tokens>
        </chunking>
        <chunking id="13" string="go about finding who was legal or illegal" type="VP">
          <tokens>
            <token id="34" string="go" />
            <token id="35" string="about" />
            <token id="36" string="finding" />
            <token id="37" string="who" />
            <token id="38" string="was" />
            <token id="39" string="legal" />
            <token id="40" string="or" />
            <token id="41" string="illegal" />
          </tokens>
        </chunking>
        <chunking id="14" string="how" type="WHADVP">
          <tokens>
            <token id="32" string="how" />
          </tokens>
        </chunking>
        <chunking id="15" string="does n't know how to go about finding who was legal or illegal" type="VP">
          <tokens>
            <token id="29" string="does" />
            <token id="30" string="n't" />
            <token id="31" string="know" />
            <token id="32" string="how" />
            <token id="33" string="to" />
            <token id="34" string="go" />
            <token id="35" string="about" />
            <token id="36" string="finding" />
            <token id="37" string="who" />
            <token id="38" string="was" />
            <token id="39" string="legal" />
            <token id="40" string="or" />
            <token id="41" string="illegal" />
          </tokens>
        </chunking>
        <chunking id="16" string="how to go about finding who was legal or illegal" type="SBAR">
          <tokens>
            <token id="32" string="how" />
            <token id="33" string="to" />
            <token id="34" string="go" />
            <token id="35" string="about" />
            <token id="36" string="finding" />
            <token id="37" string="who" />
            <token id="38" string="was" />
            <token id="39" string="legal" />
            <token id="40" string="or" />
            <token id="41" string="illegal" />
          </tokens>
        </chunking>
        <chunking id="17" string="the Senate 's decision" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="Senate" />
            <token id="21" string="'s" />
            <token id="22" string="decision" />
          </tokens>
        </chunking>
        <chunking id="18" string="the U.S. Census" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="U.S." />
            <token id="10" string="Census" />
          </tokens>
        </chunking>
        <chunking id="19" string="was legal or illegal" type="VP">
          <tokens>
            <token id="38" string="was" />
            <token id="39" string="legal" />
            <token id="40" string="or" />
            <token id="41" string="illegal" />
          </tokens>
        </chunking>
        <chunking id="20" string="the Senate 's" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="Senate" />
            <token id="21" string="'s" />
          </tokens>
        </chunking>
        <chunking id="21" string="Adrian Dove" type="NP">
          <tokens>
            <token id="1" string="Adrian" />
            <token id="2" string="Dove" />
          </tokens>
        </chunking>
        <chunking id="22" string="the census bureau" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="census" />
            <token id="26" string="bureau" />
          </tokens>
        </chunking>
        <chunking id="23" string="know how to go about finding who was legal or illegal" type="VP">
          <tokens>
            <token id="31" string="know" />
            <token id="32" string="how" />
            <token id="33" string="to" />
            <token id="34" string="go" />
            <token id="35" string="about" />
            <token id="36" string="finding" />
            <token id="37" string="who" />
            <token id="38" string="was" />
            <token id="39" string="legal" />
            <token id="40" string="or" />
            <token id="41" string="illegal" />
          </tokens>
        </chunking>
        <chunking id="24" string="assistant regional director for the U.S. Census in charge of outreach" type="NP">
          <tokens>
            <token id="4" string="assistant" />
            <token id="5" string="regional" />
            <token id="6" string="director" />
            <token id="7" string="for" />
            <token id="8" string="the" />
            <token id="9" string="U.S." />
            <token id="10" string="Census" />
            <token id="11" string="in" />
            <token id="12" string="charge" />
            <token id="13" string="of" />
            <token id="14" string="outreach" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Dove</governor>
          <dependent id="1">Adrian</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">said</governor>
          <dependent id="2">Dove</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">director</governor>
          <dependent id="4">assistant</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">director</governor>
          <dependent id="5">regional</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">Dove</governor>
          <dependent id="6">director</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Census</governor>
          <dependent id="7">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">Census</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Census</governor>
          <dependent id="9">U.S.</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">director</governor>
          <dependent id="10">Census</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">charge</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">Census</governor>
          <dependent id="12">charge</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">outreach</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">charge</governor>
          <dependent id="14">outreach</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">said</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="31">know</governor>
          <dependent id="17">that</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">decision</governor>
          <dependent id="18">despite</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">Senate</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="22">decision</governor>
          <dependent id="20">Senate</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">Senate</governor>
          <dependent id="21">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">know</governor>
          <dependent id="22">decision</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">bureau</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">bureau</governor>
          <dependent id="25">census</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">know</governor>
          <dependent id="26">bureau</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="31">know</governor>
          <dependent id="28">really</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="31">know</governor>
          <dependent id="29">does</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="31">know</governor>
          <dependent id="30">n't</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">said</governor>
          <dependent id="31">know</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="34">go</governor>
          <dependent id="32">how</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="34">go</governor>
          <dependent id="33">to</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="31">know</governor>
          <dependent id="34">go</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="36">finding</governor>
          <dependent id="35">about</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="34">go</governor>
          <dependent id="36">finding</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="39">legal</governor>
          <dependent id="37">who</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="39">legal</governor>
          <dependent id="38">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="36">finding</governor>
          <dependent id="39">legal</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="39">legal</governor>
          <dependent id="40">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="39">legal</governor>
          <dependent id="41">illegal</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Senate" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="20" string="Senate" />
          </tokens>
        </entity>
        <entity id="2" string="U.S. Census" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="9" string="U.S." />
            <token id="10" string="Census" />
          </tokens>
        </entity>
        <entity id="3" string="Adrian Dove" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Adrian" />
            <token id="2" string="Dove" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="42" has_coreference="true">
      <content>&amp;quot;But we have a mandate to follow that law, and we would have to find out,&amp;quot; he said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="mandate" lemma="mandate" stem="mandat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="follow" lemma="follow" stem="follow" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="law" lemma="law" stem="law" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="find" lemma="find" stem="find" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (S (CC But) (NP (PRP we)) (VP (VBP have) (NP (DT a) (NN mandate) (S (VP (TO to) (VP (VB follow) (NP (DT that) (NN law)))))))) (, ,) (CC and) (S (NP (PRP we)) (VP (MD would) (VP (VB have) (S (VP (TO to) (VP (VB find) (PRT (RP out))))))))) (, ,) ('' '') (NP (PRP he)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a mandate to follow that law" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="mandate" />
            <token id="7" string="to" />
            <token id="8" string="follow" />
            <token id="9" string="that" />
            <token id="10" string="law" />
          </tokens>
        </chunking>
        <chunking id="2" string="that law" type="NP">
          <tokens>
            <token id="9" string="that" />
            <token id="10" string="law" />
          </tokens>
        </chunking>
        <chunking id="3" string="to follow that law" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="follow" />
            <token id="9" string="that" />
            <token id="10" string="law" />
          </tokens>
        </chunking>
        <chunking id="4" string="follow that law" type="VP">
          <tokens>
            <token id="8" string="follow" />
            <token id="9" string="that" />
            <token id="10" string="law" />
          </tokens>
        </chunking>
        <chunking id="5" string="would have to find out" type="VP">
          <tokens>
            <token id="14" string="would" />
            <token id="15" string="have" />
            <token id="16" string="to" />
            <token id="17" string="find" />
            <token id="18" string="out" />
          </tokens>
        </chunking>
        <chunking id="6" string="to find out" type="VP">
          <tokens>
            <token id="16" string="to" />
            <token id="17" string="find" />
            <token id="18" string="out" />
          </tokens>
        </chunking>
        <chunking id="7" string="have to find out" type="VP">
          <tokens>
            <token id="15" string="have" />
            <token id="16" string="to" />
            <token id="17" string="find" />
            <token id="18" string="out" />
          </tokens>
        </chunking>
        <chunking id="8" string="find out" type="VP">
          <tokens>
            <token id="17" string="find" />
            <token id="18" string="out" />
          </tokens>
        </chunking>
        <chunking id="9" string="have a mandate to follow that law" type="VP">
          <tokens>
            <token id="4" string="have" />
            <token id="5" string="a" />
            <token id="6" string="mandate" />
            <token id="7" string="to" />
            <token id="8" string="follow" />
            <token id="9" string="that" />
            <token id="10" string="law" />
          </tokens>
        </chunking>
        <chunking id="10" string="he" type="NP">
          <tokens>
            <token id="21" string="he" />
          </tokens>
        </chunking>
        <chunking id="11" string="we" type="NP">
          <tokens>
            <token id="3" string="we" />
          </tokens>
        </chunking>
        <chunking id="12" string="said" type="VP">
          <tokens>
            <token id="22" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="4">have</governor>
          <dependent id="2">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">have</governor>
          <dependent id="3">we</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="22">said</governor>
          <dependent id="4">have</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">mandate</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">have</governor>
          <dependent id="6">mandate</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">follow</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="6">mandate</governor>
          <dependent id="8">follow</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">law</governor>
          <dependent id="9">that</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">follow</governor>
          <dependent id="10">law</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">have</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">have</governor>
          <dependent id="13">we</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">have</governor>
          <dependent id="14">would</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">have</governor>
          <dependent id="15">have</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">find</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="15">have</governor>
          <dependent id="17">find</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="17">find</governor>
          <dependent id="18">out</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">said</governor>
          <dependent id="21">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="22">said</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="43" has_coreference="false">
      <content>Opponents of a ban on counting illegal aliens said that a ban is impractical because the Census Bureau has already printed questionnaires that do not contain any question about legality of residence.</content>
      <tokens>
        <token id="1" string="Opponents" lemma="opponent" stem="opponent" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="ban" lemma="ban" stem="ban" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="counting" lemma="count" stem="count" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="aliens" lemma="alien" stem="alien" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="ban" lemma="ban" stem="ban" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="impractical" lemma="impractical" stem="impract" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Census" lemma="Census" stem="censu" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="18" string="Bureau" lemma="Bureau" stem="bureau" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="19" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="already" lemma="already" stem="alreadi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="printed" lemma="print" stem="print" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="questionnaires" lemma="questionnaire" stem="questionnair" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="contain" lemma="contain" stem="contain" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="question" lemma="question" stem="question" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="legality" lemma="legality" stem="legal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="residence" lemma="residence" stem="resid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNS Opponents)) (PP (IN of) (NP (NP (DT a) (NN ban)) (PP (IN on) (NP (VBG counting) (JJ illegal) (NNS aliens)))))) (VP (VBD said) (SBAR (IN that) (S (NP (DT a) (NN ban)) (VP (VBZ is) (ADJP (JJ impractical)) (SBAR (IN because) (S (NP (DT the) (NNP Census) (NNP Bureau)) (VP (VBZ has) (ADVP (RB already)) (VP (VBN printed) (NP (NP (NNS questionnaires)) (SBAR (WHNP (WDT that)) (S (VP (VBP do) (RB not) (VP (VB contain) (NP (DT any) (NN question)) (PP (IN about) (NP (NP (NN legality)) (PP (IN of) (NP (NN residence)))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="any question" type="NP">
          <tokens>
            <token id="27" string="any" />
            <token id="28" string="question" />
          </tokens>
        </chunking>
        <chunking id="2" string="that a ban is impractical because the Census Bureau has already printed questionnaires that do not contain any question about legality of residence" type="SBAR">
          <tokens>
            <token id="10" string="that" />
            <token id="11" string="a" />
            <token id="12" string="ban" />
            <token id="13" string="is" />
            <token id="14" string="impractical" />
            <token id="15" string="because" />
            <token id="16" string="the" />
            <token id="17" string="Census" />
            <token id="18" string="Bureau" />
            <token id="19" string="has" />
            <token id="20" string="already" />
            <token id="21" string="printed" />
            <token id="22" string="questionnaires" />
            <token id="23" string="that" />
            <token id="24" string="do" />
            <token id="25" string="not" />
            <token id="26" string="contain" />
            <token id="27" string="any" />
            <token id="28" string="question" />
            <token id="29" string="about" />
            <token id="30" string="legality" />
            <token id="31" string="of" />
            <token id="32" string="residence" />
          </tokens>
        </chunking>
        <chunking id="3" string="legality of residence" type="NP">
          <tokens>
            <token id="30" string="legality" />
            <token id="31" string="of" />
            <token id="32" string="residence" />
          </tokens>
        </chunking>
        <chunking id="4" string="the Census Bureau" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="Census" />
            <token id="18" string="Bureau" />
          </tokens>
        </chunking>
        <chunking id="5" string="a ban on counting illegal aliens" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="ban" />
            <token id="5" string="on" />
            <token id="6" string="counting" />
            <token id="7" string="illegal" />
            <token id="8" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="6" string="a ban" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="ban" />
          </tokens>
        </chunking>
        <chunking id="7" string="that do not contain any question about legality of residence" type="SBAR">
          <tokens>
            <token id="23" string="that" />
            <token id="24" string="do" />
            <token id="25" string="not" />
            <token id="26" string="contain" />
            <token id="27" string="any" />
            <token id="28" string="question" />
            <token id="29" string="about" />
            <token id="30" string="legality" />
            <token id="31" string="of" />
            <token id="32" string="residence" />
          </tokens>
        </chunking>
        <chunking id="8" string="contain any question about legality of residence" type="VP">
          <tokens>
            <token id="26" string="contain" />
            <token id="27" string="any" />
            <token id="28" string="question" />
            <token id="29" string="about" />
            <token id="30" string="legality" />
            <token id="31" string="of" />
            <token id="32" string="residence" />
          </tokens>
        </chunking>
        <chunking id="9" string="questionnaires" type="NP">
          <tokens>
            <token id="22" string="questionnaires" />
          </tokens>
        </chunking>
        <chunking id="10" string="questionnaires that do not contain any question about legality of residence" type="NP">
          <tokens>
            <token id="22" string="questionnaires" />
            <token id="23" string="that" />
            <token id="24" string="do" />
            <token id="25" string="not" />
            <token id="26" string="contain" />
            <token id="27" string="any" />
            <token id="28" string="question" />
            <token id="29" string="about" />
            <token id="30" string="legality" />
            <token id="31" string="of" />
            <token id="32" string="residence" />
          </tokens>
        </chunking>
        <chunking id="11" string="said that a ban is impractical because the Census Bureau has already printed questionnaires that do not contain any question about legality of residence" type="VP">
          <tokens>
            <token id="9" string="said" />
            <token id="10" string="that" />
            <token id="11" string="a" />
            <token id="12" string="ban" />
            <token id="13" string="is" />
            <token id="14" string="impractical" />
            <token id="15" string="because" />
            <token id="16" string="the" />
            <token id="17" string="Census" />
            <token id="18" string="Bureau" />
            <token id="19" string="has" />
            <token id="20" string="already" />
            <token id="21" string="printed" />
            <token id="22" string="questionnaires" />
            <token id="23" string="that" />
            <token id="24" string="do" />
            <token id="25" string="not" />
            <token id="26" string="contain" />
            <token id="27" string="any" />
            <token id="28" string="question" />
            <token id="29" string="about" />
            <token id="30" string="legality" />
            <token id="31" string="of" />
            <token id="32" string="residence" />
          </tokens>
        </chunking>
        <chunking id="12" string="counting illegal aliens" type="NP">
          <tokens>
            <token id="6" string="counting" />
            <token id="7" string="illegal" />
            <token id="8" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="13" string="because the Census Bureau has already printed questionnaires that do not contain any question about legality of residence" type="SBAR">
          <tokens>
            <token id="15" string="because" />
            <token id="16" string="the" />
            <token id="17" string="Census" />
            <token id="18" string="Bureau" />
            <token id="19" string="has" />
            <token id="20" string="already" />
            <token id="21" string="printed" />
            <token id="22" string="questionnaires" />
            <token id="23" string="that" />
            <token id="24" string="do" />
            <token id="25" string="not" />
            <token id="26" string="contain" />
            <token id="27" string="any" />
            <token id="28" string="question" />
            <token id="29" string="about" />
            <token id="30" string="legality" />
            <token id="31" string="of" />
            <token id="32" string="residence" />
          </tokens>
        </chunking>
        <chunking id="14" string="legality" type="NP">
          <tokens>
            <token id="30" string="legality" />
          </tokens>
        </chunking>
        <chunking id="15" string="Opponents of a ban on counting illegal aliens" type="NP">
          <tokens>
            <token id="1" string="Opponents" />
            <token id="2" string="of" />
            <token id="3" string="a" />
            <token id="4" string="ban" />
            <token id="5" string="on" />
            <token id="6" string="counting" />
            <token id="7" string="illegal" />
            <token id="8" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="16" string="Opponents" type="NP">
          <tokens>
            <token id="1" string="Opponents" />
          </tokens>
        </chunking>
        <chunking id="17" string="printed questionnaires that do not contain any question about legality of residence" type="VP">
          <tokens>
            <token id="21" string="printed" />
            <token id="22" string="questionnaires" />
            <token id="23" string="that" />
            <token id="24" string="do" />
            <token id="25" string="not" />
            <token id="26" string="contain" />
            <token id="27" string="any" />
            <token id="28" string="question" />
            <token id="29" string="about" />
            <token id="30" string="legality" />
            <token id="31" string="of" />
            <token id="32" string="residence" />
          </tokens>
        </chunking>
        <chunking id="18" string="has already printed questionnaires that do not contain any question about legality of residence" type="VP">
          <tokens>
            <token id="19" string="has" />
            <token id="20" string="already" />
            <token id="21" string="printed" />
            <token id="22" string="questionnaires" />
            <token id="23" string="that" />
            <token id="24" string="do" />
            <token id="25" string="not" />
            <token id="26" string="contain" />
            <token id="27" string="any" />
            <token id="28" string="question" />
            <token id="29" string="about" />
            <token id="30" string="legality" />
            <token id="31" string="of" />
            <token id="32" string="residence" />
          </tokens>
        </chunking>
        <chunking id="19" string="is impractical because the Census Bureau has already printed questionnaires that do not contain any question about legality of residence" type="VP">
          <tokens>
            <token id="13" string="is" />
            <token id="14" string="impractical" />
            <token id="15" string="because" />
            <token id="16" string="the" />
            <token id="17" string="Census" />
            <token id="18" string="Bureau" />
            <token id="19" string="has" />
            <token id="20" string="already" />
            <token id="21" string="printed" />
            <token id="22" string="questionnaires" />
            <token id="23" string="that" />
            <token id="24" string="do" />
            <token id="25" string="not" />
            <token id="26" string="contain" />
            <token id="27" string="any" />
            <token id="28" string="question" />
            <token id="29" string="about" />
            <token id="30" string="legality" />
            <token id="31" string="of" />
            <token id="32" string="residence" />
          </tokens>
        </chunking>
        <chunking id="20" string="impractical" type="ADJP">
          <tokens>
            <token id="14" string="impractical" />
          </tokens>
        </chunking>
        <chunking id="21" string="do not contain any question about legality of residence" type="VP">
          <tokens>
            <token id="24" string="do" />
            <token id="25" string="not" />
            <token id="26" string="contain" />
            <token id="27" string="any" />
            <token id="28" string="question" />
            <token id="29" string="about" />
            <token id="30" string="legality" />
            <token id="31" string="of" />
            <token id="32" string="residence" />
          </tokens>
        </chunking>
        <chunking id="22" string="residence" type="NP">
          <tokens>
            <token id="32" string="residence" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="9">said</governor>
          <dependent id="1">Opponents</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">ban</governor>
          <dependent id="2">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">ban</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Opponents</governor>
          <dependent id="4">ban</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">aliens</governor>
          <dependent id="5">on</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">aliens</governor>
          <dependent id="6">counting</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">aliens</governor>
          <dependent id="7">illegal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">ban</governor>
          <dependent id="8">aliens</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">said</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">impractical</governor>
          <dependent id="10">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">ban</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">impractical</governor>
          <dependent id="12">ban</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">impractical</governor>
          <dependent id="13">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">said</governor>
          <dependent id="14">impractical</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">printed</governor>
          <dependent id="15">because</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">Bureau</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Bureau</governor>
          <dependent id="17">Census</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">printed</governor>
          <dependent id="18">Bureau</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">printed</governor>
          <dependent id="19">has</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="21">printed</governor>
          <dependent id="20">already</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="14">impractical</governor>
          <dependent id="21">printed</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">printed</governor>
          <dependent id="22">questionnaires</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">contain</governor>
          <dependent id="23">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="26">contain</governor>
          <dependent id="24">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="26">contain</governor>
          <dependent id="25">not</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="22">questionnaires</governor>
          <dependent id="26">contain</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">question</governor>
          <dependent id="27">any</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="26">contain</governor>
          <dependent id="28">question</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">legality</governor>
          <dependent id="29">about</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">contain</governor>
          <dependent id="30">legality</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">residence</governor>
          <dependent id="31">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">legality</governor>
          <dependent id="32">residence</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Census Bureau" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="17" string="Census" />
            <token id="18" string="Bureau" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="44" has_coreference="true">
      <content>For 190 years, said Sen. Daniel Patrick Moynihan (D-N.Y.), the federal government has counted all inhabitants without regard to citizenship in accordance with the Constitution&amp;apost;s provisions.</content>
      <tokens>
        <token id="1" string="For" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="190" lemma="190" stem="190" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="3" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="Sen." lemma="Sen." stem="sen." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="Daniel" lemma="Daniel" stem="daniel" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="8" string="Patrick" lemma="Patrick" stem="patrick" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="9" string="Moynihan" lemma="Moynihan" stem="moynihan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="10" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="D-N.Y." lemma="D-N.Y." stem="d-n.y." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="federal" lemma="federal" stem="feder" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="government" lemma="government" stem="govern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="counted" lemma="count" stem="count" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="inhabitants" lemma="inhabitant" stem="inhabit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="without" lemma="without" stem="without" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="regard" lemma="regard" stem="regard" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="citizenship" lemma="citizenship" stem="citizenship" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="accordance" lemma="accordance" stem="accord" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="Constitution" lemma="Constitution" stem="constitut" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="provisions" lemma="provision" stem="provis" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN For) (NP (CD 190) (NNS years))) (PRN (, ,) (SINV (VP (VBD said)) (NP (NP (NNP Sen.) (NNP Daniel) (NNP Patrick) (NNP Moynihan)) (PRN (-LRB- -LRB-) (NP (NNP D-N.Y.)) (-RRB- -RRB-)))) (, ,)) (NP (DT the) (JJ federal) (NN government)) (VP (VBZ has) (VP (VBN counted) (NP (DT all) (NNS inhabitants)) (PP (IN without) (NP (NN regard))) (PP (TO to) (NP (NP (NN citizenship)) (PP (IN in) (NP (NN accordance))))) (PP (IN with) (NP (NP (DT the) (NNP Constitution) (POS 's)) (NNS provisions))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="citizenship" type="NP">
          <tokens>
            <token id="24" string="citizenship" />
          </tokens>
        </chunking>
        <chunking id="2" string="the federal government" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="federal" />
            <token id="16" string="government" />
          </tokens>
        </chunking>
        <chunking id="3" string="accordance" type="NP">
          <tokens>
            <token id="26" string="accordance" />
          </tokens>
        </chunking>
        <chunking id="4" string="the Constitution 's" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="Constitution" />
            <token id="30" string="'s" />
          </tokens>
        </chunking>
        <chunking id="5" string="190 years" type="NP">
          <tokens>
            <token id="2" string="190" />
            <token id="3" string="years" />
          </tokens>
        </chunking>
        <chunking id="6" string="Sen. Daniel Patrick Moynihan" type="NP">
          <tokens>
            <token id="6" string="Sen." />
            <token id="7" string="Daniel" />
            <token id="8" string="Patrick" />
            <token id="9" string="Moynihan" />
          </tokens>
        </chunking>
        <chunking id="7" string="has counted all inhabitants without regard to citizenship in accordance with the Constitution 's provisions" type="VP">
          <tokens>
            <token id="17" string="has" />
            <token id="18" string="counted" />
            <token id="19" string="all" />
            <token id="20" string="inhabitants" />
            <token id="21" string="without" />
            <token id="22" string="regard" />
            <token id="23" string="to" />
            <token id="24" string="citizenship" />
            <token id="25" string="in" />
            <token id="26" string="accordance" />
            <token id="27" string="with" />
            <token id="28" string="the" />
            <token id="29" string="Constitution" />
            <token id="30" string="'s" />
            <token id="31" string="provisions" />
          </tokens>
        </chunking>
        <chunking id="8" string="Sen. Daniel Patrick Moynihan -LRB- D-N.Y. -RRB-" type="NP">
          <tokens>
            <token id="6" string="Sen." />
            <token id="7" string="Daniel" />
            <token id="8" string="Patrick" />
            <token id="9" string="Moynihan" />
            <token id="10" string="(" />
            <token id="11" string="D-N.Y." />
            <token id="12" string=")" />
          </tokens>
        </chunking>
        <chunking id="9" string="citizenship in accordance" type="NP">
          <tokens>
            <token id="24" string="citizenship" />
            <token id="25" string="in" />
            <token id="26" string="accordance" />
          </tokens>
        </chunking>
        <chunking id="10" string="all inhabitants" type="NP">
          <tokens>
            <token id="19" string="all" />
            <token id="20" string="inhabitants" />
          </tokens>
        </chunking>
        <chunking id="11" string="the Constitution 's provisions" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="Constitution" />
            <token id="30" string="'s" />
            <token id="31" string="provisions" />
          </tokens>
        </chunking>
        <chunking id="12" string="regard" type="NP">
          <tokens>
            <token id="22" string="regard" />
          </tokens>
        </chunking>
        <chunking id="13" string="counted all inhabitants without regard to citizenship in accordance with the Constitution 's provisions" type="VP">
          <tokens>
            <token id="18" string="counted" />
            <token id="19" string="all" />
            <token id="20" string="inhabitants" />
            <token id="21" string="without" />
            <token id="22" string="regard" />
            <token id="23" string="to" />
            <token id="24" string="citizenship" />
            <token id="25" string="in" />
            <token id="26" string="accordance" />
            <token id="27" string="with" />
            <token id="28" string="the" />
            <token id="29" string="Constitution" />
            <token id="30" string="'s" />
            <token id="31" string="provisions" />
          </tokens>
        </chunking>
        <chunking id="14" string="D-N.Y." type="NP">
          <tokens>
            <token id="11" string="D-N.Y." />
          </tokens>
        </chunking>
        <chunking id="15" string="said" type="VP">
          <tokens>
            <token id="5" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">years</governor>
          <dependent id="1">For</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="3">years</governor>
          <dependent id="2">190</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">counted</governor>
          <dependent id="3">years</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="18">counted</governor>
          <dependent id="5">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Moynihan</governor>
          <dependent id="6">Sen.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Moynihan</governor>
          <dependent id="7">Daniel</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Moynihan</governor>
          <dependent id="8">Patrick</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">said</governor>
          <dependent id="9">Moynihan</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="9">Moynihan</governor>
          <dependent id="11">D-N.Y.</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">government</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">government</governor>
          <dependent id="15">federal</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">counted</governor>
          <dependent id="16">government</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">counted</governor>
          <dependent id="17">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">counted</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">inhabitants</governor>
          <dependent id="19">all</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">counted</governor>
          <dependent id="20">inhabitants</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">regard</governor>
          <dependent id="21">without</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">counted</governor>
          <dependent id="22">regard</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">citizenship</governor>
          <dependent id="23">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">counted</governor>
          <dependent id="24">citizenship</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">accordance</governor>
          <dependent id="25">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">citizenship</governor>
          <dependent id="26">accordance</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">provisions</governor>
          <dependent id="27">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">Constitution</governor>
          <dependent id="28">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="31">provisions</governor>
          <dependent id="29">Constitution</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">Constitution</governor>
          <dependent id="30">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">counted</governor>
          <dependent id="31">provisions</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="190 years" type="DURATION" score="0.0">
          <tokens>
            <token id="2" string="190" />
            <token id="3" string="years" />
          </tokens>
        </entity>
        <entity id="2" string="Daniel Patrick Moynihan" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Daniel" />
            <token id="8" string="Patrick" />
            <token id="9" string="Moynihan" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="45" has_coreference="true">
      <content>&amp;quot;Fiddling with the numbers&amp;quot; now will destroy confidence in the census results, he added.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Fiddling" lemma="fiddle" stem="fiddl" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="numbers" lemma="number" stem="number" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="8" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="destroy" lemma="destroy" stem="destroi" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="confidence" lemma="confidence" stem="confid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="census" lemma="census" stem="censu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="results" lemma="result" stem="result" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="added" lemma="add" stem="ad" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (`` ``) (S (VP (VBG Fiddling) (PP (IN with) (NP (DT the) (NNS numbers))))) ('' '') (VP (ADVP (RB now)) (MD will) (VP (VB destroy) (NP (NN confidence)) (PP (IN in) (NP (NP (DT the) (NN census)) (VP (VBZ results))))))) (, ,) (NP (PRP he)) (VP (VBD added)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="now will destroy confidence in the census results" type="VP">
          <tokens>
            <token id="7" string="now" />
            <token id="8" string="will" />
            <token id="9" string="destroy" />
            <token id="10" string="confidence" />
            <token id="11" string="in" />
            <token id="12" string="the" />
            <token id="13" string="census" />
            <token id="14" string="results" />
          </tokens>
        </chunking>
        <chunking id="2" string="the numbers" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="numbers" />
          </tokens>
        </chunking>
        <chunking id="3" string="destroy confidence in the census results" type="VP">
          <tokens>
            <token id="9" string="destroy" />
            <token id="10" string="confidence" />
            <token id="11" string="in" />
            <token id="12" string="the" />
            <token id="13" string="census" />
            <token id="14" string="results" />
          </tokens>
        </chunking>
        <chunking id="4" string="confidence" type="NP">
          <tokens>
            <token id="10" string="confidence" />
          </tokens>
        </chunking>
        <chunking id="5" string="the census results" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="census" />
            <token id="14" string="results" />
          </tokens>
        </chunking>
        <chunking id="6" string="the census" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="census" />
          </tokens>
        </chunking>
        <chunking id="7" string="added" type="VP">
          <tokens>
            <token id="17" string="added" />
          </tokens>
        </chunking>
        <chunking id="8" string="Fiddling with the numbers" type="VP">
          <tokens>
            <token id="2" string="Fiddling" />
            <token id="3" string="with" />
            <token id="4" string="the" />
            <token id="5" string="numbers" />
          </tokens>
        </chunking>
        <chunking id="9" string="he" type="NP">
          <tokens>
            <token id="16" string="he" />
          </tokens>
        </chunking>
        <chunking id="10" string="results" type="VP">
          <tokens>
            <token id="14" string="results" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="csubj">
          <governor id="9">destroy</governor>
          <dependent id="2">Fiddling</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">numbers</governor>
          <dependent id="3">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">numbers</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">Fiddling</governor>
          <dependent id="5">numbers</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">destroy</governor>
          <dependent id="7">now</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">destroy</governor>
          <dependent id="8">will</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">added</governor>
          <dependent id="9">destroy</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">destroy</governor>
          <dependent id="10">confidence</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">census</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">census</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">destroy</governor>
          <dependent id="13">census</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="13">census</governor>
          <dependent id="14">results</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">added</governor>
          <dependent id="16">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">added</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="7" string="now" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="46" has_coreference="true">
      <content>The Senate&amp;apost;s action was sharply criticized by Undersecretary of Commerce Michael Darby, but he voiced hope that it would be reversed by a Senate-House conference.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="Senate" lemma="Senate" stem="senat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="3" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="action" lemma="action" stem="action" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="sharply" lemma="sharply" stem="sharpli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="criticized" lemma="criticize" stem="critic" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Undersecretary" lemma="Undersecretary" stem="undersecretari" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="Commerce" lemma="Commerce" stem="commerc" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="Michael" lemma="Michael" stem="michael" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="13" string="Darby" lemma="Darby" stem="darbi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="voiced" lemma="voice" stem="voic" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="hope" lemma="hope" stem="hope" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="reversed" lemma="reverse" stem="revers" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="Senate-House" lemma="senate-house" stem="senate-hous" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="conference" lemma="conference" stem="confer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (DT The) (NNP Senate) (POS 's)) (NN action)) (VP (VBD was) (ADVP (RB sharply)) (VP (VBN criticized) (PP (IN by) (NP (NP (NNP Undersecretary)) (PP (IN of) (NP (NNP Commerce) (NNP Michael) (NNP Darby)))))))) (, ,) (CC but) (S (NP (PRP he)) (VP (VBD voiced) (NP (NN hope)) (SBAR (IN that) (S (NP (PRP it)) (VP (MD would) (VP (VB be) (VP (VBN reversed) (PP (IN by) (NP (DT a) (JJ Senate-House) (NN conference)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="voiced hope that it would be reversed by a Senate-House conference" type="VP">
          <tokens>
            <token id="17" string="voiced" />
            <token id="18" string="hope" />
            <token id="19" string="that" />
            <token id="20" string="it" />
            <token id="21" string="would" />
            <token id="22" string="be" />
            <token id="23" string="reversed" />
            <token id="24" string="by" />
            <token id="25" string="a" />
            <token id="26" string="Senate-House" />
            <token id="27" string="conference" />
          </tokens>
        </chunking>
        <chunking id="2" string="Commerce Michael Darby" type="NP">
          <tokens>
            <token id="11" string="Commerce" />
            <token id="12" string="Michael" />
            <token id="13" string="Darby" />
          </tokens>
        </chunking>
        <chunking id="3" string="it" type="NP">
          <tokens>
            <token id="20" string="it" />
          </tokens>
        </chunking>
        <chunking id="4" string="hope" type="NP">
          <tokens>
            <token id="18" string="hope" />
          </tokens>
        </chunking>
        <chunking id="5" string="that it would be reversed by a Senate-House conference" type="SBAR">
          <tokens>
            <token id="19" string="that" />
            <token id="20" string="it" />
            <token id="21" string="would" />
            <token id="22" string="be" />
            <token id="23" string="reversed" />
            <token id="24" string="by" />
            <token id="25" string="a" />
            <token id="26" string="Senate-House" />
            <token id="27" string="conference" />
          </tokens>
        </chunking>
        <chunking id="6" string="would be reversed by a Senate-House conference" type="VP">
          <tokens>
            <token id="21" string="would" />
            <token id="22" string="be" />
            <token id="23" string="reversed" />
            <token id="24" string="by" />
            <token id="25" string="a" />
            <token id="26" string="Senate-House" />
            <token id="27" string="conference" />
          </tokens>
        </chunking>
        <chunking id="7" string="criticized by Undersecretary of Commerce Michael Darby" type="VP">
          <tokens>
            <token id="7" string="criticized" />
            <token id="8" string="by" />
            <token id="9" string="Undersecretary" />
            <token id="10" string="of" />
            <token id="11" string="Commerce" />
            <token id="12" string="Michael" />
            <token id="13" string="Darby" />
          </tokens>
        </chunking>
        <chunking id="8" string="Undersecretary" type="NP">
          <tokens>
            <token id="9" string="Undersecretary" />
          </tokens>
        </chunking>
        <chunking id="9" string="The Senate 's action" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Senate" />
            <token id="3" string="'s" />
            <token id="4" string="action" />
          </tokens>
        </chunking>
        <chunking id="10" string="Undersecretary of Commerce Michael Darby" type="NP">
          <tokens>
            <token id="9" string="Undersecretary" />
            <token id="10" string="of" />
            <token id="11" string="Commerce" />
            <token id="12" string="Michael" />
            <token id="13" string="Darby" />
          </tokens>
        </chunking>
        <chunking id="11" string="be reversed by a Senate-House conference" type="VP">
          <tokens>
            <token id="22" string="be" />
            <token id="23" string="reversed" />
            <token id="24" string="by" />
            <token id="25" string="a" />
            <token id="26" string="Senate-House" />
            <token id="27" string="conference" />
          </tokens>
        </chunking>
        <chunking id="12" string="reversed by a Senate-House conference" type="VP">
          <tokens>
            <token id="23" string="reversed" />
            <token id="24" string="by" />
            <token id="25" string="a" />
            <token id="26" string="Senate-House" />
            <token id="27" string="conference" />
          </tokens>
        </chunking>
        <chunking id="13" string="The Senate 's" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Senate" />
            <token id="3" string="'s" />
          </tokens>
        </chunking>
        <chunking id="14" string="he" type="NP">
          <tokens>
            <token id="16" string="he" />
          </tokens>
        </chunking>
        <chunking id="15" string="a Senate-House conference" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="Senate-House" />
            <token id="27" string="conference" />
          </tokens>
        </chunking>
        <chunking id="16" string="was sharply criticized by Undersecretary of Commerce Michael Darby" type="VP">
          <tokens>
            <token id="5" string="was" />
            <token id="6" string="sharply" />
            <token id="7" string="criticized" />
            <token id="8" string="by" />
            <token id="9" string="Undersecretary" />
            <token id="10" string="of" />
            <token id="11" string="Commerce" />
            <token id="12" string="Michael" />
            <token id="13" string="Darby" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">Senate</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">action</governor>
          <dependent id="2">Senate</dependent>
        </dependency>
        <dependency type="case">
          <governor id="2">Senate</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="7">criticized</governor>
          <dependent id="4">action</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="7">criticized</governor>
          <dependent id="5">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">criticized</governor>
          <dependent id="6">sharply</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">criticized</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Undersecretary</governor>
          <dependent id="8">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">criticized</governor>
          <dependent id="9">Undersecretary</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Darby</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Darby</governor>
          <dependent id="11">Commerce</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Darby</governor>
          <dependent id="12">Michael</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">Undersecretary</governor>
          <dependent id="13">Darby</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">criticized</governor>
          <dependent id="15">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">voiced</governor>
          <dependent id="16">he</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">criticized</governor>
          <dependent id="17">voiced</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">voiced</governor>
          <dependent id="18">hope</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">reversed</governor>
          <dependent id="19">that</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="23">reversed</governor>
          <dependent id="20">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="23">reversed</governor>
          <dependent id="21">would</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="23">reversed</governor>
          <dependent id="22">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">voiced</governor>
          <dependent id="23">reversed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">conference</governor>
          <dependent id="24">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">conference</governor>
          <dependent id="25">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">conference</governor>
          <dependent id="26">Senate-House</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">reversed</governor>
          <dependent id="27">conference</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Senate" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="2" string="Senate" />
          </tokens>
        </entity>
        <entity id="2" string="Michael Darby" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Michael" />
            <token id="13" string="Darby" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="47" has_coreference="true">
      <content>&amp;quot;There really is a widespread realization that this would not only be unconstitutional but literally impossible,&amp;quot; Darby said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="really" lemma="really" stem="realli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="widespread" lemma="widespread" stem="widespread" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="realization" lemma="realization" stem="realiz" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="unconstitutional" lemma="unconstitutional" stem="unconstitut" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="literally" lemma="literally" stem="liter" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="impossible" lemma="impossible" stem="imposs" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Darby" lemma="Darby" stem="darbi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="21" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (EX There)) (ADVP (RB really)) (VP (VBZ is) (NP (DT a) (JJ widespread) (NN realization)) (SBAR (IN that) (S (NP (DT this)) (VP (MD would) (RB not) (ADVP (RB only)) (VP (VB be) (ADJP (ADJP (JJ unconstitutional)) (CC but) (ADJP (ADVP (RB literally)) (JJ impossible))))))))) (, ,) ('' '') (NP (NNP Darby)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="be unconstitutional but literally impossible" type="VP">
          <tokens>
            <token id="13" string="be" />
            <token id="14" string="unconstitutional" />
            <token id="15" string="but" />
            <token id="16" string="literally" />
            <token id="17" string="impossible" />
          </tokens>
        </chunking>
        <chunking id="2" string="There" type="NP">
          <tokens>
            <token id="2" string="There" />
          </tokens>
        </chunking>
        <chunking id="3" string="that this would not only be unconstitutional but literally impossible" type="SBAR">
          <tokens>
            <token id="8" string="that" />
            <token id="9" string="this" />
            <token id="10" string="would" />
            <token id="11" string="not" />
            <token id="12" string="only" />
            <token id="13" string="be" />
            <token id="14" string="unconstitutional" />
            <token id="15" string="but" />
            <token id="16" string="literally" />
            <token id="17" string="impossible" />
          </tokens>
        </chunking>
        <chunking id="4" string="Darby" type="NP">
          <tokens>
            <token id="20" string="Darby" />
          </tokens>
        </chunking>
        <chunking id="5" string="unconstitutional but literally impossible" type="ADJP">
          <tokens>
            <token id="14" string="unconstitutional" />
            <token id="15" string="but" />
            <token id="16" string="literally" />
            <token id="17" string="impossible" />
          </tokens>
        </chunking>
        <chunking id="6" string="literally impossible" type="ADJP">
          <tokens>
            <token id="16" string="literally" />
            <token id="17" string="impossible" />
          </tokens>
        </chunking>
        <chunking id="7" string="this" type="NP">
          <tokens>
            <token id="9" string="this" />
          </tokens>
        </chunking>
        <chunking id="8" string="would not only be unconstitutional but literally impossible" type="VP">
          <tokens>
            <token id="10" string="would" />
            <token id="11" string="not" />
            <token id="12" string="only" />
            <token id="13" string="be" />
            <token id="14" string="unconstitutional" />
            <token id="15" string="but" />
            <token id="16" string="literally" />
            <token id="17" string="impossible" />
          </tokens>
        </chunking>
        <chunking id="9" string="a widespread realization" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="widespread" />
            <token id="7" string="realization" />
          </tokens>
        </chunking>
        <chunking id="10" string="said" type="VP">
          <tokens>
            <token id="21" string="said" />
          </tokens>
        </chunking>
        <chunking id="11" string="is a widespread realization that this would not only be unconstitutional but literally impossible" type="VP">
          <tokens>
            <token id="4" string="is" />
            <token id="5" string="a" />
            <token id="6" string="widespread" />
            <token id="7" string="realization" />
            <token id="8" string="that" />
            <token id="9" string="this" />
            <token id="10" string="would" />
            <token id="11" string="not" />
            <token id="12" string="only" />
            <token id="13" string="be" />
            <token id="14" string="unconstitutional" />
            <token id="15" string="but" />
            <token id="16" string="literally" />
            <token id="17" string="impossible" />
          </tokens>
        </chunking>
        <chunking id="12" string="unconstitutional" type="ADJP">
          <tokens>
            <token id="14" string="unconstitutional" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="4">is</governor>
          <dependent id="2">There</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">is</governor>
          <dependent id="3">really</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="21">said</governor>
          <dependent id="4">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">realization</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">realization</governor>
          <dependent id="6">widespread</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">is</governor>
          <dependent id="7">realization</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">unconstitutional</governor>
          <dependent id="8">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">unconstitutional</governor>
          <dependent id="9">this</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">unconstitutional</governor>
          <dependent id="10">would</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="14">unconstitutional</governor>
          <dependent id="11">not</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">unconstitutional</governor>
          <dependent id="12">only</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">unconstitutional</governor>
          <dependent id="13">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">is</governor>
          <dependent id="14">unconstitutional</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">unconstitutional</governor>
          <dependent id="15">but</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">impossible</governor>
          <dependent id="16">literally</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">unconstitutional</governor>
          <dependent id="17">impossible</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">said</governor>
          <dependent id="20">Darby</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="21">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Darby" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="Darby" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="48" has_coreference="true">
      <content>But he added that he is &amp;quot;optimistic, cautiously optimistic,&amp;quot; that House conferees would resist the Senate-approved ban and not force Bush to veto the legislation.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="added" lemma="add" stem="ad" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="optimistic" lemma="optimistic" stem="optimist" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="cautiously" lemma="cautiously" stem="cautious" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="optimistic" lemma="optimistic" stem="optimist" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="House" lemma="House" stem="hous" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="16" string="conferees" lemma="conferee" stem="confere" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="resist" lemma="resist" stem="resist" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Senate-approved" lemma="senate-approved" stem="senate-approv" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="21" string="ban" lemma="ban" stem="ban" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="force" lemma="force" stem="forc" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="Bush" lemma="Bush" stem="bush" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="26" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="veto" lemma="veto" stem="veto" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="legislation" lemma="legislation" stem="legisl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (PRP he)) (VP (VBD added) (SBAR (IN that) (S (NP (PRP he)) (VP (VBZ is) (ADJP (`` ``) (JJ optimistic) (, ,) (RB cautiously) (JJ optimistic)) (, ,) ('' '') (SBAR (IN that) (S (NP (NNP House) (NNS conferees)) (VP (MD would) (VP (VP (VB resist) (NP (DT the) (JJ Senate-approved) (NN ban))) (CC and) (RB not) (VP (VB force) (S (NP (NNP Bush)) (VP (TO to) (VP (VB veto) (NP (DT the) (NN legislation)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="added that he is `` optimistic , cautiously optimistic , '' that House conferees would resist the Senate-approved ban and not force Bush to veto the legislation" type="VP">
          <tokens>
            <token id="3" string="added" />
            <token id="4" string="that" />
            <token id="5" string="he" />
            <token id="6" string="is" />
            <token id="7" string="&quot;" />
            <token id="8" string="optimistic" />
            <token id="9" string="," />
            <token id="10" string="cautiously" />
            <token id="11" string="optimistic" />
            <token id="12" string="," />
            <token id="13" string="&quot;" />
            <token id="14" string="that" />
            <token id="15" string="House" />
            <token id="16" string="conferees" />
            <token id="17" string="would" />
            <token id="18" string="resist" />
            <token id="19" string="the" />
            <token id="20" string="Senate-approved" />
            <token id="21" string="ban" />
            <token id="22" string="and" />
            <token id="23" string="not" />
            <token id="24" string="force" />
            <token id="25" string="Bush" />
            <token id="26" string="to" />
            <token id="27" string="veto" />
            <token id="28" string="the" />
            <token id="29" string="legislation" />
          </tokens>
        </chunking>
        <chunking id="2" string="veto the legislation" type="VP">
          <tokens>
            <token id="27" string="veto" />
            <token id="28" string="the" />
            <token id="29" string="legislation" />
          </tokens>
        </chunking>
        <chunking id="3" string="the Senate-approved ban" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="Senate-approved" />
            <token id="21" string="ban" />
          </tokens>
        </chunking>
        <chunking id="4" string="`` optimistic , cautiously optimistic" type="ADJP">
          <tokens>
            <token id="7" string="&quot;" />
            <token id="8" string="optimistic" />
            <token id="9" string="," />
            <token id="10" string="cautiously" />
            <token id="11" string="optimistic" />
          </tokens>
        </chunking>
        <chunking id="5" string="is `` optimistic , cautiously optimistic , '' that House conferees would resist the Senate-approved ban and not force Bush to veto the legislation" type="VP">
          <tokens>
            <token id="6" string="is" />
            <token id="7" string="&quot;" />
            <token id="8" string="optimistic" />
            <token id="9" string="," />
            <token id="10" string="cautiously" />
            <token id="11" string="optimistic" />
            <token id="12" string="," />
            <token id="13" string="&quot;" />
            <token id="14" string="that" />
            <token id="15" string="House" />
            <token id="16" string="conferees" />
            <token id="17" string="would" />
            <token id="18" string="resist" />
            <token id="19" string="the" />
            <token id="20" string="Senate-approved" />
            <token id="21" string="ban" />
            <token id="22" string="and" />
            <token id="23" string="not" />
            <token id="24" string="force" />
            <token id="25" string="Bush" />
            <token id="26" string="to" />
            <token id="27" string="veto" />
            <token id="28" string="the" />
            <token id="29" string="legislation" />
          </tokens>
        </chunking>
        <chunking id="6" string="would resist the Senate-approved ban and not force Bush to veto the legislation" type="VP">
          <tokens>
            <token id="17" string="would" />
            <token id="18" string="resist" />
            <token id="19" string="the" />
            <token id="20" string="Senate-approved" />
            <token id="21" string="ban" />
            <token id="22" string="and" />
            <token id="23" string="not" />
            <token id="24" string="force" />
            <token id="25" string="Bush" />
            <token id="26" string="to" />
            <token id="27" string="veto" />
            <token id="28" string="the" />
            <token id="29" string="legislation" />
          </tokens>
        </chunking>
        <chunking id="7" string="resist the Senate-approved ban and not force Bush to veto the legislation" type="VP">
          <tokens>
            <token id="18" string="resist" />
            <token id="19" string="the" />
            <token id="20" string="Senate-approved" />
            <token id="21" string="ban" />
            <token id="22" string="and" />
            <token id="23" string="not" />
            <token id="24" string="force" />
            <token id="25" string="Bush" />
            <token id="26" string="to" />
            <token id="27" string="veto" />
            <token id="28" string="the" />
            <token id="29" string="legislation" />
          </tokens>
        </chunking>
        <chunking id="8" string="to veto the legislation" type="VP">
          <tokens>
            <token id="26" string="to" />
            <token id="27" string="veto" />
            <token id="28" string="the" />
            <token id="29" string="legislation" />
          </tokens>
        </chunking>
        <chunking id="9" string="House conferees" type="NP">
          <tokens>
            <token id="15" string="House" />
            <token id="16" string="conferees" />
          </tokens>
        </chunking>
        <chunking id="10" string="Bush" type="NP">
          <tokens>
            <token id="25" string="Bush" />
          </tokens>
        </chunking>
        <chunking id="11" string="resist the Senate-approved ban" type="VP">
          <tokens>
            <token id="18" string="resist" />
            <token id="19" string="the" />
            <token id="20" string="Senate-approved" />
            <token id="21" string="ban" />
          </tokens>
        </chunking>
        <chunking id="12" string="that he is `` optimistic , cautiously optimistic , '' that House conferees would resist the Senate-approved ban and not force Bush to veto the legislation" type="SBAR">
          <tokens>
            <token id="4" string="that" />
            <token id="5" string="he" />
            <token id="6" string="is" />
            <token id="7" string="&quot;" />
            <token id="8" string="optimistic" />
            <token id="9" string="," />
            <token id="10" string="cautiously" />
            <token id="11" string="optimistic" />
            <token id="12" string="," />
            <token id="13" string="&quot;" />
            <token id="14" string="that" />
            <token id="15" string="House" />
            <token id="16" string="conferees" />
            <token id="17" string="would" />
            <token id="18" string="resist" />
            <token id="19" string="the" />
            <token id="20" string="Senate-approved" />
            <token id="21" string="ban" />
            <token id="22" string="and" />
            <token id="23" string="not" />
            <token id="24" string="force" />
            <token id="25" string="Bush" />
            <token id="26" string="to" />
            <token id="27" string="veto" />
            <token id="28" string="the" />
            <token id="29" string="legislation" />
          </tokens>
        </chunking>
        <chunking id="13" string="that House conferees would resist the Senate-approved ban and not force Bush to veto the legislation" type="SBAR">
          <tokens>
            <token id="14" string="that" />
            <token id="15" string="House" />
            <token id="16" string="conferees" />
            <token id="17" string="would" />
            <token id="18" string="resist" />
            <token id="19" string="the" />
            <token id="20" string="Senate-approved" />
            <token id="21" string="ban" />
            <token id="22" string="and" />
            <token id="23" string="not" />
            <token id="24" string="force" />
            <token id="25" string="Bush" />
            <token id="26" string="to" />
            <token id="27" string="veto" />
            <token id="28" string="the" />
            <token id="29" string="legislation" />
          </tokens>
        </chunking>
        <chunking id="14" string="the legislation" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="legislation" />
          </tokens>
        </chunking>
        <chunking id="15" string="he" type="NP">
          <tokens>
            <token id="2" string="he" />
          </tokens>
        </chunking>
        <chunking id="16" string="force Bush to veto the legislation" type="VP">
          <tokens>
            <token id="24" string="force" />
            <token id="25" string="Bush" />
            <token id="26" string="to" />
            <token id="27" string="veto" />
            <token id="28" string="the" />
            <token id="29" string="legislation" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="3">added</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">added</governor>
          <dependent id="2">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">added</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">optimistic</governor>
          <dependent id="4">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">optimistic</governor>
          <dependent id="5">he</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">optimistic</governor>
          <dependent id="6">is</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">optimistic</governor>
          <dependent id="8">optimistic</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">optimistic</governor>
          <dependent id="10">cautiously</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">added</governor>
          <dependent id="11">optimistic</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">resist</governor>
          <dependent id="14">that</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">conferees</governor>
          <dependent id="15">House</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">resist</governor>
          <dependent id="16">conferees</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">resist</governor>
          <dependent id="17">would</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">optimistic</governor>
          <dependent id="18">resist</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">ban</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">ban</governor>
          <dependent id="20">Senate-approved</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">resist</governor>
          <dependent id="21">ban</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="18">resist</governor>
          <dependent id="22">and</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="24">force</governor>
          <dependent id="23">not</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">resist</governor>
          <dependent id="24">force</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">force</governor>
          <dependent id="25">Bush</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="27">veto</governor>
          <dependent id="26">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="24">force</governor>
          <dependent id="27">veto</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">legislation</governor>
          <dependent id="28">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="27">veto</governor>
          <dependent id="29">legislation</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="House" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="15" string="House" />
          </tokens>
        </entity>
        <entity id="2" string="Bush" type="PERSON" score="0.0">
          <tokens>
            <token id="25" string="Bush" />
          </tokens>
        </entity>
        <entity id="3" string="Senate-approved" type="MISC" score="0.0">
          <tokens>
            <token id="20" string="Senate-approved" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="49" has_coreference="true">
      <content>Mario Moreno, head of the Mexican American Legal Defense Fund, said he was shocked by the Senate&amp;apost;s decision.</content>
      <tokens>
        <token id="1" string="Mario" lemma="Mario" stem="mario" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Moreno" lemma="Moreno" stem="moreno" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="head" lemma="head" stem="head" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="Mexican" lemma="mexican" stem="mexican" pos="JJ" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="8" string="American" lemma="american" stem="american" pos="JJ" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="9" string="Legal" lemma="Legal" stem="legal" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="10" string="Defense" lemma="Defense" stem="defens" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="11" string="Fund" lemma="Fund" stem="fund" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="shocked" lemma="shock" stem="shock" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="Senate" lemma="Senate" stem="senat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="20" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="decision" lemma="decision" stem="decis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Mario) (NNP Moreno)) (, ,) (NP (NP (NP (NN head)) (PP (IN of) (NP (DT the) (JJ Mexican) (JJ American) (NNP Legal)))) (NP (NNP Defense) (NNP Fund))) (, ,)) (VP (VBD said) (SBAR (S (NP (PRP he)) (VP (VBD was) (VP (VBN shocked) (PP (IN by) (NP (NP (DT the) (NNP Senate) (POS 's)) (NN decision)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="said he was shocked by the Senate 's decision" type="VP">
          <tokens>
            <token id="13" string="said" />
            <token id="14" string="he" />
            <token id="15" string="was" />
            <token id="16" string="shocked" />
            <token id="17" string="by" />
            <token id="18" string="the" />
            <token id="19" string="Senate" />
            <token id="20" string="'s" />
            <token id="21" string="decision" />
          </tokens>
        </chunking>
        <chunking id="2" string="head of the Mexican American Legal Defense Fund" type="NP">
          <tokens>
            <token id="4" string="head" />
            <token id="5" string="of" />
            <token id="6" string="the" />
            <token id="7" string="Mexican" />
            <token id="8" string="American" />
            <token id="9" string="Legal" />
            <token id="10" string="Defense" />
            <token id="11" string="Fund" />
          </tokens>
        </chunking>
        <chunking id="3" string="shocked by the Senate 's decision" type="VP">
          <tokens>
            <token id="16" string="shocked" />
            <token id="17" string="by" />
            <token id="18" string="the" />
            <token id="19" string="Senate" />
            <token id="20" string="'s" />
            <token id="21" string="decision" />
          </tokens>
        </chunking>
        <chunking id="4" string="he was shocked by the Senate 's decision" type="SBAR">
          <tokens>
            <token id="14" string="he" />
            <token id="15" string="was" />
            <token id="16" string="shocked" />
            <token id="17" string="by" />
            <token id="18" string="the" />
            <token id="19" string="Senate" />
            <token id="20" string="'s" />
            <token id="21" string="decision" />
          </tokens>
        </chunking>
        <chunking id="5" string="Mario Moreno" type="NP">
          <tokens>
            <token id="1" string="Mario" />
            <token id="2" string="Moreno" />
          </tokens>
        </chunking>
        <chunking id="6" string="was shocked by the Senate 's decision" type="VP">
          <tokens>
            <token id="15" string="was" />
            <token id="16" string="shocked" />
            <token id="17" string="by" />
            <token id="18" string="the" />
            <token id="19" string="Senate" />
            <token id="20" string="'s" />
            <token id="21" string="decision" />
          </tokens>
        </chunking>
        <chunking id="7" string="head" type="NP">
          <tokens>
            <token id="4" string="head" />
          </tokens>
        </chunking>
        <chunking id="8" string="the Senate 's decision" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="Senate" />
            <token id="20" string="'s" />
            <token id="21" string="decision" />
          </tokens>
        </chunking>
        <chunking id="9" string="the Mexican American Legal" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="Mexican" />
            <token id="8" string="American" />
            <token id="9" string="Legal" />
          </tokens>
        </chunking>
        <chunking id="10" string="Mario Moreno , head of the Mexican American Legal Defense Fund ," type="NP">
          <tokens>
            <token id="1" string="Mario" />
            <token id="2" string="Moreno" />
            <token id="3" string="," />
            <token id="4" string="head" />
            <token id="5" string="of" />
            <token id="6" string="the" />
            <token id="7" string="Mexican" />
            <token id="8" string="American" />
            <token id="9" string="Legal" />
            <token id="10" string="Defense" />
            <token id="11" string="Fund" />
            <token id="12" string="," />
          </tokens>
        </chunking>
        <chunking id="11" string="the Senate 's" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="Senate" />
            <token id="20" string="'s" />
          </tokens>
        </chunking>
        <chunking id="12" string="head of the Mexican American Legal" type="NP">
          <tokens>
            <token id="4" string="head" />
            <token id="5" string="of" />
            <token id="6" string="the" />
            <token id="7" string="Mexican" />
            <token id="8" string="American" />
            <token id="9" string="Legal" />
          </tokens>
        </chunking>
        <chunking id="13" string="he" type="NP">
          <tokens>
            <token id="14" string="he" />
          </tokens>
        </chunking>
        <chunking id="14" string="Defense Fund" type="NP">
          <tokens>
            <token id="10" string="Defense" />
            <token id="11" string="Fund" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Moreno</governor>
          <dependent id="1">Mario</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">said</governor>
          <dependent id="2">Moreno</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">Moreno</governor>
          <dependent id="4">head</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Legal</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">Legal</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">Legal</governor>
          <dependent id="7">Mexican</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">Legal</governor>
          <dependent id="8">American</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">head</governor>
          <dependent id="9">Legal</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Fund</governor>
          <dependent id="10">Defense</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">head</governor>
          <dependent id="11">Fund</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">said</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="16">shocked</governor>
          <dependent id="14">he</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="16">shocked</governor>
          <dependent id="15">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">said</governor>
          <dependent id="16">shocked</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">decision</governor>
          <dependent id="17">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">Senate</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="21">decision</governor>
          <dependent id="19">Senate</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">Senate</governor>
          <dependent id="20">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">shocked</governor>
          <dependent id="21">decision</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Senate" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="19" string="Senate" />
          </tokens>
        </entity>
        <entity id="2" string="Mexican American Legal Defense Fund" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="7" string="Mexican" />
            <token id="8" string="American" />
            <token id="9" string="Legal" />
            <token id="10" string="Defense" />
            <token id="11" string="Fund" />
          </tokens>
        </entity>
        <entity id="3" string="Mario Moreno" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Mario" />
            <token id="2" string="Moreno" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="50" has_coreference="true">
      <content>&amp;quot;It is going to have a dramatic and disastrous impact in the Hispanic community,&amp;quot; Moreno said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="dramatic" lemma="dramatic" stem="dramat" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="disastrous" lemma="disastrous" stem="disastr" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="impact" lemma="impact" stem="impact" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Hispanic" lemma="hispanic" stem="hispan" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="15" string="community" lemma="community" stem="commun" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Moreno" lemma="Moreno" stem="moreno" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="19" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP It)) (VP (VBZ is) (VP (VBG going) (S (VP (TO to) (VP (VB have) (NP (NP (DT a) (ADJP (JJ dramatic) (CC and) (JJ disastrous)) (NN impact)) (PP (IN in) (NP (DT the) (JJ Hispanic) (NN community)))))))))) (, ,) ('' '') (NP (NNP Moreno)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is going to have a dramatic and disastrous impact in the Hispanic community" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="going" />
            <token id="5" string="to" />
            <token id="6" string="have" />
            <token id="7" string="a" />
            <token id="8" string="dramatic" />
            <token id="9" string="and" />
            <token id="10" string="disastrous" />
            <token id="11" string="impact" />
            <token id="12" string="in" />
            <token id="13" string="the" />
            <token id="14" string="Hispanic" />
            <token id="15" string="community" />
          </tokens>
        </chunking>
        <chunking id="2" string="dramatic and disastrous" type="ADJP">
          <tokens>
            <token id="8" string="dramatic" />
            <token id="9" string="and" />
            <token id="10" string="disastrous" />
          </tokens>
        </chunking>
        <chunking id="3" string="Moreno" type="NP">
          <tokens>
            <token id="18" string="Moreno" />
          </tokens>
        </chunking>
        <chunking id="4" string="to have a dramatic and disastrous impact in the Hispanic community" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="have" />
            <token id="7" string="a" />
            <token id="8" string="dramatic" />
            <token id="9" string="and" />
            <token id="10" string="disastrous" />
            <token id="11" string="impact" />
            <token id="12" string="in" />
            <token id="13" string="the" />
            <token id="14" string="Hispanic" />
            <token id="15" string="community" />
          </tokens>
        </chunking>
        <chunking id="5" string="have a dramatic and disastrous impact in the Hispanic community" type="VP">
          <tokens>
            <token id="6" string="have" />
            <token id="7" string="a" />
            <token id="8" string="dramatic" />
            <token id="9" string="and" />
            <token id="10" string="disastrous" />
            <token id="11" string="impact" />
            <token id="12" string="in" />
            <token id="13" string="the" />
            <token id="14" string="Hispanic" />
            <token id="15" string="community" />
          </tokens>
        </chunking>
        <chunking id="6" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="7" string="going to have a dramatic and disastrous impact in the Hispanic community" type="VP">
          <tokens>
            <token id="4" string="going" />
            <token id="5" string="to" />
            <token id="6" string="have" />
            <token id="7" string="a" />
            <token id="8" string="dramatic" />
            <token id="9" string="and" />
            <token id="10" string="disastrous" />
            <token id="11" string="impact" />
            <token id="12" string="in" />
            <token id="13" string="the" />
            <token id="14" string="Hispanic" />
            <token id="15" string="community" />
          </tokens>
        </chunking>
        <chunking id="8" string="a dramatic and disastrous impact" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="dramatic" />
            <token id="9" string="and" />
            <token id="10" string="disastrous" />
            <token id="11" string="impact" />
          </tokens>
        </chunking>
        <chunking id="9" string="said" type="VP">
          <tokens>
            <token id="19" string="said" />
          </tokens>
        </chunking>
        <chunking id="10" string="the Hispanic community" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="Hispanic" />
            <token id="15" string="community" />
          </tokens>
        </chunking>
        <chunking id="11" string="a dramatic and disastrous impact in the Hispanic community" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="dramatic" />
            <token id="9" string="and" />
            <token id="10" string="disastrous" />
            <token id="11" string="impact" />
            <token id="12" string="in" />
            <token id="13" string="the" />
            <token id="14" string="Hispanic" />
            <token id="15" string="community" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">going</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">going</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">said</governor>
          <dependent id="4">going</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">have</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">going</governor>
          <dependent id="6">have</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">impact</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">impact</governor>
          <dependent id="8">dramatic</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">dramatic</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">dramatic</governor>
          <dependent id="10">disastrous</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">have</governor>
          <dependent id="11">impact</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">community</governor>
          <dependent id="12">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">community</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">community</governor>
          <dependent id="14">Hispanic</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">impact</governor>
          <dependent id="15">community</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">said</governor>
          <dependent id="18">Moreno</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="19">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Moreno" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Moreno" />
          </tokens>
        </entity>
        <entity id="2" string="Hispanic" type="MISC" score="0.0">
          <tokens>
            <token id="14" string="Hispanic" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="51" has_coreference="true">
      <content>&amp;quot;People are going to be discouraged from participating.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="People" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="discouraged" lemma="discourage" stem="discourag" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="participating" lemma="participate" stem="particip" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (NNS People)) (VP (VBP are) (VP (VBG going) (S (VP (TO to) (VP (VB be) (VP (VBN discouraged) (PP (IN from) (S (VP (VBG participating)))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="discouraged from participating" type="VP">
          <tokens>
            <token id="7" string="discouraged" />
            <token id="8" string="from" />
            <token id="9" string="participating" />
          </tokens>
        </chunking>
        <chunking id="2" string="be discouraged from participating" type="VP">
          <tokens>
            <token id="6" string="be" />
            <token id="7" string="discouraged" />
            <token id="8" string="from" />
            <token id="9" string="participating" />
          </tokens>
        </chunking>
        <chunking id="3" string="are going to be discouraged from participating" type="VP">
          <tokens>
            <token id="3" string="are" />
            <token id="4" string="going" />
            <token id="5" string="to" />
            <token id="6" string="be" />
            <token id="7" string="discouraged" />
            <token id="8" string="from" />
            <token id="9" string="participating" />
          </tokens>
        </chunking>
        <chunking id="4" string="going to be discouraged from participating" type="VP">
          <tokens>
            <token id="4" string="going" />
            <token id="5" string="to" />
            <token id="6" string="be" />
            <token id="7" string="discouraged" />
            <token id="8" string="from" />
            <token id="9" string="participating" />
          </tokens>
        </chunking>
        <chunking id="5" string="People" type="NP">
          <tokens>
            <token id="2" string="People" />
          </tokens>
        </chunking>
        <chunking id="6" string="to be discouraged from participating" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="be" />
            <token id="7" string="discouraged" />
            <token id="8" string="from" />
            <token id="9" string="participating" />
          </tokens>
        </chunking>
        <chunking id="7" string="participating" type="VP">
          <tokens>
            <token id="9" string="participating" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">going</governor>
          <dependent id="2">People</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">going</governor>
          <dependent id="3">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">going</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">discouraged</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="7">discouraged</governor>
          <dependent id="6">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">going</governor>
          <dependent id="7">discouraged</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">participating</governor>
          <dependent id="8">from</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">discouraged</governor>
          <dependent id="9">participating</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="52" has_coreference="true">
      <content>A Census Bureau spokesman took a more dispassionate view, however.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Census" lemma="Census" stem="censu" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="3" string="Bureau" lemma="Bureau" stem="bureau" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="4" string="spokesman" lemma="spokesman" stem="spokesman" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="took" lemma="take" stem="took" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="dispassionate" lemma="dispassionate" stem="dispassion" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="view" lemma="view" stem="view" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="however" lemma="however" stem="howev" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT A) (NNP Census) (NNP Bureau) (NN spokesman)) (VP (VBD took) (NP (DT a) (ADJP (RBR more) (JJ dispassionate)) (NN view)) (, ,) (ADVP (RB however))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a more dispassionate view" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="more" />
            <token id="8" string="dispassionate" />
            <token id="9" string="view" />
          </tokens>
        </chunking>
        <chunking id="2" string="A Census Bureau spokesman" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="Census" />
            <token id="3" string="Bureau" />
            <token id="4" string="spokesman" />
          </tokens>
        </chunking>
        <chunking id="3" string="more dispassionate" type="ADJP">
          <tokens>
            <token id="7" string="more" />
            <token id="8" string="dispassionate" />
          </tokens>
        </chunking>
        <chunking id="4" string="took a more dispassionate view , however" type="VP">
          <tokens>
            <token id="5" string="took" />
            <token id="6" string="a" />
            <token id="7" string="more" />
            <token id="8" string="dispassionate" />
            <token id="9" string="view" />
            <token id="10" string="," />
            <token id="11" string="however" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">spokesman</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">spokesman</governor>
          <dependent id="2">Census</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">spokesman</governor>
          <dependent id="3">Bureau</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">took</governor>
          <dependent id="4">spokesman</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">took</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">view</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">dispassionate</governor>
          <dependent id="7">more</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">view</governor>
          <dependent id="8">dispassionate</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">took</governor>
          <dependent id="9">view</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">took</governor>
          <dependent id="11">however</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Census Bureau" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="2" string="Census" />
            <token id="3" string="Bureau" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="53" has_coreference="true">
      <content>&amp;quot;Our position is that we count everybody at their place of residence,&amp;quot; said bureau spokesman James Gorman.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Our" lemma="we" stem="our" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="3" string="position" lemma="position" stem="posit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="count" lemma="count" stem="count" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="everybody" lemma="everybody" stem="everybodi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="place" lemma="place" stem="place" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="residence" lemma="residence" stem="resid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="bureau" lemma="bureau" stem="bureau" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="spokesman" lemma="spokesman" stem="spokesman" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="James" lemma="James" stem="jame" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="20" string="Gorman" lemma="Gorman" stem="gorman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (PRP$ Our) (NN position)) (VP (VBZ is) (SBAR (IN that) (S (NP (PRP we)) (VP (VBP count) (NP (NN everybody)) (PP (IN at) (NP (NP (PRP$ their) (NN place)) (PP (IN of) (NP (NN residence)))))))))) (, ,) ('' '') (VP (VBD said)) (NP (NN bureau) (NN spokesman) (NNP James) (NNP Gorman)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Our position" type="NP">
          <tokens>
            <token id="2" string="Our" />
            <token id="3" string="position" />
          </tokens>
        </chunking>
        <chunking id="2" string="their place" type="NP">
          <tokens>
            <token id="10" string="their" />
            <token id="11" string="place" />
          </tokens>
        </chunking>
        <chunking id="3" string="everybody" type="NP">
          <tokens>
            <token id="8" string="everybody" />
          </tokens>
        </chunking>
        <chunking id="4" string="count everybody at their place of residence" type="VP">
          <tokens>
            <token id="7" string="count" />
            <token id="8" string="everybody" />
            <token id="9" string="at" />
            <token id="10" string="their" />
            <token id="11" string="place" />
            <token id="12" string="of" />
            <token id="13" string="residence" />
          </tokens>
        </chunking>
        <chunking id="5" string="their place of residence" type="NP">
          <tokens>
            <token id="10" string="their" />
            <token id="11" string="place" />
            <token id="12" string="of" />
            <token id="13" string="residence" />
          </tokens>
        </chunking>
        <chunking id="6" string="is that we count everybody at their place of residence" type="VP">
          <tokens>
            <token id="4" string="is" />
            <token id="5" string="that" />
            <token id="6" string="we" />
            <token id="7" string="count" />
            <token id="8" string="everybody" />
            <token id="9" string="at" />
            <token id="10" string="their" />
            <token id="11" string="place" />
            <token id="12" string="of" />
            <token id="13" string="residence" />
          </tokens>
        </chunking>
        <chunking id="7" string="bureau spokesman James Gorman" type="NP">
          <tokens>
            <token id="17" string="bureau" />
            <token id="18" string="spokesman" />
            <token id="19" string="James" />
            <token id="20" string="Gorman" />
          </tokens>
        </chunking>
        <chunking id="8" string="that we count everybody at their place of residence" type="SBAR">
          <tokens>
            <token id="5" string="that" />
            <token id="6" string="we" />
            <token id="7" string="count" />
            <token id="8" string="everybody" />
            <token id="9" string="at" />
            <token id="10" string="their" />
            <token id="11" string="place" />
            <token id="12" string="of" />
            <token id="13" string="residence" />
          </tokens>
        </chunking>
        <chunking id="9" string="we" type="NP">
          <tokens>
            <token id="6" string="we" />
          </tokens>
        </chunking>
        <chunking id="10" string="said" type="VP">
          <tokens>
            <token id="16" string="said" />
          </tokens>
        </chunking>
        <chunking id="11" string="residence" type="NP">
          <tokens>
            <token id="13" string="residence" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="3">position</governor>
          <dependent id="2">Our</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">is</governor>
          <dependent id="3">position</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">said</governor>
          <dependent id="4">is</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">count</governor>
          <dependent id="5">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">count</governor>
          <dependent id="6">we</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">is</governor>
          <dependent id="7">count</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">count</governor>
          <dependent id="8">everybody</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">place</governor>
          <dependent id="9">at</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">place</governor>
          <dependent id="10">their</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">count</governor>
          <dependent id="11">place</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">residence</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">place</governor>
          <dependent id="13">residence</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Gorman</governor>
          <dependent id="17">bureau</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Gorman</governor>
          <dependent id="18">spokesman</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Gorman</governor>
          <dependent id="19">James</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">said</governor>
          <dependent id="20">Gorman</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="James Gorman" type="PERSON" score="0.0">
          <tokens>
            <token id="19" string="James" />
            <token id="20" string="Gorman" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="54" has_coreference="true">
      <content>&amp;quot;If Congress passes a law that says we will or will not count people, we will do what it says.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="If" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Congress" lemma="Congress" stem="congress" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="4" string="passes" lemma="pass" stem="pass" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="law" lemma="law" stem="law" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="count" lemma="count" stem="count" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="do" lemma="do" stem="do" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (SBAR (IN If) (S (NP (NNP Congress)) (VP (VBZ passes) (NP (NP (DT a) (NN law)) (SBAR (WHNP (WDT that)) (S (VP (VBZ says) (SBAR (S (NP (PRP we)) (VP (MD will) (CC or) (MD will) (RB not) (VP (VB count) (NP (NNS people))))))))))))) (, ,) (NP (PRP we)) (VP (MD will) (VP (VB do) (SBAR (WHNP (WP what)) (S (NP (PRP it)) (VP (VBZ says)))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="If Congress passes a law that says we will or will not count people" type="SBAR">
          <tokens>
            <token id="2" string="If" />
            <token id="3" string="Congress" />
            <token id="4" string="passes" />
            <token id="5" string="a" />
            <token id="6" string="law" />
            <token id="7" string="that" />
            <token id="8" string="says" />
            <token id="9" string="we" />
            <token id="10" string="will" />
            <token id="11" string="or" />
            <token id="12" string="will" />
            <token id="13" string="not" />
            <token id="14" string="count" />
            <token id="15" string="people" />
          </tokens>
        </chunking>
        <chunking id="2" string="we will or will not count people" type="SBAR">
          <tokens>
            <token id="9" string="we" />
            <token id="10" string="will" />
            <token id="11" string="or" />
            <token id="12" string="will" />
            <token id="13" string="not" />
            <token id="14" string="count" />
            <token id="15" string="people" />
          </tokens>
        </chunking>
        <chunking id="3" string="a law" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="law" />
          </tokens>
        </chunking>
        <chunking id="4" string="do what it says" type="VP">
          <tokens>
            <token id="19" string="do" />
            <token id="20" string="what" />
            <token id="21" string="it" />
            <token id="22" string="says" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="21" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="will or will not count people" type="VP">
          <tokens>
            <token id="10" string="will" />
            <token id="11" string="or" />
            <token id="12" string="will" />
            <token id="13" string="not" />
            <token id="14" string="count" />
            <token id="15" string="people" />
          </tokens>
        </chunking>
        <chunking id="7" string="people" type="NP">
          <tokens>
            <token id="15" string="people" />
          </tokens>
        </chunking>
        <chunking id="8" string="we" type="NP">
          <tokens>
            <token id="9" string="we" />
          </tokens>
        </chunking>
        <chunking id="9" string="Congress" type="NP">
          <tokens>
            <token id="3" string="Congress" />
          </tokens>
        </chunking>
        <chunking id="10" string="what it says" type="SBAR">
          <tokens>
            <token id="20" string="what" />
            <token id="21" string="it" />
            <token id="22" string="says" />
          </tokens>
        </chunking>
        <chunking id="11" string="says" type="VP">
          <tokens>
            <token id="22" string="says" />
          </tokens>
        </chunking>
        <chunking id="12" string="that says we will or will not count people" type="SBAR">
          <tokens>
            <token id="7" string="that" />
            <token id="8" string="says" />
            <token id="9" string="we" />
            <token id="10" string="will" />
            <token id="11" string="or" />
            <token id="12" string="will" />
            <token id="13" string="not" />
            <token id="14" string="count" />
            <token id="15" string="people" />
          </tokens>
        </chunking>
        <chunking id="13" string="says we will or will not count people" type="VP">
          <tokens>
            <token id="8" string="says" />
            <token id="9" string="we" />
            <token id="10" string="will" />
            <token id="11" string="or" />
            <token id="12" string="will" />
            <token id="13" string="not" />
            <token id="14" string="count" />
            <token id="15" string="people" />
          </tokens>
        </chunking>
        <chunking id="14" string="a law that says we will or will not count people" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="law" />
            <token id="7" string="that" />
            <token id="8" string="says" />
            <token id="9" string="we" />
            <token id="10" string="will" />
            <token id="11" string="or" />
            <token id="12" string="will" />
            <token id="13" string="not" />
            <token id="14" string="count" />
            <token id="15" string="people" />
          </tokens>
        </chunking>
        <chunking id="15" string="will do what it says" type="VP">
          <tokens>
            <token id="18" string="will" />
            <token id="19" string="do" />
            <token id="20" string="what" />
            <token id="21" string="it" />
            <token id="22" string="says" />
          </tokens>
        </chunking>
        <chunking id="16" string="count people" type="VP">
          <tokens>
            <token id="14" string="count" />
            <token id="15" string="people" />
          </tokens>
        </chunking>
        <chunking id="17" string="passes a law that says we will or will not count people" type="VP">
          <tokens>
            <token id="4" string="passes" />
            <token id="5" string="a" />
            <token id="6" string="law" />
            <token id="7" string="that" />
            <token id="8" string="says" />
            <token id="9" string="we" />
            <token id="10" string="will" />
            <token id="11" string="or" />
            <token id="12" string="will" />
            <token id="13" string="not" />
            <token id="14" string="count" />
            <token id="15" string="people" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="4">passes</governor>
          <dependent id="2">If</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">passes</governor>
          <dependent id="3">Congress</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="19">do</governor>
          <dependent id="4">passes</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">law</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">passes</governor>
          <dependent id="6">law</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">says</governor>
          <dependent id="7">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="6">law</governor>
          <dependent id="8">says</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">count</governor>
          <dependent id="9">we</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">count</governor>
          <dependent id="10">will</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">count</governor>
          <dependent id="11">or</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">count</governor>
          <dependent id="12">will</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="14">count</governor>
          <dependent id="13">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">says</governor>
          <dependent id="14">count</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">count</governor>
          <dependent id="15">people</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">do</governor>
          <dependent id="17">we</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="19">do</governor>
          <dependent id="18">will</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="19">do</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">says</governor>
          <dependent id="20">what</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">says</governor>
          <dependent id="21">it</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">do</governor>
          <dependent id="22">says</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Congress" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="3" string="Congress" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="2" type="PROPER">
      <referenced ids_tokens="14-15" string="the Senate" id_sentence="1" />
      <mentions>
        <mention ids_tokens="1-3" string="The Senate's" id_sentence="5" />
        <mention ids_tokens="11-13" string="the Senate's" id_sentence="19" />
        <mention ids_tokens="9" string="Senate" id_sentence="21" />
        <mention ids_tokens="1-3" string="The Senate's" id_sentence="30" />
        <mention ids_tokens="19-21" string="the Senate's" id_sentence="41" />
        <mention ids_tokens="1-3" string="The Senate's" id_sentence="46" />
        <mention ids_tokens="18-20" string="the Senate's" id_sentence="49" />
      </mentions>
    </coreference>
    <coreference id="3" type="PROPER">
      <referenced ids_tokens="20-21-22" string="the Census Bureau" id_sentence="1" />
      <mentions>
        <mention ids_tokens="2-3" string="Census Bureau" id_sentence="52" />
      </mentions>
    </coreference>
    <coreference id="4" type="NOMINAL">
      <referenced ids_tokens="25-26" string="illegal aliens" id_sentence="1" />
      <mentions>
        <mention ids_tokens="7" string="aliens" id_sentence="26" />
      </mentions>
    </coreference>
    <coreference id="5" type="NOMINAL">
      <referenced ids_tokens="28-29-30-31" string="the 1990 population count" id_sentence="1" />
      <mentions>
        <mention ids_tokens="20-22" string="the 1990 count" id_sentence="4" />
        <mention ids_tokens="23-24" string="the count" id_sentence="6" />
      </mentions>
    </coreference>
    <coreference id="6" type="PRONOMINAL">
      <referenced ids_tokens="2" string="I" id_sentence="2" />
      <mentions>
        <mention ids_tokens="3" string="you" id_sentence="36" />
      </mentions>
    </coreference>
    <coreference id="7" type="PROPER">
      <referenced ids_tokens="8-9-10-11-12-13-14-15" string="Santa Ana City Council member Miguel A. Pulido" id_sentence="2" />
      <mentions>
        <mention ids_tokens="1" string="Pulido" id_sentence="3" />
        <mention ids_tokens="4" string="Pulido" id_sentence="13" />
        <mention ids_tokens="26" string="Pulido" id_sentence="16" />
        <mention ids_tokens="2" string="Pulido" id_sentence="20" />
        <mention ids_tokens="4" string="he" id_sentence="20" />
      </mentions>
    </coreference>
    <coreference id="8" type="PROPER">
      <referenced ids_tokens="4-5" string="Santa Ana" id_sentence="3" />
      <mentions>
        <mention ids_tokens="5" string="its" id_sentence="12" />
      </mentions>
    </coreference>
    <coreference id="9" type="PROPER">
      <referenced ids_tokens="11-12-13" string="the 1980 Census" id_sentence="25" />
      <mentions>
        <mention ids_tokens="15" string="its" id_sentence="3" />
        <mention ids_tokens="3-5" string="the census's" id_sentence="18" />
        <mention ids_tokens="14-15" string="the census" id_sentence="22" />
      </mentions>
    </coreference>
    <coreference id="10" type="PROPER">
      <referenced ids_tokens="16" string="50,000" id_sentence="4" />
      <mentions>
        <mention ids_tokens="1" string="I" id_sentence="18" />
      </mentions>
    </coreference>
    <coreference id="11" type="NOMINAL">
      <referenced ids_tokens="1-2" string="The city" id_sentence="4" />
      <mentions>
        <mention ids_tokens="15-23" string="the city that will affect us in the future" id_sentence="34" />
      </mentions>
    </coreference>
    <coreference id="12" type="PROPER">
      <referenced ids_tokens="22-23" string="President Bush" id_sentence="8" />
      <mentions>
        <mention ids_tokens="15" string="Bush" id_sentence="5" />
        <mention ids_tokens="25" string="Bush" id_sentence="48" />
      </mentions>
    </coreference>
    <coreference id="13" type="NOMINAL">
      <referenced ids_tokens="1-2-3-4" string="The Senate 's action" id_sentence="5" />
      <mentions>
        <mention ids_tokens="20" string="it" id_sentence="46" />
      </mentions>
    </coreference>
    <coreference id="14" type="NOMINAL">
      <referenced ids_tokens="7-8-9" string="a voice vote" id_sentence="5" />
      <mentions>
        <mention ids_tokens="3-5" string="the voice vote" id_sentence="6" />
      </mentions>
    </coreference>
    <coreference id="15" type="NOMINAL">
      <referenced ids_tokens="7-8" string="the senators" id_sentence="6" />
      <mentions>
        <mention ids_tokens="18-20" string="the senators'" id_sentence="35" />
        <mention ids_tokens="23" string="they" id_sentence="35" />
        <mention ids_tokens="5" string="them" id_sentence="36" />
        <mention ids_tokens="8" string="they" id_sentence="37" />
      </mentions>
    </coreference>
    <coreference id="16" type="NOMINAL">
      <referenced ids_tokens="8-9-10-11-12-13-14-15-16-17" string="the prohibition against including illegal immigrants in the census totals" id_sentence="7" />
      <mentions>
        <mention ids_tokens="6-7" string="the prohibition" id_sentence="8" />
      </mentions>
    </coreference>
    <coreference id="18" type="PROPER">
      <referenced ids_tokens="9" string="Congress" id_sentence="9" />
      <mentions>
        <mention ids_tokens="21" string="it" id_sentence="54" />
      </mentions>
    </coreference>
    <coreference id="19" type="NOMINAL">
      <referenced ids_tokens="23-24" string="those states" id_sentence="29" />
      <mentions>
        <mention ids_tokens="4" string="states" id_sentence="10" />
      </mentions>
    </coreference>
    <coreference id="20" type="LIST">
      <referenced ids_tokens="4-5-6-7-8-9-10-11" string="Pulido and county advocates for poor Latino residents" id_sentence="13" />
      <mentions>
        <mention ids_tokens="5" string="we" id_sentence="16" />
      </mentions>
    </coreference>
    <coreference id="21" type="NOMINAL">
      <referenced ids_tokens="23-24" string="the community" id_sentence="13" />
      <mentions>
        <mention ids_tokens="20-21" string="our community" id_sentence="36" />
        <mention ids_tokens="5" string="it" id_sentence="37" />
      </mentions>
    </coreference>
    <coreference id="23" type="NOMINAL">
      <referenced ids_tokens="2-3" string="Those individuals" id_sentence="17" />
      <mentions>
        <mention ids_tokens="9" string="them" id_sentence="18" />
        <mention ids_tokens="34" string="we" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="24" type="NOMINAL">
      <referenced ids_tokens="17-18-19" string="the immigration service" id_sentence="18" />
      <mentions>
        <mention ids_tokens="28" string="I" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="27" type="PROPER">
      <referenced ids_tokens="12-13-14-15-16-17-18-19" string="Minority Leader Bob Dole ( R-Kan . )" id_sentence="21" />
      <mentions>
        <mention ids_tokens="18" string="Dole" id_sentence="23" />
      </mentions>
    </coreference>
    <coreference id="28" type="PROPER">
      <referenced ids_tokens="4-5" string="White House" id_sentence="22" />
      <mentions>
        <mention ids_tokens="8" string="House" id_sentence="25" />
        <mention ids_tokens="15" string="House" id_sentence="48" />
      </mentions>
    </coreference>
    <coreference id="29" type="NOMINAL">
      <referenced ids_tokens="3-4-5-6" string="the White House position" id_sentence="22" />
      <mentions>
        <mention ids_tokens="2-3" string="Our position" id_sentence="53" />
      </mentions>
    </coreference>
    <coreference id="30" type="PROPER">
      <referenced ids_tokens="1-2-3-4-5-6-7" string="Sen. Thad Cochran ( R-Miss . )" id_sentence="24" />
      <mentions>
        <mention ids_tokens="17" string="Cochran" id_sentence="26" />
      </mentions>
    </coreference>
    <coreference id="32" type="PROPER">
      <referenced ids_tokens="1-2-3-4-5-6-7" string="Sen. Pete Wilson ( R-Calif . )" id_sentence="27" />
      <mentions>
        <mention ids_tokens="18" string="Wilson" id_sentence="29" />
      </mentions>
    </coreference>
    <coreference id="33" type="PROPER">
      <referenced ids_tokens="34-35" string="Don Vestal" id_sentence="30" />
      <mentions>
        <mention ids_tokens="22" string="he" id_sentence="32" />
        <mention ids_tokens="12" string="Vestal" id_sentence="33" />
        <mention ids_tokens="26" string="he" id_sentence="34" />
      </mentions>
    </coreference>
    <coreference id="34" type="PROPER">
      <referenced ids_tokens="1" string="Westminster" id_sentence="31" />
      <mentions>
        <mention ids_tokens="5" string="it" id_sentence="32" />
      </mentions>
    </coreference>
    <coreference id="35" type="LIST">
      <referenced ids_tokens="17-18-19-20" string="officials and community leaders" id_sentence="31" />
      <mentions>
        <mention ids_tokens="2" string="We" id_sentence="32" />
        <mention ids_tokens="8" string="our" id_sentence="32" />
        <mention ids_tokens="18" string="we" id_sentence="32" />
        <mention ids_tokens="20" string="us" id_sentence="34" />
        <mention ids_tokens="20" string="our" id_sentence="36" />
        <mention ids_tokens="3" string="we" id_sentence="37" />
      </mentions>
    </coreference>
    <coreference id="36" type="NOMINAL">
      <referenced ids_tokens="23-24-25-26-27-28" string="lower income residents in the city" id_sentence="33" />
      <mentions>
        <mention ids_tokens="9" string="they" id_sentence="34" />
      </mentions>
    </coreference>
    <coreference id="37" type="PROPER">
      <referenced ids_tokens="1-2" string="Gloria McDonough" id_sentence="35" />
      <mentions>
        <mention ids_tokens="17" string="McDonough" id_sentence="37" />
        <mention ids_tokens="43" string="McDonough" id_sentence="38" />
        <mention ids_tokens="35" string="she" id_sentence="39" />
      </mentions>
    </coreference>
    <coreference id="39" type="NOMINAL">
      <referenced ids_tokens="5-6-7-8-9-10-11-12" string="representatives from the census office in Santa Ana" id_sentence="38" />
      <mentions>
        <mention ids_tokens="2" string="Their" id_sentence="39" />
      </mentions>
    </coreference>
    <coreference id="40" type="NOMINAL">
      <referenced ids_tokens="21" string="others" id_sentence="38" />
      <mentions>
        <mention ids_tokens="8" string="We" id_sentence="39" />
      </mentions>
    </coreference>
    <coreference id="41" type="NOMINAL">
      <referenced ids_tokens="24-25-26" string="center staff people" id_sentence="38" />
      <mentions>
        <mention ids_tokens="17-18" string="these people" id_sentence="39" />
        <mention ids_tokens="27" string="their" id_sentence="39" />
        <mention ids_tokens="2" string="People" id_sentence="51" />
        <mention ids_tokens="10" string="their" id_sentence="53" />
        <mention ids_tokens="15" string="people" id_sentence="54" />
      </mentions>
    </coreference>
    <coreference id="42" type="NOMINAL">
      <referenced ids_tokens="6-7-8-9-10" string="census officials in Santa Ana" id_sentence="40" />
      <mentions>
        <mention ids_tokens="3" string="we" id_sentence="42" />
        <mention ids_tokens="13" string="we" id_sentence="42" />
      </mentions>
    </coreference>
    <coreference id="43" type="PROPER">
      <referenced ids_tokens="1-2" string="Adrian Dove" id_sentence="41" />
      <mentions>
        <mention ids_tokens="21" string="he" id_sentence="42" />
      </mentions>
    </coreference>
    <coreference id="45" type="PROPER">
      <referenced ids_tokens="6-7-8-9-10-11-12" string="Sen. Daniel Patrick Moynihan ( D-N.Y. )" id_sentence="44" />
      <mentions>
        <mention ids_tokens="16" string="he" id_sentence="45" />
      </mentions>
    </coreference>
    <coreference id="46" type="PROPER">
      <referenced ids_tokens="12-13" string="Michael Darby" id_sentence="46" />
      <mentions>
        <mention ids_tokens="20" string="Darby" id_sentence="47" />
        <mention ids_tokens="2" string="he" id_sentence="48" />
        <mention ids_tokens="5" string="he" id_sentence="48" />
      </mentions>
    </coreference>
    <coreference id="48" type="PROPER">
      <referenced ids_tokens="1-2" string="Mario Moreno" id_sentence="49" />
      <mentions>
        <mention ids_tokens="18" string="Moreno" id_sentence="50" />
      </mentions>
    </coreference>
    <coreference id="49" type="PROPER">
      <referenced ids_tokens="6-7-8-9" string="the Mexican American Legal" id_sentence="49" />
      <mentions>
        <mention ids_tokens="2" string="It" id_sentence="50" />
      </mentions>
    </coreference>
    <coreference id="50" type="PRONOMINAL">
      <referenced ids_tokens="2" string="Our" id_sentence="53" />
      <mentions>
        <mention ids_tokens="9" string="we" id_sentence="54" />
        <mention ids_tokens="17" string="we" id_sentence="54" />
      </mentions>
    </coreference>
  </coreferences>
</document>
