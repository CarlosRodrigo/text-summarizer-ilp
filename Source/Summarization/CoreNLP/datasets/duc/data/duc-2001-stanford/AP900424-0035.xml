<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="AP900424-0035">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>A seriously ill Elizabeth Taylor battled pneumonia at her hospital, her breathing assisted by a ventilator, doctors say.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="seriously" lemma="seriously" stem="serious" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="ill" lemma="ill" stem="ill" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="Elizabeth" lemma="Elizabeth" stem="elizabeth" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="5" string="Taylor" lemma="Taylor" stem="taylor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string="battled" lemma="battle" stem="battl" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="pneumonia" lemma="pneumonia" stem="pneumonia" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="8" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="hospital" lemma="hospital" stem="hospit" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="breathing" lemma="breathing" stem="breath" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="assisted" lemma="assist" stem="assist" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="ventilator" lemma="ventilator" stem="ventil" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="doctors" lemma="doctor" stem="doctor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="say" lemma="say" stem="sai" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT A) (ADJP (ADVP (RB seriously)) (JJ ill)) (NNP Elizabeth) (NNP Taylor)) (VP (VBD battled) (NP (NN pneumonia)) (PP (IN at) (NP (NP (PRP$ her) (NN hospital)) (, ,) (NP (NP (PRP$ her) (NN breathing)) (VP (VBN assisted) (PP (IN by) (NP (DT a) (NN ventilator))))))))) (, ,) (NP (NNS doctors)) (VP (VBP say)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="her hospital , her breathing assisted by a ventilator" type="NP">
          <tokens>
            <token id="9" string="her" />
            <token id="10" string="hospital" />
            <token id="11" string="," />
            <token id="12" string="her" />
            <token id="13" string="breathing" />
            <token id="14" string="assisted" />
            <token id="15" string="by" />
            <token id="16" string="a" />
            <token id="17" string="ventilator" />
          </tokens>
        </chunking>
        <chunking id="2" string="doctors" type="NP">
          <tokens>
            <token id="19" string="doctors" />
          </tokens>
        </chunking>
        <chunking id="3" string="assisted by a ventilator" type="VP">
          <tokens>
            <token id="14" string="assisted" />
            <token id="15" string="by" />
            <token id="16" string="a" />
            <token id="17" string="ventilator" />
          </tokens>
        </chunking>
        <chunking id="4" string="battled pneumonia at her hospital , her breathing assisted by a ventilator" type="VP">
          <tokens>
            <token id="6" string="battled" />
            <token id="7" string="pneumonia" />
            <token id="8" string="at" />
            <token id="9" string="her" />
            <token id="10" string="hospital" />
            <token id="11" string="," />
            <token id="12" string="her" />
            <token id="13" string="breathing" />
            <token id="14" string="assisted" />
            <token id="15" string="by" />
            <token id="16" string="a" />
            <token id="17" string="ventilator" />
          </tokens>
        </chunking>
        <chunking id="5" string="pneumonia" type="NP">
          <tokens>
            <token id="7" string="pneumonia" />
          </tokens>
        </chunking>
        <chunking id="6" string="her breathing" type="NP">
          <tokens>
            <token id="12" string="her" />
            <token id="13" string="breathing" />
          </tokens>
        </chunking>
        <chunking id="7" string="seriously ill" type="ADJP">
          <tokens>
            <token id="2" string="seriously" />
            <token id="3" string="ill" />
          </tokens>
        </chunking>
        <chunking id="8" string="her hospital" type="NP">
          <tokens>
            <token id="9" string="her" />
            <token id="10" string="hospital" />
          </tokens>
        </chunking>
        <chunking id="9" string="say" type="VP">
          <tokens>
            <token id="20" string="say" />
          </tokens>
        </chunking>
        <chunking id="10" string="her breathing assisted by a ventilator" type="NP">
          <tokens>
            <token id="12" string="her" />
            <token id="13" string="breathing" />
            <token id="14" string="assisted" />
            <token id="15" string="by" />
            <token id="16" string="a" />
            <token id="17" string="ventilator" />
          </tokens>
        </chunking>
        <chunking id="11" string="a ventilator" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="ventilator" />
          </tokens>
        </chunking>
        <chunking id="12" string="A seriously ill Elizabeth Taylor" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="seriously" />
            <token id="3" string="ill" />
            <token id="4" string="Elizabeth" />
            <token id="5" string="Taylor" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="5">Taylor</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">ill</governor>
          <dependent id="2">seriously</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">Taylor</governor>
          <dependent id="3">ill</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Taylor</governor>
          <dependent id="4">Elizabeth</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">battled</governor>
          <dependent id="5">Taylor</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="20">say</governor>
          <dependent id="6">battled</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">battled</governor>
          <dependent id="7">pneumonia</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">hospital</governor>
          <dependent id="8">at</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">hospital</governor>
          <dependent id="9">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">battled</governor>
          <dependent id="10">hospital</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">breathing</governor>
          <dependent id="12">her</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="10">hospital</governor>
          <dependent id="13">breathing</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="13">breathing</governor>
          <dependent id="14">assisted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">ventilator</governor>
          <dependent id="15">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">ventilator</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">assisted</governor>
          <dependent id="17">ventilator</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">say</governor>
          <dependent id="19">doctors</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="20">say</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="pneumonia" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="7" string="pneumonia" />
          </tokens>
        </entity>
        <entity id="2" string="Elizabeth Taylor" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Elizabeth" />
            <token id="5" string="Taylor" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>Hospital officials described her condition late Monday as stabilizing after a lung biopsy to determine the cause of the pneumonia.</content>
      <tokens>
        <token id="1" string="Hospital" lemma="hospital" stem="hospit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="officials" lemma="official" stem="offici" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="described" lemma="describe" stem="describ" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="5" string="condition" lemma="condition" stem="condit" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="late" lemma="late" stem="late" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="7" string="Monday" lemma="Monday" stem="mondai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="8" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="stabilizing" lemma="stabilize" stem="stabil" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="lung" lemma="lung" stem="lung" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="biopsy" lemma="biopsy" stem="biopsi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="determine" lemma="determine" stem="determin" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="cause" lemma="cause" stem="caus" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="pneumonia" lemma="pneumonia" stem="pneumonia" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NN Hospital) (NNS officials)) (VP (VBD described) (NP (PRP$ her) (NN condition)) (NP-TMP (RB late) (NNP Monday)) (PP (IN as) (S (VP (VBG stabilizing) (PP (IN after) (NP (DT a) (NN lung) (NN biopsy))) (S (VP (TO to) (VP (VB determine) (NP (NP (DT the) (NN cause)) (PP (IN of) (NP (DT the) (NN pneumonia))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the pneumonia" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="pneumonia" />
          </tokens>
        </chunking>
        <chunking id="2" string="the cause" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="cause" />
          </tokens>
        </chunking>
        <chunking id="3" string="Hospital officials" type="NP">
          <tokens>
            <token id="1" string="Hospital" />
            <token id="2" string="officials" />
          </tokens>
        </chunking>
        <chunking id="4" string="stabilizing after a lung biopsy to determine the cause of the pneumonia" type="VP">
          <tokens>
            <token id="9" string="stabilizing" />
            <token id="10" string="after" />
            <token id="11" string="a" />
            <token id="12" string="lung" />
            <token id="13" string="biopsy" />
            <token id="14" string="to" />
            <token id="15" string="determine" />
            <token id="16" string="the" />
            <token id="17" string="cause" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="pneumonia" />
          </tokens>
        </chunking>
        <chunking id="5" string="a lung biopsy" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="lung" />
            <token id="13" string="biopsy" />
          </tokens>
        </chunking>
        <chunking id="6" string="the cause of the pneumonia" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="cause" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="pneumonia" />
          </tokens>
        </chunking>
        <chunking id="7" string="determine the cause of the pneumonia" type="VP">
          <tokens>
            <token id="15" string="determine" />
            <token id="16" string="the" />
            <token id="17" string="cause" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="pneumonia" />
          </tokens>
        </chunking>
        <chunking id="8" string="described her condition late Monday as stabilizing after a lung biopsy to determine the cause of the pneumonia" type="VP">
          <tokens>
            <token id="3" string="described" />
            <token id="4" string="her" />
            <token id="5" string="condition" />
            <token id="6" string="late" />
            <token id="7" string="Monday" />
            <token id="8" string="as" />
            <token id="9" string="stabilizing" />
            <token id="10" string="after" />
            <token id="11" string="a" />
            <token id="12" string="lung" />
            <token id="13" string="biopsy" />
            <token id="14" string="to" />
            <token id="15" string="determine" />
            <token id="16" string="the" />
            <token id="17" string="cause" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="pneumonia" />
          </tokens>
        </chunking>
        <chunking id="9" string="to determine the cause of the pneumonia" type="VP">
          <tokens>
            <token id="14" string="to" />
            <token id="15" string="determine" />
            <token id="16" string="the" />
            <token id="17" string="cause" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="pneumonia" />
          </tokens>
        </chunking>
        <chunking id="10" string="her condition" type="NP">
          <tokens>
            <token id="4" string="her" />
            <token id="5" string="condition" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">officials</governor>
          <dependent id="1">Hospital</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">described</governor>
          <dependent id="2">officials</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">described</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">condition</governor>
          <dependent id="4">her</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">described</governor>
          <dependent id="5">condition</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">Monday</governor>
          <dependent id="6">late</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="3">described</governor>
          <dependent id="7">Monday</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">stabilizing</governor>
          <dependent id="8">as</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">described</governor>
          <dependent id="9">stabilizing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">biopsy</governor>
          <dependent id="10">after</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">biopsy</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">biopsy</governor>
          <dependent id="12">lung</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">stabilizing</governor>
          <dependent id="13">biopsy</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">determine</governor>
          <dependent id="14">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">stabilizing</governor>
          <dependent id="15">determine</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">cause</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">determine</governor>
          <dependent id="17">cause</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">pneumonia</governor>
          <dependent id="18">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">pneumonia</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">cause</governor>
          <dependent id="20">pneumonia</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="pneumonia" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="20" string="pneumonia" />
          </tokens>
        </entity>
        <entity id="2" string="late Monday" type="DATE" score="0.0">
          <tokens>
            <token id="6" string="late" />
            <token id="7" string="Monday" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>Analysis of the tissue sample was expected to take until Thursday, said her spokeswoman, Chen Sam.</content>
      <tokens>
        <token id="1" string="Analysis" lemma="analysis" stem="analysi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="tissue" lemma="tissue" stem="tissu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="sample" lemma="sample" stem="sampl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="expected" lemma="expect" stem="expect" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="take" lemma="take" stem="take" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="until" lemma="until" stem="until" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Thursday" lemma="Thursday" stem="thursdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="spokeswoman" lemma="spokeswoman" stem="spokeswoman" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Chen" lemma="Chen" stem="chen" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="18" string="Sam" lemma="Sam" stem="sam" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (S (NP (NP (NN Analysis)) (PP (IN of) (NP (DT the) (NN tissue) (NN sample)))) (VP (VBD was) (VP (VBN expected) (S (VP (TO to) (VP (VB take) (PP (IN until) (NP (NNP Thursday))))))))) (, ,) (VP (VBD said)) (NP (NP (PRP$ her) (NN spokeswoman)) (, ,) (NP (NNP Chen) (NNP Sam))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Analysis" type="NP">
          <tokens>
            <token id="1" string="Analysis" />
          </tokens>
        </chunking>
        <chunking id="2" string="the tissue sample" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="tissue" />
            <token id="5" string="sample" />
          </tokens>
        </chunking>
        <chunking id="3" string="Chen Sam" type="NP">
          <tokens>
            <token id="17" string="Chen" />
            <token id="18" string="Sam" />
          </tokens>
        </chunking>
        <chunking id="4" string="Analysis of the tissue sample" type="NP">
          <tokens>
            <token id="1" string="Analysis" />
            <token id="2" string="of" />
            <token id="3" string="the" />
            <token id="4" string="tissue" />
            <token id="5" string="sample" />
          </tokens>
        </chunking>
        <chunking id="5" string="her spokeswoman" type="NP">
          <tokens>
            <token id="14" string="her" />
            <token id="15" string="spokeswoman" />
          </tokens>
        </chunking>
        <chunking id="6" string="take until Thursday" type="VP">
          <tokens>
            <token id="9" string="take" />
            <token id="10" string="until" />
            <token id="11" string="Thursday" />
          </tokens>
        </chunking>
        <chunking id="7" string="was expected to take until Thursday" type="VP">
          <tokens>
            <token id="6" string="was" />
            <token id="7" string="expected" />
            <token id="8" string="to" />
            <token id="9" string="take" />
            <token id="10" string="until" />
            <token id="11" string="Thursday" />
          </tokens>
        </chunking>
        <chunking id="8" string="to take until Thursday" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="take" />
            <token id="10" string="until" />
            <token id="11" string="Thursday" />
          </tokens>
        </chunking>
        <chunking id="9" string="Thursday" type="NP">
          <tokens>
            <token id="11" string="Thursday" />
          </tokens>
        </chunking>
        <chunking id="10" string="her spokeswoman , Chen Sam" type="NP">
          <tokens>
            <token id="14" string="her" />
            <token id="15" string="spokeswoman" />
            <token id="16" string="," />
            <token id="17" string="Chen" />
            <token id="18" string="Sam" />
          </tokens>
        </chunking>
        <chunking id="11" string="expected to take until Thursday" type="VP">
          <tokens>
            <token id="7" string="expected" />
            <token id="8" string="to" />
            <token id="9" string="take" />
            <token id="10" string="until" />
            <token id="11" string="Thursday" />
          </tokens>
        </chunking>
        <chunking id="12" string="said" type="VP">
          <tokens>
            <token id="13" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="7">expected</governor>
          <dependent id="1">Analysis</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">sample</governor>
          <dependent id="2">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">sample</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">sample</governor>
          <dependent id="4">tissue</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Analysis</governor>
          <dependent id="5">sample</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="7">expected</governor>
          <dependent id="6">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">said</governor>
          <dependent id="7">expected</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">take</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">expected</governor>
          <dependent id="9">take</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Thursday</governor>
          <dependent id="10">until</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">take</governor>
          <dependent id="11">Thursday</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">said</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">spokeswoman</governor>
          <dependent id="14">her</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">said</governor>
          <dependent id="15">spokeswoman</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Sam</governor>
          <dependent id="17">Chen</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="15">spokeswoman</governor>
          <dependent id="18">Sam</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Chen Sam" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="Chen" />
            <token id="18" string="Sam" />
          </tokens>
        </entity>
        <entity id="2" string="Thursday" type="DATE" score="0.0">
          <tokens>
            <token id="11" string="Thursday" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>The 58-year-old actress, who won best-actress Oscars for ``Butterfield 8&amp;apost;&amp;apost; and ``Who&amp;apost;s Afraid of Virginia Woolf,&amp;apost;&amp;apost; has been hospitalized more than two weeks.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="58-year-old" lemma="58-year-old" stem="58-year-old" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="3" string="actress" lemma="actress" stem="actress" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="won" lemma="win" stem="won" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="best-actress" lemma="best-actress" stem="best-actress" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="Oscars" lemma="Oscars" stem="oscar" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="9" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="Butterfield" lemma="Butterfield" stem="butterfield" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="8" lemma="8" stem="8" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="13" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="Who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="Afraid" lemma="Afraid" stem="afraid" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="Virginia" lemma="Virginia" stem="virginia" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="21" string="Woolf" lemma="Woolf" stem="woolf" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="hospitalized" lemma="hospitalize" stem="hospit" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="28" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="29" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="30" string="weeks" lemma="week" stem="week" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (JJ 58-year-old) (NN actress)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD won) (NP (NP (NP (JJ best-actress) (NNP Oscars)) (PP (IN for) (`` ``) (NP (NNP Butterfield) (CD 8)) ('' ''))) (CC and) (SBAR (`` ``) (WHNP (WP Who)) (S (VP (VBZ 's) (NP (NP (NNP Afraid)) (PP (IN of) (NP (NNP Virginia) (NNP Woolf))))))))))) (, ,) ('' '')) (VP (VBZ has) (VP (VBN been) (VP (VBN hospitalized) (NP-TMP (QP (RBR more) (IN than) (CD two)) (NNS weeks))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Butterfield 8" type="NP">
          <tokens>
            <token id="11" string="Butterfield" />
            <token id="12" string="8" />
          </tokens>
        </chunking>
        <chunking id="2" string="been hospitalized more than two weeks" type="VP">
          <tokens>
            <token id="25" string="been" />
            <token id="26" string="hospitalized" />
            <token id="27" string="more" />
            <token id="28" string="than" />
            <token id="29" string="two" />
            <token id="30" string="weeks" />
          </tokens>
        </chunking>
        <chunking id="3" string="'s Afraid of Virginia Woolf" type="VP">
          <tokens>
            <token id="17" string="'s" />
            <token id="18" string="Afraid" />
            <token id="19" string="of" />
            <token id="20" string="Virginia" />
            <token id="21" string="Woolf" />
          </tokens>
        </chunking>
        <chunking id="4" string="Virginia Woolf" type="NP">
          <tokens>
            <token id="20" string="Virginia" />
            <token id="21" string="Woolf" />
          </tokens>
        </chunking>
        <chunking id="5" string="hospitalized more than two weeks" type="VP">
          <tokens>
            <token id="26" string="hospitalized" />
            <token id="27" string="more" />
            <token id="28" string="than" />
            <token id="29" string="two" />
            <token id="30" string="weeks" />
          </tokens>
        </chunking>
        <chunking id="6" string="best-actress Oscars" type="NP">
          <tokens>
            <token id="7" string="best-actress" />
            <token id="8" string="Oscars" />
          </tokens>
        </chunking>
        <chunking id="7" string="has been hospitalized more than two weeks" type="VP">
          <tokens>
            <token id="24" string="has" />
            <token id="25" string="been" />
            <token id="26" string="hospitalized" />
            <token id="27" string="more" />
            <token id="28" string="than" />
            <token id="29" string="two" />
            <token id="30" string="weeks" />
          </tokens>
        </chunking>
        <chunking id="8" string="best-actress Oscars for `` Butterfield 8 '' and `` Who 's Afraid of Virginia Woolf" type="NP">
          <tokens>
            <token id="7" string="best-actress" />
            <token id="8" string="Oscars" />
            <token id="9" string="for" />
            <token id="10" string="``" />
            <token id="11" string="Butterfield" />
            <token id="12" string="8" />
            <token id="13" string="''" />
            <token id="14" string="and" />
            <token id="15" string="``" />
            <token id="16" string="Who" />
            <token id="17" string="'s" />
            <token id="18" string="Afraid" />
            <token id="19" string="of" />
            <token id="20" string="Virginia" />
            <token id="21" string="Woolf" />
          </tokens>
        </chunking>
        <chunking id="9" string="best-actress Oscars for `` Butterfield 8 ''" type="NP">
          <tokens>
            <token id="7" string="best-actress" />
            <token id="8" string="Oscars" />
            <token id="9" string="for" />
            <token id="10" string="``" />
            <token id="11" string="Butterfield" />
            <token id="12" string="8" />
            <token id="13" string="''" />
          </tokens>
        </chunking>
        <chunking id="10" string="Afraid of Virginia Woolf" type="NP">
          <tokens>
            <token id="18" string="Afraid" />
            <token id="19" string="of" />
            <token id="20" string="Virginia" />
            <token id="21" string="Woolf" />
          </tokens>
        </chunking>
        <chunking id="11" string="Afraid" type="NP">
          <tokens>
            <token id="18" string="Afraid" />
          </tokens>
        </chunking>
        <chunking id="12" string="The 58-year-old actress" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="58-year-old" />
            <token id="3" string="actress" />
          </tokens>
        </chunking>
        <chunking id="13" string="The 58-year-old actress , who won best-actress Oscars for `` Butterfield 8 '' and `` Who 's Afraid of Virginia Woolf , ''" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="58-year-old" />
            <token id="3" string="actress" />
            <token id="4" string="," />
            <token id="5" string="who" />
            <token id="6" string="won" />
            <token id="7" string="best-actress" />
            <token id="8" string="Oscars" />
            <token id="9" string="for" />
            <token id="10" string="``" />
            <token id="11" string="Butterfield" />
            <token id="12" string="8" />
            <token id="13" string="''" />
            <token id="14" string="and" />
            <token id="15" string="``" />
            <token id="16" string="Who" />
            <token id="17" string="'s" />
            <token id="18" string="Afraid" />
            <token id="19" string="of" />
            <token id="20" string="Virginia" />
            <token id="21" string="Woolf" />
            <token id="22" string="," />
            <token id="23" string="''" />
          </tokens>
        </chunking>
        <chunking id="14" string="`` Who 's Afraid of Virginia Woolf" type="SBAR">
          <tokens>
            <token id="15" string="``" />
            <token id="16" string="Who" />
            <token id="17" string="'s" />
            <token id="18" string="Afraid" />
            <token id="19" string="of" />
            <token id="20" string="Virginia" />
            <token id="21" string="Woolf" />
          </tokens>
        </chunking>
        <chunking id="15" string="won best-actress Oscars for `` Butterfield 8 '' and `` Who 's Afraid of Virginia Woolf" type="VP">
          <tokens>
            <token id="6" string="won" />
            <token id="7" string="best-actress" />
            <token id="8" string="Oscars" />
            <token id="9" string="for" />
            <token id="10" string="``" />
            <token id="11" string="Butterfield" />
            <token id="12" string="8" />
            <token id="13" string="''" />
            <token id="14" string="and" />
            <token id="15" string="``" />
            <token id="16" string="Who" />
            <token id="17" string="'s" />
            <token id="18" string="Afraid" />
            <token id="19" string="of" />
            <token id="20" string="Virginia" />
            <token id="21" string="Woolf" />
          </tokens>
        </chunking>
        <chunking id="16" string="who won best-actress Oscars for `` Butterfield 8 '' and `` Who 's Afraid of Virginia Woolf" type="SBAR">
          <tokens>
            <token id="5" string="who" />
            <token id="6" string="won" />
            <token id="7" string="best-actress" />
            <token id="8" string="Oscars" />
            <token id="9" string="for" />
            <token id="10" string="``" />
            <token id="11" string="Butterfield" />
            <token id="12" string="8" />
            <token id="13" string="''" />
            <token id="14" string="and" />
            <token id="15" string="``" />
            <token id="16" string="Who" />
            <token id="17" string="'s" />
            <token id="18" string="Afraid" />
            <token id="19" string="of" />
            <token id="20" string="Virginia" />
            <token id="21" string="Woolf" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">actress</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">actress</governor>
          <dependent id="2">58-year-old</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="26">hospitalized</governor>
          <dependent id="3">actress</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">won</governor>
          <dependent id="5">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="3">actress</governor>
          <dependent id="6">won</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">Oscars</governor>
          <dependent id="7">best-actress</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">won</governor>
          <dependent id="8">Oscars</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Butterfield</governor>
          <dependent id="9">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">Oscars</governor>
          <dependent id="11">Butterfield</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="11">Butterfield</governor>
          <dependent id="12">8</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">Oscars</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">Afraid</governor>
          <dependent id="16">Who</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="18">Afraid</governor>
          <dependent id="17">'s</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">Oscars</governor>
          <dependent id="18">Afraid</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">Woolf</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">Woolf</governor>
          <dependent id="20">Virginia</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">Afraid</governor>
          <dependent id="21">Woolf</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="26">hospitalized</governor>
          <dependent id="24">has</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="26">hospitalized</governor>
          <dependent id="25">been</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="26">hospitalized</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="29">two</governor>
          <dependent id="27">more</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="27">more</governor>
          <dependent id="28">than</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="30">weeks</governor>
          <dependent id="29">two</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="26">hospitalized</governor>
          <dependent id="30">weeks</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Virginia Woolf" type="LOCATION" score="0.0">
          <tokens>
            <token id="20" string="Virginia" />
            <token id="21" string="Woolf" />
          </tokens>
        </entity>
        <entity id="2" string="Oscars" type="MISC" score="0.0">
          <tokens>
            <token id="8" string="Oscars" />
          </tokens>
        </entity>
        <entity id="3" string="58-year-old" type="DURATION" score="0.0">
          <tokens>
            <token id="2" string="58-year-old" />
          </tokens>
        </entity>
        <entity id="4" string="8" type="NUMBER" score="0.0">
          <tokens>
            <token id="12" string="8" />
          </tokens>
        </entity>
        <entity id="5" string="more than two weeks" type="DURATION" score="0.0">
          <tokens>
            <token id="27" string="more" />
            <token id="28" string="than" />
            <token id="29" string="two" />
            <token id="30" string="weeks" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>She was in the intensive care unit at St. John&amp;apost;s Hospital and Health Center.</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="intensive" lemma="intensive" stem="intens" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="care" lemma="care" stem="care" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="unit" lemma="unit" stem="unit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="St." lemma="St." stem="st." pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="10" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="11" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="12" string="Hospital" lemma="Hospital" stem="hospit" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="14" string="Health" lemma="Health" stem="health" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="15" string="Center" lemma="Center" stem="center" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP She)) (VP (VBD was) (PP (IN in) (NP (NP (DT the) (JJ intensive) (NN care) (NN unit)) (PP (IN at) (NP (NP (NNP St.) (NNP John) (POS 's)) (NNP Hospital) (CC and) (NNP Health) (NNP Center)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was in the intensive care unit at St. John 's Hospital and Health Center" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="in" />
            <token id="4" string="the" />
            <token id="5" string="intensive" />
            <token id="6" string="care" />
            <token id="7" string="unit" />
            <token id="8" string="at" />
            <token id="9" string="St." />
            <token id="10" string="John" />
            <token id="11" string="'s" />
            <token id="12" string="Hospital" />
            <token id="13" string="and" />
            <token id="14" string="Health" />
            <token id="15" string="Center" />
          </tokens>
        </chunking>
        <chunking id="2" string="St. John 's Hospital and Health Center" type="NP">
          <tokens>
            <token id="9" string="St." />
            <token id="10" string="John" />
            <token id="11" string="'s" />
            <token id="12" string="Hospital" />
            <token id="13" string="and" />
            <token id="14" string="Health" />
            <token id="15" string="Center" />
          </tokens>
        </chunking>
        <chunking id="3" string="the intensive care unit" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="intensive" />
            <token id="6" string="care" />
            <token id="7" string="unit" />
          </tokens>
        </chunking>
        <chunking id="4" string="St. John 's" type="NP">
          <tokens>
            <token id="9" string="St." />
            <token id="10" string="John" />
            <token id="11" string="'s" />
          </tokens>
        </chunking>
        <chunking id="5" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
        <chunking id="6" string="the intensive care unit at St. John 's Hospital and Health Center" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="intensive" />
            <token id="6" string="care" />
            <token id="7" string="unit" />
            <token id="8" string="at" />
            <token id="9" string="St." />
            <token id="10" string="John" />
            <token id="11" string="'s" />
            <token id="12" string="Hospital" />
            <token id="13" string="and" />
            <token id="14" string="Health" />
            <token id="15" string="Center" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="7">unit</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">unit</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">unit</governor>
          <dependent id="3">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">unit</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">unit</governor>
          <dependent id="5">intensive</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">unit</governor>
          <dependent id="6">care</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">unit</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Hospital</governor>
          <dependent id="8">at</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">John</governor>
          <dependent id="9">St.</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">Hospital</governor>
          <dependent id="10">John</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">John</governor>
          <dependent id="11">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">unit</governor>
          <dependent id="12">Hospital</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">Hospital</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Center</governor>
          <dependent id="14">Health</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">Hospital</governor>
          <dependent id="15">Center</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="St. John 's Hospital and Health Center" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="9" string="St." />
            <token id="10" string="John" />
            <token id="11" string="'s" />
            <token id="12" string="Hospital" />
            <token id="13" string="and" />
            <token id="14" string="Health" />
            <token id="15" string="Center" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>``She is seriously ill,&amp;apost;&amp;apost; her doctors said in a statement.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="seriously" lemma="seriously" stem="serious" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="ill" lemma="ill" stem="ill" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="9" string="doctors" lemma="doctor" stem="doctor" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="statement" lemma="statement" stem="statement" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP She)) (VP (VBZ is) (ADVP (RB seriously)) (ADJP (RB ill)))) (, ,) ('' '') (NP (PRP$ her) (NNS doctors)) (VP (VBD said) (PP (IN in) (NP (DT a) (NN statement)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="said in a statement" type="VP">
          <tokens>
            <token id="10" string="said" />
            <token id="11" string="in" />
            <token id="12" string="a" />
            <token id="13" string="statement" />
          </tokens>
        </chunking>
        <chunking id="2" string="a statement" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="statement" />
          </tokens>
        </chunking>
        <chunking id="3" string="ill" type="ADJP">
          <tokens>
            <token id="5" string="ill" />
          </tokens>
        </chunking>
        <chunking id="4" string="her doctors" type="NP">
          <tokens>
            <token id="8" string="her" />
            <token id="9" string="doctors" />
          </tokens>
        </chunking>
        <chunking id="5" string="She" type="NP">
          <tokens>
            <token id="2" string="She" />
          </tokens>
        </chunking>
        <chunking id="6" string="is seriously ill" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="seriously" />
            <token id="5" string="ill" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">ill</governor>
          <dependent id="2">She</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">ill</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">ill</governor>
          <dependent id="4">seriously</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">said</governor>
          <dependent id="5">ill</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">doctors</governor>
          <dependent id="8">her</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">said</governor>
          <dependent id="9">doctors</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">said</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">statement</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">statement</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">said</governor>
          <dependent id="13">statement</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>``After surgery, her breathing is now being assisted by a ventilator.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="After" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="surgery" lemma="surgery" stem="surgeri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="breathing" lemma="breathing" stem="breath" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="9" string="being" lemma="be" stem="be" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="assisted" lemma="assist" stem="assist" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="ventilator" lemma="ventilator" stem="ventil" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (PP (IN After) (NP (NN surgery))) (, ,) (NP (PRP$ her) (NN breathing)) (VP (VBZ is) (ADVP (RB now)) (VP (VBG being) (VP (VBN assisted) (PP (IN by) (NP (DT a) (NN ventilator)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="assisted by a ventilator" type="VP">
          <tokens>
            <token id="10" string="assisted" />
            <token id="11" string="by" />
            <token id="12" string="a" />
            <token id="13" string="ventilator" />
          </tokens>
        </chunking>
        <chunking id="2" string="being assisted by a ventilator" type="VP">
          <tokens>
            <token id="9" string="being" />
            <token id="10" string="assisted" />
            <token id="11" string="by" />
            <token id="12" string="a" />
            <token id="13" string="ventilator" />
          </tokens>
        </chunking>
        <chunking id="3" string="her breathing" type="NP">
          <tokens>
            <token id="5" string="her" />
            <token id="6" string="breathing" />
          </tokens>
        </chunking>
        <chunking id="4" string="is now being assisted by a ventilator" type="VP">
          <tokens>
            <token id="7" string="is" />
            <token id="8" string="now" />
            <token id="9" string="being" />
            <token id="10" string="assisted" />
            <token id="11" string="by" />
            <token id="12" string="a" />
            <token id="13" string="ventilator" />
          </tokens>
        </chunking>
        <chunking id="5" string="a ventilator" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="ventilator" />
          </tokens>
        </chunking>
        <chunking id="6" string="surgery" type="NP">
          <tokens>
            <token id="3" string="surgery" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">surgery</governor>
          <dependent id="2">After</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">assisted</governor>
          <dependent id="3">surgery</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">breathing</governor>
          <dependent id="5">her</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="10">assisted</governor>
          <dependent id="6">breathing</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">assisted</governor>
          <dependent id="7">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">assisted</governor>
          <dependent id="8">now</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="10">assisted</governor>
          <dependent id="9">being</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">assisted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">ventilator</governor>
          <dependent id="11">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">ventilator</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">assisted</governor>
          <dependent id="13">ventilator</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="8" string="now" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>Her condition is presently stabilizing and her physicians are pleased with her progress.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="Her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="condition" lemma="condition" stem="condit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="presently" lemma="presently" stem="present" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="stabilizing" lemma="stabilize" stem="stabil" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="physicians" lemma="physician" stem="physician" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="pleased" lemma="please" stem="pleas" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="13" string="progress" lemma="progress" stem="progress" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP$ Her) (NN condition)) (VP (VBZ is) (ADVP (RB presently)) (VP (VBG stabilizing)))) (CC and) (S (NP (PRP$ her) (NNS physicians)) (VP (VBP are) (VP (VBN pleased) (PP (IN with) (NP (PRP$ her) (NN progress)))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="Her condition" type="NP">
          <tokens>
            <token id="1" string="Her" />
            <token id="2" string="condition" />
          </tokens>
        </chunking>
        <chunking id="2" string="stabilizing" type="VP">
          <tokens>
            <token id="5" string="stabilizing" />
          </tokens>
        </chunking>
        <chunking id="3" string="pleased with her progress" type="VP">
          <tokens>
            <token id="10" string="pleased" />
            <token id="11" string="with" />
            <token id="12" string="her" />
            <token id="13" string="progress" />
          </tokens>
        </chunking>
        <chunking id="4" string="her physicians" type="NP">
          <tokens>
            <token id="7" string="her" />
            <token id="8" string="physicians" />
          </tokens>
        </chunking>
        <chunking id="5" string="her progress" type="NP">
          <tokens>
            <token id="12" string="her" />
            <token id="13" string="progress" />
          </tokens>
        </chunking>
        <chunking id="6" string="is presently stabilizing" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="presently" />
            <token id="5" string="stabilizing" />
          </tokens>
        </chunking>
        <chunking id="7" string="are pleased with her progress" type="VP">
          <tokens>
            <token id="9" string="are" />
            <token id="10" string="pleased" />
            <token id="11" string="with" />
            <token id="12" string="her" />
            <token id="13" string="progress" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="2">condition</governor>
          <dependent id="1">Her</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">stabilizing</governor>
          <dependent id="2">condition</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">stabilizing</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">stabilizing</governor>
          <dependent id="4">presently</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">stabilizing</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">stabilizing</governor>
          <dependent id="6">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">physicians</governor>
          <dependent id="7">her</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="10">pleased</governor>
          <dependent id="8">physicians</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="10">pleased</governor>
          <dependent id="9">are</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">stabilizing</governor>
          <dependent id="10">pleased</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">progress</governor>
          <dependent id="11">with</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">progress</governor>
          <dependent id="12">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">pleased</governor>
          <dependent id="13">progress</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>Another spokewoman for the actress, Lisa Del Favaro, said Miss Taylor&amp;apost;s family was at her bedside.</content>
      <tokens>
        <token id="1" string="Another" lemma="another" stem="another" pos="DT" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="spokewoman" lemma="spokewoman" stem="spokewoman" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="5" string="actress" lemma="actress" stem="actress" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="Lisa" lemma="Lisa" stem="lisa" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="8" string="Del" lemma="Del" stem="del" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="9" string="Favaro" lemma="Favaro" stem="favaro" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="13" string="Taylor" lemma="Taylor" stem="taylor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="14" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="15" string="family" lemma="family" stem="famili" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="bedside" lemma="bedside" stem="bedsid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT Another) (NN spokewoman)) (PP (IN for) (NP (NP (DT the) (NN actress)) (, ,) (NP (NNP Lisa) (NNP Del) (NNP Favaro)) (, ,)))) (VP (VBD said) (SBAR (S (NP (NP (NNP Miss) (NNP Taylor) (POS 's)) (NN family)) (VP (VBD was) (PP (IN at) (NP (PRP$ her) (NN bedside))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Another spokewoman for the actress , Lisa Del Favaro ," type="NP">
          <tokens>
            <token id="1" string="Another" />
            <token id="2" string="spokewoman" />
            <token id="3" string="for" />
            <token id="4" string="the" />
            <token id="5" string="actress" />
            <token id="6" string="," />
            <token id="7" string="Lisa" />
            <token id="8" string="Del" />
            <token id="9" string="Favaro" />
            <token id="10" string="," />
          </tokens>
        </chunking>
        <chunking id="2" string="Miss Taylor 's family" type="NP">
          <tokens>
            <token id="12" string="Miss" />
            <token id="13" string="Taylor" />
            <token id="14" string="'s" />
            <token id="15" string="family" />
          </tokens>
        </chunking>
        <chunking id="3" string="Another spokewoman" type="NP">
          <tokens>
            <token id="1" string="Another" />
            <token id="2" string="spokewoman" />
          </tokens>
        </chunking>
        <chunking id="4" string="was at her bedside" type="VP">
          <tokens>
            <token id="16" string="was" />
            <token id="17" string="at" />
            <token id="18" string="her" />
            <token id="19" string="bedside" />
          </tokens>
        </chunking>
        <chunking id="5" string="the actress , Lisa Del Favaro ," type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="actress" />
            <token id="6" string="," />
            <token id="7" string="Lisa" />
            <token id="8" string="Del" />
            <token id="9" string="Favaro" />
            <token id="10" string="," />
          </tokens>
        </chunking>
        <chunking id="6" string="the actress" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="actress" />
          </tokens>
        </chunking>
        <chunking id="7" string="said Miss Taylor 's family was at her bedside" type="VP">
          <tokens>
            <token id="11" string="said" />
            <token id="12" string="Miss" />
            <token id="13" string="Taylor" />
            <token id="14" string="'s" />
            <token id="15" string="family" />
            <token id="16" string="was" />
            <token id="17" string="at" />
            <token id="18" string="her" />
            <token id="19" string="bedside" />
          </tokens>
        </chunking>
        <chunking id="8" string="her bedside" type="NP">
          <tokens>
            <token id="18" string="her" />
            <token id="19" string="bedside" />
          </tokens>
        </chunking>
        <chunking id="9" string="Lisa Del Favaro" type="NP">
          <tokens>
            <token id="7" string="Lisa" />
            <token id="8" string="Del" />
            <token id="9" string="Favaro" />
          </tokens>
        </chunking>
        <chunking id="10" string="Miss Taylor 's" type="NP">
          <tokens>
            <token id="12" string="Miss" />
            <token id="13" string="Taylor" />
            <token id="14" string="'s" />
          </tokens>
        </chunking>
        <chunking id="11" string="Miss Taylor 's family was at her bedside" type="SBAR">
          <tokens>
            <token id="12" string="Miss" />
            <token id="13" string="Taylor" />
            <token id="14" string="'s" />
            <token id="15" string="family" />
            <token id="16" string="was" />
            <token id="17" string="at" />
            <token id="18" string="her" />
            <token id="19" string="bedside" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">spokewoman</governor>
          <dependent id="1">Another</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">said</governor>
          <dependent id="2">spokewoman</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">actress</governor>
          <dependent id="3">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">actress</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">spokewoman</governor>
          <dependent id="5">actress</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Favaro</governor>
          <dependent id="7">Lisa</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Favaro</governor>
          <dependent id="8">Del</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="5">actress</governor>
          <dependent id="9">Favaro</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Taylor</governor>
          <dependent id="12">Miss</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">family</governor>
          <dependent id="13">Taylor</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Taylor</governor>
          <dependent id="14">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">bedside</governor>
          <dependent id="15">family</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="19">bedside</governor>
          <dependent id="16">was</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">bedside</governor>
          <dependent id="17">at</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">bedside</governor>
          <dependent id="18">her</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">said</governor>
          <dependent id="19">bedside</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Taylor" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Taylor" />
          </tokens>
        </entity>
        <entity id="2" string="Lisa Del Favaro" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Lisa" />
            <token id="8" string="Del" />
            <token id="9" string="Favaro" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>She did not identify the family members.</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="identify" lemma="identify" stem="identifi" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="family" lemma="family" stem="famili" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="members" lemma="member" stem="member" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP She)) (VP (VBD did) (RB not) (VP (VB identify) (NP (DT the) (NN family) (NNS members)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="did not identify the family members" type="VP">
          <tokens>
            <token id="2" string="did" />
            <token id="3" string="not" />
            <token id="4" string="identify" />
            <token id="5" string="the" />
            <token id="6" string="family" />
            <token id="7" string="members" />
          </tokens>
        </chunking>
        <chunking id="2" string="the family members" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="family" />
            <token id="7" string="members" />
          </tokens>
        </chunking>
        <chunking id="3" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
        <chunking id="4" string="identify the family members" type="VP">
          <tokens>
            <token id="4" string="identify" />
            <token id="5" string="the" />
            <token id="6" string="family" />
            <token id="7" string="members" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">identify</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">identify</governor>
          <dependent id="2">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">identify</governor>
          <dependent id="3">not</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">identify</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">members</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">members</governor>
          <dependent id="6">family</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">identify</governor>
          <dependent id="7">members</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>Miss Taylor entered Daniel Freeman Marina Hospital on April 9 with a persistent fever and sinus infection, doctors said.</content>
      <tokens>
        <token id="1" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="Taylor" lemma="Taylor" stem="taylor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="entered" lemma="enter" stem="enter" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="Daniel" lemma="Daniel" stem="daniel" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="5" string="Freeman" lemma="Freeman" stem="freeman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="6" string="Marina" lemma="Marina" stem="marina" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="7" string="Hospital" lemma="Hospital" stem="hospit" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="8" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="April" lemma="April" stem="april" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="10" string="9" lemma="9" stem="9" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="11" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="persistent" lemma="persistent" stem="persist" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="fever" lemma="fever" stem="fever" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="sinus" lemma="sinus" stem="sinu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="infection" lemma="infection" stem="infect" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="doctors" lemma="doctor" stem="doctor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNP Miss) (NNP Taylor)) (VP (VBD entered) (NP (NP (NNP Daniel) (NNP Freeman) (NNP Marina) (NNP Hospital)) (PP (IN on) (NP (NNP April) (CD 9)))) (PP (IN with) (NP (DT a) (JJ persistent) (NN fever) (CC and) (NN sinus) (NN infection))))) (, ,) (NP (NNS doctors)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="entered Daniel Freeman Marina Hospital on April 9 with a persistent fever and sinus infection" type="VP">
          <tokens>
            <token id="3" string="entered" />
            <token id="4" string="Daniel" />
            <token id="5" string="Freeman" />
            <token id="6" string="Marina" />
            <token id="7" string="Hospital" />
            <token id="8" string="on" />
            <token id="9" string="April" />
            <token id="10" string="9" />
            <token id="11" string="with" />
            <token id="12" string="a" />
            <token id="13" string="persistent" />
            <token id="14" string="fever" />
            <token id="15" string="and" />
            <token id="16" string="sinus" />
            <token id="17" string="infection" />
          </tokens>
        </chunking>
        <chunking id="2" string="doctors" type="NP">
          <tokens>
            <token id="19" string="doctors" />
          </tokens>
        </chunking>
        <chunking id="3" string="April 9" type="NP">
          <tokens>
            <token id="9" string="April" />
            <token id="10" string="9" />
          </tokens>
        </chunking>
        <chunking id="4" string="Daniel Freeman Marina Hospital on April 9" type="NP">
          <tokens>
            <token id="4" string="Daniel" />
            <token id="5" string="Freeman" />
            <token id="6" string="Marina" />
            <token id="7" string="Hospital" />
            <token id="8" string="on" />
            <token id="9" string="April" />
            <token id="10" string="9" />
          </tokens>
        </chunking>
        <chunking id="5" string="Miss Taylor" type="NP">
          <tokens>
            <token id="1" string="Miss" />
            <token id="2" string="Taylor" />
          </tokens>
        </chunking>
        <chunking id="6" string="a persistent fever and sinus infection" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="persistent" />
            <token id="14" string="fever" />
            <token id="15" string="and" />
            <token id="16" string="sinus" />
            <token id="17" string="infection" />
          </tokens>
        </chunking>
        <chunking id="7" string="Daniel Freeman Marina Hospital" type="NP">
          <tokens>
            <token id="4" string="Daniel" />
            <token id="5" string="Freeman" />
            <token id="6" string="Marina" />
            <token id="7" string="Hospital" />
          </tokens>
        </chunking>
        <chunking id="8" string="said" type="VP">
          <tokens>
            <token id="20" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Taylor</governor>
          <dependent id="1">Miss</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">entered</governor>
          <dependent id="2">Taylor</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="20">said</governor>
          <dependent id="3">entered</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Hospital</governor>
          <dependent id="4">Daniel</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Hospital</governor>
          <dependent id="5">Freeman</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Hospital</governor>
          <dependent id="6">Marina</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">entered</governor>
          <dependent id="7">Hospital</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">April</governor>
          <dependent id="8">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">Hospital</governor>
          <dependent id="9">April</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="9">April</governor>
          <dependent id="10">9</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">fever</governor>
          <dependent id="11">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">fever</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">fever</governor>
          <dependent id="13">persistent</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">entered</governor>
          <dependent id="14">fever</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">fever</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">infection</governor>
          <dependent id="16">sinus</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">fever</governor>
          <dependent id="17">infection</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">said</governor>
          <dependent id="19">doctors</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="20">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="infection" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="17" string="infection" />
          </tokens>
        </entity>
        <entity id="2" string="Taylor" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Taylor" />
          </tokens>
        </entity>
        <entity id="3" string="April 9" type="DATE" score="0.0">
          <tokens>
            <token id="9" string="April" />
            <token id="10" string="9" />
          </tokens>
        </entity>
        <entity id="4" string="Daniel Freeman" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Daniel" />
            <token id="5" string="Freeman" />
          </tokens>
        </entity>
        <entity id="5" string="Marina Hospital" type="LOCATION" score="0.0">
          <tokens>
            <token id="6" string="Marina" />
            <token id="7" string="Hospital" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>Her condition worsened and she was transferred April 16 to St. John&amp;apost;s and moved into intensive care on Friday.</content>
      <tokens>
        <token id="1" string="Her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="condition" lemma="condition" stem="condit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="worsened" lemma="worsen" stem="worsen" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="transferred" lemma="transfer" stem="transfer" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="April" lemma="April" stem="april" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="9" string="16" lemma="16" stem="16" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="St." lemma="St." stem="st." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="12" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="13" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="moved" lemma="move" stem="move" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="intensive" lemma="intensive" stem="intens" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="care" lemma="care" stem="care" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Friday" lemma="Friday" stem="fridai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP$ Her) (NN condition)) (VP (VBD worsened))) (CC and) (S (NP (PRP she)) (VP (VP (VBD was) (VP (VBN transferred) (NP-TMP (NNP April) (CD 16)) (PP (TO to) (NP (NNP St.) (NNP John) (POS 's))))) (CC and) (VP (VBD moved) (PP (IN into) (NP (JJ intensive) (NN care))) (PP (IN on) (NP (NNP Friday)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Her condition" type="NP">
          <tokens>
            <token id="1" string="Her" />
            <token id="2" string="condition" />
          </tokens>
        </chunking>
        <chunking id="2" string="moved into intensive care on Friday" type="VP">
          <tokens>
            <token id="15" string="moved" />
            <token id="16" string="into" />
            <token id="17" string="intensive" />
            <token id="18" string="care" />
            <token id="19" string="on" />
            <token id="20" string="Friday" />
          </tokens>
        </chunking>
        <chunking id="3" string="intensive care" type="NP">
          <tokens>
            <token id="17" string="intensive" />
            <token id="18" string="care" />
          </tokens>
        </chunking>
        <chunking id="4" string="was transferred April 16 to St. John 's and moved into intensive care on Friday" type="VP">
          <tokens>
            <token id="6" string="was" />
            <token id="7" string="transferred" />
            <token id="8" string="April" />
            <token id="9" string="16" />
            <token id="10" string="to" />
            <token id="11" string="St." />
            <token id="12" string="John" />
            <token id="13" string="'s" />
            <token id="14" string="and" />
            <token id="15" string="moved" />
            <token id="16" string="into" />
            <token id="17" string="intensive" />
            <token id="18" string="care" />
            <token id="19" string="on" />
            <token id="20" string="Friday" />
          </tokens>
        </chunking>
        <chunking id="5" string="Friday" type="NP">
          <tokens>
            <token id="20" string="Friday" />
          </tokens>
        </chunking>
        <chunking id="6" string="was transferred April 16 to St. John 's" type="VP">
          <tokens>
            <token id="6" string="was" />
            <token id="7" string="transferred" />
            <token id="8" string="April" />
            <token id="9" string="16" />
            <token id="10" string="to" />
            <token id="11" string="St." />
            <token id="12" string="John" />
            <token id="13" string="'s" />
          </tokens>
        </chunking>
        <chunking id="7" string="transferred April 16 to St. John 's" type="VP">
          <tokens>
            <token id="7" string="transferred" />
            <token id="8" string="April" />
            <token id="9" string="16" />
            <token id="10" string="to" />
            <token id="11" string="St." />
            <token id="12" string="John" />
            <token id="13" string="'s" />
          </tokens>
        </chunking>
        <chunking id="8" string="worsened" type="VP">
          <tokens>
            <token id="3" string="worsened" />
          </tokens>
        </chunking>
        <chunking id="9" string="St. John 's" type="NP">
          <tokens>
            <token id="11" string="St." />
            <token id="12" string="John" />
            <token id="13" string="'s" />
          </tokens>
        </chunking>
        <chunking id="10" string="she" type="NP">
          <tokens>
            <token id="5" string="she" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="2">condition</governor>
          <dependent id="1">Her</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">worsened</governor>
          <dependent id="2">condition</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">worsened</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">worsened</governor>
          <dependent id="4">and</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="7">transferred</governor>
          <dependent id="5">she</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="7">transferred</governor>
          <dependent id="6">was</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">worsened</governor>
          <dependent id="7">transferred</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="7">transferred</governor>
          <dependent id="8">April</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="8">April</governor>
          <dependent id="9">16</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">John</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">John</governor>
          <dependent id="11">St.</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">transferred</governor>
          <dependent id="12">John</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">John</governor>
          <dependent id="13">'s</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">transferred</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">transferred</governor>
          <dependent id="15">moved</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">care</governor>
          <dependent id="16">into</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">care</governor>
          <dependent id="17">intensive</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">moved</governor>
          <dependent id="18">care</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">Friday</governor>
          <dependent id="19">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">moved</governor>
          <dependent id="20">Friday</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="St. John" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="St." />
            <token id="12" string="John" />
          </tokens>
        </entity>
        <entity id="2" string="Friday" type="DATE" score="0.0">
          <tokens>
            <token id="20" string="Friday" />
          </tokens>
        </entity>
        <entity id="3" string="April 16" type="DATE" score="0.0">
          <tokens>
            <token id="8" string="April" />
            <token id="9" string="16" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>``It is serious, but they are really pleased with her progress.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="serious" lemma="serious" stem="seriou" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="really" lemma="really" stem="realli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="pleased" lemma="please" stem="pleas" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="progress" lemma="progress" stem="progress" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP It)) (VP (VBZ is) (ADJP (JJ serious)))) (, ,) (CC but) (S (NP (PRP they)) (VP (VBP are) (ADVP (RB really)) (VP (VBN pleased) (PP (IN with) (NP (PRP$ her) (NN progress)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="they" type="NP">
          <tokens>
            <token id="7" string="they" />
          </tokens>
        </chunking>
        <chunking id="2" string="pleased with her progress" type="VP">
          <tokens>
            <token id="10" string="pleased" />
            <token id="11" string="with" />
            <token id="12" string="her" />
            <token id="13" string="progress" />
          </tokens>
        </chunking>
        <chunking id="3" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="4" string="are really pleased with her progress" type="VP">
          <tokens>
            <token id="8" string="are" />
            <token id="9" string="really" />
            <token id="10" string="pleased" />
            <token id="11" string="with" />
            <token id="12" string="her" />
            <token id="13" string="progress" />
          </tokens>
        </chunking>
        <chunking id="5" string="her progress" type="NP">
          <tokens>
            <token id="12" string="her" />
            <token id="13" string="progress" />
          </tokens>
        </chunking>
        <chunking id="6" string="is serious" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="serious" />
          </tokens>
        </chunking>
        <chunking id="7" string="serious" type="ADJP">
          <tokens>
            <token id="4" string="serious" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">serious</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">serious</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">serious</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">serious</governor>
          <dependent id="6">but</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="10">pleased</governor>
          <dependent id="7">they</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="10">pleased</governor>
          <dependent id="8">are</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">pleased</governor>
          <dependent id="9">really</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">serious</governor>
          <dependent id="10">pleased</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">progress</governor>
          <dependent id="11">with</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">progress</governor>
          <dependent id="12">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">pleased</governor>
          <dependent id="13">progress</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>She&amp;apost;s not well.</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="well" lemma="well" stem="well" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP She)) (VP (VBZ 's) (RB not) (ADVP (RB well))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="'s not well" type="VP">
          <tokens>
            <token id="2" string="'s" />
            <token id="3" string="not" />
            <token id="4" string="well" />
          </tokens>
        </chunking>
        <chunking id="2" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">'s</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="2">'s</governor>
          <dependent id="3">not</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="2">'s</governor>
          <dependent id="4">well</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>She&amp;apost;s not on her deathbed or anything,&amp;apost;&amp;apost; Ms. Sam said late Monday.</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="deathbed" lemma="deathbed" stem="deathb" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="anything" lemma="anything" stem="anyth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Ms." lemma="Ms." stem="ms." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="Sam" lemma="Sam" stem="sam" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="13" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="late" lemma="late" stem="late" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="15" string="Monday" lemma="Monday" stem="mondai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP She)) (VP (VBZ 's) (RB not) (PP (IN on) (NP (NP (PRP$ her) (JJ deathbed)) (CC or) (NP (NN anything)))))) (, ,) ('' '') (NP (NNP Ms.) (NNP Sam)) (VP (VBD said) (NP-TMP (JJ late) (NNP Monday))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Ms. Sam" type="NP">
          <tokens>
            <token id="11" string="Ms." />
            <token id="12" string="Sam" />
          </tokens>
        </chunking>
        <chunking id="2" string="'s not on her deathbed or anything" type="VP">
          <tokens>
            <token id="2" string="'s" />
            <token id="3" string="not" />
            <token id="4" string="on" />
            <token id="5" string="her" />
            <token id="6" string="deathbed" />
            <token id="7" string="or" />
            <token id="8" string="anything" />
          </tokens>
        </chunking>
        <chunking id="3" string="her deathbed or anything" type="NP">
          <tokens>
            <token id="5" string="her" />
            <token id="6" string="deathbed" />
            <token id="7" string="or" />
            <token id="8" string="anything" />
          </tokens>
        </chunking>
        <chunking id="4" string="her deathbed" type="NP">
          <tokens>
            <token id="5" string="her" />
            <token id="6" string="deathbed" />
          </tokens>
        </chunking>
        <chunking id="5" string="said late Monday" type="VP">
          <tokens>
            <token id="13" string="said" />
            <token id="14" string="late" />
            <token id="15" string="Monday" />
          </tokens>
        </chunking>
        <chunking id="6" string="anything" type="NP">
          <tokens>
            <token id="8" string="anything" />
          </tokens>
        </chunking>
        <chunking id="7" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">deathbed</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">deathbed</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">deathbed</governor>
          <dependent id="3">not</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">deathbed</governor>
          <dependent id="4">on</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">deathbed</governor>
          <dependent id="5">her</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">said</governor>
          <dependent id="6">deathbed</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">deathbed</governor>
          <dependent id="7">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">deathbed</governor>
          <dependent id="8">anything</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Sam</governor>
          <dependent id="11">Ms.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">said</governor>
          <dependent id="12">Sam</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">said</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">Monday</governor>
          <dependent id="14">late</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="13">said</governor>
          <dependent id="15">Monday</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="late Monday" type="DATE" score="0.0">
          <tokens>
            <token id="14" string="late" />
            <token id="15" string="Monday" />
          </tokens>
        </entity>
        <entity id="2" string="Sam" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Sam" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>While it is unusual to put a pneumonia patient on a ventilator, it does not mean that person is near death, said Dr. John G. Mohler, a University of Southern California lung disease expert who emphasized he had no direct knowledge of Miss Taylor&amp;apost;s condition.</content>
      <tokens>
        <token id="1" string="While" lemma="while" stem="while" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="unusual" lemma="unusual" stem="unusu" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="put" lemma="put" stem="put" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="pneumonia" lemma="pneumonia" stem="pneumonia" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="false" />
        <token id="9" string="patient" lemma="patient" stem="patient" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="ventilator" lemma="ventilator" stem="ventil" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="does" lemma="do" stem="doe" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="mean" lemma="mean" stem="mean" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="person" lemma="person" stem="person" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="near" lemma="near" stem="near" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="death" lemma="death" stem="death" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="Dr." lemma="Dr." stem="dr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="27" string="G." lemma="G." stem="g." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="28" string="Mohler" lemma="Mohler" stem="mohler" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="29" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="University" lemma="University" stem="univers" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="32" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="33" string="Southern" lemma="Southern" stem="southern" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="34" string="California" lemma="California" stem="california" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="35" string="lung" lemma="lung" stem="lung" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="37" string="expert" lemma="expert" stem="expert" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="emphasized" lemma="emphasize" stem="emphas" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="direct" lemma="direct" stem="direct" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="knowledge" lemma="knowledge" stem="knowledg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="47" string="Taylor" lemma="Taylor" stem="taylor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="48" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="49" string="condition" lemma="condition" stem="condit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="50" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (S (SBAR (IN While) (S (NP (PRP it)) (VP (VBZ is) (ADJP (JJ unusual) (S (VP (TO to) (VP (VB put) (NP (DT a) (NN pneumonia) (NN patient)) (PP (IN on) (NP (DT a) (NN ventilator)))))))))) (, ,) (NP (PRP it)) (VP (VBZ does) (RB not) (VP (VB mean) (SBAR (IN that) (S (NP (NN person)) (VP (VBZ is) (PP (IN near) (NP (NN death))))))))) (, ,) (VP (VBD said)) (NP (NP (NNP Dr.) (NNP John) (NNP G.) (NNP Mohler)) (, ,) (NP (NP (DT a) (NAC (NNP University) (PP (IN of) (NP (NNP Southern) (NNP California)))) (NN lung) (NN disease) (NN expert)) (SBAR (WHNP (WP who)) (S (VP (VBD emphasized) (SBAR (S (NP (PRP he)) (VP (VBD had) (NP (NP (DT no) (JJ direct) (NN knowledge)) (PP (IN of) (NP (NP (NNP Miss) (NNP Taylor) (POS 's)) (NN condition)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="While it is unusual to put a pneumonia patient on a ventilator" type="SBAR">
          <tokens>
            <token id="1" string="While" />
            <token id="2" string="it" />
            <token id="3" string="is" />
            <token id="4" string="unusual" />
            <token id="5" string="to" />
            <token id="6" string="put" />
            <token id="7" string="a" />
            <token id="8" string="pneumonia" />
            <token id="9" string="patient" />
            <token id="10" string="on" />
            <token id="11" string="a" />
            <token id="12" string="ventilator" />
          </tokens>
        </chunking>
        <chunking id="2" string="is near death" type="VP">
          <tokens>
            <token id="20" string="is" />
            <token id="21" string="near" />
            <token id="22" string="death" />
          </tokens>
        </chunking>
        <chunking id="3" string="Dr. John G. Mohler , a University of Southern California lung disease expert who emphasized he had no direct knowledge of Miss Taylor 's condition" type="NP">
          <tokens>
            <token id="25" string="Dr." />
            <token id="26" string="John" />
            <token id="27" string="G." />
            <token id="28" string="Mohler" />
            <token id="29" string="," />
            <token id="30" string="a" />
            <token id="31" string="University" />
            <token id="32" string="of" />
            <token id="33" string="Southern" />
            <token id="34" string="California" />
            <token id="35" string="lung" />
            <token id="36" string="disease" />
            <token id="37" string="expert" />
            <token id="38" string="who" />
            <token id="39" string="emphasized" />
            <token id="40" string="he" />
            <token id="41" string="had" />
            <token id="42" string="no" />
            <token id="43" string="direct" />
            <token id="44" string="knowledge" />
            <token id="45" string="of" />
            <token id="46" string="Miss" />
            <token id="47" string="Taylor" />
            <token id="48" string="'s" />
            <token id="49" string="condition" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="2" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="does not mean that person is near death" type="VP">
          <tokens>
            <token id="15" string="does" />
            <token id="16" string="not" />
            <token id="17" string="mean" />
            <token id="18" string="that" />
            <token id="19" string="person" />
            <token id="20" string="is" />
            <token id="21" string="near" />
            <token id="22" string="death" />
          </tokens>
        </chunking>
        <chunking id="6" string="Dr. John G. Mohler" type="NP">
          <tokens>
            <token id="25" string="Dr." />
            <token id="26" string="John" />
            <token id="27" string="G." />
            <token id="28" string="Mohler" />
          </tokens>
        </chunking>
        <chunking id="7" string="a University of Southern California lung disease expert" type="NP">
          <tokens>
            <token id="30" string="a" />
            <token id="31" string="University" />
            <token id="32" string="of" />
            <token id="33" string="Southern" />
            <token id="34" string="California" />
            <token id="35" string="lung" />
            <token id="36" string="disease" />
            <token id="37" string="expert" />
          </tokens>
        </chunking>
        <chunking id="8" string="to put a pneumonia patient on a ventilator" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="put" />
            <token id="7" string="a" />
            <token id="8" string="pneumonia" />
            <token id="9" string="patient" />
            <token id="10" string="on" />
            <token id="11" string="a" />
            <token id="12" string="ventilator" />
          </tokens>
        </chunking>
        <chunking id="9" string="a ventilator" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="ventilator" />
          </tokens>
        </chunking>
        <chunking id="10" string="Southern California" type="NP">
          <tokens>
            <token id="33" string="Southern" />
            <token id="34" string="California" />
          </tokens>
        </chunking>
        <chunking id="11" string="person" type="NP">
          <tokens>
            <token id="19" string="person" />
          </tokens>
        </chunking>
        <chunking id="12" string="Miss Taylor 's" type="NP">
          <tokens>
            <token id="46" string="Miss" />
            <token id="47" string="Taylor" />
            <token id="48" string="'s" />
          </tokens>
        </chunking>
        <chunking id="13" string="he" type="NP">
          <tokens>
            <token id="40" string="he" />
          </tokens>
        </chunking>
        <chunking id="14" string="mean that person is near death" type="VP">
          <tokens>
            <token id="17" string="mean" />
            <token id="18" string="that" />
            <token id="19" string="person" />
            <token id="20" string="is" />
            <token id="21" string="near" />
            <token id="22" string="death" />
          </tokens>
        </chunking>
        <chunking id="15" string="no direct knowledge" type="NP">
          <tokens>
            <token id="42" string="no" />
            <token id="43" string="direct" />
            <token id="44" string="knowledge" />
          </tokens>
        </chunking>
        <chunking id="16" string="death" type="NP">
          <tokens>
            <token id="22" string="death" />
          </tokens>
        </chunking>
        <chunking id="17" string="a University of Southern California lung disease expert who emphasized he had no direct knowledge of Miss Taylor 's condition" type="NP">
          <tokens>
            <token id="30" string="a" />
            <token id="31" string="University" />
            <token id="32" string="of" />
            <token id="33" string="Southern" />
            <token id="34" string="California" />
            <token id="35" string="lung" />
            <token id="36" string="disease" />
            <token id="37" string="expert" />
            <token id="38" string="who" />
            <token id="39" string="emphasized" />
            <token id="40" string="he" />
            <token id="41" string="had" />
            <token id="42" string="no" />
            <token id="43" string="direct" />
            <token id="44" string="knowledge" />
            <token id="45" string="of" />
            <token id="46" string="Miss" />
            <token id="47" string="Taylor" />
            <token id="48" string="'s" />
            <token id="49" string="condition" />
          </tokens>
        </chunking>
        <chunking id="18" string="who emphasized he had no direct knowledge of Miss Taylor 's condition" type="SBAR">
          <tokens>
            <token id="38" string="who" />
            <token id="39" string="emphasized" />
            <token id="40" string="he" />
            <token id="41" string="had" />
            <token id="42" string="no" />
            <token id="43" string="direct" />
            <token id="44" string="knowledge" />
            <token id="45" string="of" />
            <token id="46" string="Miss" />
            <token id="47" string="Taylor" />
            <token id="48" string="'s" />
            <token id="49" string="condition" />
          </tokens>
        </chunking>
        <chunking id="19" string="no direct knowledge of Miss Taylor 's condition" type="NP">
          <tokens>
            <token id="42" string="no" />
            <token id="43" string="direct" />
            <token id="44" string="knowledge" />
            <token id="45" string="of" />
            <token id="46" string="Miss" />
            <token id="47" string="Taylor" />
            <token id="48" string="'s" />
            <token id="49" string="condition" />
          </tokens>
        </chunking>
        <chunking id="20" string="put a pneumonia patient on a ventilator" type="VP">
          <tokens>
            <token id="6" string="put" />
            <token id="7" string="a" />
            <token id="8" string="pneumonia" />
            <token id="9" string="patient" />
            <token id="10" string="on" />
            <token id="11" string="a" />
            <token id="12" string="ventilator" />
          </tokens>
        </chunking>
        <chunking id="21" string="a pneumonia patient" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="pneumonia" />
            <token id="9" string="patient" />
          </tokens>
        </chunking>
        <chunking id="22" string="unusual to put a pneumonia patient on a ventilator" type="ADJP">
          <tokens>
            <token id="4" string="unusual" />
            <token id="5" string="to" />
            <token id="6" string="put" />
            <token id="7" string="a" />
            <token id="8" string="pneumonia" />
            <token id="9" string="patient" />
            <token id="10" string="on" />
            <token id="11" string="a" />
            <token id="12" string="ventilator" />
          </tokens>
        </chunking>
        <chunking id="23" string="emphasized he had no direct knowledge of Miss Taylor 's condition" type="VP">
          <tokens>
            <token id="39" string="emphasized" />
            <token id="40" string="he" />
            <token id="41" string="had" />
            <token id="42" string="no" />
            <token id="43" string="direct" />
            <token id="44" string="knowledge" />
            <token id="45" string="of" />
            <token id="46" string="Miss" />
            <token id="47" string="Taylor" />
            <token id="48" string="'s" />
            <token id="49" string="condition" />
          </tokens>
        </chunking>
        <chunking id="24" string="that person is near death" type="SBAR">
          <tokens>
            <token id="18" string="that" />
            <token id="19" string="person" />
            <token id="20" string="is" />
            <token id="21" string="near" />
            <token id="22" string="death" />
          </tokens>
        </chunking>
        <chunking id="25" string="he had no direct knowledge of Miss Taylor 's condition" type="SBAR">
          <tokens>
            <token id="40" string="he" />
            <token id="41" string="had" />
            <token id="42" string="no" />
            <token id="43" string="direct" />
            <token id="44" string="knowledge" />
            <token id="45" string="of" />
            <token id="46" string="Miss" />
            <token id="47" string="Taylor" />
            <token id="48" string="'s" />
            <token id="49" string="condition" />
          </tokens>
        </chunking>
        <chunking id="26" string="said" type="VP">
          <tokens>
            <token id="24" string="said" />
          </tokens>
        </chunking>
        <chunking id="27" string="had no direct knowledge of Miss Taylor 's condition" type="VP">
          <tokens>
            <token id="41" string="had" />
            <token id="42" string="no" />
            <token id="43" string="direct" />
            <token id="44" string="knowledge" />
            <token id="45" string="of" />
            <token id="46" string="Miss" />
            <token id="47" string="Taylor" />
            <token id="48" string="'s" />
            <token id="49" string="condition" />
          </tokens>
        </chunking>
        <chunking id="28" string="Miss Taylor 's condition" type="NP">
          <tokens>
            <token id="46" string="Miss" />
            <token id="47" string="Taylor" />
            <token id="48" string="'s" />
            <token id="49" string="condition" />
          </tokens>
        </chunking>
        <chunking id="29" string="is unusual to put a pneumonia patient on a ventilator" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="unusual" />
            <token id="5" string="to" />
            <token id="6" string="put" />
            <token id="7" string="a" />
            <token id="8" string="pneumonia" />
            <token id="9" string="patient" />
            <token id="10" string="on" />
            <token id="11" string="a" />
            <token id="12" string="ventilator" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="4">unusual</governor>
          <dependent id="1">While</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">unusual</governor>
          <dependent id="2">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">unusual</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="17">mean</governor>
          <dependent id="4">unusual</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">put</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">unusual</governor>
          <dependent id="6">put</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">patient</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">patient</governor>
          <dependent id="8">pneumonia</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">put</governor>
          <dependent id="9">patient</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">ventilator</governor>
          <dependent id="10">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">ventilator</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">put</governor>
          <dependent id="12">ventilator</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">mean</governor>
          <dependent id="14">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="17">mean</governor>
          <dependent id="15">does</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="17">mean</governor>
          <dependent id="16">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="24">said</governor>
          <dependent id="17">mean</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">death</governor>
          <dependent id="18">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">death</governor>
          <dependent id="19">person</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="22">death</governor>
          <dependent id="20">is</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">death</governor>
          <dependent id="21">near</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">mean</governor>
          <dependent id="22">death</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="24">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">Mohler</governor>
          <dependent id="25">Dr.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">Mohler</governor>
          <dependent id="26">John</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">Mohler</governor>
          <dependent id="27">G.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">said</governor>
          <dependent id="28">Mohler</dependent>
        </dependency>
        <dependency type="det">
          <governor id="37">expert</governor>
          <dependent id="30">a</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="37">expert</governor>
          <dependent id="31">University</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">California</governor>
          <dependent id="32">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="34">California</governor>
          <dependent id="33">Southern</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">University</governor>
          <dependent id="34">California</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="37">expert</governor>
          <dependent id="35">lung</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="37">expert</governor>
          <dependent id="36">disease</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="28">Mohler</governor>
          <dependent id="37">expert</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="39">emphasized</governor>
          <dependent id="38">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="37">expert</governor>
          <dependent id="39">emphasized</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="41">had</governor>
          <dependent id="40">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="39">emphasized</governor>
          <dependent id="41">had</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="44">knowledge</governor>
          <dependent id="42">no</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="44">knowledge</governor>
          <dependent id="43">direct</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="41">had</governor>
          <dependent id="44">knowledge</dependent>
        </dependency>
        <dependency type="case">
          <governor id="49">condition</governor>
          <dependent id="45">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="47">Taylor</governor>
          <dependent id="46">Miss</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="49">condition</governor>
          <dependent id="47">Taylor</dependent>
        </dependency>
        <dependency type="case">
          <governor id="47">Taylor</governor>
          <dependent id="48">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="44">knowledge</governor>
          <dependent id="49">condition</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="John G. Mohler" type="PERSON" score="0.0">
          <tokens>
            <token id="26" string="John" />
            <token id="27" string="G." />
            <token id="28" string="Mohler" />
          </tokens>
        </entity>
        <entity id="2" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="36" string="disease" />
          </tokens>
        </entity>
        <entity id="3" string="Taylor" type="PERSON" score="0.0">
          <tokens>
            <token id="47" string="Taylor" />
          </tokens>
        </entity>
        <entity id="4" string="pneumonia" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="8" string="pneumonia" />
          </tokens>
        </entity>
        <entity id="5" string="University of Southern California" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="31" string="University" />
            <token id="32" string="of" />
            <token id="33" string="Southern" />
            <token id="34" string="California" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>Doctors may put a patient on a ventilator simply to restore oxygen in the blood to proper levels if pneumonia-related breathing difficulties have reduced those levels, Mohler said.</content>
      <tokens>
        <token id="1" string="Doctors" lemma="doctor" stem="doctor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="put" lemma="put" stem="put" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="patient" lemma="patient" stem="patient" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="ventilator" lemma="ventilator" stem="ventil" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="simply" lemma="simply" stem="simpli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="restore" lemma="restore" stem="restor" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="oxygen" lemma="oxygen" stem="oxygen" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="blood" lemma="blood" stem="blood" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="proper" lemma="proper" stem="proper" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="levels" lemma="level" stem="level" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="pneumonia-related" lemma="pneumonia-related" stem="pneumonia-rel" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="breathing" lemma="breathing" stem="breath" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="difficulties" lemma="difficulty" stem="difficulti" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="reduced" lemma="reduce" stem="reduc" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="levels" lemma="level" stem="level" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="Mohler" lemma="Mohler" stem="mohler" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="29" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNS Doctors)) (VP (MD may) (VP (VB put) (NP (NP (DT a) (NN patient)) (PP (IN on) (NP (DT a) (NN ventilator)))) (ADVP (RB simply)) (S (VP (TO to) (VP (VB restore) (NP (NP (NN oxygen)) (PP (IN in) (NP (DT the) (NN blood)))) (PP (TO to) (NP (JJ proper) (NNS levels))) (SBAR (IN if) (S (NP (JJ pneumonia-related) (NN breathing) (NNS difficulties)) (VP (VBP have) (VP (VBN reduced) (NP (DT those) (NNS levels)))))))))))) (, ,) (NP (NNP Mohler)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="oxygen in the blood" type="NP">
          <tokens>
            <token id="12" string="oxygen" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="blood" />
          </tokens>
        </chunking>
        <chunking id="2" string="Mohler" type="NP">
          <tokens>
            <token id="28" string="Mohler" />
          </tokens>
        </chunking>
        <chunking id="3" string="a patient" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="patient" />
          </tokens>
        </chunking>
        <chunking id="4" string="oxygen" type="NP">
          <tokens>
            <token id="12" string="oxygen" />
          </tokens>
        </chunking>
        <chunking id="5" string="proper levels" type="NP">
          <tokens>
            <token id="17" string="proper" />
            <token id="18" string="levels" />
          </tokens>
        </chunking>
        <chunking id="6" string="Doctors" type="NP">
          <tokens>
            <token id="1" string="Doctors" />
          </tokens>
        </chunking>
        <chunking id="7" string="a patient on a ventilator" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="patient" />
            <token id="6" string="on" />
            <token id="7" string="a" />
            <token id="8" string="ventilator" />
          </tokens>
        </chunking>
        <chunking id="8" string="pneumonia-related breathing difficulties" type="NP">
          <tokens>
            <token id="20" string="pneumonia-related" />
            <token id="21" string="breathing" />
            <token id="22" string="difficulties" />
          </tokens>
        </chunking>
        <chunking id="9" string="restore oxygen in the blood to proper levels if pneumonia-related breathing difficulties have reduced those levels" type="VP">
          <tokens>
            <token id="11" string="restore" />
            <token id="12" string="oxygen" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="blood" />
            <token id="16" string="to" />
            <token id="17" string="proper" />
            <token id="18" string="levels" />
            <token id="19" string="if" />
            <token id="20" string="pneumonia-related" />
            <token id="21" string="breathing" />
            <token id="22" string="difficulties" />
            <token id="23" string="have" />
            <token id="24" string="reduced" />
            <token id="25" string="those" />
            <token id="26" string="levels" />
          </tokens>
        </chunking>
        <chunking id="10" string="a ventilator" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="ventilator" />
          </tokens>
        </chunking>
        <chunking id="11" string="if pneumonia-related breathing difficulties have reduced those levels" type="SBAR">
          <tokens>
            <token id="19" string="if" />
            <token id="20" string="pneumonia-related" />
            <token id="21" string="breathing" />
            <token id="22" string="difficulties" />
            <token id="23" string="have" />
            <token id="24" string="reduced" />
            <token id="25" string="those" />
            <token id="26" string="levels" />
          </tokens>
        </chunking>
        <chunking id="12" string="those levels" type="NP">
          <tokens>
            <token id="25" string="those" />
            <token id="26" string="levels" />
          </tokens>
        </chunking>
        <chunking id="13" string="put a patient on a ventilator simply to restore oxygen in the blood to proper levels if pneumonia-related breathing difficulties have reduced those levels" type="VP">
          <tokens>
            <token id="3" string="put" />
            <token id="4" string="a" />
            <token id="5" string="patient" />
            <token id="6" string="on" />
            <token id="7" string="a" />
            <token id="8" string="ventilator" />
            <token id="9" string="simply" />
            <token id="10" string="to" />
            <token id="11" string="restore" />
            <token id="12" string="oxygen" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="blood" />
            <token id="16" string="to" />
            <token id="17" string="proper" />
            <token id="18" string="levels" />
            <token id="19" string="if" />
            <token id="20" string="pneumonia-related" />
            <token id="21" string="breathing" />
            <token id="22" string="difficulties" />
            <token id="23" string="have" />
            <token id="24" string="reduced" />
            <token id="25" string="those" />
            <token id="26" string="levels" />
          </tokens>
        </chunking>
        <chunking id="14" string="the blood" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="blood" />
          </tokens>
        </chunking>
        <chunking id="15" string="may put a patient on a ventilator simply to restore oxygen in the blood to proper levels if pneumonia-related breathing difficulties have reduced those levels" type="VP">
          <tokens>
            <token id="2" string="may" />
            <token id="3" string="put" />
            <token id="4" string="a" />
            <token id="5" string="patient" />
            <token id="6" string="on" />
            <token id="7" string="a" />
            <token id="8" string="ventilator" />
            <token id="9" string="simply" />
            <token id="10" string="to" />
            <token id="11" string="restore" />
            <token id="12" string="oxygen" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="blood" />
            <token id="16" string="to" />
            <token id="17" string="proper" />
            <token id="18" string="levels" />
            <token id="19" string="if" />
            <token id="20" string="pneumonia-related" />
            <token id="21" string="breathing" />
            <token id="22" string="difficulties" />
            <token id="23" string="have" />
            <token id="24" string="reduced" />
            <token id="25" string="those" />
            <token id="26" string="levels" />
          </tokens>
        </chunking>
        <chunking id="16" string="to restore oxygen in the blood to proper levels if pneumonia-related breathing difficulties have reduced those levels" type="VP">
          <tokens>
            <token id="10" string="to" />
            <token id="11" string="restore" />
            <token id="12" string="oxygen" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="blood" />
            <token id="16" string="to" />
            <token id="17" string="proper" />
            <token id="18" string="levels" />
            <token id="19" string="if" />
            <token id="20" string="pneumonia-related" />
            <token id="21" string="breathing" />
            <token id="22" string="difficulties" />
            <token id="23" string="have" />
            <token id="24" string="reduced" />
            <token id="25" string="those" />
            <token id="26" string="levels" />
          </tokens>
        </chunking>
        <chunking id="17" string="reduced those levels" type="VP">
          <tokens>
            <token id="24" string="reduced" />
            <token id="25" string="those" />
            <token id="26" string="levels" />
          </tokens>
        </chunking>
        <chunking id="18" string="have reduced those levels" type="VP">
          <tokens>
            <token id="23" string="have" />
            <token id="24" string="reduced" />
            <token id="25" string="those" />
            <token id="26" string="levels" />
          </tokens>
        </chunking>
        <chunking id="19" string="said" type="VP">
          <tokens>
            <token id="29" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">put</governor>
          <dependent id="1">Doctors</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">put</governor>
          <dependent id="2">may</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="29">said</governor>
          <dependent id="3">put</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">patient</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">put</governor>
          <dependent id="5">patient</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">ventilator</governor>
          <dependent id="6">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">ventilator</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">patient</governor>
          <dependent id="8">ventilator</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">put</governor>
          <dependent id="9">simply</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">restore</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">put</governor>
          <dependent id="11">restore</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">restore</governor>
          <dependent id="12">oxygen</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">blood</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">blood</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">oxygen</governor>
          <dependent id="15">blood</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">levels</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">levels</governor>
          <dependent id="17">proper</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">restore</governor>
          <dependent id="18">levels</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">reduced</governor>
          <dependent id="19">if</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">difficulties</governor>
          <dependent id="20">pneumonia-related</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">difficulties</governor>
          <dependent id="21">breathing</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">reduced</governor>
          <dependent id="22">difficulties</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="24">reduced</governor>
          <dependent id="23">have</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">restore</governor>
          <dependent id="24">reduced</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">levels</governor>
          <dependent id="25">those</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">reduced</governor>
          <dependent id="26">levels</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">said</governor>
          <dependent id="28">Mohler</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="29">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Mohler" type="PERSON" score="0.0">
          <tokens>
            <token id="28" string="Mohler" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>``It may be that because she is such a prominent person, they are taking a conservative course,&amp;apost;&amp;apost; he added.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="prominent" lemma="prominent" stem="promin" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="person" lemma="person" stem="person" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="taking" lemma="take" stem="take" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="conservative" lemma="conservative" stem="conserv" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="19" string="course" lemma="course" stem="cours" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="added" lemma="add" stem="ad" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP It)) (VP (MD may) (VP (VB be) (SBAR (IN that) (S (SBAR (IN because) (S (NP (PRP she)) (VP (VBZ is) (PP (JJ such) (NP (DT a) (JJ prominent) (NN person)))))) (, ,) (NP (PRP they)) (VP (VBP are) (VP (VBG taking) (NP (DT a) (JJ conservative) (NN course))))))))) (, ,) ('' '') (NP (PRP he)) (VP (VBD added)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a conservative course" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="conservative" />
            <token id="19" string="course" />
          </tokens>
        </chunking>
        <chunking id="2" string="is such a prominent person" type="VP">
          <tokens>
            <token id="8" string="is" />
            <token id="9" string="such" />
            <token id="10" string="a" />
            <token id="11" string="prominent" />
            <token id="12" string="person" />
          </tokens>
        </chunking>
        <chunking id="3" string="may be that because she is such a prominent person , they are taking a conservative course" type="VP">
          <tokens>
            <token id="3" string="may" />
            <token id="4" string="be" />
            <token id="5" string="that" />
            <token id="6" string="because" />
            <token id="7" string="she" />
            <token id="8" string="is" />
            <token id="9" string="such" />
            <token id="10" string="a" />
            <token id="11" string="prominent" />
            <token id="12" string="person" />
            <token id="13" string="," />
            <token id="14" string="they" />
            <token id="15" string="are" />
            <token id="16" string="taking" />
            <token id="17" string="a" />
            <token id="18" string="conservative" />
            <token id="19" string="course" />
          </tokens>
        </chunking>
        <chunking id="4" string="that because she is such a prominent person , they are taking a conservative course" type="SBAR">
          <tokens>
            <token id="5" string="that" />
            <token id="6" string="because" />
            <token id="7" string="she" />
            <token id="8" string="is" />
            <token id="9" string="such" />
            <token id="10" string="a" />
            <token id="11" string="prominent" />
            <token id="12" string="person" />
            <token id="13" string="," />
            <token id="14" string="they" />
            <token id="15" string="are" />
            <token id="16" string="taking" />
            <token id="17" string="a" />
            <token id="18" string="conservative" />
            <token id="19" string="course" />
          </tokens>
        </chunking>
        <chunking id="5" string="taking a conservative course" type="VP">
          <tokens>
            <token id="16" string="taking" />
            <token id="17" string="a" />
            <token id="18" string="conservative" />
            <token id="19" string="course" />
          </tokens>
        </chunking>
        <chunking id="6" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="7" string="she" type="NP">
          <tokens>
            <token id="7" string="she" />
          </tokens>
        </chunking>
        <chunking id="8" string="they" type="NP">
          <tokens>
            <token id="14" string="they" />
          </tokens>
        </chunking>
        <chunking id="9" string="be that because she is such a prominent person , they are taking a conservative course" type="VP">
          <tokens>
            <token id="4" string="be" />
            <token id="5" string="that" />
            <token id="6" string="because" />
            <token id="7" string="she" />
            <token id="8" string="is" />
            <token id="9" string="such" />
            <token id="10" string="a" />
            <token id="11" string="prominent" />
            <token id="12" string="person" />
            <token id="13" string="," />
            <token id="14" string="they" />
            <token id="15" string="are" />
            <token id="16" string="taking" />
            <token id="17" string="a" />
            <token id="18" string="conservative" />
            <token id="19" string="course" />
          </tokens>
        </chunking>
        <chunking id="10" string="because she is such a prominent person" type="SBAR">
          <tokens>
            <token id="6" string="because" />
            <token id="7" string="she" />
            <token id="8" string="is" />
            <token id="9" string="such" />
            <token id="10" string="a" />
            <token id="11" string="prominent" />
            <token id="12" string="person" />
          </tokens>
        </chunking>
        <chunking id="11" string="are taking a conservative course" type="VP">
          <tokens>
            <token id="15" string="are" />
            <token id="16" string="taking" />
            <token id="17" string="a" />
            <token id="18" string="conservative" />
            <token id="19" string="course" />
          </tokens>
        </chunking>
        <chunking id="12" string="added" type="VP">
          <tokens>
            <token id="23" string="added" />
          </tokens>
        </chunking>
        <chunking id="13" string="he" type="NP">
          <tokens>
            <token id="22" string="he" />
          </tokens>
        </chunking>
        <chunking id="14" string="a prominent person" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="prominent" />
            <token id="12" string="person" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">be</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">be</governor>
          <dependent id="3">may</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="23">added</governor>
          <dependent id="4">be</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">taking</governor>
          <dependent id="5">that</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">person</governor>
          <dependent id="6">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">person</governor>
          <dependent id="7">she</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">person</governor>
          <dependent id="8">is</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">person</governor>
          <dependent id="9">such</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">person</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">person</governor>
          <dependent id="11">prominent</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="16">taking</governor>
          <dependent id="12">person</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">taking</governor>
          <dependent id="14">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">taking</governor>
          <dependent id="15">are</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">be</governor>
          <dependent id="16">taking</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">course</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">course</governor>
          <dependent id="18">conservative</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">taking</governor>
          <dependent id="19">course</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">added</governor>
          <dependent id="22">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="23">added</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="conservative" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="18" string="conservative" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>Miss Taylor has been plagued with health problems for years, particularly back troubles from filming of ``National Velvet&amp;apost; in 1945, when she fell off a horse.</content>
      <tokens>
        <token id="1" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="Taylor" lemma="Taylor" stem="taylor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="plagued" lemma="plague" stem="plagu" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="health" lemma="health" stem="health" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="problems" lemma="problem" stem="problem" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="particularly" lemma="particularly" stem="particularli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="back" lemma="back" stem="back" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="troubles" lemma="trouble" stem="troubl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="filming" lemma="film" stem="film" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="National" lemma="National" stem="nation" pos="NNP" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="20" string="Velvet" lemma="Velvet" stem="velvet" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="1945" lemma="1945" stem="1945" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="fell" lemma="fall" stem="fell" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="off" lemma="off" stem="off" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="horse" lemma="horse" stem="hors" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Miss) (NNP Taylor)) (VP (VBZ has) (VP (VBN been) (VP (VBN plagued) (PP (IN with) (NP (NP (NN health) (NNS problems)) (PP (IN for) (NP (NP (NNS years)) (, ,) (RB particularly) (RB back) (NP (NNS troubles)))))) (PP (IN from) (S (VP (VBG filming) (PP (IN of) (`` ``) (NP (NP (NNP National) (NNP Velvet) (POS ')) (PP (IN in) (NP (CD 1945)))))))) (, ,) (SBAR (WHADVP (WRB when)) (S (NP (PRP she)) (VP (VBD fell) (PRT (RP off)) (NP (DT a) (NN horse)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="been plagued with health problems for years , particularly back troubles from filming of `` National Velvet ' in 1945 , when she fell off a horse" type="VP">
          <tokens>
            <token id="4" string="been" />
            <token id="5" string="plagued" />
            <token id="6" string="with" />
            <token id="7" string="health" />
            <token id="8" string="problems" />
            <token id="9" string="for" />
            <token id="10" string="years" />
            <token id="11" string="," />
            <token id="12" string="particularly" />
            <token id="13" string="back" />
            <token id="14" string="troubles" />
            <token id="15" string="from" />
            <token id="16" string="filming" />
            <token id="17" string="of" />
            <token id="18" string="``" />
            <token id="19" string="National" />
            <token id="20" string="Velvet" />
            <token id="21" string="'" />
            <token id="22" string="in" />
            <token id="23" string="1945" />
            <token id="24" string="," />
            <token id="25" string="when" />
            <token id="26" string="she" />
            <token id="27" string="fell" />
            <token id="28" string="off" />
            <token id="29" string="a" />
            <token id="30" string="horse" />
          </tokens>
        </chunking>
        <chunking id="2" string="National Velvet '" type="NP">
          <tokens>
            <token id="19" string="National" />
            <token id="20" string="Velvet" />
            <token id="21" string="'" />
          </tokens>
        </chunking>
        <chunking id="3" string="when she fell off a horse" type="SBAR">
          <tokens>
            <token id="25" string="when" />
            <token id="26" string="she" />
            <token id="27" string="fell" />
            <token id="28" string="off" />
            <token id="29" string="a" />
            <token id="30" string="horse" />
          </tokens>
        </chunking>
        <chunking id="4" string="troubles" type="NP">
          <tokens>
            <token id="14" string="troubles" />
          </tokens>
        </chunking>
        <chunking id="5" string="years , particularly back troubles" type="NP">
          <tokens>
            <token id="10" string="years" />
            <token id="11" string="," />
            <token id="12" string="particularly" />
            <token id="13" string="back" />
            <token id="14" string="troubles" />
          </tokens>
        </chunking>
        <chunking id="6" string="years" type="NP">
          <tokens>
            <token id="10" string="years" />
          </tokens>
        </chunking>
        <chunking id="7" string="when" type="WHADVP">
          <tokens>
            <token id="25" string="when" />
          </tokens>
        </chunking>
        <chunking id="8" string="she" type="NP">
          <tokens>
            <token id="26" string="she" />
          </tokens>
        </chunking>
        <chunking id="9" string="plagued with health problems for years , particularly back troubles from filming of `` National Velvet ' in 1945 , when she fell off a horse" type="VP">
          <tokens>
            <token id="5" string="plagued" />
            <token id="6" string="with" />
            <token id="7" string="health" />
            <token id="8" string="problems" />
            <token id="9" string="for" />
            <token id="10" string="years" />
            <token id="11" string="," />
            <token id="12" string="particularly" />
            <token id="13" string="back" />
            <token id="14" string="troubles" />
            <token id="15" string="from" />
            <token id="16" string="filming" />
            <token id="17" string="of" />
            <token id="18" string="``" />
            <token id="19" string="National" />
            <token id="20" string="Velvet" />
            <token id="21" string="'" />
            <token id="22" string="in" />
            <token id="23" string="1945" />
            <token id="24" string="," />
            <token id="25" string="when" />
            <token id="26" string="she" />
            <token id="27" string="fell" />
            <token id="28" string="off" />
            <token id="29" string="a" />
            <token id="30" string="horse" />
          </tokens>
        </chunking>
        <chunking id="10" string="National Velvet ' in 1945" type="NP">
          <tokens>
            <token id="19" string="National" />
            <token id="20" string="Velvet" />
            <token id="21" string="'" />
            <token id="22" string="in" />
            <token id="23" string="1945" />
          </tokens>
        </chunking>
        <chunking id="11" string="health problems for years , particularly back troubles" type="NP">
          <tokens>
            <token id="7" string="health" />
            <token id="8" string="problems" />
            <token id="9" string="for" />
            <token id="10" string="years" />
            <token id="11" string="," />
            <token id="12" string="particularly" />
            <token id="13" string="back" />
            <token id="14" string="troubles" />
          </tokens>
        </chunking>
        <chunking id="12" string="has been plagued with health problems for years , particularly back troubles from filming of `` National Velvet ' in 1945 , when she fell off a horse" type="VP">
          <tokens>
            <token id="3" string="has" />
            <token id="4" string="been" />
            <token id="5" string="plagued" />
            <token id="6" string="with" />
            <token id="7" string="health" />
            <token id="8" string="problems" />
            <token id="9" string="for" />
            <token id="10" string="years" />
            <token id="11" string="," />
            <token id="12" string="particularly" />
            <token id="13" string="back" />
            <token id="14" string="troubles" />
            <token id="15" string="from" />
            <token id="16" string="filming" />
            <token id="17" string="of" />
            <token id="18" string="``" />
            <token id="19" string="National" />
            <token id="20" string="Velvet" />
            <token id="21" string="'" />
            <token id="22" string="in" />
            <token id="23" string="1945" />
            <token id="24" string="," />
            <token id="25" string="when" />
            <token id="26" string="she" />
            <token id="27" string="fell" />
            <token id="28" string="off" />
            <token id="29" string="a" />
            <token id="30" string="horse" />
          </tokens>
        </chunking>
        <chunking id="13" string="a horse" type="NP">
          <tokens>
            <token id="29" string="a" />
            <token id="30" string="horse" />
          </tokens>
        </chunking>
        <chunking id="14" string="Miss Taylor" type="NP">
          <tokens>
            <token id="1" string="Miss" />
            <token id="2" string="Taylor" />
          </tokens>
        </chunking>
        <chunking id="15" string="health problems" type="NP">
          <tokens>
            <token id="7" string="health" />
            <token id="8" string="problems" />
          </tokens>
        </chunking>
        <chunking id="16" string="fell off a horse" type="VP">
          <tokens>
            <token id="27" string="fell" />
            <token id="28" string="off" />
            <token id="29" string="a" />
            <token id="30" string="horse" />
          </tokens>
        </chunking>
        <chunking id="17" string="filming of `` National Velvet ' in 1945" type="VP">
          <tokens>
            <token id="16" string="filming" />
            <token id="17" string="of" />
            <token id="18" string="``" />
            <token id="19" string="National" />
            <token id="20" string="Velvet" />
            <token id="21" string="'" />
            <token id="22" string="in" />
            <token id="23" string="1945" />
          </tokens>
        </chunking>
        <chunking id="18" string="1945" type="NP">
          <tokens>
            <token id="23" string="1945" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Taylor</governor>
          <dependent id="1">Miss</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="5">plagued</governor>
          <dependent id="2">Taylor</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">plagued</governor>
          <dependent id="3">has</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">plagued</governor>
          <dependent id="4">been</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">plagued</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">problems</governor>
          <dependent id="6">with</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">problems</governor>
          <dependent id="7">health</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">plagued</governor>
          <dependent id="8">problems</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">years</governor>
          <dependent id="9">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">problems</governor>
          <dependent id="10">years</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">years</governor>
          <dependent id="12">particularly</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">years</governor>
          <dependent id="13">back</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="10">years</governor>
          <dependent id="14">troubles</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">filming</governor>
          <dependent id="15">from</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">plagued</governor>
          <dependent id="16">filming</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">Velvet</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Velvet</governor>
          <dependent id="19">National</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">filming</governor>
          <dependent id="20">Velvet</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">Velvet</governor>
          <dependent id="21">'</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">1945</governor>
          <dependent id="22">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">Velvet</governor>
          <dependent id="23">1945</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="27">fell</governor>
          <dependent id="25">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">fell</governor>
          <dependent id="26">she</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">plagued</governor>
          <dependent id="27">fell</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="27">fell</governor>
          <dependent id="28">off</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">horse</governor>
          <dependent id="29">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="27">fell</governor>
          <dependent id="30">horse</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Taylor" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Taylor" />
          </tokens>
        </entity>
        <entity id="2" string="National" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="19" string="National" />
          </tokens>
        </entity>
        <entity id="3" string="years" type="DURATION" score="0.0">
          <tokens>
            <token id="10" string="years" />
          </tokens>
        </entity>
        <entity id="4" string="1945" type="DATE" score="0.0">
          <tokens>
            <token id="23" string="1945" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>In 1983 she acknowledged a 35-year addiction to sleeping pills and painkillers.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="1983" lemma="1983" stem="1983" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="acknowledged" lemma="acknowledge" stem="acknowledg" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="35-year" lemma="35-year" stem="35-year" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="7" string="addiction" lemma="addiction" stem="addict" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="sleeping" lemma="sleep" stem="sleep" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="pills" lemma="pill" stem="pill" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="painkillers" lemma="painkiller" stem="painkil" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (CD 1983))) (NP (PRP she)) (VP (VBD acknowledged) (NP (DT a) (JJ 35-year) (NN addiction)) (PP (TO to) (NP (NP (VBG sleeping) (NNS pills)) (CC and) (NP (NNS painkillers))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="painkillers" type="NP">
          <tokens>
            <token id="12" string="painkillers" />
          </tokens>
        </chunking>
        <chunking id="2" string="sleeping pills" type="NP">
          <tokens>
            <token id="9" string="sleeping" />
            <token id="10" string="pills" />
          </tokens>
        </chunking>
        <chunking id="3" string="1983" type="NP">
          <tokens>
            <token id="2" string="1983" />
          </tokens>
        </chunking>
        <chunking id="4" string="sleeping pills and painkillers" type="NP">
          <tokens>
            <token id="9" string="sleeping" />
            <token id="10" string="pills" />
            <token id="11" string="and" />
            <token id="12" string="painkillers" />
          </tokens>
        </chunking>
        <chunking id="5" string="acknowledged a 35-year addiction to sleeping pills and painkillers" type="VP">
          <tokens>
            <token id="4" string="acknowledged" />
            <token id="5" string="a" />
            <token id="6" string="35-year" />
            <token id="7" string="addiction" />
            <token id="8" string="to" />
            <token id="9" string="sleeping" />
            <token id="10" string="pills" />
            <token id="11" string="and" />
            <token id="12" string="painkillers" />
          </tokens>
        </chunking>
        <chunking id="6" string="a 35-year addiction" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="35-year" />
            <token id="7" string="addiction" />
          </tokens>
        </chunking>
        <chunking id="7" string="she" type="NP">
          <tokens>
            <token id="3" string="she" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">1983</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">acknowledged</governor>
          <dependent id="2">1983</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">acknowledged</governor>
          <dependent id="3">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">acknowledged</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">addiction</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">addiction</governor>
          <dependent id="6">35-year</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">acknowledged</governor>
          <dependent id="7">addiction</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">pills</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">pills</governor>
          <dependent id="9">sleeping</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">acknowledged</governor>
          <dependent id="10">pills</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">pills</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">pills</governor>
          <dependent id="12">painkillers</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1983" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="1983" />
          </tokens>
        </entity>
        <entity id="2" string="35-year" type="DURATION" score="0.0">
          <tokens>
            <token id="6" string="35-year" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>Miss Taylor has been treated for alcohol and drug abuse at the Betty Ford Clinic.</content>
      <tokens>
        <token id="1" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="Taylor" lemma="Taylor" stem="taylor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="treated" lemma="treat" stem="treat" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="alcohol" lemma="alcohol" stem="alcohol" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="drug" lemma="drug" stem="drug" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="abuse" lemma="abuse" stem="abus" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Betty" lemma="Betty" stem="betti" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="14" string="Ford" lemma="Ford" stem="ford" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="15" string="Clinic" lemma="Clinic" stem="clinic" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Miss) (NNP Taylor)) (VP (VBZ has) (VP (VBN been) (VP (VBN treated) (PP (IN for) (NP (UCP (NN alcohol) (CC and) (NN drug)) (NN abuse))) (PP (IN at) (NP (DT the) (NNP Betty) (NNP Ford) (NNP Clinic)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="alcohol and drug abuse" type="NP">
          <tokens>
            <token id="7" string="alcohol" />
            <token id="8" string="and" />
            <token id="9" string="drug" />
            <token id="10" string="abuse" />
          </tokens>
        </chunking>
        <chunking id="2" string="treated for alcohol and drug abuse at the Betty Ford Clinic" type="VP">
          <tokens>
            <token id="5" string="treated" />
            <token id="6" string="for" />
            <token id="7" string="alcohol" />
            <token id="8" string="and" />
            <token id="9" string="drug" />
            <token id="10" string="abuse" />
            <token id="11" string="at" />
            <token id="12" string="the" />
            <token id="13" string="Betty" />
            <token id="14" string="Ford" />
            <token id="15" string="Clinic" />
          </tokens>
        </chunking>
        <chunking id="3" string="been treated for alcohol and drug abuse at the Betty Ford Clinic" type="VP">
          <tokens>
            <token id="4" string="been" />
            <token id="5" string="treated" />
            <token id="6" string="for" />
            <token id="7" string="alcohol" />
            <token id="8" string="and" />
            <token id="9" string="drug" />
            <token id="10" string="abuse" />
            <token id="11" string="at" />
            <token id="12" string="the" />
            <token id="13" string="Betty" />
            <token id="14" string="Ford" />
            <token id="15" string="Clinic" />
          </tokens>
        </chunking>
        <chunking id="4" string="Miss Taylor" type="NP">
          <tokens>
            <token id="1" string="Miss" />
            <token id="2" string="Taylor" />
          </tokens>
        </chunking>
        <chunking id="5" string="has been treated for alcohol and drug abuse at the Betty Ford Clinic" type="VP">
          <tokens>
            <token id="3" string="has" />
            <token id="4" string="been" />
            <token id="5" string="treated" />
            <token id="6" string="for" />
            <token id="7" string="alcohol" />
            <token id="8" string="and" />
            <token id="9" string="drug" />
            <token id="10" string="abuse" />
            <token id="11" string="at" />
            <token id="12" string="the" />
            <token id="13" string="Betty" />
            <token id="14" string="Ford" />
            <token id="15" string="Clinic" />
          </tokens>
        </chunking>
        <chunking id="6" string="the Betty Ford Clinic" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="Betty" />
            <token id="14" string="Ford" />
            <token id="15" string="Clinic" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Taylor</governor>
          <dependent id="1">Miss</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="5">treated</governor>
          <dependent id="2">Taylor</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">treated</governor>
          <dependent id="3">has</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">treated</governor>
          <dependent id="4">been</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">treated</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">abuse</governor>
          <dependent id="6">for</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">abuse</governor>
          <dependent id="7">alcohol</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">alcohol</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">alcohol</governor>
          <dependent id="9">drug</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">treated</governor>
          <dependent id="10">abuse</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">Clinic</governor>
          <dependent id="11">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">Clinic</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Clinic</governor>
          <dependent id="13">Betty</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Clinic</governor>
          <dependent id="14">Ford</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">treated</governor>
          <dependent id="15">Clinic</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Taylor" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Taylor" />
          </tokens>
        </entity>
        <entity id="2" string="Betty Ford Clinic" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="13" string="Betty" />
            <token id="14" string="Ford" />
            <token id="15" string="Clinic" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>During a nearly fatal bout with pneumonia in 1961, Miss Taylor underwent a tracheotomy, an incision into her windpipe to help her breathe.</content>
      <tokens>
        <token id="1" string="During" lemma="during" stem="dure" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="nearly" lemma="nearly" stem="nearli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="fatal" lemma="fatal" stem="fatal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="bout" lemma="bout" stem="bout" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="pneumonia" lemma="pneumonia" stem="pneumonia" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="1961" lemma="1961" stem="1961" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="Taylor" lemma="Taylor" stem="taylor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="13" string="underwent" lemma="undergo" stem="underw" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="tracheotomy" lemma="tracheotomy" stem="tracheotomi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="incision" lemma="incision" stem="incis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="windpipe" lemma="windpipe" stem="windpip" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="help" lemma="help" stem="help" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="breathe" lemma="breathe" stem="breath" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN During) (NP (NP (DT a) (ADJP (RB nearly) (JJ fatal)) (NN bout)) (PP (IN with) (NP (NP (NN pneumonia)) (PP (IN in) (NP (CD 1961))))))) (, ,) (NP (NNP Miss) (NNP Taylor)) (VP (VBD underwent) (NP (NP (DT a) (NN tracheotomy)) (, ,) (NP (DT an) (NN incision))) (PP (IN into) (NP (PRP$ her) (NN windpipe) (S (VP (TO to) (VP (VB help) (SBAR (S (NP (PRP$ her)) (VP (VBP breathe)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="pneumonia in 1961" type="NP">
          <tokens>
            <token id="7" string="pneumonia" />
            <token id="8" string="in" />
            <token id="9" string="1961" />
          </tokens>
        </chunking>
        <chunking id="2" string="an incision" type="NP">
          <tokens>
            <token id="17" string="an" />
            <token id="18" string="incision" />
          </tokens>
        </chunking>
        <chunking id="3" string="nearly fatal" type="ADJP">
          <tokens>
            <token id="3" string="nearly" />
            <token id="4" string="fatal" />
          </tokens>
        </chunking>
        <chunking id="4" string="breathe" type="VP">
          <tokens>
            <token id="25" string="breathe" />
          </tokens>
        </chunking>
        <chunking id="5" string="a tracheotomy , an incision" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="tracheotomy" />
            <token id="16" string="," />
            <token id="17" string="an" />
            <token id="18" string="incision" />
          </tokens>
        </chunking>
        <chunking id="6" string="help her breathe" type="VP">
          <tokens>
            <token id="23" string="help" />
            <token id="24" string="her" />
            <token id="25" string="breathe" />
          </tokens>
        </chunking>
        <chunking id="7" string="a nearly fatal bout" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="nearly" />
            <token id="4" string="fatal" />
            <token id="5" string="bout" />
          </tokens>
        </chunking>
        <chunking id="8" string="underwent a tracheotomy , an incision into her windpipe to help her breathe" type="VP">
          <tokens>
            <token id="13" string="underwent" />
            <token id="14" string="a" />
            <token id="15" string="tracheotomy" />
            <token id="16" string="," />
            <token id="17" string="an" />
            <token id="18" string="incision" />
            <token id="19" string="into" />
            <token id="20" string="her" />
            <token id="21" string="windpipe" />
            <token id="22" string="to" />
            <token id="23" string="help" />
            <token id="24" string="her" />
            <token id="25" string="breathe" />
          </tokens>
        </chunking>
        <chunking id="9" string="her breathe" type="SBAR">
          <tokens>
            <token id="24" string="her" />
            <token id="25" string="breathe" />
          </tokens>
        </chunking>
        <chunking id="10" string="1961" type="NP">
          <tokens>
            <token id="9" string="1961" />
          </tokens>
        </chunking>
        <chunking id="11" string="her" type="NP">
          <tokens>
            <token id="24" string="her" />
          </tokens>
        </chunking>
        <chunking id="12" string="pneumonia" type="NP">
          <tokens>
            <token id="7" string="pneumonia" />
          </tokens>
        </chunking>
        <chunking id="13" string="to help her breathe" type="VP">
          <tokens>
            <token id="22" string="to" />
            <token id="23" string="help" />
            <token id="24" string="her" />
            <token id="25" string="breathe" />
          </tokens>
        </chunking>
        <chunking id="14" string="Miss Taylor" type="NP">
          <tokens>
            <token id="11" string="Miss" />
            <token id="12" string="Taylor" />
          </tokens>
        </chunking>
        <chunking id="15" string="a nearly fatal bout with pneumonia in 1961" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="nearly" />
            <token id="4" string="fatal" />
            <token id="5" string="bout" />
            <token id="6" string="with" />
            <token id="7" string="pneumonia" />
            <token id="8" string="in" />
            <token id="9" string="1961" />
          </tokens>
        </chunking>
        <chunking id="16" string="her windpipe to help her breathe" type="NP">
          <tokens>
            <token id="20" string="her" />
            <token id="21" string="windpipe" />
            <token id="22" string="to" />
            <token id="23" string="help" />
            <token id="24" string="her" />
            <token id="25" string="breathe" />
          </tokens>
        </chunking>
        <chunking id="17" string="a tracheotomy" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="tracheotomy" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="5">bout</governor>
          <dependent id="1">During</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">bout</governor>
          <dependent id="2">a</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">fatal</governor>
          <dependent id="3">nearly</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">bout</governor>
          <dependent id="4">fatal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">underwent</governor>
          <dependent id="5">bout</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">pneumonia</governor>
          <dependent id="6">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">bout</governor>
          <dependent id="7">pneumonia</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">1961</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">pneumonia</governor>
          <dependent id="9">1961</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Taylor</governor>
          <dependent id="11">Miss</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">underwent</governor>
          <dependent id="12">Taylor</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">underwent</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">tracheotomy</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">underwent</governor>
          <dependent id="15">tracheotomy</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">incision</governor>
          <dependent id="17">an</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="15">tracheotomy</governor>
          <dependent id="18">incision</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">windpipe</governor>
          <dependent id="19">into</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="21">windpipe</governor>
          <dependent id="20">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">underwent</governor>
          <dependent id="21">windpipe</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">help</governor>
          <dependent id="22">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="21">windpipe</governor>
          <dependent id="23">help</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">breathe</governor>
          <dependent id="24">her</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="23">help</governor>
          <dependent id="25">breathe</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Taylor" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Taylor" />
          </tokens>
        </entity>
        <entity id="2" string="1961" type="DATE" score="0.0">
          <tokens>
            <token id="9" string="1961" />
          </tokens>
        </entity>
        <entity id="3" string="pneumonia" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="7" string="pneumonia" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>She appeared at the 1961 Academy Awards with a bandage over her scar as she accepted the ``Butterfield 8&amp;apost;&amp;apost; Oscar.</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="appeared" lemma="appear" stem="appear" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="1961" lemma="1961" stem="1961" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string="Academy" lemma="Academy" stem="academi" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="7" string="Awards" lemma="award" stem="award" pos="NNS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="8" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="bandage" lemma="bandage" stem="bandag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="scar" lemma="scar" stem="scar" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="accepted" lemma="accept" stem="accept" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Butterfield" lemma="Butterfield" stem="butterfield" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="8" lemma="8" stem="8" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="21" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="Oscar" lemma="Oscar" stem="oscar" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP She)) (VP (VBD appeared) (PP (IN at) (NP (DT the) (CD 1961) (NNP Academy) (NNS Awards))) (PP (IN with) (NP (NP (DT a) (NN bandage)) (PP (IN over) (NP (PRP$ her) (NN scar))))) (SBAR (IN as) (S (NP (PRP she)) (VP (VBD accepted) (S (NP (NP (DT the)) (`` ``) (NP (NNP Butterfield) (CD 8)) ('' '')) (NP (NNP Oscar))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Oscar" type="NP">
          <tokens>
            <token id="22" string="Oscar" />
          </tokens>
        </chunking>
        <chunking id="2" string="as she accepted the `` Butterfield 8 '' Oscar" type="SBAR">
          <tokens>
            <token id="14" string="as" />
            <token id="15" string="she" />
            <token id="16" string="accepted" />
            <token id="17" string="the" />
            <token id="18" string="``" />
            <token id="19" string="Butterfield" />
            <token id="20" string="8" />
            <token id="21" string="''" />
            <token id="22" string="Oscar" />
          </tokens>
        </chunking>
        <chunking id="3" string="Butterfield 8" type="NP">
          <tokens>
            <token id="19" string="Butterfield" />
            <token id="20" string="8" />
          </tokens>
        </chunking>
        <chunking id="4" string="accepted the `` Butterfield 8 '' Oscar" type="VP">
          <tokens>
            <token id="16" string="accepted" />
            <token id="17" string="the" />
            <token id="18" string="``" />
            <token id="19" string="Butterfield" />
            <token id="20" string="8" />
            <token id="21" string="''" />
            <token id="22" string="Oscar" />
          </tokens>
        </chunking>
        <chunking id="5" string="the 1961 Academy Awards" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="1961" />
            <token id="6" string="Academy" />
            <token id="7" string="Awards" />
          </tokens>
        </chunking>
        <chunking id="6" string="appeared at the 1961 Academy Awards with a bandage over her scar as she accepted the `` Butterfield 8 '' Oscar" type="VP">
          <tokens>
            <token id="2" string="appeared" />
            <token id="3" string="at" />
            <token id="4" string="the" />
            <token id="5" string="1961" />
            <token id="6" string="Academy" />
            <token id="7" string="Awards" />
            <token id="8" string="with" />
            <token id="9" string="a" />
            <token id="10" string="bandage" />
            <token id="11" string="over" />
            <token id="12" string="her" />
            <token id="13" string="scar" />
            <token id="14" string="as" />
            <token id="15" string="she" />
            <token id="16" string="accepted" />
            <token id="17" string="the" />
            <token id="18" string="``" />
            <token id="19" string="Butterfield" />
            <token id="20" string="8" />
            <token id="21" string="''" />
            <token id="22" string="Oscar" />
          </tokens>
        </chunking>
        <chunking id="7" string="the `` Butterfield 8 ''" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="``" />
            <token id="19" string="Butterfield" />
            <token id="20" string="8" />
            <token id="21" string="''" />
          </tokens>
        </chunking>
        <chunking id="8" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
        <chunking id="9" string="a bandage over her scar" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="bandage" />
            <token id="11" string="over" />
            <token id="12" string="her" />
            <token id="13" string="scar" />
          </tokens>
        </chunking>
        <chunking id="10" string="she" type="NP">
          <tokens>
            <token id="15" string="she" />
          </tokens>
        </chunking>
        <chunking id="11" string="the" type="NP">
          <tokens>
            <token id="17" string="the" />
          </tokens>
        </chunking>
        <chunking id="12" string="a bandage" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="bandage" />
          </tokens>
        </chunking>
        <chunking id="13" string="her scar" type="NP">
          <tokens>
            <token id="12" string="her" />
            <token id="13" string="scar" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">appeared</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">appeared</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Awards</governor>
          <dependent id="3">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">Awards</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="7">Awards</governor>
          <dependent id="5">1961</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Awards</governor>
          <dependent id="6">Academy</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">appeared</governor>
          <dependent id="7">Awards</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">bandage</governor>
          <dependent id="8">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">bandage</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">appeared</governor>
          <dependent id="10">bandage</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">scar</governor>
          <dependent id="11">over</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">scar</governor>
          <dependent id="12">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">bandage</governor>
          <dependent id="13">scar</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">accepted</governor>
          <dependent id="14">as</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">accepted</governor>
          <dependent id="15">she</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="2">appeared</governor>
          <dependent id="16">accepted</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">Oscar</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="17">the</governor>
          <dependent id="19">Butterfield</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="19">Butterfield</governor>
          <dependent id="20">8</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="16">accepted</governor>
          <dependent id="22">Oscar</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Academy Awards" type="MISC" score="0.0">
          <tokens>
            <token id="6" string="Academy" />
            <token id="7" string="Awards" />
          </tokens>
        </entity>
        <entity id="2" string="1961" type="DATE" score="0.0">
          <tokens>
            <token id="5" string="1961" />
          </tokens>
        </entity>
        <entity id="3" string="8" type="NUMBER" score="0.0">
          <tokens>
            <token id="20" string="8" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="1-2-3-4-5" string="A seriously ill Elizabeth Taylor" id_sentence="1" />
      <mentions>
        <mention ids_tokens="4" string="her" id_sentence="2" />
        <mention ids_tokens="14" string="her" id_sentence="3" />
        <mention ids_tokens="12-14" string="Miss Taylor's" id_sentence="9" />
        <mention ids_tokens="1-2" string="Miss Taylor" id_sentence="11" />
        <mention ids_tokens="1" string="Her" id_sentence="12" />
        <mention ids_tokens="5" string="she" id_sentence="12" />
        <mention ids_tokens="12" string="her" id_sentence="13" />
        <mention ids_tokens="1" string="She" id_sentence="14" />
        <mention ids_tokens="1" string="She" id_sentence="15" />
        <mention ids_tokens="46-48" string="Miss Taylor's" id_sentence="16" />
        <mention ids_tokens="1-2" string="Miss Taylor" id_sentence="19" />
        <mention ids_tokens="26" string="she" id_sentence="19" />
        <mention ids_tokens="3" string="she" id_sentence="20" />
        <mention ids_tokens="1-2" string="Miss Taylor" id_sentence="21" />
        <mention ids_tokens="11-12" string="Miss Taylor" id_sentence="22" />
        <mention ids_tokens="20" string="her" id_sentence="22" />
        <mention ids_tokens="24" string="her" id_sentence="22" />
        <mention ids_tokens="1" string="She" id_sentence="23" />
        <mention ids_tokens="12" string="her" id_sentence="23" />
        <mention ids_tokens="15" string="she" id_sentence="23" />
      </mentions>
    </coreference>
    <coreference id="2" type="NOMINAL">
      <referenced ids_tokens="9-10" string="her hospital" id_sentence="1" />
      <mentions>
        <mention ids_tokens="5-6" string="her breathing" id_sentence="7" />
      </mentions>
    </coreference>
    <coreference id="3" type="NOMINAL">
      <referenced ids_tokens="16-17" string="a ventilator" id_sentence="1" />
      <mentions>
        <mention ids_tokens="14" string="it" id_sentence="16" />
        <mention ids_tokens="2" string="It" id_sentence="18" />
      </mentions>
    </coreference>
    <coreference id="4" type="NOMINAL">
      <referenced ids_tokens="8-9" string="her doctors" id_sentence="6" />
      <mentions>
        <mention ids_tokens="19" string="doctors" id_sentence="1" />
        <mention ids_tokens="19" string="doctors" id_sentence="11" />
        <mention ids_tokens="7" string="they" id_sentence="13" />
        <mention ids_tokens="1" string="Doctors" id_sentence="17" />
        <mention ids_tokens="14" string="they" id_sentence="18" />
      </mentions>
    </coreference>
    <coreference id="5" type="NOMINAL">
      <referenced ids_tokens="4-5" string="her condition" id_sentence="2" />
      <mentions>
        <mention ids_tokens="2" string="It" id_sentence="13" />
      </mentions>
    </coreference>
    <coreference id="7" type="PROPER">
      <referenced ids_tokens="17-18" string="Chen Sam" id_sentence="3" />
      <mentions>
        <mention ids_tokens="11-12" string="Ms. Sam" id_sentence="15" />
      </mentions>
    </coreference>
    <coreference id="9" type="NOMINAL">
      <referenced ids_tokens="1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18-19-20-21-22-23" string="The 58-year-old actress , who won best-actress Oscars for `` Butterfield 8 '' and `` Who 's Afraid of Virginia Woolf , ''" id_sentence="4" />
      <mentions>
        <mention ids_tokens="5" string="her" id_sentence="7" />
        <mention ids_tokens="1" string="Her" id_sentence="8" />
        <mention ids_tokens="7" string="her" id_sentence="8" />
        <mention ids_tokens="12" string="her" id_sentence="8" />
      </mentions>
    </coreference>
    <coreference id="10" type="NOMINAL">
      <referenced ids_tokens="1-2-3" string="The 58-year-old actress" id_sentence="4" />
      <mentions>
        <mention ids_tokens="1" string="She" id_sentence="5" />
        <mention ids_tokens="2" string="She" id_sentence="6" />
        <mention ids_tokens="8" string="her" id_sentence="6" />
        <mention ids_tokens="4-5" string="the actress" id_sentence="9" />
      </mentions>
    </coreference>
    <coreference id="13" type="NOMINAL">
      <referenced ids_tokens="1-2-3-4-5-6-7-8-9" string="Another spokewoman for the actress , Lisa Del Favaro" id_sentence="9" />
      <mentions>
        <mention ids_tokens="1" string="She" id_sentence="10" />
      </mentions>
    </coreference>
    <coreference id="15" type="PROPER">
      <referenced ids_tokens="26-27-28" string="John G. Mohler" id_sentence="16" />
      <mentions>
        <mention ids_tokens="28" string="Mohler" id_sentence="17" />
      </mentions>
    </coreference>
    <coreference id="17" type="NOMINAL">
      <referenced ids_tokens="4-5-6-7-8" string="a patient on a ventilator" id_sentence="17" />
      <mentions>
        <mention ids_tokens="7" string="she" id_sentence="18" />
      </mentions>
    </coreference>
  </coreferences>
</document>
