<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="SJMN91-06283083">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>For months, this county&amp;apost;s politically astute Sheriff Sherman Block maintained a low profile for himself and his department while city police were being hammered after the videotaped beating of black motorist Rodney King.</content>
      <tokens>
        <token id="1" string="For" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="months" lemma="month" stem="month" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="county" lemma="county" stem="counti" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="politically" lemma="politically" stem="polit" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="astute" lemma="astute" stem="astut" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="Sheriff" lemma="Sheriff" stem="sheriff" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="10" string="Sherman" lemma="Sherman" stem="sherman" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="11" string="Block" lemma="Block" stem="block" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="12" string="maintained" lemma="maintain" stem="maintain" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="low" lemma="low" stem="low" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="profile" lemma="profile" stem="profil" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="himself" lemma="himself" stem="himself" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="department" lemma="department" stem="depart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="while" lemma="while" stem="while" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="city" lemma="city" stem="citi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="police" lemma="police" stem="polic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="being" lemma="be" stem="be" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="hammered" lemma="hammer" stem="hammer" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="29" string="videotaped" lemma="videotaped" stem="videotap" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="30" string="beating" lemma="beating" stem="beat" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="31" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="32" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="33" string="motorist" lemma="motorist" stem="motorist" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="34" string="Rodney" lemma="Rodney" stem="rodnei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="35" string="King" lemma="King" stem="king" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN For) (NP (NNS months))) (, ,) (NP (NP (DT this) (NN county) (POS 's)) (ADJP (RB politically) (JJ astute)) (NNP Sheriff) (NNP Sherman) (NNP Block)) (VP (VBD maintained) (NP (DT a) (JJ low) (NN profile)) (PP (IN for) (NP (NP (PRP himself)) (CC and) (NP (PRP$ his) (NN department)))) (SBAR (IN while) (S (NP (NN city) (NNS police)) (VP (VBD were) (VP (VBG being) (VP (VBN hammered) (PP (IN after) (NP (NP (DT the) (JJ videotaped) (NN beating)) (PP (IN of) (NP (JJ black) (NN motorist) (NNP Rodney) (NNP King))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="this county 's politically astute Sheriff Sherman Block" type="NP">
          <tokens>
            <token id="4" string="this" />
            <token id="5" string="county" />
            <token id="6" string="'s" />
            <token id="7" string="politically" />
            <token id="8" string="astute" />
            <token id="9" string="Sheriff" />
            <token id="10" string="Sherman" />
            <token id="11" string="Block" />
          </tokens>
        </chunking>
        <chunking id="2" string="months" type="NP">
          <tokens>
            <token id="2" string="months" />
          </tokens>
        </chunking>
        <chunking id="3" string="politically astute" type="ADJP">
          <tokens>
            <token id="7" string="politically" />
            <token id="8" string="astute" />
          </tokens>
        </chunking>
        <chunking id="4" string="himself and his department" type="NP">
          <tokens>
            <token id="17" string="himself" />
            <token id="18" string="and" />
            <token id="19" string="his" />
            <token id="20" string="department" />
          </tokens>
        </chunking>
        <chunking id="5" string="the videotaped beating" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="videotaped" />
            <token id="30" string="beating" />
          </tokens>
        </chunking>
        <chunking id="6" string="maintained a low profile for himself and his department while city police were being hammered after the videotaped beating of black motorist Rodney King" type="VP">
          <tokens>
            <token id="12" string="maintained" />
            <token id="13" string="a" />
            <token id="14" string="low" />
            <token id="15" string="profile" />
            <token id="16" string="for" />
            <token id="17" string="himself" />
            <token id="18" string="and" />
            <token id="19" string="his" />
            <token id="20" string="department" />
            <token id="21" string="while" />
            <token id="22" string="city" />
            <token id="23" string="police" />
            <token id="24" string="were" />
            <token id="25" string="being" />
            <token id="26" string="hammered" />
            <token id="27" string="after" />
            <token id="28" string="the" />
            <token id="29" string="videotaped" />
            <token id="30" string="beating" />
            <token id="31" string="of" />
            <token id="32" string="black" />
            <token id="33" string="motorist" />
            <token id="34" string="Rodney" />
            <token id="35" string="King" />
          </tokens>
        </chunking>
        <chunking id="7" string="city police" type="NP">
          <tokens>
            <token id="22" string="city" />
            <token id="23" string="police" />
          </tokens>
        </chunking>
        <chunking id="8" string="hammered after the videotaped beating of black motorist Rodney King" type="VP">
          <tokens>
            <token id="26" string="hammered" />
            <token id="27" string="after" />
            <token id="28" string="the" />
            <token id="29" string="videotaped" />
            <token id="30" string="beating" />
            <token id="31" string="of" />
            <token id="32" string="black" />
            <token id="33" string="motorist" />
            <token id="34" string="Rodney" />
            <token id="35" string="King" />
          </tokens>
        </chunking>
        <chunking id="9" string="the videotaped beating of black motorist Rodney King" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="videotaped" />
            <token id="30" string="beating" />
            <token id="31" string="of" />
            <token id="32" string="black" />
            <token id="33" string="motorist" />
            <token id="34" string="Rodney" />
            <token id="35" string="King" />
          </tokens>
        </chunking>
        <chunking id="10" string="black motorist Rodney King" type="NP">
          <tokens>
            <token id="32" string="black" />
            <token id="33" string="motorist" />
            <token id="34" string="Rodney" />
            <token id="35" string="King" />
          </tokens>
        </chunking>
        <chunking id="11" string="a low profile" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="low" />
            <token id="15" string="profile" />
          </tokens>
        </chunking>
        <chunking id="12" string="while city police were being hammered after the videotaped beating of black motorist Rodney King" type="SBAR">
          <tokens>
            <token id="21" string="while" />
            <token id="22" string="city" />
            <token id="23" string="police" />
            <token id="24" string="were" />
            <token id="25" string="being" />
            <token id="26" string="hammered" />
            <token id="27" string="after" />
            <token id="28" string="the" />
            <token id="29" string="videotaped" />
            <token id="30" string="beating" />
            <token id="31" string="of" />
            <token id="32" string="black" />
            <token id="33" string="motorist" />
            <token id="34" string="Rodney" />
            <token id="35" string="King" />
          </tokens>
        </chunking>
        <chunking id="13" string="were being hammered after the videotaped beating of black motorist Rodney King" type="VP">
          <tokens>
            <token id="24" string="were" />
            <token id="25" string="being" />
            <token id="26" string="hammered" />
            <token id="27" string="after" />
            <token id="28" string="the" />
            <token id="29" string="videotaped" />
            <token id="30" string="beating" />
            <token id="31" string="of" />
            <token id="32" string="black" />
            <token id="33" string="motorist" />
            <token id="34" string="Rodney" />
            <token id="35" string="King" />
          </tokens>
        </chunking>
        <chunking id="14" string="his department" type="NP">
          <tokens>
            <token id="19" string="his" />
            <token id="20" string="department" />
          </tokens>
        </chunking>
        <chunking id="15" string="being hammered after the videotaped beating of black motorist Rodney King" type="VP">
          <tokens>
            <token id="25" string="being" />
            <token id="26" string="hammered" />
            <token id="27" string="after" />
            <token id="28" string="the" />
            <token id="29" string="videotaped" />
            <token id="30" string="beating" />
            <token id="31" string="of" />
            <token id="32" string="black" />
            <token id="33" string="motorist" />
            <token id="34" string="Rodney" />
            <token id="35" string="King" />
          </tokens>
        </chunking>
        <chunking id="16" string="this county 's" type="NP">
          <tokens>
            <token id="4" string="this" />
            <token id="5" string="county" />
            <token id="6" string="'s" />
          </tokens>
        </chunking>
        <chunking id="17" string="himself" type="NP">
          <tokens>
            <token id="17" string="himself" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">months</governor>
          <dependent id="1">For</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">maintained</governor>
          <dependent id="2">months</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">county</governor>
          <dependent id="4">this</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">Block</governor>
          <dependent id="5">county</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">county</governor>
          <dependent id="6">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">astute</governor>
          <dependent id="7">politically</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">Block</governor>
          <dependent id="8">astute</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Block</governor>
          <dependent id="9">Sheriff</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Block</governor>
          <dependent id="10">Sherman</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">maintained</governor>
          <dependent id="11">Block</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">maintained</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">profile</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">profile</governor>
          <dependent id="14">low</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">maintained</governor>
          <dependent id="15">profile</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">himself</governor>
          <dependent id="16">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">maintained</governor>
          <dependent id="17">himself</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">himself</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="20">department</governor>
          <dependent id="19">his</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">himself</governor>
          <dependent id="20">department</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="26">hammered</governor>
          <dependent id="21">while</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">police</governor>
          <dependent id="22">city</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="26">hammered</governor>
          <dependent id="23">police</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="26">hammered</governor>
          <dependent id="24">were</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="26">hammered</governor>
          <dependent id="25">being</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">maintained</governor>
          <dependent id="26">hammered</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">beating</governor>
          <dependent id="27">after</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">beating</governor>
          <dependent id="28">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="30">beating</governor>
          <dependent id="29">videotaped</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">hammered</governor>
          <dependent id="30">beating</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">King</governor>
          <dependent id="31">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="35">King</governor>
          <dependent id="32">black</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">King</governor>
          <dependent id="33">motorist</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">King</governor>
          <dependent id="34">Rodney</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">beating</governor>
          <dependent id="35">King</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="months" type="DURATION" score="0.0">
          <tokens>
            <token id="2" string="months" />
          </tokens>
        </entity>
        <entity id="2" string="Sheriff Sherman Block" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="9" string="Sheriff" />
            <token id="10" string="Sherman" />
            <token id="11" string="Block" />
          </tokens>
        </entity>
        <entity id="3" string="Rodney King" type="PERSON" score="0.0">
          <tokens>
            <token id="34" string="Rodney" />
            <token id="35" string="King" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="false">
      <content>But then sheriff&amp;apost;s deputies shot four people dead in the space of one month.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="sheriff" lemma="sheriff" stem="sheriff" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="deputies" lemma="deputy" stem="deputi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="shot" lemma="shoot" stem="shot" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="four" lemma="four" stem="four" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="8" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="dead" lemma="dead" stem="dead" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="space" lemma="space" stem="space" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="15" string="month" lemma="month" stem="month" pos="NN" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (ADVP (RB then)) (NP (NP (NN sheriff) (POS 's)) (NNS deputies)) (VP (VBD shot) (ADJP (NP (CD four) (NNS people)) (JJ dead)) (PP (IN in) (NP (NP (DT the) (NN space)) (PP (IN of) (NP (CD one) (NN month)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="sheriff 's deputies" type="NP">
          <tokens>
            <token id="3" string="sheriff" />
            <token id="4" string="'s" />
            <token id="5" string="deputies" />
          </tokens>
        </chunking>
        <chunking id="2" string="the space" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="space" />
          </tokens>
        </chunking>
        <chunking id="3" string="sheriff 's" type="NP">
          <tokens>
            <token id="3" string="sheriff" />
            <token id="4" string="'s" />
          </tokens>
        </chunking>
        <chunking id="4" string="four people" type="NP">
          <tokens>
            <token id="7" string="four" />
            <token id="8" string="people" />
          </tokens>
        </chunking>
        <chunking id="5" string="the space of one month" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="space" />
            <token id="13" string="of" />
            <token id="14" string="one" />
            <token id="15" string="month" />
          </tokens>
        </chunking>
        <chunking id="6" string="one month" type="NP">
          <tokens>
            <token id="14" string="one" />
            <token id="15" string="month" />
          </tokens>
        </chunking>
        <chunking id="7" string="four people dead" type="ADJP">
          <tokens>
            <token id="7" string="four" />
            <token id="8" string="people" />
            <token id="9" string="dead" />
          </tokens>
        </chunking>
        <chunking id="8" string="shot four people dead in the space of one month" type="VP">
          <tokens>
            <token id="6" string="shot" />
            <token id="7" string="four" />
            <token id="8" string="people" />
            <token id="9" string="dead" />
            <token id="10" string="in" />
            <token id="11" string="the" />
            <token id="12" string="space" />
            <token id="13" string="of" />
            <token id="14" string="one" />
            <token id="15" string="month" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="6">shot</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">shot</governor>
          <dependent id="2">then</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">deputies</governor>
          <dependent id="3">sheriff</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">sheriff</governor>
          <dependent id="4">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">shot</governor>
          <dependent id="5">deputies</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">shot</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="8">people</governor>
          <dependent id="7">four</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="9">dead</governor>
          <dependent id="8">people</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">shot</governor>
          <dependent id="9">dead</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">space</governor>
          <dependent id="10">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">space</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">shot</governor>
          <dependent id="12">space</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">month</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="15">month</governor>
          <dependent id="14">one</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">space</governor>
          <dependent id="15">month</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="four" type="NUMBER" score="0.0">
          <tokens>
            <token id="7" string="four" />
          </tokens>
        </entity>
        <entity id="2" string="one month" type="DURATION" score="0.0">
          <tokens>
            <token id="14" string="one" />
            <token id="15" string="month" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="false">
      <content>The corruption case of an elite drug unit continued to make headlines.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="corruption" lemma="corruption" stem="corrupt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="elite" lemma="elite" stem="elit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="drug" lemma="drug" stem="drug" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="unit" lemma="unit" stem="unit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="continued" lemma="continue" stem="continu" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="make" lemma="make" stem="make" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="headlines" lemma="headline" stem="headlin" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NN corruption) (NN case)) (PP (IN of) (NP (DT an) (NN elite) (NN drug) (NN unit)))) (VP (VBD continued) (S (VP (TO to) (VP (VB make) (NP (NNS headlines)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="continued to make headlines" type="VP">
          <tokens>
            <token id="9" string="continued" />
            <token id="10" string="to" />
            <token id="11" string="make" />
            <token id="12" string="headlines" />
          </tokens>
        </chunking>
        <chunking id="2" string="The corruption case" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="corruption" />
            <token id="3" string="case" />
          </tokens>
        </chunking>
        <chunking id="3" string="headlines" type="NP">
          <tokens>
            <token id="12" string="headlines" />
          </tokens>
        </chunking>
        <chunking id="4" string="make headlines" type="VP">
          <tokens>
            <token id="11" string="make" />
            <token id="12" string="headlines" />
          </tokens>
        </chunking>
        <chunking id="5" string="to make headlines" type="VP">
          <tokens>
            <token id="10" string="to" />
            <token id="11" string="make" />
            <token id="12" string="headlines" />
          </tokens>
        </chunking>
        <chunking id="6" string="The corruption case of an elite drug unit" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="corruption" />
            <token id="3" string="case" />
            <token id="4" string="of" />
            <token id="5" string="an" />
            <token id="6" string="elite" />
            <token id="7" string="drug" />
            <token id="8" string="unit" />
          </tokens>
        </chunking>
        <chunking id="7" string="an elite drug unit" type="NP">
          <tokens>
            <token id="5" string="an" />
            <token id="6" string="elite" />
            <token id="7" string="drug" />
            <token id="8" string="unit" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">case</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">case</governor>
          <dependent id="2">corruption</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">continued</governor>
          <dependent id="3">case</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">unit</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">unit</governor>
          <dependent id="5">an</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">unit</governor>
          <dependent id="6">elite</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">unit</governor>
          <dependent id="7">drug</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">case</governor>
          <dependent id="8">unit</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">continued</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">make</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">continued</governor>
          <dependent id="11">make</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">make</governor>
          <dependent id="12">headlines</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="4" has_coreference="false">
      <content>Three deputies were charged with stealing credit cards from elderly people.</content>
      <tokens>
        <token id="1" string="Three" lemma="three" stem="three" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="2" string="deputies" lemma="deputy" stem="deputi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="charged" lemma="charge" stem="charg" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="stealing" lemma="steal" stem="steal" pos="VBG" type="Word" isStopWord="false" ner="CRIMINAL_CHARGE" is_referenced="false" is_refers="false" />
        <token id="7" string="credit" lemma="credit" stem="credit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="cards" lemma="card" stem="card" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="elderly" lemma="elderly" stem="elderli" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (CD Three) (NNS deputies)) (VP (VBD were) (VP (VBN charged) (PP (IN with) (S (VP (VBG stealing) (NP (NN credit) (NNS cards)) (PP (IN from) (NP (JJ elderly) (NNS people)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="credit cards" type="NP">
          <tokens>
            <token id="7" string="credit" />
            <token id="8" string="cards" />
          </tokens>
        </chunking>
        <chunking id="2" string="Three deputies" type="NP">
          <tokens>
            <token id="1" string="Three" />
            <token id="2" string="deputies" />
          </tokens>
        </chunking>
        <chunking id="3" string="elderly people" type="NP">
          <tokens>
            <token id="10" string="elderly" />
            <token id="11" string="people" />
          </tokens>
        </chunking>
        <chunking id="4" string="stealing credit cards from elderly people" type="VP">
          <tokens>
            <token id="6" string="stealing" />
            <token id="7" string="credit" />
            <token id="8" string="cards" />
            <token id="9" string="from" />
            <token id="10" string="elderly" />
            <token id="11" string="people" />
          </tokens>
        </chunking>
        <chunking id="5" string="charged with stealing credit cards from elderly people" type="VP">
          <tokens>
            <token id="4" string="charged" />
            <token id="5" string="with" />
            <token id="6" string="stealing" />
            <token id="7" string="credit" />
            <token id="8" string="cards" />
            <token id="9" string="from" />
            <token id="10" string="elderly" />
            <token id="11" string="people" />
          </tokens>
        </chunking>
        <chunking id="6" string="were charged with stealing credit cards from elderly people" type="VP">
          <tokens>
            <token id="3" string="were" />
            <token id="4" string="charged" />
            <token id="5" string="with" />
            <token id="6" string="stealing" />
            <token id="7" string="credit" />
            <token id="8" string="cards" />
            <token id="9" string="from" />
            <token id="10" string="elderly" />
            <token id="11" string="people" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nummod">
          <governor id="2">deputies</governor>
          <dependent id="1">Three</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="4">charged</governor>
          <dependent id="2">deputies</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">charged</governor>
          <dependent id="3">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">charged</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">stealing</governor>
          <dependent id="5">with</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">charged</governor>
          <dependent id="6">stealing</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">cards</governor>
          <dependent id="7">credit</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">stealing</governor>
          <dependent id="8">cards</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">people</governor>
          <dependent id="9">from</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">people</governor>
          <dependent id="10">elderly</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">stealing</governor>
          <dependent id="11">people</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Three" type="NUMBER" score="0.0">
          <tokens>
            <token id="1" string="Three" />
          </tokens>
        </entity>
        <entity id="2" string="stealing" type="CRIMINAL_CHARGE" score="0.0">
          <tokens>
            <token id="6" string="stealing" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>And allegations that the department is home to white supremacist gangs resurfaced.</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="allegations" lemma="allegation" stem="alleg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="department" lemma="department" stem="depart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="home" lemma="home" stem="home" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="white" lemma="white" stem="white" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="supremacist" lemma="supremacist" stem="supremacist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="gangs" lemma="gang" stem="gang" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="resurfaced" lemma="resurface" stem="resurfac" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC And) (NP (NP (NNS allegations)) (SBAR (IN that) (S (NP (DT the) (NN department)) (VP (VBZ is) (ADVP (NN home)) (PP (TO to) (NP (JJ white) (NN supremacist) (NNS gangs))))))) (VP (VBD resurfaced)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is home to white supremacist gangs" type="VP">
          <tokens>
            <token id="6" string="is" />
            <token id="7" string="home" />
            <token id="8" string="to" />
            <token id="9" string="white" />
            <token id="10" string="supremacist" />
            <token id="11" string="gangs" />
          </tokens>
        </chunking>
        <chunking id="2" string="allegations that the department is home to white supremacist gangs" type="NP">
          <tokens>
            <token id="2" string="allegations" />
            <token id="3" string="that" />
            <token id="4" string="the" />
            <token id="5" string="department" />
            <token id="6" string="is" />
            <token id="7" string="home" />
            <token id="8" string="to" />
            <token id="9" string="white" />
            <token id="10" string="supremacist" />
            <token id="11" string="gangs" />
          </tokens>
        </chunking>
        <chunking id="3" string="that the department is home to white supremacist gangs" type="SBAR">
          <tokens>
            <token id="3" string="that" />
            <token id="4" string="the" />
            <token id="5" string="department" />
            <token id="6" string="is" />
            <token id="7" string="home" />
            <token id="8" string="to" />
            <token id="9" string="white" />
            <token id="10" string="supremacist" />
            <token id="11" string="gangs" />
          </tokens>
        </chunking>
        <chunking id="4" string="white supremacist gangs" type="NP">
          <tokens>
            <token id="9" string="white" />
            <token id="10" string="supremacist" />
            <token id="11" string="gangs" />
          </tokens>
        </chunking>
        <chunking id="5" string="allegations" type="NP">
          <tokens>
            <token id="2" string="allegations" />
          </tokens>
        </chunking>
        <chunking id="6" string="the department" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="department" />
          </tokens>
        </chunking>
        <chunking id="7" string="resurfaced" type="VP">
          <tokens>
            <token id="12" string="resurfaced" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="12">resurfaced</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">resurfaced</governor>
          <dependent id="2">allegations</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">gangs</governor>
          <dependent id="3">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">department</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">gangs</governor>
          <dependent id="5">department</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">gangs</governor>
          <dependent id="6">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">gangs</governor>
          <dependent id="7">home</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">gangs</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">gangs</governor>
          <dependent id="9">white</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">gangs</governor>
          <dependent id="10">supremacist</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="2">allegations</governor>
          <dependent id="11">gangs</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">resurfaced</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>Just last week, a federal judge hearing a civil rights suit issued an unusual order that employees follow department policy -- and the department appealed, winning a temporary delay of the order.</content>
      <tokens>
        <token id="1" string="Just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="week" lemma="week" stem="week" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="federal" lemma="federal" stem="feder" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="judge" lemma="judge" stem="judg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="hearing" lemma="hear" stem="hear" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="civil" lemma="civil" stem="civil" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="rights" lemma="rights" stem="right" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="suit" lemma="suit" stem="suit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="issued" lemma="issue" stem="issu" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="unusual" lemma="unusual" stem="unusu" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="order" lemma="order" stem="order" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="employees" lemma="employee" stem="employe" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="follow" lemma="follow" stem="follow" pos="VBP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="department" lemma="department" stem="depart" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="policy" lemma="policy" stem="polici" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="department" lemma="department" stem="depart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="26" string="appealed" lemma="appeal" stem="appeal" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="winning" lemma="win" stem="win" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="temporary" lemma="temporary" stem="temporari" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="delay" lemma="delay" stem="delai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="order" lemma="order" stem="order" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP-TMP (RB Just) (JJ last) (NN week)) (, ,) (NP (NP (DT a) (JJ federal) (NN judge)) (VP (VBG hearing) (NP (DT a) (JJ civil) (NNS rights) (NN suit)))) (VP (VBD issued) (NP (NP (DT an) (JJ unusual) (NN order)) (SBAR (WHNP (WDT that)) (S (NP (NNS employees)) (VP (VBP follow) (NP (NN department) (NN policy)))))))) (: --) (CC and) (S (NP (DT the) (NN department)) (VP (VBD appealed) (, ,) (S (VP (VBG winning) (NP (NP (DT a) (JJ temporary) (NN delay)) (PP (IN of) (NP (DT the) (NN order)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a civil rights suit" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="civil" />
            <token id="11" string="rights" />
            <token id="12" string="suit" />
          </tokens>
        </chunking>
        <chunking id="2" string="the order" type="NP">
          <tokens>
            <token id="33" string="the" />
            <token id="34" string="order" />
          </tokens>
        </chunking>
        <chunking id="3" string="a temporary delay" type="NP">
          <tokens>
            <token id="29" string="a" />
            <token id="30" string="temporary" />
            <token id="31" string="delay" />
          </tokens>
        </chunking>
        <chunking id="4" string="follow department policy" type="VP">
          <tokens>
            <token id="19" string="follow" />
            <token id="20" string="department" />
            <token id="21" string="policy" />
          </tokens>
        </chunking>
        <chunking id="5" string="an unusual order" type="NP">
          <tokens>
            <token id="14" string="an" />
            <token id="15" string="unusual" />
            <token id="16" string="order" />
          </tokens>
        </chunking>
        <chunking id="6" string="winning a temporary delay of the order" type="VP">
          <tokens>
            <token id="28" string="winning" />
            <token id="29" string="a" />
            <token id="30" string="temporary" />
            <token id="31" string="delay" />
            <token id="32" string="of" />
            <token id="33" string="the" />
            <token id="34" string="order" />
          </tokens>
        </chunking>
        <chunking id="7" string="a federal judge hearing a civil rights suit" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="federal" />
            <token id="7" string="judge" />
            <token id="8" string="hearing" />
            <token id="9" string="a" />
            <token id="10" string="civil" />
            <token id="11" string="rights" />
            <token id="12" string="suit" />
          </tokens>
        </chunking>
        <chunking id="8" string="issued an unusual order that employees follow department policy" type="VP">
          <tokens>
            <token id="13" string="issued" />
            <token id="14" string="an" />
            <token id="15" string="unusual" />
            <token id="16" string="order" />
            <token id="17" string="that" />
            <token id="18" string="employees" />
            <token id="19" string="follow" />
            <token id="20" string="department" />
            <token id="21" string="policy" />
          </tokens>
        </chunking>
        <chunking id="9" string="a temporary delay of the order" type="NP">
          <tokens>
            <token id="29" string="a" />
            <token id="30" string="temporary" />
            <token id="31" string="delay" />
            <token id="32" string="of" />
            <token id="33" string="the" />
            <token id="34" string="order" />
          </tokens>
        </chunking>
        <chunking id="10" string="an unusual order that employees follow department policy" type="NP">
          <tokens>
            <token id="14" string="an" />
            <token id="15" string="unusual" />
            <token id="16" string="order" />
            <token id="17" string="that" />
            <token id="18" string="employees" />
            <token id="19" string="follow" />
            <token id="20" string="department" />
            <token id="21" string="policy" />
          </tokens>
        </chunking>
        <chunking id="11" string="the department" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="department" />
          </tokens>
        </chunking>
        <chunking id="12" string="hearing a civil rights suit" type="VP">
          <tokens>
            <token id="8" string="hearing" />
            <token id="9" string="a" />
            <token id="10" string="civil" />
            <token id="11" string="rights" />
            <token id="12" string="suit" />
          </tokens>
        </chunking>
        <chunking id="13" string="department policy" type="NP">
          <tokens>
            <token id="20" string="department" />
            <token id="21" string="policy" />
          </tokens>
        </chunking>
        <chunking id="14" string="employees" type="NP">
          <tokens>
            <token id="18" string="employees" />
          </tokens>
        </chunking>
        <chunking id="15" string="a federal judge" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="federal" />
            <token id="7" string="judge" />
          </tokens>
        </chunking>
        <chunking id="16" string="appealed , winning a temporary delay of the order" type="VP">
          <tokens>
            <token id="26" string="appealed" />
            <token id="27" string="," />
            <token id="28" string="winning" />
            <token id="29" string="a" />
            <token id="30" string="temporary" />
            <token id="31" string="delay" />
            <token id="32" string="of" />
            <token id="33" string="the" />
            <token id="34" string="order" />
          </tokens>
        </chunking>
        <chunking id="17" string="that employees follow department policy" type="SBAR">
          <tokens>
            <token id="17" string="that" />
            <token id="18" string="employees" />
            <token id="19" string="follow" />
            <token id="20" string="department" />
            <token id="21" string="policy" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="3">week</governor>
          <dependent id="1">Just</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">week</governor>
          <dependent id="2">last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="13">issued</governor>
          <dependent id="3">week</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">judge</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">judge</governor>
          <dependent id="6">federal</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">issued</governor>
          <dependent id="7">judge</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="7">judge</governor>
          <dependent id="8">hearing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">suit</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">suit</governor>
          <dependent id="10">civil</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">suit</governor>
          <dependent id="11">rights</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">hearing</governor>
          <dependent id="12">suit</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">issued</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">order</governor>
          <dependent id="14">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">order</governor>
          <dependent id="15">unusual</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">issued</governor>
          <dependent id="16">order</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">follow</governor>
          <dependent id="17">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">follow</governor>
          <dependent id="18">employees</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="16">order</governor>
          <dependent id="19">follow</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">policy</governor>
          <dependent id="20">department</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">follow</governor>
          <dependent id="21">policy</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">issued</governor>
          <dependent id="23">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">department</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">appealed</governor>
          <dependent id="25">department</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">issued</governor>
          <dependent id="26">appealed</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="26">appealed</governor>
          <dependent id="28">winning</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">delay</governor>
          <dependent id="29">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">delay</governor>
          <dependent id="30">temporary</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="28">winning</governor>
          <dependent id="31">delay</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">order</governor>
          <dependent id="32">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">order</governor>
          <dependent id="33">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">delay</governor>
          <dependent id="34">order</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="last week" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="last" />
            <token id="3" string="week" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>The spotlight that had been trained on the police department and its 8,300 officers now has widened to take in the equally large sheriff&amp;apost;s department.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="spotlight" lemma="spotlight" stem="spotlight" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="trained" lemma="train" stem="train" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="department" lemma="department" stem="depart" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="8,300" lemma="8,300" stem="8,300" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="14" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="16" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="widened" lemma="widen" stem="widen" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="take" lemma="take" stem="take" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="in" lemma="in" stem="in" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="equally" lemma="equally" stem="equal" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="large" lemma="large" stem="larg" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="sheriff" lemma="sheriff" stem="sheriff" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="26" string="department" lemma="department" stem="depart" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NN spotlight)) (SBAR (WHNP (WDT that)) (S (VP (VBD had) (VP (VBN been) (VP (VBN trained) (PP (IN on) (NP (NP (DT the) (NN police) (NN department)) (CC and) (NP (PRP$ its) (CD 8,300) (NNS officers)))))))))) (ADVP (RB now)) (VP (VBZ has) (VP (VBN widened) (S (VP (TO to) (VP (VB take) (PRT (RP in)) (NP (NP (DT the) (ADJP (RB equally) (JJ large)) (NN sheriff) (POS 's)) (NN department))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="trained on the police department and its 8,300 officers" type="VP">
          <tokens>
            <token id="6" string="trained" />
            <token id="7" string="on" />
            <token id="8" string="the" />
            <token id="9" string="police" />
            <token id="10" string="department" />
            <token id="11" string="and" />
            <token id="12" string="its" />
            <token id="13" string="8,300" />
            <token id="14" string="officers" />
          </tokens>
        </chunking>
        <chunking id="2" string="equally large" type="ADJP">
          <tokens>
            <token id="22" string="equally" />
            <token id="23" string="large" />
          </tokens>
        </chunking>
        <chunking id="3" string="the police department" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="police" />
            <token id="10" string="department" />
          </tokens>
        </chunking>
        <chunking id="4" string="had been trained on the police department and its 8,300 officers" type="VP">
          <tokens>
            <token id="4" string="had" />
            <token id="5" string="been" />
            <token id="6" string="trained" />
            <token id="7" string="on" />
            <token id="8" string="the" />
            <token id="9" string="police" />
            <token id="10" string="department" />
            <token id="11" string="and" />
            <token id="12" string="its" />
            <token id="13" string="8,300" />
            <token id="14" string="officers" />
          </tokens>
        </chunking>
        <chunking id="5" string="the equally large sheriff 's" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="equally" />
            <token id="23" string="large" />
            <token id="24" string="sheriff" />
            <token id="25" string="'s" />
          </tokens>
        </chunking>
        <chunking id="6" string="that had been trained on the police department and its 8,300 officers" type="SBAR">
          <tokens>
            <token id="3" string="that" />
            <token id="4" string="had" />
            <token id="5" string="been" />
            <token id="6" string="trained" />
            <token id="7" string="on" />
            <token id="8" string="the" />
            <token id="9" string="police" />
            <token id="10" string="department" />
            <token id="11" string="and" />
            <token id="12" string="its" />
            <token id="13" string="8,300" />
            <token id="14" string="officers" />
          </tokens>
        </chunking>
        <chunking id="7" string="been trained on the police department and its 8,300 officers" type="VP">
          <tokens>
            <token id="5" string="been" />
            <token id="6" string="trained" />
            <token id="7" string="on" />
            <token id="8" string="the" />
            <token id="9" string="police" />
            <token id="10" string="department" />
            <token id="11" string="and" />
            <token id="12" string="its" />
            <token id="13" string="8,300" />
            <token id="14" string="officers" />
          </tokens>
        </chunking>
        <chunking id="8" string="the equally large sheriff 's department" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="equally" />
            <token id="23" string="large" />
            <token id="24" string="sheriff" />
            <token id="25" string="'s" />
            <token id="26" string="department" />
          </tokens>
        </chunking>
        <chunking id="9" string="its 8,300 officers" type="NP">
          <tokens>
            <token id="12" string="its" />
            <token id="13" string="8,300" />
            <token id="14" string="officers" />
          </tokens>
        </chunking>
        <chunking id="10" string="widened to take in the equally large sheriff 's department" type="VP">
          <tokens>
            <token id="17" string="widened" />
            <token id="18" string="to" />
            <token id="19" string="take" />
            <token id="20" string="in" />
            <token id="21" string="the" />
            <token id="22" string="equally" />
            <token id="23" string="large" />
            <token id="24" string="sheriff" />
            <token id="25" string="'s" />
            <token id="26" string="department" />
          </tokens>
        </chunking>
        <chunking id="11" string="to take in the equally large sheriff 's department" type="VP">
          <tokens>
            <token id="18" string="to" />
            <token id="19" string="take" />
            <token id="20" string="in" />
            <token id="21" string="the" />
            <token id="22" string="equally" />
            <token id="23" string="large" />
            <token id="24" string="sheriff" />
            <token id="25" string="'s" />
            <token id="26" string="department" />
          </tokens>
        </chunking>
        <chunking id="12" string="has widened to take in the equally large sheriff 's department" type="VP">
          <tokens>
            <token id="16" string="has" />
            <token id="17" string="widened" />
            <token id="18" string="to" />
            <token id="19" string="take" />
            <token id="20" string="in" />
            <token id="21" string="the" />
            <token id="22" string="equally" />
            <token id="23" string="large" />
            <token id="24" string="sheriff" />
            <token id="25" string="'s" />
            <token id="26" string="department" />
          </tokens>
        </chunking>
        <chunking id="13" string="The spotlight" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="spotlight" />
          </tokens>
        </chunking>
        <chunking id="14" string="The spotlight that had been trained on the police department and its 8,300 officers" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="spotlight" />
            <token id="3" string="that" />
            <token id="4" string="had" />
            <token id="5" string="been" />
            <token id="6" string="trained" />
            <token id="7" string="on" />
            <token id="8" string="the" />
            <token id="9" string="police" />
            <token id="10" string="department" />
            <token id="11" string="and" />
            <token id="12" string="its" />
            <token id="13" string="8,300" />
            <token id="14" string="officers" />
          </tokens>
        </chunking>
        <chunking id="15" string="the police department and its 8,300 officers" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="police" />
            <token id="10" string="department" />
            <token id="11" string="and" />
            <token id="12" string="its" />
            <token id="13" string="8,300" />
            <token id="14" string="officers" />
          </tokens>
        </chunking>
        <chunking id="16" string="take in the equally large sheriff 's department" type="VP">
          <tokens>
            <token id="19" string="take" />
            <token id="20" string="in" />
            <token id="21" string="the" />
            <token id="22" string="equally" />
            <token id="23" string="large" />
            <token id="24" string="sheriff" />
            <token id="25" string="'s" />
            <token id="26" string="department" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">spotlight</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">widened</governor>
          <dependent id="2">spotlight</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="6">trained</governor>
          <dependent id="3">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">trained</governor>
          <dependent id="4">had</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">trained</governor>
          <dependent id="5">been</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="2">spotlight</governor>
          <dependent id="6">trained</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">department</governor>
          <dependent id="7">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">department</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">department</governor>
          <dependent id="9">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">trained</governor>
          <dependent id="10">department</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">department</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">officers</governor>
          <dependent id="12">its</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="14">officers</governor>
          <dependent id="13">8,300</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">department</governor>
          <dependent id="14">officers</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">widened</governor>
          <dependent id="15">now</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="17">widened</governor>
          <dependent id="16">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">widened</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">take</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="17">widened</governor>
          <dependent id="19">take</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="19">take</governor>
          <dependent id="20">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">sheriff</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="23">large</governor>
          <dependent id="22">equally</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">sheriff</governor>
          <dependent id="23">large</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="26">department</governor>
          <dependent id="24">sheriff</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">sheriff</governor>
          <dependent id="25">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">take</governor>
          <dependent id="26">department</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="15" string="now" />
          </tokens>
        </entity>
        <entity id="2" string="8,300" type="NUMBER" score="0.0">
          <tokens>
            <token id="13" string="8,300" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>Block&amp;apost;s measured response to the criticism -- and the lack of a riveting videotape -- have spared him the level of heat felt by Police Chief Daryl Gates.</content>
      <tokens>
        <token id="1" string="Block" lemma="Block" stem="block" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="measured" lemma="measure" stem="measur" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="response" lemma="response" stem="respons" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="criticism" lemma="criticism" stem="critic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="lack" lemma="lack" stem="lack" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="riveting" lemma="riveting" stem="rivet" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="videotape" lemma="videotape" stem="videotap" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="spared" lemma="spare" stem="spare" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="level" lemma="level" stem="level" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="heat" lemma="heat" stem="heat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="felt" lemma="feel" stem="felt" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="Police" lemma="Police" stem="polic" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="Chief" lemma="Chief" stem="chief" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="true" is_refers="false" />
        <token id="28" string="Daryl" lemma="Daryl" stem="daryl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="29" string="Gates" lemma="Gates" stem="gate" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NP (NNP Block) (POS 's)) (VBN measured) (NN response)) (PP (TO to) (NP (NP (DT the) (NN criticism)) (PRN (: --) (CC and) (NP (NP (DT the) (NN lack)) (PP (IN of) (NP (DT a) (JJ riveting) (NN videotape)))) (: --))))) (VP (VBP have) (VP (VBN spared) (S (NP (PRP him)) (NP (NP (DT the) (NN level)) (PP (IN of) (NP (NP (NN heat)) (VP (VBN felt) (PP (IN by) (NP (NNP Police) (NNP Chief) (NNP Daryl) (NNP Gates)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Block 's" type="NP">
          <tokens>
            <token id="1" string="Block" />
            <token id="2" string="'s" />
          </tokens>
        </chunking>
        <chunking id="2" string="felt by Police Chief Daryl Gates" type="VP">
          <tokens>
            <token id="24" string="felt" />
            <token id="25" string="by" />
            <token id="26" string="Police" />
            <token id="27" string="Chief" />
            <token id="28" string="Daryl" />
            <token id="29" string="Gates" />
          </tokens>
        </chunking>
        <chunking id="3" string="have spared him the level of heat felt by Police Chief Daryl Gates" type="VP">
          <tokens>
            <token id="17" string="have" />
            <token id="18" string="spared" />
            <token id="19" string="him" />
            <token id="20" string="the" />
            <token id="21" string="level" />
            <token id="22" string="of" />
            <token id="23" string="heat" />
            <token id="24" string="felt" />
            <token id="25" string="by" />
            <token id="26" string="Police" />
            <token id="27" string="Chief" />
            <token id="28" string="Daryl" />
            <token id="29" string="Gates" />
          </tokens>
        </chunking>
        <chunking id="4" string="Block 's measured response to the criticism -- and the lack of a riveting videotape --" type="NP">
          <tokens>
            <token id="1" string="Block" />
            <token id="2" string="'s" />
            <token id="3" string="measured" />
            <token id="4" string="response" />
            <token id="5" string="to" />
            <token id="6" string="the" />
            <token id="7" string="criticism" />
            <token id="8" string="--" />
            <token id="9" string="and" />
            <token id="10" string="the" />
            <token id="11" string="lack" />
            <token id="12" string="of" />
            <token id="13" string="a" />
            <token id="14" string="riveting" />
            <token id="15" string="videotape" />
            <token id="16" string="--" />
          </tokens>
        </chunking>
        <chunking id="5" string="the criticism -- and the lack of a riveting videotape --" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="criticism" />
            <token id="8" string="--" />
            <token id="9" string="and" />
            <token id="10" string="the" />
            <token id="11" string="lack" />
            <token id="12" string="of" />
            <token id="13" string="a" />
            <token id="14" string="riveting" />
            <token id="15" string="videotape" />
            <token id="16" string="--" />
          </tokens>
        </chunking>
        <chunking id="6" string="him" type="NP">
          <tokens>
            <token id="19" string="him" />
          </tokens>
        </chunking>
        <chunking id="7" string="Police Chief Daryl Gates" type="NP">
          <tokens>
            <token id="26" string="Police" />
            <token id="27" string="Chief" />
            <token id="28" string="Daryl" />
            <token id="29" string="Gates" />
          </tokens>
        </chunking>
        <chunking id="8" string="spared him the level of heat felt by Police Chief Daryl Gates" type="VP">
          <tokens>
            <token id="18" string="spared" />
            <token id="19" string="him" />
            <token id="20" string="the" />
            <token id="21" string="level" />
            <token id="22" string="of" />
            <token id="23" string="heat" />
            <token id="24" string="felt" />
            <token id="25" string="by" />
            <token id="26" string="Police" />
            <token id="27" string="Chief" />
            <token id="28" string="Daryl" />
            <token id="29" string="Gates" />
          </tokens>
        </chunking>
        <chunking id="9" string="heat felt by Police Chief Daryl Gates" type="NP">
          <tokens>
            <token id="23" string="heat" />
            <token id="24" string="felt" />
            <token id="25" string="by" />
            <token id="26" string="Police" />
            <token id="27" string="Chief" />
            <token id="28" string="Daryl" />
            <token id="29" string="Gates" />
          </tokens>
        </chunking>
        <chunking id="10" string="the lack" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="lack" />
          </tokens>
        </chunking>
        <chunking id="11" string="the level of heat felt by Police Chief Daryl Gates" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="level" />
            <token id="22" string="of" />
            <token id="23" string="heat" />
            <token id="24" string="felt" />
            <token id="25" string="by" />
            <token id="26" string="Police" />
            <token id="27" string="Chief" />
            <token id="28" string="Daryl" />
            <token id="29" string="Gates" />
          </tokens>
        </chunking>
        <chunking id="12" string="the criticism" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="criticism" />
          </tokens>
        </chunking>
        <chunking id="13" string="the level" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="level" />
          </tokens>
        </chunking>
        <chunking id="14" string="a riveting videotape" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="riveting" />
            <token id="15" string="videotape" />
          </tokens>
        </chunking>
        <chunking id="15" string="the lack of a riveting videotape" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="lack" />
            <token id="12" string="of" />
            <token id="13" string="a" />
            <token id="14" string="riveting" />
            <token id="15" string="videotape" />
          </tokens>
        </chunking>
        <chunking id="16" string="Block 's measured response" type="NP">
          <tokens>
            <token id="1" string="Block" />
            <token id="2" string="'s" />
            <token id="3" string="measured" />
            <token id="4" string="response" />
          </tokens>
        </chunking>
        <chunking id="17" string="heat" type="NP">
          <tokens>
            <token id="23" string="heat" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="4">response</governor>
          <dependent id="1">Block</dependent>
        </dependency>
        <dependency type="case">
          <governor id="1">Block</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">response</governor>
          <dependent id="3">measured</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">spared</governor>
          <dependent id="4">response</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">criticism</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">criticism</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">response</governor>
          <dependent id="7">criticism</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">lack</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">lack</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">criticism</governor>
          <dependent id="11">lack</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">videotape</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">videotape</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">videotape</governor>
          <dependent id="14">riveting</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">lack</governor>
          <dependent id="15">videotape</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">spared</governor>
          <dependent id="17">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">spared</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">level</governor>
          <dependent id="19">him</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">level</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="18">spared</governor>
          <dependent id="21">level</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">heat</governor>
          <dependent id="22">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">level</governor>
          <dependent id="23">heat</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="23">heat</governor>
          <dependent id="24">felt</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">Gates</governor>
          <dependent id="25">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">Gates</governor>
          <dependent id="26">Police</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">Gates</governor>
          <dependent id="27">Chief</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">Gates</governor>
          <dependent id="28">Daryl</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">felt</governor>
          <dependent id="29">Gates</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Daryl Gates" type="PERSON" score="0.0">
          <tokens>
            <token id="28" string="Daryl" />
            <token id="29" string="Gates" />
          </tokens>
        </entity>
        <entity id="2" string="Chief" type="TITLE" score="0.0">
          <tokens>
            <token id="27" string="Chief" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>But after years of boasting that their methods were models in policing, both departments are facing pressure to revolutionize their tactics to better fit this first-of-its-kind metropolis.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="boasting" lemma="boast" stem="boast" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="8" string="methods" lemma="method" stem="method" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="models" lemma="model" stem="model" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="policing" lemma="police" stem="polic" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="both" lemma="both" stem="both" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="departments" lemma="department" stem="depart" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="facing" lemma="face" stem="face" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="pressure" lemma="pressure" stem="pressur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="revolutionize" lemma="revolutionize" stem="revolution" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="tactics" lemma="tactic" stem="tactic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="better" lemma="better" stem="better" pos="RBR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="fit" lemma="fit" stem="fit" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="first-of-its-kind" lemma="first-of-its-kind" stem="first-of-its-kind" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="metropolis" lemma="metropolis" stem="metropoli" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (PP (IN after) (NP (NP (NNS years)) (PP (IN of) (S (VP (VBG boasting) (SBAR (IN that) (S (NP (PRP$ their) (NNS methods)) (VP (VBD were) (NP (NP (NNS models)) (PP (IN in) (S (VP (VBG policing))))))))))))) (, ,) (NP (DT both) (NNS departments)) (VP (VBP are) (VP (VBG facing) (NP (NN pressure)) (S (VP (TO to) (VP (VB revolutionize) (NP (PRP$ their) (NNS tactics)) (S (VP (TO to) (VP (ADVP (RBR better)) (VB fit) (NP (DT this) (JJ first-of-its-kind) (NN metropolis)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="models" type="NP">
          <tokens>
            <token id="10" string="models" />
          </tokens>
        </chunking>
        <chunking id="2" string="policing" type="VP">
          <tokens>
            <token id="12" string="policing" />
          </tokens>
        </chunking>
        <chunking id="3" string="both departments" type="NP">
          <tokens>
            <token id="14" string="both" />
            <token id="15" string="departments" />
          </tokens>
        </chunking>
        <chunking id="4" string="pressure" type="NP">
          <tokens>
            <token id="18" string="pressure" />
          </tokens>
        </chunking>
        <chunking id="5" string="models in policing" type="NP">
          <tokens>
            <token id="10" string="models" />
            <token id="11" string="in" />
            <token id="12" string="policing" />
          </tokens>
        </chunking>
        <chunking id="6" string="years" type="NP">
          <tokens>
            <token id="3" string="years" />
          </tokens>
        </chunking>
        <chunking id="7" string="that their methods were models in policing" type="SBAR">
          <tokens>
            <token id="6" string="that" />
            <token id="7" string="their" />
            <token id="8" string="methods" />
            <token id="9" string="were" />
            <token id="10" string="models" />
            <token id="11" string="in" />
            <token id="12" string="policing" />
          </tokens>
        </chunking>
        <chunking id="8" string="better fit this first-of-its-kind metropolis" type="VP">
          <tokens>
            <token id="24" string="better" />
            <token id="25" string="fit" />
            <token id="26" string="this" />
            <token id="27" string="first-of-its-kind" />
            <token id="28" string="metropolis" />
          </tokens>
        </chunking>
        <chunking id="9" string="their tactics" type="NP">
          <tokens>
            <token id="21" string="their" />
            <token id="22" string="tactics" />
          </tokens>
        </chunking>
        <chunking id="10" string="years of boasting that their methods were models in policing" type="NP">
          <tokens>
            <token id="3" string="years" />
            <token id="4" string="of" />
            <token id="5" string="boasting" />
            <token id="6" string="that" />
            <token id="7" string="their" />
            <token id="8" string="methods" />
            <token id="9" string="were" />
            <token id="10" string="models" />
            <token id="11" string="in" />
            <token id="12" string="policing" />
          </tokens>
        </chunking>
        <chunking id="11" string="were models in policing" type="VP">
          <tokens>
            <token id="9" string="were" />
            <token id="10" string="models" />
            <token id="11" string="in" />
            <token id="12" string="policing" />
          </tokens>
        </chunking>
        <chunking id="12" string="are facing pressure to revolutionize their tactics to better fit this first-of-its-kind metropolis" type="VP">
          <tokens>
            <token id="16" string="are" />
            <token id="17" string="facing" />
            <token id="18" string="pressure" />
            <token id="19" string="to" />
            <token id="20" string="revolutionize" />
            <token id="21" string="their" />
            <token id="22" string="tactics" />
            <token id="23" string="to" />
            <token id="24" string="better" />
            <token id="25" string="fit" />
            <token id="26" string="this" />
            <token id="27" string="first-of-its-kind" />
            <token id="28" string="metropolis" />
          </tokens>
        </chunking>
        <chunking id="13" string="facing pressure to revolutionize their tactics to better fit this first-of-its-kind metropolis" type="VP">
          <tokens>
            <token id="17" string="facing" />
            <token id="18" string="pressure" />
            <token id="19" string="to" />
            <token id="20" string="revolutionize" />
            <token id="21" string="their" />
            <token id="22" string="tactics" />
            <token id="23" string="to" />
            <token id="24" string="better" />
            <token id="25" string="fit" />
            <token id="26" string="this" />
            <token id="27" string="first-of-its-kind" />
            <token id="28" string="metropolis" />
          </tokens>
        </chunking>
        <chunking id="14" string="revolutionize their tactics to better fit this first-of-its-kind metropolis" type="VP">
          <tokens>
            <token id="20" string="revolutionize" />
            <token id="21" string="their" />
            <token id="22" string="tactics" />
            <token id="23" string="to" />
            <token id="24" string="better" />
            <token id="25" string="fit" />
            <token id="26" string="this" />
            <token id="27" string="first-of-its-kind" />
            <token id="28" string="metropolis" />
          </tokens>
        </chunking>
        <chunking id="15" string="to better fit this first-of-its-kind metropolis" type="VP">
          <tokens>
            <token id="23" string="to" />
            <token id="24" string="better" />
            <token id="25" string="fit" />
            <token id="26" string="this" />
            <token id="27" string="first-of-its-kind" />
            <token id="28" string="metropolis" />
          </tokens>
        </chunking>
        <chunking id="16" string="boasting that their methods were models in policing" type="VP">
          <tokens>
            <token id="5" string="boasting" />
            <token id="6" string="that" />
            <token id="7" string="their" />
            <token id="8" string="methods" />
            <token id="9" string="were" />
            <token id="10" string="models" />
            <token id="11" string="in" />
            <token id="12" string="policing" />
          </tokens>
        </chunking>
        <chunking id="17" string="their methods" type="NP">
          <tokens>
            <token id="7" string="their" />
            <token id="8" string="methods" />
          </tokens>
        </chunking>
        <chunking id="18" string="to revolutionize their tactics to better fit this first-of-its-kind metropolis" type="VP">
          <tokens>
            <token id="19" string="to" />
            <token id="20" string="revolutionize" />
            <token id="21" string="their" />
            <token id="22" string="tactics" />
            <token id="23" string="to" />
            <token id="24" string="better" />
            <token id="25" string="fit" />
            <token id="26" string="this" />
            <token id="27" string="first-of-its-kind" />
            <token id="28" string="metropolis" />
          </tokens>
        </chunking>
        <chunking id="19" string="this first-of-its-kind metropolis" type="NP">
          <tokens>
            <token id="26" string="this" />
            <token id="27" string="first-of-its-kind" />
            <token id="28" string="metropolis" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="17">facing</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">years</governor>
          <dependent id="2">after</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">facing</governor>
          <dependent id="3">years</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">boasting</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="3">years</governor>
          <dependent id="5">boasting</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">models</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">methods</governor>
          <dependent id="7">their</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">models</governor>
          <dependent id="8">methods</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="10">models</governor>
          <dependent id="9">were</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">boasting</governor>
          <dependent id="10">models</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">policing</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="10">models</governor>
          <dependent id="12">policing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">departments</governor>
          <dependent id="14">both</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">facing</governor>
          <dependent id="15">departments</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="17">facing</governor>
          <dependent id="16">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">facing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">facing</governor>
          <dependent id="18">pressure</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">revolutionize</governor>
          <dependent id="19">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="17">facing</governor>
          <dependent id="20">revolutionize</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="22">tactics</governor>
          <dependent id="21">their</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">revolutionize</governor>
          <dependent id="22">tactics</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="25">fit</governor>
          <dependent id="23">to</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="25">fit</governor>
          <dependent id="24">better</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="20">revolutionize</governor>
          <dependent id="25">fit</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">metropolis</governor>
          <dependent id="26">this</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">metropolis</governor>
          <dependent id="27">first-of-its-kind</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">fit</governor>
          <dependent id="28">metropolis</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="years" type="DURATION" score="0.0">
          <tokens>
            <token id="3" string="years" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>&amp;quot;We are a multiracial, multicultural city more than any other,&amp;quot; said Ramona Ripston, head of the American Civil Liberties Union of Southern California.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="multiracial" lemma="multiracial" stem="multiraci" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="multicultural" lemma="multicultural" stem="multicultur" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="city" lemma="city" stem="citi" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="Ramona" lemma="Ramona" stem="ramona" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="17" string="Ripston" lemma="Ripston" stem="ripston" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="head" lemma="head" stem="head" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="American" lemma="American" stem="american" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="23" string="Civil" lemma="Civil" stem="civil" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="24" string="Liberties" lemma="Liberties" stem="liberti" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="25" string="Union" lemma="Union" stem="union" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="26" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="27" string="Southern" lemma="Southern" stem="southern" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="28" string="California" lemma="California" stem="california" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (PRP We)) (VP (VBP are) (NP (DT a) (JJ multiracial) (, ,) (JJ multicultural) (NN city)) (ADVP (RBR more) (PP (IN than) (NP (DT any) (JJ other)))))) (, ,) ('' '') (VP (VBD said)) (NP (NP (NNP Ramona) (NNP Ripston)) (, ,) (NP (NP (NN head)) (PP (IN of) (NP (DT the) (NNP American) (NNP Civil) (NNP Liberties) (NNP Union))) (PP (IN of) (NP (NNP Southern) (NNP California))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="any other" type="NP">
          <tokens>
            <token id="11" string="any" />
            <token id="12" string="other" />
          </tokens>
        </chunking>
        <chunking id="2" string="Southern California" type="NP">
          <tokens>
            <token id="27" string="Southern" />
            <token id="28" string="California" />
          </tokens>
        </chunking>
        <chunking id="3" string="a multiracial , multicultural city" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="multiracial" />
            <token id="6" string="," />
            <token id="7" string="multicultural" />
            <token id="8" string="city" />
          </tokens>
        </chunking>
        <chunking id="4" string="Ramona Ripston , head of the American Civil Liberties Union of Southern California" type="NP">
          <tokens>
            <token id="16" string="Ramona" />
            <token id="17" string="Ripston" />
            <token id="18" string="," />
            <token id="19" string="head" />
            <token id="20" string="of" />
            <token id="21" string="the" />
            <token id="22" string="American" />
            <token id="23" string="Civil" />
            <token id="24" string="Liberties" />
            <token id="25" string="Union" />
            <token id="26" string="of" />
            <token id="27" string="Southern" />
            <token id="28" string="California" />
          </tokens>
        </chunking>
        <chunking id="5" string="Ramona Ripston" type="NP">
          <tokens>
            <token id="16" string="Ramona" />
            <token id="17" string="Ripston" />
          </tokens>
        </chunking>
        <chunking id="6" string="head of the American Civil Liberties Union of Southern California" type="NP">
          <tokens>
            <token id="19" string="head" />
            <token id="20" string="of" />
            <token id="21" string="the" />
            <token id="22" string="American" />
            <token id="23" string="Civil" />
            <token id="24" string="Liberties" />
            <token id="25" string="Union" />
            <token id="26" string="of" />
            <token id="27" string="Southern" />
            <token id="28" string="California" />
          </tokens>
        </chunking>
        <chunking id="7" string="the American Civil Liberties Union" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="American" />
            <token id="23" string="Civil" />
            <token id="24" string="Liberties" />
            <token id="25" string="Union" />
          </tokens>
        </chunking>
        <chunking id="8" string="are a multiracial , multicultural city more than any other" type="VP">
          <tokens>
            <token id="3" string="are" />
            <token id="4" string="a" />
            <token id="5" string="multiracial" />
            <token id="6" string="," />
            <token id="7" string="multicultural" />
            <token id="8" string="city" />
            <token id="9" string="more" />
            <token id="10" string="than" />
            <token id="11" string="any" />
            <token id="12" string="other" />
          </tokens>
        </chunking>
        <chunking id="9" string="We" type="NP">
          <tokens>
            <token id="2" string="We" />
          </tokens>
        </chunking>
        <chunking id="10" string="said" type="VP">
          <tokens>
            <token id="15" string="said" />
          </tokens>
        </chunking>
        <chunking id="11" string="head" type="NP">
          <tokens>
            <token id="19" string="head" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="8">city</governor>
          <dependent id="2">We</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">city</governor>
          <dependent id="3">are</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">city</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">city</governor>
          <dependent id="5">multiracial</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">city</governor>
          <dependent id="7">multicultural</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">said</governor>
          <dependent id="8">city</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">city</governor>
          <dependent id="9">more</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">other</governor>
          <dependent id="10">than</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">other</governor>
          <dependent id="11">any</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">more</governor>
          <dependent id="12">other</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Ripston</governor>
          <dependent id="16">Ramona</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">said</governor>
          <dependent id="17">Ripston</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="17">Ripston</governor>
          <dependent id="19">head</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">Union</governor>
          <dependent id="20">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">Union</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">Union</governor>
          <dependent id="22">American</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">Union</governor>
          <dependent id="23">Civil</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">Union</governor>
          <dependent id="24">Liberties</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">head</governor>
          <dependent id="25">Union</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">California</governor>
          <dependent id="26">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">California</governor>
          <dependent id="27">Southern</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">head</governor>
          <dependent id="28">California</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="American Civil Liberties Union of Southern California" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="22" string="American" />
            <token id="23" string="Civil" />
            <token id="24" string="Liberties" />
            <token id="25" string="Union" />
            <token id="26" string="of" />
            <token id="27" string="Southern" />
            <token id="28" string="California" />
          </tokens>
        </entity>
        <entity id="2" string="Ramona Ripston" type="PERSON" score="0.0">
          <tokens>
            <token id="16" string="Ramona" />
            <token id="17" string="Ripston" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>&amp;quot;If something can be worked out here, it would be really, I think, a model that can be exported.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="If" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="something" lemma="something" stem="someth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="worked" lemma="work" stem="work" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="here" lemma="here" stem="here" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="really" lemma="really" stem="realli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="think" lemma="think" stem="think" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="model" lemma="model" stem="model" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="exported" lemma="export" stem="export" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (SBAR (IN If) (S (NP (NN something)) (VP (MD can) (VP (VB be) (VP (VBN worked) (PRT (RP out)) (ADVP (RB here))))))) (PRN (, ,) (S (NP (PRP it)) (VP (MD would) (VP (VB be) (ADVP (RB really))))) (, ,)) (NP (PRP I)) (VP (VBP think) (, ,) (NP (NP (DT a) (NN model)) (SBAR (WHNP (WDT that)) (S (VP (MD can) (VP (VB be) (VP (VBN exported)))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="be worked out here" type="VP">
          <tokens>
            <token id="5" string="be" />
            <token id="6" string="worked" />
            <token id="7" string="out" />
            <token id="8" string="here" />
          </tokens>
        </chunking>
        <chunking id="2" string="exported" type="VP">
          <tokens>
            <token id="23" string="exported" />
          </tokens>
        </chunking>
        <chunking id="3" string="a model" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="model" />
          </tokens>
        </chunking>
        <chunking id="4" string="If something can be worked out here" type="SBAR">
          <tokens>
            <token id="2" string="If" />
            <token id="3" string="something" />
            <token id="4" string="can" />
            <token id="5" string="be" />
            <token id="6" string="worked" />
            <token id="7" string="out" />
            <token id="8" string="here" />
          </tokens>
        </chunking>
        <chunking id="5" string="a model that can be exported" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="model" />
            <token id="20" string="that" />
            <token id="21" string="can" />
            <token id="22" string="be" />
            <token id="23" string="exported" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="15" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="be exported" type="VP">
          <tokens>
            <token id="22" string="be" />
            <token id="23" string="exported" />
          </tokens>
        </chunking>
        <chunking id="8" string="worked out here" type="VP">
          <tokens>
            <token id="6" string="worked" />
            <token id="7" string="out" />
            <token id="8" string="here" />
          </tokens>
        </chunking>
        <chunking id="9" string="it" type="NP">
          <tokens>
            <token id="10" string="it" />
          </tokens>
        </chunking>
        <chunking id="10" string="would be really" type="VP">
          <tokens>
            <token id="11" string="would" />
            <token id="12" string="be" />
            <token id="13" string="really" />
          </tokens>
        </chunking>
        <chunking id="11" string="think , a model that can be exported" type="VP">
          <tokens>
            <token id="16" string="think" />
            <token id="17" string="," />
            <token id="18" string="a" />
            <token id="19" string="model" />
            <token id="20" string="that" />
            <token id="21" string="can" />
            <token id="22" string="be" />
            <token id="23" string="exported" />
          </tokens>
        </chunking>
        <chunking id="12" string="something" type="NP">
          <tokens>
            <token id="3" string="something" />
          </tokens>
        </chunking>
        <chunking id="13" string="be really" type="VP">
          <tokens>
            <token id="12" string="be" />
            <token id="13" string="really" />
          </tokens>
        </chunking>
        <chunking id="14" string="can be worked out here" type="VP">
          <tokens>
            <token id="4" string="can" />
            <token id="5" string="be" />
            <token id="6" string="worked" />
            <token id="7" string="out" />
            <token id="8" string="here" />
          </tokens>
        </chunking>
        <chunking id="15" string="can be exported" type="VP">
          <tokens>
            <token id="21" string="can" />
            <token id="22" string="be" />
            <token id="23" string="exported" />
          </tokens>
        </chunking>
        <chunking id="16" string="that can be exported" type="SBAR">
          <tokens>
            <token id="20" string="that" />
            <token id="21" string="can" />
            <token id="22" string="be" />
            <token id="23" string="exported" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="6">worked</governor>
          <dependent id="2">If</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="6">worked</governor>
          <dependent id="3">something</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">worked</governor>
          <dependent id="4">can</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">worked</governor>
          <dependent id="5">be</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="16">think</governor>
          <dependent id="6">worked</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="6">worked</governor>
          <dependent id="7">out</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">worked</governor>
          <dependent id="8">here</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">be</governor>
          <dependent id="10">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">be</governor>
          <dependent id="11">would</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="16">think</governor>
          <dependent id="12">be</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">be</governor>
          <dependent id="13">really</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">think</governor>
          <dependent id="15">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">think</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">model</governor>
          <dependent id="18">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">think</governor>
          <dependent id="19">model</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="23">exported</governor>
          <dependent id="20">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="23">exported</governor>
          <dependent id="21">can</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="23">exported</governor>
          <dependent id="22">be</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="19">model</governor>
          <dependent id="23">exported</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>; Joseph McNamara, retired chief of San Jose&amp;apost;s department and now a fellow at Stanford University&amp;apost;s Hoover Institution, said he has been getting calls all summer from cities around the country about racism and brutality in their departments.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Joseph" lemma="Joseph" stem="joseph" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="3" string="McNamara" lemma="McNamara" stem="mcnamara" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="retired" lemma="retire" stem="retir" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="chief" lemma="chief" stem="chief" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="San" lemma="San" stem="san" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="9" string="Jose" lemma="Jose" stem="jose" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="10" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="department" lemma="department" stem="depart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="fellow" lemma="fellow" stem="fellow" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="Stanford" lemma="Stanford" stem="stanford" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="18" string="University" lemma="University" stem="univers" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="19" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="20" string="Hoover" lemma="Hoover" stem="hoover" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="21" string="Institution" lemma="Institution" stem="institut" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="getting" lemma="get" stem="get" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="calls" lemma="call" stem="call" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="summer" lemma="summer" stem="summer" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="31" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="cities" lemma="city" stem="citi" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="33" string="around" lemma="around" stem="around" pos="IN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="34" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="35" string="country" lemma="country" stem="countri" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="36" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="37" string="racism" lemma="racism" stem="racism" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="38" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="39" string="brutality" lemma="brutality" stem="brutal" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="40" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="42" string="departments" lemma="department" stem="depart" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="43" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (NP (NP (NNP Joseph) (NNP McNamara)) (, ,) (VP (VBD retired) (NP (NP (NN chief)) (PP (IN of) (NP (NP (NP (NNP San) (NNP Jose) (POS 's)) (NN department)) (CC and) (NP (ADVP (RB now)) (DT a) (NN fellow))))) (PP (IN at) (NP (NP (NNP Stanford) (NNP University) (POS 's)) (NNP Hoover) (NNP Institution)))) (, ,)) (VP (VBD said) (SBAR (S (NP (PRP he)) (VP (VBZ has) (VP (VBN been) (VP (VBG getting) (NP (NNS calls)) (NP-TMP (DT all) (NN summer)) (PP (IN from) (NP (NP (NNS cities)) (PP (IN around) (NP (NP (DT the) (NN country)) (PP (IN about) (NP (NN racism) (CC and) (NN brutality))))))) (PP (IN in) (NP (PRP$ their) (NNS departments))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="cities" type="NP">
          <tokens>
            <token id="32" string="cities" />
          </tokens>
        </chunking>
        <chunking id="2" string="the country about racism and brutality" type="NP">
          <tokens>
            <token id="34" string="the" />
            <token id="35" string="country" />
            <token id="36" string="about" />
            <token id="37" string="racism" />
            <token id="38" string="and" />
            <token id="39" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="3" string="chief" type="NP">
          <tokens>
            <token id="6" string="chief" />
          </tokens>
        </chunking>
        <chunking id="4" string="retired chief of San Jose 's department and now a fellow at Stanford University 's Hoover Institution" type="VP">
          <tokens>
            <token id="5" string="retired" />
            <token id="6" string="chief" />
            <token id="7" string="of" />
            <token id="8" string="San" />
            <token id="9" string="Jose" />
            <token id="10" string="'s" />
            <token id="11" string="department" />
            <token id="12" string="and" />
            <token id="13" string="now" />
            <token id="14" string="a" />
            <token id="15" string="fellow" />
            <token id="16" string="at" />
            <token id="17" string="Stanford" />
            <token id="18" string="University" />
            <token id="19" string="'s" />
            <token id="20" string="Hoover" />
            <token id="21" string="Institution" />
          </tokens>
        </chunking>
        <chunking id="5" string="been getting calls all summer from cities around the country about racism and brutality in their departments" type="VP">
          <tokens>
            <token id="26" string="been" />
            <token id="27" string="getting" />
            <token id="28" string="calls" />
            <token id="29" string="all" />
            <token id="30" string="summer" />
            <token id="31" string="from" />
            <token id="32" string="cities" />
            <token id="33" string="around" />
            <token id="34" string="the" />
            <token id="35" string="country" />
            <token id="36" string="about" />
            <token id="37" string="racism" />
            <token id="38" string="and" />
            <token id="39" string="brutality" />
            <token id="40" string="in" />
            <token id="41" string="their" />
            <token id="42" string="departments" />
          </tokens>
        </chunking>
        <chunking id="6" string="San Jose 's department" type="NP">
          <tokens>
            <token id="8" string="San" />
            <token id="9" string="Jose" />
            <token id="10" string="'s" />
            <token id="11" string="department" />
          </tokens>
        </chunking>
        <chunking id="7" string="Joseph McNamara , retired chief of San Jose 's department and now a fellow at Stanford University 's Hoover Institution ," type="NP">
          <tokens>
            <token id="2" string="Joseph" />
            <token id="3" string="McNamara" />
            <token id="4" string="," />
            <token id="5" string="retired" />
            <token id="6" string="chief" />
            <token id="7" string="of" />
            <token id="8" string="San" />
            <token id="9" string="Jose" />
            <token id="10" string="'s" />
            <token id="11" string="department" />
            <token id="12" string="and" />
            <token id="13" string="now" />
            <token id="14" string="a" />
            <token id="15" string="fellow" />
            <token id="16" string="at" />
            <token id="17" string="Stanford" />
            <token id="18" string="University" />
            <token id="19" string="'s" />
            <token id="20" string="Hoover" />
            <token id="21" string="Institution" />
            <token id="22" string="," />
          </tokens>
        </chunking>
        <chunking id="8" string="their departments" type="NP">
          <tokens>
            <token id="41" string="their" />
            <token id="42" string="departments" />
          </tokens>
        </chunking>
        <chunking id="9" string="Stanford University 's" type="NP">
          <tokens>
            <token id="17" string="Stanford" />
            <token id="18" string="University" />
            <token id="19" string="'s" />
          </tokens>
        </chunking>
        <chunking id="10" string="Stanford University 's Hoover Institution" type="NP">
          <tokens>
            <token id="17" string="Stanford" />
            <token id="18" string="University" />
            <token id="19" string="'s" />
            <token id="20" string="Hoover" />
            <token id="21" string="Institution" />
          </tokens>
        </chunking>
        <chunking id="11" string="calls" type="NP">
          <tokens>
            <token id="28" string="calls" />
          </tokens>
        </chunking>
        <chunking id="12" string="San Jose 's" type="NP">
          <tokens>
            <token id="8" string="San" />
            <token id="9" string="Jose" />
            <token id="10" string="'s" />
          </tokens>
        </chunking>
        <chunking id="13" string="the country" type="NP">
          <tokens>
            <token id="34" string="the" />
            <token id="35" string="country" />
          </tokens>
        </chunking>
        <chunking id="14" string="San Jose 's department and now a fellow" type="NP">
          <tokens>
            <token id="8" string="San" />
            <token id="9" string="Jose" />
            <token id="10" string="'s" />
            <token id="11" string="department" />
            <token id="12" string="and" />
            <token id="13" string="now" />
            <token id="14" string="a" />
            <token id="15" string="fellow" />
          </tokens>
        </chunking>
        <chunking id="15" string="now a fellow" type="NP">
          <tokens>
            <token id="13" string="now" />
            <token id="14" string="a" />
            <token id="15" string="fellow" />
          </tokens>
        </chunking>
        <chunking id="16" string="racism and brutality" type="NP">
          <tokens>
            <token id="37" string="racism" />
            <token id="38" string="and" />
            <token id="39" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="17" string="cities around the country about racism and brutality" type="NP">
          <tokens>
            <token id="32" string="cities" />
            <token id="33" string="around" />
            <token id="34" string="the" />
            <token id="35" string="country" />
            <token id="36" string="about" />
            <token id="37" string="racism" />
            <token id="38" string="and" />
            <token id="39" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="18" string="he" type="NP">
          <tokens>
            <token id="24" string="he" />
          </tokens>
        </chunking>
        <chunking id="19" string="chief of San Jose 's department and now a fellow" type="NP">
          <tokens>
            <token id="6" string="chief" />
            <token id="7" string="of" />
            <token id="8" string="San" />
            <token id="9" string="Jose" />
            <token id="10" string="'s" />
            <token id="11" string="department" />
            <token id="12" string="and" />
            <token id="13" string="now" />
            <token id="14" string="a" />
            <token id="15" string="fellow" />
          </tokens>
        </chunking>
        <chunking id="20" string="Joseph McNamara" type="NP">
          <tokens>
            <token id="2" string="Joseph" />
            <token id="3" string="McNamara" />
          </tokens>
        </chunking>
        <chunking id="21" string="said he has been getting calls all summer from cities around the country about racism and brutality in their departments" type="VP">
          <tokens>
            <token id="23" string="said" />
            <token id="24" string="he" />
            <token id="25" string="has" />
            <token id="26" string="been" />
            <token id="27" string="getting" />
            <token id="28" string="calls" />
            <token id="29" string="all" />
            <token id="30" string="summer" />
            <token id="31" string="from" />
            <token id="32" string="cities" />
            <token id="33" string="around" />
            <token id="34" string="the" />
            <token id="35" string="country" />
            <token id="36" string="about" />
            <token id="37" string="racism" />
            <token id="38" string="and" />
            <token id="39" string="brutality" />
            <token id="40" string="in" />
            <token id="41" string="their" />
            <token id="42" string="departments" />
          </tokens>
        </chunking>
        <chunking id="22" string="he has been getting calls all summer from cities around the country about racism and brutality in their departments" type="SBAR">
          <tokens>
            <token id="24" string="he" />
            <token id="25" string="has" />
            <token id="26" string="been" />
            <token id="27" string="getting" />
            <token id="28" string="calls" />
            <token id="29" string="all" />
            <token id="30" string="summer" />
            <token id="31" string="from" />
            <token id="32" string="cities" />
            <token id="33" string="around" />
            <token id="34" string="the" />
            <token id="35" string="country" />
            <token id="36" string="about" />
            <token id="37" string="racism" />
            <token id="38" string="and" />
            <token id="39" string="brutality" />
            <token id="40" string="in" />
            <token id="41" string="their" />
            <token id="42" string="departments" />
          </tokens>
        </chunking>
        <chunking id="23" string="getting calls all summer from cities around the country about racism and brutality in their departments" type="VP">
          <tokens>
            <token id="27" string="getting" />
            <token id="28" string="calls" />
            <token id="29" string="all" />
            <token id="30" string="summer" />
            <token id="31" string="from" />
            <token id="32" string="cities" />
            <token id="33" string="around" />
            <token id="34" string="the" />
            <token id="35" string="country" />
            <token id="36" string="about" />
            <token id="37" string="racism" />
            <token id="38" string="and" />
            <token id="39" string="brutality" />
            <token id="40" string="in" />
            <token id="41" string="their" />
            <token id="42" string="departments" />
          </tokens>
        </chunking>
        <chunking id="24" string="has been getting calls all summer from cities around the country about racism and brutality in their departments" type="VP">
          <tokens>
            <token id="25" string="has" />
            <token id="26" string="been" />
            <token id="27" string="getting" />
            <token id="28" string="calls" />
            <token id="29" string="all" />
            <token id="30" string="summer" />
            <token id="31" string="from" />
            <token id="32" string="cities" />
            <token id="33" string="around" />
            <token id="34" string="the" />
            <token id="35" string="country" />
            <token id="36" string="about" />
            <token id="37" string="racism" />
            <token id="38" string="and" />
            <token id="39" string="brutality" />
            <token id="40" string="in" />
            <token id="41" string="their" />
            <token id="42" string="departments" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">McNamara</governor>
          <dependent id="2">Joseph</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">said</governor>
          <dependent id="3">McNamara</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="3">McNamara</governor>
          <dependent id="5">retired</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">retired</governor>
          <dependent id="6">chief</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">department</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Jose</governor>
          <dependent id="8">San</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">department</governor>
          <dependent id="9">Jose</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Jose</governor>
          <dependent id="10">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">chief</governor>
          <dependent id="11">department</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">department</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">fellow</governor>
          <dependent id="13">now</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">fellow</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">department</governor>
          <dependent id="15">fellow</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">Institution</governor>
          <dependent id="16">at</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">University</governor>
          <dependent id="17">Stanford</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="21">Institution</governor>
          <dependent id="18">University</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">University</governor>
          <dependent id="19">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">Institution</governor>
          <dependent id="20">Hoover</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">retired</governor>
          <dependent id="21">Institution</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="23">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">getting</governor>
          <dependent id="24">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="27">getting</governor>
          <dependent id="25">has</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="27">getting</governor>
          <dependent id="26">been</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="23">said</governor>
          <dependent id="27">getting</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="27">getting</governor>
          <dependent id="28">calls</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">summer</governor>
          <dependent id="29">all</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="27">getting</governor>
          <dependent id="30">summer</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">cities</governor>
          <dependent id="31">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">getting</governor>
          <dependent id="32">cities</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">country</governor>
          <dependent id="33">around</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">country</governor>
          <dependent id="34">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">cities</governor>
          <dependent id="35">country</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">racism</governor>
          <dependent id="36">about</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="35">country</governor>
          <dependent id="37">racism</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="37">racism</governor>
          <dependent id="38">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="37">racism</governor>
          <dependent id="39">brutality</dependent>
        </dependency>
        <dependency type="case">
          <governor id="42">departments</governor>
          <dependent id="40">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="42">departments</governor>
          <dependent id="41">their</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">getting</governor>
          <dependent id="42">departments</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Stanford University 's Hoover Institution" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="17" string="Stanford" />
            <token id="18" string="University" />
            <token id="19" string="'s" />
            <token id="20" string="Hoover" />
            <token id="21" string="Institution" />
          </tokens>
        </entity>
        <entity id="2" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="13" string="now" />
          </tokens>
        </entity>
        <entity id="3" string="Joseph McNamara" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Joseph" />
            <token id="3" string="McNamara" />
          </tokens>
        </entity>
        <entity id="4" string="San Jose" type="LOCATION" score="0.0">
          <tokens>
            <token id="8" string="San" />
            <token id="9" string="Jose" />
          </tokens>
        </entity>
        <entity id="5" string="summer" type="DATE" score="0.0">
          <tokens>
            <token id="30" string="summer" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>&amp;quot;There&amp;apost;s got to be a revolution in American policing,&amp;quot; McNamara said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="got" lemma="get" stem="got" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="revolution" lemma="revolution" stem="revolut" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="American" lemma="american" stem="american" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="11" string="policing" lemma="police" stem="polic" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="McNamara" lemma="McNamara" stem="mcnamara" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="15" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (EX There)) (VP (VBZ 's) (VP (VBN got) (S (VP (TO to) (VP (VB be) (NP (NP (DT a) (NN revolution)) (PP (IN in) (NP (NP (JJ American)) (VP (VBG policing))))))))))) (, ,) ('' '') (NP (NNP McNamara)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="policing" type="VP">
          <tokens>
            <token id="11" string="policing" />
          </tokens>
        </chunking>
        <chunking id="2" string="There" type="NP">
          <tokens>
            <token id="2" string="There" />
          </tokens>
        </chunking>
        <chunking id="3" string="be a revolution in American policing" type="VP">
          <tokens>
            <token id="6" string="be" />
            <token id="7" string="a" />
            <token id="8" string="revolution" />
            <token id="9" string="in" />
            <token id="10" string="American" />
            <token id="11" string="policing" />
          </tokens>
        </chunking>
        <chunking id="4" string="American policing" type="NP">
          <tokens>
            <token id="10" string="American" />
            <token id="11" string="policing" />
          </tokens>
        </chunking>
        <chunking id="5" string="got to be a revolution in American policing" type="VP">
          <tokens>
            <token id="4" string="got" />
            <token id="5" string="to" />
            <token id="6" string="be" />
            <token id="7" string="a" />
            <token id="8" string="revolution" />
            <token id="9" string="in" />
            <token id="10" string="American" />
            <token id="11" string="policing" />
          </tokens>
        </chunking>
        <chunking id="6" string="to be a revolution in American policing" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="be" />
            <token id="7" string="a" />
            <token id="8" string="revolution" />
            <token id="9" string="in" />
            <token id="10" string="American" />
            <token id="11" string="policing" />
          </tokens>
        </chunking>
        <chunking id="7" string="American" type="NP">
          <tokens>
            <token id="10" string="American" />
          </tokens>
        </chunking>
        <chunking id="8" string="a revolution" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="revolution" />
          </tokens>
        </chunking>
        <chunking id="9" string="McNamara" type="NP">
          <tokens>
            <token id="14" string="McNamara" />
          </tokens>
        </chunking>
        <chunking id="10" string="a revolution in American policing" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="revolution" />
            <token id="9" string="in" />
            <token id="10" string="American" />
            <token id="11" string="policing" />
          </tokens>
        </chunking>
        <chunking id="11" string="said" type="VP">
          <tokens>
            <token id="15" string="said" />
          </tokens>
        </chunking>
        <chunking id="12" string="'s got to be a revolution in American policing" type="VP">
          <tokens>
            <token id="3" string="'s" />
            <token id="4" string="got" />
            <token id="5" string="to" />
            <token id="6" string="be" />
            <token id="7" string="a" />
            <token id="8" string="revolution" />
            <token id="9" string="in" />
            <token id="10" string="American" />
            <token id="11" string="policing" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="4">got</governor>
          <dependent id="2">There</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">got</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">said</governor>
          <dependent id="4">got</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">revolution</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">revolution</governor>
          <dependent id="6">be</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">revolution</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">got</governor>
          <dependent id="8">revolution</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">American</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">revolution</governor>
          <dependent id="10">American</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="10">American</governor>
          <dependent id="11">policing</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">said</governor>
          <dependent id="14">McNamara</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="American" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="10" string="American" />
          </tokens>
        </entity>
        <entity id="2" string="McNamara" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="McNamara" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>&amp;quot;Militarizing police is a definite trend in the past 10 years, and part of it is because of the Los Angeles models.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Militarizing" lemma="militarize" stem="militar" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="definite" lemma="definite" stem="definit" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="trend" lemma="trend" stem="trend" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="10" string="past" lemma="past" stem="past" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="11" string="10" lemma="10" stem="10" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="12" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="part" lemma="part" stem="part" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="Los" lemma="Los" stem="lo" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="23" string="Angeles" lemma="Angeles" stem="angele" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="24" string="models" lemma="model" stem="model" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (VBG Militarizing) (NN police)) (VP (VBZ is) (NP (NP (DT a) (JJ definite) (NN trend)) (PP (IN in) (NP (DT the) (JJ past) (CD 10) (NNS years)))))) (, ,) (CC and) (S (NP (NP (NN part)) (PP (IN of) (NP (PRP it)))) (VP (VBZ is) (PP (IN because) (PP (IN of) (NP (DT the) (NNP Los) (NNP Angeles) (NNS models)))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="the past 10 years" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="past" />
            <token id="11" string="10" />
            <token id="12" string="years" />
          </tokens>
        </chunking>
        <chunking id="2" string="a definite trend in the past 10 years" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="definite" />
            <token id="7" string="trend" />
            <token id="8" string="in" />
            <token id="9" string="the" />
            <token id="10" string="past" />
            <token id="11" string="10" />
            <token id="12" string="years" />
          </tokens>
        </chunking>
        <chunking id="3" string="part" type="NP">
          <tokens>
            <token id="15" string="part" />
          </tokens>
        </chunking>
        <chunking id="4" string="a definite trend" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="definite" />
            <token id="7" string="trend" />
          </tokens>
        </chunking>
        <chunking id="5" string="Militarizing police" type="NP">
          <tokens>
            <token id="2" string="Militarizing" />
            <token id="3" string="police" />
          </tokens>
        </chunking>
        <chunking id="6" string="part of it" type="NP">
          <tokens>
            <token id="15" string="part" />
            <token id="16" string="of" />
            <token id="17" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="17" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="the Los Angeles models" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="Los" />
            <token id="23" string="Angeles" />
            <token id="24" string="models" />
          </tokens>
        </chunking>
        <chunking id="9" string="is a definite trend in the past 10 years" type="VP">
          <tokens>
            <token id="4" string="is" />
            <token id="5" string="a" />
            <token id="6" string="definite" />
            <token id="7" string="trend" />
            <token id="8" string="in" />
            <token id="9" string="the" />
            <token id="10" string="past" />
            <token id="11" string="10" />
            <token id="12" string="years" />
          </tokens>
        </chunking>
        <chunking id="10" string="is because of the Los Angeles models" type="VP">
          <tokens>
            <token id="18" string="is" />
            <token id="19" string="because" />
            <token id="20" string="of" />
            <token id="21" string="the" />
            <token id="22" string="Los" />
            <token id="23" string="Angeles" />
            <token id="24" string="models" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="3">police</governor>
          <dependent id="2">Militarizing</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">trend</governor>
          <dependent id="3">police</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">trend</governor>
          <dependent id="4">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">trend</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">trend</governor>
          <dependent id="6">definite</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">trend</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">years</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">years</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">years</governor>
          <dependent id="10">past</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="12">years</governor>
          <dependent id="11">10</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">trend</governor>
          <dependent id="12">years</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">trend</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">models</governor>
          <dependent id="15">part</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">it</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">part</governor>
          <dependent id="17">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="24">models</governor>
          <dependent id="18">is</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">models</governor>
          <dependent id="19">because</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">models</governor>
          <dependent id="20">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">models</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">models</governor>
          <dependent id="22">Los</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">models</governor>
          <dependent id="23">Angeles</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">trend</governor>
          <dependent id="24">models</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="the past 10 years" type="DURATION" score="0.0">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="past" />
            <token id="11" string="10" />
            <token id="12" string="years" />
          </tokens>
        </entity>
        <entity id="2" string="Los Angeles" type="LOCATION" score="0.0">
          <tokens>
            <token id="22" string="Los" />
            <token id="23" string="Angeles" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>; But some observers say that, for a variety of political and social reasons, the possibility for substantive change on L.A. law&amp;apost;s front lines is scant.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="observers" lemma="observer" stem="observ" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="say" lemma="say" stem="sai" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="variety" lemma="variety" stem="varieti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="political" lemma="political" stem="polit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="social" lemma="social" stem="social" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="reasons" lemma="reason" stem="reason" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="possibility" lemma="possibility" stem="possibl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="substantive" lemma="substantive" stem="substant" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="change" lemma="change" stem="chang" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="L.A." lemma="L.A." stem="l.a." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="24" string="law" lemma="law" stem="law" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="front" lemma="front" stem="front" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="lines" lemma="line" stem="line" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="scant" lemma="scant" stem="scant" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (CC But) (NP (DT some) (NNS observers)) (VP (VBP say) (SBAR (IN that) (S (PRN (, ,) (PP (IN for) (NP (NP (DT a) (NN variety)) (PP (IN of) (NP (JJ political) (CC and) (JJ social) (NNS reasons))))) (, ,)) (NP (NP (DT the) (NN possibility)) (PP (IN for) (NP (NP (JJ substantive) (NN change)) (PP (IN on) (NP (NP (NNP L.A.) (NN law) (POS 's)) (NN front) (NNS lines)))))) (VP (VBZ is) (ADJP (JJ scant)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="political and social reasons" type="NP">
          <tokens>
            <token id="12" string="political" />
            <token id="13" string="and" />
            <token id="14" string="social" />
            <token id="15" string="reasons" />
          </tokens>
        </chunking>
        <chunking id="2" string="is scant" type="VP">
          <tokens>
            <token id="28" string="is" />
            <token id="29" string="scant" />
          </tokens>
        </chunking>
        <chunking id="3" string="a variety of political and social reasons" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="variety" />
            <token id="11" string="of" />
            <token id="12" string="political" />
            <token id="13" string="and" />
            <token id="14" string="social" />
            <token id="15" string="reasons" />
          </tokens>
        </chunking>
        <chunking id="4" string="substantive change on L.A. law 's front lines" type="NP">
          <tokens>
            <token id="20" string="substantive" />
            <token id="21" string="change" />
            <token id="22" string="on" />
            <token id="23" string="L.A." />
            <token id="24" string="law" />
            <token id="25" string="'s" />
            <token id="26" string="front" />
            <token id="27" string="lines" />
          </tokens>
        </chunking>
        <chunking id="5" string="L.A. law 's front lines" type="NP">
          <tokens>
            <token id="23" string="L.A." />
            <token id="24" string="law" />
            <token id="25" string="'s" />
            <token id="26" string="front" />
            <token id="27" string="lines" />
          </tokens>
        </chunking>
        <chunking id="6" string="some observers" type="NP">
          <tokens>
            <token id="3" string="some" />
            <token id="4" string="observers" />
          </tokens>
        </chunking>
        <chunking id="7" string="that , for a variety of political and social reasons , the possibility for substantive change on L.A. law 's front lines is scant" type="SBAR">
          <tokens>
            <token id="6" string="that" />
            <token id="7" string="," />
            <token id="8" string="for" />
            <token id="9" string="a" />
            <token id="10" string="variety" />
            <token id="11" string="of" />
            <token id="12" string="political" />
            <token id="13" string="and" />
            <token id="14" string="social" />
            <token id="15" string="reasons" />
            <token id="16" string="," />
            <token id="17" string="the" />
            <token id="18" string="possibility" />
            <token id="19" string="for" />
            <token id="20" string="substantive" />
            <token id="21" string="change" />
            <token id="22" string="on" />
            <token id="23" string="L.A." />
            <token id="24" string="law" />
            <token id="25" string="'s" />
            <token id="26" string="front" />
            <token id="27" string="lines" />
            <token id="28" string="is" />
            <token id="29" string="scant" />
          </tokens>
        </chunking>
        <chunking id="8" string="substantive change" type="NP">
          <tokens>
            <token id="20" string="substantive" />
            <token id="21" string="change" />
          </tokens>
        </chunking>
        <chunking id="9" string="scant" type="ADJP">
          <tokens>
            <token id="29" string="scant" />
          </tokens>
        </chunking>
        <chunking id="10" string="L.A. law 's" type="NP">
          <tokens>
            <token id="23" string="L.A." />
            <token id="24" string="law" />
            <token id="25" string="'s" />
          </tokens>
        </chunking>
        <chunking id="11" string="a variety" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="variety" />
          </tokens>
        </chunking>
        <chunking id="12" string="the possibility" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="possibility" />
          </tokens>
        </chunking>
        <chunking id="13" string="say that , for a variety of political and social reasons , the possibility for substantive change on L.A. law 's front lines is scant" type="VP">
          <tokens>
            <token id="5" string="say" />
            <token id="6" string="that" />
            <token id="7" string="," />
            <token id="8" string="for" />
            <token id="9" string="a" />
            <token id="10" string="variety" />
            <token id="11" string="of" />
            <token id="12" string="political" />
            <token id="13" string="and" />
            <token id="14" string="social" />
            <token id="15" string="reasons" />
            <token id="16" string="," />
            <token id="17" string="the" />
            <token id="18" string="possibility" />
            <token id="19" string="for" />
            <token id="20" string="substantive" />
            <token id="21" string="change" />
            <token id="22" string="on" />
            <token id="23" string="L.A." />
            <token id="24" string="law" />
            <token id="25" string="'s" />
            <token id="26" string="front" />
            <token id="27" string="lines" />
            <token id="28" string="is" />
            <token id="29" string="scant" />
          </tokens>
        </chunking>
        <chunking id="14" string="the possibility for substantive change on L.A. law 's front lines" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="possibility" />
            <token id="19" string="for" />
            <token id="20" string="substantive" />
            <token id="21" string="change" />
            <token id="22" string="on" />
            <token id="23" string="L.A." />
            <token id="24" string="law" />
            <token id="25" string="'s" />
            <token id="26" string="front" />
            <token id="27" string="lines" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="5">say</governor>
          <dependent id="2">But</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">observers</governor>
          <dependent id="3">some</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">say</governor>
          <dependent id="4">observers</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">say</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="29">scant</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">variety</governor>
          <dependent id="8">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">variety</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="29">scant</governor>
          <dependent id="10">variety</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">reasons</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">reasons</governor>
          <dependent id="12">political</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">political</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">political</governor>
          <dependent id="14">social</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">variety</governor>
          <dependent id="15">reasons</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">possibility</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">scant</governor>
          <dependent id="18">possibility</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">change</governor>
          <dependent id="19">for</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">change</governor>
          <dependent id="20">substantive</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">possibility</governor>
          <dependent id="21">change</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">lines</governor>
          <dependent id="22">on</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">law</governor>
          <dependent id="23">L.A.</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="27">lines</governor>
          <dependent id="24">law</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">law</governor>
          <dependent id="25">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">lines</governor>
          <dependent id="26">front</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">change</governor>
          <dependent id="27">lines</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="29">scant</governor>
          <dependent id="28">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">say</governor>
          <dependent id="29">scant</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="L.A." type="LOCATION" score="0.0">
          <tokens>
            <token id="23" string="L.A." />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>Low level of interest; &amp;quot;There isn&amp;apost;t the level of interest among voting people, people with power, people with influence,&amp;quot; ACLU spokesman Joe Hicks said.</content>
      <tokens>
        <token id="1" string="Low" lemma="low" stem="low" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="level" lemma="level" stem="level" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="interest" lemma="interest" stem="interest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="level" lemma="level" stem="level" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="interest" lemma="interest" stem="interest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="among" lemma="among" stem="among" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="voting" lemma="vote" stem="vote" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="power" lemma="power" stem="power" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="influence" lemma="influence" stem="influenc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="ACLU" lemma="ACLU" stem="aclu" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="28" string="spokesman" lemma="spokesman" stem="spokesman" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="Joe" lemma="Joe" stem="joe" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="30" string="Hicks" lemma="Hicks" stem="hick" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="31" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (FRAG (NP (NP (JJ Low) (NN level)) (PP (IN of) (NP (NN interest))))) (: ;) (S (`` ``) (S (NP (EX There)) (VP (VBZ is) (RB n't) (NP (NP (DT the) (NN level)) (PP (IN of) (NP (NP (NP (NN interest)) (PP (IN among) (NP (VBG voting) (NNS people)))) (, ,) (NP (NP (NNS people)) (PP (IN with) (NP (NN power)))) (, ,) (NP (NP (NNS people)) (PP (IN with) (NP (NN influence))))))))) (, ,) ('' '') (NP (NNP ACLU) (NN spokesman) (NNP Joe) (NNP Hicks)) (VP (VBD said))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="people with power" type="NP">
          <tokens>
            <token id="18" string="people" />
            <token id="19" string="with" />
            <token id="20" string="power" />
          </tokens>
        </chunking>
        <chunking id="2" string="Low level" type="NP">
          <tokens>
            <token id="1" string="Low" />
            <token id="2" string="level" />
          </tokens>
        </chunking>
        <chunking id="3" string="people with influence" type="NP">
          <tokens>
            <token id="22" string="people" />
            <token id="23" string="with" />
            <token id="24" string="influence" />
          </tokens>
        </chunking>
        <chunking id="4" string="people" type="NP">
          <tokens>
            <token id="18" string="people" />
          </tokens>
        </chunking>
        <chunking id="5" string="the level of interest among voting people , people with power , people with influence" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="level" />
            <token id="12" string="of" />
            <token id="13" string="interest" />
            <token id="14" string="among" />
            <token id="15" string="voting" />
            <token id="16" string="people" />
            <token id="17" string="," />
            <token id="18" string="people" />
            <token id="19" string="with" />
            <token id="20" string="power" />
            <token id="21" string="," />
            <token id="22" string="people" />
            <token id="23" string="with" />
            <token id="24" string="influence" />
          </tokens>
        </chunking>
        <chunking id="6" string="influence" type="NP">
          <tokens>
            <token id="24" string="influence" />
          </tokens>
        </chunking>
        <chunking id="7" string="is n't the level of interest among voting people , people with power , people with influence" type="VP">
          <tokens>
            <token id="8" string="is" />
            <token id="9" string="n't" />
            <token id="10" string="the" />
            <token id="11" string="level" />
            <token id="12" string="of" />
            <token id="13" string="interest" />
            <token id="14" string="among" />
            <token id="15" string="voting" />
            <token id="16" string="people" />
            <token id="17" string="," />
            <token id="18" string="people" />
            <token id="19" string="with" />
            <token id="20" string="power" />
            <token id="21" string="," />
            <token id="22" string="people" />
            <token id="23" string="with" />
            <token id="24" string="influence" />
          </tokens>
        </chunking>
        <chunking id="8" string="voting people" type="NP">
          <tokens>
            <token id="15" string="voting" />
            <token id="16" string="people" />
          </tokens>
        </chunking>
        <chunking id="9" string="ACLU spokesman Joe Hicks" type="NP">
          <tokens>
            <token id="27" string="ACLU" />
            <token id="28" string="spokesman" />
            <token id="29" string="Joe" />
            <token id="30" string="Hicks" />
          </tokens>
        </chunking>
        <chunking id="10" string="There" type="NP">
          <tokens>
            <token id="7" string="There" />
          </tokens>
        </chunking>
        <chunking id="11" string="interest among voting people , people with power , people with influence" type="NP">
          <tokens>
            <token id="13" string="interest" />
            <token id="14" string="among" />
            <token id="15" string="voting" />
            <token id="16" string="people" />
            <token id="17" string="," />
            <token id="18" string="people" />
            <token id="19" string="with" />
            <token id="20" string="power" />
            <token id="21" string="," />
            <token id="22" string="people" />
            <token id="23" string="with" />
            <token id="24" string="influence" />
          </tokens>
        </chunking>
        <chunking id="12" string="interest" type="NP">
          <tokens>
            <token id="4" string="interest" />
          </tokens>
        </chunking>
        <chunking id="13" string="Low level of interest" type="NP">
          <tokens>
            <token id="1" string="Low" />
            <token id="2" string="level" />
            <token id="3" string="of" />
            <token id="4" string="interest" />
          </tokens>
        </chunking>
        <chunking id="14" string="the level" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="level" />
          </tokens>
        </chunking>
        <chunking id="15" string="power" type="NP">
          <tokens>
            <token id="20" string="power" />
          </tokens>
        </chunking>
        <chunking id="16" string="interest among voting people" type="NP">
          <tokens>
            <token id="13" string="interest" />
            <token id="14" string="among" />
            <token id="15" string="voting" />
            <token id="16" string="people" />
          </tokens>
        </chunking>
        <chunking id="17" string="said" type="VP">
          <tokens>
            <token id="31" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">level</governor>
          <dependent id="1">Low</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="31">said</governor>
          <dependent id="2">level</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">interest</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">level</governor>
          <dependent id="4">interest</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="8">is</governor>
          <dependent id="7">There</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="31">said</governor>
          <dependent id="8">is</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="8">is</governor>
          <dependent id="9">n't</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">level</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">is</governor>
          <dependent id="11">level</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">interest</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">level</governor>
          <dependent id="13">interest</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">people</governor>
          <dependent id="14">among</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">people</governor>
          <dependent id="15">voting</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">interest</governor>
          <dependent id="16">people</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="13">interest</governor>
          <dependent id="18">people</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">power</governor>
          <dependent id="19">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">people</governor>
          <dependent id="20">power</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="13">interest</governor>
          <dependent id="22">people</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">influence</governor>
          <dependent id="23">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">people</governor>
          <dependent id="24">influence</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">Hicks</governor>
          <dependent id="27">ACLU</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">Hicks</governor>
          <dependent id="28">spokesman</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">Hicks</governor>
          <dependent id="29">Joe</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">said</governor>
          <dependent id="30">Hicks</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="31">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="ACLU" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="27" string="ACLU" />
          </tokens>
        </entity>
        <entity id="2" string="Joe Hicks" type="PERSON" score="0.0">
          <tokens>
            <token id="29" string="Joe" />
            <token id="30" string="Hicks" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>&amp;quot;They don&amp;apost;t really care much about police reform.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="really" lemma="really" stem="realli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="care" lemma="care" stem="care" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="much" lemma="much" stem="much" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="reform" lemma="reform" stem="reform" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP They)) (VP (VBP do) (RB n't) (ADVP (RB really)) (VP (VB care) (ADJP (JJ much)) (PP (IN about) (NP (NN police) (NN reform))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="2" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="do n't really care much about police reform" type="VP">
          <tokens>
            <token id="3" string="do" />
            <token id="4" string="n't" />
            <token id="5" string="really" />
            <token id="6" string="care" />
            <token id="7" string="much" />
            <token id="8" string="about" />
            <token id="9" string="police" />
            <token id="10" string="reform" />
          </tokens>
        </chunking>
        <chunking id="3" string="care much about police reform" type="VP">
          <tokens>
            <token id="6" string="care" />
            <token id="7" string="much" />
            <token id="8" string="about" />
            <token id="9" string="police" />
            <token id="10" string="reform" />
          </tokens>
        </chunking>
        <chunking id="4" string="police reform" type="NP">
          <tokens>
            <token id="9" string="police" />
            <token id="10" string="reform" />
          </tokens>
        </chunking>
        <chunking id="5" string="much" type="ADJP">
          <tokens>
            <token id="7" string="much" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">care</governor>
          <dependent id="2">They</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">care</governor>
          <dependent id="3">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">care</governor>
          <dependent id="4">n't</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">care</governor>
          <dependent id="5">really</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">care</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">care</governor>
          <dependent id="7">much</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">reform</governor>
          <dependent id="8">about</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">reform</governor>
          <dependent id="9">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">care</governor>
          <dependent id="10">reform</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>They just want to make sure their communities are safe.&amp;quot;</content>
      <tokens>
        <token id="1" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="want" lemma="want" stem="want" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="make" lemma="make" stem="make" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="sure" lemma="sure" stem="sure" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="communities" lemma="community" stem="commun" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="safe" lemma="safe" stem="safe" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP They)) (ADVP (RB just)) (VP (VBP want) (S (VP (TO to) (VP (VB make) (ADJP (JJ sure) (SBAR (S (NP (PRP$ their) (NNS communities)) (VP (VBP are) (ADJP (JJ safe)))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="1" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="to make sure their communities are safe" type="VP">
          <tokens>
            <token id="4" string="to" />
            <token id="5" string="make" />
            <token id="6" string="sure" />
            <token id="7" string="their" />
            <token id="8" string="communities" />
            <token id="9" string="are" />
            <token id="10" string="safe" />
          </tokens>
        </chunking>
        <chunking id="3" string="their communities are safe" type="SBAR">
          <tokens>
            <token id="7" string="their" />
            <token id="8" string="communities" />
            <token id="9" string="are" />
            <token id="10" string="safe" />
          </tokens>
        </chunking>
        <chunking id="4" string="want to make sure their communities are safe" type="VP">
          <tokens>
            <token id="3" string="want" />
            <token id="4" string="to" />
            <token id="5" string="make" />
            <token id="6" string="sure" />
            <token id="7" string="their" />
            <token id="8" string="communities" />
            <token id="9" string="are" />
            <token id="10" string="safe" />
          </tokens>
        </chunking>
        <chunking id="5" string="are safe" type="VP">
          <tokens>
            <token id="9" string="are" />
            <token id="10" string="safe" />
          </tokens>
        </chunking>
        <chunking id="6" string="sure their communities are safe" type="ADJP">
          <tokens>
            <token id="6" string="sure" />
            <token id="7" string="their" />
            <token id="8" string="communities" />
            <token id="9" string="are" />
            <token id="10" string="safe" />
          </tokens>
        </chunking>
        <chunking id="7" string="make sure their communities are safe" type="VP">
          <tokens>
            <token id="5" string="make" />
            <token id="6" string="sure" />
            <token id="7" string="their" />
            <token id="8" string="communities" />
            <token id="9" string="are" />
            <token id="10" string="safe" />
          </tokens>
        </chunking>
        <chunking id="8" string="their communities" type="NP">
          <tokens>
            <token id="7" string="their" />
            <token id="8" string="communities" />
          </tokens>
        </chunking>
        <chunking id="9" string="safe" type="ADJP">
          <tokens>
            <token id="10" string="safe" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">want</governor>
          <dependent id="1">They</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">want</governor>
          <dependent id="2">just</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">want</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">make</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">want</governor>
          <dependent id="5">make</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">make</governor>
          <dependent id="6">sure</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">communities</governor>
          <dependent id="7">their</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">safe</governor>
          <dependent id="8">communities</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="10">safe</governor>
          <dependent id="9">are</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">sure</governor>
          <dependent id="10">safe</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>; The poor minority communities that do care suffer &amp;quot;a lack of organization that really can take advantage of the anger over the police and keep some momentum going that could potentially force reforms,&amp;quot; Hicks said.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="poor" lemma="poor" stem="poor" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="minority" lemma="minority" stem="minor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="communities" lemma="community" stem="commun" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="care" lemma="care" stem="care" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="suffer" lemma="suffer" stem="suffer" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="lack" lemma="lack" stem="lack" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="organization" lemma="organization" stem="organ" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="really" lemma="really" stem="realli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="take" lemma="take" stem="take" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="advantage" lemma="advantage" stem="advantag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="anger" lemma="anger" stem="anger" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="26" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="keep" lemma="keep" stem="keep" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="29" string="momentum" lemma="momentum" stem="momentum" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="30" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="potentially" lemma="potentially" stem="potenti" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="force" lemma="force" stem="forc" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="reforms" lemma="reform" stem="reform" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="Hicks" lemma="Hicks" stem="hick" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="39" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (NP (NP (NP (DT The) (JJ poor) (NN minority) (NNS communities)) (SBAR (WHNP (WDT that)) (S (VP (VBP do) (S (VP (VB care) (VP (VB suffer) (`` ``) (NP (NP (DT a) (NN lack)) (PP (IN of) (NP (NN organization))) (SBAR (WHNP (WDT that)) (S (ADVP (RB really)) (VP (MD can) (VP (VP (VB take) (NP (NP (NN advantage)) (PP (IN of) (NP (NP (DT the) (NN anger)) (PP (IN over) (NP (DT the) (NN police))))))) (CC and) (VP (VB keep) (NP (DT some) (NN momentum)))))))) (S (VP (VBG going) (SBAR (S (NP (DT that)) (VP (MD could) (ADVP (RB potentially)) (VP (VB force) (NP (NNS reforms))))))))))))))) (, ,) ('' '') (NP (NNP Hicks))) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the anger" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="anger" />
          </tokens>
        </chunking>
        <chunking id="2" string="do care suffer `` a lack of organization that really can take advantage of the anger over the police and keep some momentum going that could potentially force reforms" type="VP">
          <tokens>
            <token id="7" string="do" />
            <token id="8" string="care" />
            <token id="9" string="suffer" />
            <token id="10" string="&quot;" />
            <token id="11" string="a" />
            <token id="12" string="lack" />
            <token id="13" string="of" />
            <token id="14" string="organization" />
            <token id="15" string="that" />
            <token id="16" string="really" />
            <token id="17" string="can" />
            <token id="18" string="take" />
            <token id="19" string="advantage" />
            <token id="20" string="of" />
            <token id="21" string="the" />
            <token id="22" string="anger" />
            <token id="23" string="over" />
            <token id="24" string="the" />
            <token id="25" string="police" />
            <token id="26" string="and" />
            <token id="27" string="keep" />
            <token id="28" string="some" />
            <token id="29" string="momentum" />
            <token id="30" string="going" />
            <token id="31" string="that" />
            <token id="32" string="could" />
            <token id="33" string="potentially" />
            <token id="34" string="force" />
            <token id="35" string="reforms" />
          </tokens>
        </chunking>
        <chunking id="3" string="advantage of the anger over the police" type="NP">
          <tokens>
            <token id="19" string="advantage" />
            <token id="20" string="of" />
            <token id="21" string="the" />
            <token id="22" string="anger" />
            <token id="23" string="over" />
            <token id="24" string="the" />
            <token id="25" string="police" />
          </tokens>
        </chunking>
        <chunking id="4" string="advantage" type="NP">
          <tokens>
            <token id="19" string="advantage" />
          </tokens>
        </chunking>
        <chunking id="5" string="reforms" type="NP">
          <tokens>
            <token id="35" string="reforms" />
          </tokens>
        </chunking>
        <chunking id="6" string="keep some momentum" type="VP">
          <tokens>
            <token id="27" string="keep" />
            <token id="28" string="some" />
            <token id="29" string="momentum" />
          </tokens>
        </chunking>
        <chunking id="7" string="Hicks" type="NP">
          <tokens>
            <token id="38" string="Hicks" />
          </tokens>
        </chunking>
        <chunking id="8" string="take advantage of the anger over the police and keep some momentum" type="VP">
          <tokens>
            <token id="18" string="take" />
            <token id="19" string="advantage" />
            <token id="20" string="of" />
            <token id="21" string="the" />
            <token id="22" string="anger" />
            <token id="23" string="over" />
            <token id="24" string="the" />
            <token id="25" string="police" />
            <token id="26" string="and" />
            <token id="27" string="keep" />
            <token id="28" string="some" />
            <token id="29" string="momentum" />
          </tokens>
        </chunking>
        <chunking id="9" string="organization" type="NP">
          <tokens>
            <token id="14" string="organization" />
          </tokens>
        </chunking>
        <chunking id="10" string="force reforms" type="VP">
          <tokens>
            <token id="34" string="force" />
            <token id="35" string="reforms" />
          </tokens>
        </chunking>
        <chunking id="11" string="a lack of organization that really can take advantage of the anger over the police and keep some momentum" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="lack" />
            <token id="13" string="of" />
            <token id="14" string="organization" />
            <token id="15" string="that" />
            <token id="16" string="really" />
            <token id="17" string="can" />
            <token id="18" string="take" />
            <token id="19" string="advantage" />
            <token id="20" string="of" />
            <token id="21" string="the" />
            <token id="22" string="anger" />
            <token id="23" string="over" />
            <token id="24" string="the" />
            <token id="25" string="police" />
            <token id="26" string="and" />
            <token id="27" string="keep" />
            <token id="28" string="some" />
            <token id="29" string="momentum" />
          </tokens>
        </chunking>
        <chunking id="12" string="can take advantage of the anger over the police and keep some momentum" type="VP">
          <tokens>
            <token id="17" string="can" />
            <token id="18" string="take" />
            <token id="19" string="advantage" />
            <token id="20" string="of" />
            <token id="21" string="the" />
            <token id="22" string="anger" />
            <token id="23" string="over" />
            <token id="24" string="the" />
            <token id="25" string="police" />
            <token id="26" string="and" />
            <token id="27" string="keep" />
            <token id="28" string="some" />
            <token id="29" string="momentum" />
          </tokens>
        </chunking>
        <chunking id="13" string="The poor minority communities that do care suffer `` a lack of organization that really can take advantage of the anger over the police and keep some momentum going that could potentially force reforms" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="poor" />
            <token id="4" string="minority" />
            <token id="5" string="communities" />
            <token id="6" string="that" />
            <token id="7" string="do" />
            <token id="8" string="care" />
            <token id="9" string="suffer" />
            <token id="10" string="&quot;" />
            <token id="11" string="a" />
            <token id="12" string="lack" />
            <token id="13" string="of" />
            <token id="14" string="organization" />
            <token id="15" string="that" />
            <token id="16" string="really" />
            <token id="17" string="can" />
            <token id="18" string="take" />
            <token id="19" string="advantage" />
            <token id="20" string="of" />
            <token id="21" string="the" />
            <token id="22" string="anger" />
            <token id="23" string="over" />
            <token id="24" string="the" />
            <token id="25" string="police" />
            <token id="26" string="and" />
            <token id="27" string="keep" />
            <token id="28" string="some" />
            <token id="29" string="momentum" />
            <token id="30" string="going" />
            <token id="31" string="that" />
            <token id="32" string="could" />
            <token id="33" string="potentially" />
            <token id="34" string="force" />
            <token id="35" string="reforms" />
          </tokens>
        </chunking>
        <chunking id="14" string="that could potentially force reforms" type="SBAR">
          <tokens>
            <token id="31" string="that" />
            <token id="32" string="could" />
            <token id="33" string="potentially" />
            <token id="34" string="force" />
            <token id="35" string="reforms" />
          </tokens>
        </chunking>
        <chunking id="15" string="that really can take advantage of the anger over the police and keep some momentum" type="SBAR">
          <tokens>
            <token id="15" string="that" />
            <token id="16" string="really" />
            <token id="17" string="can" />
            <token id="18" string="take" />
            <token id="19" string="advantage" />
            <token id="20" string="of" />
            <token id="21" string="the" />
            <token id="22" string="anger" />
            <token id="23" string="over" />
            <token id="24" string="the" />
            <token id="25" string="police" />
            <token id="26" string="and" />
            <token id="27" string="keep" />
            <token id="28" string="some" />
            <token id="29" string="momentum" />
          </tokens>
        </chunking>
        <chunking id="16" string="a lack" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="lack" />
          </tokens>
        </chunking>
        <chunking id="17" string="some momentum" type="NP">
          <tokens>
            <token id="28" string="some" />
            <token id="29" string="momentum" />
          </tokens>
        </chunking>
        <chunking id="18" string="going that could potentially force reforms" type="VP">
          <tokens>
            <token id="30" string="going" />
            <token id="31" string="that" />
            <token id="32" string="could" />
            <token id="33" string="potentially" />
            <token id="34" string="force" />
            <token id="35" string="reforms" />
          </tokens>
        </chunking>
        <chunking id="19" string="The poor minority communities that do care suffer `` a lack of organization that really can take advantage of the anger over the police and keep some momentum going that could potentially force reforms , '' Hicks" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="poor" />
            <token id="4" string="minority" />
            <token id="5" string="communities" />
            <token id="6" string="that" />
            <token id="7" string="do" />
            <token id="8" string="care" />
            <token id="9" string="suffer" />
            <token id="10" string="&quot;" />
            <token id="11" string="a" />
            <token id="12" string="lack" />
            <token id="13" string="of" />
            <token id="14" string="organization" />
            <token id="15" string="that" />
            <token id="16" string="really" />
            <token id="17" string="can" />
            <token id="18" string="take" />
            <token id="19" string="advantage" />
            <token id="20" string="of" />
            <token id="21" string="the" />
            <token id="22" string="anger" />
            <token id="23" string="over" />
            <token id="24" string="the" />
            <token id="25" string="police" />
            <token id="26" string="and" />
            <token id="27" string="keep" />
            <token id="28" string="some" />
            <token id="29" string="momentum" />
            <token id="30" string="going" />
            <token id="31" string="that" />
            <token id="32" string="could" />
            <token id="33" string="potentially" />
            <token id="34" string="force" />
            <token id="35" string="reforms" />
            <token id="36" string="," />
            <token id="37" string="&quot;" />
            <token id="38" string="Hicks" />
          </tokens>
        </chunking>
        <chunking id="20" string="take advantage of the anger over the police" type="VP">
          <tokens>
            <token id="18" string="take" />
            <token id="19" string="advantage" />
            <token id="20" string="of" />
            <token id="21" string="the" />
            <token id="22" string="anger" />
            <token id="23" string="over" />
            <token id="24" string="the" />
            <token id="25" string="police" />
          </tokens>
        </chunking>
        <chunking id="21" string="the police" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="police" />
          </tokens>
        </chunking>
        <chunking id="22" string="that do care suffer `` a lack of organization that really can take advantage of the anger over the police and keep some momentum going that could potentially force reforms" type="SBAR">
          <tokens>
            <token id="6" string="that" />
            <token id="7" string="do" />
            <token id="8" string="care" />
            <token id="9" string="suffer" />
            <token id="10" string="&quot;" />
            <token id="11" string="a" />
            <token id="12" string="lack" />
            <token id="13" string="of" />
            <token id="14" string="organization" />
            <token id="15" string="that" />
            <token id="16" string="really" />
            <token id="17" string="can" />
            <token id="18" string="take" />
            <token id="19" string="advantage" />
            <token id="20" string="of" />
            <token id="21" string="the" />
            <token id="22" string="anger" />
            <token id="23" string="over" />
            <token id="24" string="the" />
            <token id="25" string="police" />
            <token id="26" string="and" />
            <token id="27" string="keep" />
            <token id="28" string="some" />
            <token id="29" string="momentum" />
            <token id="30" string="going" />
            <token id="31" string="that" />
            <token id="32" string="could" />
            <token id="33" string="potentially" />
            <token id="34" string="force" />
            <token id="35" string="reforms" />
          </tokens>
        </chunking>
        <chunking id="23" string="could potentially force reforms" type="VP">
          <tokens>
            <token id="32" string="could" />
            <token id="33" string="potentially" />
            <token id="34" string="force" />
            <token id="35" string="reforms" />
          </tokens>
        </chunking>
        <chunking id="24" string="care suffer `` a lack of organization that really can take advantage of the anger over the police and keep some momentum going that could potentially force reforms" type="VP">
          <tokens>
            <token id="8" string="care" />
            <token id="9" string="suffer" />
            <token id="10" string="&quot;" />
            <token id="11" string="a" />
            <token id="12" string="lack" />
            <token id="13" string="of" />
            <token id="14" string="organization" />
            <token id="15" string="that" />
            <token id="16" string="really" />
            <token id="17" string="can" />
            <token id="18" string="take" />
            <token id="19" string="advantage" />
            <token id="20" string="of" />
            <token id="21" string="the" />
            <token id="22" string="anger" />
            <token id="23" string="over" />
            <token id="24" string="the" />
            <token id="25" string="police" />
            <token id="26" string="and" />
            <token id="27" string="keep" />
            <token id="28" string="some" />
            <token id="29" string="momentum" />
            <token id="30" string="going" />
            <token id="31" string="that" />
            <token id="32" string="could" />
            <token id="33" string="potentially" />
            <token id="34" string="force" />
            <token id="35" string="reforms" />
          </tokens>
        </chunking>
        <chunking id="25" string="suffer `` a lack of organization that really can take advantage of the anger over the police and keep some momentum going that could potentially force reforms" type="VP">
          <tokens>
            <token id="9" string="suffer" />
            <token id="10" string="&quot;" />
            <token id="11" string="a" />
            <token id="12" string="lack" />
            <token id="13" string="of" />
            <token id="14" string="organization" />
            <token id="15" string="that" />
            <token id="16" string="really" />
            <token id="17" string="can" />
            <token id="18" string="take" />
            <token id="19" string="advantage" />
            <token id="20" string="of" />
            <token id="21" string="the" />
            <token id="22" string="anger" />
            <token id="23" string="over" />
            <token id="24" string="the" />
            <token id="25" string="police" />
            <token id="26" string="and" />
            <token id="27" string="keep" />
            <token id="28" string="some" />
            <token id="29" string="momentum" />
            <token id="30" string="going" />
            <token id="31" string="that" />
            <token id="32" string="could" />
            <token id="33" string="potentially" />
            <token id="34" string="force" />
            <token id="35" string="reforms" />
          </tokens>
        </chunking>
        <chunking id="26" string="that" type="NP">
          <tokens>
            <token id="31" string="that" />
          </tokens>
        </chunking>
        <chunking id="27" string="the anger over the police" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="anger" />
            <token id="23" string="over" />
            <token id="24" string="the" />
            <token id="25" string="police" />
          </tokens>
        </chunking>
        <chunking id="28" string="The poor minority communities" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="poor" />
            <token id="4" string="minority" />
            <token id="5" string="communities" />
          </tokens>
        </chunking>
        <chunking id="29" string="said" type="VP">
          <tokens>
            <token id="39" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="5">communities</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">communities</governor>
          <dependent id="3">poor</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">communities</governor>
          <dependent id="4">minority</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="39">said</governor>
          <dependent id="5">communities</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">do</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="5">communities</governor>
          <dependent id="7">do</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">do</governor>
          <dependent id="8">care</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">care</governor>
          <dependent id="9">suffer</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">lack</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">suffer</governor>
          <dependent id="12">lack</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">organization</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">lack</governor>
          <dependent id="14">organization</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">take</governor>
          <dependent id="15">that</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">take</governor>
          <dependent id="16">really</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">take</governor>
          <dependent id="17">can</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="12">lack</governor>
          <dependent id="18">take</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">take</governor>
          <dependent id="19">advantage</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">anger</governor>
          <dependent id="20">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">anger</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">advantage</governor>
          <dependent id="22">anger</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">police</governor>
          <dependent id="23">over</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">police</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">anger</governor>
          <dependent id="25">police</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="18">take</governor>
          <dependent id="26">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">take</governor>
          <dependent id="27">keep</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">momentum</governor>
          <dependent id="28">some</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="27">keep</governor>
          <dependent id="29">momentum</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">suffer</governor>
          <dependent id="30">going</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="34">force</governor>
          <dependent id="31">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="34">force</governor>
          <dependent id="32">could</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="34">force</governor>
          <dependent id="33">potentially</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="30">going</governor>
          <dependent id="34">force</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="34">force</governor>
          <dependent id="35">reforms</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="5">communities</governor>
          <dependent id="38">Hicks</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="39">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Hicks" type="PERSON" score="0.0">
          <tokens>
            <token id="38" string="Hicks" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>The King beating led to an investigation of the police department by an independent commission that found racism, brutality, inadequate discipline, mismanagement and a &amp;quot;siege mentality&amp;quot; pitting officers against the community.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="King" lemma="King" stem="king" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="false" is_refers="true" />
        <token id="3" string="beating" lemma="beating" stem="beat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="led" lemma="lead" stem="led" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="investigation" lemma="investigation" stem="investig" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="department" lemma="department" stem="depart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="independent" lemma="independent" stem="independ" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="true" is_refers="false" />
        <token id="15" string="commission" lemma="commission" stem="commiss" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="found" lemma="find" stem="found" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="racism" lemma="racism" stem="racism" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="brutality" lemma="brutality" stem="brutal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="inadequate" lemma="inadequate" stem="inadequ" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="discipline" lemma="discipline" stem="disciplin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="mismanagement" lemma="mismanagement" stem="mismanag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="siege" lemma="siege" stem="sieg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="mentality" lemma="mentality" stem="mental" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="pitting" lemma="pit" stem="pit" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="34" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="36" string="community" lemma="community" stem="commun" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="37" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNP King) (NN beating)) (VP (VBD led) (PP (TO to) (NP (NP (DT an) (NN investigation)) (PP (IN of) (NP (DT the) (NN police) (NN department))))) (PP (IN by) (NP (NP (DT an) (JJ independent) (NN commission)) (SBAR (WHNP (WDT that)) (S (VP (VBD found) (NP (NP (NN racism)) (, ,) (NP (NN brutality)) (, ,) (NP (JJ inadequate) (NN discipline)) (, ,) (NP (NN mismanagement)) (CC and) (NP (DT a) (`` ``) (NN siege) (NN mentality) ('' ''))) (S (VP (VBG pitting) (NP (NNS officers)) (PP (IN against) (NP (DT the) (NN community))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="mismanagement" type="NP">
          <tokens>
            <token id="25" string="mismanagement" />
          </tokens>
        </chunking>
        <chunking id="2" string="a `` siege mentality ''" type="NP">
          <tokens>
            <token id="27" string="a" />
            <token id="28" string="&quot;" />
            <token id="29" string="siege" />
            <token id="30" string="mentality" />
            <token id="31" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="3" string="racism" type="NP">
          <tokens>
            <token id="18" string="racism" />
          </tokens>
        </chunking>
        <chunking id="4" string="the police department" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="police" />
            <token id="11" string="department" />
          </tokens>
        </chunking>
        <chunking id="5" string="racism , brutality , inadequate discipline , mismanagement and a `` siege mentality ''" type="NP">
          <tokens>
            <token id="18" string="racism" />
            <token id="19" string="," />
            <token id="20" string="brutality" />
            <token id="21" string="," />
            <token id="22" string="inadequate" />
            <token id="23" string="discipline" />
            <token id="24" string="," />
            <token id="25" string="mismanagement" />
            <token id="26" string="and" />
            <token id="27" string="a" />
            <token id="28" string="&quot;" />
            <token id="29" string="siege" />
            <token id="30" string="mentality" />
            <token id="31" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="6" string="an investigation of the police department" type="NP">
          <tokens>
            <token id="6" string="an" />
            <token id="7" string="investigation" />
            <token id="8" string="of" />
            <token id="9" string="the" />
            <token id="10" string="police" />
            <token id="11" string="department" />
          </tokens>
        </chunking>
        <chunking id="7" string="found racism , brutality , inadequate discipline , mismanagement and a `` siege mentality '' pitting officers against the community" type="VP">
          <tokens>
            <token id="17" string="found" />
            <token id="18" string="racism" />
            <token id="19" string="," />
            <token id="20" string="brutality" />
            <token id="21" string="," />
            <token id="22" string="inadequate" />
            <token id="23" string="discipline" />
            <token id="24" string="," />
            <token id="25" string="mismanagement" />
            <token id="26" string="and" />
            <token id="27" string="a" />
            <token id="28" string="&quot;" />
            <token id="29" string="siege" />
            <token id="30" string="mentality" />
            <token id="31" string="&quot;" />
            <token id="32" string="pitting" />
            <token id="33" string="officers" />
            <token id="34" string="against" />
            <token id="35" string="the" />
            <token id="36" string="community" />
          </tokens>
        </chunking>
        <chunking id="8" string="the community" type="NP">
          <tokens>
            <token id="35" string="the" />
            <token id="36" string="community" />
          </tokens>
        </chunking>
        <chunking id="9" string="an investigation" type="NP">
          <tokens>
            <token id="6" string="an" />
            <token id="7" string="investigation" />
          </tokens>
        </chunking>
        <chunking id="10" string="inadequate discipline" type="NP">
          <tokens>
            <token id="22" string="inadequate" />
            <token id="23" string="discipline" />
          </tokens>
        </chunking>
        <chunking id="11" string="The King beating" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="King" />
            <token id="3" string="beating" />
          </tokens>
        </chunking>
        <chunking id="12" string="an independent commission that found racism , brutality , inadequate discipline , mismanagement and a `` siege mentality '' pitting officers against the community" type="NP">
          <tokens>
            <token id="13" string="an" />
            <token id="14" string="independent" />
            <token id="15" string="commission" />
            <token id="16" string="that" />
            <token id="17" string="found" />
            <token id="18" string="racism" />
            <token id="19" string="," />
            <token id="20" string="brutality" />
            <token id="21" string="," />
            <token id="22" string="inadequate" />
            <token id="23" string="discipline" />
            <token id="24" string="," />
            <token id="25" string="mismanagement" />
            <token id="26" string="and" />
            <token id="27" string="a" />
            <token id="28" string="&quot;" />
            <token id="29" string="siege" />
            <token id="30" string="mentality" />
            <token id="31" string="&quot;" />
            <token id="32" string="pitting" />
            <token id="33" string="officers" />
            <token id="34" string="against" />
            <token id="35" string="the" />
            <token id="36" string="community" />
          </tokens>
        </chunking>
        <chunking id="13" string="led to an investigation of the police department by an independent commission that found racism , brutality , inadequate discipline , mismanagement and a `` siege mentality '' pitting officers against the community" type="VP">
          <tokens>
            <token id="4" string="led" />
            <token id="5" string="to" />
            <token id="6" string="an" />
            <token id="7" string="investigation" />
            <token id="8" string="of" />
            <token id="9" string="the" />
            <token id="10" string="police" />
            <token id="11" string="department" />
            <token id="12" string="by" />
            <token id="13" string="an" />
            <token id="14" string="independent" />
            <token id="15" string="commission" />
            <token id="16" string="that" />
            <token id="17" string="found" />
            <token id="18" string="racism" />
            <token id="19" string="," />
            <token id="20" string="brutality" />
            <token id="21" string="," />
            <token id="22" string="inadequate" />
            <token id="23" string="discipline" />
            <token id="24" string="," />
            <token id="25" string="mismanagement" />
            <token id="26" string="and" />
            <token id="27" string="a" />
            <token id="28" string="&quot;" />
            <token id="29" string="siege" />
            <token id="30" string="mentality" />
            <token id="31" string="&quot;" />
            <token id="32" string="pitting" />
            <token id="33" string="officers" />
            <token id="34" string="against" />
            <token id="35" string="the" />
            <token id="36" string="community" />
          </tokens>
        </chunking>
        <chunking id="14" string="that found racism , brutality , inadequate discipline , mismanagement and a `` siege mentality '' pitting officers against the community" type="SBAR">
          <tokens>
            <token id="16" string="that" />
            <token id="17" string="found" />
            <token id="18" string="racism" />
            <token id="19" string="," />
            <token id="20" string="brutality" />
            <token id="21" string="," />
            <token id="22" string="inadequate" />
            <token id="23" string="discipline" />
            <token id="24" string="," />
            <token id="25" string="mismanagement" />
            <token id="26" string="and" />
            <token id="27" string="a" />
            <token id="28" string="&quot;" />
            <token id="29" string="siege" />
            <token id="30" string="mentality" />
            <token id="31" string="&quot;" />
            <token id="32" string="pitting" />
            <token id="33" string="officers" />
            <token id="34" string="against" />
            <token id="35" string="the" />
            <token id="36" string="community" />
          </tokens>
        </chunking>
        <chunking id="15" string="pitting officers against the community" type="VP">
          <tokens>
            <token id="32" string="pitting" />
            <token id="33" string="officers" />
            <token id="34" string="against" />
            <token id="35" string="the" />
            <token id="36" string="community" />
          </tokens>
        </chunking>
        <chunking id="16" string="an independent commission" type="NP">
          <tokens>
            <token id="13" string="an" />
            <token id="14" string="independent" />
            <token id="15" string="commission" />
          </tokens>
        </chunking>
        <chunking id="17" string="brutality" type="NP">
          <tokens>
            <token id="20" string="brutality" />
          </tokens>
        </chunking>
        <chunking id="18" string="officers" type="NP">
          <tokens>
            <token id="33" string="officers" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">beating</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">beating</governor>
          <dependent id="2">King</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">led</governor>
          <dependent id="3">beating</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">led</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">investigation</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">investigation</governor>
          <dependent id="6">an</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">led</governor>
          <dependent id="7">investigation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">department</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">department</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">department</governor>
          <dependent id="10">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">investigation</governor>
          <dependent id="11">department</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">commission</governor>
          <dependent id="12">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">commission</governor>
          <dependent id="13">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">commission</governor>
          <dependent id="14">independent</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">led</governor>
          <dependent id="15">commission</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">found</governor>
          <dependent id="16">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="15">commission</governor>
          <dependent id="17">found</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">found</governor>
          <dependent id="18">racism</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">racism</governor>
          <dependent id="20">brutality</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">discipline</governor>
          <dependent id="22">inadequate</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">racism</governor>
          <dependent id="23">discipline</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">racism</governor>
          <dependent id="25">mismanagement</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="18">racism</governor>
          <dependent id="26">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">mentality</governor>
          <dependent id="27">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">mentality</governor>
          <dependent id="29">siege</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">racism</governor>
          <dependent id="30">mentality</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="17">found</governor>
          <dependent id="32">pitting</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="32">pitting</governor>
          <dependent id="33">officers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">community</governor>
          <dependent id="34">against</dependent>
        </dependency>
        <dependency type="det">
          <governor id="36">community</governor>
          <dependent id="35">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">pitting</governor>
          <dependent id="36">community</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="King" type="TITLE" score="0.0">
          <tokens>
            <token id="2" string="King" />
          </tokens>
        </entity>
        <entity id="2" string="independent" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="14" string="independent" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>The Christopher Commission&amp;apost;s scathing report made more than 100 recommendations, many of them aimed at moving away from the department&amp;apost;s &amp;quot;hard-nosed&amp;quot; approach and improving relations with residents.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="Christopher" lemma="Christopher" stem="christoph" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="3" string="Commission" lemma="Commission" stem="commiss" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="4" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="scathing" lemma="scathing" stem="scath" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="report" lemma="report" stem="report" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="made" lemma="make" stem="made" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="100" lemma="100" stem="100" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="11" string="recommendations" lemma="recommendation" stem="recommend" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="aimed" lemma="aim" stem="aim" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="moving" lemma="move" stem="move" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="away" lemma="away" stem="awai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="department" lemma="department" stem="depart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="23" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="hard-nosed" lemma="hard-nosed" stem="hard-nos" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="approach" lemma="approach" stem="approach" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="improving" lemma="improve" stem="improv" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="relations" lemma="relation" stem="relat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="residents" lemma="resident" stem="resid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NNP Christopher) (NNP Commission) (POS 's)) (JJ scathing) (NN report)) (VP (VBD made) (NP (NP (QP (JJR more) (IN than) (CD 100)) (NNS recommendations)) (, ,) (NP (NP (JJ many)) (PP (IN of) (NP (PRP them))) (VP (VBN aimed) (PP (IN at) (S (VP (VP (VBG moving) (ADVP (RB away)) (PP (IN from) (NP (NP (DT the) (NN department) (POS 's)) (`` ``) (JJ hard-nosed) ('' '') (NN approach)))) (CC and) (VP (VBG improving) (NP (NNS relations)) (PP (IN with) (NP (NNS residents))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="aimed at moving away from the department 's `` hard-nosed '' approach and improving relations with residents" type="VP">
          <tokens>
            <token id="16" string="aimed" />
            <token id="17" string="at" />
            <token id="18" string="moving" />
            <token id="19" string="away" />
            <token id="20" string="from" />
            <token id="21" string="the" />
            <token id="22" string="department" />
            <token id="23" string="'s" />
            <token id="24" string="&quot;" />
            <token id="25" string="hard-nosed" />
            <token id="26" string="&quot;" />
            <token id="27" string="approach" />
            <token id="28" string="and" />
            <token id="29" string="improving" />
            <token id="30" string="relations" />
            <token id="31" string="with" />
            <token id="32" string="residents" />
          </tokens>
        </chunking>
        <chunking id="2" string="moving away from the department 's `` hard-nosed '' approach" type="VP">
          <tokens>
            <token id="18" string="moving" />
            <token id="19" string="away" />
            <token id="20" string="from" />
            <token id="21" string="the" />
            <token id="22" string="department" />
            <token id="23" string="'s" />
            <token id="24" string="&quot;" />
            <token id="25" string="hard-nosed" />
            <token id="26" string="&quot;" />
            <token id="27" string="approach" />
          </tokens>
        </chunking>
        <chunking id="3" string="moving away from the department 's `` hard-nosed '' approach and improving relations with residents" type="VP">
          <tokens>
            <token id="18" string="moving" />
            <token id="19" string="away" />
            <token id="20" string="from" />
            <token id="21" string="the" />
            <token id="22" string="department" />
            <token id="23" string="'s" />
            <token id="24" string="&quot;" />
            <token id="25" string="hard-nosed" />
            <token id="26" string="&quot;" />
            <token id="27" string="approach" />
            <token id="28" string="and" />
            <token id="29" string="improving" />
            <token id="30" string="relations" />
            <token id="31" string="with" />
            <token id="32" string="residents" />
          </tokens>
        </chunking>
        <chunking id="4" string="The Christopher Commission 's scathing report" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Christopher" />
            <token id="3" string="Commission" />
            <token id="4" string="'s" />
            <token id="5" string="scathing" />
            <token id="6" string="report" />
          </tokens>
        </chunking>
        <chunking id="5" string="the department 's `` hard-nosed '' approach" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="department" />
            <token id="23" string="'s" />
            <token id="24" string="&quot;" />
            <token id="25" string="hard-nosed" />
            <token id="26" string="&quot;" />
            <token id="27" string="approach" />
          </tokens>
        </chunking>
        <chunking id="6" string="many of them aimed at moving away from the department 's `` hard-nosed '' approach and improving relations with residents" type="NP">
          <tokens>
            <token id="13" string="many" />
            <token id="14" string="of" />
            <token id="15" string="them" />
            <token id="16" string="aimed" />
            <token id="17" string="at" />
            <token id="18" string="moving" />
            <token id="19" string="away" />
            <token id="20" string="from" />
            <token id="21" string="the" />
            <token id="22" string="department" />
            <token id="23" string="'s" />
            <token id="24" string="&quot;" />
            <token id="25" string="hard-nosed" />
            <token id="26" string="&quot;" />
            <token id="27" string="approach" />
            <token id="28" string="and" />
            <token id="29" string="improving" />
            <token id="30" string="relations" />
            <token id="31" string="with" />
            <token id="32" string="residents" />
          </tokens>
        </chunking>
        <chunking id="7" string="improving relations with residents" type="VP">
          <tokens>
            <token id="29" string="improving" />
            <token id="30" string="relations" />
            <token id="31" string="with" />
            <token id="32" string="residents" />
          </tokens>
        </chunking>
        <chunking id="8" string="made more than 100 recommendations , many of them aimed at moving away from the department 's `` hard-nosed '' approach and improving relations with residents" type="VP">
          <tokens>
            <token id="7" string="made" />
            <token id="8" string="more" />
            <token id="9" string="than" />
            <token id="10" string="100" />
            <token id="11" string="recommendations" />
            <token id="12" string="," />
            <token id="13" string="many" />
            <token id="14" string="of" />
            <token id="15" string="them" />
            <token id="16" string="aimed" />
            <token id="17" string="at" />
            <token id="18" string="moving" />
            <token id="19" string="away" />
            <token id="20" string="from" />
            <token id="21" string="the" />
            <token id="22" string="department" />
            <token id="23" string="'s" />
            <token id="24" string="&quot;" />
            <token id="25" string="hard-nosed" />
            <token id="26" string="&quot;" />
            <token id="27" string="approach" />
            <token id="28" string="and" />
            <token id="29" string="improving" />
            <token id="30" string="relations" />
            <token id="31" string="with" />
            <token id="32" string="residents" />
          </tokens>
        </chunking>
        <chunking id="9" string="many" type="NP">
          <tokens>
            <token id="13" string="many" />
          </tokens>
        </chunking>
        <chunking id="10" string="them" type="NP">
          <tokens>
            <token id="15" string="them" />
          </tokens>
        </chunking>
        <chunking id="11" string="more than 100 recommendations" type="NP">
          <tokens>
            <token id="8" string="more" />
            <token id="9" string="than" />
            <token id="10" string="100" />
            <token id="11" string="recommendations" />
          </tokens>
        </chunking>
        <chunking id="12" string="residents" type="NP">
          <tokens>
            <token id="32" string="residents" />
          </tokens>
        </chunking>
        <chunking id="13" string="The Christopher Commission 's" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Christopher" />
            <token id="3" string="Commission" />
            <token id="4" string="'s" />
          </tokens>
        </chunking>
        <chunking id="14" string="the department 's" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="department" />
            <token id="23" string="'s" />
          </tokens>
        </chunking>
        <chunking id="15" string="more than 100 recommendations , many of them aimed at moving away from the department 's `` hard-nosed '' approach and improving relations with residents" type="NP">
          <tokens>
            <token id="8" string="more" />
            <token id="9" string="than" />
            <token id="10" string="100" />
            <token id="11" string="recommendations" />
            <token id="12" string="," />
            <token id="13" string="many" />
            <token id="14" string="of" />
            <token id="15" string="them" />
            <token id="16" string="aimed" />
            <token id="17" string="at" />
            <token id="18" string="moving" />
            <token id="19" string="away" />
            <token id="20" string="from" />
            <token id="21" string="the" />
            <token id="22" string="department" />
            <token id="23" string="'s" />
            <token id="24" string="&quot;" />
            <token id="25" string="hard-nosed" />
            <token id="26" string="&quot;" />
            <token id="27" string="approach" />
            <token id="28" string="and" />
            <token id="29" string="improving" />
            <token id="30" string="relations" />
            <token id="31" string="with" />
            <token id="32" string="residents" />
          </tokens>
        </chunking>
        <chunking id="16" string="relations" type="NP">
          <tokens>
            <token id="30" string="relations" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">Commission</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Commission</governor>
          <dependent id="2">Christopher</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">report</governor>
          <dependent id="3">Commission</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">Commission</governor>
          <dependent id="4">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">report</governor>
          <dependent id="5">scathing</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">made</governor>
          <dependent id="6">report</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">made</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">100</governor>
          <dependent id="8">more</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="8">more</governor>
          <dependent id="9">than</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="11">recommendations</governor>
          <dependent id="10">100</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">made</governor>
          <dependent id="11">recommendations</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="11">recommendations</governor>
          <dependent id="13">many</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">them</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">many</governor>
          <dependent id="15">them</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="13">many</governor>
          <dependent id="16">aimed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">moving</governor>
          <dependent id="17">at</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="16">aimed</governor>
          <dependent id="18">moving</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">moving</governor>
          <dependent id="19">away</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">approach</governor>
          <dependent id="20">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">department</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="27">approach</governor>
          <dependent id="22">department</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">department</governor>
          <dependent id="23">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">approach</governor>
          <dependent id="25">hard-nosed</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">moving</governor>
          <dependent id="27">approach</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="18">moving</governor>
          <dependent id="28">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">moving</governor>
          <dependent id="29">improving</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="29">improving</governor>
          <dependent id="30">relations</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">residents</governor>
          <dependent id="31">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">improving</governor>
          <dependent id="32">residents</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="100" type="NUMBER" score="0.0">
          <tokens>
            <token id="10" string="100" />
          </tokens>
        </entity>
        <entity id="2" string="Christopher Commission" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="2" string="Christopher" />
            <token id="3" string="Commission" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>At the street level, it suggested officers spend more time out of their patrol cars, work more with community groups and ease up on the common practice of making suspects lie face down on the ground even when they pose no apparent threat.</content>
      <tokens>
        <token id="1" string="At" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="street" lemma="street" stem="street" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="level" lemma="level" stem="level" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="suggested" lemma="suggest" stem="suggest" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="officers" lemma="officer" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="spend" lemma="spend" stem="spend" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="out" lemma="out" stem="out" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="patrol" lemma="patrol" stem="patrol" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="cars" lemma="car" stem="car" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="work" lemma="work" stem="work" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="community" lemma="community" stem="commun" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="groups" lemma="group" stem="group" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="ease" lemma="ease" stem="eas" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="common" lemma="common" stem="common" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="practice" lemma="practice" stem="practic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="making" lemma="make" stem="make" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="suspects" lemma="suspect" stem="suspect" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="33" string="lie" lemma="lie" stem="lie" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="face" lemma="face" stem="face" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="down" lemma="down" stem="down" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="ground" lemma="ground" stem="ground" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="pose" lemma="pose" stem="pose" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="apparent" lemma="apparent" stem="appar" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="threat" lemma="threat" stem="threat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="46" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN At) (NP (DT the) (NN street) (NN level))) (, ,) (NP (PRP it)) (VP (VBD suggested) (S (NP (NNS officers)) (VP (VP (VB spend) (NP (JJR more) (NN time)) (ADVP (IN out) (PP (IN of) (NP (PRP$ their) (NN patrol) (NNS cars))))) (, ,) (VP (VB work) (ADVP (RBR more)) (PP (IN with) (NP (NN community) (NNS groups)))) (CC and) (VP (VB ease) (PRT (RP up)) (PP (IN on) (NP (NP (DT the) (JJ common) (NN practice)) (PP (IN of) (S (VP (VBG making) (SBAR (S (NP (NNS suspects)) (VP (VBP lie) (NP (NN face)) (ADVP (RB down) (PP (IN on) (NP (DT the) (NN ground)))) (SBAR (RB even) (WHADVP (WRB when)) (S (NP (PRP they)) (VP (VBP pose) (NP (DT no) (JJ apparent) (NN threat))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="suspects lie face down on the ground even when they pose no apparent threat" type="SBAR">
          <tokens>
            <token id="32" string="suspects" />
            <token id="33" string="lie" />
            <token id="34" string="face" />
            <token id="35" string="down" />
            <token id="36" string="on" />
            <token id="37" string="the" />
            <token id="38" string="ground" />
            <token id="39" string="even" />
            <token id="40" string="when" />
            <token id="41" string="they" />
            <token id="42" string="pose" />
            <token id="43" string="no" />
            <token id="44" string="apparent" />
            <token id="45" string="threat" />
          </tokens>
        </chunking>
        <chunking id="2" string="spend more time out of their patrol cars , work more with community groups and ease up on the common practice of making suspects lie face down on the ground even when they pose no apparent threat" type="VP">
          <tokens>
            <token id="9" string="spend" />
            <token id="10" string="more" />
            <token id="11" string="time" />
            <token id="12" string="out" />
            <token id="13" string="of" />
            <token id="14" string="their" />
            <token id="15" string="patrol" />
            <token id="16" string="cars" />
            <token id="17" string="," />
            <token id="18" string="work" />
            <token id="19" string="more" />
            <token id="20" string="with" />
            <token id="21" string="community" />
            <token id="22" string="groups" />
            <token id="23" string="and" />
            <token id="24" string="ease" />
            <token id="25" string="up" />
            <token id="26" string="on" />
            <token id="27" string="the" />
            <token id="28" string="common" />
            <token id="29" string="practice" />
            <token id="30" string="of" />
            <token id="31" string="making" />
            <token id="32" string="suspects" />
            <token id="33" string="lie" />
            <token id="34" string="face" />
            <token id="35" string="down" />
            <token id="36" string="on" />
            <token id="37" string="the" />
            <token id="38" string="ground" />
            <token id="39" string="even" />
            <token id="40" string="when" />
            <token id="41" string="they" />
            <token id="42" string="pose" />
            <token id="43" string="no" />
            <token id="44" string="apparent" />
            <token id="45" string="threat" />
          </tokens>
        </chunking>
        <chunking id="3" string="ease up on the common practice of making suspects lie face down on the ground even when they pose no apparent threat" type="VP">
          <tokens>
            <token id="24" string="ease" />
            <token id="25" string="up" />
            <token id="26" string="on" />
            <token id="27" string="the" />
            <token id="28" string="common" />
            <token id="29" string="practice" />
            <token id="30" string="of" />
            <token id="31" string="making" />
            <token id="32" string="suspects" />
            <token id="33" string="lie" />
            <token id="34" string="face" />
            <token id="35" string="down" />
            <token id="36" string="on" />
            <token id="37" string="the" />
            <token id="38" string="ground" />
            <token id="39" string="even" />
            <token id="40" string="when" />
            <token id="41" string="they" />
            <token id="42" string="pose" />
            <token id="43" string="no" />
            <token id="44" string="apparent" />
            <token id="45" string="threat" />
          </tokens>
        </chunking>
        <chunking id="4" string="pose no apparent threat" type="VP">
          <tokens>
            <token id="42" string="pose" />
            <token id="43" string="no" />
            <token id="44" string="apparent" />
            <token id="45" string="threat" />
          </tokens>
        </chunking>
        <chunking id="5" string="community groups" type="NP">
          <tokens>
            <token id="21" string="community" />
            <token id="22" string="groups" />
          </tokens>
        </chunking>
        <chunking id="6" string="the ground" type="NP">
          <tokens>
            <token id="37" string="the" />
            <token id="38" string="ground" />
          </tokens>
        </chunking>
        <chunking id="7" string="spend more time out of their patrol cars" type="VP">
          <tokens>
            <token id="9" string="spend" />
            <token id="10" string="more" />
            <token id="11" string="time" />
            <token id="12" string="out" />
            <token id="13" string="of" />
            <token id="14" string="their" />
            <token id="15" string="patrol" />
            <token id="16" string="cars" />
          </tokens>
        </chunking>
        <chunking id="8" string="their patrol cars" type="NP">
          <tokens>
            <token id="14" string="their" />
            <token id="15" string="patrol" />
            <token id="16" string="cars" />
          </tokens>
        </chunking>
        <chunking id="9" string="no apparent threat" type="NP">
          <tokens>
            <token id="43" string="no" />
            <token id="44" string="apparent" />
            <token id="45" string="threat" />
          </tokens>
        </chunking>
        <chunking id="10" string="more time" type="NP">
          <tokens>
            <token id="10" string="more" />
            <token id="11" string="time" />
          </tokens>
        </chunking>
        <chunking id="11" string="the common practice" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="common" />
            <token id="29" string="practice" />
          </tokens>
        </chunking>
        <chunking id="12" string="it" type="NP">
          <tokens>
            <token id="6" string="it" />
          </tokens>
        </chunking>
        <chunking id="13" string="making suspects lie face down on the ground even when they pose no apparent threat" type="VP">
          <tokens>
            <token id="31" string="making" />
            <token id="32" string="suspects" />
            <token id="33" string="lie" />
            <token id="34" string="face" />
            <token id="35" string="down" />
            <token id="36" string="on" />
            <token id="37" string="the" />
            <token id="38" string="ground" />
            <token id="39" string="even" />
            <token id="40" string="when" />
            <token id="41" string="they" />
            <token id="42" string="pose" />
            <token id="43" string="no" />
            <token id="44" string="apparent" />
            <token id="45" string="threat" />
          </tokens>
        </chunking>
        <chunking id="14" string="suspects" type="NP">
          <tokens>
            <token id="32" string="suspects" />
          </tokens>
        </chunking>
        <chunking id="15" string="when" type="WHADVP">
          <tokens>
            <token id="40" string="when" />
          </tokens>
        </chunking>
        <chunking id="16" string="the street level" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="street" />
            <token id="4" string="level" />
          </tokens>
        </chunking>
        <chunking id="17" string="work more with community groups" type="VP">
          <tokens>
            <token id="18" string="work" />
            <token id="19" string="more" />
            <token id="20" string="with" />
            <token id="21" string="community" />
            <token id="22" string="groups" />
          </tokens>
        </chunking>
        <chunking id="18" string="they" type="NP">
          <tokens>
            <token id="41" string="they" />
          </tokens>
        </chunking>
        <chunking id="19" string="face" type="NP">
          <tokens>
            <token id="34" string="face" />
          </tokens>
        </chunking>
        <chunking id="20" string="suggested officers spend more time out of their patrol cars , work more with community groups and ease up on the common practice of making suspects lie face down on the ground even when they pose no apparent threat" type="VP">
          <tokens>
            <token id="7" string="suggested" />
            <token id="8" string="officers" />
            <token id="9" string="spend" />
            <token id="10" string="more" />
            <token id="11" string="time" />
            <token id="12" string="out" />
            <token id="13" string="of" />
            <token id="14" string="their" />
            <token id="15" string="patrol" />
            <token id="16" string="cars" />
            <token id="17" string="," />
            <token id="18" string="work" />
            <token id="19" string="more" />
            <token id="20" string="with" />
            <token id="21" string="community" />
            <token id="22" string="groups" />
            <token id="23" string="and" />
            <token id="24" string="ease" />
            <token id="25" string="up" />
            <token id="26" string="on" />
            <token id="27" string="the" />
            <token id="28" string="common" />
            <token id="29" string="practice" />
            <token id="30" string="of" />
            <token id="31" string="making" />
            <token id="32" string="suspects" />
            <token id="33" string="lie" />
            <token id="34" string="face" />
            <token id="35" string="down" />
            <token id="36" string="on" />
            <token id="37" string="the" />
            <token id="38" string="ground" />
            <token id="39" string="even" />
            <token id="40" string="when" />
            <token id="41" string="they" />
            <token id="42" string="pose" />
            <token id="43" string="no" />
            <token id="44" string="apparent" />
            <token id="45" string="threat" />
          </tokens>
        </chunking>
        <chunking id="21" string="lie face down on the ground even when they pose no apparent threat" type="VP">
          <tokens>
            <token id="33" string="lie" />
            <token id="34" string="face" />
            <token id="35" string="down" />
            <token id="36" string="on" />
            <token id="37" string="the" />
            <token id="38" string="ground" />
            <token id="39" string="even" />
            <token id="40" string="when" />
            <token id="41" string="they" />
            <token id="42" string="pose" />
            <token id="43" string="no" />
            <token id="44" string="apparent" />
            <token id="45" string="threat" />
          </tokens>
        </chunking>
        <chunking id="22" string="the common practice of making suspects lie face down on the ground even when they pose no apparent threat" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="common" />
            <token id="29" string="practice" />
            <token id="30" string="of" />
            <token id="31" string="making" />
            <token id="32" string="suspects" />
            <token id="33" string="lie" />
            <token id="34" string="face" />
            <token id="35" string="down" />
            <token id="36" string="on" />
            <token id="37" string="the" />
            <token id="38" string="ground" />
            <token id="39" string="even" />
            <token id="40" string="when" />
            <token id="41" string="they" />
            <token id="42" string="pose" />
            <token id="43" string="no" />
            <token id="44" string="apparent" />
            <token id="45" string="threat" />
          </tokens>
        </chunking>
        <chunking id="23" string="officers" type="NP">
          <tokens>
            <token id="8" string="officers" />
          </tokens>
        </chunking>
        <chunking id="24" string="even when they pose no apparent threat" type="SBAR">
          <tokens>
            <token id="39" string="even" />
            <token id="40" string="when" />
            <token id="41" string="they" />
            <token id="42" string="pose" />
            <token id="43" string="no" />
            <token id="44" string="apparent" />
            <token id="45" string="threat" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">level</governor>
          <dependent id="1">At</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">level</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">level</governor>
          <dependent id="3">street</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">suggested</governor>
          <dependent id="4">level</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">suggested</governor>
          <dependent id="6">it</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">suggested</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">spend</governor>
          <dependent id="8">officers</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">suggested</governor>
          <dependent id="9">spend</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">time</governor>
          <dependent id="10">more</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">spend</governor>
          <dependent id="11">time</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">cars</governor>
          <dependent id="12">out</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="12">out</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">cars</governor>
          <dependent id="14">their</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">cars</governor>
          <dependent id="15">patrol</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">spend</governor>
          <dependent id="16">cars</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">spend</governor>
          <dependent id="18">work</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">work</governor>
          <dependent id="19">more</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">groups</governor>
          <dependent id="20">with</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">groups</governor>
          <dependent id="21">community</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">work</governor>
          <dependent id="22">groups</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">spend</governor>
          <dependent id="23">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">spend</governor>
          <dependent id="24">ease</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="24">ease</governor>
          <dependent id="25">up</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">practice</governor>
          <dependent id="26">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">practice</governor>
          <dependent id="27">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">practice</governor>
          <dependent id="28">common</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">ease</governor>
          <dependent id="29">practice</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="31">making</governor>
          <dependent id="30">of</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="29">practice</governor>
          <dependent id="31">making</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="33">lie</governor>
          <dependent id="32">suspects</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="31">making</governor>
          <dependent id="33">lie</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="33">lie</governor>
          <dependent id="34">face</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="33">lie</governor>
          <dependent id="35">down</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">ground</governor>
          <dependent id="36">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="38">ground</governor>
          <dependent id="37">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="35">down</governor>
          <dependent id="38">ground</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="42">pose</governor>
          <dependent id="39">even</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="42">pose</governor>
          <dependent id="40">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="42">pose</governor>
          <dependent id="41">they</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="33">lie</governor>
          <dependent id="42">pose</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="45">threat</governor>
          <dependent id="43">no</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="45">threat</governor>
          <dependent id="44">apparent</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="42">pose</governor>
          <dependent id="45">threat</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>The city council is reviewing the recommendations, some of which -- for instance, a term limit for the chief -- require voter approval.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="city" lemma="city" stem="citi" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="council" lemma="council" stem="council" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="reviewing" lemma="review" stem="review" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="recommendations" lemma="recommendation" stem="recommend" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="instance" lemma="instance" stem="instanc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="term" lemma="term" stem="term" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="limit" lemma="limit" stem="limit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="chief" lemma="chief" stem="chief" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="require" lemma="require" stem="requir" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="voter" lemma="voter" stem="voter" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="approval" lemma="approval" stem="approv" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN city) (NN council)) (VP (VBZ is) (VP (VBG reviewing) (NP (NP (DT the) (NNS recommendations)) (, ,) (SBAR (WHNP (NP (DT some)) (WHPP (IN of) (WHNP (WDT which)))) (S (PRN (: --) (PP (IN for) (NP (NP (NN instance)) (, ,) (NP (NP (DT a) (NN term) (NN limit)) (PP (IN for) (NP (DT the) (NN chief)))))) (: --)) (VP (VBP require) (NP (NN voter) (NN approval)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="require voter approval" type="VP">
          <tokens>
            <token id="23" string="require" />
            <token id="24" string="voter" />
            <token id="25" string="approval" />
          </tokens>
        </chunking>
        <chunking id="2" string="instance" type="NP">
          <tokens>
            <token id="14" string="instance" />
          </tokens>
        </chunking>
        <chunking id="3" string="a term limit for the chief" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="term" />
            <token id="18" string="limit" />
            <token id="19" string="for" />
            <token id="20" string="the" />
            <token id="21" string="chief" />
          </tokens>
        </chunking>
        <chunking id="4" string="The city council" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="city" />
            <token id="3" string="council" />
          </tokens>
        </chunking>
        <chunking id="5" string="the chief" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="chief" />
          </tokens>
        </chunking>
        <chunking id="6" string="the recommendations , some of which -- for instance , a term limit for the chief -- require voter approval" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="recommendations" />
            <token id="8" string="," />
            <token id="9" string="some" />
            <token id="10" string="of" />
            <token id="11" string="which" />
            <token id="12" string="--" />
            <token id="13" string="for" />
            <token id="14" string="instance" />
            <token id="15" string="," />
            <token id="16" string="a" />
            <token id="17" string="term" />
            <token id="18" string="limit" />
            <token id="19" string="for" />
            <token id="20" string="the" />
            <token id="21" string="chief" />
            <token id="22" string="--" />
            <token id="23" string="require" />
            <token id="24" string="voter" />
            <token id="25" string="approval" />
          </tokens>
        </chunking>
        <chunking id="7" string="some" type="NP">
          <tokens>
            <token id="9" string="some" />
          </tokens>
        </chunking>
        <chunking id="8" string="is reviewing the recommendations , some of which -- for instance , a term limit for the chief -- require voter approval" type="VP">
          <tokens>
            <token id="4" string="is" />
            <token id="5" string="reviewing" />
            <token id="6" string="the" />
            <token id="7" string="recommendations" />
            <token id="8" string="," />
            <token id="9" string="some" />
            <token id="10" string="of" />
            <token id="11" string="which" />
            <token id="12" string="--" />
            <token id="13" string="for" />
            <token id="14" string="instance" />
            <token id="15" string="," />
            <token id="16" string="a" />
            <token id="17" string="term" />
            <token id="18" string="limit" />
            <token id="19" string="for" />
            <token id="20" string="the" />
            <token id="21" string="chief" />
            <token id="22" string="--" />
            <token id="23" string="require" />
            <token id="24" string="voter" />
            <token id="25" string="approval" />
          </tokens>
        </chunking>
        <chunking id="9" string="voter approval" type="NP">
          <tokens>
            <token id="24" string="voter" />
            <token id="25" string="approval" />
          </tokens>
        </chunking>
        <chunking id="10" string="some of which -- for instance , a term limit for the chief -- require voter approval" type="SBAR">
          <tokens>
            <token id="9" string="some" />
            <token id="10" string="of" />
            <token id="11" string="which" />
            <token id="12" string="--" />
            <token id="13" string="for" />
            <token id="14" string="instance" />
            <token id="15" string="," />
            <token id="16" string="a" />
            <token id="17" string="term" />
            <token id="18" string="limit" />
            <token id="19" string="for" />
            <token id="20" string="the" />
            <token id="21" string="chief" />
            <token id="22" string="--" />
            <token id="23" string="require" />
            <token id="24" string="voter" />
            <token id="25" string="approval" />
          </tokens>
        </chunking>
        <chunking id="11" string="instance , a term limit for the chief" type="NP">
          <tokens>
            <token id="14" string="instance" />
            <token id="15" string="," />
            <token id="16" string="a" />
            <token id="17" string="term" />
            <token id="18" string="limit" />
            <token id="19" string="for" />
            <token id="20" string="the" />
            <token id="21" string="chief" />
          </tokens>
        </chunking>
        <chunking id="12" string="the recommendations" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="recommendations" />
          </tokens>
        </chunking>
        <chunking id="13" string="reviewing the recommendations , some of which -- for instance , a term limit for the chief -- require voter approval" type="VP">
          <tokens>
            <token id="5" string="reviewing" />
            <token id="6" string="the" />
            <token id="7" string="recommendations" />
            <token id="8" string="," />
            <token id="9" string="some" />
            <token id="10" string="of" />
            <token id="11" string="which" />
            <token id="12" string="--" />
            <token id="13" string="for" />
            <token id="14" string="instance" />
            <token id="15" string="," />
            <token id="16" string="a" />
            <token id="17" string="term" />
            <token id="18" string="limit" />
            <token id="19" string="for" />
            <token id="20" string="the" />
            <token id="21" string="chief" />
            <token id="22" string="--" />
            <token id="23" string="require" />
            <token id="24" string="voter" />
            <token id="25" string="approval" />
          </tokens>
        </chunking>
        <chunking id="14" string="a term limit" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="term" />
            <token id="18" string="limit" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">council</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">council</governor>
          <dependent id="2">city</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">reviewing</governor>
          <dependent id="3">council</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">reviewing</governor>
          <dependent id="4">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">reviewing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">recommendations</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">reviewing</governor>
          <dependent id="7">recommendations</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">require</governor>
          <dependent id="9">some</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">which</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">some</governor>
          <dependent id="11">which</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">instance</governor>
          <dependent id="13">for</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="23">require</governor>
          <dependent id="14">instance</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">limit</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">limit</governor>
          <dependent id="17">term</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="14">instance</governor>
          <dependent id="18">limit</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">chief</governor>
          <dependent id="19">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">chief</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">limit</governor>
          <dependent id="21">chief</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="7">recommendations</governor>
          <dependent id="23">require</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">approval</governor>
          <dependent id="24">voter</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">require</governor>
          <dependent id="25">approval</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>Now, critics are calling for the same kind of independent investigation of the sheriff&amp;apost;s department.</content>
      <tokens>
        <token id="1" string="Now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="critics" lemma="critic" stem="critic" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="calling" lemma="call" stem="call" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="same" lemma="same" stem="same" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="kind" lemma="kind" stem="kind" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="independent" lemma="independent" stem="independ" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="12" string="investigation" lemma="investigation" stem="investig" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="sheriff" lemma="sheriff" stem="sheriff" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="department" lemma="department" stem="depart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Now)) (, ,) (NP (NNS critics)) (VP (VBP are) (VP (VBG calling) (PP (IN for) (NP (NP (DT the) (JJ same) (NN kind)) (PP (IN of) (NP (NP (JJ independent) (NN investigation)) (PP (IN of) (NP (NP (DT the) (NN sheriff) (POS 's)) (NN department))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="critics" type="NP">
          <tokens>
            <token id="3" string="critics" />
          </tokens>
        </chunking>
        <chunking id="2" string="independent investigation of the sheriff 's department" type="NP">
          <tokens>
            <token id="11" string="independent" />
            <token id="12" string="investigation" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="sheriff" />
            <token id="16" string="'s" />
            <token id="17" string="department" />
          </tokens>
        </chunking>
        <chunking id="3" string="the sheriff 's" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="sheriff" />
            <token id="16" string="'s" />
          </tokens>
        </chunking>
        <chunking id="4" string="the same kind of independent investigation of the sheriff 's department" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="same" />
            <token id="9" string="kind" />
            <token id="10" string="of" />
            <token id="11" string="independent" />
            <token id="12" string="investigation" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="sheriff" />
            <token id="16" string="'s" />
            <token id="17" string="department" />
          </tokens>
        </chunking>
        <chunking id="5" string="the same kind" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="same" />
            <token id="9" string="kind" />
          </tokens>
        </chunking>
        <chunking id="6" string="the sheriff 's department" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="sheriff" />
            <token id="16" string="'s" />
            <token id="17" string="department" />
          </tokens>
        </chunking>
        <chunking id="7" string="are calling for the same kind of independent investigation of the sheriff 's department" type="VP">
          <tokens>
            <token id="4" string="are" />
            <token id="5" string="calling" />
            <token id="6" string="for" />
            <token id="7" string="the" />
            <token id="8" string="same" />
            <token id="9" string="kind" />
            <token id="10" string="of" />
            <token id="11" string="independent" />
            <token id="12" string="investigation" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="sheriff" />
            <token id="16" string="'s" />
            <token id="17" string="department" />
          </tokens>
        </chunking>
        <chunking id="8" string="calling for the same kind of independent investigation of the sheriff 's department" type="VP">
          <tokens>
            <token id="5" string="calling" />
            <token id="6" string="for" />
            <token id="7" string="the" />
            <token id="8" string="same" />
            <token id="9" string="kind" />
            <token id="10" string="of" />
            <token id="11" string="independent" />
            <token id="12" string="investigation" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="sheriff" />
            <token id="16" string="'s" />
            <token id="17" string="department" />
          </tokens>
        </chunking>
        <chunking id="9" string="independent investigation" type="NP">
          <tokens>
            <token id="11" string="independent" />
            <token id="12" string="investigation" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="5">calling</governor>
          <dependent id="1">Now</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">calling</governor>
          <dependent id="3">critics</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">calling</governor>
          <dependent id="4">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">calling</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">kind</governor>
          <dependent id="6">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">kind</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">kind</governor>
          <dependent id="8">same</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">calling</governor>
          <dependent id="9">kind</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">investigation</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">investigation</governor>
          <dependent id="11">independent</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">kind</governor>
          <dependent id="12">investigation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">department</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">sheriff</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="17">department</governor>
          <dependent id="15">sheriff</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">sheriff</governor>
          <dependent id="16">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">investigation</governor>
          <dependent id="17">department</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Now" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="Now" />
          </tokens>
        </entity>
        <entity id="2" string="independent" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="11" string="independent" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>But Block has dug in his heels, insisting a panel he appointed is independent enough to advise which Christopher Commission recommendations might apply to his department.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Block" lemma="Block" stem="block" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="dug" lemma="dig" stem="dug" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="heels" lemma="heel" stem="heel" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="insisting" lemma="insist" stem="insist" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="panel" lemma="panel" stem="panel" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="13" string="appointed" lemma="appoint" stem="appoint" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="independent" lemma="independent" stem="independ" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="true" is_refers="false" />
        <token id="16" string="enough" lemma="enough" stem="enough" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="advise" lemma="advise" stem="advis" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="Christopher" lemma="Christopher" stem="christoph" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="21" string="Commission" lemma="Commission" stem="commiss" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="22" string="recommendations" lemma="recommendation" stem="recommend" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="might" lemma="might" stem="might" pos="MD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="apply" lemma="apply" stem="appli" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="26" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="27" string="department" lemma="department" stem="depart" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (NNP Block)) (VP (VBZ has) (VP (VBN dug) (PP (IN in) (NP (PRP$ his) (NNS heels))) (, ,) (S (VP (VBG insisting) (NP (NP (DT a) (NN panel)) (SBAR (S (NP (PRP he)) (VP (VBD appointed) (SBAR (S (VP (VBZ is) (ADJP (JJ independent)) (S (ADJP (JJ enough) (S (VP (TO to) (VP (VB advise) (SBAR (WHNP (WDT which)) (S (NP (NNP Christopher) (NNP Commission) (NNS recommendations)) (VP (MD might) (VP (VB apply) (PP (TO to) (NP (PRP$ his) (NN department))))))))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is independent enough to advise which Christopher Commission recommendations might apply to his department" type="SBAR">
          <tokens>
            <token id="14" string="is" />
            <token id="15" string="independent" />
            <token id="16" string="enough" />
            <token id="17" string="to" />
            <token id="18" string="advise" />
            <token id="19" string="which" />
            <token id="20" string="Christopher" />
            <token id="21" string="Commission" />
            <token id="22" string="recommendations" />
            <token id="23" string="might" />
            <token id="24" string="apply" />
            <token id="25" string="to" />
            <token id="26" string="his" />
            <token id="27" string="department" />
          </tokens>
        </chunking>
        <chunking id="2" string="insisting a panel he appointed is independent enough to advise which Christopher Commission recommendations might apply to his department" type="VP">
          <tokens>
            <token id="9" string="insisting" />
            <token id="10" string="a" />
            <token id="11" string="panel" />
            <token id="12" string="he" />
            <token id="13" string="appointed" />
            <token id="14" string="is" />
            <token id="15" string="independent" />
            <token id="16" string="enough" />
            <token id="17" string="to" />
            <token id="18" string="advise" />
            <token id="19" string="which" />
            <token id="20" string="Christopher" />
            <token id="21" string="Commission" />
            <token id="22" string="recommendations" />
            <token id="23" string="might" />
            <token id="24" string="apply" />
            <token id="25" string="to" />
            <token id="26" string="his" />
            <token id="27" string="department" />
          </tokens>
        </chunking>
        <chunking id="3" string="apply to his department" type="VP">
          <tokens>
            <token id="24" string="apply" />
            <token id="25" string="to" />
            <token id="26" string="his" />
            <token id="27" string="department" />
          </tokens>
        </chunking>
        <chunking id="4" string="appointed is independent enough to advise which Christopher Commission recommendations might apply to his department" type="VP">
          <tokens>
            <token id="13" string="appointed" />
            <token id="14" string="is" />
            <token id="15" string="independent" />
            <token id="16" string="enough" />
            <token id="17" string="to" />
            <token id="18" string="advise" />
            <token id="19" string="which" />
            <token id="20" string="Christopher" />
            <token id="21" string="Commission" />
            <token id="22" string="recommendations" />
            <token id="23" string="might" />
            <token id="24" string="apply" />
            <token id="25" string="to" />
            <token id="26" string="his" />
            <token id="27" string="department" />
          </tokens>
        </chunking>
        <chunking id="5" string="independent" type="ADJP">
          <tokens>
            <token id="15" string="independent" />
          </tokens>
        </chunking>
        <chunking id="6" string="might apply to his department" type="VP">
          <tokens>
            <token id="23" string="might" />
            <token id="24" string="apply" />
            <token id="25" string="to" />
            <token id="26" string="his" />
            <token id="27" string="department" />
          </tokens>
        </chunking>
        <chunking id="7" string="a panel" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="panel" />
          </tokens>
        </chunking>
        <chunking id="8" string="to advise which Christopher Commission recommendations might apply to his department" type="VP">
          <tokens>
            <token id="17" string="to" />
            <token id="18" string="advise" />
            <token id="19" string="which" />
            <token id="20" string="Christopher" />
            <token id="21" string="Commission" />
            <token id="22" string="recommendations" />
            <token id="23" string="might" />
            <token id="24" string="apply" />
            <token id="25" string="to" />
            <token id="26" string="his" />
            <token id="27" string="department" />
          </tokens>
        </chunking>
        <chunking id="9" string="enough to advise which Christopher Commission recommendations might apply to his department" type="ADJP">
          <tokens>
            <token id="16" string="enough" />
            <token id="17" string="to" />
            <token id="18" string="advise" />
            <token id="19" string="which" />
            <token id="20" string="Christopher" />
            <token id="21" string="Commission" />
            <token id="22" string="recommendations" />
            <token id="23" string="might" />
            <token id="24" string="apply" />
            <token id="25" string="to" />
            <token id="26" string="his" />
            <token id="27" string="department" />
          </tokens>
        </chunking>
        <chunking id="10" string="which Christopher Commission recommendations might apply to his department" type="SBAR">
          <tokens>
            <token id="19" string="which" />
            <token id="20" string="Christopher" />
            <token id="21" string="Commission" />
            <token id="22" string="recommendations" />
            <token id="23" string="might" />
            <token id="24" string="apply" />
            <token id="25" string="to" />
            <token id="26" string="his" />
            <token id="27" string="department" />
          </tokens>
        </chunking>
        <chunking id="11" string="his department" type="NP">
          <tokens>
            <token id="26" string="his" />
            <token id="27" string="department" />
          </tokens>
        </chunking>
        <chunking id="12" string="Block" type="NP">
          <tokens>
            <token id="2" string="Block" />
          </tokens>
        </chunking>
        <chunking id="13" string="has dug in his heels , insisting a panel he appointed is independent enough to advise which Christopher Commission recommendations might apply to his department" type="VP">
          <tokens>
            <token id="3" string="has" />
            <token id="4" string="dug" />
            <token id="5" string="in" />
            <token id="6" string="his" />
            <token id="7" string="heels" />
            <token id="8" string="," />
            <token id="9" string="insisting" />
            <token id="10" string="a" />
            <token id="11" string="panel" />
            <token id="12" string="he" />
            <token id="13" string="appointed" />
            <token id="14" string="is" />
            <token id="15" string="independent" />
            <token id="16" string="enough" />
            <token id="17" string="to" />
            <token id="18" string="advise" />
            <token id="19" string="which" />
            <token id="20" string="Christopher" />
            <token id="21" string="Commission" />
            <token id="22" string="recommendations" />
            <token id="23" string="might" />
            <token id="24" string="apply" />
            <token id="25" string="to" />
            <token id="26" string="his" />
            <token id="27" string="department" />
          </tokens>
        </chunking>
        <chunking id="14" string="he appointed is independent enough to advise which Christopher Commission recommendations might apply to his department" type="SBAR">
          <tokens>
            <token id="12" string="he" />
            <token id="13" string="appointed" />
            <token id="14" string="is" />
            <token id="15" string="independent" />
            <token id="16" string="enough" />
            <token id="17" string="to" />
            <token id="18" string="advise" />
            <token id="19" string="which" />
            <token id="20" string="Christopher" />
            <token id="21" string="Commission" />
            <token id="22" string="recommendations" />
            <token id="23" string="might" />
            <token id="24" string="apply" />
            <token id="25" string="to" />
            <token id="26" string="his" />
            <token id="27" string="department" />
          </tokens>
        </chunking>
        <chunking id="15" string="his heels" type="NP">
          <tokens>
            <token id="6" string="his" />
            <token id="7" string="heels" />
          </tokens>
        </chunking>
        <chunking id="16" string="Christopher Commission recommendations" type="NP">
          <tokens>
            <token id="20" string="Christopher" />
            <token id="21" string="Commission" />
            <token id="22" string="recommendations" />
          </tokens>
        </chunking>
        <chunking id="17" string="dug in his heels , insisting a panel he appointed is independent enough to advise which Christopher Commission recommendations might apply to his department" type="VP">
          <tokens>
            <token id="4" string="dug" />
            <token id="5" string="in" />
            <token id="6" string="his" />
            <token id="7" string="heels" />
            <token id="8" string="," />
            <token id="9" string="insisting" />
            <token id="10" string="a" />
            <token id="11" string="panel" />
            <token id="12" string="he" />
            <token id="13" string="appointed" />
            <token id="14" string="is" />
            <token id="15" string="independent" />
            <token id="16" string="enough" />
            <token id="17" string="to" />
            <token id="18" string="advise" />
            <token id="19" string="which" />
            <token id="20" string="Christopher" />
            <token id="21" string="Commission" />
            <token id="22" string="recommendations" />
            <token id="23" string="might" />
            <token id="24" string="apply" />
            <token id="25" string="to" />
            <token id="26" string="his" />
            <token id="27" string="department" />
          </tokens>
        </chunking>
        <chunking id="18" string="a panel he appointed is independent enough to advise which Christopher Commission recommendations might apply to his department" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="panel" />
            <token id="12" string="he" />
            <token id="13" string="appointed" />
            <token id="14" string="is" />
            <token id="15" string="independent" />
            <token id="16" string="enough" />
            <token id="17" string="to" />
            <token id="18" string="advise" />
            <token id="19" string="which" />
            <token id="20" string="Christopher" />
            <token id="21" string="Commission" />
            <token id="22" string="recommendations" />
            <token id="23" string="might" />
            <token id="24" string="apply" />
            <token id="25" string="to" />
            <token id="26" string="his" />
            <token id="27" string="department" />
          </tokens>
        </chunking>
        <chunking id="19" string="he" type="NP">
          <tokens>
            <token id="12" string="he" />
          </tokens>
        </chunking>
        <chunking id="20" string="advise which Christopher Commission recommendations might apply to his department" type="VP">
          <tokens>
            <token id="18" string="advise" />
            <token id="19" string="which" />
            <token id="20" string="Christopher" />
            <token id="21" string="Commission" />
            <token id="22" string="recommendations" />
            <token id="23" string="might" />
            <token id="24" string="apply" />
            <token id="25" string="to" />
            <token id="26" string="his" />
            <token id="27" string="department" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="4">dug</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">dug</governor>
          <dependent id="2">Block</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">dug</governor>
          <dependent id="3">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">dug</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">heels</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">heels</governor>
          <dependent id="6">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">dug</governor>
          <dependent id="7">heels</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">dug</governor>
          <dependent id="9">insisting</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">panel</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">insisting</governor>
          <dependent id="11">panel</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">appointed</governor>
          <dependent id="12">he</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="11">panel</governor>
          <dependent id="13">appointed</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="15">independent</governor>
          <dependent id="14">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">appointed</governor>
          <dependent id="15">independent</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="15">independent</governor>
          <dependent id="16">enough</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">advise</governor>
          <dependent id="17">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="16">enough</governor>
          <dependent id="18">advise</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">apply</governor>
          <dependent id="19">which</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">recommendations</governor>
          <dependent id="20">Christopher</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">recommendations</governor>
          <dependent id="21">Commission</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">apply</governor>
          <dependent id="22">recommendations</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="24">apply</governor>
          <dependent id="23">might</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="18">advise</governor>
          <dependent id="24">apply</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">department</governor>
          <dependent id="25">to</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="27">department</governor>
          <dependent id="26">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">apply</governor>
          <dependent id="27">department</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Christopher Commission" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="20" string="Christopher" />
            <token id="21" string="Commission" />
          </tokens>
        </entity>
        <entity id="2" string="independent" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="15" string="independent" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="26" has_coreference="true">
      <content>Critics say its leaders have been supporters of the local law establishment.</content>
      <tokens>
        <token id="1" string="Critics" lemma="critic" stem="critic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="say" lemma="say" stem="sai" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="4" string="leaders" lemma="leader" stem="leader" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="supporters" lemma="supporter" stem="support" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="local" lemma="local" stem="local" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="law" lemma="law" stem="law" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="establishment" lemma="establishment" stem="establish" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNS Critics)) (VP (VBP say) (SBAR (S (NP (PRP$ its) (NNS leaders)) (VP (VBP have) (VP (VBN been) (NP (NP (NNS supporters)) (PP (IN of) (NP (DT the) (JJ local) (NN law) (NN establishment))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="say its leaders have been supporters of the local law establishment" type="VP">
          <tokens>
            <token id="2" string="say" />
            <token id="3" string="its" />
            <token id="4" string="leaders" />
            <token id="5" string="have" />
            <token id="6" string="been" />
            <token id="7" string="supporters" />
            <token id="8" string="of" />
            <token id="9" string="the" />
            <token id="10" string="local" />
            <token id="11" string="law" />
            <token id="12" string="establishment" />
          </tokens>
        </chunking>
        <chunking id="2" string="have been supporters of the local law establishment" type="VP">
          <tokens>
            <token id="5" string="have" />
            <token id="6" string="been" />
            <token id="7" string="supporters" />
            <token id="8" string="of" />
            <token id="9" string="the" />
            <token id="10" string="local" />
            <token id="11" string="law" />
            <token id="12" string="establishment" />
          </tokens>
        </chunking>
        <chunking id="3" string="supporters of the local law establishment" type="NP">
          <tokens>
            <token id="7" string="supporters" />
            <token id="8" string="of" />
            <token id="9" string="the" />
            <token id="10" string="local" />
            <token id="11" string="law" />
            <token id="12" string="establishment" />
          </tokens>
        </chunking>
        <chunking id="4" string="Critics" type="NP">
          <tokens>
            <token id="1" string="Critics" />
          </tokens>
        </chunking>
        <chunking id="5" string="its leaders" type="NP">
          <tokens>
            <token id="3" string="its" />
            <token id="4" string="leaders" />
          </tokens>
        </chunking>
        <chunking id="6" string="its leaders have been supporters of the local law establishment" type="SBAR">
          <tokens>
            <token id="3" string="its" />
            <token id="4" string="leaders" />
            <token id="5" string="have" />
            <token id="6" string="been" />
            <token id="7" string="supporters" />
            <token id="8" string="of" />
            <token id="9" string="the" />
            <token id="10" string="local" />
            <token id="11" string="law" />
            <token id="12" string="establishment" />
          </tokens>
        </chunking>
        <chunking id="7" string="the local law establishment" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="local" />
            <token id="11" string="law" />
            <token id="12" string="establishment" />
          </tokens>
        </chunking>
        <chunking id="8" string="been supporters of the local law establishment" type="VP">
          <tokens>
            <token id="6" string="been" />
            <token id="7" string="supporters" />
            <token id="8" string="of" />
            <token id="9" string="the" />
            <token id="10" string="local" />
            <token id="11" string="law" />
            <token id="12" string="establishment" />
          </tokens>
        </chunking>
        <chunking id="9" string="supporters" type="NP">
          <tokens>
            <token id="7" string="supporters" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">say</governor>
          <dependent id="1">Critics</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">say</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">leaders</governor>
          <dependent id="3">its</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">supporters</governor>
          <dependent id="4">leaders</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">supporters</governor>
          <dependent id="5">have</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">supporters</governor>
          <dependent id="6">been</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">say</governor>
          <dependent id="7">supporters</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">establishment</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">establishment</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">establishment</governor>
          <dependent id="10">local</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">establishment</governor>
          <dependent id="11">law</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">supporters</governor>
          <dependent id="12">establishment</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>But because Block is elected, his is the last word.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Block" lemma="Block" stem="block" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="elected" lemma="elect" stem="elect" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="word" lemma="word" stem="word" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (SBAR (IN because) (S (NP (NNP Block)) (VP (VBZ is) (VP (VBN elected))))) (, ,) (NP (PRP$ his)) (VP (VBZ is) (NP (DT the) (JJ last) (NN word))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="his" type="NP">
          <tokens>
            <token id="7" string="his" />
          </tokens>
        </chunking>
        <chunking id="2" string="elected" type="VP">
          <tokens>
            <token id="5" string="elected" />
          </tokens>
        </chunking>
        <chunking id="3" string="is the last word" type="VP">
          <tokens>
            <token id="8" string="is" />
            <token id="9" string="the" />
            <token id="10" string="last" />
            <token id="11" string="word" />
          </tokens>
        </chunking>
        <chunking id="4" string="is elected" type="VP">
          <tokens>
            <token id="4" string="is" />
            <token id="5" string="elected" />
          </tokens>
        </chunking>
        <chunking id="5" string="Block" type="NP">
          <tokens>
            <token id="3" string="Block" />
          </tokens>
        </chunking>
        <chunking id="6" string="the last word" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="last" />
            <token id="11" string="word" />
          </tokens>
        </chunking>
        <chunking id="7" string="because Block is elected" type="SBAR">
          <tokens>
            <token id="2" string="because" />
            <token id="3" string="Block" />
            <token id="4" string="is" />
            <token id="5" string="elected" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="11">word</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">elected</governor>
          <dependent id="2">because</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="5">elected</governor>
          <dependent id="3">Block</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">elected</governor>
          <dependent id="4">is</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">word</governor>
          <dependent id="5">elected</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">word</governor>
          <dependent id="7">his</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">word</governor>
          <dependent id="8">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">word</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">word</governor>
          <dependent id="10">last</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">word</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="28" has_coreference="true">
      <content>Like Gates before him, Block maintains his department is a good one with &amp;quot;a reputation as being one of the most progressive, one of the most professional, one of the finest law enforcement agencies.&amp;quot;</content>
      <tokens>
        <token id="1" string="Like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="Gates" lemma="Gates" stem="gate" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Block" lemma="Block" stem="block" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="maintains" lemma="maintain" stem="maintain" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="department" lemma="department" stem="depart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="good" lemma="good" stem="good" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="14" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="reputation" lemma="reputation" stem="reput" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="being" lemma="be" stem="be" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="21" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="most" lemma="most" stem="most" pos="RBS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="progressive" lemma="progressive" stem="progress" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="27" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="most" lemma="most" stem="most" pos="RBS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="professional" lemma="professional" stem="profession" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="33" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="finest" lemma="finest" stem="finest" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="law" lemma="law" stem="law" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="enforcement" lemma="enforcement" stem="enforc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="agencies" lemma="agency" stem="agenc" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN Like) (NP (NP (NNP Gates)) (PP (IN before) (NP (PRP him))))) (, ,) (NP (NNP Block)) (VP (VBZ maintains) (SBAR (S (NP (PRP$ his) (NN department)) (VP (VBZ is) (NP (DT a) (JJ good) (CD one)) (PP (IN with) (`` ``) (NP (DT a) (NN reputation))) (PP (IN as) (S (VP (VBG being) (NP (NP (CD one)) (PP (IN of) (NP (DT the) (UCP (ADJP (RBS most) (JJ progressive)) (, ,) (NP (NP (CD one)) (PP (IN of) (NP (NP (DT the) (RBS most) (JJ professional)) (, ,) (NP (NP (CD one)) (PP (IN of) (NP (DT the) (JJS finest) (NN law)))))))) (NN enforcement) (NNS agencies))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="is a good one with `` a reputation as being one of the most progressive , one of the most professional , one of the finest law enforcement agencies" type="VP">
          <tokens>
            <token id="10" string="is" />
            <token id="11" string="a" />
            <token id="12" string="good" />
            <token id="13" string="one" />
            <token id="14" string="with" />
            <token id="15" string="&quot;" />
            <token id="16" string="a" />
            <token id="17" string="reputation" />
            <token id="18" string="as" />
            <token id="19" string="being" />
            <token id="20" string="one" />
            <token id="21" string="of" />
            <token id="22" string="the" />
            <token id="23" string="most" />
            <token id="24" string="progressive" />
            <token id="25" string="," />
            <token id="26" string="one" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="most" />
            <token id="30" string="professional" />
            <token id="31" string="," />
            <token id="32" string="one" />
            <token id="33" string="of" />
            <token id="34" string="the" />
            <token id="35" string="finest" />
            <token id="36" string="law" />
            <token id="37" string="enforcement" />
            <token id="38" string="agencies" />
          </tokens>
        </chunking>
        <chunking id="2" string="maintains his department is a good one with `` a reputation as being one of the most progressive , one of the most professional , one of the finest law enforcement agencies" type="VP">
          <tokens>
            <token id="7" string="maintains" />
            <token id="8" string="his" />
            <token id="9" string="department" />
            <token id="10" string="is" />
            <token id="11" string="a" />
            <token id="12" string="good" />
            <token id="13" string="one" />
            <token id="14" string="with" />
            <token id="15" string="&quot;" />
            <token id="16" string="a" />
            <token id="17" string="reputation" />
            <token id="18" string="as" />
            <token id="19" string="being" />
            <token id="20" string="one" />
            <token id="21" string="of" />
            <token id="22" string="the" />
            <token id="23" string="most" />
            <token id="24" string="progressive" />
            <token id="25" string="," />
            <token id="26" string="one" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="most" />
            <token id="30" string="professional" />
            <token id="31" string="," />
            <token id="32" string="one" />
            <token id="33" string="of" />
            <token id="34" string="the" />
            <token id="35" string="finest" />
            <token id="36" string="law" />
            <token id="37" string="enforcement" />
            <token id="38" string="agencies" />
          </tokens>
        </chunking>
        <chunking id="3" string="a reputation" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="reputation" />
          </tokens>
        </chunking>
        <chunking id="4" string="one of the most professional , one of the finest law" type="NP">
          <tokens>
            <token id="26" string="one" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="most" />
            <token id="30" string="professional" />
            <token id="31" string="," />
            <token id="32" string="one" />
            <token id="33" string="of" />
            <token id="34" string="the" />
            <token id="35" string="finest" />
            <token id="36" string="law" />
          </tokens>
        </chunking>
        <chunking id="5" string="one" type="NP">
          <tokens>
            <token id="20" string="one" />
          </tokens>
        </chunking>
        <chunking id="6" string="a good one" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="good" />
            <token id="13" string="one" />
          </tokens>
        </chunking>
        <chunking id="7" string="most progressive" type="ADJP">
          <tokens>
            <token id="23" string="most" />
            <token id="24" string="progressive" />
          </tokens>
        </chunking>
        <chunking id="8" string="the most progressive , one of the most professional , one of the finest law enforcement agencies" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="most" />
            <token id="24" string="progressive" />
            <token id="25" string="," />
            <token id="26" string="one" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="most" />
            <token id="30" string="professional" />
            <token id="31" string="," />
            <token id="32" string="one" />
            <token id="33" string="of" />
            <token id="34" string="the" />
            <token id="35" string="finest" />
            <token id="36" string="law" />
            <token id="37" string="enforcement" />
            <token id="38" string="agencies" />
          </tokens>
        </chunking>
        <chunking id="9" string="him" type="NP">
          <tokens>
            <token id="4" string="him" />
          </tokens>
        </chunking>
        <chunking id="10" string="the finest law" type="NP">
          <tokens>
            <token id="34" string="the" />
            <token id="35" string="finest" />
            <token id="36" string="law" />
          </tokens>
        </chunking>
        <chunking id="11" string="Gates" type="NP">
          <tokens>
            <token id="2" string="Gates" />
          </tokens>
        </chunking>
        <chunking id="12" string="one of the most progressive , one of the most professional , one of the finest law enforcement agencies" type="NP">
          <tokens>
            <token id="20" string="one" />
            <token id="21" string="of" />
            <token id="22" string="the" />
            <token id="23" string="most" />
            <token id="24" string="progressive" />
            <token id="25" string="," />
            <token id="26" string="one" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="most" />
            <token id="30" string="professional" />
            <token id="31" string="," />
            <token id="32" string="one" />
            <token id="33" string="of" />
            <token id="34" string="the" />
            <token id="35" string="finest" />
            <token id="36" string="law" />
            <token id="37" string="enforcement" />
            <token id="38" string="agencies" />
          </tokens>
        </chunking>
        <chunking id="13" string="his department" type="NP">
          <tokens>
            <token id="8" string="his" />
            <token id="9" string="department" />
          </tokens>
        </chunking>
        <chunking id="14" string="Block" type="NP">
          <tokens>
            <token id="6" string="Block" />
          </tokens>
        </chunking>
        <chunking id="15" string="his department is a good one with `` a reputation as being one of the most progressive , one of the most professional , one of the finest law enforcement agencies" type="SBAR">
          <tokens>
            <token id="8" string="his" />
            <token id="9" string="department" />
            <token id="10" string="is" />
            <token id="11" string="a" />
            <token id="12" string="good" />
            <token id="13" string="one" />
            <token id="14" string="with" />
            <token id="15" string="&quot;" />
            <token id="16" string="a" />
            <token id="17" string="reputation" />
            <token id="18" string="as" />
            <token id="19" string="being" />
            <token id="20" string="one" />
            <token id="21" string="of" />
            <token id="22" string="the" />
            <token id="23" string="most" />
            <token id="24" string="progressive" />
            <token id="25" string="," />
            <token id="26" string="one" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="most" />
            <token id="30" string="professional" />
            <token id="31" string="," />
            <token id="32" string="one" />
            <token id="33" string="of" />
            <token id="34" string="the" />
            <token id="35" string="finest" />
            <token id="36" string="law" />
            <token id="37" string="enforcement" />
            <token id="38" string="agencies" />
          </tokens>
        </chunking>
        <chunking id="16" string="being one of the most progressive , one of the most professional , one of the finest law enforcement agencies" type="VP">
          <tokens>
            <token id="19" string="being" />
            <token id="20" string="one" />
            <token id="21" string="of" />
            <token id="22" string="the" />
            <token id="23" string="most" />
            <token id="24" string="progressive" />
            <token id="25" string="," />
            <token id="26" string="one" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="most" />
            <token id="30" string="professional" />
            <token id="31" string="," />
            <token id="32" string="one" />
            <token id="33" string="of" />
            <token id="34" string="the" />
            <token id="35" string="finest" />
            <token id="36" string="law" />
            <token id="37" string="enforcement" />
            <token id="38" string="agencies" />
          </tokens>
        </chunking>
        <chunking id="17" string="the most professional , one of the finest law" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="most" />
            <token id="30" string="professional" />
            <token id="31" string="," />
            <token id="32" string="one" />
            <token id="33" string="of" />
            <token id="34" string="the" />
            <token id="35" string="finest" />
            <token id="36" string="law" />
          </tokens>
        </chunking>
        <chunking id="18" string="the most professional" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="most" />
            <token id="30" string="professional" />
          </tokens>
        </chunking>
        <chunking id="19" string="one of the finest law" type="NP">
          <tokens>
            <token id="32" string="one" />
            <token id="33" string="of" />
            <token id="34" string="the" />
            <token id="35" string="finest" />
            <token id="36" string="law" />
          </tokens>
        </chunking>
        <chunking id="20" string="Gates before him" type="NP">
          <tokens>
            <token id="2" string="Gates" />
            <token id="3" string="before" />
            <token id="4" string="him" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">Gates</governor>
          <dependent id="1">Like</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">maintains</governor>
          <dependent id="2">Gates</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">him</governor>
          <dependent id="3">before</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">Gates</governor>
          <dependent id="4">him</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">maintains</governor>
          <dependent id="6">Block</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">maintains</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">department</governor>
          <dependent id="8">his</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">one</governor>
          <dependent id="9">department</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="13">one</governor>
          <dependent id="10">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">one</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">one</governor>
          <dependent id="12">good</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">maintains</governor>
          <dependent id="13">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">reputation</governor>
          <dependent id="14">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">reputation</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">one</governor>
          <dependent id="17">reputation</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">one</governor>
          <dependent id="18">as</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="20">one</governor>
          <dependent id="19">being</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="13">one</governor>
          <dependent id="20">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">agencies</governor>
          <dependent id="21">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="38">agencies</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="24">progressive</governor>
          <dependent id="23">most</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="38">agencies</governor>
          <dependent id="24">progressive</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="24">progressive</governor>
          <dependent id="26">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">professional</governor>
          <dependent id="27">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">professional</governor>
          <dependent id="28">the</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="30">professional</governor>
          <dependent id="29">most</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">one</governor>
          <dependent id="30">professional</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="30">professional</governor>
          <dependent id="32">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">law</governor>
          <dependent id="33">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="36">law</governor>
          <dependent id="34">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="36">law</governor>
          <dependent id="35">finest</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">one</governor>
          <dependent id="36">law</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="38">agencies</governor>
          <dependent id="37">enforcement</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">one</governor>
          <dependent id="38">agencies</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Gates" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Gates" />
          </tokens>
        </entity>
        <entity id="2" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="13" string="one" />
          </tokens>
        </entity>
        <entity id="3" string="Block" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Block" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="29" has_coreference="true">
      <content>; The sheriff has said that his department continually re-examines itself and launched several Christopher Commission recommendations before the commission even existed -- but that it can&amp;apost;t do everything. &amp;apost;</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="sheriff" lemma="sheriff" stem="sheriff" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="said" lemma="say" stem="said" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="department" lemma="department" stem="depart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="continually" lemma="continually" stem="continu" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="re-examines" lemma="re-examine" stem="re-examin" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="itself" lemma="itself" stem="itself" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="launched" lemma="launch" stem="launch" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="several" lemma="several" stem="sever" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="Christopher" lemma="Christopher" stem="christoph" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="16" string="Commission" lemma="Commission" stem="commiss" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="17" string="recommendations" lemma="recommendation" stem="recommend" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="commission" lemma="commission" stem="commiss" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="existed" lemma="exist" stem="exist" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="ca" lemma="can" stem="ca" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="do" lemma="do" stem="do" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="everything" lemma="everything" stem="everyth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (PRN (: ;) (S (NP (DT The) (NN sheriff)) (VP (VBZ has) (VP (VBN said) (SBAR (IN that) (S (NP (PRP$ his) (NN department)) (VP (VP (ADVP (RB continually)) (VBZ re-examines) (NP (PRP itself))) (CC and) (VP (VBD launched) (NP (JJ several) (NNP Christopher) (NNP Commission) (NNS recommendations)) (SBAR (SBAR (IN before) (S (NP (DT the) (NN commission)) (ADVP (RB even)) (VP (VBD existed))) (: --)) (CC but) (SBAR (IN that) (S (NP (PRP it)) (VP (MD ca) (RB n't) (VP (VB do) (NP (NN everything))))) (. .) ('' '))))))))))))</syntactictree>
      <chunkings>
        <chunking id="1" string="the commission" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="commission" />
          </tokens>
        </chunking>
        <chunking id="2" string="continually re-examines itself and launched several Christopher Commission recommendations before the commission even existed -- but that it ca n't do everything . '" type="VP">
          <tokens>
            <token id="9" string="continually" />
            <token id="10" string="re-examines" />
            <token id="11" string="itself" />
            <token id="12" string="and" />
            <token id="13" string="launched" />
            <token id="14" string="several" />
            <token id="15" string="Christopher" />
            <token id="16" string="Commission" />
            <token id="17" string="recommendations" />
            <token id="18" string="before" />
            <token id="19" string="the" />
            <token id="20" string="commission" />
            <token id="21" string="even" />
            <token id="22" string="existed" />
            <token id="23" string="--" />
            <token id="24" string="but" />
            <token id="25" string="that" />
            <token id="26" string="it" />
            <token id="27" string="ca" />
            <token id="28" string="n't" />
            <token id="29" string="do" />
            <token id="30" string="everything" />
            <token id="31" string="." />
            <token id="32" string="'" />
          </tokens>
        </chunking>
        <chunking id="3" string="has said that his department continually re-examines itself and launched several Christopher Commission recommendations before the commission even existed -- but that it ca n't do everything . '" type="VP">
          <tokens>
            <token id="4" string="has" />
            <token id="5" string="said" />
            <token id="6" string="that" />
            <token id="7" string="his" />
            <token id="8" string="department" />
            <token id="9" string="continually" />
            <token id="10" string="re-examines" />
            <token id="11" string="itself" />
            <token id="12" string="and" />
            <token id="13" string="launched" />
            <token id="14" string="several" />
            <token id="15" string="Christopher" />
            <token id="16" string="Commission" />
            <token id="17" string="recommendations" />
            <token id="18" string="before" />
            <token id="19" string="the" />
            <token id="20" string="commission" />
            <token id="21" string="even" />
            <token id="22" string="existed" />
            <token id="23" string="--" />
            <token id="24" string="but" />
            <token id="25" string="that" />
            <token id="26" string="it" />
            <token id="27" string="ca" />
            <token id="28" string="n't" />
            <token id="29" string="do" />
            <token id="30" string="everything" />
            <token id="31" string="." />
            <token id="32" string="'" />
          </tokens>
        </chunking>
        <chunking id="4" string="said that his department continually re-examines itself and launched several Christopher Commission recommendations before the commission even existed -- but that it ca n't do everything . '" type="VP">
          <tokens>
            <token id="5" string="said" />
            <token id="6" string="that" />
            <token id="7" string="his" />
            <token id="8" string="department" />
            <token id="9" string="continually" />
            <token id="10" string="re-examines" />
            <token id="11" string="itself" />
            <token id="12" string="and" />
            <token id="13" string="launched" />
            <token id="14" string="several" />
            <token id="15" string="Christopher" />
            <token id="16" string="Commission" />
            <token id="17" string="recommendations" />
            <token id="18" string="before" />
            <token id="19" string="the" />
            <token id="20" string="commission" />
            <token id="21" string="even" />
            <token id="22" string="existed" />
            <token id="23" string="--" />
            <token id="24" string="but" />
            <token id="25" string="that" />
            <token id="26" string="it" />
            <token id="27" string="ca" />
            <token id="28" string="n't" />
            <token id="29" string="do" />
            <token id="30" string="everything" />
            <token id="31" string="." />
            <token id="32" string="'" />
          </tokens>
        </chunking>
        <chunking id="5" string="before the commission even existed -- but that it ca n't do everything . '" type="SBAR">
          <tokens>
            <token id="18" string="before" />
            <token id="19" string="the" />
            <token id="20" string="commission" />
            <token id="21" string="even" />
            <token id="22" string="existed" />
            <token id="23" string="--" />
            <token id="24" string="but" />
            <token id="25" string="that" />
            <token id="26" string="it" />
            <token id="27" string="ca" />
            <token id="28" string="n't" />
            <token id="29" string="do" />
            <token id="30" string="everything" />
            <token id="31" string="." />
            <token id="32" string="'" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="26" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="continually re-examines itself" type="VP">
          <tokens>
            <token id="9" string="continually" />
            <token id="10" string="re-examines" />
            <token id="11" string="itself" />
          </tokens>
        </chunking>
        <chunking id="8" string="existed" type="VP">
          <tokens>
            <token id="22" string="existed" />
          </tokens>
        </chunking>
        <chunking id="9" string="before the commission even existed --" type="SBAR">
          <tokens>
            <token id="18" string="before" />
            <token id="19" string="the" />
            <token id="20" string="commission" />
            <token id="21" string="even" />
            <token id="22" string="existed" />
            <token id="23" string="--" />
          </tokens>
        </chunking>
        <chunking id="10" string="itself" type="NP">
          <tokens>
            <token id="11" string="itself" />
          </tokens>
        </chunking>
        <chunking id="11" string="launched several Christopher Commission recommendations before the commission even existed -- but that it ca n't do everything . '" type="VP">
          <tokens>
            <token id="13" string="launched" />
            <token id="14" string="several" />
            <token id="15" string="Christopher" />
            <token id="16" string="Commission" />
            <token id="17" string="recommendations" />
            <token id="18" string="before" />
            <token id="19" string="the" />
            <token id="20" string="commission" />
            <token id="21" string="even" />
            <token id="22" string="existed" />
            <token id="23" string="--" />
            <token id="24" string="but" />
            <token id="25" string="that" />
            <token id="26" string="it" />
            <token id="27" string="ca" />
            <token id="28" string="n't" />
            <token id="29" string="do" />
            <token id="30" string="everything" />
            <token id="31" string="." />
            <token id="32" string="'" />
          </tokens>
        </chunking>
        <chunking id="12" string="several Christopher Commission recommendations" type="NP">
          <tokens>
            <token id="14" string="several" />
            <token id="15" string="Christopher" />
            <token id="16" string="Commission" />
            <token id="17" string="recommendations" />
          </tokens>
        </chunking>
        <chunking id="13" string="his department" type="NP">
          <tokens>
            <token id="7" string="his" />
            <token id="8" string="department" />
          </tokens>
        </chunking>
        <chunking id="14" string="The sheriff" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="sheriff" />
          </tokens>
        </chunking>
        <chunking id="15" string="ca n't do everything" type="VP">
          <tokens>
            <token id="27" string="ca" />
            <token id="28" string="n't" />
            <token id="29" string="do" />
            <token id="30" string="everything" />
          </tokens>
        </chunking>
        <chunking id="16" string="do everything" type="VP">
          <tokens>
            <token id="29" string="do" />
            <token id="30" string="everything" />
          </tokens>
        </chunking>
        <chunking id="17" string="that his department continually re-examines itself and launched several Christopher Commission recommendations before the commission even existed -- but that it ca n't do everything . '" type="SBAR">
          <tokens>
            <token id="6" string="that" />
            <token id="7" string="his" />
            <token id="8" string="department" />
            <token id="9" string="continually" />
            <token id="10" string="re-examines" />
            <token id="11" string="itself" />
            <token id="12" string="and" />
            <token id="13" string="launched" />
            <token id="14" string="several" />
            <token id="15" string="Christopher" />
            <token id="16" string="Commission" />
            <token id="17" string="recommendations" />
            <token id="18" string="before" />
            <token id="19" string="the" />
            <token id="20" string="commission" />
            <token id="21" string="even" />
            <token id="22" string="existed" />
            <token id="23" string="--" />
            <token id="24" string="but" />
            <token id="25" string="that" />
            <token id="26" string="it" />
            <token id="27" string="ca" />
            <token id="28" string="n't" />
            <token id="29" string="do" />
            <token id="30" string="everything" />
            <token id="31" string="." />
            <token id="32" string="'" />
          </tokens>
        </chunking>
        <chunking id="18" string="that it ca n't do everything . '" type="SBAR">
          <tokens>
            <token id="25" string="that" />
            <token id="26" string="it" />
            <token id="27" string="ca" />
            <token id="28" string="n't" />
            <token id="29" string="do" />
            <token id="30" string="everything" />
            <token id="31" string="." />
            <token id="32" string="'" />
          </tokens>
        </chunking>
        <chunking id="19" string="everything" type="NP">
          <tokens>
            <token id="30" string="everything" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">sheriff</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">said</governor>
          <dependent id="3">sheriff</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">said</governor>
          <dependent id="4">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">said</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">re-examines</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">department</governor>
          <dependent id="7">his</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">re-examines</governor>
          <dependent id="8">department</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">re-examines</governor>
          <dependent id="9">continually</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">said</governor>
          <dependent id="10">re-examines</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">re-examines</governor>
          <dependent id="11">itself</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">re-examines</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">re-examines</governor>
          <dependent id="13">launched</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">recommendations</governor>
          <dependent id="14">several</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">recommendations</governor>
          <dependent id="15">Christopher</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">recommendations</governor>
          <dependent id="16">Commission</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">launched</governor>
          <dependent id="17">recommendations</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">existed</governor>
          <dependent id="18">before</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">commission</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">existed</governor>
          <dependent id="20">commission</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="22">existed</governor>
          <dependent id="21">even</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="13">launched</governor>
          <dependent id="22">existed</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="22">existed</governor>
          <dependent id="24">but</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="29">do</governor>
          <dependent id="25">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">do</governor>
          <dependent id="26">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="29">do</governor>
          <dependent id="27">ca</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="29">do</governor>
          <dependent id="28">n't</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="22">existed</governor>
          <dependent id="29">do</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="29">do</governor>
          <dependent id="30">everything</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Christopher Commission" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="15" string="Christopher" />
            <token id="16" string="Commission" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="30" has_coreference="true">
      <content>A last-resort mechanism&amp;apost;; &amp;quot;Law enforcement, and I&amp;apost;m going beyond the sheriff&amp;apost;s department, did not create the social conditions out there from which the violence is springing,&amp;quot; he said.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="last-resort" lemma="last-resort" stem="last-resort" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="mechanism" lemma="mechanism" stem="mechan" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Law" lemma="Law" stem="law" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="enforcement" lemma="enforcement" stem="enforc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="'m" lemma="be" stem="'m" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="beyond" lemma="beyond" stem="beyond" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="sheriff" lemma="sheriff" stem="sheriff" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="department" lemma="department" stem="depart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="create" lemma="create" stem="creat" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="social" lemma="social" stem="social" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="conditions" lemma="condition" stem="condit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="out" lemma="out" stem="out" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="there" lemma="there" stem="there" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="violence" lemma="violence" stem="violenc" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="32" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="springing" lemma="spring" stem="spring" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="37" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT A) (JJ last-resort) (NN mechanism) ('' ')) (: ;) (S (`` ``) (S (NP (NNP Law) (NN enforcement)) (PRN (, ,) (CC and) (S (NP (PRP I)) (VP (VBP 'm) (VP (VBG going) (PP (IN beyond) (NP (NP (DT the) (NN sheriff) (POS 's)) (NN department)))))) (, ,)) (VP (VBD did) (RB not) (VP (VB create) (NP (DT the) (JJ social) (NNS conditions)) (PP (IN out) (NP (RB there))) (PP (IN from) (SBAR (WHNP (WDT which)) (S (NP (DT the) (NN violence)) (VP (VBZ is) (VP (VBG springing))))))))) (, ,) ('' '') (NP (PRP he)) (VP (VBD said))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="going beyond the sheriff 's department" type="VP">
          <tokens>
            <token id="13" string="going" />
            <token id="14" string="beyond" />
            <token id="15" string="the" />
            <token id="16" string="sheriff" />
            <token id="17" string="'s" />
            <token id="18" string="department" />
          </tokens>
        </chunking>
        <chunking id="2" string="which the violence is springing" type="SBAR">
          <tokens>
            <token id="29" string="which" />
            <token id="30" string="the" />
            <token id="31" string="violence" />
            <token id="32" string="is" />
            <token id="33" string="springing" />
          </tokens>
        </chunking>
        <chunking id="3" string="is springing" type="VP">
          <tokens>
            <token id="32" string="is" />
            <token id="33" string="springing" />
          </tokens>
        </chunking>
        <chunking id="4" string="springing" type="VP">
          <tokens>
            <token id="33" string="springing" />
          </tokens>
        </chunking>
        <chunking id="5" string="I" type="NP">
          <tokens>
            <token id="11" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="A last-resort mechanism '" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="last-resort" />
            <token id="3" string="mechanism" />
            <token id="4" string="'" />
          </tokens>
        </chunking>
        <chunking id="7" string="create the social conditions out there from which the violence is springing" type="VP">
          <tokens>
            <token id="22" string="create" />
            <token id="23" string="the" />
            <token id="24" string="social" />
            <token id="25" string="conditions" />
            <token id="26" string="out" />
            <token id="27" string="there" />
            <token id="28" string="from" />
            <token id="29" string="which" />
            <token id="30" string="the" />
            <token id="31" string="violence" />
            <token id="32" string="is" />
            <token id="33" string="springing" />
          </tokens>
        </chunking>
        <chunking id="8" string="the social conditions" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="social" />
            <token id="25" string="conditions" />
          </tokens>
        </chunking>
        <chunking id="9" string="Law enforcement" type="NP">
          <tokens>
            <token id="7" string="Law" />
            <token id="8" string="enforcement" />
          </tokens>
        </chunking>
        <chunking id="10" string="there" type="NP">
          <tokens>
            <token id="27" string="there" />
          </tokens>
        </chunking>
        <chunking id="11" string="did not create the social conditions out there from which the violence is springing" type="VP">
          <tokens>
            <token id="20" string="did" />
            <token id="21" string="not" />
            <token id="22" string="create" />
            <token id="23" string="the" />
            <token id="24" string="social" />
            <token id="25" string="conditions" />
            <token id="26" string="out" />
            <token id="27" string="there" />
            <token id="28" string="from" />
            <token id="29" string="which" />
            <token id="30" string="the" />
            <token id="31" string="violence" />
            <token id="32" string="is" />
            <token id="33" string="springing" />
          </tokens>
        </chunking>
        <chunking id="12" string="the sheriff 's" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="sheriff" />
            <token id="17" string="'s" />
          </tokens>
        </chunking>
        <chunking id="13" string="the sheriff 's department" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="sheriff" />
            <token id="17" string="'s" />
            <token id="18" string="department" />
          </tokens>
        </chunking>
        <chunking id="14" string="the violence" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="violence" />
          </tokens>
        </chunking>
        <chunking id="15" string="'m going beyond the sheriff 's department" type="VP">
          <tokens>
            <token id="12" string="'m" />
            <token id="13" string="going" />
            <token id="14" string="beyond" />
            <token id="15" string="the" />
            <token id="16" string="sheriff" />
            <token id="17" string="'s" />
            <token id="18" string="department" />
          </tokens>
        </chunking>
        <chunking id="16" string="he" type="NP">
          <tokens>
            <token id="36" string="he" />
          </tokens>
        </chunking>
        <chunking id="17" string="said" type="VP">
          <tokens>
            <token id="37" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">mechanism</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">mechanism</governor>
          <dependent id="2">last-resort</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="37">said</governor>
          <dependent id="3">mechanism</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">enforcement</governor>
          <dependent id="7">Law</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">create</governor>
          <dependent id="8">enforcement</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">going</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">going</governor>
          <dependent id="11">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">going</governor>
          <dependent id="12">'m</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="22">create</governor>
          <dependent id="13">going</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">department</governor>
          <dependent id="14">beyond</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">sheriff</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="18">department</governor>
          <dependent id="16">sheriff</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">sheriff</governor>
          <dependent id="17">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">going</governor>
          <dependent id="18">department</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="22">create</governor>
          <dependent id="20">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="22">create</governor>
          <dependent id="21">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="37">said</governor>
          <dependent id="22">create</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">conditions</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">conditions</governor>
          <dependent id="24">social</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">create</governor>
          <dependent id="25">conditions</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">there</governor>
          <dependent id="26">out</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">create</governor>
          <dependent id="27">there</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="33">springing</governor>
          <dependent id="28">from</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="33">springing</governor>
          <dependent id="29">which</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">violence</governor>
          <dependent id="30">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="33">springing</governor>
          <dependent id="31">violence</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="33">springing</governor>
          <dependent id="32">is</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="22">create</governor>
          <dependent id="33">springing</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="37">said</governor>
          <dependent id="36">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="37">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="violence" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="31" string="violence" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="31" has_coreference="true">
      <content>&amp;quot;People are looking at the criminal justice system today as being the linchpins of government. . . . (But) We&amp;apost;re a last-resort mechanism when other kinder and gentler processes fail in our society.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="People" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="looking" lemma="look" stem="look" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="criminal" lemma="criminal" stem="crimin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="justice" lemma="justice" stem="justic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="system" lemma="system" stem="system" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="today" lemma="today" stem="todai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="11" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="being" lemma="be" stem="be" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="linchpins" lemma="linchpin" stem="linchpin" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="government" lemma="government" stem="govern" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string=". . . ." lemma="..." stem=". . . ." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="'re" lemma="be" stem="'re" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="last-resort" lemma="last-resort" stem="last-resort" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="mechanism" lemma="mechanism" stem="mechan" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="kinder" lemma="kinder" stem="kinder" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="gentler" lemma="gentler" stem="gentler" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="processes" lemma="process" stem="process" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="fail" lemma="fail" stem="fail" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="our" lemma="we" stem="our" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="35" string="society" lemma="society" stem="societi" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (NNS People)) (VP (VBP are) (S (VP (VBG looking) (PP (IN at) (NP (DT the) (JJ criminal) (NN justice) (NN system))) (NP-TMP (NN today)) (PP (IN as) (S (VP (VBG being) (NP (NP (DT the) (NNS linchpins)) (PP (IN of) (NP (NN government))))))))) (: ...) (S (-LRB- -LRB-) (NP (CC But)) (-RRB- -RRB-) (NP (NP (PRP We)) (SBAR (S (VP (VBP 're) (NP (NP (DT a) (JJ last-resort) (NN mechanism)) (SBAR (WHADVP (WRB when)) (S (NP (NP (JJ other) (JJR kinder)) (CC and) (NP (JJR gentler) (NNS processes))) (VP (VBP fail) (PP (IN in) (NP (PRP$ our) (NN society))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="other kinder and gentler processes" type="NP">
          <tokens>
            <token id="27" string="other" />
            <token id="28" string="kinder" />
            <token id="29" string="and" />
            <token id="30" string="gentler" />
            <token id="31" string="processes" />
          </tokens>
        </chunking>
        <chunking id="2" string="But" type="NP">
          <tokens>
            <token id="19" string="But" />
          </tokens>
        </chunking>
        <chunking id="3" string="are looking at the criminal justice system today as being the linchpins of government ... -LRB- But -RRB- We 're a last-resort mechanism when other kinder and gentler processes fail in our society" type="VP">
          <tokens>
            <token id="3" string="are" />
            <token id="4" string="looking" />
            <token id="5" string="at" />
            <token id="6" string="the" />
            <token id="7" string="criminal" />
            <token id="8" string="justice" />
            <token id="9" string="system" />
            <token id="10" string="today" />
            <token id="11" string="as" />
            <token id="12" string="being" />
            <token id="13" string="the" />
            <token id="14" string="linchpins" />
            <token id="15" string="of" />
            <token id="16" string="government" />
            <token id="17" string=". . . ." />
            <token id="18" string="(" />
            <token id="19" string="But" />
            <token id="20" string=")" />
            <token id="21" string="We" />
            <token id="22" string="'re" />
            <token id="23" string="a" />
            <token id="24" string="last-resort" />
            <token id="25" string="mechanism" />
            <token id="26" string="when" />
            <token id="27" string="other" />
            <token id="28" string="kinder" />
            <token id="29" string="and" />
            <token id="30" string="gentler" />
            <token id="31" string="processes" />
            <token id="32" string="fail" />
            <token id="33" string="in" />
            <token id="34" string="our" />
            <token id="35" string="society" />
          </tokens>
        </chunking>
        <chunking id="4" string="a last-resort mechanism" type="NP">
          <tokens>
            <token id="23" string="a" />
            <token id="24" string="last-resort" />
            <token id="25" string="mechanism" />
          </tokens>
        </chunking>
        <chunking id="5" string="fail in our society" type="VP">
          <tokens>
            <token id="32" string="fail" />
            <token id="33" string="in" />
            <token id="34" string="our" />
            <token id="35" string="society" />
          </tokens>
        </chunking>
        <chunking id="6" string="the linchpins of government" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="linchpins" />
            <token id="15" string="of" />
            <token id="16" string="government" />
          </tokens>
        </chunking>
        <chunking id="7" string="our society" type="NP">
          <tokens>
            <token id="34" string="our" />
            <token id="35" string="society" />
          </tokens>
        </chunking>
        <chunking id="8" string="People" type="NP">
          <tokens>
            <token id="2" string="People" />
          </tokens>
        </chunking>
        <chunking id="9" string="looking at the criminal justice system today as being the linchpins of government" type="VP">
          <tokens>
            <token id="4" string="looking" />
            <token id="5" string="at" />
            <token id="6" string="the" />
            <token id="7" string="criminal" />
            <token id="8" string="justice" />
            <token id="9" string="system" />
            <token id="10" string="today" />
            <token id="11" string="as" />
            <token id="12" string="being" />
            <token id="13" string="the" />
            <token id="14" string="linchpins" />
            <token id="15" string="of" />
            <token id="16" string="government" />
          </tokens>
        </chunking>
        <chunking id="10" string="other kinder" type="NP">
          <tokens>
            <token id="27" string="other" />
            <token id="28" string="kinder" />
          </tokens>
        </chunking>
        <chunking id="11" string="We" type="NP">
          <tokens>
            <token id="21" string="We" />
          </tokens>
        </chunking>
        <chunking id="12" string="a last-resort mechanism when other kinder and gentler processes fail in our society" type="NP">
          <tokens>
            <token id="23" string="a" />
            <token id="24" string="last-resort" />
            <token id="25" string="mechanism" />
            <token id="26" string="when" />
            <token id="27" string="other" />
            <token id="28" string="kinder" />
            <token id="29" string="and" />
            <token id="30" string="gentler" />
            <token id="31" string="processes" />
            <token id="32" string="fail" />
            <token id="33" string="in" />
            <token id="34" string="our" />
            <token id="35" string="society" />
          </tokens>
        </chunking>
        <chunking id="13" string="when" type="WHADVP">
          <tokens>
            <token id="26" string="when" />
          </tokens>
        </chunking>
        <chunking id="14" string="government" type="NP">
          <tokens>
            <token id="16" string="government" />
          </tokens>
        </chunking>
        <chunking id="15" string="We 're a last-resort mechanism when other kinder and gentler processes fail in our society" type="NP">
          <tokens>
            <token id="21" string="We" />
            <token id="22" string="'re" />
            <token id="23" string="a" />
            <token id="24" string="last-resort" />
            <token id="25" string="mechanism" />
            <token id="26" string="when" />
            <token id="27" string="other" />
            <token id="28" string="kinder" />
            <token id="29" string="and" />
            <token id="30" string="gentler" />
            <token id="31" string="processes" />
            <token id="32" string="fail" />
            <token id="33" string="in" />
            <token id="34" string="our" />
            <token id="35" string="society" />
          </tokens>
        </chunking>
        <chunking id="16" string="being the linchpins of government" type="VP">
          <tokens>
            <token id="12" string="being" />
            <token id="13" string="the" />
            <token id="14" string="linchpins" />
            <token id="15" string="of" />
            <token id="16" string="government" />
          </tokens>
        </chunking>
        <chunking id="17" string="the criminal justice system" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="criminal" />
            <token id="8" string="justice" />
            <token id="9" string="system" />
          </tokens>
        </chunking>
        <chunking id="18" string="the linchpins" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="linchpins" />
          </tokens>
        </chunking>
        <chunking id="19" string="gentler processes" type="NP">
          <tokens>
            <token id="30" string="gentler" />
            <token id="31" string="processes" />
          </tokens>
        </chunking>
        <chunking id="20" string="'re a last-resort mechanism when other kinder and gentler processes fail in our society" type="SBAR">
          <tokens>
            <token id="22" string="'re" />
            <token id="23" string="a" />
            <token id="24" string="last-resort" />
            <token id="25" string="mechanism" />
            <token id="26" string="when" />
            <token id="27" string="other" />
            <token id="28" string="kinder" />
            <token id="29" string="and" />
            <token id="30" string="gentler" />
            <token id="31" string="processes" />
            <token id="32" string="fail" />
            <token id="33" string="in" />
            <token id="34" string="our" />
            <token id="35" string="society" />
          </tokens>
        </chunking>
        <chunking id="21" string="when other kinder and gentler processes fail in our society" type="SBAR">
          <tokens>
            <token id="26" string="when" />
            <token id="27" string="other" />
            <token id="28" string="kinder" />
            <token id="29" string="and" />
            <token id="30" string="gentler" />
            <token id="31" string="processes" />
            <token id="32" string="fail" />
            <token id="33" string="in" />
            <token id="34" string="our" />
            <token id="35" string="society" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">are</governor>
          <dependent id="2">People</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">are</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">are</governor>
          <dependent id="4">looking</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">system</governor>
          <dependent id="5">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">system</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">system</governor>
          <dependent id="7">criminal</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">system</governor>
          <dependent id="8">justice</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">looking</governor>
          <dependent id="9">system</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="4">looking</governor>
          <dependent id="10">today</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">linchpins</governor>
          <dependent id="11">as</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">linchpins</governor>
          <dependent id="12">being</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">linchpins</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">looking</governor>
          <dependent id="14">linchpins</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">government</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">linchpins</governor>
          <dependent id="16">government</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="21">We</governor>
          <dependent id="19">But</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="3">are</governor>
          <dependent id="21">We</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="25">mechanism</governor>
          <dependent id="22">'re</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">mechanism</governor>
          <dependent id="23">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">mechanism</governor>
          <dependent id="24">last-resort</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="21">We</governor>
          <dependent id="25">mechanism</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="32">fail</governor>
          <dependent id="26">when</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">kinder</governor>
          <dependent id="27">other</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="32">fail</governor>
          <dependent id="28">kinder</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="28">kinder</governor>
          <dependent id="29">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">processes</governor>
          <dependent id="30">gentler</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="28">kinder</governor>
          <dependent id="31">processes</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="25">mechanism</governor>
          <dependent id="32">fail</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">society</governor>
          <dependent id="33">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="35">society</governor>
          <dependent id="34">our</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">fail</governor>
          <dependent id="35">society</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="today" type="DATE" score="0.0">
          <tokens>
            <token id="10" string="today" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="32" has_coreference="true">
      <content>And fail they have.&amp;quot;</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="fail" lemma="fail" stem="fail" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC And) (S (VP (VBP fail) (NP (PRP they)))) (VP (VBP have)) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="fail they" type="VP">
          <tokens>
            <token id="2" string="fail" />
            <token id="3" string="they" />
          </tokens>
        </chunking>
        <chunking id="2" string="they" type="NP">
          <tokens>
            <token id="3" string="they" />
          </tokens>
        </chunking>
        <chunking id="3" string="have" type="VP">
          <tokens>
            <token id="4" string="have" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="4">have</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="csubj">
          <governor id="4">have</governor>
          <dependent id="2">fail</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">fail</governor>
          <dependent id="3">they</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">have</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="33" has_coreference="true">
      <content>; Block pointed to social ills including high drop-out and illiteracy rates, &amp;quot;young people who are raising themselves,&amp;quot; and a county jail system that is &amp;quot;perhaps the major houser of mentally ill people in our society in this nation.&amp;quot;</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="Block" lemma="Block" stem="block" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="pointed" lemma="point" stem="point" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="social" lemma="social" stem="social" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="ills" lemma="ill" stem="ill" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="including" lemma="include" stem="includ" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="high" lemma="high" stem="high" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="drop-out" lemma="drop-out" stem="drop-out" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="illiteracy" lemma="illiteracy" stem="illiteraci" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="rates" lemma="rate" stem="rate" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="young" lemma="young" stem="young" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="raising" lemma="raise" stem="rais" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="themselves" lemma="themselves" stem="themselv" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="county" lemma="county" stem="counti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="jail" lemma="jail" stem="jail" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="system" lemma="system" stem="system" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="perhaps" lemma="perhaps" stem="perhap" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="major" lemma="major" stem="major" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="houser" lemma="houser" stem="houser" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="mentally" lemma="mentally" stem="mental" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="ill" lemma="ill" stem="ill" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="our" lemma="we" stem="our" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="41" string="society" lemma="society" stem="societi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="nation" lemma="nation" stem="nation" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRN (: ;) (NP (NNP Block)))) (VP (VBD pointed) (PP (TO to) (NP (JJ social) (NNS ills))) (PP (VBG including) (NP (NP (JJ high) (JJ drop-out) (CC and) (NN illiteracy) (NNS rates)) (, ,) (`` ``) (NP (NP (JJ young) (NNS people)) (SBAR (WHNP (WP who)) (S (VP (VBP are) (VP (VBG raising) (NP (PRP themselves))))))))))) (, ,) ('' '') (CC and) (S (NP (NP (DT a) (NN county) (NN jail) (NN system)) (SBAR (WHNP (WDT that)) (S (VP (VBZ is) (`` ``) (ADVP (RB perhaps)) (NP (NP (DT the) (JJ major) (NN houser)) (PP (IN of) (NP (NP (ADJP (RB mentally) (JJ ill)) (NNS people)) (PP (IN in) (NP (PRP$ our) (NN society)))))))))) (PP (IN in) (NP (DT this) (NN nation)))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="raising themselves" type="VP">
          <tokens>
            <token id="19" string="raising" />
            <token id="20" string="themselves" />
          </tokens>
        </chunking>
        <chunking id="2" string="mentally ill people in our society" type="NP">
          <tokens>
            <token id="36" string="mentally" />
            <token id="37" string="ill" />
            <token id="38" string="people" />
            <token id="39" string="in" />
            <token id="40" string="our" />
            <token id="41" string="society" />
          </tokens>
        </chunking>
        <chunking id="3" string="a county jail system" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="county" />
            <token id="26" string="jail" />
            <token id="27" string="system" />
          </tokens>
        </chunking>
        <chunking id="4" string="pointed to social ills including high drop-out and illiteracy rates , `` young people who are raising themselves" type="VP">
          <tokens>
            <token id="3" string="pointed" />
            <token id="4" string="to" />
            <token id="5" string="social" />
            <token id="6" string="ills" />
            <token id="7" string="including" />
            <token id="8" string="high" />
            <token id="9" string="drop-out" />
            <token id="10" string="and" />
            <token id="11" string="illiteracy" />
            <token id="12" string="rates" />
            <token id="13" string="," />
            <token id="14" string="&quot;" />
            <token id="15" string="young" />
            <token id="16" string="people" />
            <token id="17" string="who" />
            <token id="18" string="are" />
            <token id="19" string="raising" />
            <token id="20" string="themselves" />
          </tokens>
        </chunking>
        <chunking id="5" string="are raising themselves" type="VP">
          <tokens>
            <token id="18" string="are" />
            <token id="19" string="raising" />
            <token id="20" string="themselves" />
          </tokens>
        </chunking>
        <chunking id="6" string="our society" type="NP">
          <tokens>
            <token id="40" string="our" />
            <token id="41" string="society" />
          </tokens>
        </chunking>
        <chunking id="7" string="high drop-out and illiteracy rates , `` young people who are raising themselves" type="NP">
          <tokens>
            <token id="8" string="high" />
            <token id="9" string="drop-out" />
            <token id="10" string="and" />
            <token id="11" string="illiteracy" />
            <token id="12" string="rates" />
            <token id="13" string="," />
            <token id="14" string="&quot;" />
            <token id="15" string="young" />
            <token id="16" string="people" />
            <token id="17" string="who" />
            <token id="18" string="are" />
            <token id="19" string="raising" />
            <token id="20" string="themselves" />
          </tokens>
        </chunking>
        <chunking id="8" string="high drop-out and illiteracy rates" type="NP">
          <tokens>
            <token id="8" string="high" />
            <token id="9" string="drop-out" />
            <token id="10" string="and" />
            <token id="11" string="illiteracy" />
            <token id="12" string="rates" />
          </tokens>
        </chunking>
        <chunking id="9" string="young people who are raising themselves" type="NP">
          <tokens>
            <token id="15" string="young" />
            <token id="16" string="people" />
            <token id="17" string="who" />
            <token id="18" string="are" />
            <token id="19" string="raising" />
            <token id="20" string="themselves" />
          </tokens>
        </chunking>
        <chunking id="10" string="young people" type="NP">
          <tokens>
            <token id="15" string="young" />
            <token id="16" string="people" />
          </tokens>
        </chunking>
        <chunking id="11" string="is `` perhaps the major houser of mentally ill people in our society" type="VP">
          <tokens>
            <token id="29" string="is" />
            <token id="30" string="&quot;" />
            <token id="31" string="perhaps" />
            <token id="32" string="the" />
            <token id="33" string="major" />
            <token id="34" string="houser" />
            <token id="35" string="of" />
            <token id="36" string="mentally" />
            <token id="37" string="ill" />
            <token id="38" string="people" />
            <token id="39" string="in" />
            <token id="40" string="our" />
            <token id="41" string="society" />
          </tokens>
        </chunking>
        <chunking id="12" string="mentally ill people" type="NP">
          <tokens>
            <token id="36" string="mentally" />
            <token id="37" string="ill" />
            <token id="38" string="people" />
          </tokens>
        </chunking>
        <chunking id="13" string="that is `` perhaps the major houser of mentally ill people in our society" type="SBAR">
          <tokens>
            <token id="28" string="that" />
            <token id="29" string="is" />
            <token id="30" string="&quot;" />
            <token id="31" string="perhaps" />
            <token id="32" string="the" />
            <token id="33" string="major" />
            <token id="34" string="houser" />
            <token id="35" string="of" />
            <token id="36" string="mentally" />
            <token id="37" string="ill" />
            <token id="38" string="people" />
            <token id="39" string="in" />
            <token id="40" string="our" />
            <token id="41" string="society" />
          </tokens>
        </chunking>
        <chunking id="14" string="this nation" type="NP">
          <tokens>
            <token id="43" string="this" />
            <token id="44" string="nation" />
          </tokens>
        </chunking>
        <chunking id="15" string="a county jail system that is `` perhaps the major houser of mentally ill people in our society" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="county" />
            <token id="26" string="jail" />
            <token id="27" string="system" />
            <token id="28" string="that" />
            <token id="29" string="is" />
            <token id="30" string="&quot;" />
            <token id="31" string="perhaps" />
            <token id="32" string="the" />
            <token id="33" string="major" />
            <token id="34" string="houser" />
            <token id="35" string="of" />
            <token id="36" string="mentally" />
            <token id="37" string="ill" />
            <token id="38" string="people" />
            <token id="39" string="in" />
            <token id="40" string="our" />
            <token id="41" string="society" />
          </tokens>
        </chunking>
        <chunking id="16" string="the major houser" type="NP">
          <tokens>
            <token id="32" string="the" />
            <token id="33" string="major" />
            <token id="34" string="houser" />
          </tokens>
        </chunking>
        <chunking id="17" string="themselves" type="NP">
          <tokens>
            <token id="20" string="themselves" />
          </tokens>
        </chunking>
        <chunking id="18" string="; Block" type="NP">
          <tokens>
            <token id="1" string=";" />
            <token id="2" string="Block" />
          </tokens>
        </chunking>
        <chunking id="19" string="Block" type="NP">
          <tokens>
            <token id="2" string="Block" />
          </tokens>
        </chunking>
        <chunking id="20" string="who are raising themselves" type="SBAR">
          <tokens>
            <token id="17" string="who" />
            <token id="18" string="are" />
            <token id="19" string="raising" />
            <token id="20" string="themselves" />
          </tokens>
        </chunking>
        <chunking id="21" string="mentally ill" type="ADJP">
          <tokens>
            <token id="36" string="mentally" />
            <token id="37" string="ill" />
          </tokens>
        </chunking>
        <chunking id="22" string="the major houser of mentally ill people in our society" type="NP">
          <tokens>
            <token id="32" string="the" />
            <token id="33" string="major" />
            <token id="34" string="houser" />
            <token id="35" string="of" />
            <token id="36" string="mentally" />
            <token id="37" string="ill" />
            <token id="38" string="people" />
            <token id="39" string="in" />
            <token id="40" string="our" />
            <token id="41" string="society" />
          </tokens>
        </chunking>
        <chunking id="23" string="social ills" type="NP">
          <tokens>
            <token id="5" string="social" />
            <token id="6" string="ills" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">pointed</governor>
          <dependent id="2">Block</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">pointed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">ills</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">ills</governor>
          <dependent id="5">social</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">pointed</governor>
          <dependent id="6">ills</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">drop-out</governor>
          <dependent id="7">including</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">drop-out</governor>
          <dependent id="8">high</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">pointed</governor>
          <dependent id="9">drop-out</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">drop-out</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">rates</governor>
          <dependent id="11">illiteracy</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">drop-out</governor>
          <dependent id="12">rates</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">people</governor>
          <dependent id="15">young</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="9">drop-out</governor>
          <dependent id="16">people</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">raising</governor>
          <dependent id="17">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="19">raising</governor>
          <dependent id="18">are</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="16">people</governor>
          <dependent id="19">raising</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">raising</governor>
          <dependent id="20">themselves</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">pointed</governor>
          <dependent id="23">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">system</governor>
          <dependent id="24">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">system</governor>
          <dependent id="25">county</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">system</governor>
          <dependent id="26">jail</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">pointed</governor>
          <dependent id="27">system</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="34">houser</governor>
          <dependent id="28">that</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="34">houser</governor>
          <dependent id="29">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="34">houser</governor>
          <dependent id="31">perhaps</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">houser</governor>
          <dependent id="32">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="34">houser</governor>
          <dependent id="33">major</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="27">system</governor>
          <dependent id="34">houser</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">people</governor>
          <dependent id="35">of</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="37">ill</governor>
          <dependent id="36">mentally</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="38">people</governor>
          <dependent id="37">ill</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="34">houser</governor>
          <dependent id="38">people</dependent>
        </dependency>
        <dependency type="case">
          <governor id="41">society</governor>
          <dependent id="39">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="41">society</governor>
          <dependent id="40">our</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="38">people</governor>
          <dependent id="41">society</dependent>
        </dependency>
        <dependency type="case">
          <governor id="44">nation</governor>
          <dependent id="42">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="44">nation</governor>
          <dependent id="43">this</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="27">system</governor>
          <dependent id="44">nation</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="34" has_coreference="true">
      <content>; Countywide, homicides soared to 1,964 last year, compared with 1,463 five years earlier.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Countywide" lemma="Countywide" stem="countywid" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="homicides" lemma="homicide" stem="homicid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="soared" lemma="soar" stem="soar" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="1,964" lemma="1,964" stem="1,964" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="8" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="9" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="compared" lemma="compare" stem="compar" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="1,463" lemma="1,463" stem="1,463" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="14" string="five" lemma="five" stem="five" pos="CD" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="15" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="16" string="earlier" lemma="earlier" stem="earlier" pos="RBR" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (NP (NP (NNP Countywide)) (, ,) (NP (NNS homicides))) (VP (VBD soared) (PP (TO to) (NP (CD 1,964))) (NP-TMP (JJ last) (NN year)) (, ,) (PP (VBN compared) (PP (IN with) (NP (CD 1,463)) (ADVP (NP (CD five) (NNS years)) (RBR earlier))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Countywide" type="NP">
          <tokens>
            <token id="2" string="Countywide" />
          </tokens>
        </chunking>
        <chunking id="2" string="1,463" type="NP">
          <tokens>
            <token id="13" string="1,463" />
          </tokens>
        </chunking>
        <chunking id="3" string="soared to 1,964 last year , compared with 1,463 five years earlier" type="VP">
          <tokens>
            <token id="5" string="soared" />
            <token id="6" string="to" />
            <token id="7" string="1,964" />
            <token id="8" string="last" />
            <token id="9" string="year" />
            <token id="10" string="," />
            <token id="11" string="compared" />
            <token id="12" string="with" />
            <token id="13" string="1,463" />
            <token id="14" string="five" />
            <token id="15" string="years" />
            <token id="16" string="earlier" />
          </tokens>
        </chunking>
        <chunking id="4" string="1,964" type="NP">
          <tokens>
            <token id="7" string="1,964" />
          </tokens>
        </chunking>
        <chunking id="5" string="Countywide , homicides" type="NP">
          <tokens>
            <token id="2" string="Countywide" />
            <token id="3" string="," />
            <token id="4" string="homicides" />
          </tokens>
        </chunking>
        <chunking id="6" string="homicides" type="NP">
          <tokens>
            <token id="4" string="homicides" />
          </tokens>
        </chunking>
        <chunking id="7" string="five years" type="NP">
          <tokens>
            <token id="14" string="five" />
            <token id="15" string="years" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">soared</governor>
          <dependent id="2">Countywide</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">Countywide</governor>
          <dependent id="4">homicides</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">soared</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">1,964</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">soared</governor>
          <dependent id="7">1,964</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">year</governor>
          <dependent id="8">last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="5">soared</governor>
          <dependent id="9">year</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">1,463</governor>
          <dependent id="11">compared</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="11">compared</governor>
          <dependent id="12">with</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">soared</governor>
          <dependent id="13">1,463</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="15">years</governor>
          <dependent id="14">five</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="16">earlier</governor>
          <dependent id="15">years</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">1,463</governor>
          <dependent id="16">earlier</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1,463" type="NUMBER" score="0.0">
          <tokens>
            <token id="13" string="1,463" />
          </tokens>
        </entity>
        <entity id="2" string="1,964" type="NUMBER" score="0.0">
          <tokens>
            <token id="7" string="1,964" />
          </tokens>
        </entity>
        <entity id="3" string="five years earlier" type="DATE" score="0.0">
          <tokens>
            <token id="14" string="five" />
            <token id="15" string="years" />
            <token id="16" string="earlier" />
          </tokens>
        </entity>
        <entity id="4" string="last year" type="DATE" score="0.0">
          <tokens>
            <token id="8" string="last" />
            <token id="9" string="year" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="35" has_coreference="true">
      <content>There are 950 known street gangs with more than 99,300 members in the county, according to the sheriff&amp;apost;s department.</content>
      <tokens>
        <token id="1" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="950" lemma="950" stem="950" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="4" string="known" lemma="known" stem="known" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="street" lemma="street" stem="street" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="gangs" lemma="gang" stem="gang" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="99,300" lemma="99,300" stem="99,300" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="11" string="members" lemma="member" stem="member" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="county" lemma="county" stem="counti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="according" lemma="accord" stem="accord" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="sheriff" lemma="sheriff" stem="sheriff" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="department" lemma="department" stem="depart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP (CD 950) (JJ known) (NN street) (NNS gangs)) (PP (IN with) (NP (QP (JJR more) (IN than) (CD 99,300)) (NNS members)))) (PP (IN in) (NP (DT the) (NN county))) (, ,) (PP (VBG according) (PP (TO to) (NP (NP (DT the) (NN sheriff) (POS 's)) (NN department))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="950 known street gangs with more than 99,300 members" type="NP">
          <tokens>
            <token id="3" string="950" />
            <token id="4" string="known" />
            <token id="5" string="street" />
            <token id="6" string="gangs" />
            <token id="7" string="with" />
            <token id="8" string="more" />
            <token id="9" string="than" />
            <token id="10" string="99,300" />
            <token id="11" string="members" />
          </tokens>
        </chunking>
        <chunking id="2" string="There" type="NP">
          <tokens>
            <token id="1" string="There" />
          </tokens>
        </chunking>
        <chunking id="3" string="950 known street gangs" type="NP">
          <tokens>
            <token id="3" string="950" />
            <token id="4" string="known" />
            <token id="5" string="street" />
            <token id="6" string="gangs" />
          </tokens>
        </chunking>
        <chunking id="4" string="more than 99,300 members" type="NP">
          <tokens>
            <token id="8" string="more" />
            <token id="9" string="than" />
            <token id="10" string="99,300" />
            <token id="11" string="members" />
          </tokens>
        </chunking>
        <chunking id="5" string="the sheriff 's" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="sheriff" />
            <token id="20" string="'s" />
          </tokens>
        </chunking>
        <chunking id="6" string="the sheriff 's department" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="sheriff" />
            <token id="20" string="'s" />
            <token id="21" string="department" />
          </tokens>
        </chunking>
        <chunking id="7" string="are 950 known street gangs with more than 99,300 members in the county , according to the sheriff 's department" type="VP">
          <tokens>
            <token id="2" string="are" />
            <token id="3" string="950" />
            <token id="4" string="known" />
            <token id="5" string="street" />
            <token id="6" string="gangs" />
            <token id="7" string="with" />
            <token id="8" string="more" />
            <token id="9" string="than" />
            <token id="10" string="99,300" />
            <token id="11" string="members" />
            <token id="12" string="in" />
            <token id="13" string="the" />
            <token id="14" string="county" />
            <token id="15" string="," />
            <token id="16" string="according" />
            <token id="17" string="to" />
            <token id="18" string="the" />
            <token id="19" string="sheriff" />
            <token id="20" string="'s" />
            <token id="21" string="department" />
          </tokens>
        </chunking>
        <chunking id="8" string="the county" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="county" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="2">are</governor>
          <dependent id="1">There</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">are</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="6">gangs</governor>
          <dependent id="3">950</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">gangs</governor>
          <dependent id="4">known</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">gangs</governor>
          <dependent id="5">street</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="2">are</governor>
          <dependent id="6">gangs</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">members</governor>
          <dependent id="7">with</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">99,300</governor>
          <dependent id="8">more</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="8">more</governor>
          <dependent id="9">than</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="11">members</governor>
          <dependent id="10">99,300</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">gangs</governor>
          <dependent id="11">members</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">county</governor>
          <dependent id="12">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">county</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">are</governor>
          <dependent id="14">county</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">department</governor>
          <dependent id="16">according</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="16">according</governor>
          <dependent id="17">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">sheriff</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="21">department</governor>
          <dependent id="19">sheriff</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">sheriff</governor>
          <dependent id="20">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">are</governor>
          <dependent id="21">department</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="950" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="950" />
          </tokens>
        </entity>
        <entity id="2" string="99,300" type="NUMBER" score="0.0">
          <tokens>
            <token id="10" string="99,300" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="36" has_coreference="true">
      <content>Agreeing that law enforcement is not the answer to all of society&amp;apost;s failures, critics say Block is missing the point.</content>
      <tokens>
        <token id="1" string="Agreeing" lemma="agree" stem="agree" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="law" lemma="law" stem="law" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="enforcement" lemma="enforcement" stem="enforc" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="answer" lemma="answer" stem="answer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="society" lemma="society" stem="societi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="failures" lemma="failure" stem="failur" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="critics" lemma="critic" stem="critic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="say" lemma="say" stem="sai" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="Block" lemma="Block" stem="block" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="missing" lemma="miss" stem="miss" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="point" lemma="point" stem="point" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VBG Agreeing) (SBAR (S (NP (DT that) (NN law) (NN enforcement)) (VP (VBZ is) (RB not) (NP (DT the) (NN answer)) (PP (TO to) (NP (NP (DT all)) (PP (IN of) (NP (NP (NN society) (POS 's)) (NNS failures)))))))))) (, ,) (NP (NNS critics)) (VP (VBP say) (SBAR (S (NP (NNP Block)) (VP (VBZ is) (VP (VBG missing) (NP (DT the) (NN point))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="all" type="NP">
          <tokens>
            <token id="10" string="all" />
          </tokens>
        </chunking>
        <chunking id="2" string="is missing the point" type="VP">
          <tokens>
            <token id="19" string="is" />
            <token id="20" string="missing" />
            <token id="21" string="the" />
            <token id="22" string="point" />
          </tokens>
        </chunking>
        <chunking id="3" string="society 's" type="NP">
          <tokens>
            <token id="12" string="society" />
            <token id="13" string="'s" />
          </tokens>
        </chunking>
        <chunking id="4" string="say Block is missing the point" type="VP">
          <tokens>
            <token id="17" string="say" />
            <token id="18" string="Block" />
            <token id="19" string="is" />
            <token id="20" string="missing" />
            <token id="21" string="the" />
            <token id="22" string="point" />
          </tokens>
        </chunking>
        <chunking id="5" string="that law enforcement is not the answer to all of society 's failures" type="SBAR">
          <tokens>
            <token id="2" string="that" />
            <token id="3" string="law" />
            <token id="4" string="enforcement" />
            <token id="5" string="is" />
            <token id="6" string="not" />
            <token id="7" string="the" />
            <token id="8" string="answer" />
            <token id="9" string="to" />
            <token id="10" string="all" />
            <token id="11" string="of" />
            <token id="12" string="society" />
            <token id="13" string="'s" />
            <token id="14" string="failures" />
          </tokens>
        </chunking>
        <chunking id="6" string="Agreeing that law enforcement is not the answer to all of society 's failures" type="VP">
          <tokens>
            <token id="1" string="Agreeing" />
            <token id="2" string="that" />
            <token id="3" string="law" />
            <token id="4" string="enforcement" />
            <token id="5" string="is" />
            <token id="6" string="not" />
            <token id="7" string="the" />
            <token id="8" string="answer" />
            <token id="9" string="to" />
            <token id="10" string="all" />
            <token id="11" string="of" />
            <token id="12" string="society" />
            <token id="13" string="'s" />
            <token id="14" string="failures" />
          </tokens>
        </chunking>
        <chunking id="7" string="society 's failures" type="NP">
          <tokens>
            <token id="12" string="society" />
            <token id="13" string="'s" />
            <token id="14" string="failures" />
          </tokens>
        </chunking>
        <chunking id="8" string="the point" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="point" />
          </tokens>
        </chunking>
        <chunking id="9" string="that law enforcement" type="NP">
          <tokens>
            <token id="2" string="that" />
            <token id="3" string="law" />
            <token id="4" string="enforcement" />
          </tokens>
        </chunking>
        <chunking id="10" string="missing the point" type="VP">
          <tokens>
            <token id="20" string="missing" />
            <token id="21" string="the" />
            <token id="22" string="point" />
          </tokens>
        </chunking>
        <chunking id="11" string="the answer" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="answer" />
          </tokens>
        </chunking>
        <chunking id="12" string="critics" type="NP">
          <tokens>
            <token id="16" string="critics" />
          </tokens>
        </chunking>
        <chunking id="13" string="Block is missing the point" type="SBAR">
          <tokens>
            <token id="18" string="Block" />
            <token id="19" string="is" />
            <token id="20" string="missing" />
            <token id="21" string="the" />
            <token id="22" string="point" />
          </tokens>
        </chunking>
        <chunking id="14" string="all of society 's failures" type="NP">
          <tokens>
            <token id="10" string="all" />
            <token id="11" string="of" />
            <token id="12" string="society" />
            <token id="13" string="'s" />
            <token id="14" string="failures" />
          </tokens>
        </chunking>
        <chunking id="15" string="Block" type="NP">
          <tokens>
            <token id="18" string="Block" />
          </tokens>
        </chunking>
        <chunking id="16" string="is not the answer to all of society 's failures" type="VP">
          <tokens>
            <token id="5" string="is" />
            <token id="6" string="not" />
            <token id="7" string="the" />
            <token id="8" string="answer" />
            <token id="9" string="to" />
            <token id="10" string="all" />
            <token id="11" string="of" />
            <token id="12" string="society" />
            <token id="13" string="'s" />
            <token id="14" string="failures" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advcl">
          <governor id="17">say</governor>
          <dependent id="1">Agreeing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">enforcement</governor>
          <dependent id="2">that</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">enforcement</governor>
          <dependent id="3">law</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">answer</governor>
          <dependent id="4">enforcement</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">answer</governor>
          <dependent id="5">is</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="8">answer</governor>
          <dependent id="6">not</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">answer</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="1">Agreeing</governor>
          <dependent id="8">answer</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">all</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">answer</governor>
          <dependent id="10">all</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">failures</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">failures</governor>
          <dependent id="12">society</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">society</governor>
          <dependent id="13">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">all</governor>
          <dependent id="14">failures</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">say</governor>
          <dependent id="16">critics</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">say</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">missing</governor>
          <dependent id="18">Block</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="20">missing</governor>
          <dependent id="19">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">say</governor>
          <dependent id="20">missing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">point</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">missing</governor>
          <dependent id="22">point</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="37" has_coreference="true">
      <content>&amp;quot;Police brutality (or) racism is not a social problem, it&amp;apost;s a law enforcement lack of leadership,&amp;quot; the Hoover Institution&amp;apost;s McNamara said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Police" lemma="police" stem="polic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="brutality" lemma="brutality" stem="brutal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="racism" lemma="racism" stem="racism" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="social" lemma="social" stem="social" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="problem" lemma="problem" stem="problem" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="law" lemma="law" stem="law" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="enforcement" lemma="enforcement" stem="enforc" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="lack" lemma="lack" stem="lack" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="leadership" lemma="leadership" stem="leadership" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="25" string="Hoover" lemma="Hoover" stem="hoover" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="26" string="Institution" lemma="Institution" stem="institut" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="27" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="28" string="McNamara" lemma="McNamara" stem="mcnamara" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="29" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (S (NP (NNS Police)) (VP (NN brutality) (S (-LRB- -LRB-) (NP (CC or)) (-RRB- -RRB-) (NP (NP (NN racism)) (SBAR (S (VP (VBZ is) (RB not) (NP (DT a) (JJ social) (NN problem))))))))) (, ,) (NP (PRP it)) (VP (VBZ 's) (NP (NP (DT a) (NN law) (NN enforcement) (NN lack)) (PP (IN of) (NP (NN leadership)))))) (, ,) ('' '') (NP (NP (DT the) (NNP Hoover) (NNP Institution) (POS 's)) (NNP McNamara)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="or" type="NP">
          <tokens>
            <token id="5" string="or" />
          </tokens>
        </chunking>
        <chunking id="2" string="racism" type="NP">
          <tokens>
            <token id="7" string="racism" />
          </tokens>
        </chunking>
        <chunking id="3" string="a social problem" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="social" />
            <token id="12" string="problem" />
          </tokens>
        </chunking>
        <chunking id="4" string="the Hoover Institution 's McNamara" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="Hoover" />
            <token id="26" string="Institution" />
            <token id="27" string="'s" />
            <token id="28" string="McNamara" />
          </tokens>
        </chunking>
        <chunking id="5" string="racism is not a social problem" type="NP">
          <tokens>
            <token id="7" string="racism" />
            <token id="8" string="is" />
            <token id="9" string="not" />
            <token id="10" string="a" />
            <token id="11" string="social" />
            <token id="12" string="problem" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="14" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="a law enforcement lack of leadership" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="law" />
            <token id="18" string="enforcement" />
            <token id="19" string="lack" />
            <token id="20" string="of" />
            <token id="21" string="leadership" />
          </tokens>
        </chunking>
        <chunking id="8" string="Police" type="NP">
          <tokens>
            <token id="2" string="Police" />
          </tokens>
        </chunking>
        <chunking id="9" string="leadership" type="NP">
          <tokens>
            <token id="21" string="leadership" />
          </tokens>
        </chunking>
        <chunking id="10" string="brutality -LRB- or -RRB- racism is not a social problem" type="VP">
          <tokens>
            <token id="3" string="brutality" />
            <token id="4" string="(" />
            <token id="5" string="or" />
            <token id="6" string=")" />
            <token id="7" string="racism" />
            <token id="8" string="is" />
            <token id="9" string="not" />
            <token id="10" string="a" />
            <token id="11" string="social" />
            <token id="12" string="problem" />
          </tokens>
        </chunking>
        <chunking id="11" string="a law enforcement lack" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="law" />
            <token id="18" string="enforcement" />
            <token id="19" string="lack" />
          </tokens>
        </chunking>
        <chunking id="12" string="said" type="VP">
          <tokens>
            <token id="29" string="said" />
          </tokens>
        </chunking>
        <chunking id="13" string="is not a social problem" type="SBAR">
          <tokens>
            <token id="8" string="is" />
            <token id="9" string="not" />
            <token id="10" string="a" />
            <token id="11" string="social" />
            <token id="12" string="problem" />
          </tokens>
        </chunking>
        <chunking id="14" string="'s a law enforcement lack of leadership" type="VP">
          <tokens>
            <token id="15" string="'s" />
            <token id="16" string="a" />
            <token id="17" string="law" />
            <token id="18" string="enforcement" />
            <token id="19" string="lack" />
            <token id="20" string="of" />
            <token id="21" string="leadership" />
          </tokens>
        </chunking>
        <chunking id="15" string="the Hoover Institution 's" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="Hoover" />
            <token id="26" string="Institution" />
            <token id="27" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">brutality</governor>
          <dependent id="2">Police</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">lack</governor>
          <dependent id="3">brutality</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">racism</governor>
          <dependent id="5">or</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">brutality</governor>
          <dependent id="7">racism</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">problem</governor>
          <dependent id="8">is</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="12">problem</governor>
          <dependent id="9">not</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">problem</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">problem</governor>
          <dependent id="11">social</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="7">racism</governor>
          <dependent id="12">problem</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">lack</governor>
          <dependent id="14">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="19">lack</governor>
          <dependent id="15">'s</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">lack</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">lack</governor>
          <dependent id="17">law</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">lack</governor>
          <dependent id="18">enforcement</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="29">said</governor>
          <dependent id="19">lack</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">leadership</governor>
          <dependent id="20">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">lack</governor>
          <dependent id="21">leadership</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">Institution</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">Institution</governor>
          <dependent id="25">Hoover</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="28">McNamara</governor>
          <dependent id="26">Institution</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">Institution</governor>
          <dependent id="27">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">said</governor>
          <dependent id="28">McNamara</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="29">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Hoover Institution" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="25" string="Hoover" />
            <token id="26" string="Institution" />
          </tokens>
        </entity>
        <entity id="2" string="McNamara" type="PERSON" score="0.0">
          <tokens>
            <token id="28" string="McNamara" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="38" has_coreference="false">
      <content>&amp;quot;The basic goal and mission of law enforcement people is to reduce conflict in the community. . . .</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="basic" lemma="basic" stem="basic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="goal" lemma="goal" stem="goal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="mission" lemma="mission" stem="mission" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="law" lemma="law" stem="law" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="enforcement" lemma="enforcement" stem="enforc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="reduce" lemma="reduce" stem="reduc" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="conflict" lemma="conflict" stem="conflict" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="community" lemma="community" stem="commun" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string=". . ." lemma="..." stem=". . ." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (NP (DT The) (JJ basic) (NN goal) (CC and) (NN mission)) (PP (IN of) (NP (NN law) (NN enforcement) (NNS people)))) (VP (VBZ is) (S (VP (TO to) (VP (VB reduce) (NP (NN conflict)) (PP (IN in) (NP (DT the) (NN community))))))) (: ...) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="law enforcement people" type="NP">
          <tokens>
            <token id="8" string="law" />
            <token id="9" string="enforcement" />
            <token id="10" string="people" />
          </tokens>
        </chunking>
        <chunking id="2" string="The basic goal and mission of law enforcement people" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="basic" />
            <token id="4" string="goal" />
            <token id="5" string="and" />
            <token id="6" string="mission" />
            <token id="7" string="of" />
            <token id="8" string="law" />
            <token id="9" string="enforcement" />
            <token id="10" string="people" />
          </tokens>
        </chunking>
        <chunking id="3" string="is to reduce conflict in the community" type="VP">
          <tokens>
            <token id="11" string="is" />
            <token id="12" string="to" />
            <token id="13" string="reduce" />
            <token id="14" string="conflict" />
            <token id="15" string="in" />
            <token id="16" string="the" />
            <token id="17" string="community" />
          </tokens>
        </chunking>
        <chunking id="4" string="The basic goal and mission" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="basic" />
            <token id="4" string="goal" />
            <token id="5" string="and" />
            <token id="6" string="mission" />
          </tokens>
        </chunking>
        <chunking id="5" string="reduce conflict in the community" type="VP">
          <tokens>
            <token id="13" string="reduce" />
            <token id="14" string="conflict" />
            <token id="15" string="in" />
            <token id="16" string="the" />
            <token id="17" string="community" />
          </tokens>
        </chunking>
        <chunking id="6" string="to reduce conflict in the community" type="VP">
          <tokens>
            <token id="12" string="to" />
            <token id="13" string="reduce" />
            <token id="14" string="conflict" />
            <token id="15" string="in" />
            <token id="16" string="the" />
            <token id="17" string="community" />
          </tokens>
        </chunking>
        <chunking id="7" string="conflict" type="NP">
          <tokens>
            <token id="14" string="conflict" />
          </tokens>
        </chunking>
        <chunking id="8" string="the community" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="community" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">goal</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">goal</governor>
          <dependent id="3">basic</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">is</governor>
          <dependent id="4">goal</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">goal</governor>
          <dependent id="5">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">goal</governor>
          <dependent id="6">mission</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">people</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">people</governor>
          <dependent id="8">law</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">people</governor>
          <dependent id="9">enforcement</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">goal</governor>
          <dependent id="10">people</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">is</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">reduce</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="11">is</governor>
          <dependent id="13">reduce</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">reduce</governor>
          <dependent id="14">conflict</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">community</governor>
          <dependent id="15">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">community</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">reduce</governor>
          <dependent id="17">community</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="39" has_coreference="true">
      <content>The rhetoric of the Los Angeles police establishment through the years seems to have escalated conflict, not lowered it.&amp;quot;</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="rhetoric" lemma="rhetoric" stem="rhetor" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="Los" lemma="Los" stem="lo" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="6" string="Angeles" lemma="Angeles" stem="angele" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="7" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="establishment" lemma="establishment" stem="establish" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="true" is_refers="true" />
        <token id="11" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="true" />
        <token id="12" string="seems" lemma="seem" stem="seem" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="escalated" lemma="escalate" stem="escal" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="conflict" lemma="conflict" stem="conflict" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="lowered" lemma="lower" stem="lower" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NN rhetoric)) (PP (IN of) (NP (NP (DT the) (NNP Los) (NNP Angeles) (NN police) (NN establishment)) (PP (IN through) (NP (DT the) (NNS years)))))) (VP (VP (VBZ seems) (S (VP (TO to) (VP (VB have) (VP (VBN escalated) (NP (NN conflict))))))) (, ,) (RB not) (VP (VBD lowered) (NP (PRP it)))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="the years" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="years" />
          </tokens>
        </chunking>
        <chunking id="2" string="lowered it" type="VP">
          <tokens>
            <token id="19" string="lowered" />
            <token id="20" string="it" />
          </tokens>
        </chunking>
        <chunking id="3" string="The rhetoric" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="rhetoric" />
          </tokens>
        </chunking>
        <chunking id="4" string="to have escalated conflict" type="VP">
          <tokens>
            <token id="13" string="to" />
            <token id="14" string="have" />
            <token id="15" string="escalated" />
            <token id="16" string="conflict" />
          </tokens>
        </chunking>
        <chunking id="5" string="seems to have escalated conflict , not lowered it" type="VP">
          <tokens>
            <token id="12" string="seems" />
            <token id="13" string="to" />
            <token id="14" string="have" />
            <token id="15" string="escalated" />
            <token id="16" string="conflict" />
            <token id="17" string="," />
            <token id="18" string="not" />
            <token id="19" string="lowered" />
            <token id="20" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="have escalated conflict" type="VP">
          <tokens>
            <token id="14" string="have" />
            <token id="15" string="escalated" />
            <token id="16" string="conflict" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="20" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="the Los Angeles police establishment through the years" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="Los" />
            <token id="6" string="Angeles" />
            <token id="7" string="police" />
            <token id="8" string="establishment" />
            <token id="9" string="through" />
            <token id="10" string="the" />
            <token id="11" string="years" />
          </tokens>
        </chunking>
        <chunking id="9" string="The rhetoric of the Los Angeles police establishment through the years" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="rhetoric" />
            <token id="3" string="of" />
            <token id="4" string="the" />
            <token id="5" string="Los" />
            <token id="6" string="Angeles" />
            <token id="7" string="police" />
            <token id="8" string="establishment" />
            <token id="9" string="through" />
            <token id="10" string="the" />
            <token id="11" string="years" />
          </tokens>
        </chunking>
        <chunking id="10" string="the Los Angeles police establishment" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="Los" />
            <token id="6" string="Angeles" />
            <token id="7" string="police" />
            <token id="8" string="establishment" />
          </tokens>
        </chunking>
        <chunking id="11" string="seems to have escalated conflict" type="VP">
          <tokens>
            <token id="12" string="seems" />
            <token id="13" string="to" />
            <token id="14" string="have" />
            <token id="15" string="escalated" />
            <token id="16" string="conflict" />
          </tokens>
        </chunking>
        <chunking id="12" string="escalated conflict" type="VP">
          <tokens>
            <token id="15" string="escalated" />
            <token id="16" string="conflict" />
          </tokens>
        </chunking>
        <chunking id="13" string="conflict" type="NP">
          <tokens>
            <token id="16" string="conflict" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">rhetoric</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">seems</governor>
          <dependent id="2">rhetoric</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">establishment</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">establishment</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">establishment</governor>
          <dependent id="5">Los</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">establishment</governor>
          <dependent id="6">Angeles</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">establishment</governor>
          <dependent id="7">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">rhetoric</governor>
          <dependent id="8">establishment</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">years</governor>
          <dependent id="9">through</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">years</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">establishment</governor>
          <dependent id="11">years</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">seems</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">escalated</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">escalated</governor>
          <dependent id="14">have</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="12">seems</governor>
          <dependent id="15">escalated</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">escalated</governor>
          <dependent id="16">conflict</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="19">lowered</governor>
          <dependent id="18">not</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="12">seems</governor>
          <dependent id="19">lowered</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">lowered</governor>
          <dependent id="20">it</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="the years" type="DURATION" score="0.0">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="years" />
          </tokens>
        </entity>
        <entity id="2" string="Los Angeles" type="LOCATION" score="0.0">
          <tokens>
            <token id="5" string="Los" />
            <token id="6" string="Angeles" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="40" has_coreference="false">
      <content>; The FBI, Amnesty International and the county grand jury are investigating allegations about both departments.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="FBI" lemma="FBI" stem="fbi" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Amnesty" lemma="Amnesty" stem="amnesti" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="6" string="International" lemma="International" stem="internat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="county" lemma="county" stem="counti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="grand" lemma="grand" stem="grand" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="jury" lemma="jury" stem="juri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="investigating" lemma="investigate" stem="investig" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="allegations" lemma="allegation" stem="alleg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="both" lemma="both" stem="both" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="departments" lemma="department" stem="depart" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (NP (NP (DT The) (NNP FBI)) (, ,) (NP (NNP Amnesty) (NNP International)) (CC and) (NP (DT the) (NN county) (JJ grand) (NN jury))) (VP (VBP are) (VP (VBG investigating) (NP (NP (NNS allegations)) (PP (IN about) (NP (DT both) (NNS departments)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="both departments" type="NP">
          <tokens>
            <token id="16" string="both" />
            <token id="17" string="departments" />
          </tokens>
        </chunking>
        <chunking id="2" string="allegations" type="NP">
          <tokens>
            <token id="14" string="allegations" />
          </tokens>
        </chunking>
        <chunking id="3" string="investigating allegations about both departments" type="VP">
          <tokens>
            <token id="13" string="investigating" />
            <token id="14" string="allegations" />
            <token id="15" string="about" />
            <token id="16" string="both" />
            <token id="17" string="departments" />
          </tokens>
        </chunking>
        <chunking id="4" string="allegations about both departments" type="NP">
          <tokens>
            <token id="14" string="allegations" />
            <token id="15" string="about" />
            <token id="16" string="both" />
            <token id="17" string="departments" />
          </tokens>
        </chunking>
        <chunking id="5" string="Amnesty International" type="NP">
          <tokens>
            <token id="5" string="Amnesty" />
            <token id="6" string="International" />
          </tokens>
        </chunking>
        <chunking id="6" string="are investigating allegations about both departments" type="VP">
          <tokens>
            <token id="12" string="are" />
            <token id="13" string="investigating" />
            <token id="14" string="allegations" />
            <token id="15" string="about" />
            <token id="16" string="both" />
            <token id="17" string="departments" />
          </tokens>
        </chunking>
        <chunking id="7" string="The FBI , Amnesty International and the county grand jury" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="FBI" />
            <token id="4" string="," />
            <token id="5" string="Amnesty" />
            <token id="6" string="International" />
            <token id="7" string="and" />
            <token id="8" string="the" />
            <token id="9" string="county" />
            <token id="10" string="grand" />
            <token id="11" string="jury" />
          </tokens>
        </chunking>
        <chunking id="8" string="the county grand jury" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="county" />
            <token id="10" string="grand" />
            <token id="11" string="jury" />
          </tokens>
        </chunking>
        <chunking id="9" string="The FBI" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="FBI" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">FBI</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">investigating</governor>
          <dependent id="3">FBI</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">International</governor>
          <dependent id="5">Amnesty</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">FBI</governor>
          <dependent id="6">International</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">FBI</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">jury</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">jury</governor>
          <dependent id="9">county</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">jury</governor>
          <dependent id="10">grand</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">FBI</governor>
          <dependent id="11">jury</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">investigating</governor>
          <dependent id="12">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">investigating</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">investigating</governor>
          <dependent id="14">allegations</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">departments</governor>
          <dependent id="15">about</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">departments</governor>
          <dependent id="16">both</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">allegations</governor>
          <dependent id="17">departments</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Amnesty International" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="5" string="Amnesty" />
            <token id="6" string="International" />
          </tokens>
        </entity>
        <entity id="2" string="FBI" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="3" string="FBI" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="41" has_coreference="true">
      <content>But some critics are skeptical that the police culture here will change significantly.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="critics" lemma="critic" stem="critic" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="skeptical" lemma="skeptical" stem="skeptic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="culture" lemma="culture" stem="cultur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="here" lemma="here" stem="here" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="change" lemma="change" stem="chang" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="significantly" lemma="significantly" stem="significantli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (DT some) (NNS critics)) (VP (VBP are) (ADJP (JJ skeptical) (SBAR (IN that) (S (NP (DT the) (NN police) (NN culture)) (ADVP (RB here)) (VP (MD will) (VP (VB change) (ADVP (RB significantly)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="some critics" type="NP">
          <tokens>
            <token id="2" string="some" />
            <token id="3" string="critics" />
          </tokens>
        </chunking>
        <chunking id="2" string="that the police culture here will change significantly" type="SBAR">
          <tokens>
            <token id="6" string="that" />
            <token id="7" string="the" />
            <token id="8" string="police" />
            <token id="9" string="culture" />
            <token id="10" string="here" />
            <token id="11" string="will" />
            <token id="12" string="change" />
            <token id="13" string="significantly" />
          </tokens>
        </chunking>
        <chunking id="3" string="change significantly" type="VP">
          <tokens>
            <token id="12" string="change" />
            <token id="13" string="significantly" />
          </tokens>
        </chunking>
        <chunking id="4" string="the police culture" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="police" />
            <token id="9" string="culture" />
          </tokens>
        </chunking>
        <chunking id="5" string="will change significantly" type="VP">
          <tokens>
            <token id="11" string="will" />
            <token id="12" string="change" />
            <token id="13" string="significantly" />
          </tokens>
        </chunking>
        <chunking id="6" string="are skeptical that the police culture here will change significantly" type="VP">
          <tokens>
            <token id="4" string="are" />
            <token id="5" string="skeptical" />
            <token id="6" string="that" />
            <token id="7" string="the" />
            <token id="8" string="police" />
            <token id="9" string="culture" />
            <token id="10" string="here" />
            <token id="11" string="will" />
            <token id="12" string="change" />
            <token id="13" string="significantly" />
          </tokens>
        </chunking>
        <chunking id="7" string="skeptical that the police culture here will change significantly" type="ADJP">
          <tokens>
            <token id="5" string="skeptical" />
            <token id="6" string="that" />
            <token id="7" string="the" />
            <token id="8" string="police" />
            <token id="9" string="culture" />
            <token id="10" string="here" />
            <token id="11" string="will" />
            <token id="12" string="change" />
            <token id="13" string="significantly" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="5">skeptical</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">critics</governor>
          <dependent id="2">some</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">skeptical</governor>
          <dependent id="3">critics</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">skeptical</governor>
          <dependent id="4">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">skeptical</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">change</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">culture</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">culture</governor>
          <dependent id="8">police</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">change</governor>
          <dependent id="9">culture</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">change</governor>
          <dependent id="10">here</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">change</governor>
          <dependent id="11">will</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">skeptical</governor>
          <dependent id="12">change</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">change</governor>
          <dependent id="13">significantly</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="42" has_coreference="true">
      <content>&amp;apost;Window dressing&amp;apost; predicted; On the city side, they worry that the Christopher Commission recommendations will be diluted by the time the city council and voters are finished with them.</content>
      <tokens>
        <token id="1" string="'" lemma="`" stem="'" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Window" lemma="window" stem="window" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="dressing" lemma="dress" stem="dress" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="predicted" lemma="predict" stem="predict" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="On" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="city" lemma="city" stem="citi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="side" lemma="side" stem="side" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="worry" lemma="worry" stem="worri" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="Christopher" lemma="Christopher" stem="christoph" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="17" string="Commission" lemma="Commission" stem="commiss" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="18" string="recommendations" lemma="recommendation" stem="recommend" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="diluted" lemma="dilute" stem="dilut" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="city" lemma="city" stem="citi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="council" lemma="council" stem="council" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="voters" lemma="voter" stem="voter" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="30" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="finished" lemma="finish" stem="finish" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="34" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` `) (S (NP (NN Window) (S (VP (VBG dressing) ('' ')))) (VP (VBN predicted))) (: ;) (S (PP (IN On) (NP (DT the) (NN city) (NN side))) (, ,) (NP (PRP they)) (VP (VBP worry) (SBAR (IN that) (S (NP (DT the) (NNP Christopher) (NNP Commission) (NNS recommendations)) (VP (MD will) (VP (VB be) (ADJP (VBN diluted) (PP (IN by) (NP (NP (DT the) (NN time)) (SBAR (S (NP (NP (DT the) (NN city) (NN council)) (CC and) (NP (NNS voters))) (VP (VBP are) (VP (VBN finished) (PP (IN with) (NP (PRP them)))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the city council" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="city" />
            <token id="27" string="council" />
          </tokens>
        </chunking>
        <chunking id="2" string="the city council and voters" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="city" />
            <token id="27" string="council" />
            <token id="28" string="and" />
            <token id="29" string="voters" />
          </tokens>
        </chunking>
        <chunking id="3" string="voters" type="NP">
          <tokens>
            <token id="29" string="voters" />
          </tokens>
        </chunking>
        <chunking id="4" string="the Christopher Commission recommendations" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="Christopher" />
            <token id="17" string="Commission" />
            <token id="18" string="recommendations" />
          </tokens>
        </chunking>
        <chunking id="5" string="worry that the Christopher Commission recommendations will be diluted by the time the city council and voters are finished with them" type="VP">
          <tokens>
            <token id="13" string="worry" />
            <token id="14" string="that" />
            <token id="15" string="the" />
            <token id="16" string="Christopher" />
            <token id="17" string="Commission" />
            <token id="18" string="recommendations" />
            <token id="19" string="will" />
            <token id="20" string="be" />
            <token id="21" string="diluted" />
            <token id="22" string="by" />
            <token id="23" string="the" />
            <token id="24" string="time" />
            <token id="25" string="the" />
            <token id="26" string="city" />
            <token id="27" string="council" />
            <token id="28" string="and" />
            <token id="29" string="voters" />
            <token id="30" string="are" />
            <token id="31" string="finished" />
            <token id="32" string="with" />
            <token id="33" string="them" />
          </tokens>
        </chunking>
        <chunking id="6" string="the city council and voters are finished with them" type="SBAR">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="city" />
            <token id="27" string="council" />
            <token id="28" string="and" />
            <token id="29" string="voters" />
            <token id="30" string="are" />
            <token id="31" string="finished" />
            <token id="32" string="with" />
            <token id="33" string="them" />
          </tokens>
        </chunking>
        <chunking id="7" string="them" type="NP">
          <tokens>
            <token id="33" string="them" />
          </tokens>
        </chunking>
        <chunking id="8" string="diluted by the time the city council and voters are finished with them" type="ADJP">
          <tokens>
            <token id="21" string="diluted" />
            <token id="22" string="by" />
            <token id="23" string="the" />
            <token id="24" string="time" />
            <token id="25" string="the" />
            <token id="26" string="city" />
            <token id="27" string="council" />
            <token id="28" string="and" />
            <token id="29" string="voters" />
            <token id="30" string="are" />
            <token id="31" string="finished" />
            <token id="32" string="with" />
            <token id="33" string="them" />
          </tokens>
        </chunking>
        <chunking id="9" string="predicted" type="VP">
          <tokens>
            <token id="5" string="predicted" />
          </tokens>
        </chunking>
        <chunking id="10" string="they" type="NP">
          <tokens>
            <token id="12" string="they" />
          </tokens>
        </chunking>
        <chunking id="11" string="the time the city council and voters are finished with them" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="time" />
            <token id="25" string="the" />
            <token id="26" string="city" />
            <token id="27" string="council" />
            <token id="28" string="and" />
            <token id="29" string="voters" />
            <token id="30" string="are" />
            <token id="31" string="finished" />
            <token id="32" string="with" />
            <token id="33" string="them" />
          </tokens>
        </chunking>
        <chunking id="12" string="will be diluted by the time the city council and voters are finished with them" type="VP">
          <tokens>
            <token id="19" string="will" />
            <token id="20" string="be" />
            <token id="21" string="diluted" />
            <token id="22" string="by" />
            <token id="23" string="the" />
            <token id="24" string="time" />
            <token id="25" string="the" />
            <token id="26" string="city" />
            <token id="27" string="council" />
            <token id="28" string="and" />
            <token id="29" string="voters" />
            <token id="30" string="are" />
            <token id="31" string="finished" />
            <token id="32" string="with" />
            <token id="33" string="them" />
          </tokens>
        </chunking>
        <chunking id="13" string="be diluted by the time the city council and voters are finished with them" type="VP">
          <tokens>
            <token id="20" string="be" />
            <token id="21" string="diluted" />
            <token id="22" string="by" />
            <token id="23" string="the" />
            <token id="24" string="time" />
            <token id="25" string="the" />
            <token id="26" string="city" />
            <token id="27" string="council" />
            <token id="28" string="and" />
            <token id="29" string="voters" />
            <token id="30" string="are" />
            <token id="31" string="finished" />
            <token id="32" string="with" />
            <token id="33" string="them" />
          </tokens>
        </chunking>
        <chunking id="14" string="dressing '" type="VP">
          <tokens>
            <token id="3" string="dressing" />
            <token id="4" string="'" />
          </tokens>
        </chunking>
        <chunking id="15" string="the city side" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="city" />
            <token id="10" string="side" />
          </tokens>
        </chunking>
        <chunking id="16" string="the time" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="time" />
          </tokens>
        </chunking>
        <chunking id="17" string="Window dressing '" type="NP">
          <tokens>
            <token id="2" string="Window" />
            <token id="3" string="dressing" />
            <token id="4" string="'" />
          </tokens>
        </chunking>
        <chunking id="18" string="that the Christopher Commission recommendations will be diluted by the time the city council and voters are finished with them" type="SBAR">
          <tokens>
            <token id="14" string="that" />
            <token id="15" string="the" />
            <token id="16" string="Christopher" />
            <token id="17" string="Commission" />
            <token id="18" string="recommendations" />
            <token id="19" string="will" />
            <token id="20" string="be" />
            <token id="21" string="diluted" />
            <token id="22" string="by" />
            <token id="23" string="the" />
            <token id="24" string="time" />
            <token id="25" string="the" />
            <token id="26" string="city" />
            <token id="27" string="council" />
            <token id="28" string="and" />
            <token id="29" string="voters" />
            <token id="30" string="are" />
            <token id="31" string="finished" />
            <token id="32" string="with" />
            <token id="33" string="them" />
          </tokens>
        </chunking>
        <chunking id="19" string="finished with them" type="VP">
          <tokens>
            <token id="31" string="finished" />
            <token id="32" string="with" />
            <token id="33" string="them" />
          </tokens>
        </chunking>
        <chunking id="20" string="are finished with them" type="VP">
          <tokens>
            <token id="30" string="are" />
            <token id="31" string="finished" />
            <token id="32" string="with" />
            <token id="33" string="them" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">predicted</governor>
          <dependent id="2">Window</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="2">Window</governor>
          <dependent id="3">dressing</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">predicted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">side</governor>
          <dependent id="7">On</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">side</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">side</governor>
          <dependent id="9">city</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">worry</governor>
          <dependent id="10">side</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">worry</governor>
          <dependent id="12">they</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="5">predicted</governor>
          <dependent id="13">worry</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">diluted</governor>
          <dependent id="14">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">recommendations</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">recommendations</governor>
          <dependent id="16">Christopher</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">recommendations</governor>
          <dependent id="17">Commission</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="21">diluted</governor>
          <dependent id="18">recommendations</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">diluted</governor>
          <dependent id="19">will</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="21">diluted</governor>
          <dependent id="20">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">worry</governor>
          <dependent id="21">diluted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">time</governor>
          <dependent id="22">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">time</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">diluted</governor>
          <dependent id="24">time</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">council</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">council</governor>
          <dependent id="26">city</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="31">finished</governor>
          <dependent id="27">council</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="27">council</governor>
          <dependent id="28">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="27">council</governor>
          <dependent id="29">voters</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="31">finished</governor>
          <dependent id="30">are</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="24">time</governor>
          <dependent id="31">finished</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">them</governor>
          <dependent id="32">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">finished</governor>
          <dependent id="33">them</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Christopher Commission" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="16" string="Christopher" />
            <token id="17" string="Commission" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="43" has_coreference="true">
      <content>Besides a new police chief, the ACLU&amp;apost;s Hicks predicted only &amp;quot;some window dressing and some moderate changes made to training.&amp;quot;</content>
      <tokens>
        <token id="1" string="Besides" lemma="besides" stem="besid" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="new" lemma="new" stem="new" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="chief" lemma="chief" stem="chief" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="ACLU" lemma="ACLU" stem="aclu" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="9" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="Hicks" lemma="Hicks" stem="hick" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="predicted" lemma="predict" stem="predict" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="window" lemma="window" stem="window" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="dressing" lemma="dress" stem="dress" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="moderate" lemma="moderate" stem="moder" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="changes" lemma="change" stem="chang" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="made" lemma="make" stem="made" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="training" lemma="training" stem="train" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN Besides) (NP (DT a) (JJ new) (NN police) (NN chief))) (, ,) (NP (NP (DT the) (NNP ACLU) (POS 's)) (NNP Hicks)) (VP (VBD predicted) (ADVP (RB only)) (NP (NP (`` ``) (NP (DT some) (NN window)) (VP (VBG dressing))) (CC and) (NP (NP (DT some) (JJ moderate) (NNS changes)) (VP (VBN made) (PP (TO to) (NP (NN training))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="predicted only `` some window dressing and some moderate changes made to training" type="VP">
          <tokens>
            <token id="11" string="predicted" />
            <token id="12" string="only" />
            <token id="13" string="&quot;" />
            <token id="14" string="some" />
            <token id="15" string="window" />
            <token id="16" string="dressing" />
            <token id="17" string="and" />
            <token id="18" string="some" />
            <token id="19" string="moderate" />
            <token id="20" string="changes" />
            <token id="21" string="made" />
            <token id="22" string="to" />
            <token id="23" string="training" />
          </tokens>
        </chunking>
        <chunking id="2" string="the ACLU 's Hicks" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="ACLU" />
            <token id="9" string="'s" />
            <token id="10" string="Hicks" />
          </tokens>
        </chunking>
        <chunking id="3" string="a new police chief" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="new" />
            <token id="4" string="police" />
            <token id="5" string="chief" />
          </tokens>
        </chunking>
        <chunking id="4" string="dressing" type="VP">
          <tokens>
            <token id="16" string="dressing" />
          </tokens>
        </chunking>
        <chunking id="5" string="some moderate changes made to training" type="NP">
          <tokens>
            <token id="18" string="some" />
            <token id="19" string="moderate" />
            <token id="20" string="changes" />
            <token id="21" string="made" />
            <token id="22" string="to" />
            <token id="23" string="training" />
          </tokens>
        </chunking>
        <chunking id="6" string="some moderate changes" type="NP">
          <tokens>
            <token id="18" string="some" />
            <token id="19" string="moderate" />
            <token id="20" string="changes" />
          </tokens>
        </chunking>
        <chunking id="7" string="training" type="NP">
          <tokens>
            <token id="23" string="training" />
          </tokens>
        </chunking>
        <chunking id="8" string="some window" type="NP">
          <tokens>
            <token id="14" string="some" />
            <token id="15" string="window" />
          </tokens>
        </chunking>
        <chunking id="9" string="the ACLU 's" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="ACLU" />
            <token id="9" string="'s" />
          </tokens>
        </chunking>
        <chunking id="10" string="`` some window dressing and some moderate changes made to training" type="NP">
          <tokens>
            <token id="13" string="&quot;" />
            <token id="14" string="some" />
            <token id="15" string="window" />
            <token id="16" string="dressing" />
            <token id="17" string="and" />
            <token id="18" string="some" />
            <token id="19" string="moderate" />
            <token id="20" string="changes" />
            <token id="21" string="made" />
            <token id="22" string="to" />
            <token id="23" string="training" />
          </tokens>
        </chunking>
        <chunking id="11" string="made to training" type="VP">
          <tokens>
            <token id="21" string="made" />
            <token id="22" string="to" />
            <token id="23" string="training" />
          </tokens>
        </chunking>
        <chunking id="12" string="`` some window dressing" type="NP">
          <tokens>
            <token id="13" string="&quot;" />
            <token id="14" string="some" />
            <token id="15" string="window" />
            <token id="16" string="dressing" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="5">chief</governor>
          <dependent id="1">Besides</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">chief</governor>
          <dependent id="2">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">chief</governor>
          <dependent id="3">new</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">chief</governor>
          <dependent id="4">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">predicted</governor>
          <dependent id="5">chief</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">ACLU</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">Hicks</governor>
          <dependent id="8">ACLU</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">ACLU</governor>
          <dependent id="9">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">predicted</governor>
          <dependent id="10">Hicks</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">predicted</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">predicted</governor>
          <dependent id="12">only</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">window</governor>
          <dependent id="14">some</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">predicted</governor>
          <dependent id="15">window</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="15">window</governor>
          <dependent id="16">dressing</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">window</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">changes</governor>
          <dependent id="18">some</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">changes</governor>
          <dependent id="19">moderate</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">window</governor>
          <dependent id="20">changes</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="20">changes</governor>
          <dependent id="21">made</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">training</governor>
          <dependent id="22">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">made</governor>
          <dependent id="23">training</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="ACLU" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="8" string="ACLU" />
          </tokens>
        </entity>
        <entity id="2" string="Hicks" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Hicks" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="44" has_coreference="true">
      <content>; On the county side, critics say Block&amp;apost;s position as an elected official insulates him from the kind of independent review the city was able to order for the police department.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="On" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="county" lemma="county" stem="counti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="side" lemma="side" stem="side" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="critics" lemma="critic" stem="critic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="say" lemma="say" stem="sai" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="Block" lemma="Block" stem="block" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="position" lemma="position" stem="posit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="elected" lemma="elect" stem="elect" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="official" lemma="official" stem="offici" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="insulates" lemma="insulate" stem="insul" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="kind" lemma="kind" stem="kind" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="independent" lemma="independent" stem="independ" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="23" string="review" lemma="review" stem="review" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="city" lemma="city" stem="citi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="26" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="able" lemma="able" stem="abl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="order" lemma="order" stem="order" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="department" lemma="department" stem="depart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (PP (IN On) (NP (DT the) (NN county) (NN side))) (, ,) (NP (NNS critics)) (VP (VBP say) (SBAR (S (NP (NP (NP (NNP Block) (POS 's)) (NN position)) (PP (IN as) (NP (DT an) (VBN elected) (NN official)))) (VP (VBZ insulates) (NP (PRP him)) (PP (IN from) (NP (NP (DT the) (NN kind)) (PP (IN of) (NP (NP (JJ independent) (NN review)) (SBAR (S (NP (DT the) (NN city)) (VP (VBD was) (ADJP (JJ able) (S (VP (TO to) (VP (VB order) (PP (IN for) (NP (DT the) (NN police) (NN department)))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="independent review the city was able to order for the police department" type="NP">
          <tokens>
            <token id="22" string="independent" />
            <token id="23" string="review" />
            <token id="24" string="the" />
            <token id="25" string="city" />
            <token id="26" string="was" />
            <token id="27" string="able" />
            <token id="28" string="to" />
            <token id="29" string="order" />
            <token id="30" string="for" />
            <token id="31" string="the" />
            <token id="32" string="police" />
            <token id="33" string="department" />
          </tokens>
        </chunking>
        <chunking id="2" string="to order for the police department" type="VP">
          <tokens>
            <token id="28" string="to" />
            <token id="29" string="order" />
            <token id="30" string="for" />
            <token id="31" string="the" />
            <token id="32" string="police" />
            <token id="33" string="department" />
          </tokens>
        </chunking>
        <chunking id="3" string="Block 's" type="NP">
          <tokens>
            <token id="9" string="Block" />
            <token id="10" string="'s" />
          </tokens>
        </chunking>
        <chunking id="4" string="the city" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="city" />
          </tokens>
        </chunking>
        <chunking id="5" string="Block 's position" type="NP">
          <tokens>
            <token id="9" string="Block" />
            <token id="10" string="'s" />
            <token id="11" string="position" />
          </tokens>
        </chunking>
        <chunking id="6" string="order for the police department" type="VP">
          <tokens>
            <token id="29" string="order" />
            <token id="30" string="for" />
            <token id="31" string="the" />
            <token id="32" string="police" />
            <token id="33" string="department" />
          </tokens>
        </chunking>
        <chunking id="7" string="was able to order for the police department" type="VP">
          <tokens>
            <token id="26" string="was" />
            <token id="27" string="able" />
            <token id="28" string="to" />
            <token id="29" string="order" />
            <token id="30" string="for" />
            <token id="31" string="the" />
            <token id="32" string="police" />
            <token id="33" string="department" />
          </tokens>
        </chunking>
        <chunking id="8" string="the police department" type="NP">
          <tokens>
            <token id="31" string="the" />
            <token id="32" string="police" />
            <token id="33" string="department" />
          </tokens>
        </chunking>
        <chunking id="9" string="the kind of independent review the city was able to order for the police department" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="kind" />
            <token id="21" string="of" />
            <token id="22" string="independent" />
            <token id="23" string="review" />
            <token id="24" string="the" />
            <token id="25" string="city" />
            <token id="26" string="was" />
            <token id="27" string="able" />
            <token id="28" string="to" />
            <token id="29" string="order" />
            <token id="30" string="for" />
            <token id="31" string="the" />
            <token id="32" string="police" />
            <token id="33" string="department" />
          </tokens>
        </chunking>
        <chunking id="10" string="the city was able to order for the police department" type="SBAR">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="city" />
            <token id="26" string="was" />
            <token id="27" string="able" />
            <token id="28" string="to" />
            <token id="29" string="order" />
            <token id="30" string="for" />
            <token id="31" string="the" />
            <token id="32" string="police" />
            <token id="33" string="department" />
          </tokens>
        </chunking>
        <chunking id="11" string="insulates him from the kind of independent review the city was able to order for the police department" type="VP">
          <tokens>
            <token id="16" string="insulates" />
            <token id="17" string="him" />
            <token id="18" string="from" />
            <token id="19" string="the" />
            <token id="20" string="kind" />
            <token id="21" string="of" />
            <token id="22" string="independent" />
            <token id="23" string="review" />
            <token id="24" string="the" />
            <token id="25" string="city" />
            <token id="26" string="was" />
            <token id="27" string="able" />
            <token id="28" string="to" />
            <token id="29" string="order" />
            <token id="30" string="for" />
            <token id="31" string="the" />
            <token id="32" string="police" />
            <token id="33" string="department" />
          </tokens>
        </chunking>
        <chunking id="12" string="him" type="NP">
          <tokens>
            <token id="17" string="him" />
          </tokens>
        </chunking>
        <chunking id="13" string="critics" type="NP">
          <tokens>
            <token id="7" string="critics" />
          </tokens>
        </chunking>
        <chunking id="14" string="an elected official" type="NP">
          <tokens>
            <token id="13" string="an" />
            <token id="14" string="elected" />
            <token id="15" string="official" />
          </tokens>
        </chunking>
        <chunking id="15" string="Block 's position as an elected official" type="NP">
          <tokens>
            <token id="9" string="Block" />
            <token id="10" string="'s" />
            <token id="11" string="position" />
            <token id="12" string="as" />
            <token id="13" string="an" />
            <token id="14" string="elected" />
            <token id="15" string="official" />
          </tokens>
        </chunking>
        <chunking id="16" string="say Block 's position as an elected official insulates him from the kind of independent review the city was able to order for the police department" type="VP">
          <tokens>
            <token id="8" string="say" />
            <token id="9" string="Block" />
            <token id="10" string="'s" />
            <token id="11" string="position" />
            <token id="12" string="as" />
            <token id="13" string="an" />
            <token id="14" string="elected" />
            <token id="15" string="official" />
            <token id="16" string="insulates" />
            <token id="17" string="him" />
            <token id="18" string="from" />
            <token id="19" string="the" />
            <token id="20" string="kind" />
            <token id="21" string="of" />
            <token id="22" string="independent" />
            <token id="23" string="review" />
            <token id="24" string="the" />
            <token id="25" string="city" />
            <token id="26" string="was" />
            <token id="27" string="able" />
            <token id="28" string="to" />
            <token id="29" string="order" />
            <token id="30" string="for" />
            <token id="31" string="the" />
            <token id="32" string="police" />
            <token id="33" string="department" />
          </tokens>
        </chunking>
        <chunking id="17" string="able to order for the police department" type="ADJP">
          <tokens>
            <token id="27" string="able" />
            <token id="28" string="to" />
            <token id="29" string="order" />
            <token id="30" string="for" />
            <token id="31" string="the" />
            <token id="32" string="police" />
            <token id="33" string="department" />
          </tokens>
        </chunking>
        <chunking id="18" string="Block 's position as an elected official insulates him from the kind of independent review the city was able to order for the police department" type="SBAR">
          <tokens>
            <token id="9" string="Block" />
            <token id="10" string="'s" />
            <token id="11" string="position" />
            <token id="12" string="as" />
            <token id="13" string="an" />
            <token id="14" string="elected" />
            <token id="15" string="official" />
            <token id="16" string="insulates" />
            <token id="17" string="him" />
            <token id="18" string="from" />
            <token id="19" string="the" />
            <token id="20" string="kind" />
            <token id="21" string="of" />
            <token id="22" string="independent" />
            <token id="23" string="review" />
            <token id="24" string="the" />
            <token id="25" string="city" />
            <token id="26" string="was" />
            <token id="27" string="able" />
            <token id="28" string="to" />
            <token id="29" string="order" />
            <token id="30" string="for" />
            <token id="31" string="the" />
            <token id="32" string="police" />
            <token id="33" string="department" />
          </tokens>
        </chunking>
        <chunking id="19" string="the kind" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="kind" />
          </tokens>
        </chunking>
        <chunking id="20" string="the county side" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="county" />
            <token id="5" string="side" />
          </tokens>
        </chunking>
        <chunking id="21" string="independent review" type="NP">
          <tokens>
            <token id="22" string="independent" />
            <token id="23" string="review" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="5">side</governor>
          <dependent id="2">On</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">side</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">side</governor>
          <dependent id="4">county</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">say</governor>
          <dependent id="5">side</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">say</governor>
          <dependent id="7">critics</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">say</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">position</governor>
          <dependent id="9">Block</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Block</governor>
          <dependent id="10">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">insulates</governor>
          <dependent id="11">position</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">official</governor>
          <dependent id="12">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">official</governor>
          <dependent id="13">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">official</governor>
          <dependent id="14">elected</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">position</governor>
          <dependent id="15">official</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">say</governor>
          <dependent id="16">insulates</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">insulates</governor>
          <dependent id="17">him</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">kind</governor>
          <dependent id="18">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">kind</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">insulates</governor>
          <dependent id="20">kind</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">review</governor>
          <dependent id="21">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">review</governor>
          <dependent id="22">independent</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">kind</governor>
          <dependent id="23">review</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">city</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">able</governor>
          <dependent id="25">city</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="27">able</governor>
          <dependent id="26">was</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="23">review</governor>
          <dependent id="27">able</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="29">order</governor>
          <dependent id="28">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="27">able</governor>
          <dependent id="29">order</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">department</governor>
          <dependent id="30">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">department</governor>
          <dependent id="31">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="33">department</governor>
          <dependent id="32">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">order</governor>
          <dependent id="33">department</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="independent" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="22" string="independent" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="45" has_coreference="true">
      <content>And although he can be voted out, they say, the voters include great numbers of people in cities that his department doesn&amp;apost;t patrol.</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="although" lemma="although" stem="although" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="voted" lemma="vote" stem="vote" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="say" lemma="say" stem="sai" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="voters" lemma="voter" stem="voter" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="include" lemma="include" stem="includ" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="great" lemma="great" stem="great" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="numbers" lemma="number" stem="number" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="cities" lemma="city" stem="citi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="department" lemma="department" stem="depart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="24" string="does" lemma="do" stem="doe" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="patrol" lemma="patrol" stem="patrol" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC And) (SBAR (IN although) (S (NP (PRP he)) (VP (MD can) (VP (VB be) (VP (VBN voted) (PRT (RP out))))))) (PRN (, ,) (S (NP (PRP they)) (VP (VBP say))) (, ,)) (NP (DT the) (NNS voters)) (VP (VBP include) (NP (NP (JJ great) (NNS numbers)) (PP (IN of) (NP (NP (NNS people)) (PP (IN in) (NP (NNS cities)))))) (SBAR (IN that) (S (NP (PRP$ his) (NN department)) (VP (VBZ does) (RB n't) (NP (NN patrol)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="cities" type="NP">
          <tokens>
            <token id="20" string="cities" />
          </tokens>
        </chunking>
        <chunking id="2" string="patrol" type="NP">
          <tokens>
            <token id="26" string="patrol" />
          </tokens>
        </chunking>
        <chunking id="3" string="say" type="VP">
          <tokens>
            <token id="10" string="say" />
          </tokens>
        </chunking>
        <chunking id="4" string="voted out" type="VP">
          <tokens>
            <token id="6" string="voted" />
            <token id="7" string="out" />
          </tokens>
        </chunking>
        <chunking id="5" string="people" type="NP">
          <tokens>
            <token id="18" string="people" />
          </tokens>
        </chunking>
        <chunking id="6" string="that his department does n't patrol" type="SBAR">
          <tokens>
            <token id="21" string="that" />
            <token id="22" string="his" />
            <token id="23" string="department" />
            <token id="24" string="does" />
            <token id="25" string="n't" />
            <token id="26" string="patrol" />
          </tokens>
        </chunking>
        <chunking id="7" string="they" type="NP">
          <tokens>
            <token id="9" string="they" />
          </tokens>
        </chunking>
        <chunking id="8" string="great numbers of people in cities" type="NP">
          <tokens>
            <token id="15" string="great" />
            <token id="16" string="numbers" />
            <token id="17" string="of" />
            <token id="18" string="people" />
            <token id="19" string="in" />
            <token id="20" string="cities" />
          </tokens>
        </chunking>
        <chunking id="9" string="people in cities" type="NP">
          <tokens>
            <token id="18" string="people" />
            <token id="19" string="in" />
            <token id="20" string="cities" />
          </tokens>
        </chunking>
        <chunking id="10" string="can be voted out" type="VP">
          <tokens>
            <token id="4" string="can" />
            <token id="5" string="be" />
            <token id="6" string="voted" />
            <token id="7" string="out" />
          </tokens>
        </chunking>
        <chunking id="11" string="his department" type="NP">
          <tokens>
            <token id="22" string="his" />
            <token id="23" string="department" />
          </tokens>
        </chunking>
        <chunking id="12" string="although he can be voted out" type="SBAR">
          <tokens>
            <token id="2" string="although" />
            <token id="3" string="he" />
            <token id="4" string="can" />
            <token id="5" string="be" />
            <token id="6" string="voted" />
            <token id="7" string="out" />
          </tokens>
        </chunking>
        <chunking id="13" string="the voters" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="voters" />
          </tokens>
        </chunking>
        <chunking id="14" string="great numbers" type="NP">
          <tokens>
            <token id="15" string="great" />
            <token id="16" string="numbers" />
          </tokens>
        </chunking>
        <chunking id="15" string="does n't patrol" type="VP">
          <tokens>
            <token id="24" string="does" />
            <token id="25" string="n't" />
            <token id="26" string="patrol" />
          </tokens>
        </chunking>
        <chunking id="16" string="he" type="NP">
          <tokens>
            <token id="3" string="he" />
          </tokens>
        </chunking>
        <chunking id="17" string="be voted out" type="VP">
          <tokens>
            <token id="5" string="be" />
            <token id="6" string="voted" />
            <token id="7" string="out" />
          </tokens>
        </chunking>
        <chunking id="18" string="include great numbers of people in cities that his department does n't patrol" type="VP">
          <tokens>
            <token id="14" string="include" />
            <token id="15" string="great" />
            <token id="16" string="numbers" />
            <token id="17" string="of" />
            <token id="18" string="people" />
            <token id="19" string="in" />
            <token id="20" string="cities" />
            <token id="21" string="that" />
            <token id="22" string="his" />
            <token id="23" string="department" />
            <token id="24" string="does" />
            <token id="25" string="n't" />
            <token id="26" string="patrol" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="14">include</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">voted</governor>
          <dependent id="2">although</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="6">voted</governor>
          <dependent id="3">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">voted</governor>
          <dependent id="4">can</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">voted</governor>
          <dependent id="5">be</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="14">include</governor>
          <dependent id="6">voted</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="6">voted</governor>
          <dependent id="7">out</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">say</governor>
          <dependent id="9">they</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="14">include</governor>
          <dependent id="10">say</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">voters</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">include</governor>
          <dependent id="13">voters</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">include</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">numbers</governor>
          <dependent id="15">great</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">include</governor>
          <dependent id="16">numbers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">people</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">numbers</governor>
          <dependent id="18">people</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">cities</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">people</governor>
          <dependent id="20">cities</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">does</governor>
          <dependent id="21">that</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="23">department</governor>
          <dependent id="22">his</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">does</governor>
          <dependent id="23">department</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">include</governor>
          <dependent id="24">does</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="24">does</governor>
          <dependent id="25">n't</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">does</governor>
          <dependent id="26">patrol</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="46" has_coreference="false">
      <content>John Burton, an attorney specializing in police misconduct cases, offers a grim view on the potential for change: &amp;quot;I think it&amp;apost;s going to get worse, because of the general decay in social conditions and unemployment.</content>
      <tokens>
        <token id="1" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Burton" lemma="Burton" stem="burton" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="attorney" lemma="attorney" stem="attornei" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="specializing" lemma="specialize" stem="special" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="misconduct" lemma="misconduct" stem="misconduct" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="cases" lemma="case" stem="case" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="offers" lemma="offer" stem="offer" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="grim" lemma="grim" stem="grim" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="view" lemma="view" stem="view" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="potential" lemma="potential" stem="potenti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="change" lemma="change" stem="chang" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="think" lemma="think" stem="think" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="get" lemma="get" stem="get" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="worse" lemma="worse" stem="wors" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="general" lemma="general" stem="gener" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="decay" lemma="decay" stem="decai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="social" lemma="social" stem="social" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="conditions" lemma="condition" stem="condit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="unemployment" lemma="unemployment" stem="unemploy" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP John) (NNP Burton)) (, ,) (NP (NP (DT an) (NN attorney)) (VP (VBG specializing) (PP (IN in) (NP (NN police) (NN misconduct) (NNS cases))))) (, ,)) (VP (VBZ offers) (NP (DT a) (JJ grim) (NN view)) (PP (IN on) (NP (NP (DT the) (NN potential)) (PP (IN for) (NP (NN change))))) (: :) (`` ``) (S (NP (PRP I)) (VP (VBP think) (SBAR (S (NP (PRP it)) (VP (VBZ 's) (VP (VBG going) (S (VP (TO to) (VP (VB get) (ADJP (JJR worse)) (, ,) (PP (IN because) (IN of) (NP (NP (DT the) (JJ general) (NN decay)) (PP (IN in) (NP (JJ social) (NNS conditions) (CC and) (NN unemployment))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="police misconduct cases" type="NP">
          <tokens>
            <token id="8" string="police" />
            <token id="9" string="misconduct" />
            <token id="10" string="cases" />
          </tokens>
        </chunking>
        <chunking id="2" string="social conditions and unemployment" type="NP">
          <tokens>
            <token id="38" string="social" />
            <token id="39" string="conditions" />
            <token id="40" string="and" />
            <token id="41" string="unemployment" />
          </tokens>
        </chunking>
        <chunking id="3" string="the general decay in social conditions and unemployment" type="NP">
          <tokens>
            <token id="34" string="the" />
            <token id="35" string="general" />
            <token id="36" string="decay" />
            <token id="37" string="in" />
            <token id="38" string="social" />
            <token id="39" string="conditions" />
            <token id="40" string="and" />
            <token id="41" string="unemployment" />
          </tokens>
        </chunking>
        <chunking id="4" string="an attorney specializing in police misconduct cases" type="NP">
          <tokens>
            <token id="4" string="an" />
            <token id="5" string="attorney" />
            <token id="6" string="specializing" />
            <token id="7" string="in" />
            <token id="8" string="police" />
            <token id="9" string="misconduct" />
            <token id="10" string="cases" />
          </tokens>
        </chunking>
        <chunking id="5" string="John Burton" type="NP">
          <tokens>
            <token id="1" string="John" />
            <token id="2" string="Burton" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="23" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="'s going to get worse , because of the general decay in social conditions and unemployment" type="VP">
          <tokens>
            <token id="26" string="'s" />
            <token id="27" string="going" />
            <token id="28" string="to" />
            <token id="29" string="get" />
            <token id="30" string="worse" />
            <token id="31" string="," />
            <token id="32" string="because" />
            <token id="33" string="of" />
            <token id="34" string="the" />
            <token id="35" string="general" />
            <token id="36" string="decay" />
            <token id="37" string="in" />
            <token id="38" string="social" />
            <token id="39" string="conditions" />
            <token id="40" string="and" />
            <token id="41" string="unemployment" />
          </tokens>
        </chunking>
        <chunking id="8" string="think it 's going to get worse , because of the general decay in social conditions and unemployment" type="VP">
          <tokens>
            <token id="24" string="think" />
            <token id="25" string="it" />
            <token id="26" string="'s" />
            <token id="27" string="going" />
            <token id="28" string="to" />
            <token id="29" string="get" />
            <token id="30" string="worse" />
            <token id="31" string="," />
            <token id="32" string="because" />
            <token id="33" string="of" />
            <token id="34" string="the" />
            <token id="35" string="general" />
            <token id="36" string="decay" />
            <token id="37" string="in" />
            <token id="38" string="social" />
            <token id="39" string="conditions" />
            <token id="40" string="and" />
            <token id="41" string="unemployment" />
          </tokens>
        </chunking>
        <chunking id="9" string="specializing in police misconduct cases" type="VP">
          <tokens>
            <token id="6" string="specializing" />
            <token id="7" string="in" />
            <token id="8" string="police" />
            <token id="9" string="misconduct" />
            <token id="10" string="cases" />
          </tokens>
        </chunking>
        <chunking id="10" string="it" type="NP">
          <tokens>
            <token id="25" string="it" />
          </tokens>
        </chunking>
        <chunking id="11" string="worse" type="ADJP">
          <tokens>
            <token id="30" string="worse" />
          </tokens>
        </chunking>
        <chunking id="12" string="the potential for change" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="potential" />
            <token id="19" string="for" />
            <token id="20" string="change" />
          </tokens>
        </chunking>
        <chunking id="13" string="to get worse , because of the general decay in social conditions and unemployment" type="VP">
          <tokens>
            <token id="28" string="to" />
            <token id="29" string="get" />
            <token id="30" string="worse" />
            <token id="31" string="," />
            <token id="32" string="because" />
            <token id="33" string="of" />
            <token id="34" string="the" />
            <token id="35" string="general" />
            <token id="36" string="decay" />
            <token id="37" string="in" />
            <token id="38" string="social" />
            <token id="39" string="conditions" />
            <token id="40" string="and" />
            <token id="41" string="unemployment" />
          </tokens>
        </chunking>
        <chunking id="14" string="going to get worse , because of the general decay in social conditions and unemployment" type="VP">
          <tokens>
            <token id="27" string="going" />
            <token id="28" string="to" />
            <token id="29" string="get" />
            <token id="30" string="worse" />
            <token id="31" string="," />
            <token id="32" string="because" />
            <token id="33" string="of" />
            <token id="34" string="the" />
            <token id="35" string="general" />
            <token id="36" string="decay" />
            <token id="37" string="in" />
            <token id="38" string="social" />
            <token id="39" string="conditions" />
            <token id="40" string="and" />
            <token id="41" string="unemployment" />
          </tokens>
        </chunking>
        <chunking id="15" string="the potential" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="potential" />
          </tokens>
        </chunking>
        <chunking id="16" string="change" type="NP">
          <tokens>
            <token id="20" string="change" />
          </tokens>
        </chunking>
        <chunking id="17" string="get worse , because of the general decay in social conditions and unemployment" type="VP">
          <tokens>
            <token id="29" string="get" />
            <token id="30" string="worse" />
            <token id="31" string="," />
            <token id="32" string="because" />
            <token id="33" string="of" />
            <token id="34" string="the" />
            <token id="35" string="general" />
            <token id="36" string="decay" />
            <token id="37" string="in" />
            <token id="38" string="social" />
            <token id="39" string="conditions" />
            <token id="40" string="and" />
            <token id="41" string="unemployment" />
          </tokens>
        </chunking>
        <chunking id="18" string="it 's going to get worse , because of the general decay in social conditions and unemployment" type="SBAR">
          <tokens>
            <token id="25" string="it" />
            <token id="26" string="'s" />
            <token id="27" string="going" />
            <token id="28" string="to" />
            <token id="29" string="get" />
            <token id="30" string="worse" />
            <token id="31" string="," />
            <token id="32" string="because" />
            <token id="33" string="of" />
            <token id="34" string="the" />
            <token id="35" string="general" />
            <token id="36" string="decay" />
            <token id="37" string="in" />
            <token id="38" string="social" />
            <token id="39" string="conditions" />
            <token id="40" string="and" />
            <token id="41" string="unemployment" />
          </tokens>
        </chunking>
        <chunking id="19" string="John Burton , an attorney specializing in police misconduct cases ," type="NP">
          <tokens>
            <token id="1" string="John" />
            <token id="2" string="Burton" />
            <token id="3" string="," />
            <token id="4" string="an" />
            <token id="5" string="attorney" />
            <token id="6" string="specializing" />
            <token id="7" string="in" />
            <token id="8" string="police" />
            <token id="9" string="misconduct" />
            <token id="10" string="cases" />
            <token id="11" string="," />
          </tokens>
        </chunking>
        <chunking id="20" string="a grim view" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="grim" />
            <token id="15" string="view" />
          </tokens>
        </chunking>
        <chunking id="21" string="the general decay" type="NP">
          <tokens>
            <token id="34" string="the" />
            <token id="35" string="general" />
            <token id="36" string="decay" />
          </tokens>
        </chunking>
        <chunking id="22" string="an attorney" type="NP">
          <tokens>
            <token id="4" string="an" />
            <token id="5" string="attorney" />
          </tokens>
        </chunking>
        <chunking id="23" string="offers a grim view on the potential for change : `` I think it 's going to get worse , because of the general decay in social conditions and unemployment" type="VP">
          <tokens>
            <token id="12" string="offers" />
            <token id="13" string="a" />
            <token id="14" string="grim" />
            <token id="15" string="view" />
            <token id="16" string="on" />
            <token id="17" string="the" />
            <token id="18" string="potential" />
            <token id="19" string="for" />
            <token id="20" string="change" />
            <token id="21" string=":" />
            <token id="22" string="&quot;" />
            <token id="23" string="I" />
            <token id="24" string="think" />
            <token id="25" string="it" />
            <token id="26" string="'s" />
            <token id="27" string="going" />
            <token id="28" string="to" />
            <token id="29" string="get" />
            <token id="30" string="worse" />
            <token id="31" string="," />
            <token id="32" string="because" />
            <token id="33" string="of" />
            <token id="34" string="the" />
            <token id="35" string="general" />
            <token id="36" string="decay" />
            <token id="37" string="in" />
            <token id="38" string="social" />
            <token id="39" string="conditions" />
            <token id="40" string="and" />
            <token id="41" string="unemployment" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Burton</governor>
          <dependent id="1">John</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">offers</governor>
          <dependent id="2">Burton</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">attorney</governor>
          <dependent id="4">an</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">Burton</governor>
          <dependent id="5">attorney</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="5">attorney</governor>
          <dependent id="6">specializing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">cases</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">cases</governor>
          <dependent id="8">police</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">cases</governor>
          <dependent id="9">misconduct</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">specializing</governor>
          <dependent id="10">cases</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">offers</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">view</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">view</governor>
          <dependent id="14">grim</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">offers</governor>
          <dependent id="15">view</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">potential</governor>
          <dependent id="16">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">potential</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">offers</governor>
          <dependent id="18">potential</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">change</governor>
          <dependent id="19">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">potential</governor>
          <dependent id="20">change</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">think</governor>
          <dependent id="23">I</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="12">offers</governor>
          <dependent id="24">think</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">going</governor>
          <dependent id="25">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="27">going</governor>
          <dependent id="26">'s</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="24">think</governor>
          <dependent id="27">going</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="29">get</governor>
          <dependent id="28">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="27">going</governor>
          <dependent id="29">get</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="29">get</governor>
          <dependent id="30">worse</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">decay</governor>
          <dependent id="32">because</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="32">because</governor>
          <dependent id="33">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="36">decay</governor>
          <dependent id="34">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="36">decay</governor>
          <dependent id="35">general</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">get</governor>
          <dependent id="36">decay</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">conditions</governor>
          <dependent id="37">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="39">conditions</governor>
          <dependent id="38">social</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="36">decay</governor>
          <dependent id="39">conditions</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="39">conditions</governor>
          <dependent id="40">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="39">conditions</governor>
          <dependent id="41">unemployment</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="John Burton" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="John" />
            <token id="2" string="Burton" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="47" has_coreference="true">
      <content>The government doesn&amp;apost;t have anything to offer except police repression, so that&amp;apost;s what we get.&amp;quot;</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="government" lemma="government" stem="govern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="does" lemma="do" stem="doe" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="anything" lemma="anything" stem="anyth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="offer" lemma="offer" stem="offer" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="except" lemma="except" stem="except" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="repression" lemma="repression" stem="repress" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="so" lemma="so" stem="so" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="get" lemma="get" stem="get" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT The) (NN government)) (VP (VBZ does) (RB n't) (VP (VB have) (NP (NN anything)) (S (VP (TO to) (VP (VB offer) (PP (IN except) (NP (NN police) (NN repression))))))))) (, ,) (IN so) (S (NP (DT that)) (VP (VBZ 's) (SBAR (WHNP (WP what)) (S (NP (PRP we)) (VP (VBP get)))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="The government" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="government" />
          </tokens>
        </chunking>
        <chunking id="2" string="that" type="NP">
          <tokens>
            <token id="14" string="that" />
          </tokens>
        </chunking>
        <chunking id="3" string="offer except police repression" type="VP">
          <tokens>
            <token id="8" string="offer" />
            <token id="9" string="except" />
            <token id="10" string="police" />
            <token id="11" string="repression" />
          </tokens>
        </chunking>
        <chunking id="4" string="have anything to offer except police repression" type="VP">
          <tokens>
            <token id="5" string="have" />
            <token id="6" string="anything" />
            <token id="7" string="to" />
            <token id="8" string="offer" />
            <token id="9" string="except" />
            <token id="10" string="police" />
            <token id="11" string="repression" />
          </tokens>
        </chunking>
        <chunking id="5" string="get" type="VP">
          <tokens>
            <token id="18" string="get" />
          </tokens>
        </chunking>
        <chunking id="6" string="to offer except police repression" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="offer" />
            <token id="9" string="except" />
            <token id="10" string="police" />
            <token id="11" string="repression" />
          </tokens>
        </chunking>
        <chunking id="7" string="'s what we get" type="VP">
          <tokens>
            <token id="15" string="'s" />
            <token id="16" string="what" />
            <token id="17" string="we" />
            <token id="18" string="get" />
          </tokens>
        </chunking>
        <chunking id="8" string="police repression" type="NP">
          <tokens>
            <token id="10" string="police" />
            <token id="11" string="repression" />
          </tokens>
        </chunking>
        <chunking id="9" string="anything" type="NP">
          <tokens>
            <token id="6" string="anything" />
          </tokens>
        </chunking>
        <chunking id="10" string="what we get" type="SBAR">
          <tokens>
            <token id="16" string="what" />
            <token id="17" string="we" />
            <token id="18" string="get" />
          </tokens>
        </chunking>
        <chunking id="11" string="we" type="NP">
          <tokens>
            <token id="17" string="we" />
          </tokens>
        </chunking>
        <chunking id="12" string="does n't have anything to offer except police repression" type="VP">
          <tokens>
            <token id="3" string="does" />
            <token id="4" string="n't" />
            <token id="5" string="have" />
            <token id="6" string="anything" />
            <token id="7" string="to" />
            <token id="8" string="offer" />
            <token id="9" string="except" />
            <token id="10" string="police" />
            <token id="11" string="repression" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">government</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">have</governor>
          <dependent id="2">government</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">have</governor>
          <dependent id="3">does</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">have</governor>
          <dependent id="4">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">have</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">have</governor>
          <dependent id="6">anything</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">offer</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">have</governor>
          <dependent id="8">offer</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">repression</governor>
          <dependent id="9">except</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">repression</governor>
          <dependent id="10">police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">offer</governor>
          <dependent id="11">repression</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="5">have</governor>
          <dependent id="13">so</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">'s</governor>
          <dependent id="14">that</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="5">have</governor>
          <dependent id="15">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">get</governor>
          <dependent id="16">what</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">get</governor>
          <dependent id="17">we</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">'s</governor>
          <dependent id="18">get</dependent>
        </dependency>
      </dependencies>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="4-5-6-7-8-9-10-11" string="this county 's politically astute Sheriff Sherman Block" id_sentence="1" />
      <mentions>
        <mention ids_tokens="1-2" string="Block's" id_sentence="8" />
        <mention ids_tokens="19" string="him" id_sentence="8" />
        <mention ids_tokens="2" string="Block" id_sentence="25" />
        <mention ids_tokens="6" string="his" id_sentence="25" />
        <mention ids_tokens="12" string="he" id_sentence="25" />
        <mention ids_tokens="26" string="his" id_sentence="25" />
        <mention ids_tokens="3" string="Block" id_sentence="27" />
        <mention ids_tokens="7" string="his" id_sentence="27" />
        <mention ids_tokens="4" string="him" id_sentence="28" />
        <mention ids_tokens="6" string="Block" id_sentence="28" />
        <mention ids_tokens="1-2" string="; Block" id_sentence="33" />
        <mention ids_tokens="18" string="Block" id_sentence="36" />
        <mention ids_tokens="9-10" string="Block's" id_sentence="44" />
        <mention ids_tokens="17" string="him" id_sentence="44" />
        <mention ids_tokens="3" string="he" id_sentence="45" />
        <mention ids_tokens="22" string="his" id_sentence="45" />
      </mentions>
    </coreference>
    <coreference id="2" type="NOMINAL">
      <referenced ids_tokens="4-5-6" string="this county 's" id_sentence="1" />
      <mentions>
        <mention ids_tokens="13-14" string="the county" id_sentence="35" />
      </mentions>
    </coreference>
    <coreference id="3" type="PROPER">
      <referenced ids_tokens="11-12-13" string="a good one" id_sentence="28" />
      <mentions>
        <mention ids_tokens="19-20" string="his department" id_sentence="1" />
        <mention ids_tokens="4-5" string="the department" id_sentence="5" />
        <mention ids_tokens="24-25" string="the department" id_sentence="6" />
        <mention ids_tokens="21-23" string="the department's" id_sentence="21" />
        <mention ids_tokens="26-27" string="his department" id_sentence="25" />
        <mention ids_tokens="7-8" string="his department" id_sentence="29" />
        <mention ids_tokens="11" string="itself" id_sentence="29" />
        <mention ids_tokens="22-23" string="his department" id_sentence="45" />
      </mentions>
    </coreference>
    <coreference id="4" type="NOMINAL">
      <referenced ids_tokens="28-29-30-31-32-33-34-35" string="the videotaped beating of black motorist Rodney King" id_sentence="1" />
      <mentions>
        <mention ids_tokens="1-3" string="The King beating" id_sentence="20" />
      </mentions>
    </coreference>
    <coreference id="5" type="PROPER">
      <referenced ids_tokens="32-33-34-35" string="black motorist Rodney King" id_sentence="1" />
      <mentions>
        <mention ids_tokens="2" string="King" id_sentence="20" />
      </mentions>
    </coreference>
    <coreference id="8" type="NOMINAL">
      <referenced ids_tokens="12-13-14" string="its 8,300 officers" id_sentence="7" />
      <mentions>
        <mention ids_tokens="7" string="their" id_sentence="9" />
        <mention ids_tokens="21" string="their" id_sentence="9" />
        <mention ids_tokens="2" string="We" id_sentence="10" />
        <mention ids_tokens="41" string="their" id_sentence="12" />
        <mention ids_tokens="33" string="officers" id_sentence="20" />
        <mention ids_tokens="15" string="them" id_sentence="21" />
        <mention ids_tokens="8" string="officers" id_sentence="22" />
        <mention ids_tokens="14" string="their" id_sentence="22" />
      </mentions>
    </coreference>
    <coreference id="9" type="NOMINAL">
      <referenced ids_tokens="21-22-23-24-25-26" string="the equally large sheriff 's department" id_sentence="7" />
      <mentions>
        <mention ids_tokens="14-17" string="the sheriff's department" id_sentence="24" />
        <mention ids_tokens="15-18" string="the sheriff's department" id_sentence="30" />
        <mention ids_tokens="18-21" string="the sheriff's department" id_sentence="35" />
      </mentions>
    </coreference>
    <coreference id="10" type="NOMINAL">
      <referenced ids_tokens="21-22-23-24-25" string="the equally large sheriff 's" id_sentence="7" />
      <mentions>
        <mention ids_tokens="14-16" string="the sheriff's" id_sentence="24" />
        <mention ids_tokens="2-3" string="The sheriff" id_sentence="29" />
        <mention ids_tokens="7" string="his" id_sentence="29" />
        <mention ids_tokens="15-17" string="the sheriff's" id_sentence="30" />
        <mention ids_tokens="18-20" string="the sheriff's" id_sentence="35" />
      </mentions>
    </coreference>
    <coreference id="11" type="PROPER">
      <referenced ids_tokens="26-27-28-29" string="Police Chief Daryl Gates" id_sentence="8" />
      <mentions>
        <mention ids_tokens="2-4" string="Gates before him" id_sentence="28" />
        <mention ids_tokens="8" string="his" id_sentence="28" />
        <mention ids_tokens="11" string="I" id_sentence="30" />
        <mention ids_tokens="36" string="he" id_sentence="30" />
      </mentions>
    </coreference>
    <coreference id="13" type="NOMINAL">
      <referenced ids_tokens="14-15" string="both departments" id_sentence="9" />
      <mentions>
        <mention ids_tokens="41-42" string="their departments" id_sentence="12" />
      </mentions>
    </coreference>
    <coreference id="14" type="PROPER">
      <referenced ids_tokens="16-17-18-19-20-21-22-23-24-25-26-27-28" string="Ramona Ripston , head of the American Civil Liberties Union of Southern California" id_sentence="10" />
      <mentions>
        <mention ids_tokens="15" string="I" id_sentence="11" />
      </mentions>
    </coreference>
    <coreference id="15" type="NOMINAL">
      <referenced ids_tokens="4-5-6-7-8" string="a multiracial , multicultural city" id_sentence="10" />
      <mentions>
        <mention ids_tokens="10" string="it" id_sentence="11" />
        <mention ids_tokens="24-25" string="the city" id_sentence="44" />
      </mentions>
    </coreference>
    <coreference id="16" type="PROPER">
      <referenced ids_tokens="21-22-23-24-25" string="the American Civil Liberties Union" id_sentence="10" />
      <mentions>
        <mention ids_tokens="27" string="ACLU" id_sentence="16" />
        <mention ids_tokens="7-9" string="the ACLU's" id_sentence="43" />
      </mentions>
    </coreference>
    <coreference id="17" type="PROPER">
      <referenced ids_tokens="2-3" string="Joseph McNamara" id_sentence="12" />
      <mentions>
        <mention ids_tokens="14" string="McNamara" id_sentence="13" />
      </mentions>
    </coreference>
    <coreference id="18" type="PROPER">
      <referenced ids_tokens="17-18-19-20-21" string="Stanford University 's Hoover Institution" id_sentence="12" />
      <mentions>
        <mention ids_tokens="24-27" string="the Hoover Institution's" id_sentence="37" />
      </mentions>
    </coreference>
    <coreference id="19" type="PROPER">
      <referenced ids_tokens="24-25-26-27-28" string="the Hoover Institution 's McNamara" id_sentence="37" />
      <mentions>
        <mention ids_tokens="2-21" string="Joseph McNamara , retired chief of San Jose's department and now a fellow at Stanford University's Hoover Institution" id_sentence="12" />
      </mentions>
    </coreference>
    <coreference id="20" type="NOMINAL">
      <referenced ids_tokens="20-21" string="the chief" id_sentence="23" />
      <mentions>
        <mention ids_tokens="6-15" string="chief of San Jose's department and now a fellow" id_sentence="12" />
      </mentions>
    </coreference>
    <coreference id="21" type="NOMINAL">
      <referenced ids_tokens="32-33-34-35-36-37-38-39" string="cities around the country about racism and brutality" id_sentence="12" />
      <mentions>
        <mention ids_tokens="20" string="cities" id_sentence="45" />
      </mentions>
    </coreference>
    <coreference id="23" type="NOMINAL">
      <referenced ids_tokens="2-3" string="Militarizing police" id_sentence="14" />
      <mentions>
        <mention ids_tokens="24-25" string="the police" id_sentence="19" />
        <mention ids_tokens="2" string="Police" id_sentence="37" />
      </mentions>
    </coreference>
    <coreference id="25" type="NOMINAL">
      <referenced ids_tokens="3-4" string="some observers" id_sentence="15" />
      <mentions>
        <mention ids_tokens="2" string="They" id_sentence="17" />
      </mentions>
    </coreference>
    <coreference id="26" type="NOMINAL">
      <referenced ids_tokens="15-16" string="voting people" id_sentence="16" />
      <mentions>
        <mention ids_tokens="1" string="They" id_sentence="18" />
        <mention ids_tokens="7" string="their" id_sentence="18" />
        <mention ids_tokens="2" string="People" id_sentence="31" />
        <mention ids_tokens="3" string="they" id_sentence="32" />
        <mention ids_tokens="20" string="themselves" id_sentence="33" />
      </mentions>
    </coreference>
    <coreference id="28" type="PROPER">
      <referenced ids_tokens="27-28-29-30" string="ACLU spokesman Joe Hicks" id_sentence="16" />
      <mentions>
        <mention ids_tokens="38" string="Hicks" id_sentence="19" />
        <mention ids_tokens="7-10" string="the ACLU's Hicks" id_sentence="43" />
      </mentions>
    </coreference>
    <coreference id="32" type="PROPER">
      <referenced ids_tokens="1-2-3-4" string="The Christopher Commission 's" id_sentence="21" />
      <mentions>
        <mention ids_tokens="20-21" string="Christopher Commission" id_sentence="25" />
        <mention ids_tokens="15-16" string="Christopher Commission" id_sentence="29" />
        <mention ids_tokens="19-20" string="the commission" id_sentence="29" />
        <mention ids_tokens="26" string="it" id_sentence="29" />
        <mention ids_tokens="16-17" string="Christopher Commission" id_sentence="42" />
      </mentions>
    </coreference>
    <coreference id="33" type="NOMINAL">
      <referenced ids_tokens="8-9-10-11" string="more than 100 recommendations" id_sentence="21" />
      <mentions>
        <mention ids_tokens="6-7" string="the recommendations" id_sentence="23" />
      </mentions>
    </coreference>
    <coreference id="37" type="NOMINAL">
      <referenced ids_tokens="3" string="critics" id_sentence="24" />
      <mentions>
        <mention ids_tokens="9" string="they" id_sentence="45" />
        <mention ids_tokens="17" string="we" id_sentence="47" />
      </mentions>
    </coreference>
    <coreference id="38" type="NOMINAL">
      <referenced ids_tokens="10-11-12-13-14-15-16-17-18-19-20-21-22-23-24-25-26-27" string="a panel he appointed is independent enough to advise which Christopher Commission recommendations might apply to his department" id_sentence="25" />
      <mentions>
        <mention ids_tokens="3" string="its" id_sentence="26" />
      </mentions>
    </coreference>
    <coreference id="40" type="NOMINAL">
      <referenced ids_tokens="14-15-16-17" string="several Christopher Commission recommendations" id_sentence="29" />
      <mentions>
        <mention ids_tokens="15-18" string="the Christopher Commission recommendations" id_sentence="42" />
      </mentions>
    </coreference>
    <coreference id="41" type="NOMINAL">
      <referenced ids_tokens="2-3-4" string="that law enforcement" id_sentence="36" />
      <mentions>
        <mention ids_tokens="7-8" string="Law enforcement" id_sentence="30" />
      </mentions>
    </coreference>
    <coreference id="42" type="NOMINAL">
      <referenced ids_tokens="13-14-15-16" string="the linchpins of government" id_sentence="31" />
      <mentions>
        <mention ids_tokens="40" string="our" id_sentence="33" />
      </mentions>
    </coreference>
    <coreference id="45" type="PROPER">
      <referenced ids_tokens="14-15" string="five years" id_sentence="34" />
      <mentions>
        <mention ids_tokens="10-11" string="the years" id_sentence="39" />
      </mentions>
    </coreference>
    <coreference id="48" type="NOMINAL">
      <referenced ids_tokens="2-3" string="some critics" id_sentence="41" />
      <mentions>
        <mention ids_tokens="12" string="they" id_sentence="42" />
      </mentions>
    </coreference>
    <coreference id="49" type="NOMINAL">
      <referenced ids_tokens="13-14-15-16" string="&quot; some window dressing" id_sentence="43" />
      <mentions>
        <mention ids_tokens="2-4" string="Window dressing'" id_sentence="42" />
      </mentions>
    </coreference>
    <coreference id="50" type="NOMINAL">
      <referenced ids_tokens="12-13" string="the voters" id_sentence="45" />
      <mentions>
        <mention ids_tokens="29" string="voters" id_sentence="42" />
        <mention ids_tokens="33" string="them" id_sentence="42" />
      </mentions>
    </coreference>
  </coreferences>
</document>
