<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="AP890313-0198">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>Inside a small motor home, Joanne Pierluissi raised her sleeve as nurse Mary Perez inserted a needle into the vein above her forearm, drawing blood into a tube for a diabetes test.</content>
      <tokens>
        <token id="1" string="Inside" lemma="inside" stem="inside" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="small" lemma="small" stem="small" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="motor" lemma="motor" stem="motor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="home" lemma="home" stem="home" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Joanne" lemma="Joanne" stem="joann" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="8" string="Pierluissi" lemma="Pierluissi" stem="pierluissi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="9" string="raised" lemma="raise" stem="rais" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="sleeve" lemma="sleeve" stem="sleev" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="nurse" lemma="nurse" stem="nurs" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="Mary" lemma="Mary" stem="mari" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="15" string="Perez" lemma="Perez" stem="perez" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="16" string="inserted" lemma="insert" stem="insert" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="needle" lemma="needle" stem="needl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="vein" lemma="vein" stem="vein" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="above" lemma="above" stem="abov" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="forearm" lemma="forearm" stem="forearm" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="drawing" lemma="draw" stem="draw" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="blood" lemma="blood" stem="blood" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="tube" lemma="tube" stem="tube" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="33" string="diabetes" lemma="diabetes" stem="diabet" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="false" />
        <token id="34" string="test" lemma="test" stem="test" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN Inside) (NP (DT a) (JJ small) (NN motor) (NN home))) (, ,) (NP (NNP Joanne) (NNP Pierluissi)) (VP (VBD raised) (NP (PRP$ her) (NN sleeve)) (SBAR (IN as) (S (NP (NN nurse) (NNP Mary) (NNP Perez)) (VP (VBD inserted) (NP (DT a) (NN needle)) (PP (IN into) (NP (NP (DT the) (NN vein)) (PP (IN above) (NP (PRP$ her) (NN forearm))))) (, ,) (S (VP (VBG drawing) (NP (NN blood)) (PP (IN into) (NP (NP (DT a) (NN tube)) (PP (IN for) (NP (DT a) (NN diabetes) (NN test))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a needle" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="needle" />
          </tokens>
        </chunking>
        <chunking id="2" string="the vein" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="vein" />
          </tokens>
        </chunking>
        <chunking id="3" string="her forearm" type="NP">
          <tokens>
            <token id="23" string="her" />
            <token id="24" string="forearm" />
          </tokens>
        </chunking>
        <chunking id="4" string="drawing blood into a tube for a diabetes test" type="VP">
          <tokens>
            <token id="26" string="drawing" />
            <token id="27" string="blood" />
            <token id="28" string="into" />
            <token id="29" string="a" />
            <token id="30" string="tube" />
            <token id="31" string="for" />
            <token id="32" string="a" />
            <token id="33" string="diabetes" />
            <token id="34" string="test" />
          </tokens>
        </chunking>
        <chunking id="5" string="raised her sleeve as nurse Mary Perez inserted a needle into the vein above her forearm , drawing blood into a tube for a diabetes test" type="VP">
          <tokens>
            <token id="9" string="raised" />
            <token id="10" string="her" />
            <token id="11" string="sleeve" />
            <token id="12" string="as" />
            <token id="13" string="nurse" />
            <token id="14" string="Mary" />
            <token id="15" string="Perez" />
            <token id="16" string="inserted" />
            <token id="17" string="a" />
            <token id="18" string="needle" />
            <token id="19" string="into" />
            <token id="20" string="the" />
            <token id="21" string="vein" />
            <token id="22" string="above" />
            <token id="23" string="her" />
            <token id="24" string="forearm" />
            <token id="25" string="," />
            <token id="26" string="drawing" />
            <token id="27" string="blood" />
            <token id="28" string="into" />
            <token id="29" string="a" />
            <token id="30" string="tube" />
            <token id="31" string="for" />
            <token id="32" string="a" />
            <token id="33" string="diabetes" />
            <token id="34" string="test" />
          </tokens>
        </chunking>
        <chunking id="6" string="blood" type="NP">
          <tokens>
            <token id="27" string="blood" />
          </tokens>
        </chunking>
        <chunking id="7" string="inserted a needle into the vein above her forearm , drawing blood into a tube for a diabetes test" type="VP">
          <tokens>
            <token id="16" string="inserted" />
            <token id="17" string="a" />
            <token id="18" string="needle" />
            <token id="19" string="into" />
            <token id="20" string="the" />
            <token id="21" string="vein" />
            <token id="22" string="above" />
            <token id="23" string="her" />
            <token id="24" string="forearm" />
            <token id="25" string="," />
            <token id="26" string="drawing" />
            <token id="27" string="blood" />
            <token id="28" string="into" />
            <token id="29" string="a" />
            <token id="30" string="tube" />
            <token id="31" string="for" />
            <token id="32" string="a" />
            <token id="33" string="diabetes" />
            <token id="34" string="test" />
          </tokens>
        </chunking>
        <chunking id="8" string="a diabetes test" type="NP">
          <tokens>
            <token id="32" string="a" />
            <token id="33" string="diabetes" />
            <token id="34" string="test" />
          </tokens>
        </chunking>
        <chunking id="9" string="as nurse Mary Perez inserted a needle into the vein above her forearm , drawing blood into a tube for a diabetes test" type="SBAR">
          <tokens>
            <token id="12" string="as" />
            <token id="13" string="nurse" />
            <token id="14" string="Mary" />
            <token id="15" string="Perez" />
            <token id="16" string="inserted" />
            <token id="17" string="a" />
            <token id="18" string="needle" />
            <token id="19" string="into" />
            <token id="20" string="the" />
            <token id="21" string="vein" />
            <token id="22" string="above" />
            <token id="23" string="her" />
            <token id="24" string="forearm" />
            <token id="25" string="," />
            <token id="26" string="drawing" />
            <token id="27" string="blood" />
            <token id="28" string="into" />
            <token id="29" string="a" />
            <token id="30" string="tube" />
            <token id="31" string="for" />
            <token id="32" string="a" />
            <token id="33" string="diabetes" />
            <token id="34" string="test" />
          </tokens>
        </chunking>
        <chunking id="10" string="her sleeve" type="NP">
          <tokens>
            <token id="10" string="her" />
            <token id="11" string="sleeve" />
          </tokens>
        </chunking>
        <chunking id="11" string="a small motor home" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="small" />
            <token id="4" string="motor" />
            <token id="5" string="home" />
          </tokens>
        </chunking>
        <chunking id="12" string="Joanne Pierluissi" type="NP">
          <tokens>
            <token id="7" string="Joanne" />
            <token id="8" string="Pierluissi" />
          </tokens>
        </chunking>
        <chunking id="13" string="a tube for a diabetes test" type="NP">
          <tokens>
            <token id="29" string="a" />
            <token id="30" string="tube" />
            <token id="31" string="for" />
            <token id="32" string="a" />
            <token id="33" string="diabetes" />
            <token id="34" string="test" />
          </tokens>
        </chunking>
        <chunking id="14" string="the vein above her forearm" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="vein" />
            <token id="22" string="above" />
            <token id="23" string="her" />
            <token id="24" string="forearm" />
          </tokens>
        </chunking>
        <chunking id="15" string="a tube" type="NP">
          <tokens>
            <token id="29" string="a" />
            <token id="30" string="tube" />
          </tokens>
        </chunking>
        <chunking id="16" string="nurse Mary Perez" type="NP">
          <tokens>
            <token id="13" string="nurse" />
            <token id="14" string="Mary" />
            <token id="15" string="Perez" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="5">home</governor>
          <dependent id="1">Inside</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">home</governor>
          <dependent id="2">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">home</governor>
          <dependent id="3">small</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">home</governor>
          <dependent id="4">motor</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">raised</governor>
          <dependent id="5">home</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Pierluissi</governor>
          <dependent id="7">Joanne</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">raised</governor>
          <dependent id="8">Pierluissi</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">raised</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">sleeve</governor>
          <dependent id="10">her</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">raised</governor>
          <dependent id="11">sleeve</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">inserted</governor>
          <dependent id="12">as</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Perez</governor>
          <dependent id="13">nurse</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Perez</governor>
          <dependent id="14">Mary</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">inserted</governor>
          <dependent id="15">Perez</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">raised</governor>
          <dependent id="16">inserted</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">needle</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">inserted</governor>
          <dependent id="18">needle</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">vein</governor>
          <dependent id="19">into</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">vein</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">inserted</governor>
          <dependent id="21">vein</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">forearm</governor>
          <dependent id="22">above</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="24">forearm</governor>
          <dependent id="23">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">vein</governor>
          <dependent id="24">forearm</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="16">inserted</governor>
          <dependent id="26">drawing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="26">drawing</governor>
          <dependent id="27">blood</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">tube</governor>
          <dependent id="28">into</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">tube</governor>
          <dependent id="29">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">drawing</governor>
          <dependent id="30">tube</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">test</governor>
          <dependent id="31">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">test</governor>
          <dependent id="32">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="34">test</governor>
          <dependent id="33">diabetes</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">tube</governor>
          <dependent id="34">test</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Mary Perez" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Mary" />
            <token id="15" string="Perez" />
          </tokens>
        </entity>
        <entity id="2" string="Joanne Pierluissi" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Joanne" />
            <token id="8" string="Pierluissi" />
          </tokens>
        </entity>
        <entity id="3" string="diabetes" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="33" string="diabetes" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>As her daughters watched, Pierluissi, 24, said it was for them, as much as for herself, that she agreed to be tested for the deadly killer of Hispanics.</content>
      <tokens>
        <token id="1" string="As" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="3" string="daughters" lemma="daughter" stem="daughter" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="watched" lemma="watch" stem="watch" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Pierluissi" lemma="pierluissi" stem="pierluissi" pos="NN" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="24" lemma="24" stem="24" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="as" lemma="as" stem="a" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="much" lemma="much" stem="much" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="herself" lemma="herself" stem="herself" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="agreed" lemma="agree" stem="agre" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="tested" lemma="test" stem="test" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="deadly" lemma="deadly" stem="deadli" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="killer" lemma="killer" stem="killer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="Hispanics" lemma="Hispanics" stem="hispan" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="34" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN As) (NP (NP (PRP$ her) (NNS daughters)) (VP (VBN watched)))) (, ,) (NP (NP (NN Pierluissi)) (, ,) (NP (CD 24)) (, ,)) (VP (VBD said) (SBAR (S (NP (PRP it)) (VP (VBD was) (PP (IN for) (NP (PRP them))) (, ,) (PP (ADVP (RB as) (RB much)) (IN as) (IN for) (NP (PRP herself))) (, ,) (SBAR (IN that) (S (NP (PRP she)) (VP (VBD agreed) (S (VP (TO to) (VP (VB be) (VP (VBN tested) (PP (IN for) (NP (NP (DT the) (JJ deadly) (NN killer)) (PP (IN of) (NP (NNPS Hispanics)))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Pierluissi" type="NP">
          <tokens>
            <token id="6" string="Pierluissi" />
          </tokens>
        </chunking>
        <chunking id="2" string="24" type="NP">
          <tokens>
            <token id="8" string="24" />
          </tokens>
        </chunking>
        <chunking id="3" string="be tested for the deadly killer of Hispanics" type="VP">
          <tokens>
            <token id="26" string="be" />
            <token id="27" string="tested" />
            <token id="28" string="for" />
            <token id="29" string="the" />
            <token id="30" string="deadly" />
            <token id="31" string="killer" />
            <token id="32" string="of" />
            <token id="33" string="Hispanics" />
          </tokens>
        </chunking>
        <chunking id="4" string="Pierluissi , 24 ," type="NP">
          <tokens>
            <token id="6" string="Pierluissi" />
            <token id="7" string="," />
            <token id="8" string="24" />
            <token id="9" string="," />
          </tokens>
        </chunking>
        <chunking id="5" string="her daughters watched" type="NP">
          <tokens>
            <token id="2" string="her" />
            <token id="3" string="daughters" />
            <token id="4" string="watched" />
          </tokens>
        </chunking>
        <chunking id="6" string="it was for them , as much as for herself , that she agreed to be tested for the deadly killer of Hispanics" type="SBAR">
          <tokens>
            <token id="11" string="it" />
            <token id="12" string="was" />
            <token id="13" string="for" />
            <token id="14" string="them" />
            <token id="15" string="," />
            <token id="16" string="as" />
            <token id="17" string="much" />
            <token id="18" string="as" />
            <token id="19" string="for" />
            <token id="20" string="herself" />
            <token id="21" string="," />
            <token id="22" string="that" />
            <token id="23" string="she" />
            <token id="24" string="agreed" />
            <token id="25" string="to" />
            <token id="26" string="be" />
            <token id="27" string="tested" />
            <token id="28" string="for" />
            <token id="29" string="the" />
            <token id="30" string="deadly" />
            <token id="31" string="killer" />
            <token id="32" string="of" />
            <token id="33" string="Hispanics" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="11" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="to be tested for the deadly killer of Hispanics" type="VP">
          <tokens>
            <token id="25" string="to" />
            <token id="26" string="be" />
            <token id="27" string="tested" />
            <token id="28" string="for" />
            <token id="29" string="the" />
            <token id="30" string="deadly" />
            <token id="31" string="killer" />
            <token id="32" string="of" />
            <token id="33" string="Hispanics" />
          </tokens>
        </chunking>
        <chunking id="9" string="the deadly killer" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="deadly" />
            <token id="31" string="killer" />
          </tokens>
        </chunking>
        <chunking id="10" string="them" type="NP">
          <tokens>
            <token id="14" string="them" />
          </tokens>
        </chunking>
        <chunking id="11" string="she" type="NP">
          <tokens>
            <token id="23" string="she" />
          </tokens>
        </chunking>
        <chunking id="12" string="her daughters" type="NP">
          <tokens>
            <token id="2" string="her" />
            <token id="3" string="daughters" />
          </tokens>
        </chunking>
        <chunking id="13" string="watched" type="VP">
          <tokens>
            <token id="4" string="watched" />
          </tokens>
        </chunking>
        <chunking id="14" string="agreed to be tested for the deadly killer of Hispanics" type="VP">
          <tokens>
            <token id="24" string="agreed" />
            <token id="25" string="to" />
            <token id="26" string="be" />
            <token id="27" string="tested" />
            <token id="28" string="for" />
            <token id="29" string="the" />
            <token id="30" string="deadly" />
            <token id="31" string="killer" />
            <token id="32" string="of" />
            <token id="33" string="Hispanics" />
          </tokens>
        </chunking>
        <chunking id="15" string="said it was for them , as much as for herself , that she agreed to be tested for the deadly killer of Hispanics" type="VP">
          <tokens>
            <token id="10" string="said" />
            <token id="11" string="it" />
            <token id="12" string="was" />
            <token id="13" string="for" />
            <token id="14" string="them" />
            <token id="15" string="," />
            <token id="16" string="as" />
            <token id="17" string="much" />
            <token id="18" string="as" />
            <token id="19" string="for" />
            <token id="20" string="herself" />
            <token id="21" string="," />
            <token id="22" string="that" />
            <token id="23" string="she" />
            <token id="24" string="agreed" />
            <token id="25" string="to" />
            <token id="26" string="be" />
            <token id="27" string="tested" />
            <token id="28" string="for" />
            <token id="29" string="the" />
            <token id="30" string="deadly" />
            <token id="31" string="killer" />
            <token id="32" string="of" />
            <token id="33" string="Hispanics" />
          </tokens>
        </chunking>
        <chunking id="16" string="tested for the deadly killer of Hispanics" type="VP">
          <tokens>
            <token id="27" string="tested" />
            <token id="28" string="for" />
            <token id="29" string="the" />
            <token id="30" string="deadly" />
            <token id="31" string="killer" />
            <token id="32" string="of" />
            <token id="33" string="Hispanics" />
          </tokens>
        </chunking>
        <chunking id="17" string="the deadly killer of Hispanics" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="deadly" />
            <token id="31" string="killer" />
            <token id="32" string="of" />
            <token id="33" string="Hispanics" />
          </tokens>
        </chunking>
        <chunking id="18" string="was for them , as much as for herself , that she agreed to be tested for the deadly killer of Hispanics" type="VP">
          <tokens>
            <token id="12" string="was" />
            <token id="13" string="for" />
            <token id="14" string="them" />
            <token id="15" string="," />
            <token id="16" string="as" />
            <token id="17" string="much" />
            <token id="18" string="as" />
            <token id="19" string="for" />
            <token id="20" string="herself" />
            <token id="21" string="," />
            <token id="22" string="that" />
            <token id="23" string="she" />
            <token id="24" string="agreed" />
            <token id="25" string="to" />
            <token id="26" string="be" />
            <token id="27" string="tested" />
            <token id="28" string="for" />
            <token id="29" string="the" />
            <token id="30" string="deadly" />
            <token id="31" string="killer" />
            <token id="32" string="of" />
            <token id="33" string="Hispanics" />
          </tokens>
        </chunking>
        <chunking id="19" string="herself" type="NP">
          <tokens>
            <token id="20" string="herself" />
          </tokens>
        </chunking>
        <chunking id="20" string="that she agreed to be tested for the deadly killer of Hispanics" type="SBAR">
          <tokens>
            <token id="22" string="that" />
            <token id="23" string="she" />
            <token id="24" string="agreed" />
            <token id="25" string="to" />
            <token id="26" string="be" />
            <token id="27" string="tested" />
            <token id="28" string="for" />
            <token id="29" string="the" />
            <token id="30" string="deadly" />
            <token id="31" string="killer" />
            <token id="32" string="of" />
            <token id="33" string="Hispanics" />
          </tokens>
        </chunking>
        <chunking id="21" string="Hispanics" type="NP">
          <tokens>
            <token id="33" string="Hispanics" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">daughters</governor>
          <dependent id="1">As</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="3">daughters</governor>
          <dependent id="2">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">said</governor>
          <dependent id="3">daughters</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="3">daughters</governor>
          <dependent id="4">watched</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">said</governor>
          <dependent id="6">Pierluissi</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">Pierluissi</governor>
          <dependent id="8">24</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">them</governor>
          <dependent id="11">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">them</governor>
          <dependent id="12">was</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">them</governor>
          <dependent id="13">for</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">said</governor>
          <dependent id="14">them</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">much</governor>
          <dependent id="16">as</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">herself</governor>
          <dependent id="17">much</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">herself</governor>
          <dependent id="18">as</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="18">as</governor>
          <dependent id="19">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">them</governor>
          <dependent id="20">herself</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">agreed</governor>
          <dependent id="22">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">agreed</governor>
          <dependent id="23">she</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">them</governor>
          <dependent id="24">agreed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="27">tested</governor>
          <dependent id="25">to</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="27">tested</governor>
          <dependent id="26">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="24">agreed</governor>
          <dependent id="27">tested</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">killer</governor>
          <dependent id="28">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">killer</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">killer</governor>
          <dependent id="30">deadly</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">tested</governor>
          <dependent id="31">killer</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">Hispanics</governor>
          <dependent id="32">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">killer</governor>
          <dependent id="33">Hispanics</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Pierluissi" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Pierluissi" />
          </tokens>
        </entity>
        <entity id="2" string="24" type="NUMBER" score="0.0">
          <tokens>
            <token id="8" string="24" />
          </tokens>
        </entity>
        <entity id="3" string="Hispanics" type="MISC" score="0.0">
          <tokens>
            <token id="33" string="Hispanics" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>``I was concerned because they said an aunt of mine had it and I just wanted to come for the checkup.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="concerned" lemma="concern" stem="concern" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="aunt" lemma="aunt" stem="aunt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="mine" lemma="mine" stem="mine" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="wanted" lemma="want" stem="want" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="come" lemma="come" stem="come" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="checkup" lemma="checkup" stem="checkup" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP I)) (VP (VBD was) (VP (VBN concerned) (SBAR (IN because) (S (NP (PRP they)) (VP (VBD said) (SBAR (S (NP (NP (DT an) (NN aunt)) (PP (IN of) (NP (NN mine)))) (VP (VBD had) (NP (PRP it))))))))))) (CC and) (S (NP (PRP I)) (ADVP (RB just)) (VP (VBD wanted) (S (VP (TO to) (VP (VB come) (PP (IN for) (NP (DT the) (NN checkup)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="mine" type="NP">
          <tokens>
            <token id="11" string="mine" />
          </tokens>
        </chunking>
        <chunking id="2" string="an aunt of mine had it" type="SBAR">
          <tokens>
            <token id="8" string="an" />
            <token id="9" string="aunt" />
            <token id="10" string="of" />
            <token id="11" string="mine" />
            <token id="12" string="had" />
            <token id="13" string="it" />
          </tokens>
        </chunking>
        <chunking id="3" string="to come for the checkup" type="VP">
          <tokens>
            <token id="18" string="to" />
            <token id="19" string="come" />
            <token id="20" string="for" />
            <token id="21" string="the" />
            <token id="22" string="checkup" />
          </tokens>
        </chunking>
        <chunking id="4" string="because they said an aunt of mine had it" type="SBAR">
          <tokens>
            <token id="5" string="because" />
            <token id="6" string="they" />
            <token id="7" string="said" />
            <token id="8" string="an" />
            <token id="9" string="aunt" />
            <token id="10" string="of" />
            <token id="11" string="mine" />
            <token id="12" string="had" />
            <token id="13" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="had it" type="VP">
          <tokens>
            <token id="12" string="had" />
            <token id="13" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="concerned because they said an aunt of mine had it" type="VP">
          <tokens>
            <token id="4" string="concerned" />
            <token id="5" string="because" />
            <token id="6" string="they" />
            <token id="7" string="said" />
            <token id="8" string="an" />
            <token id="9" string="aunt" />
            <token id="10" string="of" />
            <token id="11" string="mine" />
            <token id="12" string="had" />
            <token id="13" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="8" string="the checkup" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="checkup" />
          </tokens>
        </chunking>
        <chunking id="9" string="it" type="NP">
          <tokens>
            <token id="13" string="it" />
          </tokens>
        </chunking>
        <chunking id="10" string="was concerned because they said an aunt of mine had it" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="concerned" />
            <token id="5" string="because" />
            <token id="6" string="they" />
            <token id="7" string="said" />
            <token id="8" string="an" />
            <token id="9" string="aunt" />
            <token id="10" string="of" />
            <token id="11" string="mine" />
            <token id="12" string="had" />
            <token id="13" string="it" />
          </tokens>
        </chunking>
        <chunking id="11" string="an aunt" type="NP">
          <tokens>
            <token id="8" string="an" />
            <token id="9" string="aunt" />
          </tokens>
        </chunking>
        <chunking id="12" string="they" type="NP">
          <tokens>
            <token id="6" string="they" />
          </tokens>
        </chunking>
        <chunking id="13" string="come for the checkup" type="VP">
          <tokens>
            <token id="19" string="come" />
            <token id="20" string="for" />
            <token id="21" string="the" />
            <token id="22" string="checkup" />
          </tokens>
        </chunking>
        <chunking id="14" string="said an aunt of mine had it" type="VP">
          <tokens>
            <token id="7" string="said" />
            <token id="8" string="an" />
            <token id="9" string="aunt" />
            <token id="10" string="of" />
            <token id="11" string="mine" />
            <token id="12" string="had" />
            <token id="13" string="it" />
          </tokens>
        </chunking>
        <chunking id="15" string="an aunt of mine" type="NP">
          <tokens>
            <token id="8" string="an" />
            <token id="9" string="aunt" />
            <token id="10" string="of" />
            <token id="11" string="mine" />
          </tokens>
        </chunking>
        <chunking id="16" string="wanted to come for the checkup" type="VP">
          <tokens>
            <token id="17" string="wanted" />
            <token id="18" string="to" />
            <token id="19" string="come" />
            <token id="20" string="for" />
            <token id="21" string="the" />
            <token id="22" string="checkup" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="4">concerned</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">concerned</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">concerned</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">said</governor>
          <dependent id="5">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">said</governor>
          <dependent id="6">they</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">concerned</governor>
          <dependent id="7">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">aunt</governor>
          <dependent id="8">an</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">had</governor>
          <dependent id="9">aunt</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">mine</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">aunt</governor>
          <dependent id="11">mine</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">said</governor>
          <dependent id="12">had</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">had</governor>
          <dependent id="13">it</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">concerned</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">wanted</governor>
          <dependent id="15">I</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">wanted</governor>
          <dependent id="16">just</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">concerned</governor>
          <dependent id="17">wanted</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">come</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="17">wanted</governor>
          <dependent id="19">come</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">checkup</governor>
          <dependent id="20">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">checkup</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">come</governor>
          <dependent id="22">checkup</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>All of our family is going to go through the program to make sure that if we have it that we&amp;apost;ll do something about it.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="All" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="our" lemma="we" stem="our" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="family" lemma="family" stem="famili" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="go" lemma="go" stem="go" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="program" lemma="program" stem="program" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="make" lemma="make" stem="make" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="sure" lemma="sure" stem="sure" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="18" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="20" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="'ll" lemma="will" stem="'ll" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="do" lemma="do" stem="do" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="something" lemma="something" stem="someth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT All)) (PP (IN of) (NP (PRP$ our) (NN family)))) (VP (VBZ is) (VP (VBG going) (S (VP (TO to) (VP (VB go) (PP (IN through) (NP (DT the) (NN program) (S (VP (TO to) (VP (VB make) (ADJP (JJ sure)) (SBAR (IN that) (IN if) (S (NP (PRP we)) (VP (VBP have) (NP (PRP it)))))))))) (SBAR (IN that) (S (NP (PRP we)) (VP (MD 'll) (VP (VB do) (NP (NN something)) (PP (IN about) (NP (PRP it)))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="going to go through the program to make sure that if we have it that we 'll do something about it" type="VP">
          <tokens>
            <token id="6" string="going" />
            <token id="7" string="to" />
            <token id="8" string="go" />
            <token id="9" string="through" />
            <token id="10" string="the" />
            <token id="11" string="program" />
            <token id="12" string="to" />
            <token id="13" string="make" />
            <token id="14" string="sure" />
            <token id="15" string="that" />
            <token id="16" string="if" />
            <token id="17" string="we" />
            <token id="18" string="have" />
            <token id="19" string="it" />
            <token id="20" string="that" />
            <token id="21" string="we" />
            <token id="22" string="'ll" />
            <token id="23" string="do" />
            <token id="24" string="something" />
            <token id="25" string="about" />
            <token id="26" string="it" />
          </tokens>
        </chunking>
        <chunking id="2" string="All" type="NP">
          <tokens>
            <token id="1" string="All" />
          </tokens>
        </chunking>
        <chunking id="3" string="sure" type="ADJP">
          <tokens>
            <token id="14" string="sure" />
          </tokens>
        </chunking>
        <chunking id="4" string="All of our family" type="NP">
          <tokens>
            <token id="1" string="All" />
            <token id="2" string="of" />
            <token id="3" string="our" />
            <token id="4" string="family" />
          </tokens>
        </chunking>
        <chunking id="5" string="is going to go through the program to make sure that if we have it that we 'll do something about it" type="VP">
          <tokens>
            <token id="5" string="is" />
            <token id="6" string="going" />
            <token id="7" string="to" />
            <token id="8" string="go" />
            <token id="9" string="through" />
            <token id="10" string="the" />
            <token id="11" string="program" />
            <token id="12" string="to" />
            <token id="13" string="make" />
            <token id="14" string="sure" />
            <token id="15" string="that" />
            <token id="16" string="if" />
            <token id="17" string="we" />
            <token id="18" string="have" />
            <token id="19" string="it" />
            <token id="20" string="that" />
            <token id="21" string="we" />
            <token id="22" string="'ll" />
            <token id="23" string="do" />
            <token id="24" string="something" />
            <token id="25" string="about" />
            <token id="26" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="'ll do something about it" type="VP">
          <tokens>
            <token id="22" string="'ll" />
            <token id="23" string="do" />
            <token id="24" string="something" />
            <token id="25" string="about" />
            <token id="26" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="19" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="to make sure that if we have it" type="VP">
          <tokens>
            <token id="12" string="to" />
            <token id="13" string="make" />
            <token id="14" string="sure" />
            <token id="15" string="that" />
            <token id="16" string="if" />
            <token id="17" string="we" />
            <token id="18" string="have" />
            <token id="19" string="it" />
          </tokens>
        </chunking>
        <chunking id="9" string="go through the program to make sure that if we have it that we 'll do something about it" type="VP">
          <tokens>
            <token id="8" string="go" />
            <token id="9" string="through" />
            <token id="10" string="the" />
            <token id="11" string="program" />
            <token id="12" string="to" />
            <token id="13" string="make" />
            <token id="14" string="sure" />
            <token id="15" string="that" />
            <token id="16" string="if" />
            <token id="17" string="we" />
            <token id="18" string="have" />
            <token id="19" string="it" />
            <token id="20" string="that" />
            <token id="21" string="we" />
            <token id="22" string="'ll" />
            <token id="23" string="do" />
            <token id="24" string="something" />
            <token id="25" string="about" />
            <token id="26" string="it" />
          </tokens>
        </chunking>
        <chunking id="10" string="make sure that if we have it" type="VP">
          <tokens>
            <token id="13" string="make" />
            <token id="14" string="sure" />
            <token id="15" string="that" />
            <token id="16" string="if" />
            <token id="17" string="we" />
            <token id="18" string="have" />
            <token id="19" string="it" />
          </tokens>
        </chunking>
        <chunking id="11" string="we" type="NP">
          <tokens>
            <token id="17" string="we" />
          </tokens>
        </chunking>
        <chunking id="12" string="something" type="NP">
          <tokens>
            <token id="24" string="something" />
          </tokens>
        </chunking>
        <chunking id="13" string="the program to make sure that if we have it" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="program" />
            <token id="12" string="to" />
            <token id="13" string="make" />
            <token id="14" string="sure" />
            <token id="15" string="that" />
            <token id="16" string="if" />
            <token id="17" string="we" />
            <token id="18" string="have" />
            <token id="19" string="it" />
          </tokens>
        </chunking>
        <chunking id="14" string="our family" type="NP">
          <tokens>
            <token id="3" string="our" />
            <token id="4" string="family" />
          </tokens>
        </chunking>
        <chunking id="15" string="that we 'll do something about it" type="SBAR">
          <tokens>
            <token id="20" string="that" />
            <token id="21" string="we" />
            <token id="22" string="'ll" />
            <token id="23" string="do" />
            <token id="24" string="something" />
            <token id="25" string="about" />
            <token id="26" string="it" />
          </tokens>
        </chunking>
        <chunking id="16" string="do something about it" type="VP">
          <tokens>
            <token id="23" string="do" />
            <token id="24" string="something" />
            <token id="25" string="about" />
            <token id="26" string="it" />
          </tokens>
        </chunking>
        <chunking id="17" string="have it" type="VP">
          <tokens>
            <token id="18" string="have" />
            <token id="19" string="it" />
          </tokens>
        </chunking>
        <chunking id="18" string="to go through the program to make sure that if we have it that we 'll do something about it" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="go" />
            <token id="9" string="through" />
            <token id="10" string="the" />
            <token id="11" string="program" />
            <token id="12" string="to" />
            <token id="13" string="make" />
            <token id="14" string="sure" />
            <token id="15" string="that" />
            <token id="16" string="if" />
            <token id="17" string="we" />
            <token id="18" string="have" />
            <token id="19" string="it" />
            <token id="20" string="that" />
            <token id="21" string="we" />
            <token id="22" string="'ll" />
            <token id="23" string="do" />
            <token id="24" string="something" />
            <token id="25" string="about" />
            <token id="26" string="it" />
          </tokens>
        </chunking>
        <chunking id="19" string="that if we have it" type="SBAR">
          <tokens>
            <token id="15" string="that" />
            <token id="16" string="if" />
            <token id="17" string="we" />
            <token id="18" string="have" />
            <token id="19" string="it" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">going</governor>
          <dependent id="1">All</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">family</governor>
          <dependent id="2">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">family</governor>
          <dependent id="3">our</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">All</governor>
          <dependent id="4">family</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">going</governor>
          <dependent id="5">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">going</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">go</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">going</governor>
          <dependent id="8">go</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">program</governor>
          <dependent id="9">through</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">program</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">go</governor>
          <dependent id="11">program</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">make</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="11">program</governor>
          <dependent id="13">make</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="13">make</governor>
          <dependent id="14">sure</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">have</governor>
          <dependent id="15">that</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">have</governor>
          <dependent id="16">if</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">have</governor>
          <dependent id="17">we</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="13">make</governor>
          <dependent id="18">have</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">have</governor>
          <dependent id="19">it</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">do</governor>
          <dependent id="20">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">do</governor>
          <dependent id="21">we</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="23">do</governor>
          <dependent id="22">'ll</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">go</governor>
          <dependent id="23">do</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">do</governor>
          <dependent id="24">something</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">it</governor>
          <dependent id="25">about</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">do</governor>
          <dependent id="26">it</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>Twelve million Americans have some form of diabetes, but it is most prevalent among minorities, especially Native Americans, blacks and Hispanics.</content>
      <tokens>
        <token id="1" string="Twelve" lemma="twelve" stem="twelv" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="2" string="million" lemma="million" stem="million" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="3" string="Americans" lemma="Americans" stem="american" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="4" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="form" lemma="form" stem="form" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="diabetes" lemma="diabetes" stem="diabet" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="most" lemma="most" stem="most" pos="RBS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="prevalent" lemma="prevalent" stem="preval" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="among" lemma="among" stem="among" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="minorities" lemma="minority" stem="minor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="especially" lemma="especially" stem="especi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="Native" lemma="native" stem="nativ" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="20" string="Americans" lemma="Americans" stem="american" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="blacks" lemma="black" stem="black" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="Hispanics" lemma="Hispanics" stem="hispan" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (QP (CD Twelve) (CD million)) (NNPS Americans)) (VP (VBP have) (NP (NP (DT some) (NN form)) (PP (IN of) (NP (NN diabetes)))))) (, ,) (CC but) (S (NP (PRP it)) (VP (VBZ is) (ADJP (ADJP (RBS most) (JJ prevalent)) (PP (IN among) (NP (NP (NNS minorities)) (, ,) (NP (RB especially) (JJ Native) (NNPS Americans)) (, ,) (NP (NNS blacks)) (CC and) (NP (NNPS Hispanics))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="most prevalent" type="ADJP">
          <tokens>
            <token id="13" string="most" />
            <token id="14" string="prevalent" />
          </tokens>
        </chunking>
        <chunking id="2" string="minorities" type="NP">
          <tokens>
            <token id="16" string="minorities" />
          </tokens>
        </chunking>
        <chunking id="3" string="especially Native Americans" type="NP">
          <tokens>
            <token id="18" string="especially" />
            <token id="19" string="Native" />
            <token id="20" string="Americans" />
          </tokens>
        </chunking>
        <chunking id="4" string="is most prevalent among minorities , especially Native Americans , blacks and Hispanics" type="VP">
          <tokens>
            <token id="12" string="is" />
            <token id="13" string="most" />
            <token id="14" string="prevalent" />
            <token id="15" string="among" />
            <token id="16" string="minorities" />
            <token id="17" string="," />
            <token id="18" string="especially" />
            <token id="19" string="Native" />
            <token id="20" string="Americans" />
            <token id="21" string="," />
            <token id="22" string="blacks" />
            <token id="23" string="and" />
            <token id="24" string="Hispanics" />
          </tokens>
        </chunking>
        <chunking id="5" string="blacks" type="NP">
          <tokens>
            <token id="22" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="6" string="Twelve million Americans" type="NP">
          <tokens>
            <token id="1" string="Twelve" />
            <token id="2" string="million" />
            <token id="3" string="Americans" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="11" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="most prevalent among minorities , especially Native Americans , blacks and Hispanics" type="ADJP">
          <tokens>
            <token id="13" string="most" />
            <token id="14" string="prevalent" />
            <token id="15" string="among" />
            <token id="16" string="minorities" />
            <token id="17" string="," />
            <token id="18" string="especially" />
            <token id="19" string="Native" />
            <token id="20" string="Americans" />
            <token id="21" string="," />
            <token id="22" string="blacks" />
            <token id="23" string="and" />
            <token id="24" string="Hispanics" />
          </tokens>
        </chunking>
        <chunking id="9" string="have some form of diabetes" type="VP">
          <tokens>
            <token id="4" string="have" />
            <token id="5" string="some" />
            <token id="6" string="form" />
            <token id="7" string="of" />
            <token id="8" string="diabetes" />
          </tokens>
        </chunking>
        <chunking id="10" string="some form of diabetes" type="NP">
          <tokens>
            <token id="5" string="some" />
            <token id="6" string="form" />
            <token id="7" string="of" />
            <token id="8" string="diabetes" />
          </tokens>
        </chunking>
        <chunking id="11" string="minorities , especially Native Americans , blacks and Hispanics" type="NP">
          <tokens>
            <token id="16" string="minorities" />
            <token id="17" string="," />
            <token id="18" string="especially" />
            <token id="19" string="Native" />
            <token id="20" string="Americans" />
            <token id="21" string="," />
            <token id="22" string="blacks" />
            <token id="23" string="and" />
            <token id="24" string="Hispanics" />
          </tokens>
        </chunking>
        <chunking id="12" string="some form" type="NP">
          <tokens>
            <token id="5" string="some" />
            <token id="6" string="form" />
          </tokens>
        </chunking>
        <chunking id="13" string="diabetes" type="NP">
          <tokens>
            <token id="8" string="diabetes" />
          </tokens>
        </chunking>
        <chunking id="14" string="Hispanics" type="NP">
          <tokens>
            <token id="24" string="Hispanics" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">million</governor>
          <dependent id="1">Twelve</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="3">Americans</governor>
          <dependent id="2">million</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">have</governor>
          <dependent id="3">Americans</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">have</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">form</governor>
          <dependent id="5">some</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">have</governor>
          <dependent id="6">form</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">diabetes</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">form</governor>
          <dependent id="8">diabetes</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">have</governor>
          <dependent id="10">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">prevalent</governor>
          <dependent id="11">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">prevalent</governor>
          <dependent id="12">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">prevalent</governor>
          <dependent id="13">most</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">have</governor>
          <dependent id="14">prevalent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">minorities</governor>
          <dependent id="15">among</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">prevalent</governor>
          <dependent id="16">minorities</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">Americans</governor>
          <dependent id="18">especially</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">Americans</governor>
          <dependent id="19">Native</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">minorities</governor>
          <dependent id="20">Americans</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">minorities</governor>
          <dependent id="22">blacks</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">minorities</governor>
          <dependent id="23">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">minorities</governor>
          <dependent id="24">Hispanics</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Americans" type="MISC" score="0.0">
          <tokens>
            <token id="3" string="Americans" />
          </tokens>
        </entity>
        <entity id="2" string="Native Americans" type="MISC" score="0.0">
          <tokens>
            <token id="19" string="Native" />
            <token id="20" string="Americans" />
          </tokens>
        </entity>
        <entity id="3" string="Twelve million" type="NUMBER" score="0.0">
          <tokens>
            <token id="1" string="Twelve" />
            <token id="2" string="million" />
          </tokens>
        </entity>
        <entity id="4" string="diabetes" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="8" string="diabetes" />
          </tokens>
        </entity>
        <entity id="5" string="Hispanics" type="MISC" score="0.0">
          <tokens>
            <token id="24" string="Hispanics" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>Hispanics are three times as likely to develop diabetes as the general population, and 40 percent of the 700,000 victims in Texas are Mexican-American.</content>
      <tokens>
        <token id="1" string="Hispanics" lemma="Hispanics" stem="hispan" pos="NNPS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="three" lemma="three" stem="three" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="4" string="times" lemma="time" stem="time" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="likely" lemma="likely" stem="like" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="develop" lemma="develop" stem="develop" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="diabetes" lemma="diabetes" stem="diabet" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="10" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="general" lemma="general" stem="gener" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="population" lemma="population" stem="popul" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="40" lemma="40" stem="40" pos="CD" type="Number" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="17" string="percent" lemma="percent" stem="percent" pos="NN" type="Word" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="18" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="700,000" lemma="700,000" stem="700,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="21" string="victims" lemma="victim" stem="victim" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="Texas" lemma="Texas" stem="texa" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="24" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="Mexican-American" lemma="mexican-american" stem="mexican-american" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNPS Hispanics)) (VP (VBP are) (ADVP (NP (CD three) (NNS times)) (IN as)) (ADJP (JJ likely) (S (VP (TO to) (VP (VB develop) (NP (NN diabetes)) (PP (IN as) (NP (DT the) (JJ general) (NN population))))))))) (, ,) (CC and) (S (NP (NP (CD 40) (NN percent)) (PP (IN of) (NP (NP (DT the) (CD 700,000) (NNS victims)) (PP (IN in) (NP (NNP Texas)))))) (VP (VBP are) (ADJP (JJ Mexican-American)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="are Mexican-American" type="VP">
          <tokens>
            <token id="24" string="are" />
            <token id="25" string="Mexican-American" />
          </tokens>
        </chunking>
        <chunking id="2" string="three times" type="NP">
          <tokens>
            <token id="3" string="three" />
            <token id="4" string="times" />
          </tokens>
        </chunking>
        <chunking id="3" string="40 percent of the 700,000 victims in Texas" type="NP">
          <tokens>
            <token id="16" string="40" />
            <token id="17" string="percent" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="700,000" />
            <token id="21" string="victims" />
            <token id="22" string="in" />
            <token id="23" string="Texas" />
          </tokens>
        </chunking>
        <chunking id="4" string="are three times as likely to develop diabetes as the general population" type="VP">
          <tokens>
            <token id="2" string="are" />
            <token id="3" string="three" />
            <token id="4" string="times" />
            <token id="5" string="as" />
            <token id="6" string="likely" />
            <token id="7" string="to" />
            <token id="8" string="develop" />
            <token id="9" string="diabetes" />
            <token id="10" string="as" />
            <token id="11" string="the" />
            <token id="12" string="general" />
            <token id="13" string="population" />
          </tokens>
        </chunking>
        <chunking id="5" string="40 percent" type="NP">
          <tokens>
            <token id="16" string="40" />
            <token id="17" string="percent" />
          </tokens>
        </chunking>
        <chunking id="6" string="the 700,000 victims in Texas" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="700,000" />
            <token id="21" string="victims" />
            <token id="22" string="in" />
            <token id="23" string="Texas" />
          </tokens>
        </chunking>
        <chunking id="7" string="likely to develop diabetes as the general population" type="ADJP">
          <tokens>
            <token id="6" string="likely" />
            <token id="7" string="to" />
            <token id="8" string="develop" />
            <token id="9" string="diabetes" />
            <token id="10" string="as" />
            <token id="11" string="the" />
            <token id="12" string="general" />
            <token id="13" string="population" />
          </tokens>
        </chunking>
        <chunking id="8" string="the 700,000 victims" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="700,000" />
            <token id="21" string="victims" />
          </tokens>
        </chunking>
        <chunking id="9" string="develop diabetes as the general population" type="VP">
          <tokens>
            <token id="8" string="develop" />
            <token id="9" string="diabetes" />
            <token id="10" string="as" />
            <token id="11" string="the" />
            <token id="12" string="general" />
            <token id="13" string="population" />
          </tokens>
        </chunking>
        <chunking id="10" string="Texas" type="NP">
          <tokens>
            <token id="23" string="Texas" />
          </tokens>
        </chunking>
        <chunking id="11" string="the general population" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="general" />
            <token id="13" string="population" />
          </tokens>
        </chunking>
        <chunking id="12" string="to develop diabetes as the general population" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="develop" />
            <token id="9" string="diabetes" />
            <token id="10" string="as" />
            <token id="11" string="the" />
            <token id="12" string="general" />
            <token id="13" string="population" />
          </tokens>
        </chunking>
        <chunking id="13" string="diabetes" type="NP">
          <tokens>
            <token id="9" string="diabetes" />
          </tokens>
        </chunking>
        <chunking id="14" string="Hispanics" type="NP">
          <tokens>
            <token id="1" string="Hispanics" />
          </tokens>
        </chunking>
        <chunking id="15" string="Mexican-American" type="ADJP">
          <tokens>
            <token id="25" string="Mexican-American" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">likely</governor>
          <dependent id="1">Hispanics</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">likely</governor>
          <dependent id="2">are</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="4">times</governor>
          <dependent id="3">three</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">likely</governor>
          <dependent id="4">times</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">times</governor>
          <dependent id="5">as</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">likely</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">develop</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">likely</governor>
          <dependent id="8">develop</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">develop</governor>
          <dependent id="9">diabetes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">population</governor>
          <dependent id="10">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">population</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">population</governor>
          <dependent id="12">general</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">develop</governor>
          <dependent id="13">population</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">likely</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="17">percent</governor>
          <dependent id="16">40</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">Mexican-American</governor>
          <dependent id="17">percent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">victims</governor>
          <dependent id="18">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">victims</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="21">victims</governor>
          <dependent id="20">700,000</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">percent</governor>
          <dependent id="21">victims</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">Texas</governor>
          <dependent id="22">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">victims</governor>
          <dependent id="23">Texas</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="25">Mexican-American</governor>
          <dependent id="24">are</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">likely</governor>
          <dependent id="25">Mexican-American</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="700,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="20" string="700,000" />
          </tokens>
        </entity>
        <entity id="2" string="Texas" type="LOCATION" score="0.0">
          <tokens>
            <token id="23" string="Texas" />
          </tokens>
        </entity>
        <entity id="3" string="diabetes" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="9" string="diabetes" />
          </tokens>
        </entity>
        <entity id="4" string="40 percent" type="PERCENT" score="0.0">
          <tokens>
            <token id="16" string="40" />
            <token id="17" string="percent" />
          </tokens>
        </entity>
        <entity id="5" string="three" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="three" />
          </tokens>
        </entity>
        <entity id="6" string="Mexican-American" type="MISC" score="0.0">
          <tokens>
            <token id="25" string="Mexican-American" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>More than 150,000 Americans die from diabetes each year; another 150,000 deaths are diabetes-related, according to the American Diabetes Association.</content>
      <tokens>
        <token id="1" string="More" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="150,000" lemma="150,000" stem="150,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="4" string="Americans" lemma="Americans" stem="american" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="5" string="die" lemma="die" stem="die" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="diabetes" lemma="diabetes" stem="diabet" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="false" />
        <token id="8" string="each" lemma="each" stem="each" pos="DT" type="Word" isStopWord="true" ner="SET" is_referenced="true" is_refers="false" />
        <token id="9" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="SET" is_referenced="true" is_refers="false" />
        <token id="10" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="another" lemma="another" stem="anoth" pos="DT" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="150,000" lemma="150,000" stem="150,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="13" string="deaths" lemma="death" stem="death" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="diabetes-related" lemma="diabetes-related" stem="diabetes-rel" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="according" lemma="accord" stem="accord" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="American" lemma="american" stem="american" pos="JJ" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="21" string="Diabetes" lemma="Diabetes" stem="diabet" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="22" string="Association" lemma="Association" stem="associat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (QP (JJR More) (IN than) (CD 150,000)) (NNPS Americans)) (VP (VB die) (PP (IN from) (NP (NP (NP (NN diabetes)) (NP (DT each) (NN year))) (: ;) (S (NP (DT another) (CD 150,000) (NNS deaths)) (VP (VBP are) (ADJP (JJ diabetes-related)) (, ,) (PP (VBG according) (PP (TO to) (NP (DT the) (JJ American) (NNP Diabetes) (NNP Association))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the American Diabetes Association" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="American" />
            <token id="21" string="Diabetes" />
            <token id="22" string="Association" />
          </tokens>
        </chunking>
        <chunking id="2" string="More than 150,000 Americans" type="NP">
          <tokens>
            <token id="1" string="More" />
            <token id="2" string="than" />
            <token id="3" string="150,000" />
            <token id="4" string="Americans" />
          </tokens>
        </chunking>
        <chunking id="3" string="diabetes each year" type="NP">
          <tokens>
            <token id="7" string="diabetes" />
            <token id="8" string="each" />
            <token id="9" string="year" />
          </tokens>
        </chunking>
        <chunking id="4" string="each year" type="NP">
          <tokens>
            <token id="8" string="each" />
            <token id="9" string="year" />
          </tokens>
        </chunking>
        <chunking id="5" string="diabetes each year ; another 150,000 deaths are diabetes-related , according to the American Diabetes Association" type="NP">
          <tokens>
            <token id="7" string="diabetes" />
            <token id="8" string="each" />
            <token id="9" string="year" />
            <token id="10" string=";" />
            <token id="11" string="another" />
            <token id="12" string="150,000" />
            <token id="13" string="deaths" />
            <token id="14" string="are" />
            <token id="15" string="diabetes-related" />
            <token id="16" string="," />
            <token id="17" string="according" />
            <token id="18" string="to" />
            <token id="19" string="the" />
            <token id="20" string="American" />
            <token id="21" string="Diabetes" />
            <token id="22" string="Association" />
          </tokens>
        </chunking>
        <chunking id="6" string="another 150,000 deaths" type="NP">
          <tokens>
            <token id="11" string="another" />
            <token id="12" string="150,000" />
            <token id="13" string="deaths" />
          </tokens>
        </chunking>
        <chunking id="7" string="die from diabetes each year ; another 150,000 deaths are diabetes-related , according to the American Diabetes Association" type="VP">
          <tokens>
            <token id="5" string="die" />
            <token id="6" string="from" />
            <token id="7" string="diabetes" />
            <token id="8" string="each" />
            <token id="9" string="year" />
            <token id="10" string=";" />
            <token id="11" string="another" />
            <token id="12" string="150,000" />
            <token id="13" string="deaths" />
            <token id="14" string="are" />
            <token id="15" string="diabetes-related" />
            <token id="16" string="," />
            <token id="17" string="according" />
            <token id="18" string="to" />
            <token id="19" string="the" />
            <token id="20" string="American" />
            <token id="21" string="Diabetes" />
            <token id="22" string="Association" />
          </tokens>
        </chunking>
        <chunking id="8" string="are diabetes-related , according to the American Diabetes Association" type="VP">
          <tokens>
            <token id="14" string="are" />
            <token id="15" string="diabetes-related" />
            <token id="16" string="," />
            <token id="17" string="according" />
            <token id="18" string="to" />
            <token id="19" string="the" />
            <token id="20" string="American" />
            <token id="21" string="Diabetes" />
            <token id="22" string="Association" />
          </tokens>
        </chunking>
        <chunking id="9" string="diabetes" type="NP">
          <tokens>
            <token id="7" string="diabetes" />
          </tokens>
        </chunking>
        <chunking id="10" string="diabetes-related" type="ADJP">
          <tokens>
            <token id="15" string="diabetes-related" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="3">150,000</governor>
          <dependent id="1">More</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="1">More</governor>
          <dependent id="2">than</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="4">Americans</governor>
          <dependent id="3">150,000</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">die</governor>
          <dependent id="4">Americans</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">die</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">diabetes</governor>
          <dependent id="6">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">die</governor>
          <dependent id="7">diabetes</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">year</governor>
          <dependent id="8">each</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">diabetes</governor>
          <dependent id="9">year</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">deaths</governor>
          <dependent id="11">another</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="13">deaths</governor>
          <dependent id="12">150,000</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">diabetes-related</governor>
          <dependent id="13">deaths</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="15">diabetes-related</governor>
          <dependent id="14">are</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">diabetes</governor>
          <dependent id="15">diabetes-related</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">Association</governor>
          <dependent id="17">according</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="17">according</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">Association</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">Association</governor>
          <dependent id="20">American</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Association</governor>
          <dependent id="21">Diabetes</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">diabetes-related</governor>
          <dependent id="22">Association</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="150,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="150,000" />
          </tokens>
        </entity>
        <entity id="2" string="each year" type="SET" score="0.0">
          <tokens>
            <token id="8" string="each" />
            <token id="9" string="year" />
          </tokens>
        </entity>
        <entity id="3" string="Americans" type="MISC" score="0.0">
          <tokens>
            <token id="4" string="Americans" />
          </tokens>
        </entity>
        <entity id="4" string="diabetes" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="7" string="diabetes" />
          </tokens>
        </entity>
        <entity id="5" string="American Diabetes Association" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="20" string="American" />
            <token id="21" string="Diabetes" />
            <token id="22" string="Association" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>No one really knows what sparks it, but researchers believe Hispanics could hold the key.</content>
      <tokens>
        <token id="1" string="No" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="one" lemma="one" stem="on" pos="NN" type="Word" isStopWord="true" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="3" string="really" lemma="really" stem="realli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="knows" lemma="know" stem="know" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="sparks" lemma="spark" stem="spark" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="researchers" lemma="researcher" stem="research" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="believe" lemma="believe" stem="believ" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="Hispanics" lemma="Hispanics" stem="hispan" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="13" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="hold" lemma="hold" stem="hold" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="key" lemma="key" stem="kei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT No) (NN one)) (ADVP (RB really)) (VP (VBZ knows) (SBAR (WHNP (WP what)) (S (VP (VBZ sparks) (NP (PRP it))))))) (, ,) (CC but) (S (NP (NNS researchers)) (VP (VBP believe) (SBAR (S (NP (NNPS Hispanics)) (VP (MD could) (VP (VB hold) (NP (DT the) (NN key)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="No one" type="NP">
          <tokens>
            <token id="1" string="No" />
            <token id="2" string="one" />
          </tokens>
        </chunking>
        <chunking id="2" string="Hispanics could hold the key" type="SBAR">
          <tokens>
            <token id="12" string="Hispanics" />
            <token id="13" string="could" />
            <token id="14" string="hold" />
            <token id="15" string="the" />
            <token id="16" string="key" />
          </tokens>
        </chunking>
        <chunking id="3" string="believe Hispanics could hold the key" type="VP">
          <tokens>
            <token id="11" string="believe" />
            <token id="12" string="Hispanics" />
            <token id="13" string="could" />
            <token id="14" string="hold" />
            <token id="15" string="the" />
            <token id="16" string="key" />
          </tokens>
        </chunking>
        <chunking id="4" string="could hold the key" type="VP">
          <tokens>
            <token id="13" string="could" />
            <token id="14" string="hold" />
            <token id="15" string="the" />
            <token id="16" string="key" />
          </tokens>
        </chunking>
        <chunking id="5" string="researchers" type="NP">
          <tokens>
            <token id="10" string="researchers" />
          </tokens>
        </chunking>
        <chunking id="6" string="hold the key" type="VP">
          <tokens>
            <token id="14" string="hold" />
            <token id="15" string="the" />
            <token id="16" string="key" />
          </tokens>
        </chunking>
        <chunking id="7" string="the key" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="key" />
          </tokens>
        </chunking>
        <chunking id="8" string="knows what sparks it" type="VP">
          <tokens>
            <token id="4" string="knows" />
            <token id="5" string="what" />
            <token id="6" string="sparks" />
            <token id="7" string="it" />
          </tokens>
        </chunking>
        <chunking id="9" string="what sparks it" type="SBAR">
          <tokens>
            <token id="5" string="what" />
            <token id="6" string="sparks" />
            <token id="7" string="it" />
          </tokens>
        </chunking>
        <chunking id="10" string="it" type="NP">
          <tokens>
            <token id="7" string="it" />
          </tokens>
        </chunking>
        <chunking id="11" string="sparks it" type="VP">
          <tokens>
            <token id="6" string="sparks" />
            <token id="7" string="it" />
          </tokens>
        </chunking>
        <chunking id="12" string="Hispanics" type="NP">
          <tokens>
            <token id="12" string="Hispanics" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="neg">
          <governor id="2">one</governor>
          <dependent id="1">No</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">knows</governor>
          <dependent id="2">one</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">knows</governor>
          <dependent id="3">really</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">knows</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">sparks</governor>
          <dependent id="5">what</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">knows</governor>
          <dependent id="6">sparks</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">sparks</governor>
          <dependent id="7">it</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">knows</governor>
          <dependent id="9">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">believe</governor>
          <dependent id="10">researchers</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">knows</governor>
          <dependent id="11">believe</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">hold</governor>
          <dependent id="12">Hispanics</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">hold</governor>
          <dependent id="13">could</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">believe</governor>
          <dependent id="14">hold</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">key</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">hold</governor>
          <dependent id="16">key</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="2" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="Hispanics" type="MISC" score="0.0">
          <tokens>
            <token id="12" string="Hispanics" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>San Antonio, the nation&amp;apost;s ninth largest city, with a population that is 50 percent Hispanic, is becoming the base for diabetes studies.</content>
      <tokens>
        <token id="1" string="San" lemma="San" stem="san" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="2" string="Antonio" lemma="Antonio" stem="antonio" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="nation" lemma="nation" stem="nation" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="ninth" lemma="ninth" stem="ninth" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="8" string="largest" lemma="largest" stem="largest" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="city" lemma="city" stem="citi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="population" lemma="population" stem="popul" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="50" lemma="50" stem="50" pos="CD" type="Number" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="17" string="percent" lemma="percent" stem="percent" pos="NN" type="Word" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="18" string="Hispanic" lemma="Hispanic" stem="hispan" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="becoming" lemma="become" stem="becom" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="base" lemma="base" stem="base" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="diabetes" lemma="diabetes" stem="diabet" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="26" string="studies" lemma="study" stem="studi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP San) (NNP Antonio)) (, ,) (NP (NP (NP (DT the) (NN nation) (POS 's)) (JJ ninth) (JJS largest) (NN city)) (, ,) (PP (IN with) (NP (NP (DT a) (NN population)) (SBAR (WHNP (WDT that)) (S (VP (VBZ is) (NP (NP (CD 50) (NN percent)) (ADJP (NNP Hispanic))))))))) (, ,)) (VP (VBZ is) (VP (VBG becoming) (NP (NP (DT the) (NN base)) (PP (IN for) (NP (NN diabetes) (NNS studies)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="San Antonio" type="NP">
          <tokens>
            <token id="1" string="San" />
            <token id="2" string="Antonio" />
          </tokens>
        </chunking>
        <chunking id="2" string="a population" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="population" />
          </tokens>
        </chunking>
        <chunking id="3" string="San Antonio , the nation 's ninth largest city , with a population that is 50 percent Hispanic ," type="NP">
          <tokens>
            <token id="1" string="San" />
            <token id="2" string="Antonio" />
            <token id="3" string="," />
            <token id="4" string="the" />
            <token id="5" string="nation" />
            <token id="6" string="'s" />
            <token id="7" string="ninth" />
            <token id="8" string="largest" />
            <token id="9" string="city" />
            <token id="10" string="," />
            <token id="11" string="with" />
            <token id="12" string="a" />
            <token id="13" string="population" />
            <token id="14" string="that" />
            <token id="15" string="is" />
            <token id="16" string="50" />
            <token id="17" string="percent" />
            <token id="18" string="Hispanic" />
            <token id="19" string="," />
          </tokens>
        </chunking>
        <chunking id="4" string="the base" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="base" />
          </tokens>
        </chunking>
        <chunking id="5" string="50 percent" type="NP">
          <tokens>
            <token id="16" string="50" />
            <token id="17" string="percent" />
          </tokens>
        </chunking>
        <chunking id="6" string="is becoming the base for diabetes studies" type="VP">
          <tokens>
            <token id="20" string="is" />
            <token id="21" string="becoming" />
            <token id="22" string="the" />
            <token id="23" string="base" />
            <token id="24" string="for" />
            <token id="25" string="diabetes" />
            <token id="26" string="studies" />
          </tokens>
        </chunking>
        <chunking id="7" string="becoming the base for diabetes studies" type="VP">
          <tokens>
            <token id="21" string="becoming" />
            <token id="22" string="the" />
            <token id="23" string="base" />
            <token id="24" string="for" />
            <token id="25" string="diabetes" />
            <token id="26" string="studies" />
          </tokens>
        </chunking>
        <chunking id="8" string="is 50 percent Hispanic" type="VP">
          <tokens>
            <token id="15" string="is" />
            <token id="16" string="50" />
            <token id="17" string="percent" />
            <token id="18" string="Hispanic" />
          </tokens>
        </chunking>
        <chunking id="9" string="the base for diabetes studies" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="base" />
            <token id="24" string="for" />
            <token id="25" string="diabetes" />
            <token id="26" string="studies" />
          </tokens>
        </chunking>
        <chunking id="10" string="the nation 's" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="nation" />
            <token id="6" string="'s" />
          </tokens>
        </chunking>
        <chunking id="11" string="a population that is 50 percent Hispanic" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="population" />
            <token id="14" string="that" />
            <token id="15" string="is" />
            <token id="16" string="50" />
            <token id="17" string="percent" />
            <token id="18" string="Hispanic" />
          </tokens>
        </chunking>
        <chunking id="12" string="50 percent Hispanic" type="NP">
          <tokens>
            <token id="16" string="50" />
            <token id="17" string="percent" />
            <token id="18" string="Hispanic" />
          </tokens>
        </chunking>
        <chunking id="13" string="diabetes studies" type="NP">
          <tokens>
            <token id="25" string="diabetes" />
            <token id="26" string="studies" />
          </tokens>
        </chunking>
        <chunking id="14" string="the nation 's ninth largest city" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="nation" />
            <token id="6" string="'s" />
            <token id="7" string="ninth" />
            <token id="8" string="largest" />
            <token id="9" string="city" />
          </tokens>
        </chunking>
        <chunking id="15" string="that is 50 percent Hispanic" type="SBAR">
          <tokens>
            <token id="14" string="that" />
            <token id="15" string="is" />
            <token id="16" string="50" />
            <token id="17" string="percent" />
            <token id="18" string="Hispanic" />
          </tokens>
        </chunking>
        <chunking id="16" string="Hispanic" type="ADJP">
          <tokens>
            <token id="18" string="Hispanic" />
          </tokens>
        </chunking>
        <chunking id="17" string="the nation 's ninth largest city , with a population that is 50 percent Hispanic" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="nation" />
            <token id="6" string="'s" />
            <token id="7" string="ninth" />
            <token id="8" string="largest" />
            <token id="9" string="city" />
            <token id="10" string="," />
            <token id="11" string="with" />
            <token id="12" string="a" />
            <token id="13" string="population" />
            <token id="14" string="that" />
            <token id="15" string="is" />
            <token id="16" string="50" />
            <token id="17" string="percent" />
            <token id="18" string="Hispanic" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Antonio</governor>
          <dependent id="1">San</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">becoming</governor>
          <dependent id="2">Antonio</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">nation</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">city</governor>
          <dependent id="5">nation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">nation</governor>
          <dependent id="6">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">city</governor>
          <dependent id="7">ninth</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">city</governor>
          <dependent id="8">largest</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">Antonio</governor>
          <dependent id="9">city</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">population</governor>
          <dependent id="11">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">population</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">city</governor>
          <dependent id="13">population</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">percent</governor>
          <dependent id="14">that</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="17">percent</governor>
          <dependent id="15">is</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="17">percent</governor>
          <dependent id="16">50</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="13">population</governor>
          <dependent id="17">percent</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">percent</governor>
          <dependent id="18">Hispanic</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">becoming</governor>
          <dependent id="20">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="21">becoming</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">base</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="21">becoming</governor>
          <dependent id="23">base</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">studies</governor>
          <dependent id="24">for</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">studies</governor>
          <dependent id="25">diabetes</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">base</governor>
          <dependent id="26">studies</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="San Antonio" type="LOCATION" score="0.0">
          <tokens>
            <token id="1" string="San" />
            <token id="2" string="Antonio" />
          </tokens>
        </entity>
        <entity id="2" string="50 percent" type="PERCENT" score="0.0">
          <tokens>
            <token id="16" string="50" />
            <token id="17" string="percent" />
          </tokens>
        </entity>
        <entity id="3" string="ninth" type="ORDINAL" score="0.0">
          <tokens>
            <token id="7" string="ninth" />
          </tokens>
        </entity>
        <entity id="4" string="diabetes" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="25" string="diabetes" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>Researchers take a customized mobile home to neighborhoods to randomly check Hispanics and Anglos for the disease, which deprives the body of insulin and can lead to complications affecting the heart, kidneys, eyes and nerves.</content>
      <tokens>
        <token id="1" string="Researchers" lemma="researcher" stem="research" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="take" lemma="take" stem="take" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="customized" lemma="customize" stem="custom" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="mobile" lemma="mobile" stem="mobil" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="home" lemma="home" stem="home" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="neighborhoods" lemma="neighborhood" stem="neighborhood" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="randomly" lemma="randomly" stem="randomli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="check" lemma="check" stem="check" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="Hispanics" lemma="Hispanics" stem="hispan" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Anglos" lemma="Anglos" stem="anglo" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="15" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="deprives" lemma="deprive" stem="depriv" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="body" lemma="body" stem="bodi" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="insulin" lemma="insulin" stem="insulin" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="lead" lemma="lead" stem="lead" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="complications" lemma="complication" stem="complic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="affecting" lemma="affect" stem="affect" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="heart" lemma="heart" stem="heart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="kidneys" lemma="kidney" stem="kidnei" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="eyes" lemma="eye" stem="ey" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="nerves" lemma="nerve" stem="nerv" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNS Researchers)) (VP (VBP take) (NP (DT a) (VBN customized) (JJ mobile) (NN home)) (PP (TO to) (NP (NNS neighborhoods) (S (VP (TO to) (VP (ADVP (RB randomly)) (VB check) (NP (NP (NNPS Hispanics) (CC and) (NNPS Anglos)) (PP (IN for) (NP (NP (DT the) (NN disease)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VP (VBZ deprives) (NP (NP (DT the) (NN body)) (PP (IN of) (NP (NN insulin))))) (CC and) (VP (MD can) (VP (VB lead) (PP (TO to) (NP (NP (NNS complications)) (VP (VBG affecting) (NP (DT the) (NN heart) (, ,) (NNS kidneys) (, ,) (NNS eyes) (CC and) (NNS nerves))))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the body of insulin" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="body" />
            <token id="23" string="of" />
            <token id="24" string="insulin" />
          </tokens>
        </chunking>
        <chunking id="2" string="randomly check Hispanics and Anglos for the disease , which deprives the body of insulin and can lead to complications affecting the heart , kidneys , eyes and nerves" type="VP">
          <tokens>
            <token id="10" string="randomly" />
            <token id="11" string="check" />
            <token id="12" string="Hispanics" />
            <token id="13" string="and" />
            <token id="14" string="Anglos" />
            <token id="15" string="for" />
            <token id="16" string="the" />
            <token id="17" string="disease" />
            <token id="18" string="," />
            <token id="19" string="which" />
            <token id="20" string="deprives" />
            <token id="21" string="the" />
            <token id="22" string="body" />
            <token id="23" string="of" />
            <token id="24" string="insulin" />
            <token id="25" string="and" />
            <token id="26" string="can" />
            <token id="27" string="lead" />
            <token id="28" string="to" />
            <token id="29" string="complications" />
            <token id="30" string="affecting" />
            <token id="31" string="the" />
            <token id="32" string="heart" />
            <token id="33" string="," />
            <token id="34" string="kidneys" />
            <token id="35" string="," />
            <token id="36" string="eyes" />
            <token id="37" string="and" />
            <token id="38" string="nerves" />
          </tokens>
        </chunking>
        <chunking id="3" string="deprives the body of insulin and can lead to complications affecting the heart , kidneys , eyes and nerves" type="VP">
          <tokens>
            <token id="20" string="deprives" />
            <token id="21" string="the" />
            <token id="22" string="body" />
            <token id="23" string="of" />
            <token id="24" string="insulin" />
            <token id="25" string="and" />
            <token id="26" string="can" />
            <token id="27" string="lead" />
            <token id="28" string="to" />
            <token id="29" string="complications" />
            <token id="30" string="affecting" />
            <token id="31" string="the" />
            <token id="32" string="heart" />
            <token id="33" string="," />
            <token id="34" string="kidneys" />
            <token id="35" string="," />
            <token id="36" string="eyes" />
            <token id="37" string="and" />
            <token id="38" string="nerves" />
          </tokens>
        </chunking>
        <chunking id="4" string="can lead to complications affecting the heart , kidneys , eyes and nerves" type="VP">
          <tokens>
            <token id="26" string="can" />
            <token id="27" string="lead" />
            <token id="28" string="to" />
            <token id="29" string="complications" />
            <token id="30" string="affecting" />
            <token id="31" string="the" />
            <token id="32" string="heart" />
            <token id="33" string="," />
            <token id="34" string="kidneys" />
            <token id="35" string="," />
            <token id="36" string="eyes" />
            <token id="37" string="and" />
            <token id="38" string="nerves" />
          </tokens>
        </chunking>
        <chunking id="5" string="Hispanics and Anglos" type="NP">
          <tokens>
            <token id="12" string="Hispanics" />
            <token id="13" string="and" />
            <token id="14" string="Anglos" />
          </tokens>
        </chunking>
        <chunking id="6" string="complications" type="NP">
          <tokens>
            <token id="29" string="complications" />
          </tokens>
        </chunking>
        <chunking id="7" string="insulin" type="NP">
          <tokens>
            <token id="24" string="insulin" />
          </tokens>
        </chunking>
        <chunking id="8" string="which deprives the body of insulin and can lead to complications affecting the heart , kidneys , eyes and nerves" type="SBAR">
          <tokens>
            <token id="19" string="which" />
            <token id="20" string="deprives" />
            <token id="21" string="the" />
            <token id="22" string="body" />
            <token id="23" string="of" />
            <token id="24" string="insulin" />
            <token id="25" string="and" />
            <token id="26" string="can" />
            <token id="27" string="lead" />
            <token id="28" string="to" />
            <token id="29" string="complications" />
            <token id="30" string="affecting" />
            <token id="31" string="the" />
            <token id="32" string="heart" />
            <token id="33" string="," />
            <token id="34" string="kidneys" />
            <token id="35" string="," />
            <token id="36" string="eyes" />
            <token id="37" string="and" />
            <token id="38" string="nerves" />
          </tokens>
        </chunking>
        <chunking id="9" string="the body" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="body" />
          </tokens>
        </chunking>
        <chunking id="10" string="take a customized mobile home to neighborhoods to randomly check Hispanics and Anglos for the disease , which deprives the body of insulin and can lead to complications affecting the heart , kidneys , eyes and nerves" type="VP">
          <tokens>
            <token id="2" string="take" />
            <token id="3" string="a" />
            <token id="4" string="customized" />
            <token id="5" string="mobile" />
            <token id="6" string="home" />
            <token id="7" string="to" />
            <token id="8" string="neighborhoods" />
            <token id="9" string="to" />
            <token id="10" string="randomly" />
            <token id="11" string="check" />
            <token id="12" string="Hispanics" />
            <token id="13" string="and" />
            <token id="14" string="Anglos" />
            <token id="15" string="for" />
            <token id="16" string="the" />
            <token id="17" string="disease" />
            <token id="18" string="," />
            <token id="19" string="which" />
            <token id="20" string="deprives" />
            <token id="21" string="the" />
            <token id="22" string="body" />
            <token id="23" string="of" />
            <token id="24" string="insulin" />
            <token id="25" string="and" />
            <token id="26" string="can" />
            <token id="27" string="lead" />
            <token id="28" string="to" />
            <token id="29" string="complications" />
            <token id="30" string="affecting" />
            <token id="31" string="the" />
            <token id="32" string="heart" />
            <token id="33" string="," />
            <token id="34" string="kidneys" />
            <token id="35" string="," />
            <token id="36" string="eyes" />
            <token id="37" string="and" />
            <token id="38" string="nerves" />
          </tokens>
        </chunking>
        <chunking id="11" string="the disease" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="disease" />
          </tokens>
        </chunking>
        <chunking id="12" string="neighborhoods to randomly check Hispanics and Anglos for the disease , which deprives the body of insulin and can lead to complications affecting the heart , kidneys , eyes and nerves" type="NP">
          <tokens>
            <token id="8" string="neighborhoods" />
            <token id="9" string="to" />
            <token id="10" string="randomly" />
            <token id="11" string="check" />
            <token id="12" string="Hispanics" />
            <token id="13" string="and" />
            <token id="14" string="Anglos" />
            <token id="15" string="for" />
            <token id="16" string="the" />
            <token id="17" string="disease" />
            <token id="18" string="," />
            <token id="19" string="which" />
            <token id="20" string="deprives" />
            <token id="21" string="the" />
            <token id="22" string="body" />
            <token id="23" string="of" />
            <token id="24" string="insulin" />
            <token id="25" string="and" />
            <token id="26" string="can" />
            <token id="27" string="lead" />
            <token id="28" string="to" />
            <token id="29" string="complications" />
            <token id="30" string="affecting" />
            <token id="31" string="the" />
            <token id="32" string="heart" />
            <token id="33" string="," />
            <token id="34" string="kidneys" />
            <token id="35" string="," />
            <token id="36" string="eyes" />
            <token id="37" string="and" />
            <token id="38" string="nerves" />
          </tokens>
        </chunking>
        <chunking id="13" string="Researchers" type="NP">
          <tokens>
            <token id="1" string="Researchers" />
          </tokens>
        </chunking>
        <chunking id="14" string="the disease , which deprives the body of insulin and can lead to complications affecting the heart , kidneys , eyes and nerves" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="disease" />
            <token id="18" string="," />
            <token id="19" string="which" />
            <token id="20" string="deprives" />
            <token id="21" string="the" />
            <token id="22" string="body" />
            <token id="23" string="of" />
            <token id="24" string="insulin" />
            <token id="25" string="and" />
            <token id="26" string="can" />
            <token id="27" string="lead" />
            <token id="28" string="to" />
            <token id="29" string="complications" />
            <token id="30" string="affecting" />
            <token id="31" string="the" />
            <token id="32" string="heart" />
            <token id="33" string="," />
            <token id="34" string="kidneys" />
            <token id="35" string="," />
            <token id="36" string="eyes" />
            <token id="37" string="and" />
            <token id="38" string="nerves" />
          </tokens>
        </chunking>
        <chunking id="15" string="deprives the body of insulin" type="VP">
          <tokens>
            <token id="20" string="deprives" />
            <token id="21" string="the" />
            <token id="22" string="body" />
            <token id="23" string="of" />
            <token id="24" string="insulin" />
          </tokens>
        </chunking>
        <chunking id="16" string="affecting the heart , kidneys , eyes and nerves" type="VP">
          <tokens>
            <token id="30" string="affecting" />
            <token id="31" string="the" />
            <token id="32" string="heart" />
            <token id="33" string="," />
            <token id="34" string="kidneys" />
            <token id="35" string="," />
            <token id="36" string="eyes" />
            <token id="37" string="and" />
            <token id="38" string="nerves" />
          </tokens>
        </chunking>
        <chunking id="17" string="complications affecting the heart , kidneys , eyes and nerves" type="NP">
          <tokens>
            <token id="29" string="complications" />
            <token id="30" string="affecting" />
            <token id="31" string="the" />
            <token id="32" string="heart" />
            <token id="33" string="," />
            <token id="34" string="kidneys" />
            <token id="35" string="," />
            <token id="36" string="eyes" />
            <token id="37" string="and" />
            <token id="38" string="nerves" />
          </tokens>
        </chunking>
        <chunking id="18" string="the heart , kidneys , eyes and nerves" type="NP">
          <tokens>
            <token id="31" string="the" />
            <token id="32" string="heart" />
            <token id="33" string="," />
            <token id="34" string="kidneys" />
            <token id="35" string="," />
            <token id="36" string="eyes" />
            <token id="37" string="and" />
            <token id="38" string="nerves" />
          </tokens>
        </chunking>
        <chunking id="19" string="to randomly check Hispanics and Anglos for the disease , which deprives the body of insulin and can lead to complications affecting the heart , kidneys , eyes and nerves" type="VP">
          <tokens>
            <token id="9" string="to" />
            <token id="10" string="randomly" />
            <token id="11" string="check" />
            <token id="12" string="Hispanics" />
            <token id="13" string="and" />
            <token id="14" string="Anglos" />
            <token id="15" string="for" />
            <token id="16" string="the" />
            <token id="17" string="disease" />
            <token id="18" string="," />
            <token id="19" string="which" />
            <token id="20" string="deprives" />
            <token id="21" string="the" />
            <token id="22" string="body" />
            <token id="23" string="of" />
            <token id="24" string="insulin" />
            <token id="25" string="and" />
            <token id="26" string="can" />
            <token id="27" string="lead" />
            <token id="28" string="to" />
            <token id="29" string="complications" />
            <token id="30" string="affecting" />
            <token id="31" string="the" />
            <token id="32" string="heart" />
            <token id="33" string="," />
            <token id="34" string="kidneys" />
            <token id="35" string="," />
            <token id="36" string="eyes" />
            <token id="37" string="and" />
            <token id="38" string="nerves" />
          </tokens>
        </chunking>
        <chunking id="20" string="Hispanics and Anglos for the disease , which deprives the body of insulin and can lead to complications affecting the heart , kidneys , eyes and nerves" type="NP">
          <tokens>
            <token id="12" string="Hispanics" />
            <token id="13" string="and" />
            <token id="14" string="Anglos" />
            <token id="15" string="for" />
            <token id="16" string="the" />
            <token id="17" string="disease" />
            <token id="18" string="," />
            <token id="19" string="which" />
            <token id="20" string="deprives" />
            <token id="21" string="the" />
            <token id="22" string="body" />
            <token id="23" string="of" />
            <token id="24" string="insulin" />
            <token id="25" string="and" />
            <token id="26" string="can" />
            <token id="27" string="lead" />
            <token id="28" string="to" />
            <token id="29" string="complications" />
            <token id="30" string="affecting" />
            <token id="31" string="the" />
            <token id="32" string="heart" />
            <token id="33" string="," />
            <token id="34" string="kidneys" />
            <token id="35" string="," />
            <token id="36" string="eyes" />
            <token id="37" string="and" />
            <token id="38" string="nerves" />
          </tokens>
        </chunking>
        <chunking id="21" string="a customized mobile home" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="customized" />
            <token id="5" string="mobile" />
            <token id="6" string="home" />
          </tokens>
        </chunking>
        <chunking id="22" string="lead to complications affecting the heart , kidneys , eyes and nerves" type="VP">
          <tokens>
            <token id="27" string="lead" />
            <token id="28" string="to" />
            <token id="29" string="complications" />
            <token id="30" string="affecting" />
            <token id="31" string="the" />
            <token id="32" string="heart" />
            <token id="33" string="," />
            <token id="34" string="kidneys" />
            <token id="35" string="," />
            <token id="36" string="eyes" />
            <token id="37" string="and" />
            <token id="38" string="nerves" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">take</governor>
          <dependent id="1">Researchers</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">take</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">home</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">home</governor>
          <dependent id="4">customized</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">home</governor>
          <dependent id="5">mobile</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">take</governor>
          <dependent id="6">home</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">neighborhoods</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">take</governor>
          <dependent id="8">neighborhoods</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">check</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">check</governor>
          <dependent id="10">randomly</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="8">neighborhoods</governor>
          <dependent id="11">check</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">check</governor>
          <dependent id="12">Hispanics</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">Hispanics</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">Hispanics</governor>
          <dependent id="14">Anglos</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">disease</governor>
          <dependent id="15">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">disease</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">Hispanics</governor>
          <dependent id="17">disease</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">deprives</governor>
          <dependent id="19">which</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="17">disease</governor>
          <dependent id="20">deprives</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">body</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">deprives</governor>
          <dependent id="22">body</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">insulin</governor>
          <dependent id="23">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">body</governor>
          <dependent id="24">insulin</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="20">deprives</governor>
          <dependent id="25">and</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="27">lead</governor>
          <dependent id="26">can</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="20">deprives</governor>
          <dependent id="27">lead</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">complications</governor>
          <dependent id="28">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">lead</governor>
          <dependent id="29">complications</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="29">complications</governor>
          <dependent id="30">affecting</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">heart</governor>
          <dependent id="31">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="30">affecting</governor>
          <dependent id="32">heart</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="32">heart</governor>
          <dependent id="34">kidneys</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="32">heart</governor>
          <dependent id="36">eyes</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="32">heart</governor>
          <dependent id="37">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="32">heart</governor>
          <dependent id="38">nerves</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="17" string="disease" />
          </tokens>
        </entity>
        <entity id="2" string="Anglos" type="MISC" score="0.0">
          <tokens>
            <token id="14" string="Anglos" />
          </tokens>
        </entity>
        <entity id="3" string="Hispanics" type="MISC" score="0.0">
          <tokens>
            <token id="12" string="Hispanics" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>San Antonio&amp;apost;s Hispanic makeup led Dr. Ralph DeFronzo to abandon his prestigious position as a Yale University diabetes researcher and persuade his four-member team to relocate to the University of Texas Health Science Center.</content>
      <tokens>
        <token id="1" string="San" lemma="San" stem="san" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="2" string="Antonio" lemma="Antonio" stem="antonio" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="3" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="Hispanic" lemma="hispanic" stem="hispan" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="5" string="makeup" lemma="makeup" stem="makeup" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="led" lemma="lead" stem="led" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="Dr." lemma="Dr." stem="dr." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="Ralph" lemma="Ralph" stem="ralph" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="9" string="DeFronzo" lemma="DeFronzo" stem="defronzo" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="abandon" lemma="abandon" stem="abandon" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="prestigious" lemma="prestigious" stem="prestigi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="position" lemma="position" stem="posit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Yale" lemma="Yale" stem="yale" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="18" string="University" lemma="University" stem="univers" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="19" string="diabetes" lemma="diabetes" stem="diabet" pos="NNP" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="true" />
        <token id="20" string="researcher" lemma="researcher" stem="research" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="persuade" lemma="persuade" stem="persuad" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="four-member" lemma="four-member" stem="four-memb" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="team" lemma="team" stem="team" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="relocate" lemma="relocate" stem="reloc" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="30" string="University" lemma="University" stem="univers" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="31" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="32" string="Texas" lemma="Texas" stem="texa" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="33" string="Health" lemma="Health" stem="health" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="34" string="Science" lemma="Science" stem="scienc" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="35" string="Center" lemma="Center" stem="center" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP San) (NNP Antonio) (POS 's)) (JJ Hispanic) (NN makeup)) (VP (VBD led) (S (NP (NNP Dr.) (NNP Ralph) (NNP DeFronzo)) (VP (TO to) (VP (VP (VB abandon) (NP (PRP$ his) (JJ prestigious) (NN position)) (PP (IN as) (NP (DT a) (NNP Yale) (NNP University) (NNP diabetes) (NN researcher)))) (CC and) (VP (VB persuade) (NP (PRP$ his) (JJ four-member) (NN team)) (S (VP (TO to) (VP (VB relocate) (PP (TO to) (NP (NP (DT the) (NNP University)) (PP (IN of) (NP (NNP Texas) (NNP Health) (NNP Science) (NNP Center))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="abandon his prestigious position as a Yale University diabetes researcher" type="VP">
          <tokens>
            <token id="11" string="abandon" />
            <token id="12" string="his" />
            <token id="13" string="prestigious" />
            <token id="14" string="position" />
            <token id="15" string="as" />
            <token id="16" string="a" />
            <token id="17" string="Yale" />
            <token id="18" string="University" />
            <token id="19" string="diabetes" />
            <token id="20" string="researcher" />
          </tokens>
        </chunking>
        <chunking id="2" string="relocate to the University of Texas Health Science Center" type="VP">
          <tokens>
            <token id="27" string="relocate" />
            <token id="28" string="to" />
            <token id="29" string="the" />
            <token id="30" string="University" />
            <token id="31" string="of" />
            <token id="32" string="Texas" />
            <token id="33" string="Health" />
            <token id="34" string="Science" />
            <token id="35" string="Center" />
          </tokens>
        </chunking>
        <chunking id="3" string="his prestigious position" type="NP">
          <tokens>
            <token id="12" string="his" />
            <token id="13" string="prestigious" />
            <token id="14" string="position" />
          </tokens>
        </chunking>
        <chunking id="4" string="Dr. Ralph DeFronzo" type="NP">
          <tokens>
            <token id="7" string="Dr." />
            <token id="8" string="Ralph" />
            <token id="9" string="DeFronzo" />
          </tokens>
        </chunking>
        <chunking id="5" string="abandon his prestigious position as a Yale University diabetes researcher and persuade his four-member team to relocate to the University of Texas Health Science Center" type="VP">
          <tokens>
            <token id="11" string="abandon" />
            <token id="12" string="his" />
            <token id="13" string="prestigious" />
            <token id="14" string="position" />
            <token id="15" string="as" />
            <token id="16" string="a" />
            <token id="17" string="Yale" />
            <token id="18" string="University" />
            <token id="19" string="diabetes" />
            <token id="20" string="researcher" />
            <token id="21" string="and" />
            <token id="22" string="persuade" />
            <token id="23" string="his" />
            <token id="24" string="four-member" />
            <token id="25" string="team" />
            <token id="26" string="to" />
            <token id="27" string="relocate" />
            <token id="28" string="to" />
            <token id="29" string="the" />
            <token id="30" string="University" />
            <token id="31" string="of" />
            <token id="32" string="Texas" />
            <token id="33" string="Health" />
            <token id="34" string="Science" />
            <token id="35" string="Center" />
          </tokens>
        </chunking>
        <chunking id="6" string="a Yale University diabetes researcher" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="Yale" />
            <token id="18" string="University" />
            <token id="19" string="diabetes" />
            <token id="20" string="researcher" />
          </tokens>
        </chunking>
        <chunking id="7" string="San Antonio 's" type="NP">
          <tokens>
            <token id="1" string="San" />
            <token id="2" string="Antonio" />
            <token id="3" string="'s" />
          </tokens>
        </chunking>
        <chunking id="8" string="led Dr. Ralph DeFronzo to abandon his prestigious position as a Yale University diabetes researcher and persuade his four-member team to relocate to the University of Texas Health Science Center" type="VP">
          <tokens>
            <token id="6" string="led" />
            <token id="7" string="Dr." />
            <token id="8" string="Ralph" />
            <token id="9" string="DeFronzo" />
            <token id="10" string="to" />
            <token id="11" string="abandon" />
            <token id="12" string="his" />
            <token id="13" string="prestigious" />
            <token id="14" string="position" />
            <token id="15" string="as" />
            <token id="16" string="a" />
            <token id="17" string="Yale" />
            <token id="18" string="University" />
            <token id="19" string="diabetes" />
            <token id="20" string="researcher" />
            <token id="21" string="and" />
            <token id="22" string="persuade" />
            <token id="23" string="his" />
            <token id="24" string="four-member" />
            <token id="25" string="team" />
            <token id="26" string="to" />
            <token id="27" string="relocate" />
            <token id="28" string="to" />
            <token id="29" string="the" />
            <token id="30" string="University" />
            <token id="31" string="of" />
            <token id="32" string="Texas" />
            <token id="33" string="Health" />
            <token id="34" string="Science" />
            <token id="35" string="Center" />
          </tokens>
        </chunking>
        <chunking id="9" string="San Antonio 's Hispanic makeup" type="NP">
          <tokens>
            <token id="1" string="San" />
            <token id="2" string="Antonio" />
            <token id="3" string="'s" />
            <token id="4" string="Hispanic" />
            <token id="5" string="makeup" />
          </tokens>
        </chunking>
        <chunking id="10" string="to relocate to the University of Texas Health Science Center" type="VP">
          <tokens>
            <token id="26" string="to" />
            <token id="27" string="relocate" />
            <token id="28" string="to" />
            <token id="29" string="the" />
            <token id="30" string="University" />
            <token id="31" string="of" />
            <token id="32" string="Texas" />
            <token id="33" string="Health" />
            <token id="34" string="Science" />
            <token id="35" string="Center" />
          </tokens>
        </chunking>
        <chunking id="11" string="Texas Health Science Center" type="NP">
          <tokens>
            <token id="32" string="Texas" />
            <token id="33" string="Health" />
            <token id="34" string="Science" />
            <token id="35" string="Center" />
          </tokens>
        </chunking>
        <chunking id="12" string="to abandon his prestigious position as a Yale University diabetes researcher and persuade his four-member team to relocate to the University of Texas Health Science Center" type="VP">
          <tokens>
            <token id="10" string="to" />
            <token id="11" string="abandon" />
            <token id="12" string="his" />
            <token id="13" string="prestigious" />
            <token id="14" string="position" />
            <token id="15" string="as" />
            <token id="16" string="a" />
            <token id="17" string="Yale" />
            <token id="18" string="University" />
            <token id="19" string="diabetes" />
            <token id="20" string="researcher" />
            <token id="21" string="and" />
            <token id="22" string="persuade" />
            <token id="23" string="his" />
            <token id="24" string="four-member" />
            <token id="25" string="team" />
            <token id="26" string="to" />
            <token id="27" string="relocate" />
            <token id="28" string="to" />
            <token id="29" string="the" />
            <token id="30" string="University" />
            <token id="31" string="of" />
            <token id="32" string="Texas" />
            <token id="33" string="Health" />
            <token id="34" string="Science" />
            <token id="35" string="Center" />
          </tokens>
        </chunking>
        <chunking id="13" string="his four-member team" type="NP">
          <tokens>
            <token id="23" string="his" />
            <token id="24" string="four-member" />
            <token id="25" string="team" />
          </tokens>
        </chunking>
        <chunking id="14" string="persuade his four-member team to relocate to the University of Texas Health Science Center" type="VP">
          <tokens>
            <token id="22" string="persuade" />
            <token id="23" string="his" />
            <token id="24" string="four-member" />
            <token id="25" string="team" />
            <token id="26" string="to" />
            <token id="27" string="relocate" />
            <token id="28" string="to" />
            <token id="29" string="the" />
            <token id="30" string="University" />
            <token id="31" string="of" />
            <token id="32" string="Texas" />
            <token id="33" string="Health" />
            <token id="34" string="Science" />
            <token id="35" string="Center" />
          </tokens>
        </chunking>
        <chunking id="15" string="the University" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="University" />
          </tokens>
        </chunking>
        <chunking id="16" string="the University of Texas Health Science Center" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="University" />
            <token id="31" string="of" />
            <token id="32" string="Texas" />
            <token id="33" string="Health" />
            <token id="34" string="Science" />
            <token id="35" string="Center" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Antonio</governor>
          <dependent id="1">San</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">makeup</governor>
          <dependent id="2">Antonio</dependent>
        </dependency>
        <dependency type="case">
          <governor id="2">Antonio</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">makeup</governor>
          <dependent id="4">Hispanic</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">led</governor>
          <dependent id="5">makeup</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">led</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">DeFronzo</governor>
          <dependent id="7">Dr.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">DeFronzo</governor>
          <dependent id="8">Ralph</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">led</governor>
          <dependent id="9">DeFronzo</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">abandon</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">led</governor>
          <dependent id="11">abandon</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">position</governor>
          <dependent id="12">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">position</governor>
          <dependent id="13">prestigious</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">abandon</governor>
          <dependent id="14">position</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">researcher</governor>
          <dependent id="15">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">researcher</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">researcher</governor>
          <dependent id="17">Yale</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">researcher</governor>
          <dependent id="18">University</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">researcher</governor>
          <dependent id="19">diabetes</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">abandon</governor>
          <dependent id="20">researcher</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">abandon</governor>
          <dependent id="21">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">abandon</governor>
          <dependent id="22">persuade</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="25">team</governor>
          <dependent id="23">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">team</governor>
          <dependent id="24">four-member</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">persuade</governor>
          <dependent id="25">team</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="27">relocate</governor>
          <dependent id="26">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="22">persuade</governor>
          <dependent id="27">relocate</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">University</governor>
          <dependent id="28">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">University</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">relocate</governor>
          <dependent id="30">University</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">Center</governor>
          <dependent id="31">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">Center</governor>
          <dependent id="32">Texas</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">Center</governor>
          <dependent id="33">Health</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">Center</governor>
          <dependent id="34">Science</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">University</governor>
          <dependent id="35">Center</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="San Antonio" type="LOCATION" score="0.0">
          <tokens>
            <token id="1" string="San" />
            <token id="2" string="Antonio" />
          </tokens>
        </entity>
        <entity id="2" string="Yale University" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="17" string="Yale" />
            <token id="18" string="University" />
          </tokens>
        </entity>
        <entity id="3" string="University of Texas Health Science Center" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="30" string="University" />
            <token id="31" string="of" />
            <token id="32" string="Texas" />
            <token id="33" string="Health" />
            <token id="34" string="Science" />
            <token id="35" string="Center" />
          </tokens>
        </entity>
        <entity id="4" string="Hispanic" type="MISC" score="0.0">
          <tokens>
            <token id="4" string="Hispanic" />
          </tokens>
        </entity>
        <entity id="5" string="diabetes" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="19" string="diabetes" />
          </tokens>
        </entity>
        <entity id="6" string="Ralph DeFronzo" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Ralph" />
            <token id="9" string="DeFronzo" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>An epidemiologist at the center, Dr. Michael Stern, has devoted 10 years to studying Hispanic diabetes and led the grassroots study of Type II diabetes.</content>
      <tokens>
        <token id="1" string="An" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="epidemiologist" lemma="epidemiologist" stem="epidemiologist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="center" lemma="center" stem="center" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Dr." lemma="Dr." stem="dr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="Michael" lemma="Michael" stem="michael" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="9" string="Stern" lemma="Stern" stem="stern" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="devoted" lemma="devote" stem="devot" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="10" lemma="10" stem="10" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="14" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="studying" lemma="study" stem="studi" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="Hispanic" lemma="hispanic" stem="hispan" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="18" string="diabetes" lemma="diabetes" stem="diabet" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="led" lemma="lead" stem="led" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="grassroots" lemma="grassroot" stem="grassroot" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="study" lemma="study" stem="studi" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="Type" lemma="type" stem="type" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="II" lemma="ii" stem="ii" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="27" string="diabetes" lemma="diabetes" stem="diabet" pos="NNS" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT An) (NN epidemiologist)) (PP (IN at) (NP (NP (DT the) (NN center)) (, ,) (NP (NNP Dr.) (NNP Michael) (NNP Stern)) (, ,)))) (VP (VP (VBZ has) (VP (VBN devoted) (NP (CD 10) (NNS years)) (PP (TO to) (S (VP (VBG studying) (NP (JJ Hispanic) (NN diabetes))))))) (CC and) (VP (VBD led) (NP (NP (DT the) (NNS grassroots) (NN study)) (PP (IN of) (NP (NN Type) (CD II) (NNS diabetes)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the grassroots study of Type II diabetes" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="grassroots" />
            <token id="23" string="study" />
            <token id="24" string="of" />
            <token id="25" string="Type" />
            <token id="26" string="II" />
            <token id="27" string="diabetes" />
          </tokens>
        </chunking>
        <chunking id="2" string="the center" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="center" />
          </tokens>
        </chunking>
        <chunking id="3" string="Dr. Michael Stern" type="NP">
          <tokens>
            <token id="7" string="Dr." />
            <token id="8" string="Michael" />
            <token id="9" string="Stern" />
          </tokens>
        </chunking>
        <chunking id="4" string="Type II diabetes" type="NP">
          <tokens>
            <token id="25" string="Type" />
            <token id="26" string="II" />
            <token id="27" string="diabetes" />
          </tokens>
        </chunking>
        <chunking id="5" string="An epidemiologist" type="NP">
          <tokens>
            <token id="1" string="An" />
            <token id="2" string="epidemiologist" />
          </tokens>
        </chunking>
        <chunking id="6" string="10 years" type="NP">
          <tokens>
            <token id="13" string="10" />
            <token id="14" string="years" />
          </tokens>
        </chunking>
        <chunking id="7" string="devoted 10 years to studying Hispanic diabetes" type="VP">
          <tokens>
            <token id="12" string="devoted" />
            <token id="13" string="10" />
            <token id="14" string="years" />
            <token id="15" string="to" />
            <token id="16" string="studying" />
            <token id="17" string="Hispanic" />
            <token id="18" string="diabetes" />
          </tokens>
        </chunking>
        <chunking id="8" string="Hispanic diabetes" type="NP">
          <tokens>
            <token id="17" string="Hispanic" />
            <token id="18" string="diabetes" />
          </tokens>
        </chunking>
        <chunking id="9" string="the grassroots study" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="grassroots" />
            <token id="23" string="study" />
          </tokens>
        </chunking>
        <chunking id="10" string="the center , Dr. Michael Stern ," type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="center" />
            <token id="6" string="," />
            <token id="7" string="Dr." />
            <token id="8" string="Michael" />
            <token id="9" string="Stern" />
            <token id="10" string="," />
          </tokens>
        </chunking>
        <chunking id="11" string="has devoted 10 years to studying Hispanic diabetes and led the grassroots study of Type II diabetes" type="VP">
          <tokens>
            <token id="11" string="has" />
            <token id="12" string="devoted" />
            <token id="13" string="10" />
            <token id="14" string="years" />
            <token id="15" string="to" />
            <token id="16" string="studying" />
            <token id="17" string="Hispanic" />
            <token id="18" string="diabetes" />
            <token id="19" string="and" />
            <token id="20" string="led" />
            <token id="21" string="the" />
            <token id="22" string="grassroots" />
            <token id="23" string="study" />
            <token id="24" string="of" />
            <token id="25" string="Type" />
            <token id="26" string="II" />
            <token id="27" string="diabetes" />
          </tokens>
        </chunking>
        <chunking id="12" string="led the grassroots study of Type II diabetes" type="VP">
          <tokens>
            <token id="20" string="led" />
            <token id="21" string="the" />
            <token id="22" string="grassroots" />
            <token id="23" string="study" />
            <token id="24" string="of" />
            <token id="25" string="Type" />
            <token id="26" string="II" />
            <token id="27" string="diabetes" />
          </tokens>
        </chunking>
        <chunking id="13" string="studying Hispanic diabetes" type="VP">
          <tokens>
            <token id="16" string="studying" />
            <token id="17" string="Hispanic" />
            <token id="18" string="diabetes" />
          </tokens>
        </chunking>
        <chunking id="14" string="has devoted 10 years to studying Hispanic diabetes" type="VP">
          <tokens>
            <token id="11" string="has" />
            <token id="12" string="devoted" />
            <token id="13" string="10" />
            <token id="14" string="years" />
            <token id="15" string="to" />
            <token id="16" string="studying" />
            <token id="17" string="Hispanic" />
            <token id="18" string="diabetes" />
          </tokens>
        </chunking>
        <chunking id="15" string="An epidemiologist at the center , Dr. Michael Stern ," type="NP">
          <tokens>
            <token id="1" string="An" />
            <token id="2" string="epidemiologist" />
            <token id="3" string="at" />
            <token id="4" string="the" />
            <token id="5" string="center" />
            <token id="6" string="," />
            <token id="7" string="Dr." />
            <token id="8" string="Michael" />
            <token id="9" string="Stern" />
            <token id="10" string="," />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">epidemiologist</governor>
          <dependent id="1">An</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">devoted</governor>
          <dependent id="2">epidemiologist</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">center</governor>
          <dependent id="3">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">center</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">epidemiologist</governor>
          <dependent id="5">center</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Stern</governor>
          <dependent id="7">Dr.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Stern</governor>
          <dependent id="8">Michael</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="5">center</governor>
          <dependent id="9">Stern</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">devoted</governor>
          <dependent id="11">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">devoted</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="14">years</governor>
          <dependent id="13">10</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="12">devoted</governor>
          <dependent id="14">years</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">studying</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">devoted</governor>
          <dependent id="16">studying</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">diabetes</governor>
          <dependent id="17">Hispanic</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">studying</governor>
          <dependent id="18">diabetes</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">devoted</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">devoted</governor>
          <dependent id="20">led</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">study</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">study</governor>
          <dependent id="22">grassroots</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">led</governor>
          <dependent id="23">study</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">diabetes</governor>
          <dependent id="24">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">diabetes</governor>
          <dependent id="25">Type</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="27">diabetes</governor>
          <dependent id="26">II</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">study</governor>
          <dependent id="27">diabetes</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Michael Stern" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Michael" />
            <token id="9" string="Stern" />
          </tokens>
        </entity>
        <entity id="2" string="10 years" type="DURATION" score="0.0">
          <tokens>
            <token id="13" string="10" />
            <token id="14" string="years" />
          </tokens>
        </entity>
        <entity id="3" string="Hispanic" type="MISC" score="0.0">
          <tokens>
            <token id="17" string="Hispanic" />
          </tokens>
        </entity>
        <entity id="4" string="diabetes" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="18" string="diabetes" />
          </tokens>
        </entity>
        <entity id="5" string="II" type="NUMBER" score="0.0">
          <tokens>
            <token id="26" string="II" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="false">
      <content>Type II, the most common form, develops mostly in obese adults over 40 who also may have a family history of the disease.</content>
      <tokens>
        <token id="1" string="Type" lemma="type" stem="type" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="II" lemma="ii" stem="ii" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="most" lemma="most" stem="most" pos="RBS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="common" lemma="common" stem="common" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="form" lemma="form" stem="form" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="develops" lemma="develop" stem="develop" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="mostly" lemma="mostly" stem="mostli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="obese" lemma="obese" stem="obes" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="adults" lemma="adult" stem="adult" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="40" lemma="40" stem="40" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="16" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="family" lemma="family" stem="famili" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="history" lemma="history" stem="histori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NN Type) (CD II)) (, ,) (NP (DT the) (ADJP (RBS most) (JJ common)) (NN form)) (, ,)) (VP (VBZ develops) (ADVP (RB mostly)) (PP (IN in) (NP (NP (JJ obese) (NNS adults)) (PP (IN over) (NP (CD 40))) (SBAR (WHNP (WP who)) (S (ADVP (RB also)) (VP (MD may) (VP (VB have) (NP (NP (DT a) (NN family) (NN history)) (PP (IN of) (NP (DT the) (NN disease))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="most common" type="ADJP">
          <tokens>
            <token id="5" string="most" />
            <token id="6" string="common" />
          </tokens>
        </chunking>
        <chunking id="2" string="Type II , the most common form ," type="NP">
          <tokens>
            <token id="1" string="Type" />
            <token id="2" string="II" />
            <token id="3" string="," />
            <token id="4" string="the" />
            <token id="5" string="most" />
            <token id="6" string="common" />
            <token id="7" string="form" />
            <token id="8" string="," />
          </tokens>
        </chunking>
        <chunking id="3" string="who also may have a family history of the disease" type="SBAR">
          <tokens>
            <token id="16" string="who" />
            <token id="17" string="also" />
            <token id="18" string="may" />
            <token id="19" string="have" />
            <token id="20" string="a" />
            <token id="21" string="family" />
            <token id="22" string="history" />
            <token id="23" string="of" />
            <token id="24" string="the" />
            <token id="25" string="disease" />
          </tokens>
        </chunking>
        <chunking id="4" string="the disease" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="disease" />
          </tokens>
        </chunking>
        <chunking id="5" string="obese adults" type="NP">
          <tokens>
            <token id="12" string="obese" />
            <token id="13" string="adults" />
          </tokens>
        </chunking>
        <chunking id="6" string="obese adults over 40 who also may have a family history of the disease" type="NP">
          <tokens>
            <token id="12" string="obese" />
            <token id="13" string="adults" />
            <token id="14" string="over" />
            <token id="15" string="40" />
            <token id="16" string="who" />
            <token id="17" string="also" />
            <token id="18" string="may" />
            <token id="19" string="have" />
            <token id="20" string="a" />
            <token id="21" string="family" />
            <token id="22" string="history" />
            <token id="23" string="of" />
            <token id="24" string="the" />
            <token id="25" string="disease" />
          </tokens>
        </chunking>
        <chunking id="7" string="a family history" type="NP">
          <tokens>
            <token id="20" string="a" />
            <token id="21" string="family" />
            <token id="22" string="history" />
          </tokens>
        </chunking>
        <chunking id="8" string="the most common form" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="most" />
            <token id="6" string="common" />
            <token id="7" string="form" />
          </tokens>
        </chunking>
        <chunking id="9" string="a family history of the disease" type="NP">
          <tokens>
            <token id="20" string="a" />
            <token id="21" string="family" />
            <token id="22" string="history" />
            <token id="23" string="of" />
            <token id="24" string="the" />
            <token id="25" string="disease" />
          </tokens>
        </chunking>
        <chunking id="10" string="Type II" type="NP">
          <tokens>
            <token id="1" string="Type" />
            <token id="2" string="II" />
          </tokens>
        </chunking>
        <chunking id="11" string="40" type="NP">
          <tokens>
            <token id="15" string="40" />
          </tokens>
        </chunking>
        <chunking id="12" string="have a family history of the disease" type="VP">
          <tokens>
            <token id="19" string="have" />
            <token id="20" string="a" />
            <token id="21" string="family" />
            <token id="22" string="history" />
            <token id="23" string="of" />
            <token id="24" string="the" />
            <token id="25" string="disease" />
          </tokens>
        </chunking>
        <chunking id="13" string="may have a family history of the disease" type="VP">
          <tokens>
            <token id="18" string="may" />
            <token id="19" string="have" />
            <token id="20" string="a" />
            <token id="21" string="family" />
            <token id="22" string="history" />
            <token id="23" string="of" />
            <token id="24" string="the" />
            <token id="25" string="disease" />
          </tokens>
        </chunking>
        <chunking id="14" string="develops mostly in obese adults over 40 who also may have a family history of the disease" type="VP">
          <tokens>
            <token id="9" string="develops" />
            <token id="10" string="mostly" />
            <token id="11" string="in" />
            <token id="12" string="obese" />
            <token id="13" string="adults" />
            <token id="14" string="over" />
            <token id="15" string="40" />
            <token id="16" string="who" />
            <token id="17" string="also" />
            <token id="18" string="may" />
            <token id="19" string="have" />
            <token id="20" string="a" />
            <token id="21" string="family" />
            <token id="22" string="history" />
            <token id="23" string="of" />
            <token id="24" string="the" />
            <token id="25" string="disease" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="9">develops</governor>
          <dependent id="1">Type</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="1">Type</governor>
          <dependent id="2">II</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">form</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">common</governor>
          <dependent id="5">most</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">form</governor>
          <dependent id="6">common</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="1">Type</governor>
          <dependent id="7">form</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">develops</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">develops</governor>
          <dependent id="10">mostly</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">adults</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">adults</governor>
          <dependent id="12">obese</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">develops</governor>
          <dependent id="13">adults</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">40</governor>
          <dependent id="14">over</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">adults</governor>
          <dependent id="15">40</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">have</governor>
          <dependent id="16">who</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">have</governor>
          <dependent id="17">also</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="19">have</governor>
          <dependent id="18">may</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="13">adults</governor>
          <dependent id="19">have</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">history</governor>
          <dependent id="20">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">history</governor>
          <dependent id="21">family</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">have</governor>
          <dependent id="22">history</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">disease</governor>
          <dependent id="23">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">disease</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">history</governor>
          <dependent id="25">disease</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="25" string="disease" />
          </tokens>
        </entity>
        <entity id="2" string="40" type="NUMBER" score="0.0">
          <tokens>
            <token id="15" string="40" />
          </tokens>
        </entity>
        <entity id="3" string="II" type="NUMBER" score="0.0">
          <tokens>
            <token id="2" string="II" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>In obese diabetics, the body has too much insulin because it is burning more fats than sugars.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="obese" lemma="obese" stem="obes" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="diabetics" lemma="diabetic" stem="diabet" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="body" lemma="body" stem="bodi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="too" lemma="too" stem="too" pos="RB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="much" lemma="much" stem="much" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="insulin" lemma="insulin" stem="insulin" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="13" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="burning" lemma="burn" stem="burn" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="fats" lemma="fat" stem="fat" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="sugars" lemma="sugar" stem="sugar" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (JJ obese) (NNS diabetics))) (, ,) (NP (DT the) (NN body)) (VP (VBZ has) (NP (ADJP (RB too) (JJ much)) (NN insulin) (SBAR (IN because) (S (NP (PRP it)) (VP (VBZ is) (VP (VBG burning) (ADVP (RBR more) (NP (NNS fats))) (PP (IN than) (NP (NNS sugars))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="burning more fats than sugars" type="VP">
          <tokens>
            <token id="14" string="burning" />
            <token id="15" string="more" />
            <token id="16" string="fats" />
            <token id="17" string="than" />
            <token id="18" string="sugars" />
          </tokens>
        </chunking>
        <chunking id="2" string="obese diabetics" type="NP">
          <tokens>
            <token id="2" string="obese" />
            <token id="3" string="diabetics" />
          </tokens>
        </chunking>
        <chunking id="3" string="sugars" type="NP">
          <tokens>
            <token id="18" string="sugars" />
          </tokens>
        </chunking>
        <chunking id="4" string="too much" type="ADJP">
          <tokens>
            <token id="8" string="too" />
            <token id="9" string="much" />
          </tokens>
        </chunking>
        <chunking id="5" string="has too much insulin because it is burning more fats than sugars" type="VP">
          <tokens>
            <token id="7" string="has" />
            <token id="8" string="too" />
            <token id="9" string="much" />
            <token id="10" string="insulin" />
            <token id="11" string="because" />
            <token id="12" string="it" />
            <token id="13" string="is" />
            <token id="14" string="burning" />
            <token id="15" string="more" />
            <token id="16" string="fats" />
            <token id="17" string="than" />
            <token id="18" string="sugars" />
          </tokens>
        </chunking>
        <chunking id="6" string="fats" type="NP">
          <tokens>
            <token id="16" string="fats" />
          </tokens>
        </chunking>
        <chunking id="7" string="too much insulin because it is burning more fats than sugars" type="NP">
          <tokens>
            <token id="8" string="too" />
            <token id="9" string="much" />
            <token id="10" string="insulin" />
            <token id="11" string="because" />
            <token id="12" string="it" />
            <token id="13" string="is" />
            <token id="14" string="burning" />
            <token id="15" string="more" />
            <token id="16" string="fats" />
            <token id="17" string="than" />
            <token id="18" string="sugars" />
          </tokens>
        </chunking>
        <chunking id="8" string="is burning more fats than sugars" type="VP">
          <tokens>
            <token id="13" string="is" />
            <token id="14" string="burning" />
            <token id="15" string="more" />
            <token id="16" string="fats" />
            <token id="17" string="than" />
            <token id="18" string="sugars" />
          </tokens>
        </chunking>
        <chunking id="9" string="it" type="NP">
          <tokens>
            <token id="12" string="it" />
          </tokens>
        </chunking>
        <chunking id="10" string="the body" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="body" />
          </tokens>
        </chunking>
        <chunking id="11" string="because it is burning more fats than sugars" type="SBAR">
          <tokens>
            <token id="11" string="because" />
            <token id="12" string="it" />
            <token id="13" string="is" />
            <token id="14" string="burning" />
            <token id="15" string="more" />
            <token id="16" string="fats" />
            <token id="17" string="than" />
            <token id="18" string="sugars" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">diabetics</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">diabetics</governor>
          <dependent id="2">obese</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">has</governor>
          <dependent id="3">diabetics</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">body</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">has</governor>
          <dependent id="6">body</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">has</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">much</governor>
          <dependent id="8">too</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">insulin</governor>
          <dependent id="9">much</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">has</governor>
          <dependent id="10">insulin</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">burning</governor>
          <dependent id="11">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">burning</governor>
          <dependent id="12">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">burning</governor>
          <dependent id="13">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">insulin</governor>
          <dependent id="14">burning</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">burning</governor>
          <dependent id="15">more</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="15">more</governor>
          <dependent id="16">fats</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">sugars</governor>
          <dependent id="17">than</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">burning</governor>
          <dependent id="18">sugars</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="15" has_coreference="false">
      <content>Type I diabetes usually develops among adolescents and requires that they have daily injections of insulin.</content>
      <tokens>
        <token id="1" string="Type" lemma="type" stem="type" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="i" stem="i" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="3" string="diabetes" lemma="diabetes" stem="diabet" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="4" string="usually" lemma="usually" stem="usual" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="develops" lemma="develop" stem="develop" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="among" lemma="among" stem="among" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="adolescents" lemma="adolescent" stem="adolesc" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="requires" lemma="require" stem="requir" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="daily" lemma="daily" stem="daili" pos="JJ" type="Word" isStopWord="false" ner="SET" is_referenced="false" is_refers="false" />
        <token id="14" string="injections" lemma="injection" stem="inject" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="insulin" lemma="insulin" stem="insulin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NN Type)) (NP (CD I) (NN diabetes))) (VP (VP (ADVP (RB usually)) (VBZ develops) (PP (IN among) (NP (NNS adolescents)))) (CC and) (VP (VBZ requires) (SBAR (IN that) (S (NP (PRP they)) (VP (VBP have) (NP (NP (JJ daily) (NNS injections)) (PP (IN of) (NP (NN insulin))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that they have daily injections of insulin" type="SBAR">
          <tokens>
            <token id="10" string="that" />
            <token id="11" string="they" />
            <token id="12" string="have" />
            <token id="13" string="daily" />
            <token id="14" string="injections" />
            <token id="15" string="of" />
            <token id="16" string="insulin" />
          </tokens>
        </chunking>
        <chunking id="2" string="I diabetes" type="NP">
          <tokens>
            <token id="2" string="I" />
            <token id="3" string="diabetes" />
          </tokens>
        </chunking>
        <chunking id="3" string="adolescents" type="NP">
          <tokens>
            <token id="7" string="adolescents" />
          </tokens>
        </chunking>
        <chunking id="4" string="daily injections" type="NP">
          <tokens>
            <token id="13" string="daily" />
            <token id="14" string="injections" />
          </tokens>
        </chunking>
        <chunking id="5" string="daily injections of insulin" type="NP">
          <tokens>
            <token id="13" string="daily" />
            <token id="14" string="injections" />
            <token id="15" string="of" />
            <token id="16" string="insulin" />
          </tokens>
        </chunking>
        <chunking id="6" string="have daily injections of insulin" type="VP">
          <tokens>
            <token id="12" string="have" />
            <token id="13" string="daily" />
            <token id="14" string="injections" />
            <token id="15" string="of" />
            <token id="16" string="insulin" />
          </tokens>
        </chunking>
        <chunking id="7" string="insulin" type="NP">
          <tokens>
            <token id="16" string="insulin" />
          </tokens>
        </chunking>
        <chunking id="8" string="usually develops among adolescents and requires that they have daily injections of insulin" type="VP">
          <tokens>
            <token id="4" string="usually" />
            <token id="5" string="develops" />
            <token id="6" string="among" />
            <token id="7" string="adolescents" />
            <token id="8" string="and" />
            <token id="9" string="requires" />
            <token id="10" string="that" />
            <token id="11" string="they" />
            <token id="12" string="have" />
            <token id="13" string="daily" />
            <token id="14" string="injections" />
            <token id="15" string="of" />
            <token id="16" string="insulin" />
          </tokens>
        </chunking>
        <chunking id="9" string="Type I diabetes" type="NP">
          <tokens>
            <token id="1" string="Type" />
            <token id="2" string="I" />
            <token id="3" string="diabetes" />
          </tokens>
        </chunking>
        <chunking id="10" string="requires that they have daily injections of insulin" type="VP">
          <tokens>
            <token id="9" string="requires" />
            <token id="10" string="that" />
            <token id="11" string="they" />
            <token id="12" string="have" />
            <token id="13" string="daily" />
            <token id="14" string="injections" />
            <token id="15" string="of" />
            <token id="16" string="insulin" />
          </tokens>
        </chunking>
        <chunking id="11" string="Type" type="NP">
          <tokens>
            <token id="1" string="Type" />
          </tokens>
        </chunking>
        <chunking id="12" string="they" type="NP">
          <tokens>
            <token id="11" string="they" />
          </tokens>
        </chunking>
        <chunking id="13" string="usually develops among adolescents" type="VP">
          <tokens>
            <token id="4" string="usually" />
            <token id="5" string="develops" />
            <token id="6" string="among" />
            <token id="7" string="adolescents" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">develops</governor>
          <dependent id="1">Type</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="3">diabetes</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="1">Type</governor>
          <dependent id="3">diabetes</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">develops</governor>
          <dependent id="4">usually</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">develops</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">adolescents</governor>
          <dependent id="6">among</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">develops</governor>
          <dependent id="7">adolescents</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">develops</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">develops</governor>
          <dependent id="9">requires</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">have</governor>
          <dependent id="10">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">have</governor>
          <dependent id="11">they</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">requires</governor>
          <dependent id="12">have</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">injections</governor>
          <dependent id="13">daily</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">have</governor>
          <dependent id="14">injections</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">insulin</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">injections</governor>
          <dependent id="16">insulin</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="daily" type="SET" score="0.0">
          <tokens>
            <token id="13" string="daily" />
          </tokens>
        </entity>
        <entity id="2" string="I" type="NUMBER" score="0.0">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </entity>
        <entity id="3" string="diabetes" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="3" string="diabetes" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>Stern said family studies of diabetic patients are brining him closer to finding the gene that triggers the disease.</content>
      <tokens>
        <token id="1" string="Stern" lemma="Stern" stem="stern" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="family" lemma="family" stem="famili" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="studies" lemma="study" stem="studi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="diabetic" lemma="diabetic" stem="diabet" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="patients" lemma="patient" stem="patient" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="brining" lemma="brine" stem="brine" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="closer" lemma="closer" stem="closer" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="finding" lemma="find" stem="find" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="gene" lemma="gene" stem="gene" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="triggers" lemma="trigger" stem="trigger" pos="VBZ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Stern)) (VP (VBD said) (SBAR (S (NP (NP (NN family) (NNS studies)) (PP (IN of) (NP (JJ diabetic) (NNS patients)))) (VP (VBP are) (VP (VBG brining) (S (NP (PRP him)) (ADJP (JJR closer) (PP (TO to) (S (VP (VBG finding) (NP (NP (DT the) (NN gene)) (SBAR (WHNP (WDT that)) (S (VP (VBZ triggers) (NP (DT the) (NN disease)))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="said family studies of diabetic patients are brining him closer to finding the gene that triggers the disease" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="family" />
            <token id="4" string="studies" />
            <token id="5" string="of" />
            <token id="6" string="diabetic" />
            <token id="7" string="patients" />
            <token id="8" string="are" />
            <token id="9" string="brining" />
            <token id="10" string="him" />
            <token id="11" string="closer" />
            <token id="12" string="to" />
            <token id="13" string="finding" />
            <token id="14" string="the" />
            <token id="15" string="gene" />
            <token id="16" string="that" />
            <token id="17" string="triggers" />
            <token id="18" string="the" />
            <token id="19" string="disease" />
          </tokens>
        </chunking>
        <chunking id="2" string="brining him closer to finding the gene that triggers the disease" type="VP">
          <tokens>
            <token id="9" string="brining" />
            <token id="10" string="him" />
            <token id="11" string="closer" />
            <token id="12" string="to" />
            <token id="13" string="finding" />
            <token id="14" string="the" />
            <token id="15" string="gene" />
            <token id="16" string="that" />
            <token id="17" string="triggers" />
            <token id="18" string="the" />
            <token id="19" string="disease" />
          </tokens>
        </chunking>
        <chunking id="3" string="are brining him closer to finding the gene that triggers the disease" type="VP">
          <tokens>
            <token id="8" string="are" />
            <token id="9" string="brining" />
            <token id="10" string="him" />
            <token id="11" string="closer" />
            <token id="12" string="to" />
            <token id="13" string="finding" />
            <token id="14" string="the" />
            <token id="15" string="gene" />
            <token id="16" string="that" />
            <token id="17" string="triggers" />
            <token id="18" string="the" />
            <token id="19" string="disease" />
          </tokens>
        </chunking>
        <chunking id="4" string="family studies" type="NP">
          <tokens>
            <token id="3" string="family" />
            <token id="4" string="studies" />
          </tokens>
        </chunking>
        <chunking id="5" string="family studies of diabetic patients are brining him closer to finding the gene that triggers the disease" type="SBAR">
          <tokens>
            <token id="3" string="family" />
            <token id="4" string="studies" />
            <token id="5" string="of" />
            <token id="6" string="diabetic" />
            <token id="7" string="patients" />
            <token id="8" string="are" />
            <token id="9" string="brining" />
            <token id="10" string="him" />
            <token id="11" string="closer" />
            <token id="12" string="to" />
            <token id="13" string="finding" />
            <token id="14" string="the" />
            <token id="15" string="gene" />
            <token id="16" string="that" />
            <token id="17" string="triggers" />
            <token id="18" string="the" />
            <token id="19" string="disease" />
          </tokens>
        </chunking>
        <chunking id="6" string="him" type="NP">
          <tokens>
            <token id="10" string="him" />
          </tokens>
        </chunking>
        <chunking id="7" string="diabetic patients" type="NP">
          <tokens>
            <token id="6" string="diabetic" />
            <token id="7" string="patients" />
          </tokens>
        </chunking>
        <chunking id="8" string="closer to finding the gene that triggers the disease" type="ADJP">
          <tokens>
            <token id="11" string="closer" />
            <token id="12" string="to" />
            <token id="13" string="finding" />
            <token id="14" string="the" />
            <token id="15" string="gene" />
            <token id="16" string="that" />
            <token id="17" string="triggers" />
            <token id="18" string="the" />
            <token id="19" string="disease" />
          </tokens>
        </chunking>
        <chunking id="9" string="the disease" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="disease" />
          </tokens>
        </chunking>
        <chunking id="10" string="triggers the disease" type="VP">
          <tokens>
            <token id="17" string="triggers" />
            <token id="18" string="the" />
            <token id="19" string="disease" />
          </tokens>
        </chunking>
        <chunking id="11" string="Stern" type="NP">
          <tokens>
            <token id="1" string="Stern" />
          </tokens>
        </chunking>
        <chunking id="12" string="family studies of diabetic patients" type="NP">
          <tokens>
            <token id="3" string="family" />
            <token id="4" string="studies" />
            <token id="5" string="of" />
            <token id="6" string="diabetic" />
            <token id="7" string="patients" />
          </tokens>
        </chunking>
        <chunking id="13" string="the gene that triggers the disease" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="gene" />
            <token id="16" string="that" />
            <token id="17" string="triggers" />
            <token id="18" string="the" />
            <token id="19" string="disease" />
          </tokens>
        </chunking>
        <chunking id="14" string="that triggers the disease" type="SBAR">
          <tokens>
            <token id="16" string="that" />
            <token id="17" string="triggers" />
            <token id="18" string="the" />
            <token id="19" string="disease" />
          </tokens>
        </chunking>
        <chunking id="15" string="finding the gene that triggers the disease" type="VP">
          <tokens>
            <token id="13" string="finding" />
            <token id="14" string="the" />
            <token id="15" string="gene" />
            <token id="16" string="that" />
            <token id="17" string="triggers" />
            <token id="18" string="the" />
            <token id="19" string="disease" />
          </tokens>
        </chunking>
        <chunking id="16" string="the gene" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="gene" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">Stern</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">studies</governor>
          <dependent id="3">family</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">brining</governor>
          <dependent id="4">studies</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">patients</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">patients</governor>
          <dependent id="6">diabetic</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">studies</governor>
          <dependent id="7">patients</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">brining</governor>
          <dependent id="8">are</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="9">brining</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">closer</governor>
          <dependent id="10">him</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">brining</governor>
          <dependent id="11">closer</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">finding</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">closer</governor>
          <dependent id="13">finding</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">gene</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">finding</governor>
          <dependent id="15">gene</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">triggers</governor>
          <dependent id="16">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="15">gene</governor>
          <dependent id="17">triggers</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">disease</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">triggers</governor>
          <dependent id="19">disease</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="19" string="disease" />
          </tokens>
        </entity>
        <entity id="2" string="Stern" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Stern" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>A genetic marker might identify people who are susceptible, which could lead to a screening test, he said.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="genetic" lemma="genetic" stem="genet" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="marker" lemma="marker" stem="marker" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="might" lemma="might" stem="might" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="identify" lemma="identify" stem="identifi" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="susceptible" lemma="susceptible" stem="suscept" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="lead" lemma="lead" stem="lead" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="screening" lemma="screening" stem="screen" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="test" lemma="test" stem="test" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT A) (JJ genetic) (NN marker)) (VP (MD might) (VP (VB identify) (NP (NP (NNS people)) (SBAR (WHNP (WP who)) (S (VP (VBP are) (ADJP (JJ susceptible))))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (MD could) (VP (VB lead) (PP (TO to) (NP (DT a) (JJ screening) (NN test))))))))))) (, ,) (NP (PRP he)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="people who are susceptible , which could lead to a screening test" type="NP">
          <tokens>
            <token id="6" string="people" />
            <token id="7" string="who" />
            <token id="8" string="are" />
            <token id="9" string="susceptible" />
            <token id="10" string="," />
            <token id="11" string="which" />
            <token id="12" string="could" />
            <token id="13" string="lead" />
            <token id="14" string="to" />
            <token id="15" string="a" />
            <token id="16" string="screening" />
            <token id="17" string="test" />
          </tokens>
        </chunking>
        <chunking id="2" string="a screening test" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="screening" />
            <token id="17" string="test" />
          </tokens>
        </chunking>
        <chunking id="3" string="identify people who are susceptible , which could lead to a screening test" type="VP">
          <tokens>
            <token id="5" string="identify" />
            <token id="6" string="people" />
            <token id="7" string="who" />
            <token id="8" string="are" />
            <token id="9" string="susceptible" />
            <token id="10" string="," />
            <token id="11" string="which" />
            <token id="12" string="could" />
            <token id="13" string="lead" />
            <token id="14" string="to" />
            <token id="15" string="a" />
            <token id="16" string="screening" />
            <token id="17" string="test" />
          </tokens>
        </chunking>
        <chunking id="4" string="which could lead to a screening test" type="SBAR">
          <tokens>
            <token id="11" string="which" />
            <token id="12" string="could" />
            <token id="13" string="lead" />
            <token id="14" string="to" />
            <token id="15" string="a" />
            <token id="16" string="screening" />
            <token id="17" string="test" />
          </tokens>
        </chunking>
        <chunking id="5" string="are susceptible" type="VP">
          <tokens>
            <token id="8" string="are" />
            <token id="9" string="susceptible" />
          </tokens>
        </chunking>
        <chunking id="6" string="A genetic marker" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="genetic" />
            <token id="3" string="marker" />
          </tokens>
        </chunking>
        <chunking id="7" string="people" type="NP">
          <tokens>
            <token id="6" string="people" />
          </tokens>
        </chunking>
        <chunking id="8" string="susceptible" type="ADJP">
          <tokens>
            <token id="9" string="susceptible" />
          </tokens>
        </chunking>
        <chunking id="9" string="might identify people who are susceptible , which could lead to a screening test" type="VP">
          <tokens>
            <token id="4" string="might" />
            <token id="5" string="identify" />
            <token id="6" string="people" />
            <token id="7" string="who" />
            <token id="8" string="are" />
            <token id="9" string="susceptible" />
            <token id="10" string="," />
            <token id="11" string="which" />
            <token id="12" string="could" />
            <token id="13" string="lead" />
            <token id="14" string="to" />
            <token id="15" string="a" />
            <token id="16" string="screening" />
            <token id="17" string="test" />
          </tokens>
        </chunking>
        <chunking id="10" string="who are susceptible" type="SBAR">
          <tokens>
            <token id="7" string="who" />
            <token id="8" string="are" />
            <token id="9" string="susceptible" />
          </tokens>
        </chunking>
        <chunking id="11" string="lead to a screening test" type="VP">
          <tokens>
            <token id="13" string="lead" />
            <token id="14" string="to" />
            <token id="15" string="a" />
            <token id="16" string="screening" />
            <token id="17" string="test" />
          </tokens>
        </chunking>
        <chunking id="12" string="could lead to a screening test" type="VP">
          <tokens>
            <token id="12" string="could" />
            <token id="13" string="lead" />
            <token id="14" string="to" />
            <token id="15" string="a" />
            <token id="16" string="screening" />
            <token id="17" string="test" />
          </tokens>
        </chunking>
        <chunking id="13" string="he" type="NP">
          <tokens>
            <token id="19" string="he" />
          </tokens>
        </chunking>
        <chunking id="14" string="said" type="VP">
          <tokens>
            <token id="20" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">marker</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">marker</governor>
          <dependent id="2">genetic</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">identify</governor>
          <dependent id="3">marker</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">identify</governor>
          <dependent id="4">might</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="20">said</governor>
          <dependent id="5">identify</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">identify</governor>
          <dependent id="6">people</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">susceptible</governor>
          <dependent id="7">who</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="9">susceptible</governor>
          <dependent id="8">are</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="6">people</governor>
          <dependent id="9">susceptible</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">lead</governor>
          <dependent id="11">which</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">lead</governor>
          <dependent id="12">could</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="6">people</governor>
          <dependent id="13">lead</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">test</governor>
          <dependent id="14">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">test</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">test</governor>
          <dependent id="16">screening</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">lead</governor>
          <dependent id="17">test</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">said</governor>
          <dependent id="19">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="20">said</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>``Then you could go out and zero in on the genetic susceptibles and you can be more intense on your recommendations to them and you could also study that group.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="go" lemma="go" stem="go" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="zero" lemma="zero" stem="zero" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="genetic" lemma="genetic" stem="genet" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="susceptibles" lemma="susceptible" stem="suscept" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="intense" lemma="intense" stem="intens" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="your" lemma="you" stem="your" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="recommendations" lemma="recommendation" stem="recommend" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="study" lemma="study" stem="studi" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="group" lemma="group" stem="group" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (ADVP (RB Then)) (NP (PRP you)) (VP (MD could) (VP (VP (VB go) (PRT (RP out))) (CC and) (VP (NP (CD zero)) (PP (IN in) (PP (IN on) (NP (DT the) (JJ genetic) (NNS susceptibles)))))))) (CC and) (S (S (NP (PRP you)) (VP (MD can) (VP (VB be) (ADJP (RBR more) (JJ intense) (PP (IN on) (NP (PRP$ your) (NNS recommendations)))) (PP (TO to) (NP (PRP them)))))) (CC and) (S (NP (PRP you)) (VP (MD could) (ADVP (RB also)) (VP (VB study) (NP (DT that) (NN group)))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="go out and zero in on the genetic susceptibles" type="VP">
          <tokens>
            <token id="5" string="go" />
            <token id="6" string="out" />
            <token id="7" string="and" />
            <token id="8" string="zero" />
            <token id="9" string="in" />
            <token id="10" string="on" />
            <token id="11" string="the" />
            <token id="12" string="genetic" />
            <token id="13" string="susceptibles" />
          </tokens>
        </chunking>
        <chunking id="2" string="be more intense on your recommendations to them" type="VP">
          <tokens>
            <token id="17" string="be" />
            <token id="18" string="more" />
            <token id="19" string="intense" />
            <token id="20" string="on" />
            <token id="21" string="your" />
            <token id="22" string="recommendations" />
            <token id="23" string="to" />
            <token id="24" string="them" />
          </tokens>
        </chunking>
        <chunking id="3" string="them" type="NP">
          <tokens>
            <token id="24" string="them" />
          </tokens>
        </chunking>
        <chunking id="4" string="your recommendations" type="NP">
          <tokens>
            <token id="21" string="your" />
            <token id="22" string="recommendations" />
          </tokens>
        </chunking>
        <chunking id="5" string="that group" type="NP">
          <tokens>
            <token id="30" string="that" />
            <token id="31" string="group" />
          </tokens>
        </chunking>
        <chunking id="6" string="could go out and zero in on the genetic susceptibles" type="VP">
          <tokens>
            <token id="4" string="could" />
            <token id="5" string="go" />
            <token id="6" string="out" />
            <token id="7" string="and" />
            <token id="8" string="zero" />
            <token id="9" string="in" />
            <token id="10" string="on" />
            <token id="11" string="the" />
            <token id="12" string="genetic" />
            <token id="13" string="susceptibles" />
          </tokens>
        </chunking>
        <chunking id="7" string="can be more intense on your recommendations to them" type="VP">
          <tokens>
            <token id="16" string="can" />
            <token id="17" string="be" />
            <token id="18" string="more" />
            <token id="19" string="intense" />
            <token id="20" string="on" />
            <token id="21" string="your" />
            <token id="22" string="recommendations" />
            <token id="23" string="to" />
            <token id="24" string="them" />
          </tokens>
        </chunking>
        <chunking id="8" string="go out" type="VP">
          <tokens>
            <token id="5" string="go" />
            <token id="6" string="out" />
          </tokens>
        </chunking>
        <chunking id="9" string="zero in on the genetic susceptibles" type="VP">
          <tokens>
            <token id="8" string="zero" />
            <token id="9" string="in" />
            <token id="10" string="on" />
            <token id="11" string="the" />
            <token id="12" string="genetic" />
            <token id="13" string="susceptibles" />
          </tokens>
        </chunking>
        <chunking id="10" string="more intense on your recommendations" type="ADJP">
          <tokens>
            <token id="18" string="more" />
            <token id="19" string="intense" />
            <token id="20" string="on" />
            <token id="21" string="your" />
            <token id="22" string="recommendations" />
          </tokens>
        </chunking>
        <chunking id="11" string="the genetic susceptibles" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="genetic" />
            <token id="13" string="susceptibles" />
          </tokens>
        </chunking>
        <chunking id="12" string="could also study that group" type="VP">
          <tokens>
            <token id="27" string="could" />
            <token id="28" string="also" />
            <token id="29" string="study" />
            <token id="30" string="that" />
            <token id="31" string="group" />
          </tokens>
        </chunking>
        <chunking id="13" string="study that group" type="VP">
          <tokens>
            <token id="29" string="study" />
            <token id="30" string="that" />
            <token id="31" string="group" />
          </tokens>
        </chunking>
        <chunking id="14" string="you" type="NP">
          <tokens>
            <token id="3" string="you" />
          </tokens>
        </chunking>
        <chunking id="15" string="zero" type="NP">
          <tokens>
            <token id="8" string="zero" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="5">go</governor>
          <dependent id="2">Then</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">go</governor>
          <dependent id="3">you</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">go</governor>
          <dependent id="4">could</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">go</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="5">go</governor>
          <dependent id="6">out</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">go</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">go</governor>
          <dependent id="8">zero</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">susceptibles</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">susceptibles</governor>
          <dependent id="10">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">susceptibles</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">susceptibles</governor>
          <dependent id="12">genetic</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">zero</governor>
          <dependent id="13">susceptibles</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">go</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">intense</governor>
          <dependent id="15">you</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="19">intense</governor>
          <dependent id="16">can</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="19">intense</governor>
          <dependent id="17">be</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">intense</governor>
          <dependent id="18">more</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">go</governor>
          <dependent id="19">intense</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">recommendations</governor>
          <dependent id="20">on</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="22">recommendations</governor>
          <dependent id="21">your</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">intense</governor>
          <dependent id="22">recommendations</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">them</governor>
          <dependent id="23">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">intense</governor>
          <dependent id="24">them</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="19">intense</governor>
          <dependent id="25">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">study</governor>
          <dependent id="26">you</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="29">study</governor>
          <dependent id="27">could</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="29">study</governor>
          <dependent id="28">also</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">intense</governor>
          <dependent id="29">study</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">group</governor>
          <dependent id="30">that</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="29">study</governor>
          <dependent id="31">group</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="zero" type="NUMBER" score="0.0">
          <tokens>
            <token id="8" string="zero" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>Stern believes if people exercised more and ate less of the fat-saturated foods common to the diets of low-income Hispanics, fewer would get the disease.</content>
      <tokens>
        <token id="1" string="Stern" lemma="Stern" stem="stern" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="believes" lemma="believe" stem="believ" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="exercised" lemma="exercise" stem="exercis" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="ate" lemma="eat" stem="at" pos="VBD" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="less" lemma="less" stem="less" pos="JJR" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="fat-saturated" lemma="fat-saturated" stem="fat-satur" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="foods" lemma="food" stem="food" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="common" lemma="common" stem="common" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="diets" lemma="diet" stem="diet" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="low-income" lemma="low-income" stem="low-incom" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="Hispanics" lemma="Hispanics" stem="hispan" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="fewer" lemma="fewer" stem="fewer" pos="JJR" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="get" lemma="get" stem="get" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Stern)) (VP (VBZ believes) (SBAR (IN if) (S (NP (NP (NNS people)) (VP (VP (VBN exercised) (S (ADJP (JJR more)))) (CC and) (VP (VBD ate) (S (NP (NP (JJR less)) (PP (IN of) (NP (DT the) (JJ fat-saturated) (NNS foods)))) (ADJP (ADJP (JJ common) (PP (TO to) (NP (NP (DT the) (NNS diets)) (PP (IN of) (NP (JJ low-income) (NNPS Hispanics)))))) (, ,) (ADJP (JJR fewer))))))) (VP (MD would) (VP (VB get) (NP (DT the) (NN disease))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="exercised more" type="VP">
          <tokens>
            <token id="5" string="exercised" />
            <token id="6" string="more" />
          </tokens>
        </chunking>
        <chunking id="2" string="common to the diets of low-income Hispanics" type="ADJP">
          <tokens>
            <token id="14" string="common" />
            <token id="15" string="to" />
            <token id="16" string="the" />
            <token id="17" string="diets" />
            <token id="18" string="of" />
            <token id="19" string="low-income" />
            <token id="20" string="Hispanics" />
          </tokens>
        </chunking>
        <chunking id="3" string="more" type="ADJP">
          <tokens>
            <token id="6" string="more" />
          </tokens>
        </chunking>
        <chunking id="4" string="if people exercised more and ate less of the fat-saturated foods common to the diets of low-income Hispanics , fewer would get the disease" type="SBAR">
          <tokens>
            <token id="3" string="if" />
            <token id="4" string="people" />
            <token id="5" string="exercised" />
            <token id="6" string="more" />
            <token id="7" string="and" />
            <token id="8" string="ate" />
            <token id="9" string="less" />
            <token id="10" string="of" />
            <token id="11" string="the" />
            <token id="12" string="fat-saturated" />
            <token id="13" string="foods" />
            <token id="14" string="common" />
            <token id="15" string="to" />
            <token id="16" string="the" />
            <token id="17" string="diets" />
            <token id="18" string="of" />
            <token id="19" string="low-income" />
            <token id="20" string="Hispanics" />
            <token id="21" string="," />
            <token id="22" string="fewer" />
            <token id="23" string="would" />
            <token id="24" string="get" />
            <token id="25" string="the" />
            <token id="26" string="disease" />
          </tokens>
        </chunking>
        <chunking id="5" string="ate less of the fat-saturated foods common to the diets of low-income Hispanics , fewer" type="VP">
          <tokens>
            <token id="8" string="ate" />
            <token id="9" string="less" />
            <token id="10" string="of" />
            <token id="11" string="the" />
            <token id="12" string="fat-saturated" />
            <token id="13" string="foods" />
            <token id="14" string="common" />
            <token id="15" string="to" />
            <token id="16" string="the" />
            <token id="17" string="diets" />
            <token id="18" string="of" />
            <token id="19" string="low-income" />
            <token id="20" string="Hispanics" />
            <token id="21" string="," />
            <token id="22" string="fewer" />
          </tokens>
        </chunking>
        <chunking id="6" string="fewer" type="ADJP">
          <tokens>
            <token id="22" string="fewer" />
          </tokens>
        </chunking>
        <chunking id="7" string="would get the disease" type="VP">
          <tokens>
            <token id="23" string="would" />
            <token id="24" string="get" />
            <token id="25" string="the" />
            <token id="26" string="disease" />
          </tokens>
        </chunking>
        <chunking id="8" string="less" type="NP">
          <tokens>
            <token id="9" string="less" />
          </tokens>
        </chunking>
        <chunking id="9" string="people exercised more and ate less of the fat-saturated foods common to the diets of low-income Hispanics , fewer" type="NP">
          <tokens>
            <token id="4" string="people" />
            <token id="5" string="exercised" />
            <token id="6" string="more" />
            <token id="7" string="and" />
            <token id="8" string="ate" />
            <token id="9" string="less" />
            <token id="10" string="of" />
            <token id="11" string="the" />
            <token id="12" string="fat-saturated" />
            <token id="13" string="foods" />
            <token id="14" string="common" />
            <token id="15" string="to" />
            <token id="16" string="the" />
            <token id="17" string="diets" />
            <token id="18" string="of" />
            <token id="19" string="low-income" />
            <token id="20" string="Hispanics" />
            <token id="21" string="," />
            <token id="22" string="fewer" />
          </tokens>
        </chunking>
        <chunking id="10" string="people" type="NP">
          <tokens>
            <token id="4" string="people" />
          </tokens>
        </chunking>
        <chunking id="11" string="believes if people exercised more and ate less of the fat-saturated foods common to the diets of low-income Hispanics , fewer would get the disease" type="VP">
          <tokens>
            <token id="2" string="believes" />
            <token id="3" string="if" />
            <token id="4" string="people" />
            <token id="5" string="exercised" />
            <token id="6" string="more" />
            <token id="7" string="and" />
            <token id="8" string="ate" />
            <token id="9" string="less" />
            <token id="10" string="of" />
            <token id="11" string="the" />
            <token id="12" string="fat-saturated" />
            <token id="13" string="foods" />
            <token id="14" string="common" />
            <token id="15" string="to" />
            <token id="16" string="the" />
            <token id="17" string="diets" />
            <token id="18" string="of" />
            <token id="19" string="low-income" />
            <token id="20" string="Hispanics" />
            <token id="21" string="," />
            <token id="22" string="fewer" />
            <token id="23" string="would" />
            <token id="24" string="get" />
            <token id="25" string="the" />
            <token id="26" string="disease" />
          </tokens>
        </chunking>
        <chunking id="12" string="the diets" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="diets" />
          </tokens>
        </chunking>
        <chunking id="13" string="low-income Hispanics" type="NP">
          <tokens>
            <token id="19" string="low-income" />
            <token id="20" string="Hispanics" />
          </tokens>
        </chunking>
        <chunking id="14" string="the disease" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="disease" />
          </tokens>
        </chunking>
        <chunking id="15" string="the diets of low-income Hispanics" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="diets" />
            <token id="18" string="of" />
            <token id="19" string="low-income" />
            <token id="20" string="Hispanics" />
          </tokens>
        </chunking>
        <chunking id="16" string="exercised more and ate less of the fat-saturated foods common to the diets of low-income Hispanics , fewer" type="VP">
          <tokens>
            <token id="5" string="exercised" />
            <token id="6" string="more" />
            <token id="7" string="and" />
            <token id="8" string="ate" />
            <token id="9" string="less" />
            <token id="10" string="of" />
            <token id="11" string="the" />
            <token id="12" string="fat-saturated" />
            <token id="13" string="foods" />
            <token id="14" string="common" />
            <token id="15" string="to" />
            <token id="16" string="the" />
            <token id="17" string="diets" />
            <token id="18" string="of" />
            <token id="19" string="low-income" />
            <token id="20" string="Hispanics" />
            <token id="21" string="," />
            <token id="22" string="fewer" />
          </tokens>
        </chunking>
        <chunking id="17" string="the fat-saturated foods" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="fat-saturated" />
            <token id="13" string="foods" />
          </tokens>
        </chunking>
        <chunking id="18" string="common to the diets of low-income Hispanics , fewer" type="ADJP">
          <tokens>
            <token id="14" string="common" />
            <token id="15" string="to" />
            <token id="16" string="the" />
            <token id="17" string="diets" />
            <token id="18" string="of" />
            <token id="19" string="low-income" />
            <token id="20" string="Hispanics" />
            <token id="21" string="," />
            <token id="22" string="fewer" />
          </tokens>
        </chunking>
        <chunking id="19" string="Stern" type="NP">
          <tokens>
            <token id="1" string="Stern" />
          </tokens>
        </chunking>
        <chunking id="20" string="less of the fat-saturated foods" type="NP">
          <tokens>
            <token id="9" string="less" />
            <token id="10" string="of" />
            <token id="11" string="the" />
            <token id="12" string="fat-saturated" />
            <token id="13" string="foods" />
          </tokens>
        </chunking>
        <chunking id="21" string="get the disease" type="VP">
          <tokens>
            <token id="24" string="get" />
            <token id="25" string="the" />
            <token id="26" string="disease" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">believes</governor>
          <dependent id="1">Stern</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">believes</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">get</governor>
          <dependent id="3">if</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">get</governor>
          <dependent id="4">people</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">people</governor>
          <dependent id="5">exercised</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">exercised</governor>
          <dependent id="6">more</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">exercised</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">exercised</governor>
          <dependent id="8">ate</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">common</governor>
          <dependent id="9">less</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">foods</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">foods</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">foods</governor>
          <dependent id="12">fat-saturated</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">less</governor>
          <dependent id="13">foods</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">ate</governor>
          <dependent id="14">common</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">diets</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">diets</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">common</governor>
          <dependent id="17">diets</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">Hispanics</governor>
          <dependent id="18">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">Hispanics</governor>
          <dependent id="19">low-income</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">diets</governor>
          <dependent id="20">Hispanics</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="14">common</governor>
          <dependent id="22">fewer</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="24">get</governor>
          <dependent id="23">would</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="2">believes</governor>
          <dependent id="24">get</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">disease</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">get</governor>
          <dependent id="26">disease</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="26" string="disease" />
          </tokens>
        </entity>
        <entity id="2" string="Stern" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Stern" />
          </tokens>
        </entity>
        <entity id="3" string="Hispanics" type="MISC" score="0.0">
          <tokens>
            <token id="20" string="Hispanics" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>``We use the term double jeopardy for Mexican-Americans,&amp;apost;&amp;apost; he said.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="use" lemma="use" stem="us" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="term" lemma="term" stem="term" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="double" lemma="double" stem="doubl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="jeopardy" lemma="jeopardy" stem="jeopardi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Mexican-Americans" lemma="mexican-american" stem="mexican-american" pos="NNS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP We)) (VP (VBP use) (NP (NP (DT the) (NN term) (JJ double) (NN jeopardy)) (PP (IN for) (NP (NNS Mexican-Americans)))))) (, ,) ('' '') (NP (PRP he)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the term double jeopardy" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="term" />
            <token id="6" string="double" />
            <token id="7" string="jeopardy" />
          </tokens>
        </chunking>
        <chunking id="2" string="use the term double jeopardy for Mexican-Americans" type="VP">
          <tokens>
            <token id="3" string="use" />
            <token id="4" string="the" />
            <token id="5" string="term" />
            <token id="6" string="double" />
            <token id="7" string="jeopardy" />
            <token id="8" string="for" />
            <token id="9" string="Mexican-Americans" />
          </tokens>
        </chunking>
        <chunking id="3" string="the term double jeopardy for Mexican-Americans" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="term" />
            <token id="6" string="double" />
            <token id="7" string="jeopardy" />
            <token id="8" string="for" />
            <token id="9" string="Mexican-Americans" />
          </tokens>
        </chunking>
        <chunking id="4" string="he" type="NP">
          <tokens>
            <token id="12" string="he" />
          </tokens>
        </chunking>
        <chunking id="5" string="We" type="NP">
          <tokens>
            <token id="2" string="We" />
          </tokens>
        </chunking>
        <chunking id="6" string="said" type="VP">
          <tokens>
            <token id="13" string="said" />
          </tokens>
        </chunking>
        <chunking id="7" string="Mexican-Americans" type="NP">
          <tokens>
            <token id="9" string="Mexican-Americans" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">use</governor>
          <dependent id="2">We</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">said</governor>
          <dependent id="3">use</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">jeopardy</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">jeopardy</governor>
          <dependent id="5">term</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">jeopardy</governor>
          <dependent id="6">double</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">use</governor>
          <dependent id="7">jeopardy</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Mexican-Americans</governor>
          <dependent id="8">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">jeopardy</governor>
          <dependent id="9">Mexican-Americans</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">said</governor>
          <dependent id="12">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Mexican-Americans" type="MISC" score="0.0">
          <tokens>
            <token id="9" string="Mexican-Americans" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>``We don&amp;apost;t know why, when they get diabetes, they have a more severe form of the disease _ whether it&amp;apost;s a biological difference or is it that they are not getting as good medical care.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="know" lemma="know" stem="know" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="why" lemma="why" stem="why" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="get" lemma="get" stem="get" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="diabetes" lemma="diabetes" stem="diabet" pos="NNS" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="true" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="severe" lemma="severe" stem="sever" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="form" lemma="form" stem="form" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="22" string="_" lemma="_" stem="_" pos="NN" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="whether" lemma="whether" stem="whether" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="biological" lemma="biological" stem="biolog" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="difference" lemma="difference" stem="differ" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="32" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="34" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="getting" lemma="get" stem="get" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="as" lemma="as" stem="a" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="good" lemma="good" stem="good" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="medical" lemma="medical" stem="medic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="care" lemma="care" stem="care" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP We)) (VP (VBP do) (RB n't) (VP (VB know) (SBAR (WHADVP (WRB why)) (, ,) (S (SBAR (WHADVP (WRB when)) (S (NP (PRP they)) (VP (VBP get) (NP (NNS diabetes))))) (, ,) (NP (PRP they)) (VP (VBP have) (NP (NP (DT a) (ADJP (RBR more) (JJ severe)) (NN form)) (PP (IN of) (NP (NP (DT the) (NN disease) (NN _)) (SBAR (IN whether) (S (NP (PRP it)) (VP (VP (VBZ 's) (NP (DT a) (JJ biological) (NN difference))) (CC or) (VP (VBZ is) (NP (PRP it))))))))) (SBAR (IN that) (S (NP (PRP they)) (VP (VBP are) (RB not) (VP (VBG getting) (NP (ADJP (RB as) (JJ good)) (JJ medical) (NN care))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the disease _ whether it 's a biological difference or is it" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="disease" />
            <token id="22" string="_" />
            <token id="23" string="whether" />
            <token id="24" string="it" />
            <token id="25" string="'s" />
            <token id="26" string="a" />
            <token id="27" string="biological" />
            <token id="28" string="difference" />
            <token id="29" string="or" />
            <token id="30" string="is" />
            <token id="31" string="it" />
          </tokens>
        </chunking>
        <chunking id="2" string="'s a biological difference" type="VP">
          <tokens>
            <token id="25" string="'s" />
            <token id="26" string="a" />
            <token id="27" string="biological" />
            <token id="28" string="difference" />
          </tokens>
        </chunking>
        <chunking id="3" string="getting as good medical care" type="VP">
          <tokens>
            <token id="36" string="getting" />
            <token id="37" string="as" />
            <token id="38" string="good" />
            <token id="39" string="medical" />
            <token id="40" string="care" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="24" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="We" type="NP">
          <tokens>
            <token id="2" string="We" />
          </tokens>
        </chunking>
        <chunking id="6" string="a more severe form of the disease _ whether it 's a biological difference or is it" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="more" />
            <token id="17" string="severe" />
            <token id="18" string="form" />
            <token id="19" string="of" />
            <token id="20" string="the" />
            <token id="21" string="disease" />
            <token id="22" string="_" />
            <token id="23" string="whether" />
            <token id="24" string="it" />
            <token id="25" string="'s" />
            <token id="26" string="a" />
            <token id="27" string="biological" />
            <token id="28" string="difference" />
            <token id="29" string="or" />
            <token id="30" string="is" />
            <token id="31" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="know why , when they get diabetes , they have a more severe form of the disease _ whether it 's a biological difference or is it that they are not getting as good medical care" type="VP">
          <tokens>
            <token id="5" string="know" />
            <token id="6" string="why" />
            <token id="7" string="," />
            <token id="8" string="when" />
            <token id="9" string="they" />
            <token id="10" string="get" />
            <token id="11" string="diabetes" />
            <token id="12" string="," />
            <token id="13" string="they" />
            <token id="14" string="have" />
            <token id="15" string="a" />
            <token id="16" string="more" />
            <token id="17" string="severe" />
            <token id="18" string="form" />
            <token id="19" string="of" />
            <token id="20" string="the" />
            <token id="21" string="disease" />
            <token id="22" string="_" />
            <token id="23" string="whether" />
            <token id="24" string="it" />
            <token id="25" string="'s" />
            <token id="26" string="a" />
            <token id="27" string="biological" />
            <token id="28" string="difference" />
            <token id="29" string="or" />
            <token id="30" string="is" />
            <token id="31" string="it" />
            <token id="32" string="that" />
            <token id="33" string="they" />
            <token id="34" string="are" />
            <token id="35" string="not" />
            <token id="36" string="getting" />
            <token id="37" string="as" />
            <token id="38" string="good" />
            <token id="39" string="medical" />
            <token id="40" string="care" />
          </tokens>
        </chunking>
        <chunking id="8" string="whether it 's a biological difference or is it" type="SBAR">
          <tokens>
            <token id="23" string="whether" />
            <token id="24" string="it" />
            <token id="25" string="'s" />
            <token id="26" string="a" />
            <token id="27" string="biological" />
            <token id="28" string="difference" />
            <token id="29" string="or" />
            <token id="30" string="is" />
            <token id="31" string="it" />
          </tokens>
        </chunking>
        <chunking id="9" string="do n't know why , when they get diabetes , they have a more severe form of the disease _ whether it 's a biological difference or is it that they are not getting as good medical care" type="VP">
          <tokens>
            <token id="3" string="do" />
            <token id="4" string="n't" />
            <token id="5" string="know" />
            <token id="6" string="why" />
            <token id="7" string="," />
            <token id="8" string="when" />
            <token id="9" string="they" />
            <token id="10" string="get" />
            <token id="11" string="diabetes" />
            <token id="12" string="," />
            <token id="13" string="they" />
            <token id="14" string="have" />
            <token id="15" string="a" />
            <token id="16" string="more" />
            <token id="17" string="severe" />
            <token id="18" string="form" />
            <token id="19" string="of" />
            <token id="20" string="the" />
            <token id="21" string="disease" />
            <token id="22" string="_" />
            <token id="23" string="whether" />
            <token id="24" string="it" />
            <token id="25" string="'s" />
            <token id="26" string="a" />
            <token id="27" string="biological" />
            <token id="28" string="difference" />
            <token id="29" string="or" />
            <token id="30" string="is" />
            <token id="31" string="it" />
            <token id="32" string="that" />
            <token id="33" string="they" />
            <token id="34" string="are" />
            <token id="35" string="not" />
            <token id="36" string="getting" />
            <token id="37" string="as" />
            <token id="38" string="good" />
            <token id="39" string="medical" />
            <token id="40" string="care" />
          </tokens>
        </chunking>
        <chunking id="10" string="diabetes" type="NP">
          <tokens>
            <token id="11" string="diabetes" />
          </tokens>
        </chunking>
        <chunking id="11" string="when they get diabetes" type="SBAR">
          <tokens>
            <token id="8" string="when" />
            <token id="9" string="they" />
            <token id="10" string="get" />
            <token id="11" string="diabetes" />
          </tokens>
        </chunking>
        <chunking id="12" string="why" type="WHADVP">
          <tokens>
            <token id="6" string="why" />
          </tokens>
        </chunking>
        <chunking id="13" string="as good" type="ADJP">
          <tokens>
            <token id="37" string="as" />
            <token id="38" string="good" />
          </tokens>
        </chunking>
        <chunking id="14" string="why , when they get diabetes , they have a more severe form of the disease _ whether it 's a biological difference or is it that they are not getting as good medical care" type="SBAR">
          <tokens>
            <token id="6" string="why" />
            <token id="7" string="," />
            <token id="8" string="when" />
            <token id="9" string="they" />
            <token id="10" string="get" />
            <token id="11" string="diabetes" />
            <token id="12" string="," />
            <token id="13" string="they" />
            <token id="14" string="have" />
            <token id="15" string="a" />
            <token id="16" string="more" />
            <token id="17" string="severe" />
            <token id="18" string="form" />
            <token id="19" string="of" />
            <token id="20" string="the" />
            <token id="21" string="disease" />
            <token id="22" string="_" />
            <token id="23" string="whether" />
            <token id="24" string="it" />
            <token id="25" string="'s" />
            <token id="26" string="a" />
            <token id="27" string="biological" />
            <token id="28" string="difference" />
            <token id="29" string="or" />
            <token id="30" string="is" />
            <token id="31" string="it" />
            <token id="32" string="that" />
            <token id="33" string="they" />
            <token id="34" string="are" />
            <token id="35" string="not" />
            <token id="36" string="getting" />
            <token id="37" string="as" />
            <token id="38" string="good" />
            <token id="39" string="medical" />
            <token id="40" string="care" />
          </tokens>
        </chunking>
        <chunking id="15" string="have a more severe form of the disease _ whether it 's a biological difference or is it that they are not getting as good medical care" type="VP">
          <tokens>
            <token id="14" string="have" />
            <token id="15" string="a" />
            <token id="16" string="more" />
            <token id="17" string="severe" />
            <token id="18" string="form" />
            <token id="19" string="of" />
            <token id="20" string="the" />
            <token id="21" string="disease" />
            <token id="22" string="_" />
            <token id="23" string="whether" />
            <token id="24" string="it" />
            <token id="25" string="'s" />
            <token id="26" string="a" />
            <token id="27" string="biological" />
            <token id="28" string="difference" />
            <token id="29" string="or" />
            <token id="30" string="is" />
            <token id="31" string="it" />
            <token id="32" string="that" />
            <token id="33" string="they" />
            <token id="34" string="are" />
            <token id="35" string="not" />
            <token id="36" string="getting" />
            <token id="37" string="as" />
            <token id="38" string="good" />
            <token id="39" string="medical" />
            <token id="40" string="care" />
          </tokens>
        </chunking>
        <chunking id="16" string="get diabetes" type="VP">
          <tokens>
            <token id="10" string="get" />
            <token id="11" string="diabetes" />
          </tokens>
        </chunking>
        <chunking id="17" string="more severe" type="ADJP">
          <tokens>
            <token id="16" string="more" />
            <token id="17" string="severe" />
          </tokens>
        </chunking>
        <chunking id="18" string="when" type="WHADVP">
          <tokens>
            <token id="8" string="when" />
          </tokens>
        </chunking>
        <chunking id="19" string="they" type="NP">
          <tokens>
            <token id="9" string="they" />
          </tokens>
        </chunking>
        <chunking id="20" string="a more severe form" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="more" />
            <token id="17" string="severe" />
            <token id="18" string="form" />
          </tokens>
        </chunking>
        <chunking id="21" string="a biological difference" type="NP">
          <tokens>
            <token id="26" string="a" />
            <token id="27" string="biological" />
            <token id="28" string="difference" />
          </tokens>
        </chunking>
        <chunking id="22" string="the disease _" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="disease" />
            <token id="22" string="_" />
          </tokens>
        </chunking>
        <chunking id="23" string="as good medical care" type="NP">
          <tokens>
            <token id="37" string="as" />
            <token id="38" string="good" />
            <token id="39" string="medical" />
            <token id="40" string="care" />
          </tokens>
        </chunking>
        <chunking id="24" string="is it" type="VP">
          <tokens>
            <token id="30" string="is" />
            <token id="31" string="it" />
          </tokens>
        </chunking>
        <chunking id="25" string="that they are not getting as good medical care" type="SBAR">
          <tokens>
            <token id="32" string="that" />
            <token id="33" string="they" />
            <token id="34" string="are" />
            <token id="35" string="not" />
            <token id="36" string="getting" />
            <token id="37" string="as" />
            <token id="38" string="good" />
            <token id="39" string="medical" />
            <token id="40" string="care" />
          </tokens>
        </chunking>
        <chunking id="26" string="are not getting as good medical care" type="VP">
          <tokens>
            <token id="34" string="are" />
            <token id="35" string="not" />
            <token id="36" string="getting" />
            <token id="37" string="as" />
            <token id="38" string="good" />
            <token id="39" string="medical" />
            <token id="40" string="care" />
          </tokens>
        </chunking>
        <chunking id="27" string="'s a biological difference or is it" type="VP">
          <tokens>
            <token id="25" string="'s" />
            <token id="26" string="a" />
            <token id="27" string="biological" />
            <token id="28" string="difference" />
            <token id="29" string="or" />
            <token id="30" string="is" />
            <token id="31" string="it" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">know</governor>
          <dependent id="2">We</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">know</governor>
          <dependent id="3">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">know</governor>
          <dependent id="4">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">know</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">have</governor>
          <dependent id="6">why</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">get</governor>
          <dependent id="8">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">get</governor>
          <dependent id="9">they</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="14">have</governor>
          <dependent id="10">get</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">get</governor>
          <dependent id="11">diabetes</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">have</governor>
          <dependent id="13">they</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">know</governor>
          <dependent id="14">have</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">form</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">severe</governor>
          <dependent id="16">more</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">form</governor>
          <dependent id="17">severe</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">have</governor>
          <dependent id="18">form</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">_</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">_</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">_</governor>
          <dependent id="21">disease</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">form</governor>
          <dependent id="22">_</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="28">difference</governor>
          <dependent id="23">whether</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">difference</governor>
          <dependent id="24">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="28">difference</governor>
          <dependent id="25">'s</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">difference</governor>
          <dependent id="26">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">difference</governor>
          <dependent id="27">biological</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="22">_</governor>
          <dependent id="28">difference</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="28">difference</governor>
          <dependent id="29">or</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="31">it</governor>
          <dependent id="30">is</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="28">difference</governor>
          <dependent id="31">it</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="36">getting</governor>
          <dependent id="32">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="36">getting</governor>
          <dependent id="33">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="36">getting</governor>
          <dependent id="34">are</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="36">getting</governor>
          <dependent id="35">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">have</governor>
          <dependent id="36">getting</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="38">good</governor>
          <dependent id="37">as</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="40">care</governor>
          <dependent id="38">good</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="40">care</governor>
          <dependent id="39">medical</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="36">getting</governor>
          <dependent id="40">care</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="21" string="disease" />
          </tokens>
        </entity>
        <entity id="2" string="diabetes" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="11" string="diabetes" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>``But the interesting thing is that upper-income Mexican-Americans do not have the same risk as low-income Mexican-Americans.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="interesting" lemma="interesting" stem="interest" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="thing" lemma="thing" stem="thing" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="upper-income" lemma="upper-income" stem="upper-incom" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="Mexican-Americans" lemma="mexican-american" stem="mexican-american" pos="NNS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="10" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="same" lemma="same" stem="same" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="risk" lemma="risk" stem="risk" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="low-income" lemma="low-income" stem="low-incom" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="Mexican-Americans" lemma="Mexican-Americans" stem="mexican-american" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (CC But) (NP (DT the) (JJ interesting) (NN thing)) (VP (VBZ is) (SBAR (IN that) (S (NP (NN upper-income) (NNS Mexican-Americans)) (VP (VBP do) (RB not) (VP (VB have) (NP (NP (DT the) (JJ same) (NN risk)) (PP (IN as) (NP (JJ low-income) (NNPS Mexican-Americans))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="do not have the same risk as low-income Mexican-Americans" type="VP">
          <tokens>
            <token id="10" string="do" />
            <token id="11" string="not" />
            <token id="12" string="have" />
            <token id="13" string="the" />
            <token id="14" string="same" />
            <token id="15" string="risk" />
            <token id="16" string="as" />
            <token id="17" string="low-income" />
            <token id="18" string="Mexican-Americans" />
          </tokens>
        </chunking>
        <chunking id="2" string="the same risk" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="same" />
            <token id="15" string="risk" />
          </tokens>
        </chunking>
        <chunking id="3" string="that upper-income Mexican-Americans do not have the same risk as low-income Mexican-Americans" type="SBAR">
          <tokens>
            <token id="7" string="that" />
            <token id="8" string="upper-income" />
            <token id="9" string="Mexican-Americans" />
            <token id="10" string="do" />
            <token id="11" string="not" />
            <token id="12" string="have" />
            <token id="13" string="the" />
            <token id="14" string="same" />
            <token id="15" string="risk" />
            <token id="16" string="as" />
            <token id="17" string="low-income" />
            <token id="18" string="Mexican-Americans" />
          </tokens>
        </chunking>
        <chunking id="4" string="the same risk as low-income Mexican-Americans" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="same" />
            <token id="15" string="risk" />
            <token id="16" string="as" />
            <token id="17" string="low-income" />
            <token id="18" string="Mexican-Americans" />
          </tokens>
        </chunking>
        <chunking id="5" string="the interesting thing" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="interesting" />
            <token id="5" string="thing" />
          </tokens>
        </chunking>
        <chunking id="6" string="is that upper-income Mexican-Americans do not have the same risk as low-income Mexican-Americans" type="VP">
          <tokens>
            <token id="6" string="is" />
            <token id="7" string="that" />
            <token id="8" string="upper-income" />
            <token id="9" string="Mexican-Americans" />
            <token id="10" string="do" />
            <token id="11" string="not" />
            <token id="12" string="have" />
            <token id="13" string="the" />
            <token id="14" string="same" />
            <token id="15" string="risk" />
            <token id="16" string="as" />
            <token id="17" string="low-income" />
            <token id="18" string="Mexican-Americans" />
          </tokens>
        </chunking>
        <chunking id="7" string="have the same risk as low-income Mexican-Americans" type="VP">
          <tokens>
            <token id="12" string="have" />
            <token id="13" string="the" />
            <token id="14" string="same" />
            <token id="15" string="risk" />
            <token id="16" string="as" />
            <token id="17" string="low-income" />
            <token id="18" string="Mexican-Americans" />
          </tokens>
        </chunking>
        <chunking id="8" string="low-income Mexican-Americans" type="NP">
          <tokens>
            <token id="17" string="low-income" />
            <token id="18" string="Mexican-Americans" />
          </tokens>
        </chunking>
        <chunking id="9" string="upper-income Mexican-Americans" type="NP">
          <tokens>
            <token id="8" string="upper-income" />
            <token id="9" string="Mexican-Americans" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="6">is</governor>
          <dependent id="2">But</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">thing</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">thing</governor>
          <dependent id="4">interesting</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">is</governor>
          <dependent id="5">thing</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">is</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">have</governor>
          <dependent id="7">that</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Mexican-Americans</governor>
          <dependent id="8">upper-income</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">have</governor>
          <dependent id="9">Mexican-Americans</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">have</governor>
          <dependent id="10">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="12">have</governor>
          <dependent id="11">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">is</governor>
          <dependent id="12">have</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">risk</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">risk</governor>
          <dependent id="14">same</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">have</governor>
          <dependent id="15">risk</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Mexican-Americans</governor>
          <dependent id="16">as</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">Mexican-Americans</governor>
          <dependent id="17">low-income</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">risk</governor>
          <dependent id="18">Mexican-Americans</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Mexican-Americans" type="MISC" score="0.0">
          <tokens>
            <token id="9" string="Mexican-Americans" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>It may be that the gene is there, but for some reason it may not be expressed in the upper-income Mexican-Americans.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="gene" lemma="gene" stem="gene" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="there" lemma="there" stem="there" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="reason" lemma="reason" stem="reason" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="expressed" lemma="express" stem="express" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="upper-income" lemma="upper-income" stem="upper-incom" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="Mexican-Americans" lemma="Mexican-Americans" stem="mexican-american" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP It)) (VP (MD may) (VP (VB be) (SBAR (IN that) (S (NP (DT the) (NN gene)) (VP (VBZ is) (ADVP (RB there)))))))) (, ,) (CC but) (S (PP (IN for) (NP (DT some) (NN reason))) (NP (PRP it)) (VP (MD may) (RB not) (VP (VB be) (VP (VBN expressed) (PP (IN in) (NP (NP (DT the) (NN upper-income)) (NP (NNPS Mexican-Americans)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="expressed in the upper-income Mexican-Americans" type="VP">
          <tokens>
            <token id="18" string="expressed" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="upper-income" />
            <token id="22" string="Mexican-Americans" />
          </tokens>
        </chunking>
        <chunking id="2" string="may be that the gene is there" type="VP">
          <tokens>
            <token id="2" string="may" />
            <token id="3" string="be" />
            <token id="4" string="that" />
            <token id="5" string="the" />
            <token id="6" string="gene" />
            <token id="7" string="is" />
            <token id="8" string="there" />
          </tokens>
        </chunking>
        <chunking id="3" string="that the gene is there" type="SBAR">
          <tokens>
            <token id="4" string="that" />
            <token id="5" string="the" />
            <token id="6" string="gene" />
            <token id="7" string="is" />
            <token id="8" string="there" />
          </tokens>
        </chunking>
        <chunking id="4" string="the upper-income Mexican-Americans" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="upper-income" />
            <token id="22" string="Mexican-Americans" />
          </tokens>
        </chunking>
        <chunking id="5" string="the upper-income" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="upper-income" />
          </tokens>
        </chunking>
        <chunking id="6" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="14" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="be that the gene is there" type="VP">
          <tokens>
            <token id="3" string="be" />
            <token id="4" string="that" />
            <token id="5" string="the" />
            <token id="6" string="gene" />
            <token id="7" string="is" />
            <token id="8" string="there" />
          </tokens>
        </chunking>
        <chunking id="9" string="may not be expressed in the upper-income Mexican-Americans" type="VP">
          <tokens>
            <token id="15" string="may" />
            <token id="16" string="not" />
            <token id="17" string="be" />
            <token id="18" string="expressed" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="upper-income" />
            <token id="22" string="Mexican-Americans" />
          </tokens>
        </chunking>
        <chunking id="10" string="some reason" type="NP">
          <tokens>
            <token id="12" string="some" />
            <token id="13" string="reason" />
          </tokens>
        </chunking>
        <chunking id="11" string="be expressed in the upper-income Mexican-Americans" type="VP">
          <tokens>
            <token id="17" string="be" />
            <token id="18" string="expressed" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="upper-income" />
            <token id="22" string="Mexican-Americans" />
          </tokens>
        </chunking>
        <chunking id="12" string="is there" type="VP">
          <tokens>
            <token id="7" string="is" />
            <token id="8" string="there" />
          </tokens>
        </chunking>
        <chunking id="13" string="the gene" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="gene" />
          </tokens>
        </chunking>
        <chunking id="14" string="Mexican-Americans" type="NP">
          <tokens>
            <token id="22" string="Mexican-Americans" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">be</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">be</governor>
          <dependent id="2">may</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">be</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">is</governor>
          <dependent id="4">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">gene</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">is</governor>
          <dependent id="6">gene</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">be</governor>
          <dependent id="7">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">is</governor>
          <dependent id="8">there</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">be</governor>
          <dependent id="10">but</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">reason</governor>
          <dependent id="11">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">reason</governor>
          <dependent id="12">some</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">expressed</governor>
          <dependent id="13">reason</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="18">expressed</governor>
          <dependent id="14">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">expressed</governor>
          <dependent id="15">may</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="18">expressed</governor>
          <dependent id="16">not</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="18">expressed</governor>
          <dependent id="17">be</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">be</governor>
          <dependent id="18">expressed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">upper-income</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">upper-income</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">expressed</governor>
          <dependent id="21">upper-income</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="21">upper-income</governor>
          <dependent id="22">Mexican-Americans</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Mexican-Americans" type="MISC" score="0.0">
          <tokens>
            <token id="22" string="Mexican-Americans" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>``Also, Mexican-Americans tend to have more body fat in their upper torso and we can see that as related to diabetes.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Mexican-Americans" lemma="Mexican-Americans" stem="mexican-american" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="5" string="tend" lemma="tend" stem="tend" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="body" lemma="body" stem="bodi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="fat" lemma="fat" stem="fat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="upper" lemma="upper" stem="upper" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="torso" lemma="torso" stem="torso" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="see" lemma="see" stem="see" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="related" lemma="related" stem="relat" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="diabetes" lemma="diabetes" stem="diabet" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (ADVP (RB Also)) (, ,) (S (NP (NNPS Mexican-Americans)) (VP (VBP tend) (S (VP (TO to) (VP (VB have) (NP (NP (JJR more) (NN body) (NN fat)) (PP (IN in) (NP (PRP$ their) (JJ upper) (NN torso))))))))) (CC and) (S (NP (PRP we)) (VP (MD can) (VP (VB see) (NP (DT that)) (PP (IN as) (ADJP (JJ related))) (PP (TO to) (NP (NN diabetes)))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="have more body fat in their upper torso" type="VP">
          <tokens>
            <token id="7" string="have" />
            <token id="8" string="more" />
            <token id="9" string="body" />
            <token id="10" string="fat" />
            <token id="11" string="in" />
            <token id="12" string="their" />
            <token id="13" string="upper" />
            <token id="14" string="torso" />
          </tokens>
        </chunking>
        <chunking id="2" string="more body fat in their upper torso" type="NP">
          <tokens>
            <token id="8" string="more" />
            <token id="9" string="body" />
            <token id="10" string="fat" />
            <token id="11" string="in" />
            <token id="12" string="their" />
            <token id="13" string="upper" />
            <token id="14" string="torso" />
          </tokens>
        </chunking>
        <chunking id="3" string="to have more body fat in their upper torso" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="have" />
            <token id="8" string="more" />
            <token id="9" string="body" />
            <token id="10" string="fat" />
            <token id="11" string="in" />
            <token id="12" string="their" />
            <token id="13" string="upper" />
            <token id="14" string="torso" />
          </tokens>
        </chunking>
        <chunking id="4" string="we" type="NP">
          <tokens>
            <token id="16" string="we" />
          </tokens>
        </chunking>
        <chunking id="5" string="see that as related to diabetes" type="VP">
          <tokens>
            <token id="18" string="see" />
            <token id="19" string="that" />
            <token id="20" string="as" />
            <token id="21" string="related" />
            <token id="22" string="to" />
            <token id="23" string="diabetes" />
          </tokens>
        </chunking>
        <chunking id="6" string="that" type="NP">
          <tokens>
            <token id="19" string="that" />
          </tokens>
        </chunking>
        <chunking id="7" string="more body fat" type="NP">
          <tokens>
            <token id="8" string="more" />
            <token id="9" string="body" />
            <token id="10" string="fat" />
          </tokens>
        </chunking>
        <chunking id="8" string="tend to have more body fat in their upper torso" type="VP">
          <tokens>
            <token id="5" string="tend" />
            <token id="6" string="to" />
            <token id="7" string="have" />
            <token id="8" string="more" />
            <token id="9" string="body" />
            <token id="10" string="fat" />
            <token id="11" string="in" />
            <token id="12" string="their" />
            <token id="13" string="upper" />
            <token id="14" string="torso" />
          </tokens>
        </chunking>
        <chunking id="9" string="related" type="ADJP">
          <tokens>
            <token id="21" string="related" />
          </tokens>
        </chunking>
        <chunking id="10" string="can see that as related to diabetes" type="VP">
          <tokens>
            <token id="17" string="can" />
            <token id="18" string="see" />
            <token id="19" string="that" />
            <token id="20" string="as" />
            <token id="21" string="related" />
            <token id="22" string="to" />
            <token id="23" string="diabetes" />
          </tokens>
        </chunking>
        <chunking id="11" string="their upper torso" type="NP">
          <tokens>
            <token id="12" string="their" />
            <token id="13" string="upper" />
            <token id="14" string="torso" />
          </tokens>
        </chunking>
        <chunking id="12" string="diabetes" type="NP">
          <tokens>
            <token id="23" string="diabetes" />
          </tokens>
        </chunking>
        <chunking id="13" string="Mexican-Americans" type="NP">
          <tokens>
            <token id="4" string="Mexican-Americans" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="5">tend</governor>
          <dependent id="2">Also</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">tend</governor>
          <dependent id="4">Mexican-Americans</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">tend</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">have</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">tend</governor>
          <dependent id="7">have</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">fat</governor>
          <dependent id="8">more</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">fat</governor>
          <dependent id="9">body</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">have</governor>
          <dependent id="10">fat</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">torso</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">torso</governor>
          <dependent id="12">their</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">torso</governor>
          <dependent id="13">upper</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">fat</governor>
          <dependent id="14">torso</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">tend</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">see</governor>
          <dependent id="16">we</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">see</governor>
          <dependent id="17">can</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">tend</governor>
          <dependent id="18">see</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">see</governor>
          <dependent id="19">that</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">related</governor>
          <dependent id="20">as</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="18">see</governor>
          <dependent id="21">related</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">diabetes</governor>
          <dependent id="22">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">see</governor>
          <dependent id="23">diabetes</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="diabetes" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="23" string="diabetes" />
          </tokens>
        </entity>
        <entity id="2" string="Mexican-Americans" type="MISC" score="0.0">
          <tokens>
            <token id="4" string="Mexican-Americans" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>Between 1979 and 1988, Stern and his staff studied more than 5,000 people and found that 387 of 2,905 Hispanics had the disease, or 13.3 percent, compared to only 87 of 1,780 Anglos, or 4.8 percent.</content>
      <tokens>
        <token id="1" string="Between" lemma="between" stem="between" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="1979" lemma="1979" stem="1979" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="1988" lemma="1988" stem="1988" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Stern" lemma="Stern" stem="stern" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="staff" lemma="staff" stem="staff" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="studied" lemma="study" stem="studi" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="5,000" lemma="5,000" stem="5,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="14" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="found" lemma="find" stem="found" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="387" lemma="387" stem="387" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="2,905" lemma="2,905" stem="2,905" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="21" string="Hispanics" lemma="Hispanics" stem="hispan" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="22" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="13.3" lemma="13.3" stem="13.3" pos="CD" type="Number" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="28" string="percent" lemma="percent" stem="percent" pos="NN" type="Word" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="29" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="compared" lemma="compare" stem="compar" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="87" lemma="87" stem="87" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="34" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="1,780" lemma="1,780" stem="1,780" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="36" string="Anglos" lemma="anglo" stem="anglo" pos="NNS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="37" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="4.8" lemma="4.8" stem="4.8" pos="CD" type="Number" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="40" string="percent" lemma="percent" stem="percent" pos="NN" type="Word" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="41" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN Between) (NP (CD 1979) (CC and) (CD 1988))) (, ,) (NP (NP (NNP Stern)) (CC and) (NP (PRP$ his) (NN staff))) (VP (VP (VBN studied) (NP (QP (JJR more) (IN than) (CD 5,000)) (NNS people))) (CC and) (VP (VBD found) (SBAR (IN that) (S (NP (NP (CD 387)) (PP (IN of) (NP (CD 2,905) (NNPS Hispanics)))) (VP (VBD had) (NP (NP (DT the) (NN disease)) (, ,) (CC or) (NP (CD 13.3) (NN percent)) (, ,)) (PP (VBN compared) (PP (TO to) (NP (NP (NP (QP (RB only) (CD 87))) (PP (IN of) (NP (CD 1,780) (NNS Anglos)))) (, ,) (CC or) (NP (CD 4.8) (NN percent)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="only 87" type="NP">
          <tokens>
            <token id="32" string="only" />
            <token id="33" string="87" />
          </tokens>
        </chunking>
        <chunking id="2" string="Stern and his staff" type="NP">
          <tokens>
            <token id="6" string="Stern" />
            <token id="7" string="and" />
            <token id="8" string="his" />
            <token id="9" string="staff" />
          </tokens>
        </chunking>
        <chunking id="3" string="his staff" type="NP">
          <tokens>
            <token id="8" string="his" />
            <token id="9" string="staff" />
          </tokens>
        </chunking>
        <chunking id="4" string="1979 and 1988" type="NP">
          <tokens>
            <token id="2" string="1979" />
            <token id="3" string="and" />
            <token id="4" string="1988" />
          </tokens>
        </chunking>
        <chunking id="5" string="that 387 of 2,905 Hispanics had the disease , or 13.3 percent , compared to only 87 of 1,780 Anglos , or 4.8 percent" type="SBAR">
          <tokens>
            <token id="17" string="that" />
            <token id="18" string="387" />
            <token id="19" string="of" />
            <token id="20" string="2,905" />
            <token id="21" string="Hispanics" />
            <token id="22" string="had" />
            <token id="23" string="the" />
            <token id="24" string="disease" />
            <token id="25" string="," />
            <token id="26" string="or" />
            <token id="27" string="13.3" />
            <token id="28" string="percent" />
            <token id="29" string="," />
            <token id="30" string="compared" />
            <token id="31" string="to" />
            <token id="32" string="only" />
            <token id="33" string="87" />
            <token id="34" string="of" />
            <token id="35" string="1,780" />
            <token id="36" string="Anglos" />
            <token id="37" string="," />
            <token id="38" string="or" />
            <token id="39" string="4.8" />
            <token id="40" string="percent" />
          </tokens>
        </chunking>
        <chunking id="6" string="4.8 percent" type="NP">
          <tokens>
            <token id="39" string="4.8" />
            <token id="40" string="percent" />
          </tokens>
        </chunking>
        <chunking id="7" string="studied more than 5,000 people" type="VP">
          <tokens>
            <token id="10" string="studied" />
            <token id="11" string="more" />
            <token id="12" string="than" />
            <token id="13" string="5,000" />
            <token id="14" string="people" />
          </tokens>
        </chunking>
        <chunking id="8" string="more than 5,000 people" type="NP">
          <tokens>
            <token id="11" string="more" />
            <token id="12" string="than" />
            <token id="13" string="5,000" />
            <token id="14" string="people" />
          </tokens>
        </chunking>
        <chunking id="9" string="the disease" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="disease" />
          </tokens>
        </chunking>
        <chunking id="10" string="387" type="NP">
          <tokens>
            <token id="18" string="387" />
          </tokens>
        </chunking>
        <chunking id="11" string="studied more than 5,000 people and found that 387 of 2,905 Hispanics had the disease , or 13.3 percent , compared to only 87 of 1,780 Anglos , or 4.8 percent" type="VP">
          <tokens>
            <token id="10" string="studied" />
            <token id="11" string="more" />
            <token id="12" string="than" />
            <token id="13" string="5,000" />
            <token id="14" string="people" />
            <token id="15" string="and" />
            <token id="16" string="found" />
            <token id="17" string="that" />
            <token id="18" string="387" />
            <token id="19" string="of" />
            <token id="20" string="2,905" />
            <token id="21" string="Hispanics" />
            <token id="22" string="had" />
            <token id="23" string="the" />
            <token id="24" string="disease" />
            <token id="25" string="," />
            <token id="26" string="or" />
            <token id="27" string="13.3" />
            <token id="28" string="percent" />
            <token id="29" string="," />
            <token id="30" string="compared" />
            <token id="31" string="to" />
            <token id="32" string="only" />
            <token id="33" string="87" />
            <token id="34" string="of" />
            <token id="35" string="1,780" />
            <token id="36" string="Anglos" />
            <token id="37" string="," />
            <token id="38" string="or" />
            <token id="39" string="4.8" />
            <token id="40" string="percent" />
          </tokens>
        </chunking>
        <chunking id="12" string="387 of 2,905 Hispanics" type="NP">
          <tokens>
            <token id="18" string="387" />
            <token id="19" string="of" />
            <token id="20" string="2,905" />
            <token id="21" string="Hispanics" />
          </tokens>
        </chunking>
        <chunking id="13" string="only 87 of 1,780 Anglos" type="NP">
          <tokens>
            <token id="32" string="only" />
            <token id="33" string="87" />
            <token id="34" string="of" />
            <token id="35" string="1,780" />
            <token id="36" string="Anglos" />
          </tokens>
        </chunking>
        <chunking id="14" string="the disease , or 13.3 percent ," type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="disease" />
            <token id="25" string="," />
            <token id="26" string="or" />
            <token id="27" string="13.3" />
            <token id="28" string="percent" />
            <token id="29" string="," />
          </tokens>
        </chunking>
        <chunking id="15" string="Stern" type="NP">
          <tokens>
            <token id="6" string="Stern" />
          </tokens>
        </chunking>
        <chunking id="16" string="13.3 percent" type="NP">
          <tokens>
            <token id="27" string="13.3" />
            <token id="28" string="percent" />
          </tokens>
        </chunking>
        <chunking id="17" string="1,780 Anglos" type="NP">
          <tokens>
            <token id="35" string="1,780" />
            <token id="36" string="Anglos" />
          </tokens>
        </chunking>
        <chunking id="18" string="found that 387 of 2,905 Hispanics had the disease , or 13.3 percent , compared to only 87 of 1,780 Anglos , or 4.8 percent" type="VP">
          <tokens>
            <token id="16" string="found" />
            <token id="17" string="that" />
            <token id="18" string="387" />
            <token id="19" string="of" />
            <token id="20" string="2,905" />
            <token id="21" string="Hispanics" />
            <token id="22" string="had" />
            <token id="23" string="the" />
            <token id="24" string="disease" />
            <token id="25" string="," />
            <token id="26" string="or" />
            <token id="27" string="13.3" />
            <token id="28" string="percent" />
            <token id="29" string="," />
            <token id="30" string="compared" />
            <token id="31" string="to" />
            <token id="32" string="only" />
            <token id="33" string="87" />
            <token id="34" string="of" />
            <token id="35" string="1,780" />
            <token id="36" string="Anglos" />
            <token id="37" string="," />
            <token id="38" string="or" />
            <token id="39" string="4.8" />
            <token id="40" string="percent" />
          </tokens>
        </chunking>
        <chunking id="19" string="2,905 Hispanics" type="NP">
          <tokens>
            <token id="20" string="2,905" />
            <token id="21" string="Hispanics" />
          </tokens>
        </chunking>
        <chunking id="20" string="had the disease , or 13.3 percent , compared to only 87 of 1,780 Anglos , or 4.8 percent" type="VP">
          <tokens>
            <token id="22" string="had" />
            <token id="23" string="the" />
            <token id="24" string="disease" />
            <token id="25" string="," />
            <token id="26" string="or" />
            <token id="27" string="13.3" />
            <token id="28" string="percent" />
            <token id="29" string="," />
            <token id="30" string="compared" />
            <token id="31" string="to" />
            <token id="32" string="only" />
            <token id="33" string="87" />
            <token id="34" string="of" />
            <token id="35" string="1,780" />
            <token id="36" string="Anglos" />
            <token id="37" string="," />
            <token id="38" string="or" />
            <token id="39" string="4.8" />
            <token id="40" string="percent" />
          </tokens>
        </chunking>
        <chunking id="21" string="only 87 of 1,780 Anglos , or 4.8 percent" type="NP">
          <tokens>
            <token id="32" string="only" />
            <token id="33" string="87" />
            <token id="34" string="of" />
            <token id="35" string="1,780" />
            <token id="36" string="Anglos" />
            <token id="37" string="," />
            <token id="38" string="or" />
            <token id="39" string="4.8" />
            <token id="40" string="percent" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">1979</governor>
          <dependent id="1">Between</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">studied</governor>
          <dependent id="2">1979</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">1979</governor>
          <dependent id="3">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">1979</governor>
          <dependent id="4">1988</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">studied</governor>
          <dependent id="6">Stern</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">Stern</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">staff</governor>
          <dependent id="8">his</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">Stern</governor>
          <dependent id="9">staff</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">studied</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">5,000</governor>
          <dependent id="11">more</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="11">more</governor>
          <dependent id="12">than</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="14">people</governor>
          <dependent id="13">5,000</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">studied</governor>
          <dependent id="14">people</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">studied</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">studied</governor>
          <dependent id="16">found</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">had</governor>
          <dependent id="17">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">had</governor>
          <dependent id="18">387</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">Hispanics</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="21">Hispanics</governor>
          <dependent id="20">2,905</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">387</governor>
          <dependent id="21">Hispanics</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">found</governor>
          <dependent id="22">had</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">disease</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">had</governor>
          <dependent id="24">disease</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="24">disease</governor>
          <dependent id="26">or</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="28">percent</governor>
          <dependent id="27">13.3</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="24">disease</governor>
          <dependent id="28">percent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">87</governor>
          <dependent id="30">compared</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="30">compared</governor>
          <dependent id="31">to</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="33">87</governor>
          <dependent id="32">only</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="22">had</governor>
          <dependent id="33">87</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">Anglos</governor>
          <dependent id="34">of</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="36">Anglos</governor>
          <dependent id="35">1,780</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">87</governor>
          <dependent id="36">Anglos</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="33">87</governor>
          <dependent id="38">or</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="40">percent</governor>
          <dependent id="39">4.8</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="33">87</governor>
          <dependent id="40">percent</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="24" string="disease" />
          </tokens>
        </entity>
        <entity id="2" string="5,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="13" string="5,000" />
          </tokens>
        </entity>
        <entity id="3" string="4.8 percent" type="PERCENT" score="0.0">
          <tokens>
            <token id="39" string="4.8" />
            <token id="40" string="percent" />
          </tokens>
        </entity>
        <entity id="4" string="1988" type="DATE" score="0.0">
          <tokens>
            <token id="4" string="1988" />
          </tokens>
        </entity>
        <entity id="5" string="387" type="NUMBER" score="0.0">
          <tokens>
            <token id="18" string="387" />
          </tokens>
        </entity>
        <entity id="6" string="1,780" type="NUMBER" score="0.0">
          <tokens>
            <token id="35" string="1,780" />
          </tokens>
        </entity>
        <entity id="7" string="2,905" type="NUMBER" score="0.0">
          <tokens>
            <token id="20" string="2,905" />
          </tokens>
        </entity>
        <entity id="8" string="Stern" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Stern" />
          </tokens>
        </entity>
        <entity id="9" string="13.3 percent" type="PERCENT" score="0.0">
          <tokens>
            <token id="27" string="13.3" />
            <token id="28" string="percent" />
          </tokens>
        </entity>
        <entity id="10" string="Anglos" type="MISC" score="0.0">
          <tokens>
            <token id="36" string="Anglos" />
          </tokens>
        </entity>
        <entity id="11" string="Hispanics" type="MISC" score="0.0">
          <tokens>
            <token id="21" string="Hispanics" />
          </tokens>
        </entity>
        <entity id="12" string="1979" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="1979" />
          </tokens>
        </entity>
        <entity id="13" string="87" type="NUMBER" score="0.0">
          <tokens>
            <token id="33" string="87" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="26" has_coreference="true">
      <content>Researchers believe that poor Hispanics&amp;apost; diets of cheap, processed foods, lack of exercise and infrequent medical attention _ either due to poverty or a cultural bias against doctors _ increases their risk of acquiring diabetes.</content>
      <tokens>
        <token id="1" string="Researchers" lemma="researcher" stem="research" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="believe" lemma="believe" stem="believ" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="poor" lemma="poor" stem="poor" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="Hispanics" lemma="Hispanics" stem="hispan" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="6" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="diets" lemma="diet" stem="diet" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="cheap" lemma="cheap" stem="cheap" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="processed" lemma="process" stem="process" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="foods" lemma="food" stem="food" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="lack" lemma="lack" stem="lack" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="exercise" lemma="exercise" stem="exercis" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="infrequent" lemma="infrequent" stem="infrequ" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="medical" lemma="medical" stem="medic" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="attention" lemma="attention" stem="attent" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="_" lemma="_" stem="_" pos="NN" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="either" lemma="either" stem="either" pos="CC" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="due" lemma="due" stem="due" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="poverty" lemma="poverty" stem="poverti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="cultural" lemma="cultural" stem="cultur" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="bias" lemma="bias" stem="bia" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="doctors" lemma="doctor" stem="doctor" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string="_" lemma="_" stem="_" pos="VBP" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="increases" lemma="increase" stem="increas" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="35" string="risk" lemma="risk" stem="risk" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="36" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="37" string="acquiring" lemma="acquire" stem="acquir" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="38" string="diabetes" lemma="diabetes" stem="diabet" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="false" />
        <token id="39" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNS Researchers)) (VP (VBP believe) (SBAR (IN that) (S (NP (NP (NP (JJ poor) (NNPS Hispanics) (POS ')) (NNS diets)) (PP (IN of) (NP (NP (ADJP (JJ cheap) (, ,) (VBN processed)) (NNS foods)) (, ,) (NP (NP (NN lack)) (PP (IN of) (NP (NP (NP (UCP (NP (NN exercise)) (CC and) (ADJP (JJ infrequent))) (JJ medical) (NN attention) (NN _)) (PP (CC either) (NP (ADJP (JJ due) (PP (TO to))) (NN poverty)))) (CC or) (NP (NP (DT a) (JJ cultural) (NN bias)) (PP (IN against) (NP (NNS doctors)))))))))) (VP (VBP _) (S (NP (NNS increases)) (NP (NP (PRP$ their) (NN risk)) (PP (IN of) (S (VP (VBG acquiring) (NP (NN diabetes))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="due to" type="ADJP">
          <tokens>
            <token id="23" string="due" />
            <token id="24" string="to" />
          </tokens>
        </chunking>
        <chunking id="2" string="lack" type="NP">
          <tokens>
            <token id="14" string="lack" />
          </tokens>
        </chunking>
        <chunking id="3" string="doctors" type="NP">
          <tokens>
            <token id="31" string="doctors" />
          </tokens>
        </chunking>
        <chunking id="4" string="Researchers" type="NP">
          <tokens>
            <token id="1" string="Researchers" />
          </tokens>
        </chunking>
        <chunking id="5" string="cheap , processed foods" type="NP">
          <tokens>
            <token id="9" string="cheap" />
            <token id="10" string="," />
            <token id="11" string="processed" />
            <token id="12" string="foods" />
          </tokens>
        </chunking>
        <chunking id="6" string="poor Hispanics ' diets" type="NP">
          <tokens>
            <token id="4" string="poor" />
            <token id="5" string="Hispanics" />
            <token id="6" string="'" />
            <token id="7" string="diets" />
          </tokens>
        </chunking>
        <chunking id="7" string="that poor Hispanics ' diets of cheap , processed foods , lack of exercise and infrequent medical attention _ either due to poverty or a cultural bias against doctors _ increases their risk of acquiring diabetes" type="SBAR">
          <tokens>
            <token id="3" string="that" />
            <token id="4" string="poor" />
            <token id="5" string="Hispanics" />
            <token id="6" string="'" />
            <token id="7" string="diets" />
            <token id="8" string="of" />
            <token id="9" string="cheap" />
            <token id="10" string="," />
            <token id="11" string="processed" />
            <token id="12" string="foods" />
            <token id="13" string="," />
            <token id="14" string="lack" />
            <token id="15" string="of" />
            <token id="16" string="exercise" />
            <token id="17" string="and" />
            <token id="18" string="infrequent" />
            <token id="19" string="medical" />
            <token id="20" string="attention" />
            <token id="21" string="_" />
            <token id="22" string="either" />
            <token id="23" string="due" />
            <token id="24" string="to" />
            <token id="25" string="poverty" />
            <token id="26" string="or" />
            <token id="27" string="a" />
            <token id="28" string="cultural" />
            <token id="29" string="bias" />
            <token id="30" string="against" />
            <token id="31" string="doctors" />
            <token id="32" string="_" />
            <token id="33" string="increases" />
            <token id="34" string="their" />
            <token id="35" string="risk" />
            <token id="36" string="of" />
            <token id="37" string="acquiring" />
            <token id="38" string="diabetes" />
          </tokens>
        </chunking>
        <chunking id="8" string="diabetes" type="NP">
          <tokens>
            <token id="38" string="diabetes" />
          </tokens>
        </chunking>
        <chunking id="9" string="infrequent" type="ADJP">
          <tokens>
            <token id="18" string="infrequent" />
          </tokens>
        </chunking>
        <chunking id="10" string="a cultural bias against doctors" type="NP">
          <tokens>
            <token id="27" string="a" />
            <token id="28" string="cultural" />
            <token id="29" string="bias" />
            <token id="30" string="against" />
            <token id="31" string="doctors" />
          </tokens>
        </chunking>
        <chunking id="11" string="their risk of acquiring diabetes" type="NP">
          <tokens>
            <token id="34" string="their" />
            <token id="35" string="risk" />
            <token id="36" string="of" />
            <token id="37" string="acquiring" />
            <token id="38" string="diabetes" />
          </tokens>
        </chunking>
        <chunking id="12" string="believe that poor Hispanics ' diets of cheap , processed foods , lack of exercise and infrequent medical attention _ either due to poverty or a cultural bias against doctors _ increases their risk of acquiring diabetes" type="VP">
          <tokens>
            <token id="2" string="believe" />
            <token id="3" string="that" />
            <token id="4" string="poor" />
            <token id="5" string="Hispanics" />
            <token id="6" string="'" />
            <token id="7" string="diets" />
            <token id="8" string="of" />
            <token id="9" string="cheap" />
            <token id="10" string="," />
            <token id="11" string="processed" />
            <token id="12" string="foods" />
            <token id="13" string="," />
            <token id="14" string="lack" />
            <token id="15" string="of" />
            <token id="16" string="exercise" />
            <token id="17" string="and" />
            <token id="18" string="infrequent" />
            <token id="19" string="medical" />
            <token id="20" string="attention" />
            <token id="21" string="_" />
            <token id="22" string="either" />
            <token id="23" string="due" />
            <token id="24" string="to" />
            <token id="25" string="poverty" />
            <token id="26" string="or" />
            <token id="27" string="a" />
            <token id="28" string="cultural" />
            <token id="29" string="bias" />
            <token id="30" string="against" />
            <token id="31" string="doctors" />
            <token id="32" string="_" />
            <token id="33" string="increases" />
            <token id="34" string="their" />
            <token id="35" string="risk" />
            <token id="36" string="of" />
            <token id="37" string="acquiring" />
            <token id="38" string="diabetes" />
          </tokens>
        </chunking>
        <chunking id="13" string="exercise and infrequent medical attention _" type="NP">
          <tokens>
            <token id="16" string="exercise" />
            <token id="17" string="and" />
            <token id="18" string="infrequent" />
            <token id="19" string="medical" />
            <token id="20" string="attention" />
            <token id="21" string="_" />
          </tokens>
        </chunking>
        <chunking id="14" string="acquiring diabetes" type="VP">
          <tokens>
            <token id="37" string="acquiring" />
            <token id="38" string="diabetes" />
          </tokens>
        </chunking>
        <chunking id="15" string="exercise" type="NP">
          <tokens>
            <token id="16" string="exercise" />
          </tokens>
        </chunking>
        <chunking id="16" string="cheap , processed foods , lack of exercise and infrequent medical attention _ either due to poverty or a cultural bias against doctors" type="NP">
          <tokens>
            <token id="9" string="cheap" />
            <token id="10" string="," />
            <token id="11" string="processed" />
            <token id="12" string="foods" />
            <token id="13" string="," />
            <token id="14" string="lack" />
            <token id="15" string="of" />
            <token id="16" string="exercise" />
            <token id="17" string="and" />
            <token id="18" string="infrequent" />
            <token id="19" string="medical" />
            <token id="20" string="attention" />
            <token id="21" string="_" />
            <token id="22" string="either" />
            <token id="23" string="due" />
            <token id="24" string="to" />
            <token id="25" string="poverty" />
            <token id="26" string="or" />
            <token id="27" string="a" />
            <token id="28" string="cultural" />
            <token id="29" string="bias" />
            <token id="30" string="against" />
            <token id="31" string="doctors" />
          </tokens>
        </chunking>
        <chunking id="17" string="exercise and infrequent medical attention _ either due to poverty or a cultural bias against doctors" type="NP">
          <tokens>
            <token id="16" string="exercise" />
            <token id="17" string="and" />
            <token id="18" string="infrequent" />
            <token id="19" string="medical" />
            <token id="20" string="attention" />
            <token id="21" string="_" />
            <token id="22" string="either" />
            <token id="23" string="due" />
            <token id="24" string="to" />
            <token id="25" string="poverty" />
            <token id="26" string="or" />
            <token id="27" string="a" />
            <token id="28" string="cultural" />
            <token id="29" string="bias" />
            <token id="30" string="against" />
            <token id="31" string="doctors" />
          </tokens>
        </chunking>
        <chunking id="18" string="lack of exercise and infrequent medical attention _ either due to poverty or a cultural bias against doctors" type="NP">
          <tokens>
            <token id="14" string="lack" />
            <token id="15" string="of" />
            <token id="16" string="exercise" />
            <token id="17" string="and" />
            <token id="18" string="infrequent" />
            <token id="19" string="medical" />
            <token id="20" string="attention" />
            <token id="21" string="_" />
            <token id="22" string="either" />
            <token id="23" string="due" />
            <token id="24" string="to" />
            <token id="25" string="poverty" />
            <token id="26" string="or" />
            <token id="27" string="a" />
            <token id="28" string="cultural" />
            <token id="29" string="bias" />
            <token id="30" string="against" />
            <token id="31" string="doctors" />
          </tokens>
        </chunking>
        <chunking id="19" string="exercise and infrequent medical attention _ either due to poverty" type="NP">
          <tokens>
            <token id="16" string="exercise" />
            <token id="17" string="and" />
            <token id="18" string="infrequent" />
            <token id="19" string="medical" />
            <token id="20" string="attention" />
            <token id="21" string="_" />
            <token id="22" string="either" />
            <token id="23" string="due" />
            <token id="24" string="to" />
            <token id="25" string="poverty" />
          </tokens>
        </chunking>
        <chunking id="20" string="their risk" type="NP">
          <tokens>
            <token id="34" string="their" />
            <token id="35" string="risk" />
          </tokens>
        </chunking>
        <chunking id="21" string="poor Hispanics '" type="NP">
          <tokens>
            <token id="4" string="poor" />
            <token id="5" string="Hispanics" />
            <token id="6" string="'" />
          </tokens>
        </chunking>
        <chunking id="22" string="increases" type="NP">
          <tokens>
            <token id="33" string="increases" />
          </tokens>
        </chunking>
        <chunking id="23" string="due to poverty" type="NP">
          <tokens>
            <token id="23" string="due" />
            <token id="24" string="to" />
            <token id="25" string="poverty" />
          </tokens>
        </chunking>
        <chunking id="24" string="a cultural bias" type="NP">
          <tokens>
            <token id="27" string="a" />
            <token id="28" string="cultural" />
            <token id="29" string="bias" />
          </tokens>
        </chunking>
        <chunking id="25" string="poor Hispanics ' diets of cheap , processed foods , lack of exercise and infrequent medical attention _ either due to poverty or a cultural bias against doctors" type="NP">
          <tokens>
            <token id="4" string="poor" />
            <token id="5" string="Hispanics" />
            <token id="6" string="'" />
            <token id="7" string="diets" />
            <token id="8" string="of" />
            <token id="9" string="cheap" />
            <token id="10" string="," />
            <token id="11" string="processed" />
            <token id="12" string="foods" />
            <token id="13" string="," />
            <token id="14" string="lack" />
            <token id="15" string="of" />
            <token id="16" string="exercise" />
            <token id="17" string="and" />
            <token id="18" string="infrequent" />
            <token id="19" string="medical" />
            <token id="20" string="attention" />
            <token id="21" string="_" />
            <token id="22" string="either" />
            <token id="23" string="due" />
            <token id="24" string="to" />
            <token id="25" string="poverty" />
            <token id="26" string="or" />
            <token id="27" string="a" />
            <token id="28" string="cultural" />
            <token id="29" string="bias" />
            <token id="30" string="against" />
            <token id="31" string="doctors" />
          </tokens>
        </chunking>
        <chunking id="26" string="cheap , processed" type="ADJP">
          <tokens>
            <token id="9" string="cheap" />
            <token id="10" string="," />
            <token id="11" string="processed" />
          </tokens>
        </chunking>
        <chunking id="27" string="_ increases their risk of acquiring diabetes" type="VP">
          <tokens>
            <token id="32" string="_" />
            <token id="33" string="increases" />
            <token id="34" string="their" />
            <token id="35" string="risk" />
            <token id="36" string="of" />
            <token id="37" string="acquiring" />
            <token id="38" string="diabetes" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">believe</governor>
          <dependent id="1">Researchers</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">believe</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="32">_</governor>
          <dependent id="3">that</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">Hispanics</governor>
          <dependent id="4">poor</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">diets</governor>
          <dependent id="5">Hispanics</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">Hispanics</governor>
          <dependent id="6">'</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="32">_</governor>
          <dependent id="7">diets</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">foods</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="11">processed</governor>
          <dependent id="9">cheap</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">foods</governor>
          <dependent id="11">processed</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">diets</governor>
          <dependent id="12">foods</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="12">foods</governor>
          <dependent id="14">lack</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">_</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">_</governor>
          <dependent id="16">exercise</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">exercise</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">exercise</governor>
          <dependent id="18">infrequent</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">_</governor>
          <dependent id="19">medical</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">_</governor>
          <dependent id="20">attention</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">lack</governor>
          <dependent id="21">_</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">poverty</governor>
          <dependent id="22">either</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">poverty</governor>
          <dependent id="23">due</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">due</governor>
          <dependent id="24">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">_</governor>
          <dependent id="25">poverty</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="21">_</governor>
          <dependent id="26">or</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">bias</governor>
          <dependent id="27">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">bias</governor>
          <dependent id="28">cultural</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="21">_</governor>
          <dependent id="29">bias</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">doctors</governor>
          <dependent id="30">against</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">bias</governor>
          <dependent id="31">doctors</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">believe</governor>
          <dependent id="32">_</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="35">risk</governor>
          <dependent id="33">increases</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="35">risk</governor>
          <dependent id="34">their</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="32">_</governor>
          <dependent id="35">risk</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="37">acquiring</governor>
          <dependent id="36">of</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="35">risk</governor>
          <dependent id="37">acquiring</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="37">acquiring</governor>
          <dependent id="38">diabetes</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="diabetes" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="38" string="diabetes" />
          </tokens>
        </entity>
        <entity id="2" string="Hispanics" type="MISC" score="0.0">
          <tokens>
            <token id="5" string="Hispanics" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>The study is in its follow-up stage, to see if diagnosed diabetes patients have changed their lifestyle and have sought medical care.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="study" lemma="study" stem="studi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="follow-up" lemma="follow-up" stem="follow-up" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="stage" lemma="stage" stem="stage" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="see" lemma="see" stem="see" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="diagnosed" lemma="diagnose" stem="diagnos" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="diabetes" lemma="diabetes" stem="diabet" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="false" />
        <token id="14" string="patients" lemma="patient" stem="patient" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="changed" lemma="change" stem="chang" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="lifestyle" lemma="lifestyle" stem="lifestyl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="sought" lemma="seek" stem="sought" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="medical" lemma="medical" stem="medic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="care" lemma="care" stem="care" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN study)) (VP (VBZ is) (PP (IN in) (NP (PRP$ its) (JJ follow-up) (NN stage))) (, ,) (S (VP (TO to) (VP (VB see) (SBAR (IN if) (S (NP (VBN diagnosed) (NN diabetes) (NNS patients)) (VP (VP (VBP have) (VP (VBN changed) (NP (PRP$ their) (NN lifestyle)))) (CC and) (VP (VBP have) (VP (VBN sought) (NP (JJ medical) (NN care))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="to see if diagnosed diabetes patients have changed their lifestyle and have sought medical care" type="VP">
          <tokens>
            <token id="9" string="to" />
            <token id="10" string="see" />
            <token id="11" string="if" />
            <token id="12" string="diagnosed" />
            <token id="13" string="diabetes" />
            <token id="14" string="patients" />
            <token id="15" string="have" />
            <token id="16" string="changed" />
            <token id="17" string="their" />
            <token id="18" string="lifestyle" />
            <token id="19" string="and" />
            <token id="20" string="have" />
            <token id="21" string="sought" />
            <token id="22" string="medical" />
            <token id="23" string="care" />
          </tokens>
        </chunking>
        <chunking id="2" string="if diagnosed diabetes patients have changed their lifestyle and have sought medical care" type="SBAR">
          <tokens>
            <token id="11" string="if" />
            <token id="12" string="diagnosed" />
            <token id="13" string="diabetes" />
            <token id="14" string="patients" />
            <token id="15" string="have" />
            <token id="16" string="changed" />
            <token id="17" string="their" />
            <token id="18" string="lifestyle" />
            <token id="19" string="and" />
            <token id="20" string="have" />
            <token id="21" string="sought" />
            <token id="22" string="medical" />
            <token id="23" string="care" />
          </tokens>
        </chunking>
        <chunking id="3" string="changed their lifestyle" type="VP">
          <tokens>
            <token id="16" string="changed" />
            <token id="17" string="their" />
            <token id="18" string="lifestyle" />
          </tokens>
        </chunking>
        <chunking id="4" string="its follow-up stage" type="NP">
          <tokens>
            <token id="5" string="its" />
            <token id="6" string="follow-up" />
            <token id="7" string="stage" />
          </tokens>
        </chunking>
        <chunking id="5" string="diagnosed diabetes patients" type="NP">
          <tokens>
            <token id="12" string="diagnosed" />
            <token id="13" string="diabetes" />
            <token id="14" string="patients" />
          </tokens>
        </chunking>
        <chunking id="6" string="sought medical care" type="VP">
          <tokens>
            <token id="21" string="sought" />
            <token id="22" string="medical" />
            <token id="23" string="care" />
          </tokens>
        </chunking>
        <chunking id="7" string="medical care" type="NP">
          <tokens>
            <token id="22" string="medical" />
            <token id="23" string="care" />
          </tokens>
        </chunking>
        <chunking id="8" string="The study" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="study" />
          </tokens>
        </chunking>
        <chunking id="9" string="see if diagnosed diabetes patients have changed their lifestyle and have sought medical care" type="VP">
          <tokens>
            <token id="10" string="see" />
            <token id="11" string="if" />
            <token id="12" string="diagnosed" />
            <token id="13" string="diabetes" />
            <token id="14" string="patients" />
            <token id="15" string="have" />
            <token id="16" string="changed" />
            <token id="17" string="their" />
            <token id="18" string="lifestyle" />
            <token id="19" string="and" />
            <token id="20" string="have" />
            <token id="21" string="sought" />
            <token id="22" string="medical" />
            <token id="23" string="care" />
          </tokens>
        </chunking>
        <chunking id="10" string="is in its follow-up stage , to see if diagnosed diabetes patients have changed their lifestyle and have sought medical care" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="in" />
            <token id="5" string="its" />
            <token id="6" string="follow-up" />
            <token id="7" string="stage" />
            <token id="8" string="," />
            <token id="9" string="to" />
            <token id="10" string="see" />
            <token id="11" string="if" />
            <token id="12" string="diagnosed" />
            <token id="13" string="diabetes" />
            <token id="14" string="patients" />
            <token id="15" string="have" />
            <token id="16" string="changed" />
            <token id="17" string="their" />
            <token id="18" string="lifestyle" />
            <token id="19" string="and" />
            <token id="20" string="have" />
            <token id="21" string="sought" />
            <token id="22" string="medical" />
            <token id="23" string="care" />
          </tokens>
        </chunking>
        <chunking id="11" string="their lifestyle" type="NP">
          <tokens>
            <token id="17" string="their" />
            <token id="18" string="lifestyle" />
          </tokens>
        </chunking>
        <chunking id="12" string="have changed their lifestyle and have sought medical care" type="VP">
          <tokens>
            <token id="15" string="have" />
            <token id="16" string="changed" />
            <token id="17" string="their" />
            <token id="18" string="lifestyle" />
            <token id="19" string="and" />
            <token id="20" string="have" />
            <token id="21" string="sought" />
            <token id="22" string="medical" />
            <token id="23" string="care" />
          </tokens>
        </chunking>
        <chunking id="13" string="have changed their lifestyle" type="VP">
          <tokens>
            <token id="15" string="have" />
            <token id="16" string="changed" />
            <token id="17" string="their" />
            <token id="18" string="lifestyle" />
          </tokens>
        </chunking>
        <chunking id="14" string="have sought medical care" type="VP">
          <tokens>
            <token id="20" string="have" />
            <token id="21" string="sought" />
            <token id="22" string="medical" />
            <token id="23" string="care" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">study</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">stage</governor>
          <dependent id="2">study</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">stage</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">stage</governor>
          <dependent id="4">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">stage</governor>
          <dependent id="5">its</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">stage</governor>
          <dependent id="6">follow-up</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">stage</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">see</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">stage</governor>
          <dependent id="10">see</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">changed</governor>
          <dependent id="11">if</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">patients</governor>
          <dependent id="12">diagnosed</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">patients</governor>
          <dependent id="13">diabetes</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">changed</governor>
          <dependent id="14">patients</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">changed</governor>
          <dependent id="15">have</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="10">see</governor>
          <dependent id="16">changed</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="18">lifestyle</governor>
          <dependent id="17">their</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">changed</governor>
          <dependent id="18">lifestyle</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">changed</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">sought</governor>
          <dependent id="20">have</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">changed</governor>
          <dependent id="21">sought</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">care</governor>
          <dependent id="22">medical</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">sought</governor>
          <dependent id="23">care</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="diabetes" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="13" string="diabetes" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="28" has_coreference="true">
      <content>Teresa Castro, 54, whose diabetic husband died at age 37, went through the screening eight years ago.</content>
      <tokens>
        <token id="1" string="Teresa" lemma="Teresa" stem="teresa" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Castro" lemma="Castro" stem="castro" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="54" lemma="54" stem="54" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="whose" lemma="whose" stem="whose" pos="WP$" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="diabetic" lemma="diabetic" stem="diabet" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="husband" lemma="husband" stem="husband" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="died" lemma="die" stem="di" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="age" lemma="age" stem="ag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="37" lemma="37" stem="37" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="went" lemma="go" stem="went" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="screening" lemma="screening" stem="screen" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="18" string="eight" lemma="eight" stem="eight" pos="CD" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="19" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="20" string="ago" lemma="ago" stem="ago" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Teresa) (NNP Castro)) (, ,) (NP (CD 54)) (, ,) (SBAR (WHNP (WP$ whose) (ADJP (JJ diabetic)) (NN husband)) (S (VP (VBD died) (PP (IN at) (NP (NN age) (CD 37)))))) (, ,)) (VP (VBD went) (PP (IN through) (NP (NP (DT the) (NN screening)) (ADVP (NP (CD eight) (NNS years)) (RB ago))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="diabetic" type="ADJP">
          <tokens>
            <token id="7" string="diabetic" />
          </tokens>
        </chunking>
        <chunking id="2" string="the screening eight years ago" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="screening" />
            <token id="18" string="eight" />
            <token id="19" string="years" />
            <token id="20" string="ago" />
          </tokens>
        </chunking>
        <chunking id="3" string="the screening" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="screening" />
          </tokens>
        </chunking>
        <chunking id="4" string="Teresa Castro , 54 , whose diabetic husband died at age 37 ," type="NP">
          <tokens>
            <token id="1" string="Teresa" />
            <token id="2" string="Castro" />
            <token id="3" string="," />
            <token id="4" string="54" />
            <token id="5" string="," />
            <token id="6" string="whose" />
            <token id="7" string="diabetic" />
            <token id="8" string="husband" />
            <token id="9" string="died" />
            <token id="10" string="at" />
            <token id="11" string="age" />
            <token id="12" string="37" />
            <token id="13" string="," />
          </tokens>
        </chunking>
        <chunking id="5" string="Teresa Castro" type="NP">
          <tokens>
            <token id="1" string="Teresa" />
            <token id="2" string="Castro" />
          </tokens>
        </chunking>
        <chunking id="6" string="eight years" type="NP">
          <tokens>
            <token id="18" string="eight" />
            <token id="19" string="years" />
          </tokens>
        </chunking>
        <chunking id="7" string="whose diabetic husband died at age 37" type="SBAR">
          <tokens>
            <token id="6" string="whose" />
            <token id="7" string="diabetic" />
            <token id="8" string="husband" />
            <token id="9" string="died" />
            <token id="10" string="at" />
            <token id="11" string="age" />
            <token id="12" string="37" />
          </tokens>
        </chunking>
        <chunking id="8" string="age 37" type="NP">
          <tokens>
            <token id="11" string="age" />
            <token id="12" string="37" />
          </tokens>
        </chunking>
        <chunking id="9" string="died at age 37" type="VP">
          <tokens>
            <token id="9" string="died" />
            <token id="10" string="at" />
            <token id="11" string="age" />
            <token id="12" string="37" />
          </tokens>
        </chunking>
        <chunking id="10" string="54" type="NP">
          <tokens>
            <token id="4" string="54" />
          </tokens>
        </chunking>
        <chunking id="11" string="went through the screening eight years ago" type="VP">
          <tokens>
            <token id="14" string="went" />
            <token id="15" string="through" />
            <token id="16" string="the" />
            <token id="17" string="screening" />
            <token id="18" string="eight" />
            <token id="19" string="years" />
            <token id="20" string="ago" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Castro</governor>
          <dependent id="1">Teresa</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">went</governor>
          <dependent id="2">Castro</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="2">Castro</governor>
          <dependent id="4">54</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">husband</governor>
          <dependent id="6">whose</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">husband</governor>
          <dependent id="7">diabetic</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">died</governor>
          <dependent id="8">husband</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="2">Castro</governor>
          <dependent id="9">died</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">age</governor>
          <dependent id="10">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">died</governor>
          <dependent id="11">age</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="11">age</governor>
          <dependent id="12">37</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">went</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">screening</governor>
          <dependent id="15">through</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">screening</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">went</governor>
          <dependent id="17">screening</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="19">years</governor>
          <dependent id="18">eight</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="20">ago</governor>
          <dependent id="19">years</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">screening</governor>
          <dependent id="20">ago</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="screening eight years ago" type="DATE" score="0.0">
          <tokens>
            <token id="17" string="screening" />
            <token id="18" string="eight" />
            <token id="19" string="years" />
            <token id="20" string="ago" />
          </tokens>
        </entity>
        <entity id="2" string="37" type="NUMBER" score="0.0">
          <tokens>
            <token id="12" string="37" />
          </tokens>
        </entity>
        <entity id="3" string="Teresa Castro" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Teresa" />
            <token id="2" string="Castro" />
          </tokens>
        </entity>
        <entity id="4" string="54" type="NUMBER" score="0.0">
          <tokens>
            <token id="4" string="54" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="29" has_coreference="true">
      <content>She was told that because of her weight, 254 pounds, she had hypertension and was at risk of diabetes.</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="told" lemma="tell" stem="told" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="weight" lemma="weight" stem="weight" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="254" lemma="254" stem="254" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="11" string="pounds" lemma="pound" stem="pound" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="hypertension" lemma="hypertension" stem="hypertens" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="risk" lemma="risk" stem="risk" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="diabetes" lemma="diabetes" stem="diabet" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="true" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP She)) (VP (VBD was) (VP (VBN told) (SBAR (IN that) (IN because) (S (PP (IN of) (NP (NP (PRP$ her) (NN weight)) (, ,) (NP (CD 254) (NNS pounds)))) (, ,) (NP (PRP she)) (VP (VP (VBD had) (NP (NN hypertension))) (CC and) (VP (VBD was) (PP (IN at) (NP (NP (NN risk)) (PP (IN of) (NP (NN diabetes))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was at risk of diabetes" type="VP">
          <tokens>
            <token id="17" string="was" />
            <token id="18" string="at" />
            <token id="19" string="risk" />
            <token id="20" string="of" />
            <token id="21" string="diabetes" />
          </tokens>
        </chunking>
        <chunking id="2" string="told that because of her weight , 254 pounds , she had hypertension and was at risk of diabetes" type="VP">
          <tokens>
            <token id="3" string="told" />
            <token id="4" string="that" />
            <token id="5" string="because" />
            <token id="6" string="of" />
            <token id="7" string="her" />
            <token id="8" string="weight" />
            <token id="9" string="," />
            <token id="10" string="254" />
            <token id="11" string="pounds" />
            <token id="12" string="," />
            <token id="13" string="she" />
            <token id="14" string="had" />
            <token id="15" string="hypertension" />
            <token id="16" string="and" />
            <token id="17" string="was" />
            <token id="18" string="at" />
            <token id="19" string="risk" />
            <token id="20" string="of" />
            <token id="21" string="diabetes" />
          </tokens>
        </chunking>
        <chunking id="3" string="254 pounds" type="NP">
          <tokens>
            <token id="10" string="254" />
            <token id="11" string="pounds" />
          </tokens>
        </chunking>
        <chunking id="4" string="was told that because of her weight , 254 pounds , she had hypertension and was at risk of diabetes" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="told" />
            <token id="4" string="that" />
            <token id="5" string="because" />
            <token id="6" string="of" />
            <token id="7" string="her" />
            <token id="8" string="weight" />
            <token id="9" string="," />
            <token id="10" string="254" />
            <token id="11" string="pounds" />
            <token id="12" string="," />
            <token id="13" string="she" />
            <token id="14" string="had" />
            <token id="15" string="hypertension" />
            <token id="16" string="and" />
            <token id="17" string="was" />
            <token id="18" string="at" />
            <token id="19" string="risk" />
            <token id="20" string="of" />
            <token id="21" string="diabetes" />
          </tokens>
        </chunking>
        <chunking id="5" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
        <chunking id="6" string="she" type="NP">
          <tokens>
            <token id="13" string="she" />
          </tokens>
        </chunking>
        <chunking id="7" string="had hypertension and was at risk of diabetes" type="VP">
          <tokens>
            <token id="14" string="had" />
            <token id="15" string="hypertension" />
            <token id="16" string="and" />
            <token id="17" string="was" />
            <token id="18" string="at" />
            <token id="19" string="risk" />
            <token id="20" string="of" />
            <token id="21" string="diabetes" />
          </tokens>
        </chunking>
        <chunking id="8" string="her weight" type="NP">
          <tokens>
            <token id="7" string="her" />
            <token id="8" string="weight" />
          </tokens>
        </chunking>
        <chunking id="9" string="that because of her weight , 254 pounds , she had hypertension and was at risk of diabetes" type="SBAR">
          <tokens>
            <token id="4" string="that" />
            <token id="5" string="because" />
            <token id="6" string="of" />
            <token id="7" string="her" />
            <token id="8" string="weight" />
            <token id="9" string="," />
            <token id="10" string="254" />
            <token id="11" string="pounds" />
            <token id="12" string="," />
            <token id="13" string="she" />
            <token id="14" string="had" />
            <token id="15" string="hypertension" />
            <token id="16" string="and" />
            <token id="17" string="was" />
            <token id="18" string="at" />
            <token id="19" string="risk" />
            <token id="20" string="of" />
            <token id="21" string="diabetes" />
          </tokens>
        </chunking>
        <chunking id="10" string="risk" type="NP">
          <tokens>
            <token id="19" string="risk" />
          </tokens>
        </chunking>
        <chunking id="11" string="her weight , 254 pounds" type="NP">
          <tokens>
            <token id="7" string="her" />
            <token id="8" string="weight" />
            <token id="9" string="," />
            <token id="10" string="254" />
            <token id="11" string="pounds" />
          </tokens>
        </chunking>
        <chunking id="12" string="risk of diabetes" type="NP">
          <tokens>
            <token id="19" string="risk" />
            <token id="20" string="of" />
            <token id="21" string="diabetes" />
          </tokens>
        </chunking>
        <chunking id="13" string="diabetes" type="NP">
          <tokens>
            <token id="21" string="diabetes" />
          </tokens>
        </chunking>
        <chunking id="14" string="had hypertension" type="VP">
          <tokens>
            <token id="14" string="had" />
            <token id="15" string="hypertension" />
          </tokens>
        </chunking>
        <chunking id="15" string="hypertension" type="NP">
          <tokens>
            <token id="15" string="hypertension" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="3">told</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="3">told</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">told</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">had</governor>
          <dependent id="4">that</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">had</governor>
          <dependent id="5">because</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">weight</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">weight</governor>
          <dependent id="7">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">had</governor>
          <dependent id="8">weight</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="11">pounds</governor>
          <dependent id="10">254</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="8">weight</governor>
          <dependent id="11">pounds</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">had</governor>
          <dependent id="13">she</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">told</governor>
          <dependent id="14">had</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">had</governor>
          <dependent id="15">hypertension</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">had</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="19">risk</governor>
          <dependent id="17">was</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">risk</governor>
          <dependent id="18">at</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">had</governor>
          <dependent id="19">risk</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">diabetes</governor>
          <dependent id="20">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">risk</governor>
          <dependent id="21">diabetes</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="254" type="NUMBER" score="0.0">
          <tokens>
            <token id="10" string="254" />
          </tokens>
        </entity>
        <entity id="2" string="diabetes" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="21" string="diabetes" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="30" has_coreference="true">
      <content>Doctors put her on a strict, low-fat diet and she lost 26 pounds.</content>
      <tokens>
        <token id="1" string="Doctors" lemma="doctor" stem="doctor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="put" lemma="put" stem="put" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="strict" lemma="strict" stem="strict" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="low-fat" lemma="low-fat" stem="low-fat" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="diet" lemma="diet" stem="diet" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="lost" lemma="lose" stem="lost" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="26" lemma="26" stem="26" pos="CD" type="Number" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="14" string="pounds" lemma="pound" stem="pound" pos="NNS" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNS Doctors)) (VP (VBD put) (NP (PRP$ her)) (PP (IN on) (NP (DT a) (JJ strict) (, ,) (JJ low-fat) (NN diet))))) (CC and) (S (NP (PRP she)) (VP (VBD lost) (NP (CD 26) (NNS pounds)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="26 pounds" type="NP">
          <tokens>
            <token id="13" string="26" />
            <token id="14" string="pounds" />
          </tokens>
        </chunking>
        <chunking id="2" string="her" type="NP">
          <tokens>
            <token id="3" string="her" />
          </tokens>
        </chunking>
        <chunking id="3" string="lost 26 pounds" type="VP">
          <tokens>
            <token id="12" string="lost" />
            <token id="13" string="26" />
            <token id="14" string="pounds" />
          </tokens>
        </chunking>
        <chunking id="4" string="put her on a strict , low-fat diet" type="VP">
          <tokens>
            <token id="2" string="put" />
            <token id="3" string="her" />
            <token id="4" string="on" />
            <token id="5" string="a" />
            <token id="6" string="strict" />
            <token id="7" string="," />
            <token id="8" string="low-fat" />
            <token id="9" string="diet" />
          </tokens>
        </chunking>
        <chunking id="5" string="a strict , low-fat diet" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="strict" />
            <token id="7" string="," />
            <token id="8" string="low-fat" />
            <token id="9" string="diet" />
          </tokens>
        </chunking>
        <chunking id="6" string="Doctors" type="NP">
          <tokens>
            <token id="1" string="Doctors" />
          </tokens>
        </chunking>
        <chunking id="7" string="she" type="NP">
          <tokens>
            <token id="11" string="she" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">put</governor>
          <dependent id="1">Doctors</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">put</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">put</governor>
          <dependent id="3">her</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">diet</governor>
          <dependent id="4">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">diet</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">diet</governor>
          <dependent id="6">strict</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">diet</governor>
          <dependent id="8">low-fat</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">put</governor>
          <dependent id="9">diet</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">put</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">lost</governor>
          <dependent id="11">she</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">put</governor>
          <dependent id="12">lost</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="14">pounds</governor>
          <dependent id="13">26</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">lost</governor>
          <dependent id="14">pounds</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="26 pounds" type="MONEY" score="0.0">
          <tokens>
            <token id="13" string="26" />
            <token id="14" string="pounds" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="31" has_coreference="true">
      <content>``I went to the screening because they called and said it was free.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="went" lemma="go" stem="went" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="screening" lemma="screening" stem="screen" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="called" lemma="call" stem="call" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="free" lemma="free" stem="free" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (VBD went) (PP (TO to) (NP (DT the) (NN screening))) (SBAR (IN because) (S (NP (PRP they)) (VP (VP (VBD called)) (CC and) (VP (VBD said) (SBAR (S (NP (PRP it)) (VP (VBD was) (ADJP (JJ free)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="because they called and said it was free" type="SBAR">
          <tokens>
            <token id="7" string="because" />
            <token id="8" string="they" />
            <token id="9" string="called" />
            <token id="10" string="and" />
            <token id="11" string="said" />
            <token id="12" string="it" />
            <token id="13" string="was" />
            <token id="14" string="free" />
          </tokens>
        </chunking>
        <chunking id="2" string="the screening" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="screening" />
          </tokens>
        </chunking>
        <chunking id="3" string="they" type="NP">
          <tokens>
            <token id="8" string="they" />
          </tokens>
        </chunking>
        <chunking id="4" string="called and said it was free" type="VP">
          <tokens>
            <token id="9" string="called" />
            <token id="10" string="and" />
            <token id="11" string="said" />
            <token id="12" string="it" />
            <token id="13" string="was" />
            <token id="14" string="free" />
          </tokens>
        </chunking>
        <chunking id="5" string="called" type="VP">
          <tokens>
            <token id="9" string="called" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="12" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="was free" type="VP">
          <tokens>
            <token id="13" string="was" />
            <token id="14" string="free" />
          </tokens>
        </chunking>
        <chunking id="9" string="free" type="ADJP">
          <tokens>
            <token id="14" string="free" />
          </tokens>
        </chunking>
        <chunking id="10" string="it was free" type="SBAR">
          <tokens>
            <token id="12" string="it" />
            <token id="13" string="was" />
            <token id="14" string="free" />
          </tokens>
        </chunking>
        <chunking id="11" string="went to the screening because they called and said it was free" type="VP">
          <tokens>
            <token id="3" string="went" />
            <token id="4" string="to" />
            <token id="5" string="the" />
            <token id="6" string="screening" />
            <token id="7" string="because" />
            <token id="8" string="they" />
            <token id="9" string="called" />
            <token id="10" string="and" />
            <token id="11" string="said" />
            <token id="12" string="it" />
            <token id="13" string="was" />
            <token id="14" string="free" />
          </tokens>
        </chunking>
        <chunking id="12" string="said it was free" type="VP">
          <tokens>
            <token id="11" string="said" />
            <token id="12" string="it" />
            <token id="13" string="was" />
            <token id="14" string="free" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">went</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">went</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">screening</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">screening</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">went</governor>
          <dependent id="6">screening</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">called</governor>
          <dependent id="7">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">called</governor>
          <dependent id="8">they</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">went</governor>
          <dependent id="9">called</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">called</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">called</governor>
          <dependent id="11">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">free</governor>
          <dependent id="12">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">free</governor>
          <dependent id="13">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">said</governor>
          <dependent id="14">free</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="32" has_coreference="true">
      <content>That&amp;apost;s why I went to it, because being poor I couldn&amp;apost;t afford to go to the doctor for this type of checkup,&amp;apost;&amp;apost; she said.</content>
      <tokens>
        <token id="1" string="That" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="why" lemma="why" stem="why" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="went" lemma="go" stem="went" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="being" lemma="be" stem="be" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="poor" lemma="poor" stem="poor" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="afford" lemma="afford" stem="afford" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="go" lemma="go" stem="go" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="doctor" lemma="doctor" stem="doctor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="type" lemma="type" stem="type" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="checkup" lemma="checkup" stem="checkup" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="29" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT That)) (VP (VBZ 's) (SBAR (WHADVP (WRB why)) (S (NP (PRP I)) (VP (VBD went) (PP (TO to) (NP (PRP it))) (, ,) (PP (IN because) (S (VP (VBG being) (ADJP (JJ poor) (SBAR (S (NP (PRP I)) (VP (MD could) (RB n't) (VP (VB afford) (S (VP (TO to) (VP (VB go) (PP (TO to) (NP (NP (DT the) (NN doctor)) (PP (IN for) (NP (NP (DT this) (NN type)) (PP (IN of) (NP (NN checkup))))))))))))))))))))))) (, ,) ('' '') (NP (PRP she)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="That" type="NP">
          <tokens>
            <token id="1" string="That" />
          </tokens>
        </chunking>
        <chunking id="2" string="'s why I went to it , because being poor I could n't afford to go to the doctor for this type of checkup" type="VP">
          <tokens>
            <token id="2" string="'s" />
            <token id="3" string="why" />
            <token id="4" string="I" />
            <token id="5" string="went" />
            <token id="6" string="to" />
            <token id="7" string="it" />
            <token id="8" string="," />
            <token id="9" string="because" />
            <token id="10" string="being" />
            <token id="11" string="poor" />
            <token id="12" string="I" />
            <token id="13" string="could" />
            <token id="14" string="n't" />
            <token id="15" string="afford" />
            <token id="16" string="to" />
            <token id="17" string="go" />
            <token id="18" string="to" />
            <token id="19" string="the" />
            <token id="20" string="doctor" />
            <token id="21" string="for" />
            <token id="22" string="this" />
            <token id="23" string="type" />
            <token id="24" string="of" />
            <token id="25" string="checkup" />
          </tokens>
        </chunking>
        <chunking id="3" string="why I went to it , because being poor I could n't afford to go to the doctor for this type of checkup" type="SBAR">
          <tokens>
            <token id="3" string="why" />
            <token id="4" string="I" />
            <token id="5" string="went" />
            <token id="6" string="to" />
            <token id="7" string="it" />
            <token id="8" string="," />
            <token id="9" string="because" />
            <token id="10" string="being" />
            <token id="11" string="poor" />
            <token id="12" string="I" />
            <token id="13" string="could" />
            <token id="14" string="n't" />
            <token id="15" string="afford" />
            <token id="16" string="to" />
            <token id="17" string="go" />
            <token id="18" string="to" />
            <token id="19" string="the" />
            <token id="20" string="doctor" />
            <token id="21" string="for" />
            <token id="22" string="this" />
            <token id="23" string="type" />
            <token id="24" string="of" />
            <token id="25" string="checkup" />
          </tokens>
        </chunking>
        <chunking id="4" string="why" type="WHADVP">
          <tokens>
            <token id="3" string="why" />
          </tokens>
        </chunking>
        <chunking id="5" string="went to it , because being poor I could n't afford to go to the doctor for this type of checkup" type="VP">
          <tokens>
            <token id="5" string="went" />
            <token id="6" string="to" />
            <token id="7" string="it" />
            <token id="8" string="," />
            <token id="9" string="because" />
            <token id="10" string="being" />
            <token id="11" string="poor" />
            <token id="12" string="I" />
            <token id="13" string="could" />
            <token id="14" string="n't" />
            <token id="15" string="afford" />
            <token id="16" string="to" />
            <token id="17" string="go" />
            <token id="18" string="to" />
            <token id="19" string="the" />
            <token id="20" string="doctor" />
            <token id="21" string="for" />
            <token id="22" string="this" />
            <token id="23" string="type" />
            <token id="24" string="of" />
            <token id="25" string="checkup" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="4" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="7" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="afford to go to the doctor for this type of checkup" type="VP">
          <tokens>
            <token id="15" string="afford" />
            <token id="16" string="to" />
            <token id="17" string="go" />
            <token id="18" string="to" />
            <token id="19" string="the" />
            <token id="20" string="doctor" />
            <token id="21" string="for" />
            <token id="22" string="this" />
            <token id="23" string="type" />
            <token id="24" string="of" />
            <token id="25" string="checkup" />
          </tokens>
        </chunking>
        <chunking id="9" string="she" type="NP">
          <tokens>
            <token id="28" string="she" />
          </tokens>
        </chunking>
        <chunking id="10" string="the doctor" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="doctor" />
          </tokens>
        </chunking>
        <chunking id="11" string="poor I could n't afford to go to the doctor for this type of checkup" type="ADJP">
          <tokens>
            <token id="11" string="poor" />
            <token id="12" string="I" />
            <token id="13" string="could" />
            <token id="14" string="n't" />
            <token id="15" string="afford" />
            <token id="16" string="to" />
            <token id="17" string="go" />
            <token id="18" string="to" />
            <token id="19" string="the" />
            <token id="20" string="doctor" />
            <token id="21" string="for" />
            <token id="22" string="this" />
            <token id="23" string="type" />
            <token id="24" string="of" />
            <token id="25" string="checkup" />
          </tokens>
        </chunking>
        <chunking id="12" string="this type of checkup" type="NP">
          <tokens>
            <token id="22" string="this" />
            <token id="23" string="type" />
            <token id="24" string="of" />
            <token id="25" string="checkup" />
          </tokens>
        </chunking>
        <chunking id="13" string="I could n't afford to go to the doctor for this type of checkup" type="SBAR">
          <tokens>
            <token id="12" string="I" />
            <token id="13" string="could" />
            <token id="14" string="n't" />
            <token id="15" string="afford" />
            <token id="16" string="to" />
            <token id="17" string="go" />
            <token id="18" string="to" />
            <token id="19" string="the" />
            <token id="20" string="doctor" />
            <token id="21" string="for" />
            <token id="22" string="this" />
            <token id="23" string="type" />
            <token id="24" string="of" />
            <token id="25" string="checkup" />
          </tokens>
        </chunking>
        <chunking id="14" string="this type" type="NP">
          <tokens>
            <token id="22" string="this" />
            <token id="23" string="type" />
          </tokens>
        </chunking>
        <chunking id="15" string="the doctor for this type of checkup" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="doctor" />
            <token id="21" string="for" />
            <token id="22" string="this" />
            <token id="23" string="type" />
            <token id="24" string="of" />
            <token id="25" string="checkup" />
          </tokens>
        </chunking>
        <chunking id="16" string="being poor I could n't afford to go to the doctor for this type of checkup" type="VP">
          <tokens>
            <token id="10" string="being" />
            <token id="11" string="poor" />
            <token id="12" string="I" />
            <token id="13" string="could" />
            <token id="14" string="n't" />
            <token id="15" string="afford" />
            <token id="16" string="to" />
            <token id="17" string="go" />
            <token id="18" string="to" />
            <token id="19" string="the" />
            <token id="20" string="doctor" />
            <token id="21" string="for" />
            <token id="22" string="this" />
            <token id="23" string="type" />
            <token id="24" string="of" />
            <token id="25" string="checkup" />
          </tokens>
        </chunking>
        <chunking id="17" string="checkup" type="NP">
          <tokens>
            <token id="25" string="checkup" />
          </tokens>
        </chunking>
        <chunking id="18" string="could n't afford to go to the doctor for this type of checkup" type="VP">
          <tokens>
            <token id="13" string="could" />
            <token id="14" string="n't" />
            <token id="15" string="afford" />
            <token id="16" string="to" />
            <token id="17" string="go" />
            <token id="18" string="to" />
            <token id="19" string="the" />
            <token id="20" string="doctor" />
            <token id="21" string="for" />
            <token id="22" string="this" />
            <token id="23" string="type" />
            <token id="24" string="of" />
            <token id="25" string="checkup" />
          </tokens>
        </chunking>
        <chunking id="19" string="to go to the doctor for this type of checkup" type="VP">
          <tokens>
            <token id="16" string="to" />
            <token id="17" string="go" />
            <token id="18" string="to" />
            <token id="19" string="the" />
            <token id="20" string="doctor" />
            <token id="21" string="for" />
            <token id="22" string="this" />
            <token id="23" string="type" />
            <token id="24" string="of" />
            <token id="25" string="checkup" />
          </tokens>
        </chunking>
        <chunking id="20" string="go to the doctor for this type of checkup" type="VP">
          <tokens>
            <token id="17" string="go" />
            <token id="18" string="to" />
            <token id="19" string="the" />
            <token id="20" string="doctor" />
            <token id="21" string="for" />
            <token id="22" string="this" />
            <token id="23" string="type" />
            <token id="24" string="of" />
            <token id="25" string="checkup" />
          </tokens>
        </chunking>
        <chunking id="21" string="said" type="VP">
          <tokens>
            <token id="29" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">'s</governor>
          <dependent id="1">That</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="29">said</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">went</governor>
          <dependent id="3">why</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">went</governor>
          <dependent id="4">I</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="2">'s</governor>
          <dependent id="5">went</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">it</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">went</governor>
          <dependent id="7">it</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">poor</governor>
          <dependent id="9">because</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">poor</governor>
          <dependent id="10">being</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">went</governor>
          <dependent id="11">poor</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">afford</governor>
          <dependent id="12">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">afford</governor>
          <dependent id="13">could</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="15">afford</governor>
          <dependent id="14">n't</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">poor</governor>
          <dependent id="15">afford</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">go</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="15">afford</governor>
          <dependent id="17">go</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">doctor</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">doctor</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">go</governor>
          <dependent id="20">doctor</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">type</governor>
          <dependent id="21">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">type</governor>
          <dependent id="22">this</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">doctor</governor>
          <dependent id="23">type</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">checkup</governor>
          <dependent id="24">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">type</governor>
          <dependent id="25">checkup</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">said</governor>
          <dependent id="28">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="29">said</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="33" has_coreference="true">
      <content>``My mother has diabetes and they tell me I might have diabetes, too, but I don&amp;apost;t know too much about it.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="My" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="mother" lemma="mother" stem="mother" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="diabetes" lemma="diabetes" stem="diabet" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="6" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="tell" lemma="tell" stem="tell" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="might" lemma="might" stem="might" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="diabetes" lemma="diabetes" stem="diabet" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="too" lemma="too" stem="too" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="know" lemma="know" stem="know" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="too" lemma="too" stem="too" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="much" lemma="much" stem="much" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP$ My) (NN mother)) (VP (VBZ has) (NP (NN diabetes)))) (CC and) (S (NP (PRP they)) (VP (VBP tell) (NP (PRP me)) (SBAR (S (NP (PRP I)) (VP (MD might) (VP (VB have) (NP (NN diabetes)) (, ,) (ADVP (RB too))))) (, ,) (CC but) (S (NP (PRP I)) (VP (VBP do) (RB n't) (VP (VB know) (ADJP (RB too) (JJ much)) (PP (IN about) (NP (PRP it))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="too much" type="ADJP">
          <tokens>
            <token id="22" string="too" />
            <token id="23" string="much" />
          </tokens>
        </chunking>
        <chunking id="2" string="I" type="NP">
          <tokens>
            <token id="10" string="I" />
          </tokens>
        </chunking>
        <chunking id="3" string="do n't know too much about it" type="VP">
          <tokens>
            <token id="19" string="do" />
            <token id="20" string="n't" />
            <token id="21" string="know" />
            <token id="22" string="too" />
            <token id="23" string="much" />
            <token id="24" string="about" />
            <token id="25" string="it" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="25" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="My mother" type="NP">
          <tokens>
            <token id="2" string="My" />
            <token id="3" string="mother" />
          </tokens>
        </chunking>
        <chunking id="6" string="tell me I might have diabetes , too , but I do n't know too much about it" type="VP">
          <tokens>
            <token id="8" string="tell" />
            <token id="9" string="me" />
            <token id="10" string="I" />
            <token id="11" string="might" />
            <token id="12" string="have" />
            <token id="13" string="diabetes" />
            <token id="14" string="," />
            <token id="15" string="too" />
            <token id="16" string="," />
            <token id="17" string="but" />
            <token id="18" string="I" />
            <token id="19" string="do" />
            <token id="20" string="n't" />
            <token id="21" string="know" />
            <token id="22" string="too" />
            <token id="23" string="much" />
            <token id="24" string="about" />
            <token id="25" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="have diabetes , too" type="VP">
          <tokens>
            <token id="12" string="have" />
            <token id="13" string="diabetes" />
            <token id="14" string="," />
            <token id="15" string="too" />
          </tokens>
        </chunking>
        <chunking id="8" string="know too much about it" type="VP">
          <tokens>
            <token id="21" string="know" />
            <token id="22" string="too" />
            <token id="23" string="much" />
            <token id="24" string="about" />
            <token id="25" string="it" />
          </tokens>
        </chunking>
        <chunking id="9" string="might have diabetes , too" type="VP">
          <tokens>
            <token id="11" string="might" />
            <token id="12" string="have" />
            <token id="13" string="diabetes" />
            <token id="14" string="," />
            <token id="15" string="too" />
          </tokens>
        </chunking>
        <chunking id="10" string="they" type="NP">
          <tokens>
            <token id="7" string="they" />
          </tokens>
        </chunking>
        <chunking id="11" string="has diabetes" type="VP">
          <tokens>
            <token id="4" string="has" />
            <token id="5" string="diabetes" />
          </tokens>
        </chunking>
        <chunking id="12" string="me" type="NP">
          <tokens>
            <token id="9" string="me" />
          </tokens>
        </chunking>
        <chunking id="13" string="diabetes" type="NP">
          <tokens>
            <token id="5" string="diabetes" />
          </tokens>
        </chunking>
        <chunking id="14" string="I might have diabetes , too , but I do n't know too much about it" type="SBAR">
          <tokens>
            <token id="10" string="I" />
            <token id="11" string="might" />
            <token id="12" string="have" />
            <token id="13" string="diabetes" />
            <token id="14" string="," />
            <token id="15" string="too" />
            <token id="16" string="," />
            <token id="17" string="but" />
            <token id="18" string="I" />
            <token id="19" string="do" />
            <token id="20" string="n't" />
            <token id="21" string="know" />
            <token id="22" string="too" />
            <token id="23" string="much" />
            <token id="24" string="about" />
            <token id="25" string="it" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="3">mother</governor>
          <dependent id="2">My</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">has</governor>
          <dependent id="3">mother</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">has</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">has</governor>
          <dependent id="5">diabetes</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">has</governor>
          <dependent id="6">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">tell</governor>
          <dependent id="7">they</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">has</governor>
          <dependent id="8">tell</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">tell</governor>
          <dependent id="9">me</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">have</governor>
          <dependent id="10">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">have</governor>
          <dependent id="11">might</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">tell</governor>
          <dependent id="12">have</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">have</governor>
          <dependent id="13">diabetes</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">have</governor>
          <dependent id="15">too</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">have</governor>
          <dependent id="17">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">know</governor>
          <dependent id="18">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">know</governor>
          <dependent id="19">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="21">know</governor>
          <dependent id="20">n't</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">have</governor>
          <dependent id="21">know</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="23">much</governor>
          <dependent id="22">too</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="21">know</governor>
          <dependent id="23">much</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">it</governor>
          <dependent id="24">about</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">know</governor>
          <dependent id="25">it</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="diabetes" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="5" string="diabetes" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="34" has_coreference="true">
      <content>``I feel OK, but they tell me that one year you can be OK and the next year, it can be totally different.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="feel" lemma="feel" stem="feel" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="OK" lemma="ok" stem="ok" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="tell" lemma="tell" stem="tell" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="12" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="13" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="OK" lemma="ok" stem="ok" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="19" string="next" lemma="next" stem="next" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="20" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="totally" lemma="totally" stem="total" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="different" lemma="different" stem="differ" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP I)) (VP (VBP feel) (ADJP (JJ OK)))) (, ,) (CC but) (S (NP (PRP they)) (VP (VBP tell) (NP (PRP me)) (SBAR (IN that) (S (S (NP-TMP (CD one) (NN year)) (NP (PRP you)) (VP (MD can) (VP (VB be) (ADJP (JJ OK))))) (CC and) (S (NP-TMP (DT the) (JJ next) (NN year)) (, ,) (NP (PRP it)) (VP (MD can) (VP (VB be) (ADJP (RB totally) (JJ different))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="feel OK" type="VP">
          <tokens>
            <token id="3" string="feel" />
            <token id="4" string="OK" />
          </tokens>
        </chunking>
        <chunking id="2" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="3" string="can be totally different" type="VP">
          <tokens>
            <token id="23" string="can" />
            <token id="24" string="be" />
            <token id="25" string="totally" />
            <token id="26" string="different" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="22" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="be OK" type="VP">
          <tokens>
            <token id="15" string="be" />
            <token id="16" string="OK" />
          </tokens>
        </chunking>
        <chunking id="6" string="can be OK" type="VP">
          <tokens>
            <token id="14" string="can" />
            <token id="15" string="be" />
            <token id="16" string="OK" />
          </tokens>
        </chunking>
        <chunking id="7" string="that one year you can be OK and the next year , it can be totally different" type="SBAR">
          <tokens>
            <token id="10" string="that" />
            <token id="11" string="one" />
            <token id="12" string="year" />
            <token id="13" string="you" />
            <token id="14" string="can" />
            <token id="15" string="be" />
            <token id="16" string="OK" />
            <token id="17" string="and" />
            <token id="18" string="the" />
            <token id="19" string="next" />
            <token id="20" string="year" />
            <token id="21" string="," />
            <token id="22" string="it" />
            <token id="23" string="can" />
            <token id="24" string="be" />
            <token id="25" string="totally" />
            <token id="26" string="different" />
          </tokens>
        </chunking>
        <chunking id="8" string="they" type="NP">
          <tokens>
            <token id="7" string="they" />
          </tokens>
        </chunking>
        <chunking id="9" string="be totally different" type="VP">
          <tokens>
            <token id="24" string="be" />
            <token id="25" string="totally" />
            <token id="26" string="different" />
          </tokens>
        </chunking>
        <chunking id="10" string="me" type="NP">
          <tokens>
            <token id="9" string="me" />
          </tokens>
        </chunking>
        <chunking id="11" string="totally different" type="ADJP">
          <tokens>
            <token id="25" string="totally" />
            <token id="26" string="different" />
          </tokens>
        </chunking>
        <chunking id="12" string="OK" type="ADJP">
          <tokens>
            <token id="4" string="OK" />
          </tokens>
        </chunking>
        <chunking id="13" string="tell me that one year you can be OK and the next year , it can be totally different" type="VP">
          <tokens>
            <token id="8" string="tell" />
            <token id="9" string="me" />
            <token id="10" string="that" />
            <token id="11" string="one" />
            <token id="12" string="year" />
            <token id="13" string="you" />
            <token id="14" string="can" />
            <token id="15" string="be" />
            <token id="16" string="OK" />
            <token id="17" string="and" />
            <token id="18" string="the" />
            <token id="19" string="next" />
            <token id="20" string="year" />
            <token id="21" string="," />
            <token id="22" string="it" />
            <token id="23" string="can" />
            <token id="24" string="be" />
            <token id="25" string="totally" />
            <token id="26" string="different" />
          </tokens>
        </chunking>
        <chunking id="14" string="you" type="NP">
          <tokens>
            <token id="13" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">feel</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">feel</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">feel</governor>
          <dependent id="4">OK</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">feel</governor>
          <dependent id="6">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">tell</governor>
          <dependent id="7">they</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">feel</governor>
          <dependent id="8">tell</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">tell</governor>
          <dependent id="9">me</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">OK</governor>
          <dependent id="10">that</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="12">year</governor>
          <dependent id="11">one</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="16">OK</governor>
          <dependent id="12">year</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">OK</governor>
          <dependent id="13">you</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">OK</governor>
          <dependent id="14">can</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="16">OK</governor>
          <dependent id="15">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">tell</governor>
          <dependent id="16">OK</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">OK</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">year</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">year</governor>
          <dependent id="19">next</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="26">different</governor>
          <dependent id="20">year</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">different</governor>
          <dependent id="22">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="26">different</governor>
          <dependent id="23">can</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="26">different</governor>
          <dependent id="24">be</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="26">different</governor>
          <dependent id="25">totally</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">OK</governor>
          <dependent id="26">different</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="the next year" type="DATE" score="0.0">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="next" />
            <token id="20" string="year" />
          </tokens>
        </entity>
        <entity id="2" string="one year" type="DURATION" score="0.0">
          <tokens>
            <token id="11" string="one" />
            <token id="12" string="year" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="35" has_coreference="true">
      <content>DeFronzo, who in 1988 was chosen the top diabetes investigator by Canadian and Japanese diabetes associations, says his unit at the Health Science Center will try to use many of Stern&amp;apost;s patients for research.</content>
      <tokens>
        <token id="1" string="DeFronzo" lemma="DeFronzo" stem="defronzo" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="1988" lemma="1988" stem="1988" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="6" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="chosen" lemma="choose" stem="chosen" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="top" lemma="top" stem="top" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="diabetes" lemma="diabetes" stem="diabet" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="11" string="investigator" lemma="investigator" stem="investig" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Canadian" lemma="canadian" stem="canadian" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Japanese" lemma="japanese" stem="japanes" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="16" string="diabetes" lemma="diabetes" stem="diabet" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="17" string="associations" lemma="association" stem="associ" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="unit" lemma="unit" stem="unit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="Health" lemma="Health" stem="health" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="25" string="Science" lemma="Science" stem="scienc" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="26" string="Center" lemma="Center" stem="center" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="27" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="try" lemma="try" stem="try" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="use" lemma="use" stem="us" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="33" string="Stern" lemma="Stern" stem="stern" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="34" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="35" string="patients" lemma="patient" stem="patient" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="36" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="research" lemma="research" stem="research" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP DeFronzo)) (, ,) (SBAR (WHNP (WP who)) (S (PP (IN in) (NP (CD 1988))) (VP (VBD was) (VP (VBN chosen) (NP (DT the) (JJ top) (NN diabetes) (NN investigator)) (PP (IN by) (NP (JJ Canadian) (CC and) (JJ Japanese) (NN diabetes) (NNS associations))))))) (, ,)) (VP (VBZ says) (SBAR (S (NP (NP (PRP$ his) (NN unit)) (PP (IN at) (NP (DT the) (NNP Health) (NNP Science) (NNP Center)))) (VP (MD will) (VP (VB try) (S (VP (TO to) (VP (VB use) (NP (NP (JJ many)) (PP (IN of) (NP (NP (NNP Stern) (POS 's)) (NNS patients)))) (PP (IN for) (NP (NN research))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="who in 1988 was chosen the top diabetes investigator by Canadian and Japanese diabetes associations" type="SBAR">
          <tokens>
            <token id="3" string="who" />
            <token id="4" string="in" />
            <token id="5" string="1988" />
            <token id="6" string="was" />
            <token id="7" string="chosen" />
            <token id="8" string="the" />
            <token id="9" string="top" />
            <token id="10" string="diabetes" />
            <token id="11" string="investigator" />
            <token id="12" string="by" />
            <token id="13" string="Canadian" />
            <token id="14" string="and" />
            <token id="15" string="Japanese" />
            <token id="16" string="diabetes" />
            <token id="17" string="associations" />
          </tokens>
        </chunking>
        <chunking id="2" string="was chosen the top diabetes investigator by Canadian and Japanese diabetes associations" type="VP">
          <tokens>
            <token id="6" string="was" />
            <token id="7" string="chosen" />
            <token id="8" string="the" />
            <token id="9" string="top" />
            <token id="10" string="diabetes" />
            <token id="11" string="investigator" />
            <token id="12" string="by" />
            <token id="13" string="Canadian" />
            <token id="14" string="and" />
            <token id="15" string="Japanese" />
            <token id="16" string="diabetes" />
            <token id="17" string="associations" />
          </tokens>
        </chunking>
        <chunking id="3" string="use many of Stern 's patients for research" type="VP">
          <tokens>
            <token id="30" string="use" />
            <token id="31" string="many" />
            <token id="32" string="of" />
            <token id="33" string="Stern" />
            <token id="34" string="'s" />
            <token id="35" string="patients" />
            <token id="36" string="for" />
            <token id="37" string="research" />
          </tokens>
        </chunking>
        <chunking id="4" string="his unit at the Health Science Center" type="NP">
          <tokens>
            <token id="20" string="his" />
            <token id="21" string="unit" />
            <token id="22" string="at" />
            <token id="23" string="the" />
            <token id="24" string="Health" />
            <token id="25" string="Science" />
            <token id="26" string="Center" />
          </tokens>
        </chunking>
        <chunking id="5" string="his unit at the Health Science Center will try to use many of Stern 's patients for research" type="SBAR">
          <tokens>
            <token id="20" string="his" />
            <token id="21" string="unit" />
            <token id="22" string="at" />
            <token id="23" string="the" />
            <token id="24" string="Health" />
            <token id="25" string="Science" />
            <token id="26" string="Center" />
            <token id="27" string="will" />
            <token id="28" string="try" />
            <token id="29" string="to" />
            <token id="30" string="use" />
            <token id="31" string="many" />
            <token id="32" string="of" />
            <token id="33" string="Stern" />
            <token id="34" string="'s" />
            <token id="35" string="patients" />
            <token id="36" string="for" />
            <token id="37" string="research" />
          </tokens>
        </chunking>
        <chunking id="6" string="many" type="NP">
          <tokens>
            <token id="31" string="many" />
          </tokens>
        </chunking>
        <chunking id="7" string="Stern 's" type="NP">
          <tokens>
            <token id="33" string="Stern" />
            <token id="34" string="'s" />
          </tokens>
        </chunking>
        <chunking id="8" string="his unit" type="NP">
          <tokens>
            <token id="20" string="his" />
            <token id="21" string="unit" />
          </tokens>
        </chunking>
        <chunking id="9" string="try to use many of Stern 's patients for research" type="VP">
          <tokens>
            <token id="28" string="try" />
            <token id="29" string="to" />
            <token id="30" string="use" />
            <token id="31" string="many" />
            <token id="32" string="of" />
            <token id="33" string="Stern" />
            <token id="34" string="'s" />
            <token id="35" string="patients" />
            <token id="36" string="for" />
            <token id="37" string="research" />
          </tokens>
        </chunking>
        <chunking id="10" string="to use many of Stern 's patients for research" type="VP">
          <tokens>
            <token id="29" string="to" />
            <token id="30" string="use" />
            <token id="31" string="many" />
            <token id="32" string="of" />
            <token id="33" string="Stern" />
            <token id="34" string="'s" />
            <token id="35" string="patients" />
            <token id="36" string="for" />
            <token id="37" string="research" />
          </tokens>
        </chunking>
        <chunking id="11" string="Stern 's patients" type="NP">
          <tokens>
            <token id="33" string="Stern" />
            <token id="34" string="'s" />
            <token id="35" string="patients" />
          </tokens>
        </chunking>
        <chunking id="12" string="research" type="NP">
          <tokens>
            <token id="37" string="research" />
          </tokens>
        </chunking>
        <chunking id="13" string="DeFronzo , who in 1988 was chosen the top diabetes investigator by Canadian and Japanese diabetes associations ," type="NP">
          <tokens>
            <token id="1" string="DeFronzo" />
            <token id="2" string="," />
            <token id="3" string="who" />
            <token id="4" string="in" />
            <token id="5" string="1988" />
            <token id="6" string="was" />
            <token id="7" string="chosen" />
            <token id="8" string="the" />
            <token id="9" string="top" />
            <token id="10" string="diabetes" />
            <token id="11" string="investigator" />
            <token id="12" string="by" />
            <token id="13" string="Canadian" />
            <token id="14" string="and" />
            <token id="15" string="Japanese" />
            <token id="16" string="diabetes" />
            <token id="17" string="associations" />
            <token id="18" string="," />
          </tokens>
        </chunking>
        <chunking id="14" string="1988" type="NP">
          <tokens>
            <token id="5" string="1988" />
          </tokens>
        </chunking>
        <chunking id="15" string="the Health Science Center" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="Health" />
            <token id="25" string="Science" />
            <token id="26" string="Center" />
          </tokens>
        </chunking>
        <chunking id="16" string="DeFronzo" type="NP">
          <tokens>
            <token id="1" string="DeFronzo" />
          </tokens>
        </chunking>
        <chunking id="17" string="says his unit at the Health Science Center will try to use many of Stern 's patients for research" type="VP">
          <tokens>
            <token id="19" string="says" />
            <token id="20" string="his" />
            <token id="21" string="unit" />
            <token id="22" string="at" />
            <token id="23" string="the" />
            <token id="24" string="Health" />
            <token id="25" string="Science" />
            <token id="26" string="Center" />
            <token id="27" string="will" />
            <token id="28" string="try" />
            <token id="29" string="to" />
            <token id="30" string="use" />
            <token id="31" string="many" />
            <token id="32" string="of" />
            <token id="33" string="Stern" />
            <token id="34" string="'s" />
            <token id="35" string="patients" />
            <token id="36" string="for" />
            <token id="37" string="research" />
          </tokens>
        </chunking>
        <chunking id="18" string="the top diabetes investigator" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="top" />
            <token id="10" string="diabetes" />
            <token id="11" string="investigator" />
          </tokens>
        </chunking>
        <chunking id="19" string="Canadian and Japanese diabetes associations" type="NP">
          <tokens>
            <token id="13" string="Canadian" />
            <token id="14" string="and" />
            <token id="15" string="Japanese" />
            <token id="16" string="diabetes" />
            <token id="17" string="associations" />
          </tokens>
        </chunking>
        <chunking id="20" string="chosen the top diabetes investigator by Canadian and Japanese diabetes associations" type="VP">
          <tokens>
            <token id="7" string="chosen" />
            <token id="8" string="the" />
            <token id="9" string="top" />
            <token id="10" string="diabetes" />
            <token id="11" string="investigator" />
            <token id="12" string="by" />
            <token id="13" string="Canadian" />
            <token id="14" string="and" />
            <token id="15" string="Japanese" />
            <token id="16" string="diabetes" />
            <token id="17" string="associations" />
          </tokens>
        </chunking>
        <chunking id="21" string="will try to use many of Stern 's patients for research" type="VP">
          <tokens>
            <token id="27" string="will" />
            <token id="28" string="try" />
            <token id="29" string="to" />
            <token id="30" string="use" />
            <token id="31" string="many" />
            <token id="32" string="of" />
            <token id="33" string="Stern" />
            <token id="34" string="'s" />
            <token id="35" string="patients" />
            <token id="36" string="for" />
            <token id="37" string="research" />
          </tokens>
        </chunking>
        <chunking id="22" string="many of Stern 's patients" type="NP">
          <tokens>
            <token id="31" string="many" />
            <token id="32" string="of" />
            <token id="33" string="Stern" />
            <token id="34" string="'s" />
            <token id="35" string="patients" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="19">says</governor>
          <dependent id="1">DeFronzo</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="7">chosen</governor>
          <dependent id="3">who</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">1988</governor>
          <dependent id="4">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">chosen</governor>
          <dependent id="5">1988</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="7">chosen</governor>
          <dependent id="6">was</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="1">DeFronzo</governor>
          <dependent id="7">chosen</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">investigator</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">investigator</governor>
          <dependent id="9">top</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">investigator</governor>
          <dependent id="10">diabetes</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">chosen</governor>
          <dependent id="11">investigator</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">associations</governor>
          <dependent id="12">by</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">associations</governor>
          <dependent id="13">Canadian</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">Canadian</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">Canadian</governor>
          <dependent id="15">Japanese</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">associations</governor>
          <dependent id="16">diabetes</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">chosen</governor>
          <dependent id="17">associations</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="19">says</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="21">unit</governor>
          <dependent id="20">his</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">try</governor>
          <dependent id="21">unit</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">Center</governor>
          <dependent id="22">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">Center</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">Center</governor>
          <dependent id="24">Health</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">Center</governor>
          <dependent id="25">Science</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">unit</governor>
          <dependent id="26">Center</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="28">try</governor>
          <dependent id="27">will</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">says</governor>
          <dependent id="28">try</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="30">use</governor>
          <dependent id="29">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="28">try</governor>
          <dependent id="30">use</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="30">use</governor>
          <dependent id="31">many</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">patients</governor>
          <dependent id="32">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="35">patients</governor>
          <dependent id="33">Stern</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">Stern</governor>
          <dependent id="34">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">many</governor>
          <dependent id="35">patients</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">research</governor>
          <dependent id="36">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">use</governor>
          <dependent id="37">research</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1988" type="DATE" score="0.0">
          <tokens>
            <token id="5" string="1988" />
          </tokens>
        </entity>
        <entity id="2" string="DeFronzo" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="DeFronzo" />
          </tokens>
        </entity>
        <entity id="3" string="Health Science Center" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="24" string="Health" />
            <token id="25" string="Science" />
            <token id="26" string="Center" />
          </tokens>
        </entity>
        <entity id="4" string="Canadian" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="13" string="Canadian" />
          </tokens>
        </entity>
        <entity id="5" string="Stern" type="PERSON" score="0.0">
          <tokens>
            <token id="33" string="Stern" />
          </tokens>
        </entity>
        <entity id="6" string="diabetes" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="10" string="diabetes" />
          </tokens>
        </entity>
        <entity id="7" string="Japanese" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="15" string="Japanese" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="36" has_coreference="true">
      <content>That will include work for Lipha Chemicals, which makes an anti-diabetic drug called metaforim that improves the body&amp;apost;s ability to respond to insulin.</content>
      <tokens>
        <token id="1" string="That" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="include" lemma="include" stem="includ" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="work" lemma="work" stem="work" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Lipha" lemma="Lipha" stem="lipha" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="7" string="Chemicals" lemma="Chemicals" stem="chemic" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="makes" lemma="make" stem="make" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="anti-diabetic" lemma="anti-diabetic" stem="anti-diabet" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="drug" lemma="drug" stem="drug" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="called" lemma="call" stem="call" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="metaforim" lemma="metaforim" stem="metaforim" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="improves" lemma="improve" stem="improv" pos="VBZ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="19" string="body" lemma="body" stem="bodi" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="20" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="21" string="ability" lemma="ability" stem="abil" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="respond" lemma="respond" stem="respond" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="insulin" lemma="insulin" stem="insulin" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT That)) (VP (MD will) (VP (VB include) (NP (NN work)) (PP (IN for) (NP (NP (NNP Lipha) (NNP Chemicals)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ makes) (NP (NP (DT an) (JJ anti-diabetic) (NN drug)) (VP (VBN called) (NP (NP (NN metaforim)) (SBAR (WHNP (WDT that)) (S (VP (VBZ improves) (NP (NP (DT the) (NN body) (POS 's)) (NN ability) (S (VP (TO to) (VP (VB respond) (PP (TO to) (NP (NN insulin)))))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="That" type="NP">
          <tokens>
            <token id="1" string="That" />
          </tokens>
        </chunking>
        <chunking id="2" string="Lipha Chemicals , which makes an anti-diabetic drug called metaforim that improves the body 's ability to respond to insulin" type="NP">
          <tokens>
            <token id="6" string="Lipha" />
            <token id="7" string="Chemicals" />
            <token id="8" string="," />
            <token id="9" string="which" />
            <token id="10" string="makes" />
            <token id="11" string="an" />
            <token id="12" string="anti-diabetic" />
            <token id="13" string="drug" />
            <token id="14" string="called" />
            <token id="15" string="metaforim" />
            <token id="16" string="that" />
            <token id="17" string="improves" />
            <token id="18" string="the" />
            <token id="19" string="body" />
            <token id="20" string="'s" />
            <token id="21" string="ability" />
            <token id="22" string="to" />
            <token id="23" string="respond" />
            <token id="24" string="to" />
            <token id="25" string="insulin" />
          </tokens>
        </chunking>
        <chunking id="3" string="will include work for Lipha Chemicals , which makes an anti-diabetic drug called metaforim that improves the body 's ability to respond to insulin" type="VP">
          <tokens>
            <token id="2" string="will" />
            <token id="3" string="include" />
            <token id="4" string="work" />
            <token id="5" string="for" />
            <token id="6" string="Lipha" />
            <token id="7" string="Chemicals" />
            <token id="8" string="," />
            <token id="9" string="which" />
            <token id="10" string="makes" />
            <token id="11" string="an" />
            <token id="12" string="anti-diabetic" />
            <token id="13" string="drug" />
            <token id="14" string="called" />
            <token id="15" string="metaforim" />
            <token id="16" string="that" />
            <token id="17" string="improves" />
            <token id="18" string="the" />
            <token id="19" string="body" />
            <token id="20" string="'s" />
            <token id="21" string="ability" />
            <token id="22" string="to" />
            <token id="23" string="respond" />
            <token id="24" string="to" />
            <token id="25" string="insulin" />
          </tokens>
        </chunking>
        <chunking id="4" string="metaforim" type="NP">
          <tokens>
            <token id="15" string="metaforim" />
          </tokens>
        </chunking>
        <chunking id="5" string="metaforim that improves the body 's ability to respond to insulin" type="NP">
          <tokens>
            <token id="15" string="metaforim" />
            <token id="16" string="that" />
            <token id="17" string="improves" />
            <token id="18" string="the" />
            <token id="19" string="body" />
            <token id="20" string="'s" />
            <token id="21" string="ability" />
            <token id="22" string="to" />
            <token id="23" string="respond" />
            <token id="24" string="to" />
            <token id="25" string="insulin" />
          </tokens>
        </chunking>
        <chunking id="6" string="makes an anti-diabetic drug called metaforim that improves the body 's ability to respond to insulin" type="VP">
          <tokens>
            <token id="10" string="makes" />
            <token id="11" string="an" />
            <token id="12" string="anti-diabetic" />
            <token id="13" string="drug" />
            <token id="14" string="called" />
            <token id="15" string="metaforim" />
            <token id="16" string="that" />
            <token id="17" string="improves" />
            <token id="18" string="the" />
            <token id="19" string="body" />
            <token id="20" string="'s" />
            <token id="21" string="ability" />
            <token id="22" string="to" />
            <token id="23" string="respond" />
            <token id="24" string="to" />
            <token id="25" string="insulin" />
          </tokens>
        </chunking>
        <chunking id="7" string="that improves the body 's ability to respond to insulin" type="SBAR">
          <tokens>
            <token id="16" string="that" />
            <token id="17" string="improves" />
            <token id="18" string="the" />
            <token id="19" string="body" />
            <token id="20" string="'s" />
            <token id="21" string="ability" />
            <token id="22" string="to" />
            <token id="23" string="respond" />
            <token id="24" string="to" />
            <token id="25" string="insulin" />
          </tokens>
        </chunking>
        <chunking id="8" string="work" type="NP">
          <tokens>
            <token id="4" string="work" />
          </tokens>
        </chunking>
        <chunking id="9" string="insulin" type="NP">
          <tokens>
            <token id="25" string="insulin" />
          </tokens>
        </chunking>
        <chunking id="10" string="an anti-diabetic drug called metaforim that improves the body 's ability to respond to insulin" type="NP">
          <tokens>
            <token id="11" string="an" />
            <token id="12" string="anti-diabetic" />
            <token id="13" string="drug" />
            <token id="14" string="called" />
            <token id="15" string="metaforim" />
            <token id="16" string="that" />
            <token id="17" string="improves" />
            <token id="18" string="the" />
            <token id="19" string="body" />
            <token id="20" string="'s" />
            <token id="21" string="ability" />
            <token id="22" string="to" />
            <token id="23" string="respond" />
            <token id="24" string="to" />
            <token id="25" string="insulin" />
          </tokens>
        </chunking>
        <chunking id="11" string="called metaforim that improves the body 's ability to respond to insulin" type="VP">
          <tokens>
            <token id="14" string="called" />
            <token id="15" string="metaforim" />
            <token id="16" string="that" />
            <token id="17" string="improves" />
            <token id="18" string="the" />
            <token id="19" string="body" />
            <token id="20" string="'s" />
            <token id="21" string="ability" />
            <token id="22" string="to" />
            <token id="23" string="respond" />
            <token id="24" string="to" />
            <token id="25" string="insulin" />
          </tokens>
        </chunking>
        <chunking id="12" string="include work for Lipha Chemicals , which makes an anti-diabetic drug called metaforim that improves the body 's ability to respond to insulin" type="VP">
          <tokens>
            <token id="3" string="include" />
            <token id="4" string="work" />
            <token id="5" string="for" />
            <token id="6" string="Lipha" />
            <token id="7" string="Chemicals" />
            <token id="8" string="," />
            <token id="9" string="which" />
            <token id="10" string="makes" />
            <token id="11" string="an" />
            <token id="12" string="anti-diabetic" />
            <token id="13" string="drug" />
            <token id="14" string="called" />
            <token id="15" string="metaforim" />
            <token id="16" string="that" />
            <token id="17" string="improves" />
            <token id="18" string="the" />
            <token id="19" string="body" />
            <token id="20" string="'s" />
            <token id="21" string="ability" />
            <token id="22" string="to" />
            <token id="23" string="respond" />
            <token id="24" string="to" />
            <token id="25" string="insulin" />
          </tokens>
        </chunking>
        <chunking id="13" string="Lipha Chemicals" type="NP">
          <tokens>
            <token id="6" string="Lipha" />
            <token id="7" string="Chemicals" />
          </tokens>
        </chunking>
        <chunking id="14" string="an anti-diabetic drug" type="NP">
          <tokens>
            <token id="11" string="an" />
            <token id="12" string="anti-diabetic" />
            <token id="13" string="drug" />
          </tokens>
        </chunking>
        <chunking id="15" string="the body 's ability to respond to insulin" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="body" />
            <token id="20" string="'s" />
            <token id="21" string="ability" />
            <token id="22" string="to" />
            <token id="23" string="respond" />
            <token id="24" string="to" />
            <token id="25" string="insulin" />
          </tokens>
        </chunking>
        <chunking id="16" string="to respond to insulin" type="VP">
          <tokens>
            <token id="22" string="to" />
            <token id="23" string="respond" />
            <token id="24" string="to" />
            <token id="25" string="insulin" />
          </tokens>
        </chunking>
        <chunking id="17" string="respond to insulin" type="VP">
          <tokens>
            <token id="23" string="respond" />
            <token id="24" string="to" />
            <token id="25" string="insulin" />
          </tokens>
        </chunking>
        <chunking id="18" string="improves the body 's ability to respond to insulin" type="VP">
          <tokens>
            <token id="17" string="improves" />
            <token id="18" string="the" />
            <token id="19" string="body" />
            <token id="20" string="'s" />
            <token id="21" string="ability" />
            <token id="22" string="to" />
            <token id="23" string="respond" />
            <token id="24" string="to" />
            <token id="25" string="insulin" />
          </tokens>
        </chunking>
        <chunking id="19" string="which makes an anti-diabetic drug called metaforim that improves the body 's ability to respond to insulin" type="SBAR">
          <tokens>
            <token id="9" string="which" />
            <token id="10" string="makes" />
            <token id="11" string="an" />
            <token id="12" string="anti-diabetic" />
            <token id="13" string="drug" />
            <token id="14" string="called" />
            <token id="15" string="metaforim" />
            <token id="16" string="that" />
            <token id="17" string="improves" />
            <token id="18" string="the" />
            <token id="19" string="body" />
            <token id="20" string="'s" />
            <token id="21" string="ability" />
            <token id="22" string="to" />
            <token id="23" string="respond" />
            <token id="24" string="to" />
            <token id="25" string="insulin" />
          </tokens>
        </chunking>
        <chunking id="20" string="the body 's" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="body" />
            <token id="20" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">include</governor>
          <dependent id="1">That</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">include</governor>
          <dependent id="2">will</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">include</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">include</governor>
          <dependent id="4">work</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Chemicals</governor>
          <dependent id="5">for</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Chemicals</governor>
          <dependent id="6">Lipha</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">include</governor>
          <dependent id="7">Chemicals</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">makes</governor>
          <dependent id="9">which</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="7">Chemicals</governor>
          <dependent id="10">makes</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">drug</governor>
          <dependent id="11">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">drug</governor>
          <dependent id="12">anti-diabetic</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">makes</governor>
          <dependent id="13">drug</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="13">drug</governor>
          <dependent id="14">called</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">called</governor>
          <dependent id="15">metaforim</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">improves</governor>
          <dependent id="16">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="15">metaforim</governor>
          <dependent id="17">improves</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">body</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="21">ability</governor>
          <dependent id="19">body</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">body</governor>
          <dependent id="20">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">improves</governor>
          <dependent id="21">ability</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">respond</governor>
          <dependent id="22">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="21">ability</governor>
          <dependent id="23">respond</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">insulin</governor>
          <dependent id="24">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">respond</governor>
          <dependent id="25">insulin</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lipha Chemicals" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="6" string="Lipha" />
            <token id="7" string="Chemicals" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="37" has_coreference="true">
      <content>``The problem with Type II diabetics is not that they don&amp;apost;t make enough insulin; they don&amp;apost;t respond to the insulin,&amp;apost;&amp;apost; DeFronzo said.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="problem" lemma="problem" stem="problem" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Type" lemma="type" stem="type" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="II" lemma="ii" stem="ii" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="7" string="diabetics" lemma="diabetic" stem="diabet" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="make" lemma="make" stem="make" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="enough" lemma="enough" stem="enough" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="insulin" lemma="insulin" stem="insulin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="respond" lemma="respond" stem="respond" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="insulin" lemma="insulin" stem="insulin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="DeFronzo" lemma="DeFronzo" stem="defronzo" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="28" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (S (NP (NP (DT The) (NN problem)) (PP (IN with) (NP (NN Type) (CD II) (NNS diabetics)))) (VP (VBZ is) (RB not) (SBAR (IN that) (S (NP (PRP they)) (VP (VBP do) (RB n't) (VP (VB make) (NP (JJ enough) (NN insulin)))))))) (: ;) (S (NP (PRP they)) (VP (VBP do) (RB n't) (VP (VB respond) (PP (TO to) (NP (DT the) (NN insulin))))))) (, ,) ('' '') (NP (NNP DeFronzo)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is not that they do n't make enough insulin" type="VP">
          <tokens>
            <token id="8" string="is" />
            <token id="9" string="not" />
            <token id="10" string="that" />
            <token id="11" string="they" />
            <token id="12" string="do" />
            <token id="13" string="n't" />
            <token id="14" string="make" />
            <token id="15" string="enough" />
            <token id="16" string="insulin" />
          </tokens>
        </chunking>
        <chunking id="2" string="do n't respond to the insulin" type="VP">
          <tokens>
            <token id="19" string="do" />
            <token id="20" string="n't" />
            <token id="21" string="respond" />
            <token id="22" string="to" />
            <token id="23" string="the" />
            <token id="24" string="insulin" />
          </tokens>
        </chunking>
        <chunking id="3" string="do n't make enough insulin" type="VP">
          <tokens>
            <token id="12" string="do" />
            <token id="13" string="n't" />
            <token id="14" string="make" />
            <token id="15" string="enough" />
            <token id="16" string="insulin" />
          </tokens>
        </chunking>
        <chunking id="4" string="Type II diabetics" type="NP">
          <tokens>
            <token id="5" string="Type" />
            <token id="6" string="II" />
            <token id="7" string="diabetics" />
          </tokens>
        </chunking>
        <chunking id="5" string="The problem with Type II diabetics" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="problem" />
            <token id="4" string="with" />
            <token id="5" string="Type" />
            <token id="6" string="II" />
            <token id="7" string="diabetics" />
          </tokens>
        </chunking>
        <chunking id="6" string="they" type="NP">
          <tokens>
            <token id="11" string="they" />
          </tokens>
        </chunking>
        <chunking id="7" string="the insulin" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="insulin" />
          </tokens>
        </chunking>
        <chunking id="8" string="DeFronzo" type="NP">
          <tokens>
            <token id="27" string="DeFronzo" />
          </tokens>
        </chunking>
        <chunking id="9" string="make enough insulin" type="VP">
          <tokens>
            <token id="14" string="make" />
            <token id="15" string="enough" />
            <token id="16" string="insulin" />
          </tokens>
        </chunking>
        <chunking id="10" string="respond to the insulin" type="VP">
          <tokens>
            <token id="21" string="respond" />
            <token id="22" string="to" />
            <token id="23" string="the" />
            <token id="24" string="insulin" />
          </tokens>
        </chunking>
        <chunking id="11" string="The problem" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="problem" />
          </tokens>
        </chunking>
        <chunking id="12" string="said" type="VP">
          <tokens>
            <token id="28" string="said" />
          </tokens>
        </chunking>
        <chunking id="13" string="that they do n't make enough insulin" type="SBAR">
          <tokens>
            <token id="10" string="that" />
            <token id="11" string="they" />
            <token id="12" string="do" />
            <token id="13" string="n't" />
            <token id="14" string="make" />
            <token id="15" string="enough" />
            <token id="16" string="insulin" />
          </tokens>
        </chunking>
        <chunking id="14" string="enough insulin" type="NP">
          <tokens>
            <token id="15" string="enough" />
            <token id="16" string="insulin" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">problem</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">is</governor>
          <dependent id="3">problem</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">diabetics</governor>
          <dependent id="4">with</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">diabetics</governor>
          <dependent id="5">Type</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="7">diabetics</governor>
          <dependent id="6">II</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">problem</governor>
          <dependent id="7">diabetics</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="28">said</governor>
          <dependent id="8">is</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="8">is</governor>
          <dependent id="9">not</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">make</governor>
          <dependent id="10">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">make</governor>
          <dependent id="11">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">make</governor>
          <dependent id="12">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="14">make</governor>
          <dependent id="13">n't</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">is</governor>
          <dependent id="14">make</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">insulin</governor>
          <dependent id="15">enough</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">make</governor>
          <dependent id="16">insulin</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">respond</governor>
          <dependent id="18">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">respond</governor>
          <dependent id="19">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="21">respond</governor>
          <dependent id="20">n't</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="8">is</governor>
          <dependent id="21">respond</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">insulin</governor>
          <dependent id="22">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">insulin</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">respond</governor>
          <dependent id="24">insulin</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">said</governor>
          <dependent id="27">DeFronzo</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="28">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="DeFronzo" type="PERSON" score="0.0">
          <tokens>
            <token id="27" string="DeFronzo" />
          </tokens>
        </entity>
        <entity id="2" string="II" type="NUMBER" score="0.0">
          <tokens>
            <token id="6" string="II" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="38" has_coreference="true">
      <content>``What we&amp;apost;d like to do is make them more responsive and this drug will do that.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="What" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="'d" lemma="would" stem="'d" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="like" lemma="like" stem="like" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="do" lemma="do" stem="do" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="make" lemma="make" stem="make" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="responsive" lemma="responsive" stem="respons" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="drug" lemma="drug" stem="drug" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="do" lemma="do" stem="do" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (SBAR (WHNP (WP What)) (S (NP (PRP we)) (VP (MD 'd) (VP (VB like) (S (VP (TO to) (VP (VB do)))))))) (VP (VBZ is) (VP (VB make) (S (NP (PRP them)) (ADJP (RBR more) (JJ responsive)))))) (CC and) (S (NP (DT this) (NN drug)) (VP (MD will) (VP (VB do) (NP (DT that))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="make them more responsive" type="VP">
          <tokens>
            <token id="9" string="make" />
            <token id="10" string="them" />
            <token id="11" string="more" />
            <token id="12" string="responsive" />
          </tokens>
        </chunking>
        <chunking id="2" string="more responsive" type="ADJP">
          <tokens>
            <token id="11" string="more" />
            <token id="12" string="responsive" />
          </tokens>
        </chunking>
        <chunking id="3" string="is make them more responsive" type="VP">
          <tokens>
            <token id="8" string="is" />
            <token id="9" string="make" />
            <token id="10" string="them" />
            <token id="11" string="more" />
            <token id="12" string="responsive" />
          </tokens>
        </chunking>
        <chunking id="4" string="What we 'd like to do" type="SBAR">
          <tokens>
            <token id="2" string="What" />
            <token id="3" string="we" />
            <token id="4" string="'d" />
            <token id="5" string="like" />
            <token id="6" string="to" />
            <token id="7" string="do" />
          </tokens>
        </chunking>
        <chunking id="5" string="do that" type="VP">
          <tokens>
            <token id="17" string="do" />
            <token id="18" string="that" />
          </tokens>
        </chunking>
        <chunking id="6" string="do" type="VP">
          <tokens>
            <token id="7" string="do" />
          </tokens>
        </chunking>
        <chunking id="7" string="'d like to do" type="VP">
          <tokens>
            <token id="4" string="'d" />
            <token id="5" string="like" />
            <token id="6" string="to" />
            <token id="7" string="do" />
          </tokens>
        </chunking>
        <chunking id="8" string="we" type="NP">
          <tokens>
            <token id="3" string="we" />
          </tokens>
        </chunking>
        <chunking id="9" string="them" type="NP">
          <tokens>
            <token id="10" string="them" />
          </tokens>
        </chunking>
        <chunking id="10" string="that" type="NP">
          <tokens>
            <token id="18" string="that" />
          </tokens>
        </chunking>
        <chunking id="11" string="like to do" type="VP">
          <tokens>
            <token id="5" string="like" />
            <token id="6" string="to" />
            <token id="7" string="do" />
          </tokens>
        </chunking>
        <chunking id="12" string="to do" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="do" />
          </tokens>
        </chunking>
        <chunking id="13" string="this drug" type="NP">
          <tokens>
            <token id="14" string="this" />
            <token id="15" string="drug" />
          </tokens>
        </chunking>
        <chunking id="14" string="will do that" type="VP">
          <tokens>
            <token id="16" string="will" />
            <token id="17" string="do" />
            <token id="18" string="that" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="dobj">
          <governor id="7">do</governor>
          <dependent id="2">What</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">like</governor>
          <dependent id="3">we</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">like</governor>
          <dependent id="4">'d</dependent>
        </dependency>
        <dependency type="csubj">
          <governor id="9">make</governor>
          <dependent id="5">like</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">do</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">like</governor>
          <dependent id="7">do</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">make</governor>
          <dependent id="8">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">make</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">responsive</governor>
          <dependent id="10">them</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">responsive</governor>
          <dependent id="11">more</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">make</governor>
          <dependent id="12">responsive</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">make</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">drug</governor>
          <dependent id="14">this</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">do</governor>
          <dependent id="15">drug</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="17">do</governor>
          <dependent id="16">will</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">make</governor>
          <dependent id="17">do</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">do</governor>
          <dependent id="18">that</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="39" has_coreference="true">
      <content>The drug is widely used in Europe, Canada and Mexico and should be approved by the Food and Drug Administration in several years for U.S. use, he said.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="drug" lemma="drug" stem="drug" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="widely" lemma="widely" stem="wide" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="used" lemma="use" stem="us" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Europe" lemma="Europe" stem="europ" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Canada" lemma="Canada" stem="canada" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Mexico" lemma="Mexico" stem="mexico" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="should" lemma="should" stem="should" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="approved" lemma="approve" stem="approv" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Food" lemma="Food" stem="food" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="20" string="Drug" lemma="Drug" stem="drug" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="21" string="Administration" lemma="Administration" stem="administr" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="22" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="several" lemma="several" stem="sever" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="24" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="25" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="U.S." lemma="U.S." stem="u.s." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="27" string="use" lemma="use" stem="us" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="30" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT The) (NN drug)) (VP (VP (VBZ is) (ADVP (RB widely)) (VP (VBN used) (PP (IN in) (NP (NNP Europe) (, ,) (NNP Canada) (CC and) (NNP Mexico))))) (CC and) (VP (MD should) (VP (VB be) (VP (VBN approved) (PP (IN by) (NP (DT the) (NNP Food) (CC and) (NNP Drug) (NNP Administration))) (PP (IN in) (NP (NP (JJ several) (NNS years)) (PP (IN for) (NP (NNP U.S.) (NN use)))))))))) (, ,) (NP (PRP he)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="should be approved by the Food and Drug Administration in several years for U.S. use" type="VP">
          <tokens>
            <token id="13" string="should" />
            <token id="14" string="be" />
            <token id="15" string="approved" />
            <token id="16" string="by" />
            <token id="17" string="the" />
            <token id="18" string="Food" />
            <token id="19" string="and" />
            <token id="20" string="Drug" />
            <token id="21" string="Administration" />
            <token id="22" string="in" />
            <token id="23" string="several" />
            <token id="24" string="years" />
            <token id="25" string="for" />
            <token id="26" string="U.S." />
            <token id="27" string="use" />
          </tokens>
        </chunking>
        <chunking id="2" string="Europe , Canada and Mexico" type="NP">
          <tokens>
            <token id="7" string="Europe" />
            <token id="8" string="," />
            <token id="9" string="Canada" />
            <token id="10" string="and" />
            <token id="11" string="Mexico" />
          </tokens>
        </chunking>
        <chunking id="3" string="approved by the Food and Drug Administration in several years for U.S. use" type="VP">
          <tokens>
            <token id="15" string="approved" />
            <token id="16" string="by" />
            <token id="17" string="the" />
            <token id="18" string="Food" />
            <token id="19" string="and" />
            <token id="20" string="Drug" />
            <token id="21" string="Administration" />
            <token id="22" string="in" />
            <token id="23" string="several" />
            <token id="24" string="years" />
            <token id="25" string="for" />
            <token id="26" string="U.S." />
            <token id="27" string="use" />
          </tokens>
        </chunking>
        <chunking id="4" string="several years" type="NP">
          <tokens>
            <token id="23" string="several" />
            <token id="24" string="years" />
          </tokens>
        </chunking>
        <chunking id="5" string="U.S. use" type="NP">
          <tokens>
            <token id="26" string="U.S." />
            <token id="27" string="use" />
          </tokens>
        </chunking>
        <chunking id="6" string="is widely used in Europe , Canada and Mexico and should be approved by the Food and Drug Administration in several years for U.S. use" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="widely" />
            <token id="5" string="used" />
            <token id="6" string="in" />
            <token id="7" string="Europe" />
            <token id="8" string="," />
            <token id="9" string="Canada" />
            <token id="10" string="and" />
            <token id="11" string="Mexico" />
            <token id="12" string="and" />
            <token id="13" string="should" />
            <token id="14" string="be" />
            <token id="15" string="approved" />
            <token id="16" string="by" />
            <token id="17" string="the" />
            <token id="18" string="Food" />
            <token id="19" string="and" />
            <token id="20" string="Drug" />
            <token id="21" string="Administration" />
            <token id="22" string="in" />
            <token id="23" string="several" />
            <token id="24" string="years" />
            <token id="25" string="for" />
            <token id="26" string="U.S." />
            <token id="27" string="use" />
          </tokens>
        </chunking>
        <chunking id="7" string="be approved by the Food and Drug Administration in several years for U.S. use" type="VP">
          <tokens>
            <token id="14" string="be" />
            <token id="15" string="approved" />
            <token id="16" string="by" />
            <token id="17" string="the" />
            <token id="18" string="Food" />
            <token id="19" string="and" />
            <token id="20" string="Drug" />
            <token id="21" string="Administration" />
            <token id="22" string="in" />
            <token id="23" string="several" />
            <token id="24" string="years" />
            <token id="25" string="for" />
            <token id="26" string="U.S." />
            <token id="27" string="use" />
          </tokens>
        </chunking>
        <chunking id="8" string="several years for U.S. use" type="NP">
          <tokens>
            <token id="23" string="several" />
            <token id="24" string="years" />
            <token id="25" string="for" />
            <token id="26" string="U.S." />
            <token id="27" string="use" />
          </tokens>
        </chunking>
        <chunking id="9" string="is widely used in Europe , Canada and Mexico" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="widely" />
            <token id="5" string="used" />
            <token id="6" string="in" />
            <token id="7" string="Europe" />
            <token id="8" string="," />
            <token id="9" string="Canada" />
            <token id="10" string="and" />
            <token id="11" string="Mexico" />
          </tokens>
        </chunking>
        <chunking id="10" string="the Food and Drug Administration" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="Food" />
            <token id="19" string="and" />
            <token id="20" string="Drug" />
            <token id="21" string="Administration" />
          </tokens>
        </chunking>
        <chunking id="11" string="The drug" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="drug" />
          </tokens>
        </chunking>
        <chunking id="12" string="he" type="NP">
          <tokens>
            <token id="29" string="he" />
          </tokens>
        </chunking>
        <chunking id="13" string="said" type="VP">
          <tokens>
            <token id="30" string="said" />
          </tokens>
        </chunking>
        <chunking id="14" string="used in Europe , Canada and Mexico" type="VP">
          <tokens>
            <token id="5" string="used" />
            <token id="6" string="in" />
            <token id="7" string="Europe" />
            <token id="8" string="," />
            <token id="9" string="Canada" />
            <token id="10" string="and" />
            <token id="11" string="Mexico" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">drug</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="5">used</governor>
          <dependent id="2">drug</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">used</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">used</governor>
          <dependent id="4">widely</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="30">said</governor>
          <dependent id="5">used</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Europe</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">used</governor>
          <dependent id="7">Europe</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">Europe</governor>
          <dependent id="9">Canada</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">Europe</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">Europe</governor>
          <dependent id="11">Mexico</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">used</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">approved</governor>
          <dependent id="13">should</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="15">approved</governor>
          <dependent id="14">be</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">used</governor>
          <dependent id="15">approved</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">Administration</governor>
          <dependent id="16">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">Administration</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">Administration</governor>
          <dependent id="18">Food</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="18">Food</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">Food</governor>
          <dependent id="20">Drug</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">approved</governor>
          <dependent id="21">Administration</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">years</governor>
          <dependent id="22">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">years</governor>
          <dependent id="23">several</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">approved</governor>
          <dependent id="24">years</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">use</governor>
          <dependent id="25">for</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">use</governor>
          <dependent id="26">U.S.</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">years</governor>
          <dependent id="27">use</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="30">said</governor>
          <dependent id="29">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="30">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Canada" type="LOCATION" score="0.0">
          <tokens>
            <token id="9" string="Canada" />
          </tokens>
        </entity>
        <entity id="2" string="U.S." type="LOCATION" score="0.0">
          <tokens>
            <token id="26" string="U.S." />
          </tokens>
        </entity>
        <entity id="3" string="Europe" type="LOCATION" score="0.0">
          <tokens>
            <token id="7" string="Europe" />
          </tokens>
        </entity>
        <entity id="4" string="several years" type="DURATION" score="0.0">
          <tokens>
            <token id="23" string="several" />
            <token id="24" string="years" />
          </tokens>
        </entity>
        <entity id="5" string="Mexico" type="LOCATION" score="0.0">
          <tokens>
            <token id="11" string="Mexico" />
          </tokens>
        </entity>
        <entity id="6" string="Food and Drug Administration" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="18" string="Food" />
            <token id="19" string="and" />
            <token id="20" string="Drug" />
            <token id="21" string="Administration" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="40" has_coreference="true">
      <content>Educating elementary-school-age children about healthy diets would help reduce the number of diabetes cases, DeFronzo said.</content>
      <tokens>
        <token id="1" string="Educating" lemma="educate" stem="educat" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="elementary-school-age" lemma="elementary-school-age" stem="elementary-school-ag" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="healthy" lemma="healthy" stem="healthi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="diets" lemma="diet" stem="diet" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="help" lemma="help" stem="help" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="reduce" lemma="reduce" stem="reduc" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="number" lemma="number" stem="number" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="diabetes" lemma="diabetes" stem="diabet" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="14" string="cases" lemma="case" stem="case" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="DeFronzo" lemma="DeFronzo" stem="defronzo" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="17" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (S (VP (VBG Educating) (NP (JJ elementary-school-age) (NNS children)) (PP (IN about) (NP (JJ healthy) (NNS diets))))) (VP (MD would) (VP (VB help) (VP (VB reduce) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NN diabetes) (NNS cases)))))))) (, ,) (NP (NNP DeFronzo)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="diabetes cases" type="NP">
          <tokens>
            <token id="13" string="diabetes" />
            <token id="14" string="cases" />
          </tokens>
        </chunking>
        <chunking id="2" string="DeFronzo" type="NP">
          <tokens>
            <token id="16" string="DeFronzo" />
          </tokens>
        </chunking>
        <chunking id="3" string="reduce the number of diabetes cases" type="VP">
          <tokens>
            <token id="9" string="reduce" />
            <token id="10" string="the" />
            <token id="11" string="number" />
            <token id="12" string="of" />
            <token id="13" string="diabetes" />
            <token id="14" string="cases" />
          </tokens>
        </chunking>
        <chunking id="4" string="the number of diabetes cases" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="number" />
            <token id="12" string="of" />
            <token id="13" string="diabetes" />
            <token id="14" string="cases" />
          </tokens>
        </chunking>
        <chunking id="5" string="elementary-school-age children" type="NP">
          <tokens>
            <token id="2" string="elementary-school-age" />
            <token id="3" string="children" />
          </tokens>
        </chunking>
        <chunking id="6" string="would help reduce the number of diabetes cases" type="VP">
          <tokens>
            <token id="7" string="would" />
            <token id="8" string="help" />
            <token id="9" string="reduce" />
            <token id="10" string="the" />
            <token id="11" string="number" />
            <token id="12" string="of" />
            <token id="13" string="diabetes" />
            <token id="14" string="cases" />
          </tokens>
        </chunking>
        <chunking id="7" string="healthy diets" type="NP">
          <tokens>
            <token id="5" string="healthy" />
            <token id="6" string="diets" />
          </tokens>
        </chunking>
        <chunking id="8" string="help reduce the number of diabetes cases" type="VP">
          <tokens>
            <token id="8" string="help" />
            <token id="9" string="reduce" />
            <token id="10" string="the" />
            <token id="11" string="number" />
            <token id="12" string="of" />
            <token id="13" string="diabetes" />
            <token id="14" string="cases" />
          </tokens>
        </chunking>
        <chunking id="9" string="the number" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="number" />
          </tokens>
        </chunking>
        <chunking id="10" string="said" type="VP">
          <tokens>
            <token id="17" string="said" />
          </tokens>
        </chunking>
        <chunking id="11" string="Educating elementary-school-age children about healthy diets" type="VP">
          <tokens>
            <token id="1" string="Educating" />
            <token id="2" string="elementary-school-age" />
            <token id="3" string="children" />
            <token id="4" string="about" />
            <token id="5" string="healthy" />
            <token id="6" string="diets" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="csubj">
          <governor id="8">help</governor>
          <dependent id="1">Educating</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">children</governor>
          <dependent id="2">elementary-school-age</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="1">Educating</governor>
          <dependent id="3">children</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">diets</governor>
          <dependent id="4">about</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">diets</governor>
          <dependent id="5">healthy</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Educating</governor>
          <dependent id="6">diets</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">help</governor>
          <dependent id="7">would</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">said</governor>
          <dependent id="8">help</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">help</governor>
          <dependent id="9">reduce</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">number</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">reduce</governor>
          <dependent id="11">number</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">cases</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">cases</governor>
          <dependent id="13">diabetes</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">number</governor>
          <dependent id="14">cases</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">said</governor>
          <dependent id="16">DeFronzo</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="DeFronzo" type="PERSON" score="0.0">
          <tokens>
            <token id="16" string="DeFronzo" />
          </tokens>
        </entity>
        <entity id="2" string="diabetes" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="13" string="diabetes" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="41" has_coreference="true">
      <content>``If you have a 65-year-old mother who weighs 220 pounds and you tell her to go out and jog five miles Monday, Wednesday and Friday, she is going to laugh at you.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="If" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="65-year-old" lemma="65-year-old" stem="65-year-old" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="7" string="mother" lemma="mother" stem="mother" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="weighs" lemma="weigh" stem="weigh" pos="VBZ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="220" lemma="220" stem="220" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="11" string="pounds" lemma="pound" stem="pound" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="tell" lemma="tell" stem="tell" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="her" lemma="she" stem="her" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="go" lemma="go" stem="go" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="jog" lemma="jog" stem="jog" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="five" lemma="five" stem="five" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="22" string="miles" lemma="mile" stem="mile" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="Monday" lemma="Monday" stem="mondai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="25" string="Wednesday" lemma="Wednesday" stem="wednesdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="26" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="Friday" lemma="Friday" stem="fridai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="28" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="laugh" lemma="laugh" stem="laugh" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (SBAR (IN If) (S (S (NP (PRP you)) (VP (VBP have) (NP (NP (DT a) (JJ 65-year-old) (NN mother)) (SBAR (WHNP (WP who)) (S (VP (VBZ weighs) (NP (CD 220) (NNS pounds)))))))) (CC and) (S (NP (PRP you)) (VP (VBP tell) (S (NP (PRP her)) (VP (TO to) (VP (VP (VB go) (PRT (RP out))) (CC and) (VP (VB jog) (NP (CD five) (NNS miles))) (NP (NNP Monday) (, ,) (NNP Wednesday) (CC and) (NNP Friday))))))))) (, ,) (NP (PRP she)) (VP (VBZ is) (VP (VBG going) (S (VP (TO to) (VP (NN laugh) (PP (IN at) (NP (PRP you)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="If you have a 65-year-old mother who weighs 220 pounds and you tell her to go out and jog five miles Monday , Wednesday and Friday" type="SBAR">
          <tokens>
            <token id="2" string="If" />
            <token id="3" string="you" />
            <token id="4" string="have" />
            <token id="5" string="a" />
            <token id="6" string="65-year-old" />
            <token id="7" string="mother" />
            <token id="8" string="who" />
            <token id="9" string="weighs" />
            <token id="10" string="220" />
            <token id="11" string="pounds" />
            <token id="12" string="and" />
            <token id="13" string="you" />
            <token id="14" string="tell" />
            <token id="15" string="her" />
            <token id="16" string="to" />
            <token id="17" string="go" />
            <token id="18" string="out" />
            <token id="19" string="and" />
            <token id="20" string="jog" />
            <token id="21" string="five" />
            <token id="22" string="miles" />
            <token id="23" string="Monday" />
            <token id="24" string="," />
            <token id="25" string="Wednesday" />
            <token id="26" string="and" />
            <token id="27" string="Friday" />
          </tokens>
        </chunking>
        <chunking id="2" string="tell her to go out and jog five miles Monday , Wednesday and Friday" type="VP">
          <tokens>
            <token id="14" string="tell" />
            <token id="15" string="her" />
            <token id="16" string="to" />
            <token id="17" string="go" />
            <token id="18" string="out" />
            <token id="19" string="and" />
            <token id="20" string="jog" />
            <token id="21" string="five" />
            <token id="22" string="miles" />
            <token id="23" string="Monday" />
            <token id="24" string="," />
            <token id="25" string="Wednesday" />
            <token id="26" string="and" />
            <token id="27" string="Friday" />
          </tokens>
        </chunking>
        <chunking id="3" string="who weighs 220 pounds" type="SBAR">
          <tokens>
            <token id="8" string="who" />
            <token id="9" string="weighs" />
            <token id="10" string="220" />
            <token id="11" string="pounds" />
          </tokens>
        </chunking>
        <chunking id="4" string="a 65-year-old mother who weighs 220 pounds" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="65-year-old" />
            <token id="7" string="mother" />
            <token id="8" string="who" />
            <token id="9" string="weighs" />
            <token id="10" string="220" />
            <token id="11" string="pounds" />
          </tokens>
        </chunking>
        <chunking id="5" string="five miles" type="NP">
          <tokens>
            <token id="21" string="five" />
            <token id="22" string="miles" />
          </tokens>
        </chunking>
        <chunking id="6" string="she" type="NP">
          <tokens>
            <token id="29" string="she" />
          </tokens>
        </chunking>
        <chunking id="7" string="going to laugh at you" type="VP">
          <tokens>
            <token id="31" string="going" />
            <token id="32" string="to" />
            <token id="33" string="laugh" />
            <token id="34" string="at" />
            <token id="35" string="you" />
          </tokens>
        </chunking>
        <chunking id="8" string="220 pounds" type="NP">
          <tokens>
            <token id="10" string="220" />
            <token id="11" string="pounds" />
          </tokens>
        </chunking>
        <chunking id="9" string="to laugh at you" type="VP">
          <tokens>
            <token id="32" string="to" />
            <token id="33" string="laugh" />
            <token id="34" string="at" />
            <token id="35" string="you" />
          </tokens>
        </chunking>
        <chunking id="10" string="her" type="NP">
          <tokens>
            <token id="15" string="her" />
          </tokens>
        </chunking>
        <chunking id="11" string="go out and jog five miles Monday , Wednesday and Friday" type="VP">
          <tokens>
            <token id="17" string="go" />
            <token id="18" string="out" />
            <token id="19" string="and" />
            <token id="20" string="jog" />
            <token id="21" string="five" />
            <token id="22" string="miles" />
            <token id="23" string="Monday" />
            <token id="24" string="," />
            <token id="25" string="Wednesday" />
            <token id="26" string="and" />
            <token id="27" string="Friday" />
          </tokens>
        </chunking>
        <chunking id="12" string="Monday , Wednesday and Friday" type="NP">
          <tokens>
            <token id="23" string="Monday" />
            <token id="24" string="," />
            <token id="25" string="Wednesday" />
            <token id="26" string="and" />
            <token id="27" string="Friday" />
          </tokens>
        </chunking>
        <chunking id="13" string="have a 65-year-old mother who weighs 220 pounds" type="VP">
          <tokens>
            <token id="4" string="have" />
            <token id="5" string="a" />
            <token id="6" string="65-year-old" />
            <token id="7" string="mother" />
            <token id="8" string="who" />
            <token id="9" string="weighs" />
            <token id="10" string="220" />
            <token id="11" string="pounds" />
          </tokens>
        </chunking>
        <chunking id="14" string="to go out and jog five miles Monday , Wednesday and Friday" type="VP">
          <tokens>
            <token id="16" string="to" />
            <token id="17" string="go" />
            <token id="18" string="out" />
            <token id="19" string="and" />
            <token id="20" string="jog" />
            <token id="21" string="five" />
            <token id="22" string="miles" />
            <token id="23" string="Monday" />
            <token id="24" string="," />
            <token id="25" string="Wednesday" />
            <token id="26" string="and" />
            <token id="27" string="Friday" />
          </tokens>
        </chunking>
        <chunking id="15" string="go out" type="VP">
          <tokens>
            <token id="17" string="go" />
            <token id="18" string="out" />
          </tokens>
        </chunking>
        <chunking id="16" string="is going to laugh at you" type="VP">
          <tokens>
            <token id="30" string="is" />
            <token id="31" string="going" />
            <token id="32" string="to" />
            <token id="33" string="laugh" />
            <token id="34" string="at" />
            <token id="35" string="you" />
          </tokens>
        </chunking>
        <chunking id="17" string="jog five miles" type="VP">
          <tokens>
            <token id="20" string="jog" />
            <token id="21" string="five" />
            <token id="22" string="miles" />
          </tokens>
        </chunking>
        <chunking id="18" string="weighs 220 pounds" type="VP">
          <tokens>
            <token id="9" string="weighs" />
            <token id="10" string="220" />
            <token id="11" string="pounds" />
          </tokens>
        </chunking>
        <chunking id="19" string="laugh at you" type="VP">
          <tokens>
            <token id="33" string="laugh" />
            <token id="34" string="at" />
            <token id="35" string="you" />
          </tokens>
        </chunking>
        <chunking id="20" string="you" type="NP">
          <tokens>
            <token id="3" string="you" />
          </tokens>
        </chunking>
        <chunking id="21" string="a 65-year-old mother" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="65-year-old" />
            <token id="7" string="mother" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="4">have</governor>
          <dependent id="2">If</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">have</governor>
          <dependent id="3">you</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="31">going</governor>
          <dependent id="4">have</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">mother</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">mother</governor>
          <dependent id="6">65-year-old</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">have</governor>
          <dependent id="7">mother</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">weighs</governor>
          <dependent id="8">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="7">mother</governor>
          <dependent id="9">weighs</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="11">pounds</governor>
          <dependent id="10">220</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">weighs</governor>
          <dependent id="11">pounds</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">have</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">tell</governor>
          <dependent id="13">you</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">have</governor>
          <dependent id="14">tell</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">tell</governor>
          <dependent id="15">her</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">go</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="14">tell</governor>
          <dependent id="17">go</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="17">go</governor>
          <dependent id="18">out</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">go</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">go</governor>
          <dependent id="20">jog</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="22">miles</governor>
          <dependent id="21">five</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">jog</governor>
          <dependent id="22">miles</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="17">go</governor>
          <dependent id="23">Monday</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="23">Monday</governor>
          <dependent id="25">Wednesday</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="23">Monday</governor>
          <dependent id="26">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="23">Monday</governor>
          <dependent id="27">Friday</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">going</governor>
          <dependent id="29">she</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="31">going</governor>
          <dependent id="30">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="31">going</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="33">laugh</governor>
          <dependent id="32">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="31">going</governor>
          <dependent id="33">laugh</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">you</governor>
          <dependent id="34">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">laugh</governor>
          <dependent id="35">you</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Monday , Wednesday" type="DATE" score="0.0">
          <tokens>
            <token id="23" string="Monday" />
            <token id="24" string="," />
            <token id="25" string="Wednesday" />
          </tokens>
        </entity>
        <entity id="2" string="Friday" type="DATE" score="0.0">
          <tokens>
            <token id="27" string="Friday" />
          </tokens>
        </entity>
        <entity id="3" string="65-year-old" type="DURATION" score="0.0">
          <tokens>
            <token id="6" string="65-year-old" />
          </tokens>
        </entity>
        <entity id="4" string="five" type="NUMBER" score="0.0">
          <tokens>
            <token id="21" string="five" />
          </tokens>
        </entity>
        <entity id="5" string="220" type="NUMBER" score="0.0">
          <tokens>
            <token id="10" string="220" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="42" has_coreference="true">
      <content>``So you have to design an exercise program that is compatible with the patient&amp;apost;s lifestyle and it is something they can do.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="So" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="design" lemma="design" stem="design" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="exercise" lemma="exercise" stem="exercis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="program" lemma="program" stem="program" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="compatible" lemma="compatible" stem="compat" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="patient" lemma="patient" stem="patient" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="lifestyle" lemma="lifestyle" stem="lifestyl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="something" lemma="something" stem="someth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="do" lemma="do" stem="do" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (RB So) (NP (PRP you)) (VP (VBP have) (S (VP (TO to) (VP (VB design) (NP (NP (DT an) (NN exercise) (NN program)) (SBAR (WHNP (WDT that)) (S (VP (VBZ is) (ADJP (JJ compatible) (PP (IN with) (NP (NP (DT the) (NN patient) (POS 's)) (NN lifestyle))))))))))))) (CC and) (S (NP (PRP it)) (VP (VBZ is) (NP (NP (NN something)) (SBAR (S (NP (PRP they)) (VP (MD can) (VP (VB do)))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="that is compatible with the patient 's lifestyle" type="SBAR">
          <tokens>
            <token id="10" string="that" />
            <token id="11" string="is" />
            <token id="12" string="compatible" />
            <token id="13" string="with" />
            <token id="14" string="the" />
            <token id="15" string="patient" />
            <token id="16" string="'s" />
            <token id="17" string="lifestyle" />
          </tokens>
        </chunking>
        <chunking id="2" string="is something they can do" type="VP">
          <tokens>
            <token id="20" string="is" />
            <token id="21" string="something" />
            <token id="22" string="they" />
            <token id="23" string="can" />
            <token id="24" string="do" />
          </tokens>
        </chunking>
        <chunking id="3" string="an exercise program" type="NP">
          <tokens>
            <token id="7" string="an" />
            <token id="8" string="exercise" />
            <token id="9" string="program" />
          </tokens>
        </chunking>
        <chunking id="4" string="the patient 's lifestyle" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="patient" />
            <token id="16" string="'s" />
            <token id="17" string="lifestyle" />
          </tokens>
        </chunking>
        <chunking id="5" string="can do" type="VP">
          <tokens>
            <token id="23" string="can" />
            <token id="24" string="do" />
          </tokens>
        </chunking>
        <chunking id="6" string="compatible with the patient 's lifestyle" type="ADJP">
          <tokens>
            <token id="12" string="compatible" />
            <token id="13" string="with" />
            <token id="14" string="the" />
            <token id="15" string="patient" />
            <token id="16" string="'s" />
            <token id="17" string="lifestyle" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="19" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="do" type="VP">
          <tokens>
            <token id="24" string="do" />
          </tokens>
        </chunking>
        <chunking id="9" string="to design an exercise program that is compatible with the patient 's lifestyle" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="design" />
            <token id="7" string="an" />
            <token id="8" string="exercise" />
            <token id="9" string="program" />
            <token id="10" string="that" />
            <token id="11" string="is" />
            <token id="12" string="compatible" />
            <token id="13" string="with" />
            <token id="14" string="the" />
            <token id="15" string="patient" />
            <token id="16" string="'s" />
            <token id="17" string="lifestyle" />
          </tokens>
        </chunking>
        <chunking id="10" string="something" type="NP">
          <tokens>
            <token id="21" string="something" />
          </tokens>
        </chunking>
        <chunking id="11" string="design an exercise program that is compatible with the patient 's lifestyle" type="VP">
          <tokens>
            <token id="6" string="design" />
            <token id="7" string="an" />
            <token id="8" string="exercise" />
            <token id="9" string="program" />
            <token id="10" string="that" />
            <token id="11" string="is" />
            <token id="12" string="compatible" />
            <token id="13" string="with" />
            <token id="14" string="the" />
            <token id="15" string="patient" />
            <token id="16" string="'s" />
            <token id="17" string="lifestyle" />
          </tokens>
        </chunking>
        <chunking id="12" string="they" type="NP">
          <tokens>
            <token id="22" string="they" />
          </tokens>
        </chunking>
        <chunking id="13" string="have to design an exercise program that is compatible with the patient 's lifestyle" type="VP">
          <tokens>
            <token id="4" string="have" />
            <token id="5" string="to" />
            <token id="6" string="design" />
            <token id="7" string="an" />
            <token id="8" string="exercise" />
            <token id="9" string="program" />
            <token id="10" string="that" />
            <token id="11" string="is" />
            <token id="12" string="compatible" />
            <token id="13" string="with" />
            <token id="14" string="the" />
            <token id="15" string="patient" />
            <token id="16" string="'s" />
            <token id="17" string="lifestyle" />
          </tokens>
        </chunking>
        <chunking id="14" string="they can do" type="SBAR">
          <tokens>
            <token id="22" string="they" />
            <token id="23" string="can" />
            <token id="24" string="do" />
          </tokens>
        </chunking>
        <chunking id="15" string="an exercise program that is compatible with the patient 's lifestyle" type="NP">
          <tokens>
            <token id="7" string="an" />
            <token id="8" string="exercise" />
            <token id="9" string="program" />
            <token id="10" string="that" />
            <token id="11" string="is" />
            <token id="12" string="compatible" />
            <token id="13" string="with" />
            <token id="14" string="the" />
            <token id="15" string="patient" />
            <token id="16" string="'s" />
            <token id="17" string="lifestyle" />
          </tokens>
        </chunking>
        <chunking id="16" string="is compatible with the patient 's lifestyle" type="VP">
          <tokens>
            <token id="11" string="is" />
            <token id="12" string="compatible" />
            <token id="13" string="with" />
            <token id="14" string="the" />
            <token id="15" string="patient" />
            <token id="16" string="'s" />
            <token id="17" string="lifestyle" />
          </tokens>
        </chunking>
        <chunking id="17" string="the patient 's" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="patient" />
            <token id="16" string="'s" />
          </tokens>
        </chunking>
        <chunking id="18" string="you" type="NP">
          <tokens>
            <token id="3" string="you" />
          </tokens>
        </chunking>
        <chunking id="19" string="something they can do" type="NP">
          <tokens>
            <token id="21" string="something" />
            <token id="22" string="they" />
            <token id="23" string="can" />
            <token id="24" string="do" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="4">have</governor>
          <dependent id="2">So</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">have</governor>
          <dependent id="3">you</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">have</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">design</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">have</governor>
          <dependent id="6">design</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">program</governor>
          <dependent id="7">an</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">program</governor>
          <dependent id="8">exercise</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">design</governor>
          <dependent id="9">program</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">compatible</governor>
          <dependent id="10">that</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">compatible</governor>
          <dependent id="11">is</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="9">program</governor>
          <dependent id="12">compatible</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">lifestyle</governor>
          <dependent id="13">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">patient</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="17">lifestyle</governor>
          <dependent id="15">patient</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">patient</governor>
          <dependent id="16">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">compatible</governor>
          <dependent id="17">lifestyle</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">have</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">something</governor>
          <dependent id="19">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="21">something</governor>
          <dependent id="20">is</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">have</governor>
          <dependent id="21">something</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">do</governor>
          <dependent id="22">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="24">do</governor>
          <dependent id="23">can</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="21">something</governor>
          <dependent id="24">do</dependent>
        </dependency>
      </dependencies>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="7-8" string="Joanne Pierluissi" id_sentence="1" />
      <mentions>
        <mention ids_tokens="2" string="her" id_sentence="2" />
        <mention ids_tokens="20" string="herself" id_sentence="2" />
        <mention ids_tokens="23" string="she" id_sentence="2" />
      </mentions>
    </coreference>
    <coreference id="3" type="NOMINAL">
      <referenced ids_tokens="32-33-34" string="a diabetes test" id_sentence="1" />
      <mentions>
        <mention ids_tokens="2" string="I" id_sentence="3" />
        <mention ids_tokens="15" string="I" id_sentence="3" />
        <mention ids_tokens="3" string="you" id_sentence="18" />
        <mention ids_tokens="15" string="you" id_sentence="18" />
        <mention ids_tokens="21" string="your" id_sentence="18" />
        <mention ids_tokens="26" string="you" id_sentence="18" />
      </mentions>
    </coreference>
    <coreference id="4" type="PROPER">
      <referenced ids_tokens="8" string="24" id_sentence="2" />
      <mentions>
        <mention ids_tokens="13" string="it" id_sentence="3" />
        <mention ids_tokens="19" string="it" id_sentence="4" />
      </mentions>
    </coreference>
    <coreference id="5" type="PROPER">
      <referenced ids_tokens="19-20" string="low-income Hispanics" id_sentence="19" />
      <mentions>
        <mention ids_tokens="33" string="Hispanics" id_sentence="2" />
        <mention ids_tokens="17" string="we" id_sentence="4" />
        <mention ids_tokens="21" string="we" id_sentence="4" />
        <mention ids_tokens="24" string="Hispanics" id_sentence="5" />
        <mention ids_tokens="1" string="Hispanics" id_sentence="6" />
        <mention ids_tokens="12" string="Hispanics" id_sentence="8" />
        <mention ids_tokens="12" string="Hispanics" id_sentence="10" />
        <mention ids_tokens="9" string="they" id_sentence="21" />
        <mention ids_tokens="13" string="they" id_sentence="21" />
        <mention ids_tokens="33" string="they" id_sentence="21" />
        <mention ids_tokens="16" string="we" id_sentence="24" />
        <mention ids_tokens="20-21" string="2,905 Hispanics" id_sentence="25" />
      </mentions>
    </coreference>
    <coreference id="6" type="NOMINAL">
      <referenced ids_tokens="2-3-4" string="her daughters watched" id_sentence="2" />
      <mentions>
        <mention ids_tokens="6" string="they" id_sentence="3" />
      </mentions>
    </coreference>
    <coreference id="11" type="PROPER">
      <referenced ids_tokens="7-8-9-10-11-12-13-14-15-16-17-18-19-20-21-22" string="diabetes each year ; another 150,000 deaths are diabetes-related , according to the American Diabetes Association" id_sentence="7" />
      <mentions>
        <mention ids_tokens="19" string="diabetes" id_sentence="11" />
        <mention ids_tokens="11" string="diabetes" id_sentence="21" />
        <mention ids_tokens="24" string="it" id_sentence="21" />
        <mention ids_tokens="31" string="it" id_sentence="21" />
      </mentions>
    </coreference>
    <coreference id="14" type="PROPER">
      <referenced ids_tokens="1-2" string="San Antonio" id_sentence="9" />
      <mentions>
        <mention ids_tokens="1-3" string="San Antonio's" id_sentence="11" />
      </mentions>
    </coreference>
    <coreference id="17" type="NOMINAL">
      <referenced ids_tokens="21-22-23-24" string="the body of insulin" id_sentence="10" />
      <mentions>
        <mention ids_tokens="5-6" string="the body" id_sentence="14" />
        <mention ids_tokens="12" string="it" id_sentence="14" />
        <mention ids_tokens="18-20" string="the body's" id_sentence="36" />
      </mentions>
    </coreference>
    <coreference id="19" type="PROPER">
      <referenced ids_tokens="7-8-9" string="Dr. Ralph DeFronzo" id_sentence="11" />
      <mentions>
        <mention ids_tokens="1" string="DeFronzo" id_sentence="35" />
        <mention ids_tokens="20" string="his" id_sentence="35" />
        <mention ids_tokens="27" string="DeFronzo" id_sentence="37" />
        <mention ids_tokens="29" string="he" id_sentence="39" />
        <mention ids_tokens="16" string="DeFronzo" id_sentence="40" />
        <mention ids_tokens="3" string="you" id_sentence="42" />
      </mentions>
    </coreference>
    <coreference id="20" type="PROPER">
      <referenced ids_tokens="23-24-25-26" string="the Health Science Center" id_sentence="35" />
      <mentions>
        <mention ids_tokens="29-35" string="the University of Texas Health Science Center" id_sentence="11" />
      </mentions>
    </coreference>
    <coreference id="21" type="PROPER">
      <referenced ids_tokens="8-9" string="Michael Stern" id_sentence="12" />
      <mentions>
        <mention ids_tokens="1" string="Stern" id_sentence="16" />
        <mention ids_tokens="10" string="him" id_sentence="16" />
        <mention ids_tokens="19" string="he" id_sentence="17" />
        <mention ids_tokens="1" string="Stern" id_sentence="19" />
        <mention ids_tokens="6" string="Stern" id_sentence="25" />
        <mention ids_tokens="8" string="his" id_sentence="25" />
        <mention ids_tokens="2" string="I" id_sentence="34" />
        <mention ids_tokens="9" string="me" id_sentence="34" />
        <mention ids_tokens="33-34" string="Stern's" id_sentence="35" />
      </mentions>
    </coreference>
    <coreference id="23" type="NOMINAL">
      <referenced ids_tokens="21-22-23-24-25-26-27" string="the grassroots study of Type II diabetes" id_sentence="12" />
      <mentions>
        <mention ids_tokens="1-2" string="The study" id_sentence="27" />
        <mention ids_tokens="5" string="its" id_sentence="27" />
      </mentions>
    </coreference>
    <coreference id="25" type="NOMINAL">
      <referenced ids_tokens="8-9-10-11-12-13-14-15-16-17-18" string="too much insulin because it is burning more fats than sugars" id_sentence="14" />
      <mentions>
        <mention ids_tokens="23-24" string="the insulin" id_sentence="37" />
      </mentions>
    </coreference>
    <coreference id="27" type="NOMINAL">
      <referenced ids_tokens="14-15-16-17-18-19" string="the gene that triggers the disease" id_sentence="16" />
      <mentions>
        <mention ids_tokens="5-6" string="the gene" id_sentence="23" />
      </mentions>
    </coreference>
    <coreference id="29" type="NOMINAL">
      <referenced ids_tokens="4-5-6-7-8-9-10-11-12-13-14-15-16-17-18-19-20-21-22" string="people exercised more and ate less of the fat-saturated foods common to the diets of low-income Hispanics , fewer" id_sentence="19" />
      <mentions>
        <mention ids_tokens="2" string="We" id_sentence="20" />
        <mention ids_tokens="2" string="We" id_sentence="21" />
        <mention ids_tokens="12" string="their" id_sentence="24" />
        <mention ids_tokens="19" string="that" id_sentence="24" />
      </mentions>
    </coreference>
    <coreference id="30" type="PROPER">
      <referenced ids_tokens="17-18" string="low-income Mexican-Americans" id_sentence="22" />
      <mentions>
        <mention ids_tokens="9" string="Mexican-Americans" id_sentence="20" />
        <mention ids_tokens="12" string="he" id_sentence="20" />
        <mention ids_tokens="22" string="Mexican-Americans" id_sentence="23" />
        <mention ids_tokens="4" string="Mexican-Americans" id_sentence="24" />
      </mentions>
    </coreference>
    <coreference id="31" type="NOMINAL">
      <referenced ids_tokens="3-4-5" string="the interesting thing" id_sentence="22" />
      <mentions>
        <mention ids_tokens="1" string="It" id_sentence="23" />
      </mentions>
    </coreference>
    <coreference id="34" type="NOMINAL">
      <referenced ids_tokens="31" string="doctors" id_sentence="26" />
      <mentions>
        <mention ids_tokens="8" string="they" id_sentence="31" />
        <mention ids_tokens="7" string="they" id_sentence="33" />
        <mention ids_tokens="7" string="they" id_sentence="34" />
      </mentions>
    </coreference>
    <coreference id="35" type="NOMINAL">
      <referenced ids_tokens="34-35-36-37-38" string="their risk of acquiring diabetes" id_sentence="26" />
      <mentions>
        <mention ids_tokens="19-21" string="risk of diabetes" id_sentence="29" />
      </mentions>
    </coreference>
    <coreference id="37" type="PROPER">
      <referenced ids_tokens="1-2" string="Teresa Castro" id_sentence="28" />
      <mentions>
        <mention ids_tokens="1" string="She" id_sentence="29" />
        <mention ids_tokens="7" string="her" id_sentence="29" />
        <mention ids_tokens="13" string="she" id_sentence="29" />
        <mention ids_tokens="3" string="her" id_sentence="30" />
        <mention ids_tokens="11" string="she" id_sentence="30" />
        <mention ids_tokens="28" string="she" id_sentence="32" />
      </mentions>
    </coreference>
    <coreference id="38" type="PROPER">
      <referenced ids_tokens="16-17-18-19-20" string="the screening eight years ago" id_sentence="28" />
      <mentions>
        <mention ids_tokens="5-6" string="the screening" id_sentence="31" />
        <mention ids_tokens="12" string="it" id_sentence="31" />
        <mention ids_tokens="1" string="That" id_sentence="32" />
        <mention ids_tokens="7" string="it" id_sentence="32" />
        <mention ids_tokens="25" string="it" id_sentence="33" />
      </mentions>
    </coreference>
    <coreference id="39" type="NOMINAL">
      <referenced ids_tokens="22-23-24-25" string="this type of checkup" id_sentence="32" />
      <mentions>
        <mention ids_tokens="2" string="I" id_sentence="31" />
        <mention ids_tokens="2" string="My" id_sentence="33" />
        <mention ids_tokens="9" string="me" id_sentence="33" />
        <mention ids_tokens="10" string="I" id_sentence="33" />
        <mention ids_tokens="18" string="I" id_sentence="33" />
        <mention ids_tokens="13" string="you" id_sentence="34" />
      </mentions>
    </coreference>
    <coreference id="41" type="PROPER">
      <referenced ids_tokens="5" string="1988" id_sentence="35" />
      <mentions>
        <mention ids_tokens="1" string="That" id_sentence="36" />
      </mentions>
    </coreference>
    <coreference id="42" type="NOMINAL">
      <referenced ids_tokens="31-32-33-34-35" string="many of Stern 's patients" id_sentence="35" />
      <mentions>
        <mention ids_tokens="3" string="we" id_sentence="38" />
      </mentions>
    </coreference>
    <coreference id="43" type="NOMINAL">
      <referenced ids_tokens="11-12-13-14-15-16-17-18-19-20-21-22-23-24-25" string="an anti-diabetic drug called metaforim that improves the body 's ability to respond to insulin" id_sentence="36" />
      <mentions>
        <mention ids_tokens="14-15" string="this drug" id_sentence="38" />
        <mention ids_tokens="1-2" string="The drug" id_sentence="39" />
      </mentions>
    </coreference>
    <coreference id="44" type="NOMINAL">
      <referenced ids_tokens="5-6-7" string="Type II diabetics" id_sentence="37" />
      <mentions>
        <mention ids_tokens="10" string="them" id_sentence="38" />
        <mention ids_tokens="18" string="that" id_sentence="38" />
      </mentions>
    </coreference>
    <coreference id="45" type="PRONOMINAL">
      <referenced ids_tokens="3" string="you" id_sentence="41" />
      <mentions>
        <mention ids_tokens="22" string="they" id_sentence="42" />
      </mentions>
    </coreference>
  </coreferences>
</document>
