<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="LA021689-0227">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>Ben Johnson&amp;apost;s personal physician has said the disgraced Olympic sprinter took a banned steroid on one occasion four months before the Seoul Olympics last year, the Toronto Star newspaper reported today.</content>
      <tokens>
        <token id="1" string="Ben" lemma="Ben" stem="ben" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="personal" lemma="personal" stem="person" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="physician" lemma="physician" stem="physician" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="disgraced" lemma="disgraced" stem="disgrac" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="Olympic" lemma="Olympic" stem="olympic" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="11" string="sprinter" lemma="sprinter" stem="sprinter" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="took" lemma="take" stem="took" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="banned" lemma="ban" stem="ban" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="steroid" lemma="steroid" stem="steroid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="18" string="occasion" lemma="occasion" stem="occas" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="four" lemma="four" stem="four" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="20" string="months" lemma="month" stem="month" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="21" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="Seoul" lemma="Seoul" stem="seoul" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="24" string="Olympics" lemma="Olympics" stem="olympic" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="25" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="26" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="27" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="29" string="Toronto" lemma="Toronto" stem="toronto" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="30" string="Star" lemma="Star" stem="star" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="31" string="newspaper" lemma="newspaper" stem="newspap" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string="reported" lemma="report" stem="report" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="today" lemma="today" stem="todai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="34" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (NNP Ben) (NNP Johnson) (POS 's)) (JJ personal) (NN physician)) (VP (VBZ has) (VP (VBD said) (SBAR (S (NP (DT the) (JJ disgraced) (NNP Olympic) (NN sprinter)) (VP (VBD took) (NP (DT a) (VBN banned) (NN steroid)) (PP (IN on) (NP (NP (CD one) (NN occasion)) (NP-TMP (CD four) (NNS months)))) (PP (IN before) (NP (DT the) (NNP Seoul) (NNPS Olympics))) (NP-TMP (JJ last) (NN year)))))))) (, ,) (NP (DT the) (NNP Toronto) (NNP Star) (NN newspaper)) (VP (VBD reported) (NP-TMP (NN today))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the disgraced Olympic sprinter" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="disgraced" />
            <token id="10" string="Olympic" />
            <token id="11" string="sprinter" />
          </tokens>
        </chunking>
        <chunking id="2" string="said the disgraced Olympic sprinter took a banned steroid on one occasion four months before the Seoul Olympics last year" type="VP">
          <tokens>
            <token id="7" string="said" />
            <token id="8" string="the" />
            <token id="9" string="disgraced" />
            <token id="10" string="Olympic" />
            <token id="11" string="sprinter" />
            <token id="12" string="took" />
            <token id="13" string="a" />
            <token id="14" string="banned" />
            <token id="15" string="steroid" />
            <token id="16" string="on" />
            <token id="17" string="one" />
            <token id="18" string="occasion" />
            <token id="19" string="four" />
            <token id="20" string="months" />
            <token id="21" string="before" />
            <token id="22" string="the" />
            <token id="23" string="Seoul" />
            <token id="24" string="Olympics" />
            <token id="25" string="last" />
            <token id="26" string="year" />
          </tokens>
        </chunking>
        <chunking id="3" string="took a banned steroid on one occasion four months before the Seoul Olympics last year" type="VP">
          <tokens>
            <token id="12" string="took" />
            <token id="13" string="a" />
            <token id="14" string="banned" />
            <token id="15" string="steroid" />
            <token id="16" string="on" />
            <token id="17" string="one" />
            <token id="18" string="occasion" />
            <token id="19" string="four" />
            <token id="20" string="months" />
            <token id="21" string="before" />
            <token id="22" string="the" />
            <token id="23" string="Seoul" />
            <token id="24" string="Olympics" />
            <token id="25" string="last" />
            <token id="26" string="year" />
          </tokens>
        </chunking>
        <chunking id="4" string="the Seoul Olympics" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="Seoul" />
            <token id="24" string="Olympics" />
          </tokens>
        </chunking>
        <chunking id="5" string="a banned steroid" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="banned" />
            <token id="15" string="steroid" />
          </tokens>
        </chunking>
        <chunking id="6" string="one occasion four months" type="NP">
          <tokens>
            <token id="17" string="one" />
            <token id="18" string="occasion" />
            <token id="19" string="four" />
            <token id="20" string="months" />
          </tokens>
        </chunking>
        <chunking id="7" string="Ben Johnson 's personal physician" type="NP">
          <tokens>
            <token id="1" string="Ben" />
            <token id="2" string="Johnson" />
            <token id="3" string="'s" />
            <token id="4" string="personal" />
            <token id="5" string="physician" />
          </tokens>
        </chunking>
        <chunking id="8" string="the Toronto Star newspaper" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="Toronto" />
            <token id="30" string="Star" />
            <token id="31" string="newspaper" />
          </tokens>
        </chunking>
        <chunking id="9" string="reported today" type="VP">
          <tokens>
            <token id="32" string="reported" />
            <token id="33" string="today" />
          </tokens>
        </chunking>
        <chunking id="10" string="one occasion" type="NP">
          <tokens>
            <token id="17" string="one" />
            <token id="18" string="occasion" />
          </tokens>
        </chunking>
        <chunking id="11" string="Ben Johnson 's" type="NP">
          <tokens>
            <token id="1" string="Ben" />
            <token id="2" string="Johnson" />
            <token id="3" string="'s" />
          </tokens>
        </chunking>
        <chunking id="12" string="has said the disgraced Olympic sprinter took a banned steroid on one occasion four months before the Seoul Olympics last year" type="VP">
          <tokens>
            <token id="6" string="has" />
            <token id="7" string="said" />
            <token id="8" string="the" />
            <token id="9" string="disgraced" />
            <token id="10" string="Olympic" />
            <token id="11" string="sprinter" />
            <token id="12" string="took" />
            <token id="13" string="a" />
            <token id="14" string="banned" />
            <token id="15" string="steroid" />
            <token id="16" string="on" />
            <token id="17" string="one" />
            <token id="18" string="occasion" />
            <token id="19" string="four" />
            <token id="20" string="months" />
            <token id="21" string="before" />
            <token id="22" string="the" />
            <token id="23" string="Seoul" />
            <token id="24" string="Olympics" />
            <token id="25" string="last" />
            <token id="26" string="year" />
          </tokens>
        </chunking>
        <chunking id="13" string="the disgraced Olympic sprinter took a banned steroid on one occasion four months before the Seoul Olympics last year" type="SBAR">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="disgraced" />
            <token id="10" string="Olympic" />
            <token id="11" string="sprinter" />
            <token id="12" string="took" />
            <token id="13" string="a" />
            <token id="14" string="banned" />
            <token id="15" string="steroid" />
            <token id="16" string="on" />
            <token id="17" string="one" />
            <token id="18" string="occasion" />
            <token id="19" string="four" />
            <token id="20" string="months" />
            <token id="21" string="before" />
            <token id="22" string="the" />
            <token id="23" string="Seoul" />
            <token id="24" string="Olympics" />
            <token id="25" string="last" />
            <token id="26" string="year" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Johnson</governor>
          <dependent id="1">Ben</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">physician</governor>
          <dependent id="2">Johnson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="2">Johnson</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">physician</governor>
          <dependent id="4">personal</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">said</governor>
          <dependent id="5">physician</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">said</governor>
          <dependent id="6">has</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="32">reported</governor>
          <dependent id="7">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">sprinter</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">sprinter</governor>
          <dependent id="9">disgraced</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">sprinter</governor>
          <dependent id="10">Olympic</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">took</governor>
          <dependent id="11">sprinter</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">said</governor>
          <dependent id="12">took</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">steroid</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">steroid</governor>
          <dependent id="14">banned</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">took</governor>
          <dependent id="15">steroid</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">occasion</governor>
          <dependent id="16">on</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="18">occasion</governor>
          <dependent id="17">one</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">took</governor>
          <dependent id="18">occasion</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="20">months</governor>
          <dependent id="19">four</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="18">occasion</governor>
          <dependent id="20">months</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">Olympics</governor>
          <dependent id="21">before</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">Olympics</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">Olympics</governor>
          <dependent id="23">Seoul</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">took</governor>
          <dependent id="24">Olympics</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">year</governor>
          <dependent id="25">last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="12">took</governor>
          <dependent id="26">year</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">newspaper</governor>
          <dependent id="28">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">newspaper</governor>
          <dependent id="29">Toronto</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">newspaper</governor>
          <dependent id="30">Star</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="32">reported</governor>
          <dependent id="31">newspaper</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="32">reported</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="32">reported</governor>
          <dependent id="33">today</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ben Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Ben" />
            <token id="2" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="Seoul" type="LOCATION" score="0.0">
          <tokens>
            <token id="23" string="Seoul" />
          </tokens>
        </entity>
        <entity id="3" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="17" string="one" />
          </tokens>
        </entity>
        <entity id="4" string="Olympics" type="MISC" score="0.0">
          <tokens>
            <token id="24" string="Olympics" />
          </tokens>
        </entity>
        <entity id="5" string="today" type="DATE" score="0.0">
          <tokens>
            <token id="33" string="today" />
          </tokens>
        </entity>
        <entity id="6" string="four months" type="DURATION" score="0.0">
          <tokens>
            <token id="19" string="four" />
            <token id="20" string="months" />
          </tokens>
        </entity>
        <entity id="7" string="Olympic" type="MISC" score="0.0">
          <tokens>
            <token id="10" string="Olympic" />
          </tokens>
        </entity>
        <entity id="8" string="Toronto Star" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="29" string="Toronto" />
            <token id="30" string="Star" />
          </tokens>
        </entity>
        <entity id="9" string="last year" type="DATE" score="0.0">
          <tokens>
            <token id="25" string="last" />
            <token id="26" string="year" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>Dr. Jamie Astaphan, in a telephone interview from the Caribbean island of St. Kitts, said Johnson was depressed last May by a hamstring injury that threatened to end his rivalry against Carl Lewis for the 100 meters Olympics gold medal.</content>
      <tokens>
        <token id="1" string="Dr." lemma="Dr." stem="dr." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="Jamie" lemma="Jamie" stem="jami" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="Astaphan" lemma="Astaphan" stem="astaphan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="telephone" lemma="telephone" stem="telephon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="interview" lemma="interview" stem="interview" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="Caribbean" lemma="Caribbean" stem="caribbean" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="12" string="island" lemma="island" stem="island" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="St." lemma="St." stem="st." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="15" string="Kitts" lemma="Kitts" stem="kitt" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="19" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="depressed" lemma="depress" stem="depress" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="22" string="May" lemma="May" stem="mai" pos="NNP" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="23" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="hamstring" lemma="hamstring" stem="hamstr" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="injury" lemma="injury" stem="injuri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="threatened" lemma="threaten" stem="threaten" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="end" lemma="end" stem="end" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="32" string="rivalry" lemma="rivalry" stem="rivalri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="Carl" lemma="Carl" stem="carl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="35" string="Lewis" lemma="Lewis" stem="lewi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="36" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="100" lemma="100" stem="100" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="39" string="meters" lemma="meter" stem="meter" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="Olympics" lemma="Olympics" stem="olympic" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="41" string="gold" lemma="gold" stem="gold" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="42" string="medal" lemma="medal" stem="medal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="43" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Dr.) (NNP Jamie) (NNP Astaphan)) (, ,) (PP (IN in) (NP (NP (DT a) (NN telephone) (NN interview)) (PP (IN from) (NP (NP (DT the) (NNP Caribbean) (NN island)) (PP (IN of) (NP (NNP St.) (NNP Kitts))))))) (, ,) (VP (VBD said) (SBAR (S (NP (NNP Johnson)) (VP (VBD was) (VP (VBN depressed) (NP-TMP (JJ last) (NNP May)) (PP (IN by) (NP (NP (DT a) (NN hamstring) (NN injury)) (SBAR (WHNP (WDT that)) (S (VP (VBD threatened) (S (VP (TO to) (VP (VB end) (NP (PRP$ his) (NN rivalry)) (PP (IN against) (NP (NP (NNP Carl) (NNP Lewis)) (PP (IN for) (NP (DT the) (CD 100) (NNS meters)))))))))))))))))) (NP (NP (NNPS Olympics)) (NP (NN gold) (NN medal))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Johnson" type="NP">
          <tokens>
            <token id="18" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="2" string="depressed last May by a hamstring injury that threatened to end his rivalry against Carl Lewis for the 100 meters" type="VP">
          <tokens>
            <token id="20" string="depressed" />
            <token id="21" string="last" />
            <token id="22" string="May" />
            <token id="23" string="by" />
            <token id="24" string="a" />
            <token id="25" string="hamstring" />
            <token id="26" string="injury" />
            <token id="27" string="that" />
            <token id="28" string="threatened" />
            <token id="29" string="to" />
            <token id="30" string="end" />
            <token id="31" string="his" />
            <token id="32" string="rivalry" />
            <token id="33" string="against" />
            <token id="34" string="Carl" />
            <token id="35" string="Lewis" />
            <token id="36" string="for" />
            <token id="37" string="the" />
            <token id="38" string="100" />
            <token id="39" string="meters" />
          </tokens>
        </chunking>
        <chunking id="3" string="St. Kitts" type="NP">
          <tokens>
            <token id="14" string="St." />
            <token id="15" string="Kitts" />
          </tokens>
        </chunking>
        <chunking id="4" string="a hamstring injury that threatened to end his rivalry against Carl Lewis for the 100 meters" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="hamstring" />
            <token id="26" string="injury" />
            <token id="27" string="that" />
            <token id="28" string="threatened" />
            <token id="29" string="to" />
            <token id="30" string="end" />
            <token id="31" string="his" />
            <token id="32" string="rivalry" />
            <token id="33" string="against" />
            <token id="34" string="Carl" />
            <token id="35" string="Lewis" />
            <token id="36" string="for" />
            <token id="37" string="the" />
            <token id="38" string="100" />
            <token id="39" string="meters" />
          </tokens>
        </chunking>
        <chunking id="5" string="Olympics gold medal" type="NP">
          <tokens>
            <token id="40" string="Olympics" />
            <token id="41" string="gold" />
            <token id="42" string="medal" />
          </tokens>
        </chunking>
        <chunking id="6" string="gold medal" type="NP">
          <tokens>
            <token id="41" string="gold" />
            <token id="42" string="medal" />
          </tokens>
        </chunking>
        <chunking id="7" string="the 100 meters" type="NP">
          <tokens>
            <token id="37" string="the" />
            <token id="38" string="100" />
            <token id="39" string="meters" />
          </tokens>
        </chunking>
        <chunking id="8" string="Dr. Jamie Astaphan" type="NP">
          <tokens>
            <token id="1" string="Dr." />
            <token id="2" string="Jamie" />
            <token id="3" string="Astaphan" />
          </tokens>
        </chunking>
        <chunking id="9" string="threatened to end his rivalry against Carl Lewis for the 100 meters" type="VP">
          <tokens>
            <token id="28" string="threatened" />
            <token id="29" string="to" />
            <token id="30" string="end" />
            <token id="31" string="his" />
            <token id="32" string="rivalry" />
            <token id="33" string="against" />
            <token id="34" string="Carl" />
            <token id="35" string="Lewis" />
            <token id="36" string="for" />
            <token id="37" string="the" />
            <token id="38" string="100" />
            <token id="39" string="meters" />
          </tokens>
        </chunking>
        <chunking id="10" string="his rivalry" type="NP">
          <tokens>
            <token id="31" string="his" />
            <token id="32" string="rivalry" />
          </tokens>
        </chunking>
        <chunking id="11" string="Carl Lewis for the 100 meters" type="NP">
          <tokens>
            <token id="34" string="Carl" />
            <token id="35" string="Lewis" />
            <token id="36" string="for" />
            <token id="37" string="the" />
            <token id="38" string="100" />
            <token id="39" string="meters" />
          </tokens>
        </chunking>
        <chunking id="12" string="a hamstring injury" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="hamstring" />
            <token id="26" string="injury" />
          </tokens>
        </chunking>
        <chunking id="13" string="a telephone interview" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="telephone" />
            <token id="8" string="interview" />
          </tokens>
        </chunking>
        <chunking id="14" string="that threatened to end his rivalry against Carl Lewis for the 100 meters" type="SBAR">
          <tokens>
            <token id="27" string="that" />
            <token id="28" string="threatened" />
            <token id="29" string="to" />
            <token id="30" string="end" />
            <token id="31" string="his" />
            <token id="32" string="rivalry" />
            <token id="33" string="against" />
            <token id="34" string="Carl" />
            <token id="35" string="Lewis" />
            <token id="36" string="for" />
            <token id="37" string="the" />
            <token id="38" string="100" />
            <token id="39" string="meters" />
          </tokens>
        </chunking>
        <chunking id="15" string="a telephone interview from the Caribbean island of St. Kitts" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="telephone" />
            <token id="8" string="interview" />
            <token id="9" string="from" />
            <token id="10" string="the" />
            <token id="11" string="Caribbean" />
            <token id="12" string="island" />
            <token id="13" string="of" />
            <token id="14" string="St." />
            <token id="15" string="Kitts" />
          </tokens>
        </chunking>
        <chunking id="16" string="was depressed last May by a hamstring injury that threatened to end his rivalry against Carl Lewis for the 100 meters" type="VP">
          <tokens>
            <token id="19" string="was" />
            <token id="20" string="depressed" />
            <token id="21" string="last" />
            <token id="22" string="May" />
            <token id="23" string="by" />
            <token id="24" string="a" />
            <token id="25" string="hamstring" />
            <token id="26" string="injury" />
            <token id="27" string="that" />
            <token id="28" string="threatened" />
            <token id="29" string="to" />
            <token id="30" string="end" />
            <token id="31" string="his" />
            <token id="32" string="rivalry" />
            <token id="33" string="against" />
            <token id="34" string="Carl" />
            <token id="35" string="Lewis" />
            <token id="36" string="for" />
            <token id="37" string="the" />
            <token id="38" string="100" />
            <token id="39" string="meters" />
          </tokens>
        </chunking>
        <chunking id="17" string="end his rivalry against Carl Lewis for the 100 meters" type="VP">
          <tokens>
            <token id="30" string="end" />
            <token id="31" string="his" />
            <token id="32" string="rivalry" />
            <token id="33" string="against" />
            <token id="34" string="Carl" />
            <token id="35" string="Lewis" />
            <token id="36" string="for" />
            <token id="37" string="the" />
            <token id="38" string="100" />
            <token id="39" string="meters" />
          </tokens>
        </chunking>
        <chunking id="18" string="the Caribbean island of St. Kitts" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="Caribbean" />
            <token id="12" string="island" />
            <token id="13" string="of" />
            <token id="14" string="St." />
            <token id="15" string="Kitts" />
          </tokens>
        </chunking>
        <chunking id="19" string="to end his rivalry against Carl Lewis for the 100 meters" type="VP">
          <tokens>
            <token id="29" string="to" />
            <token id="30" string="end" />
            <token id="31" string="his" />
            <token id="32" string="rivalry" />
            <token id="33" string="against" />
            <token id="34" string="Carl" />
            <token id="35" string="Lewis" />
            <token id="36" string="for" />
            <token id="37" string="the" />
            <token id="38" string="100" />
            <token id="39" string="meters" />
          </tokens>
        </chunking>
        <chunking id="20" string="Olympics" type="NP">
          <tokens>
            <token id="40" string="Olympics" />
          </tokens>
        </chunking>
        <chunking id="21" string="Johnson was depressed last May by a hamstring injury that threatened to end his rivalry against Carl Lewis for the 100 meters" type="SBAR">
          <tokens>
            <token id="18" string="Johnson" />
            <token id="19" string="was" />
            <token id="20" string="depressed" />
            <token id="21" string="last" />
            <token id="22" string="May" />
            <token id="23" string="by" />
            <token id="24" string="a" />
            <token id="25" string="hamstring" />
            <token id="26" string="injury" />
            <token id="27" string="that" />
            <token id="28" string="threatened" />
            <token id="29" string="to" />
            <token id="30" string="end" />
            <token id="31" string="his" />
            <token id="32" string="rivalry" />
            <token id="33" string="against" />
            <token id="34" string="Carl" />
            <token id="35" string="Lewis" />
            <token id="36" string="for" />
            <token id="37" string="the" />
            <token id="38" string="100" />
            <token id="39" string="meters" />
          </tokens>
        </chunking>
        <chunking id="22" string="Carl Lewis" type="NP">
          <tokens>
            <token id="34" string="Carl" />
            <token id="35" string="Lewis" />
          </tokens>
        </chunking>
        <chunking id="23" string="said Johnson was depressed last May by a hamstring injury that threatened to end his rivalry against Carl Lewis for the 100 meters" type="VP">
          <tokens>
            <token id="17" string="said" />
            <token id="18" string="Johnson" />
            <token id="19" string="was" />
            <token id="20" string="depressed" />
            <token id="21" string="last" />
            <token id="22" string="May" />
            <token id="23" string="by" />
            <token id="24" string="a" />
            <token id="25" string="hamstring" />
            <token id="26" string="injury" />
            <token id="27" string="that" />
            <token id="28" string="threatened" />
            <token id="29" string="to" />
            <token id="30" string="end" />
            <token id="31" string="his" />
            <token id="32" string="rivalry" />
            <token id="33" string="against" />
            <token id="34" string="Carl" />
            <token id="35" string="Lewis" />
            <token id="36" string="for" />
            <token id="37" string="the" />
            <token id="38" string="100" />
            <token id="39" string="meters" />
          </tokens>
        </chunking>
        <chunking id="24" string="the Caribbean island" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="Caribbean" />
            <token id="12" string="island" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Astaphan</governor>
          <dependent id="1">Dr.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Astaphan</governor>
          <dependent id="2">Jamie</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">said</governor>
          <dependent id="3">Astaphan</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">interview</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">interview</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">interview</governor>
          <dependent id="7">telephone</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">said</governor>
          <dependent id="8">interview</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">island</governor>
          <dependent id="9">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">island</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">island</governor>
          <dependent id="11">Caribbean</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">interview</governor>
          <dependent id="12">island</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">Kitts</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Kitts</governor>
          <dependent id="14">St.</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">island</governor>
          <dependent id="15">Kitts</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">said</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="20">depressed</governor>
          <dependent id="18">Johnson</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="20">depressed</governor>
          <dependent id="19">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">said</governor>
          <dependent id="20">depressed</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">May</governor>
          <dependent id="21">last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="20">depressed</governor>
          <dependent id="22">May</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">injury</governor>
          <dependent id="23">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">injury</governor>
          <dependent id="24">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">injury</governor>
          <dependent id="25">hamstring</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">depressed</governor>
          <dependent id="26">injury</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">threatened</governor>
          <dependent id="27">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="26">injury</governor>
          <dependent id="28">threatened</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="30">end</governor>
          <dependent id="29">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="28">threatened</governor>
          <dependent id="30">end</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="32">rivalry</governor>
          <dependent id="31">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="30">end</governor>
          <dependent id="32">rivalry</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">Lewis</governor>
          <dependent id="33">against</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">Lewis</governor>
          <dependent id="34">Carl</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">end</governor>
          <dependent id="35">Lewis</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">meters</governor>
          <dependent id="36">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="39">meters</governor>
          <dependent id="37">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="39">meters</governor>
          <dependent id="38">100</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="35">Lewis</governor>
          <dependent id="39">meters</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="17">said</governor>
          <dependent id="40">Olympics</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="42">medal</governor>
          <dependent id="41">gold</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="40">Olympics</governor>
          <dependent id="42">medal</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="100" type="NUMBER" score="0.0">
          <tokens>
            <token id="38" string="100" />
          </tokens>
        </entity>
        <entity id="2" string="Jamie Astaphan" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Jamie" />
            <token id="3" string="Astaphan" />
          </tokens>
        </entity>
        <entity id="3" string="last May" type="DATE" score="0.0">
          <tokens>
            <token id="21" string="last" />
            <token id="22" string="May" />
          </tokens>
        </entity>
        <entity id="4" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Johnson" />
          </tokens>
        </entity>
        <entity id="5" string="St. Kitts" type="LOCATION" score="0.0">
          <tokens>
            <token id="14" string="St." />
            <token id="15" string="Kitts" />
          </tokens>
        </entity>
        <entity id="6" string="Olympics" type="MISC" score="0.0">
          <tokens>
            <token id="40" string="Olympics" />
          </tokens>
        </entity>
        <entity id="7" string="Carl Lewis" type="PERSON" score="0.0">
          <tokens>
            <token id="34" string="Carl" />
            <token id="35" string="Lewis" />
          </tokens>
        </entity>
        <entity id="8" string="Caribbean" type="LOCATION" score="0.0">
          <tokens>
            <token id="11" string="Caribbean" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>&amp;quot;He bought stanozolol or somebody bought it for him in Toronto,&amp;quot; Astaphan told the newspaper.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="bought" lemma="buy" stem="bought" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="stanozolol" lemma="stanozolol" stem="stanozolol" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="somebody" lemma="somebody" stem="somebodi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="bought" lemma="buy" stem="bought" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Toronto" lemma="Toronto" stem="toronto" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Astaphan" lemma="Astaphan" stem="astaphan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="16" string="told" lemma="tell" stem="told" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="newspaper" lemma="newspaper" stem="newspap" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP He)) (VP (VBD bought) (SBAR (S (NP (NN stanozolol) (CC or) (NN somebody)) (VP (VBD bought) (NP (PRP it)) (PP (IN for) (NP (PRP him))) (PP (IN in) (NP (NNP Toronto)))))))) (, ,) ('' '') (NP (NNP Astaphan)) (VP (VBD told) (NP (DT the) (NN newspaper))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="bought stanozolol or somebody bought it for him in Toronto" type="VP">
          <tokens>
            <token id="3" string="bought" />
            <token id="4" string="stanozolol" />
            <token id="5" string="or" />
            <token id="6" string="somebody" />
            <token id="7" string="bought" />
            <token id="8" string="it" />
            <token id="9" string="for" />
            <token id="10" string="him" />
            <token id="11" string="in" />
            <token id="12" string="Toronto" />
          </tokens>
        </chunking>
        <chunking id="2" string="bought it for him in Toronto" type="VP">
          <tokens>
            <token id="7" string="bought" />
            <token id="8" string="it" />
            <token id="9" string="for" />
            <token id="10" string="him" />
            <token id="11" string="in" />
            <token id="12" string="Toronto" />
          </tokens>
        </chunking>
        <chunking id="3" string="Astaphan" type="NP">
          <tokens>
            <token id="15" string="Astaphan" />
          </tokens>
        </chunking>
        <chunking id="4" string="the newspaper" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="newspaper" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="8" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="him" type="NP">
          <tokens>
            <token id="10" string="him" />
          </tokens>
        </chunking>
        <chunking id="7" string="told the newspaper" type="VP">
          <tokens>
            <token id="16" string="told" />
            <token id="17" string="the" />
            <token id="18" string="newspaper" />
          </tokens>
        </chunking>
        <chunking id="8" string="He" type="NP">
          <tokens>
            <token id="2" string="He" />
          </tokens>
        </chunking>
        <chunking id="9" string="stanozolol or somebody" type="NP">
          <tokens>
            <token id="4" string="stanozolol" />
            <token id="5" string="or" />
            <token id="6" string="somebody" />
          </tokens>
        </chunking>
        <chunking id="10" string="stanozolol or somebody bought it for him in Toronto" type="SBAR">
          <tokens>
            <token id="4" string="stanozolol" />
            <token id="5" string="or" />
            <token id="6" string="somebody" />
            <token id="7" string="bought" />
            <token id="8" string="it" />
            <token id="9" string="for" />
            <token id="10" string="him" />
            <token id="11" string="in" />
            <token id="12" string="Toronto" />
          </tokens>
        </chunking>
        <chunking id="11" string="Toronto" type="NP">
          <tokens>
            <token id="12" string="Toronto" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">bought</governor>
          <dependent id="2">He</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">told</governor>
          <dependent id="3">bought</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">bought</governor>
          <dependent id="4">stanozolol</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">stanozolol</governor>
          <dependent id="5">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">stanozolol</governor>
          <dependent id="6">somebody</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">bought</governor>
          <dependent id="7">bought</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">bought</governor>
          <dependent id="8">it</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">him</governor>
          <dependent id="9">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">bought</governor>
          <dependent id="10">him</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Toronto</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">bought</governor>
          <dependent id="12">Toronto</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">told</governor>
          <dependent id="15">Astaphan</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">told</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">newspaper</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">told</governor>
          <dependent id="18">newspaper</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Astaphan" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="Astaphan" />
          </tokens>
        </entity>
        <entity id="2" string="Toronto" type="LOCATION" score="0.0">
          <tokens>
            <token id="12" string="Toronto" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>But immediately after taking it Johnson suffered &amp;quot;violent muscle spasms.&amp;quot;</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="immediately" lemma="immediately" stem="immedi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="taking" lemma="take" stem="take" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="suffered" lemma="suffer" stem="suffer" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="violent" lemma="violent" stem="violent" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="muscle" lemma="muscle" stem="muscl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="spasms" lemma="spasm" stem="spasm" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (PP (ADVP (RB immediately)) (IN after) (S (VP (VBG taking) (NP (PRP it))))) (NP (NNP Johnson)) (VP (VBD suffered) (`` ``) (NP (JJ violent) (NN muscle) (NNS spasms))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="Johnson" type="NP">
          <tokens>
            <token id="6" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="2" string="suffered `` violent muscle spasms" type="VP">
          <tokens>
            <token id="7" string="suffered" />
            <token id="8" string="&quot;" />
            <token id="9" string="violent" />
            <token id="10" string="muscle" />
            <token id="11" string="spasms" />
          </tokens>
        </chunking>
        <chunking id="3" string="it" type="NP">
          <tokens>
            <token id="5" string="it" />
          </tokens>
        </chunking>
        <chunking id="4" string="violent muscle spasms" type="NP">
          <tokens>
            <token id="9" string="violent" />
            <token id="10" string="muscle" />
            <token id="11" string="spasms" />
          </tokens>
        </chunking>
        <chunking id="5" string="taking it" type="VP">
          <tokens>
            <token id="4" string="taking" />
            <token id="5" string="it" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="7">suffered</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">taking</governor>
          <dependent id="2">immediately</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="4">taking</governor>
          <dependent id="3">after</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">suffered</governor>
          <dependent id="4">taking</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">taking</governor>
          <dependent id="5">it</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">suffered</governor>
          <dependent id="6">Johnson</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">suffered</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">spasms</governor>
          <dependent id="9">violent</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">spasms</governor>
          <dependent id="10">muscle</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">suffered</governor>
          <dependent id="11">spasms</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Johnson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>&amp;quot;He was immediately brought to me and I nursed him back to top condition,&amp;quot; he said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="immediately" lemma="immediately" stem="immedi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="brought" lemma="bring" stem="brought" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="nursed" lemma="nurse" stem="nurs" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="back" lemma="back" stem="back" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="top" lemma="top" stem="top" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="condition" lemma="condition" stem="condit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (S (NP (PRP He)) (VP (VBD was) (ADVP (RB immediately)) (VP (VBN brought) (PP (TO to) (NP (PRP me)))))) (CC and) (S (NP (PRP I)) (VP (VBD nursed) (NP (PRP him)) (ADVP (RB back)) (PP (TO to) (NP (JJ top) (NN condition)))))) (, ,) ('' '') (NP (PRP he)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was immediately brought to me" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="immediately" />
            <token id="5" string="brought" />
            <token id="6" string="to" />
            <token id="7" string="me" />
          </tokens>
        </chunking>
        <chunking id="2" string="nursed him back to top condition" type="VP">
          <tokens>
            <token id="10" string="nursed" />
            <token id="11" string="him" />
            <token id="12" string="back" />
            <token id="13" string="to" />
            <token id="14" string="top" />
            <token id="15" string="condition" />
          </tokens>
        </chunking>
        <chunking id="3" string="top condition" type="NP">
          <tokens>
            <token id="14" string="top" />
            <token id="15" string="condition" />
          </tokens>
        </chunking>
        <chunking id="4" string="me" type="NP">
          <tokens>
            <token id="7" string="me" />
          </tokens>
        </chunking>
        <chunking id="5" string="I" type="NP">
          <tokens>
            <token id="9" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="him" type="NP">
          <tokens>
            <token id="11" string="him" />
          </tokens>
        </chunking>
        <chunking id="7" string="He" type="NP">
          <tokens>
            <token id="2" string="He" />
          </tokens>
        </chunking>
        <chunking id="8" string="he" type="NP">
          <tokens>
            <token id="18" string="he" />
          </tokens>
        </chunking>
        <chunking id="9" string="brought to me" type="VP">
          <tokens>
            <token id="5" string="brought" />
            <token id="6" string="to" />
            <token id="7" string="me" />
          </tokens>
        </chunking>
        <chunking id="10" string="said" type="VP">
          <tokens>
            <token id="19" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="5">brought</governor>
          <dependent id="2">He</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">brought</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">brought</governor>
          <dependent id="4">immediately</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">said</governor>
          <dependent id="5">brought</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">me</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">brought</governor>
          <dependent id="7">me</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">brought</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">nursed</governor>
          <dependent id="9">I</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">brought</governor>
          <dependent id="10">nursed</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">nursed</governor>
          <dependent id="11">him</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">nursed</governor>
          <dependent id="12">back</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">condition</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">condition</governor>
          <dependent id="14">top</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">nursed</governor>
          <dependent id="15">condition</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">said</governor>
          <dependent id="18">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="19">said</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>Astaphan said Johnson was not on stanozolol when he beat Lewis in a world-record time of 9.79 seconds for the 100 meters gold, a medal taken away from him when he then tested positive for stanozolol use by Olympics officials.</content>
      <tokens>
        <token id="1" string="Astaphan" lemma="Astaphan" stem="astaphan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="stanozolol" lemma="stanozolol" stem="stanozolol" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="beat" lemma="beat" stem="beat" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="Lewis" lemma="Lewis" stem="lewi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="12" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="world-record" lemma="world-record" stem="world-record" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="9.79" lemma="9.79" stem="9.79" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="18" string="seconds" lemma="seconds" stem="second" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="19" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="100" lemma="100" stem="100" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="22" string="meters" lemma="meter" stem="meter" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="gold" lemma="gold" stem="gold" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="medal" lemma="medal" stem="medal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="taken" lemma="take" stem="taken" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="away" lemma="away" stem="awai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="33" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="tested" lemma="test" stem="test" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="positive" lemma="positive" stem="posit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="stanozolol" lemma="stanozolol" stem="stanozolol" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="use" lemma="use" stem="us" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="Olympics" lemma="Olympics" stem="olympic" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="41" string="officials" lemma="official" stem="offici" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="42" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Astaphan)) (VP (VBD said) (SBAR (S (NP (NNP Johnson)) (VP (VBD was) (RB not) (PP (IN on) (NP (NN stanozolol))) (SBAR (WHADVP (WRB when)) (S (NP (PRP he)) (VP (VBD beat) (NP (NP (NNP Lewis)) (PP (IN in) (NP (NP (DT a) (JJ world-record) (NN time)) (PP (IN of) (NP (CD 9.79) (NNS seconds)))))) (PP (IN for) (NP (NP (DT the) (CD 100) (NNS meters) (NN gold)) (, ,) (NP (NP (DT a) (NN medal)) (VP (VBN taken) (ADVP (RB away)) (PP (IN from) (NP (PRP him))) (SBAR (WHADVP (WRB when)) (S (NP (PRP he)) (ADVP (RB then)) (VP (VBD tested) (ADJP (JJ positive) (PP (IN for) (NP (NN stanozolol) (NN use)))) (PP (IN by) (NP (NNPS Olympics) (NNS officials))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="when he then tested positive for stanozolol use by Olympics officials" type="SBAR">
          <tokens>
            <token id="31" string="when" />
            <token id="32" string="he" />
            <token id="33" string="then" />
            <token id="34" string="tested" />
            <token id="35" string="positive" />
            <token id="36" string="for" />
            <token id="37" string="stanozolol" />
            <token id="38" string="use" />
            <token id="39" string="by" />
            <token id="40" string="Olympics" />
            <token id="41" string="officials" />
          </tokens>
        </chunking>
        <chunking id="2" string="stanozolol use" type="NP">
          <tokens>
            <token id="37" string="stanozolol" />
            <token id="38" string="use" />
          </tokens>
        </chunking>
        <chunking id="3" string="Olympics officials" type="NP">
          <tokens>
            <token id="40" string="Olympics" />
            <token id="41" string="officials" />
          </tokens>
        </chunking>
        <chunking id="4" string="Johnson" type="NP">
          <tokens>
            <token id="3" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="5" string="stanozolol" type="NP">
          <tokens>
            <token id="7" string="stanozolol" />
          </tokens>
        </chunking>
        <chunking id="6" string="taken away from him when he then tested positive for stanozolol use by Olympics officials" type="VP">
          <tokens>
            <token id="27" string="taken" />
            <token id="28" string="away" />
            <token id="29" string="from" />
            <token id="30" string="him" />
            <token id="31" string="when" />
            <token id="32" string="he" />
            <token id="33" string="then" />
            <token id="34" string="tested" />
            <token id="35" string="positive" />
            <token id="36" string="for" />
            <token id="37" string="stanozolol" />
            <token id="38" string="use" />
            <token id="39" string="by" />
            <token id="40" string="Olympics" />
            <token id="41" string="officials" />
          </tokens>
        </chunking>
        <chunking id="7" string="9.79 seconds" type="NP">
          <tokens>
            <token id="17" string="9.79" />
            <token id="18" string="seconds" />
          </tokens>
        </chunking>
        <chunking id="8" string="the 100 meters gold" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="100" />
            <token id="22" string="meters" />
            <token id="23" string="gold" />
          </tokens>
        </chunking>
        <chunking id="9" string="Johnson was not on stanozolol when he beat Lewis in a world-record time of 9.79 seconds for the 100 meters gold , a medal taken away from him when he then tested positive for stanozolol use by Olympics officials" type="SBAR">
          <tokens>
            <token id="3" string="Johnson" />
            <token id="4" string="was" />
            <token id="5" string="not" />
            <token id="6" string="on" />
            <token id="7" string="stanozolol" />
            <token id="8" string="when" />
            <token id="9" string="he" />
            <token id="10" string="beat" />
            <token id="11" string="Lewis" />
            <token id="12" string="in" />
            <token id="13" string="a" />
            <token id="14" string="world-record" />
            <token id="15" string="time" />
            <token id="16" string="of" />
            <token id="17" string="9.79" />
            <token id="18" string="seconds" />
            <token id="19" string="for" />
            <token id="20" string="the" />
            <token id="21" string="100" />
            <token id="22" string="meters" />
            <token id="23" string="gold" />
            <token id="24" string="," />
            <token id="25" string="a" />
            <token id="26" string="medal" />
            <token id="27" string="taken" />
            <token id="28" string="away" />
            <token id="29" string="from" />
            <token id="30" string="him" />
            <token id="31" string="when" />
            <token id="32" string="he" />
            <token id="33" string="then" />
            <token id="34" string="tested" />
            <token id="35" string="positive" />
            <token id="36" string="for" />
            <token id="37" string="stanozolol" />
            <token id="38" string="use" />
            <token id="39" string="by" />
            <token id="40" string="Olympics" />
            <token id="41" string="officials" />
          </tokens>
        </chunking>
        <chunking id="10" string="a medal" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="medal" />
          </tokens>
        </chunking>
        <chunking id="11" string="was not on stanozolol when he beat Lewis in a world-record time of 9.79 seconds for the 100 meters gold , a medal taken away from him when he then tested positive for stanozolol use by Olympics officials" type="VP">
          <tokens>
            <token id="4" string="was" />
            <token id="5" string="not" />
            <token id="6" string="on" />
            <token id="7" string="stanozolol" />
            <token id="8" string="when" />
            <token id="9" string="he" />
            <token id="10" string="beat" />
            <token id="11" string="Lewis" />
            <token id="12" string="in" />
            <token id="13" string="a" />
            <token id="14" string="world-record" />
            <token id="15" string="time" />
            <token id="16" string="of" />
            <token id="17" string="9.79" />
            <token id="18" string="seconds" />
            <token id="19" string="for" />
            <token id="20" string="the" />
            <token id="21" string="100" />
            <token id="22" string="meters" />
            <token id="23" string="gold" />
            <token id="24" string="," />
            <token id="25" string="a" />
            <token id="26" string="medal" />
            <token id="27" string="taken" />
            <token id="28" string="away" />
            <token id="29" string="from" />
            <token id="30" string="him" />
            <token id="31" string="when" />
            <token id="32" string="he" />
            <token id="33" string="then" />
            <token id="34" string="tested" />
            <token id="35" string="positive" />
            <token id="36" string="for" />
            <token id="37" string="stanozolol" />
            <token id="38" string="use" />
            <token id="39" string="by" />
            <token id="40" string="Olympics" />
            <token id="41" string="officials" />
          </tokens>
        </chunking>
        <chunking id="12" string="positive for stanozolol use" type="ADJP">
          <tokens>
            <token id="35" string="positive" />
            <token id="36" string="for" />
            <token id="37" string="stanozolol" />
            <token id="38" string="use" />
          </tokens>
        </chunking>
        <chunking id="13" string="Astaphan" type="NP">
          <tokens>
            <token id="1" string="Astaphan" />
          </tokens>
        </chunking>
        <chunking id="14" string="Lewis" type="NP">
          <tokens>
            <token id="11" string="Lewis" />
          </tokens>
        </chunking>
        <chunking id="15" string="a world-record time of 9.79 seconds" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="world-record" />
            <token id="15" string="time" />
            <token id="16" string="of" />
            <token id="17" string="9.79" />
            <token id="18" string="seconds" />
          </tokens>
        </chunking>
        <chunking id="16" string="he" type="NP">
          <tokens>
            <token id="9" string="he" />
          </tokens>
        </chunking>
        <chunking id="17" string="said Johnson was not on stanozolol when he beat Lewis in a world-record time of 9.79 seconds for the 100 meters gold , a medal taken away from him when he then tested positive for stanozolol use by Olympics officials" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="Johnson" />
            <token id="4" string="was" />
            <token id="5" string="not" />
            <token id="6" string="on" />
            <token id="7" string="stanozolol" />
            <token id="8" string="when" />
            <token id="9" string="he" />
            <token id="10" string="beat" />
            <token id="11" string="Lewis" />
            <token id="12" string="in" />
            <token id="13" string="a" />
            <token id="14" string="world-record" />
            <token id="15" string="time" />
            <token id="16" string="of" />
            <token id="17" string="9.79" />
            <token id="18" string="seconds" />
            <token id="19" string="for" />
            <token id="20" string="the" />
            <token id="21" string="100" />
            <token id="22" string="meters" />
            <token id="23" string="gold" />
            <token id="24" string="," />
            <token id="25" string="a" />
            <token id="26" string="medal" />
            <token id="27" string="taken" />
            <token id="28" string="away" />
            <token id="29" string="from" />
            <token id="30" string="him" />
            <token id="31" string="when" />
            <token id="32" string="he" />
            <token id="33" string="then" />
            <token id="34" string="tested" />
            <token id="35" string="positive" />
            <token id="36" string="for" />
            <token id="37" string="stanozolol" />
            <token id="38" string="use" />
            <token id="39" string="by" />
            <token id="40" string="Olympics" />
            <token id="41" string="officials" />
          </tokens>
        </chunking>
        <chunking id="18" string="a world-record time" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="world-record" />
            <token id="15" string="time" />
          </tokens>
        </chunking>
        <chunking id="19" string="when he beat Lewis in a world-record time of 9.79 seconds for the 100 meters gold , a medal taken away from him when he then tested positive for stanozolol use by Olympics officials" type="SBAR">
          <tokens>
            <token id="8" string="when" />
            <token id="9" string="he" />
            <token id="10" string="beat" />
            <token id="11" string="Lewis" />
            <token id="12" string="in" />
            <token id="13" string="a" />
            <token id="14" string="world-record" />
            <token id="15" string="time" />
            <token id="16" string="of" />
            <token id="17" string="9.79" />
            <token id="18" string="seconds" />
            <token id="19" string="for" />
            <token id="20" string="the" />
            <token id="21" string="100" />
            <token id="22" string="meters" />
            <token id="23" string="gold" />
            <token id="24" string="," />
            <token id="25" string="a" />
            <token id="26" string="medal" />
            <token id="27" string="taken" />
            <token id="28" string="away" />
            <token id="29" string="from" />
            <token id="30" string="him" />
            <token id="31" string="when" />
            <token id="32" string="he" />
            <token id="33" string="then" />
            <token id="34" string="tested" />
            <token id="35" string="positive" />
            <token id="36" string="for" />
            <token id="37" string="stanozolol" />
            <token id="38" string="use" />
            <token id="39" string="by" />
            <token id="40" string="Olympics" />
            <token id="41" string="officials" />
          </tokens>
        </chunking>
        <chunking id="20" string="a medal taken away from him when he then tested positive for stanozolol use by Olympics officials" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="medal" />
            <token id="27" string="taken" />
            <token id="28" string="away" />
            <token id="29" string="from" />
            <token id="30" string="him" />
            <token id="31" string="when" />
            <token id="32" string="he" />
            <token id="33" string="then" />
            <token id="34" string="tested" />
            <token id="35" string="positive" />
            <token id="36" string="for" />
            <token id="37" string="stanozolol" />
            <token id="38" string="use" />
            <token id="39" string="by" />
            <token id="40" string="Olympics" />
            <token id="41" string="officials" />
          </tokens>
        </chunking>
        <chunking id="21" string="him" type="NP">
          <tokens>
            <token id="30" string="him" />
          </tokens>
        </chunking>
        <chunking id="22" string="when" type="WHADVP">
          <tokens>
            <token id="8" string="when" />
          </tokens>
        </chunking>
        <chunking id="23" string="Lewis in a world-record time of 9.79 seconds" type="NP">
          <tokens>
            <token id="11" string="Lewis" />
            <token id="12" string="in" />
            <token id="13" string="a" />
            <token id="14" string="world-record" />
            <token id="15" string="time" />
            <token id="16" string="of" />
            <token id="17" string="9.79" />
            <token id="18" string="seconds" />
          </tokens>
        </chunking>
        <chunking id="24" string="tested positive for stanozolol use by Olympics officials" type="VP">
          <tokens>
            <token id="34" string="tested" />
            <token id="35" string="positive" />
            <token id="36" string="for" />
            <token id="37" string="stanozolol" />
            <token id="38" string="use" />
            <token id="39" string="by" />
            <token id="40" string="Olympics" />
            <token id="41" string="officials" />
          </tokens>
        </chunking>
        <chunking id="25" string="beat Lewis in a world-record time of 9.79 seconds for the 100 meters gold , a medal taken away from him when he then tested positive for stanozolol use by Olympics officials" type="VP">
          <tokens>
            <token id="10" string="beat" />
            <token id="11" string="Lewis" />
            <token id="12" string="in" />
            <token id="13" string="a" />
            <token id="14" string="world-record" />
            <token id="15" string="time" />
            <token id="16" string="of" />
            <token id="17" string="9.79" />
            <token id="18" string="seconds" />
            <token id="19" string="for" />
            <token id="20" string="the" />
            <token id="21" string="100" />
            <token id="22" string="meters" />
            <token id="23" string="gold" />
            <token id="24" string="," />
            <token id="25" string="a" />
            <token id="26" string="medal" />
            <token id="27" string="taken" />
            <token id="28" string="away" />
            <token id="29" string="from" />
            <token id="30" string="him" />
            <token id="31" string="when" />
            <token id="32" string="he" />
            <token id="33" string="then" />
            <token id="34" string="tested" />
            <token id="35" string="positive" />
            <token id="36" string="for" />
            <token id="37" string="stanozolol" />
            <token id="38" string="use" />
            <token id="39" string="by" />
            <token id="40" string="Olympics" />
            <token id="41" string="officials" />
          </tokens>
        </chunking>
        <chunking id="26" string="the 100 meters gold , a medal taken away from him when he then tested positive for stanozolol use by Olympics officials" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="100" />
            <token id="22" string="meters" />
            <token id="23" string="gold" />
            <token id="24" string="," />
            <token id="25" string="a" />
            <token id="26" string="medal" />
            <token id="27" string="taken" />
            <token id="28" string="away" />
            <token id="29" string="from" />
            <token id="30" string="him" />
            <token id="31" string="when" />
            <token id="32" string="he" />
            <token id="33" string="then" />
            <token id="34" string="tested" />
            <token id="35" string="positive" />
            <token id="36" string="for" />
            <token id="37" string="stanozolol" />
            <token id="38" string="use" />
            <token id="39" string="by" />
            <token id="40" string="Olympics" />
            <token id="41" string="officials" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">Astaphan</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">stanozolol</governor>
          <dependent id="3">Johnson</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">stanozolol</governor>
          <dependent id="4">was</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="7">stanozolol</governor>
          <dependent id="5">not</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">stanozolol</governor>
          <dependent id="6">on</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="7">stanozolol</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">beat</governor>
          <dependent id="8">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">beat</governor>
          <dependent id="9">he</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">stanozolol</governor>
          <dependent id="10">beat</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">beat</governor>
          <dependent id="11">Lewis</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">time</governor>
          <dependent id="12">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">time</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">time</governor>
          <dependent id="14">world-record</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">Lewis</governor>
          <dependent id="15">time</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">seconds</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="18">seconds</governor>
          <dependent id="17">9.79</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">time</governor>
          <dependent id="18">seconds</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">gold</governor>
          <dependent id="19">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">gold</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="23">gold</governor>
          <dependent id="21">100</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">gold</governor>
          <dependent id="22">meters</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">beat</governor>
          <dependent id="23">gold</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">medal</governor>
          <dependent id="25">a</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="23">gold</governor>
          <dependent id="26">medal</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="26">medal</governor>
          <dependent id="27">taken</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="27">taken</governor>
          <dependent id="28">away</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">him</governor>
          <dependent id="29">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">taken</governor>
          <dependent id="30">him</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="34">tested</governor>
          <dependent id="31">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="34">tested</governor>
          <dependent id="32">he</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="34">tested</governor>
          <dependent id="33">then</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="27">taken</governor>
          <dependent id="34">tested</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="34">tested</governor>
          <dependent id="35">positive</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">use</governor>
          <dependent id="36">for</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="38">use</governor>
          <dependent id="37">stanozolol</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="35">positive</governor>
          <dependent id="38">use</dependent>
        </dependency>
        <dependency type="case">
          <governor id="41">officials</governor>
          <dependent id="39">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="41">officials</governor>
          <dependent id="40">Olympics</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="34">tested</governor>
          <dependent id="41">officials</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="100" type="NUMBER" score="0.0">
          <tokens>
            <token id="21" string="100" />
          </tokens>
        </entity>
        <entity id="2" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Johnson" />
          </tokens>
        </entity>
        <entity id="3" string="Astaphan" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Astaphan" />
          </tokens>
        </entity>
        <entity id="4" string="Olympics" type="MISC" score="0.0">
          <tokens>
            <token id="40" string="Olympics" />
          </tokens>
        </entity>
        <entity id="5" string="Lewis" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Lewis" />
          </tokens>
        </entity>
        <entity id="6" string="9.79 seconds" type="DURATION" score="0.0">
          <tokens>
            <token id="17" string="9.79" />
            <token id="18" string="seconds" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>Asked how he could be certain, Astaphan replied: &amp;quot;I must admit that even though I am his personal physician, there&amp;apost;s no way I can keep a constant check on him.</content>
      <tokens>
        <token id="1" string="Asked" lemma="ask" stem="asked" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="how" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="certain" lemma="certain" stem="certain" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Astaphan" lemma="Astaphan" stem="astaphan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="9" string="replied" lemma="reply" stem="repli" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="must" lemma="must" stem="must" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="admit" lemma="admit" stem="admit" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="though" lemma="though" stem="though" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="am" lemma="be" stem="am" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="personal" lemma="personal" stem="person" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="physician" lemma="physician" stem="physician" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="27" string="way" lemma="way" stem="wai" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="28" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="29" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="30" string="keep" lemma="keep" stem="keep" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="31" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="32" string="constant" lemma="constant" stem="constant" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="33" string="check" lemma="check" stem="check" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="34" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="35" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VBN Asked) (SBAR (WHADVP (WRB how)) (S (NP (PRP he)) (VP (MD could) (VP (VB be) (ADJP (JJ certain)))))))) (, ,) (NP (NNP Astaphan)) (VP (VBD replied) (: :) (`` ``) (S (NP (PRP I)) (VP (MD must) (VP (VB admit) (SBAR (IN that) (S (SBAR (RB even) (IN though) (S (NP (PRP I)) (VP (VBP am) (NP (PRP$ his) (JJ personal) (NN physician))))) (, ,) (NP (EX there)) (VP (VBZ 's) (NP (NP (DT no) (NN way)) (SBAR (S (NP (PRP I)) (VP (MD can) (VP (VB keep) (NP (DT a) (JJ constant) (NN check)) (PP (IN on) (NP (PRP him))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="I can keep a constant check on him" type="SBAR">
          <tokens>
            <token id="28" string="I" />
            <token id="29" string="can" />
            <token id="30" string="keep" />
            <token id="31" string="a" />
            <token id="32" string="constant" />
            <token id="33" string="check" />
            <token id="34" string="on" />
            <token id="35" string="him" />
          </tokens>
        </chunking>
        <chunking id="2" string="be certain" type="VP">
          <tokens>
            <token id="5" string="be" />
            <token id="6" string="certain" />
          </tokens>
        </chunking>
        <chunking id="3" string="Asked how he could be certain" type="VP">
          <tokens>
            <token id="1" string="Asked" />
            <token id="2" string="how" />
            <token id="3" string="he" />
            <token id="4" string="could" />
            <token id="5" string="be" />
            <token id="6" string="certain" />
          </tokens>
        </chunking>
        <chunking id="4" string="replied : `` I must admit that even though I am his personal physician , there 's no way I can keep a constant check on him" type="VP">
          <tokens>
            <token id="9" string="replied" />
            <token id="10" string=":" />
            <token id="11" string="&quot;" />
            <token id="12" string="I" />
            <token id="13" string="must" />
            <token id="14" string="admit" />
            <token id="15" string="that" />
            <token id="16" string="even" />
            <token id="17" string="though" />
            <token id="18" string="I" />
            <token id="19" string="am" />
            <token id="20" string="his" />
            <token id="21" string="personal" />
            <token id="22" string="physician" />
            <token id="23" string="," />
            <token id="24" string="there" />
            <token id="25" string="'s" />
            <token id="26" string="no" />
            <token id="27" string="way" />
            <token id="28" string="I" />
            <token id="29" string="can" />
            <token id="30" string="keep" />
            <token id="31" string="a" />
            <token id="32" string="constant" />
            <token id="33" string="check" />
            <token id="34" string="on" />
            <token id="35" string="him" />
          </tokens>
        </chunking>
        <chunking id="5" string="no way" type="NP">
          <tokens>
            <token id="26" string="no" />
            <token id="27" string="way" />
          </tokens>
        </chunking>
        <chunking id="6" string="there" type="NP">
          <tokens>
            <token id="24" string="there" />
          </tokens>
        </chunking>
        <chunking id="7" string="how he could be certain" type="SBAR">
          <tokens>
            <token id="2" string="how" />
            <token id="3" string="he" />
            <token id="4" string="could" />
            <token id="5" string="be" />
            <token id="6" string="certain" />
          </tokens>
        </chunking>
        <chunking id="8" string="am his personal physician" type="VP">
          <tokens>
            <token id="19" string="am" />
            <token id="20" string="his" />
            <token id="21" string="personal" />
            <token id="22" string="physician" />
          </tokens>
        </chunking>
        <chunking id="9" string="Astaphan" type="NP">
          <tokens>
            <token id="8" string="Astaphan" />
          </tokens>
        </chunking>
        <chunking id="10" string="he" type="NP">
          <tokens>
            <token id="3" string="he" />
          </tokens>
        </chunking>
        <chunking id="11" string="can keep a constant check on him" type="VP">
          <tokens>
            <token id="29" string="can" />
            <token id="30" string="keep" />
            <token id="31" string="a" />
            <token id="32" string="constant" />
            <token id="33" string="check" />
            <token id="34" string="on" />
            <token id="35" string="him" />
          </tokens>
        </chunking>
        <chunking id="12" string="certain" type="ADJP">
          <tokens>
            <token id="6" string="certain" />
          </tokens>
        </chunking>
        <chunking id="13" string="even though I am his personal physician" type="SBAR">
          <tokens>
            <token id="16" string="even" />
            <token id="17" string="though" />
            <token id="18" string="I" />
            <token id="19" string="am" />
            <token id="20" string="his" />
            <token id="21" string="personal" />
            <token id="22" string="physician" />
          </tokens>
        </chunking>
        <chunking id="14" string="'s no way I can keep a constant check on him" type="VP">
          <tokens>
            <token id="25" string="'s" />
            <token id="26" string="no" />
            <token id="27" string="way" />
            <token id="28" string="I" />
            <token id="29" string="can" />
            <token id="30" string="keep" />
            <token id="31" string="a" />
            <token id="32" string="constant" />
            <token id="33" string="check" />
            <token id="34" string="on" />
            <token id="35" string="him" />
          </tokens>
        </chunking>
        <chunking id="15" string="that even though I am his personal physician , there 's no way I can keep a constant check on him" type="SBAR">
          <tokens>
            <token id="15" string="that" />
            <token id="16" string="even" />
            <token id="17" string="though" />
            <token id="18" string="I" />
            <token id="19" string="am" />
            <token id="20" string="his" />
            <token id="21" string="personal" />
            <token id="22" string="physician" />
            <token id="23" string="," />
            <token id="24" string="there" />
            <token id="25" string="'s" />
            <token id="26" string="no" />
            <token id="27" string="way" />
            <token id="28" string="I" />
            <token id="29" string="can" />
            <token id="30" string="keep" />
            <token id="31" string="a" />
            <token id="32" string="constant" />
            <token id="33" string="check" />
            <token id="34" string="on" />
            <token id="35" string="him" />
          </tokens>
        </chunking>
        <chunking id="16" string="I" type="NP">
          <tokens>
            <token id="12" string="I" />
          </tokens>
        </chunking>
        <chunking id="17" string="admit that even though I am his personal physician , there 's no way I can keep a constant check on him" type="VP">
          <tokens>
            <token id="14" string="admit" />
            <token id="15" string="that" />
            <token id="16" string="even" />
            <token id="17" string="though" />
            <token id="18" string="I" />
            <token id="19" string="am" />
            <token id="20" string="his" />
            <token id="21" string="personal" />
            <token id="22" string="physician" />
            <token id="23" string="," />
            <token id="24" string="there" />
            <token id="25" string="'s" />
            <token id="26" string="no" />
            <token id="27" string="way" />
            <token id="28" string="I" />
            <token id="29" string="can" />
            <token id="30" string="keep" />
            <token id="31" string="a" />
            <token id="32" string="constant" />
            <token id="33" string="check" />
            <token id="34" string="on" />
            <token id="35" string="him" />
          </tokens>
        </chunking>
        <chunking id="18" string="no way I can keep a constant check on him" type="NP">
          <tokens>
            <token id="26" string="no" />
            <token id="27" string="way" />
            <token id="28" string="I" />
            <token id="29" string="can" />
            <token id="30" string="keep" />
            <token id="31" string="a" />
            <token id="32" string="constant" />
            <token id="33" string="check" />
            <token id="34" string="on" />
            <token id="35" string="him" />
          </tokens>
        </chunking>
        <chunking id="19" string="a constant check" type="NP">
          <tokens>
            <token id="31" string="a" />
            <token id="32" string="constant" />
            <token id="33" string="check" />
          </tokens>
        </chunking>
        <chunking id="20" string="him" type="NP">
          <tokens>
            <token id="35" string="him" />
          </tokens>
        </chunking>
        <chunking id="21" string="how" type="WHADVP">
          <tokens>
            <token id="2" string="how" />
          </tokens>
        </chunking>
        <chunking id="22" string="could be certain" type="VP">
          <tokens>
            <token id="4" string="could" />
            <token id="5" string="be" />
            <token id="6" string="certain" />
          </tokens>
        </chunking>
        <chunking id="23" string="keep a constant check on him" type="VP">
          <tokens>
            <token id="30" string="keep" />
            <token id="31" string="a" />
            <token id="32" string="constant" />
            <token id="33" string="check" />
            <token id="34" string="on" />
            <token id="35" string="him" />
          </tokens>
        </chunking>
        <chunking id="24" string="his personal physician" type="NP">
          <tokens>
            <token id="20" string="his" />
            <token id="21" string="personal" />
            <token id="22" string="physician" />
          </tokens>
        </chunking>
        <chunking id="25" string="must admit that even though I am his personal physician , there 's no way I can keep a constant check on him" type="VP">
          <tokens>
            <token id="13" string="must" />
            <token id="14" string="admit" />
            <token id="15" string="that" />
            <token id="16" string="even" />
            <token id="17" string="though" />
            <token id="18" string="I" />
            <token id="19" string="am" />
            <token id="20" string="his" />
            <token id="21" string="personal" />
            <token id="22" string="physician" />
            <token id="23" string="," />
            <token id="24" string="there" />
            <token id="25" string="'s" />
            <token id="26" string="no" />
            <token id="27" string="way" />
            <token id="28" string="I" />
            <token id="29" string="can" />
            <token id="30" string="keep" />
            <token id="31" string="a" />
            <token id="32" string="constant" />
            <token id="33" string="check" />
            <token id="34" string="on" />
            <token id="35" string="him" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advcl">
          <governor id="9">replied</governor>
          <dependent id="1">Asked</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">certain</governor>
          <dependent id="2">how</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">certain</governor>
          <dependent id="3">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">certain</governor>
          <dependent id="4">could</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">certain</governor>
          <dependent id="5">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="1">Asked</governor>
          <dependent id="6">certain</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">replied</governor>
          <dependent id="8">Astaphan</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">replied</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">admit</governor>
          <dependent id="12">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">admit</governor>
          <dependent id="13">must</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">replied</governor>
          <dependent id="14">admit</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="25">'s</governor>
          <dependent id="15">that</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="22">physician</governor>
          <dependent id="16">even</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">physician</governor>
          <dependent id="17">though</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">physician</governor>
          <dependent id="18">I</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="22">physician</governor>
          <dependent id="19">am</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="22">physician</governor>
          <dependent id="20">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">physician</governor>
          <dependent id="21">personal</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="25">'s</governor>
          <dependent id="22">physician</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="25">'s</governor>
          <dependent id="24">there</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">admit</governor>
          <dependent id="25">'s</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="27">way</governor>
          <dependent id="26">no</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">'s</governor>
          <dependent id="27">way</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="30">keep</governor>
          <dependent id="28">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="30">keep</governor>
          <dependent id="29">can</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="27">way</governor>
          <dependent id="30">keep</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">check</governor>
          <dependent id="31">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="33">check</governor>
          <dependent id="32">constant</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="30">keep</governor>
          <dependent id="33">check</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">him</governor>
          <dependent id="34">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">keep</governor>
          <dependent id="35">him</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Astaphan" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Astaphan" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>&amp;quot;But it would not make any sense for an athlete to go back on a drug which a few months previously could have ruined him for life.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="make" lemma="make" stem="make" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="sense" lemma="sense" stem="sens" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="athlete" lemma="athlete" stem="athlet" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="go" lemma="go" stem="go" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="back" lemma="back" stem="back" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="drug" lemma="drug" stem="drug" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="20" string="few" lemma="few" stem="few" pos="JJ" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="21" string="months" lemma="month" stem="month" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="22" string="previously" lemma="previously" stem="previous" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="23" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="ruined" lemma="ruin" stem="ruin" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="life" lemma="life" stem="life" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (CC But) (NP (PRP it)) (VP (MD would) (RB not) (VP (VB make) (NP (DT any) (NN sense)) (PP (IN for) (NP (DT an) (NN athlete) (S (VP (TO to) (VP (VB go) (ADVP (RB back)) (PP (IN on) (NP (NP (DT a) (NN drug)) (SBAR (WHNP (WDT which)) (S (NP (DT a) (JJ few) (NNS months)) (ADVP (RB previously)) (VP (MD could) (VP (VB have) (VP (VBN ruined) (NP (PRP him)) (PP (IN for) (NP (NN life))))))))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="could have ruined him for life" type="VP">
          <tokens>
            <token id="23" string="could" />
            <token id="24" string="have" />
            <token id="25" string="ruined" />
            <token id="26" string="him" />
            <token id="27" string="for" />
            <token id="28" string="life" />
          </tokens>
        </chunking>
        <chunking id="2" string="go back on a drug which a few months previously could have ruined him for life" type="VP">
          <tokens>
            <token id="13" string="go" />
            <token id="14" string="back" />
            <token id="15" string="on" />
            <token id="16" string="a" />
            <token id="17" string="drug" />
            <token id="18" string="which" />
            <token id="19" string="a" />
            <token id="20" string="few" />
            <token id="21" string="months" />
            <token id="22" string="previously" />
            <token id="23" string="could" />
            <token id="24" string="have" />
            <token id="25" string="ruined" />
            <token id="26" string="him" />
            <token id="27" string="for" />
            <token id="28" string="life" />
          </tokens>
        </chunking>
        <chunking id="3" string="to go back on a drug which a few months previously could have ruined him for life" type="VP">
          <tokens>
            <token id="12" string="to" />
            <token id="13" string="go" />
            <token id="14" string="back" />
            <token id="15" string="on" />
            <token id="16" string="a" />
            <token id="17" string="drug" />
            <token id="18" string="which" />
            <token id="19" string="a" />
            <token id="20" string="few" />
            <token id="21" string="months" />
            <token id="22" string="previously" />
            <token id="23" string="could" />
            <token id="24" string="have" />
            <token id="25" string="ruined" />
            <token id="26" string="him" />
            <token id="27" string="for" />
            <token id="28" string="life" />
          </tokens>
        </chunking>
        <chunking id="4" string="a drug" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="drug" />
          </tokens>
        </chunking>
        <chunking id="5" string="make any sense for an athlete to go back on a drug which a few months previously could have ruined him for life" type="VP">
          <tokens>
            <token id="6" string="make" />
            <token id="7" string="any" />
            <token id="8" string="sense" />
            <token id="9" string="for" />
            <token id="10" string="an" />
            <token id="11" string="athlete" />
            <token id="12" string="to" />
            <token id="13" string="go" />
            <token id="14" string="back" />
            <token id="15" string="on" />
            <token id="16" string="a" />
            <token id="17" string="drug" />
            <token id="18" string="which" />
            <token id="19" string="a" />
            <token id="20" string="few" />
            <token id="21" string="months" />
            <token id="22" string="previously" />
            <token id="23" string="could" />
            <token id="24" string="have" />
            <token id="25" string="ruined" />
            <token id="26" string="him" />
            <token id="27" string="for" />
            <token id="28" string="life" />
          </tokens>
        </chunking>
        <chunking id="6" string="life" type="NP">
          <tokens>
            <token id="28" string="life" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="3" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="him" type="NP">
          <tokens>
            <token id="26" string="him" />
          </tokens>
        </chunking>
        <chunking id="9" string="would not make any sense for an athlete to go back on a drug which a few months previously could have ruined him for life" type="VP">
          <tokens>
            <token id="4" string="would" />
            <token id="5" string="not" />
            <token id="6" string="make" />
            <token id="7" string="any" />
            <token id="8" string="sense" />
            <token id="9" string="for" />
            <token id="10" string="an" />
            <token id="11" string="athlete" />
            <token id="12" string="to" />
            <token id="13" string="go" />
            <token id="14" string="back" />
            <token id="15" string="on" />
            <token id="16" string="a" />
            <token id="17" string="drug" />
            <token id="18" string="which" />
            <token id="19" string="a" />
            <token id="20" string="few" />
            <token id="21" string="months" />
            <token id="22" string="previously" />
            <token id="23" string="could" />
            <token id="24" string="have" />
            <token id="25" string="ruined" />
            <token id="26" string="him" />
            <token id="27" string="for" />
            <token id="28" string="life" />
          </tokens>
        </chunking>
        <chunking id="10" string="ruined him for life" type="VP">
          <tokens>
            <token id="25" string="ruined" />
            <token id="26" string="him" />
            <token id="27" string="for" />
            <token id="28" string="life" />
          </tokens>
        </chunking>
        <chunking id="11" string="a drug which a few months previously could have ruined him for life" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="drug" />
            <token id="18" string="which" />
            <token id="19" string="a" />
            <token id="20" string="few" />
            <token id="21" string="months" />
            <token id="22" string="previously" />
            <token id="23" string="could" />
            <token id="24" string="have" />
            <token id="25" string="ruined" />
            <token id="26" string="him" />
            <token id="27" string="for" />
            <token id="28" string="life" />
          </tokens>
        </chunking>
        <chunking id="12" string="have ruined him for life" type="VP">
          <tokens>
            <token id="24" string="have" />
            <token id="25" string="ruined" />
            <token id="26" string="him" />
            <token id="27" string="for" />
            <token id="28" string="life" />
          </tokens>
        </chunking>
        <chunking id="13" string="a few months" type="NP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="few" />
            <token id="21" string="months" />
          </tokens>
        </chunking>
        <chunking id="14" string="which a few months previously could have ruined him for life" type="SBAR">
          <tokens>
            <token id="18" string="which" />
            <token id="19" string="a" />
            <token id="20" string="few" />
            <token id="21" string="months" />
            <token id="22" string="previously" />
            <token id="23" string="could" />
            <token id="24" string="have" />
            <token id="25" string="ruined" />
            <token id="26" string="him" />
            <token id="27" string="for" />
            <token id="28" string="life" />
          </tokens>
        </chunking>
        <chunking id="15" string="an athlete to go back on a drug which a few months previously could have ruined him for life" type="NP">
          <tokens>
            <token id="10" string="an" />
            <token id="11" string="athlete" />
            <token id="12" string="to" />
            <token id="13" string="go" />
            <token id="14" string="back" />
            <token id="15" string="on" />
            <token id="16" string="a" />
            <token id="17" string="drug" />
            <token id="18" string="which" />
            <token id="19" string="a" />
            <token id="20" string="few" />
            <token id="21" string="months" />
            <token id="22" string="previously" />
            <token id="23" string="could" />
            <token id="24" string="have" />
            <token id="25" string="ruined" />
            <token id="26" string="him" />
            <token id="27" string="for" />
            <token id="28" string="life" />
          </tokens>
        </chunking>
        <chunking id="16" string="any sense" type="NP">
          <tokens>
            <token id="7" string="any" />
            <token id="8" string="sense" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="6">make</governor>
          <dependent id="2">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">make</governor>
          <dependent id="3">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">make</governor>
          <dependent id="4">would</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">make</governor>
          <dependent id="5">not</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">make</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">sense</governor>
          <dependent id="7">any</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">make</governor>
          <dependent id="8">sense</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">athlete</governor>
          <dependent id="9">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">athlete</governor>
          <dependent id="10">an</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">make</governor>
          <dependent id="11">athlete</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">go</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="11">athlete</governor>
          <dependent id="13">go</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">go</governor>
          <dependent id="14">back</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">drug</governor>
          <dependent id="15">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">drug</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">go</governor>
          <dependent id="17">drug</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">ruined</governor>
          <dependent id="18">which</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">months</governor>
          <dependent id="19">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">months</governor>
          <dependent id="20">few</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">ruined</governor>
          <dependent id="21">months</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="25">ruined</governor>
          <dependent id="22">previously</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="25">ruined</governor>
          <dependent id="23">could</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="25">ruined</governor>
          <dependent id="24">have</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="17">drug</governor>
          <dependent id="25">ruined</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">ruined</governor>
          <dependent id="26">him</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">life</governor>
          <dependent id="27">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">ruined</governor>
          <dependent id="28">life</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="previously" type="DATE" score="0.0">
          <tokens>
            <token id="22" string="previously" />
          </tokens>
        </entity>
        <entity id="2" string="a few months" type="DURATION" score="0.0">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="few" />
            <token id="21" string="months" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>Johnson has said he never knowingly took performance-enhancing drugs.</content>
      <tokens>
        <token id="1" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="said" lemma="say" stem="said" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="knowingly" lemma="knowingly" stem="knowingli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="took" lemma="take" stem="took" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="performance-enhancing" lemma="performance-enhancing" stem="performance-enhanc" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="drugs" lemma="drug" stem="drug" pos="NNS" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Johnson)) (VP (VBZ has) (VP (VBN said) (SBAR (S (NP (PRP he)) (VP (ADVP (RB never)) (ADVP (RB knowingly)) (VBD took) (NP (JJ performance-enhancing) (NNS drugs))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Johnson" type="NP">
          <tokens>
            <token id="1" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="2" string="has said he never knowingly took performance-enhancing drugs" type="VP">
          <tokens>
            <token id="2" string="has" />
            <token id="3" string="said" />
            <token id="4" string="he" />
            <token id="5" string="never" />
            <token id="6" string="knowingly" />
            <token id="7" string="took" />
            <token id="8" string="performance-enhancing" />
            <token id="9" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="3" string="he never knowingly took performance-enhancing drugs" type="SBAR">
          <tokens>
            <token id="4" string="he" />
            <token id="5" string="never" />
            <token id="6" string="knowingly" />
            <token id="7" string="took" />
            <token id="8" string="performance-enhancing" />
            <token id="9" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="4" string="never knowingly took performance-enhancing drugs" type="VP">
          <tokens>
            <token id="5" string="never" />
            <token id="6" string="knowingly" />
            <token id="7" string="took" />
            <token id="8" string="performance-enhancing" />
            <token id="9" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="5" string="said he never knowingly took performance-enhancing drugs" type="VP">
          <tokens>
            <token id="3" string="said" />
            <token id="4" string="he" />
            <token id="5" string="never" />
            <token id="6" string="knowingly" />
            <token id="7" string="took" />
            <token id="8" string="performance-enhancing" />
            <token id="9" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="6" string="performance-enhancing drugs" type="NP">
          <tokens>
            <token id="8" string="performance-enhancing" />
            <token id="9" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="7" string="he" type="NP">
          <tokens>
            <token id="4" string="he" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">said</governor>
          <dependent id="1">Johnson</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">said</governor>
          <dependent id="2">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">took</governor>
          <dependent id="4">he</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="7">took</governor>
          <dependent id="5">never</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">took</governor>
          <dependent id="6">knowingly</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">said</governor>
          <dependent id="7">took</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">drugs</governor>
          <dependent id="8">performance-enhancing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">took</governor>
          <dependent id="9">drugs</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="drugs" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="9" string="drugs" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>Astaphan has denied he ever prescribed such drugs to Johnson or other athletes on Canada&amp;apost;s Olympics team.</content>
      <tokens>
        <token id="1" string="Astaphan" lemma="Astaphan" stem="astaphan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="denied" lemma="deny" stem="deni" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="ever" lemma="ever" stem="ever" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="prescribed" lemma="prescribe" stem="prescrib" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="drugs" lemma="drug" stem="drug" pos="NNS" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="11" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="athletes" lemma="athlete" stem="athlet" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Canada" lemma="Canada" stem="canada" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="16" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="Olympics" lemma="Olympics" stem="olympic" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="18" string="team" lemma="team" stem="team" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Astaphan)) (VP (VBZ has) (VP (VBN denied) (SBAR (S (NP (PRP he)) (ADVP (RB ever)) (VP (VBD prescribed) (NP (JJ such) (NNS drugs)) (PP (TO to) (NP (NP (NNP Johnson)) (CC or) (NP (JJ other) (NNS athletes)))) (PP (IN on) (NP (NP (NP (NNP Canada) (POS 's)) (NNPS Olympics)) (NP (NN team))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Canada 's" type="NP">
          <tokens>
            <token id="15" string="Canada" />
            <token id="16" string="'s" />
          </tokens>
        </chunking>
        <chunking id="2" string="Johnson" type="NP">
          <tokens>
            <token id="10" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="3" string="denied he ever prescribed such drugs to Johnson or other athletes on Canada 's Olympics team" type="VP">
          <tokens>
            <token id="3" string="denied" />
            <token id="4" string="he" />
            <token id="5" string="ever" />
            <token id="6" string="prescribed" />
            <token id="7" string="such" />
            <token id="8" string="drugs" />
            <token id="9" string="to" />
            <token id="10" string="Johnson" />
            <token id="11" string="or" />
            <token id="12" string="other" />
            <token id="13" string="athletes" />
            <token id="14" string="on" />
            <token id="15" string="Canada" />
            <token id="16" string="'s" />
            <token id="17" string="Olympics" />
            <token id="18" string="team" />
          </tokens>
        </chunking>
        <chunking id="4" string="Johnson or other athletes" type="NP">
          <tokens>
            <token id="10" string="Johnson" />
            <token id="11" string="or" />
            <token id="12" string="other" />
            <token id="13" string="athletes" />
          </tokens>
        </chunking>
        <chunking id="5" string="team" type="NP">
          <tokens>
            <token id="18" string="team" />
          </tokens>
        </chunking>
        <chunking id="6" string="such drugs" type="NP">
          <tokens>
            <token id="7" string="such" />
            <token id="8" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="7" string="other athletes" type="NP">
          <tokens>
            <token id="12" string="other" />
            <token id="13" string="athletes" />
          </tokens>
        </chunking>
        <chunking id="8" string="Canada 's Olympics team" type="NP">
          <tokens>
            <token id="15" string="Canada" />
            <token id="16" string="'s" />
            <token id="17" string="Olympics" />
            <token id="18" string="team" />
          </tokens>
        </chunking>
        <chunking id="9" string="Canada 's Olympics" type="NP">
          <tokens>
            <token id="15" string="Canada" />
            <token id="16" string="'s" />
            <token id="17" string="Olympics" />
          </tokens>
        </chunking>
        <chunking id="10" string="Astaphan" type="NP">
          <tokens>
            <token id="1" string="Astaphan" />
          </tokens>
        </chunking>
        <chunking id="11" string="has denied he ever prescribed such drugs to Johnson or other athletes on Canada 's Olympics team" type="VP">
          <tokens>
            <token id="2" string="has" />
            <token id="3" string="denied" />
            <token id="4" string="he" />
            <token id="5" string="ever" />
            <token id="6" string="prescribed" />
            <token id="7" string="such" />
            <token id="8" string="drugs" />
            <token id="9" string="to" />
            <token id="10" string="Johnson" />
            <token id="11" string="or" />
            <token id="12" string="other" />
            <token id="13" string="athletes" />
            <token id="14" string="on" />
            <token id="15" string="Canada" />
            <token id="16" string="'s" />
            <token id="17" string="Olympics" />
            <token id="18" string="team" />
          </tokens>
        </chunking>
        <chunking id="12" string="prescribed such drugs to Johnson or other athletes on Canada 's Olympics team" type="VP">
          <tokens>
            <token id="6" string="prescribed" />
            <token id="7" string="such" />
            <token id="8" string="drugs" />
            <token id="9" string="to" />
            <token id="10" string="Johnson" />
            <token id="11" string="or" />
            <token id="12" string="other" />
            <token id="13" string="athletes" />
            <token id="14" string="on" />
            <token id="15" string="Canada" />
            <token id="16" string="'s" />
            <token id="17" string="Olympics" />
            <token id="18" string="team" />
          </tokens>
        </chunking>
        <chunking id="13" string="he" type="NP">
          <tokens>
            <token id="4" string="he" />
          </tokens>
        </chunking>
        <chunking id="14" string="he ever prescribed such drugs to Johnson or other athletes on Canada 's Olympics team" type="SBAR">
          <tokens>
            <token id="4" string="he" />
            <token id="5" string="ever" />
            <token id="6" string="prescribed" />
            <token id="7" string="such" />
            <token id="8" string="drugs" />
            <token id="9" string="to" />
            <token id="10" string="Johnson" />
            <token id="11" string="or" />
            <token id="12" string="other" />
            <token id="13" string="athletes" />
            <token id="14" string="on" />
            <token id="15" string="Canada" />
            <token id="16" string="'s" />
            <token id="17" string="Olympics" />
            <token id="18" string="team" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">denied</governor>
          <dependent id="1">Astaphan</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">denied</governor>
          <dependent id="2">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">denied</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">prescribed</governor>
          <dependent id="4">he</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">prescribed</governor>
          <dependent id="5">ever</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">denied</governor>
          <dependent id="6">prescribed</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">drugs</governor>
          <dependent id="7">such</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">prescribed</governor>
          <dependent id="8">drugs</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Johnson</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">prescribed</governor>
          <dependent id="10">Johnson</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">Johnson</governor>
          <dependent id="11">or</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">athletes</governor>
          <dependent id="12">other</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">Johnson</governor>
          <dependent id="13">athletes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">Olympics</governor>
          <dependent id="14">on</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="17">Olympics</governor>
          <dependent id="15">Canada</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">Canada</governor>
          <dependent id="16">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">prescribed</governor>
          <dependent id="17">Olympics</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="17">Olympics</governor>
          <dependent id="18">team</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="Canada" type="LOCATION" score="0.0">
          <tokens>
            <token id="15" string="Canada" />
          </tokens>
        </entity>
        <entity id="3" string="drugs" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="8" string="drugs" />
          </tokens>
        </entity>
        <entity id="4" string="Astaphan" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Astaphan" />
          </tokens>
        </entity>
        <entity id="5" string="Olympics" type="MISC" score="0.0">
          <tokens>
            <token id="17" string="Olympics" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>The Johnson scandal prompted Canada to call an inquiry into drug use in amateur sport that resumes hearings in Toronto next Wednesday.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="scandal" lemma="scandal" stem="scandal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="prompted" lemma="prompt" stem="prompt" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="Canada" lemma="Canada" stem="canada" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="call" lemma="call" stem="call" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="inquiry" lemma="inquiry" stem="inquiri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="drug" lemma="drug" stem="drug" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="use" lemma="use" stem="us" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="amateur" lemma="amateur" stem="amateur" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="sport" lemma="sport" stem="sport" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="resumes" lemma="resume" stem="resum" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="hearings" lemma="hearing" stem="hear" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Toronto" lemma="Toronto" stem="toronto" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="21" string="next" lemma="next" stem="next" pos="IN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="22" string="Wednesday" lemma="Wednesday" stem="wednesdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNP Johnson) (NN scandal)) (VP (VBD prompted) (S (NP (NNP Canada)) (VP (TO to) (VP (VB call) (NP (DT an) (NN inquiry)) (PP (IN into) (NP (NN drug) (NN use))) (PP (IN in) (NP (NP (JJ amateur) (NN sport)) (SBAR (WHNP (WDT that)) (S (VP (VBZ resumes) (NP (NP (NNS hearings)) (PP (IN in) (NP (NNP Toronto)))) (PP (IN next) (NP (NNP Wednesday)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="an inquiry" type="NP">
          <tokens>
            <token id="8" string="an" />
            <token id="9" string="inquiry" />
          </tokens>
        </chunking>
        <chunking id="2" string="amateur sport that resumes hearings in Toronto next Wednesday" type="NP">
          <tokens>
            <token id="14" string="amateur" />
            <token id="15" string="sport" />
            <token id="16" string="that" />
            <token id="17" string="resumes" />
            <token id="18" string="hearings" />
            <token id="19" string="in" />
            <token id="20" string="Toronto" />
            <token id="21" string="next" />
            <token id="22" string="Wednesday" />
          </tokens>
        </chunking>
        <chunking id="3" string="to call an inquiry into drug use in amateur sport that resumes hearings in Toronto next Wednesday" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="call" />
            <token id="8" string="an" />
            <token id="9" string="inquiry" />
            <token id="10" string="into" />
            <token id="11" string="drug" />
            <token id="12" string="use" />
            <token id="13" string="in" />
            <token id="14" string="amateur" />
            <token id="15" string="sport" />
            <token id="16" string="that" />
            <token id="17" string="resumes" />
            <token id="18" string="hearings" />
            <token id="19" string="in" />
            <token id="20" string="Toronto" />
            <token id="21" string="next" />
            <token id="22" string="Wednesday" />
          </tokens>
        </chunking>
        <chunking id="4" string="call an inquiry into drug use in amateur sport that resumes hearings in Toronto next Wednesday" type="VP">
          <tokens>
            <token id="7" string="call" />
            <token id="8" string="an" />
            <token id="9" string="inquiry" />
            <token id="10" string="into" />
            <token id="11" string="drug" />
            <token id="12" string="use" />
            <token id="13" string="in" />
            <token id="14" string="amateur" />
            <token id="15" string="sport" />
            <token id="16" string="that" />
            <token id="17" string="resumes" />
            <token id="18" string="hearings" />
            <token id="19" string="in" />
            <token id="20" string="Toronto" />
            <token id="21" string="next" />
            <token id="22" string="Wednesday" />
          </tokens>
        </chunking>
        <chunking id="5" string="hearings in Toronto" type="NP">
          <tokens>
            <token id="18" string="hearings" />
            <token id="19" string="in" />
            <token id="20" string="Toronto" />
          </tokens>
        </chunking>
        <chunking id="6" string="prompted Canada to call an inquiry into drug use in amateur sport that resumes hearings in Toronto next Wednesday" type="VP">
          <tokens>
            <token id="4" string="prompted" />
            <token id="5" string="Canada" />
            <token id="6" string="to" />
            <token id="7" string="call" />
            <token id="8" string="an" />
            <token id="9" string="inquiry" />
            <token id="10" string="into" />
            <token id="11" string="drug" />
            <token id="12" string="use" />
            <token id="13" string="in" />
            <token id="14" string="amateur" />
            <token id="15" string="sport" />
            <token id="16" string="that" />
            <token id="17" string="resumes" />
            <token id="18" string="hearings" />
            <token id="19" string="in" />
            <token id="20" string="Toronto" />
            <token id="21" string="next" />
            <token id="22" string="Wednesday" />
          </tokens>
        </chunking>
        <chunking id="7" string="The Johnson scandal" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Johnson" />
            <token id="3" string="scandal" />
          </tokens>
        </chunking>
        <chunking id="8" string="Canada" type="NP">
          <tokens>
            <token id="5" string="Canada" />
          </tokens>
        </chunking>
        <chunking id="9" string="hearings" type="NP">
          <tokens>
            <token id="18" string="hearings" />
          </tokens>
        </chunking>
        <chunking id="10" string="Wednesday" type="NP">
          <tokens>
            <token id="22" string="Wednesday" />
          </tokens>
        </chunking>
        <chunking id="11" string="that resumes hearings in Toronto next Wednesday" type="SBAR">
          <tokens>
            <token id="16" string="that" />
            <token id="17" string="resumes" />
            <token id="18" string="hearings" />
            <token id="19" string="in" />
            <token id="20" string="Toronto" />
            <token id="21" string="next" />
            <token id="22" string="Wednesday" />
          </tokens>
        </chunking>
        <chunking id="12" string="drug use" type="NP">
          <tokens>
            <token id="11" string="drug" />
            <token id="12" string="use" />
          </tokens>
        </chunking>
        <chunking id="13" string="resumes hearings in Toronto next Wednesday" type="VP">
          <tokens>
            <token id="17" string="resumes" />
            <token id="18" string="hearings" />
            <token id="19" string="in" />
            <token id="20" string="Toronto" />
            <token id="21" string="next" />
            <token id="22" string="Wednesday" />
          </tokens>
        </chunking>
        <chunking id="14" string="amateur sport" type="NP">
          <tokens>
            <token id="14" string="amateur" />
            <token id="15" string="sport" />
          </tokens>
        </chunking>
        <chunking id="15" string="Toronto" type="NP">
          <tokens>
            <token id="20" string="Toronto" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">scandal</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">scandal</governor>
          <dependent id="2">Johnson</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">prompted</governor>
          <dependent id="3">scandal</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">prompted</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">prompted</governor>
          <dependent id="5">Canada</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">call</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">prompted</governor>
          <dependent id="7">call</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">inquiry</governor>
          <dependent id="8">an</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">call</governor>
          <dependent id="9">inquiry</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">use</governor>
          <dependent id="10">into</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">use</governor>
          <dependent id="11">drug</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">call</governor>
          <dependent id="12">use</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">sport</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">sport</governor>
          <dependent id="14">amateur</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">call</governor>
          <dependent id="15">sport</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">resumes</governor>
          <dependent id="16">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="15">sport</governor>
          <dependent id="17">resumes</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">resumes</governor>
          <dependent id="18">hearings</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">Toronto</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">hearings</governor>
          <dependent id="20">Toronto</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">Wednesday</governor>
          <dependent id="21">next</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">resumes</governor>
          <dependent id="22">Wednesday</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="Canada" type="LOCATION" score="0.0">
          <tokens>
            <token id="5" string="Canada" />
          </tokens>
        </entity>
        <entity id="3" string="next Wednesday" type="DATE" score="0.0">
          <tokens>
            <token id="21" string="next" />
            <token id="22" string="Wednesday" />
          </tokens>
        </entity>
        <entity id="4" string="Toronto" type="LOCATION" score="0.0">
          <tokens>
            <token id="20" string="Toronto" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>Commission counsel Robert Armstrong said it was &amp;quot;totally irresponsible that Dr. Astaphan made such statements outside of the commission and not under oath where they are available to be tested by cross-examination.&amp;quot;</content>
      <tokens>
        <token id="1" string="Commission" lemma="Commission" stem="commiss" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="counsel" lemma="counsel" stem="counsel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Robert" lemma="Robert" stem="robert" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="4" string="Armstrong" lemma="Armstrong" stem="armstrong" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="5" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="totally" lemma="totally" stem="total" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="irresponsible" lemma="irresponsible" stem="irrespons" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Dr." lemma="Dr." stem="dr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="Astaphan" lemma="Astaphan" stem="astaphan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="14" string="made" lemma="make" stem="made" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="statements" lemma="statement" stem="statement" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="outside" lemma="outside" stem="outsid" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="commission" lemma="commission" stem="commiss" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="under" lemma="under" stem="under" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="oath" lemma="oath" stem="oath" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="available" lemma="available" stem="avail" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="tested" lemma="test" stem="test" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="cross-examination" lemma="cross-examination" stem="cross-examin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Commission) (NN counsel) (NNP Robert) (NNP Armstrong)) (VP (VBD said) (SBAR (S (NP (PRP it)) (VP (VBD was) (`` ``) (ADJP (RB totally) (JJ irresponsible)) (SBAR (IN that) (S (NP (NNP Dr.) (NNP Astaphan)) (VP (VBD made) (NP (JJ such) (NNS statements)) (PP (PP (IN outside) (PP (IN of) (NP (DT the) (NN commission)))) (CC and) (RB not) (PP (IN under) (NP (NP (NN oath)) (SBAR (WHADVP (WRB where)) (S (NP (PRP they)) (VP (VBP are) (ADJP (JJ available) (S (VP (TO to) (VP (VB be) (VP (VBN tested) (PP (IN by) (NP (NN cross-examination))))))))))))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="be tested by cross-examination" type="VP">
          <tokens>
            <token id="30" string="be" />
            <token id="31" string="tested" />
            <token id="32" string="by" />
            <token id="33" string="cross-examination" />
          </tokens>
        </chunking>
        <chunking id="2" string="the commission" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="commission" />
          </tokens>
        </chunking>
        <chunking id="3" string="made such statements outside of the commission and not under oath where they are available to be tested by cross-examination" type="VP">
          <tokens>
            <token id="14" string="made" />
            <token id="15" string="such" />
            <token id="16" string="statements" />
            <token id="17" string="outside" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="commission" />
            <token id="21" string="and" />
            <token id="22" string="not" />
            <token id="23" string="under" />
            <token id="24" string="oath" />
            <token id="25" string="where" />
            <token id="26" string="they" />
            <token id="27" string="are" />
            <token id="28" string="available" />
            <token id="29" string="to" />
            <token id="30" string="be" />
            <token id="31" string="tested" />
            <token id="32" string="by" />
            <token id="33" string="cross-examination" />
          </tokens>
        </chunking>
        <chunking id="4" string="available to be tested by cross-examination" type="ADJP">
          <tokens>
            <token id="28" string="available" />
            <token id="29" string="to" />
            <token id="30" string="be" />
            <token id="31" string="tested" />
            <token id="32" string="by" />
            <token id="33" string="cross-examination" />
          </tokens>
        </chunking>
        <chunking id="5" string="to be tested by cross-examination" type="VP">
          <tokens>
            <token id="29" string="to" />
            <token id="30" string="be" />
            <token id="31" string="tested" />
            <token id="32" string="by" />
            <token id="33" string="cross-examination" />
          </tokens>
        </chunking>
        <chunking id="6" string="tested by cross-examination" type="VP">
          <tokens>
            <token id="31" string="tested" />
            <token id="32" string="by" />
            <token id="33" string="cross-examination" />
          </tokens>
        </chunking>
        <chunking id="7" string="cross-examination" type="NP">
          <tokens>
            <token id="33" string="cross-examination" />
          </tokens>
        </chunking>
        <chunking id="8" string="it" type="NP">
          <tokens>
            <token id="6" string="it" />
          </tokens>
        </chunking>
        <chunking id="9" string="oath where they are available to be tested by cross-examination" type="NP">
          <tokens>
            <token id="24" string="oath" />
            <token id="25" string="where" />
            <token id="26" string="they" />
            <token id="27" string="are" />
            <token id="28" string="available" />
            <token id="29" string="to" />
            <token id="30" string="be" />
            <token id="31" string="tested" />
            <token id="32" string="by" />
            <token id="33" string="cross-examination" />
          </tokens>
        </chunking>
        <chunking id="10" string="totally irresponsible" type="ADJP">
          <tokens>
            <token id="9" string="totally" />
            <token id="10" string="irresponsible" />
          </tokens>
        </chunking>
        <chunking id="11" string="they" type="NP">
          <tokens>
            <token id="26" string="they" />
          </tokens>
        </chunking>
        <chunking id="12" string="such statements" type="NP">
          <tokens>
            <token id="15" string="such" />
            <token id="16" string="statements" />
          </tokens>
        </chunking>
        <chunking id="13" string="it was `` totally irresponsible that Dr. Astaphan made such statements outside of the commission and not under oath where they are available to be tested by cross-examination" type="SBAR">
          <tokens>
            <token id="6" string="it" />
            <token id="7" string="was" />
            <token id="8" string="&quot;" />
            <token id="9" string="totally" />
            <token id="10" string="irresponsible" />
            <token id="11" string="that" />
            <token id="12" string="Dr." />
            <token id="13" string="Astaphan" />
            <token id="14" string="made" />
            <token id="15" string="such" />
            <token id="16" string="statements" />
            <token id="17" string="outside" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="commission" />
            <token id="21" string="and" />
            <token id="22" string="not" />
            <token id="23" string="under" />
            <token id="24" string="oath" />
            <token id="25" string="where" />
            <token id="26" string="they" />
            <token id="27" string="are" />
            <token id="28" string="available" />
            <token id="29" string="to" />
            <token id="30" string="be" />
            <token id="31" string="tested" />
            <token id="32" string="by" />
            <token id="33" string="cross-examination" />
          </tokens>
        </chunking>
        <chunking id="14" string="oath" type="NP">
          <tokens>
            <token id="24" string="oath" />
          </tokens>
        </chunking>
        <chunking id="15" string="are available to be tested by cross-examination" type="VP">
          <tokens>
            <token id="27" string="are" />
            <token id="28" string="available" />
            <token id="29" string="to" />
            <token id="30" string="be" />
            <token id="31" string="tested" />
            <token id="32" string="by" />
            <token id="33" string="cross-examination" />
          </tokens>
        </chunking>
        <chunking id="16" string="said it was `` totally irresponsible that Dr. Astaphan made such statements outside of the commission and not under oath where they are available to be tested by cross-examination" type="VP">
          <tokens>
            <token id="5" string="said" />
            <token id="6" string="it" />
            <token id="7" string="was" />
            <token id="8" string="&quot;" />
            <token id="9" string="totally" />
            <token id="10" string="irresponsible" />
            <token id="11" string="that" />
            <token id="12" string="Dr." />
            <token id="13" string="Astaphan" />
            <token id="14" string="made" />
            <token id="15" string="such" />
            <token id="16" string="statements" />
            <token id="17" string="outside" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="commission" />
            <token id="21" string="and" />
            <token id="22" string="not" />
            <token id="23" string="under" />
            <token id="24" string="oath" />
            <token id="25" string="where" />
            <token id="26" string="they" />
            <token id="27" string="are" />
            <token id="28" string="available" />
            <token id="29" string="to" />
            <token id="30" string="be" />
            <token id="31" string="tested" />
            <token id="32" string="by" />
            <token id="33" string="cross-examination" />
          </tokens>
        </chunking>
        <chunking id="17" string="that Dr. Astaphan made such statements outside of the commission and not under oath where they are available to be tested by cross-examination" type="SBAR">
          <tokens>
            <token id="11" string="that" />
            <token id="12" string="Dr." />
            <token id="13" string="Astaphan" />
            <token id="14" string="made" />
            <token id="15" string="such" />
            <token id="16" string="statements" />
            <token id="17" string="outside" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="commission" />
            <token id="21" string="and" />
            <token id="22" string="not" />
            <token id="23" string="under" />
            <token id="24" string="oath" />
            <token id="25" string="where" />
            <token id="26" string="they" />
            <token id="27" string="are" />
            <token id="28" string="available" />
            <token id="29" string="to" />
            <token id="30" string="be" />
            <token id="31" string="tested" />
            <token id="32" string="by" />
            <token id="33" string="cross-examination" />
          </tokens>
        </chunking>
        <chunking id="18" string="where" type="WHADVP">
          <tokens>
            <token id="25" string="where" />
          </tokens>
        </chunking>
        <chunking id="19" string="where they are available to be tested by cross-examination" type="SBAR">
          <tokens>
            <token id="25" string="where" />
            <token id="26" string="they" />
            <token id="27" string="are" />
            <token id="28" string="available" />
            <token id="29" string="to" />
            <token id="30" string="be" />
            <token id="31" string="tested" />
            <token id="32" string="by" />
            <token id="33" string="cross-examination" />
          </tokens>
        </chunking>
        <chunking id="20" string="was `` totally irresponsible that Dr. Astaphan made such statements outside of the commission and not under oath where they are available to be tested by cross-examination" type="VP">
          <tokens>
            <token id="7" string="was" />
            <token id="8" string="&quot;" />
            <token id="9" string="totally" />
            <token id="10" string="irresponsible" />
            <token id="11" string="that" />
            <token id="12" string="Dr." />
            <token id="13" string="Astaphan" />
            <token id="14" string="made" />
            <token id="15" string="such" />
            <token id="16" string="statements" />
            <token id="17" string="outside" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="commission" />
            <token id="21" string="and" />
            <token id="22" string="not" />
            <token id="23" string="under" />
            <token id="24" string="oath" />
            <token id="25" string="where" />
            <token id="26" string="they" />
            <token id="27" string="are" />
            <token id="28" string="available" />
            <token id="29" string="to" />
            <token id="30" string="be" />
            <token id="31" string="tested" />
            <token id="32" string="by" />
            <token id="33" string="cross-examination" />
          </tokens>
        </chunking>
        <chunking id="21" string="Dr. Astaphan" type="NP">
          <tokens>
            <token id="12" string="Dr." />
            <token id="13" string="Astaphan" />
          </tokens>
        </chunking>
        <chunking id="22" string="Commission counsel Robert Armstrong" type="NP">
          <tokens>
            <token id="1" string="Commission" />
            <token id="2" string="counsel" />
            <token id="3" string="Robert" />
            <token id="4" string="Armstrong" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="4">Armstrong</governor>
          <dependent id="1">Commission</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Armstrong</governor>
          <dependent id="2">counsel</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Armstrong</governor>
          <dependent id="3">Robert</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">said</governor>
          <dependent id="4">Armstrong</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">irresponsible</governor>
          <dependent id="6">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="10">irresponsible</governor>
          <dependent id="7">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">irresponsible</governor>
          <dependent id="9">totally</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">said</governor>
          <dependent id="10">irresponsible</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">made</governor>
          <dependent id="11">that</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Astaphan</governor>
          <dependent id="12">Dr.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">made</governor>
          <dependent id="13">Astaphan</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">irresponsible</governor>
          <dependent id="14">made</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">made</governor>
          <dependent id="14">made</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">statements</governor>
          <dependent id="15">such</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">made</governor>
          <dependent id="16">statements</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">commission</governor>
          <dependent id="17">outside</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="17">outside</governor>
          <dependent id="18">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">commission</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">made</governor>
          <dependent id="20">commission</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">made</governor>
          <dependent id="21">and</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="24">oath</governor>
          <dependent id="22">not</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">oath</governor>
          <dependent id="23">under</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">made</governor>
          <dependent id="24">oath</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="28">available</governor>
          <dependent id="25">where</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">available</governor>
          <dependent id="26">they</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="28">available</governor>
          <dependent id="27">are</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="24">oath</governor>
          <dependent id="28">available</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="31">tested</governor>
          <dependent id="29">to</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="31">tested</governor>
          <dependent id="30">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="28">available</governor>
          <dependent id="31">tested</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">cross-examination</governor>
          <dependent id="32">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">tested</governor>
          <dependent id="33">cross-examination</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Astaphan" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Astaphan" />
          </tokens>
        </entity>
        <entity id="2" string="Robert Armstrong" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Robert" />
            <token id="4" string="Armstrong" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="1-2-3" string="Ben Johnson 's" id_sentence="1" />
      <mentions>
        <mention ids_tokens="18" string="Johnson" id_sentence="2" />
        <mention ids_tokens="31" string="his" id_sentence="2" />
        <mention ids_tokens="6" string="Johnson" id_sentence="4" />
        <mention ids_tokens="2" string="He" id_sentence="5" />
        <mention ids_tokens="18" string="he" id_sentence="5" />
        <mention ids_tokens="3" string="Johnson" id_sentence="6" />
        <mention ids_tokens="9" string="he" id_sentence="6" />
        <mention ids_tokens="30" string="him" id_sentence="6" />
        <mention ids_tokens="32" string="he" id_sentence="6" />
        <mention ids_tokens="1" string="Johnson" id_sentence="9" />
        <mention ids_tokens="4" string="he" id_sentence="9" />
        <mention ids_tokens="10" string="Johnson" id_sentence="10" />
        <mention ids_tokens="2" string="Johnson" id_sentence="11" />
      </mentions>
    </coreference>
    <coreference id="2" type="NOMINAL">
      <referenced ids_tokens="1-2-3-4-5" string="Ben Johnson 's personal physician" id_sentence="1" />
      <mentions>
        <mention ids_tokens="40-41" string="Olympics officials" id_sentence="6" />
        <mention ids_tokens="12" string="I" id_sentence="7" />
        <mention ids_tokens="18" string="I" id_sentence="7" />
        <mention ids_tokens="20-22" string="his personal physician" id_sentence="7" />
        <mention ids_tokens="28" string="I" id_sentence="7" />
      </mentions>
    </coreference>
    <coreference id="3" type="PROPER">
      <referenced ids_tokens="22-23-24" string="the Seoul Olympics" id_sentence="1" />
      <mentions>
        <mention ids_tokens="40-42" string="Olympics gold medal" id_sentence="2" />
        <mention ids_tokens="40" string="Olympics" id_sentence="6" />
      </mentions>
    </coreference>
    <coreference id="4" type="NOMINAL">
      <referenced ids_tokens="28-29-30-31" string="the Toronto Star newspaper" id_sentence="1" />
      <mentions>
        <mention ids_tokens="17-18" string="the newspaper" id_sentence="3" />
      </mentions>
    </coreference>
    <coreference id="5" type="PROPER">
      <referenced ids_tokens="2-3" string="Jamie Astaphan" id_sentence="2" />
      <mentions>
        <mention ids_tokens="2" string="He" id_sentence="3" />
        <mention ids_tokens="10" string="him" id_sentence="3" />
        <mention ids_tokens="15" string="Astaphan" id_sentence="3" />
        <mention ids_tokens="7" string="me" id_sentence="5" />
        <mention ids_tokens="9" string="I" id_sentence="5" />
        <mention ids_tokens="11" string="him" id_sentence="5" />
        <mention ids_tokens="1" string="Astaphan" id_sentence="6" />
        <mention ids_tokens="3" string="he" id_sentence="7" />
        <mention ids_tokens="8" string="Astaphan" id_sentence="7" />
        <mention ids_tokens="20" string="his" id_sentence="7" />
        <mention ids_tokens="35" string="him" id_sentence="7" />
        <mention ids_tokens="26" string="him" id_sentence="8" />
        <mention ids_tokens="1" string="Astaphan" id_sentence="10" />
        <mention ids_tokens="4" string="he" id_sentence="10" />
      </mentions>
    </coreference>
    <coreference id="7" type="PROPER">
      <referenced ids_tokens="1-2-3" string="Dr. Jamie Astaphan" id_sentence="2" />
      <mentions>
        <mention ids_tokens="12-13" string="Dr. Astaphan" id_sentence="12" />
      </mentions>
    </coreference>
    <coreference id="8" type="NOMINAL">
      <referenced ids_tokens="10-11-12-13-14-15" string="the Caribbean island of St. Kitts" id_sentence="2" />
      <mentions>
        <mention ids_tokens="8" string="it" id_sentence="3" />
        <mention ids_tokens="5" string="it" id_sentence="4" />
      </mentions>
    </coreference>
    <coreference id="11" type="NOMINAL">
      <referenced ids_tokens="26-27-28-29-30-31-32-33-34-35" string="no way I can keep a constant check on him" id_sentence="7" />
      <mentions>
        <mention ids_tokens="3" string="it" id_sentence="8" />
      </mentions>
    </coreference>
    <coreference id="12" type="PROPER">
      <referenced ids_tokens="15-16" string="Canada 's" id_sentence="10" />
      <mentions>
        <mention ids_tokens="5" string="Canada" id_sentence="11" />
      </mentions>
    </coreference>
    <coreference id="13" type="LIST">
      <referenced ids_tokens="10-11-12-13" string="Johnson or other athletes" id_sentence="10" />
      <mentions>
        <mention ids_tokens="26" string="they" id_sentence="12" />
      </mentions>
    </coreference>
  </coreferences>
</document>
