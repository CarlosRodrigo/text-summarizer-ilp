<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="SJMN91-06184021">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>The label &amp;quot;black conservative,&amp;quot; now firmly affixed to Clarence Thomas&amp;apost; name, does not begin to tell the story of his life, an American story of transformation.; Born barnyard poor in segregated Georgia, forsaken by their father, Thomas and his brother were reared by strict Bible-believing grandparents who taught him to never say, &amp;quot;I can&amp;apost;t.&amp;quot;</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="label" lemma="label" stem="label" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="conservative" lemma="conservative" stem="conserv" pos="NN" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="9" string="firmly" lemma="firmly" stem="firmli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="affixed" lemma="affix" stem="affix" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Clarence" lemma="Clarence" stem="clarenc" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="13" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="14" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="name" lemma="name" stem="name" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="does" lemma="do" stem="doe" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="begin" lemma="begin" stem="begin" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="tell" lemma="tell" stem="tell" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="story" lemma="story" stem="stori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="life" lemma="life" stem="life" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="American" lemma="american" stem="american" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="30" string="story" lemma="story" stem="stori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="transformation." lemma="transformation." stem="transformation." pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="Born" lemma="bear" stem="born" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="barnyard" lemma="barnyard" stem="barnyard" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="poor" lemma="poor" stem="poor" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="segregated" lemma="segregate" stem="segreg" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="Georgia" lemma="Georgia" stem="georgia" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="40" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="forsaken" lemma="forsake" stem="forsaken" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="44" string="father" lemma="father" stem="father" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="45" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="47" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="48" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="49" string="brother" lemma="brother" stem="brother" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="50" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="51" string="reared" lemma="rear" stem="rear" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="52" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="53" string="strict" lemma="strict" stem="strict" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="54" string="Bible-believing" lemma="bible-believing" stem="bible-believ" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="55" string="grandparents" lemma="grandparent" stem="grandpar" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="56" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="57" string="taught" lemma="teach" stem="taught" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="58" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="59" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="60" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="61" string="say" lemma="say" stem="sai" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="62" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="63" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="64" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="65" string="ca" lemma="can" stem="ca" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="66" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="67" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="68" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT The) (NN label)) (`` ``) (NP (NP (JJ black) (NN conservative)) (, ,) ('' '') (NP (NP (RB now)) (VP (ADVP (RB firmly)) (VBN affixed) (PP (TO to) (NP (NP (NNP Clarence) (NNP Thomas) (POS ')) (NN name))))) (, ,)) (VP (VBZ does) (RB not) (VP (VB begin) (S (VP (TO to) (VP (VB tell) (NP (NP (DT the) (NN story)) (PP (IN of) (NP (PRP$ his) (NN life)))))))))) (, ,) (NP (NP (DT an) (JJ American) (NN story)) (PP (IN of) (NP (NN transformation.)))) (: ;) (S (VP (VBN Born) (S (NP (NN barnyard)) (ADJP (JJ poor))) (PP (IN in) (NP (NP (ADJP (VBN segregated)) (NNP Georgia)) (, ,) (VP (VBN forsaken) (PP (IN by) (NP (PRP$ their) (NN father)))))))) (PRN (, ,) (S (NP (NP (NNP Thomas)) (CC and) (NP (PRP$ his) (NN brother))) (VP (VBD were) (VP (VBN reared) (PP (IN by) (NP (NP (JJ strict) (JJ Bible-believing) (NNS grandparents)) (SBAR (WHNP (WP who)) (S (VP (VBD taught) (S (NP (PRP him)) (VP (TO to) (VP (ADVP (RB never)) (VB say)))))))))))) (, ,)) (`` ``) (NP (PRP I)) (VP (MD ca) (RB n't)) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="an American story of transformation." type="NP">
          <tokens>
            <token id="28" string="an" />
            <token id="29" string="American" />
            <token id="30" string="story" />
            <token id="31" string="of" />
            <token id="32" string="transformation." />
          </tokens>
        </chunking>
        <chunking id="2" string="Born barnyard poor in segregated Georgia , forsaken by their father" type="VP">
          <tokens>
            <token id="34" string="Born" />
            <token id="35" string="barnyard" />
            <token id="36" string="poor" />
            <token id="37" string="in" />
            <token id="38" string="segregated" />
            <token id="39" string="Georgia" />
            <token id="40" string="," />
            <token id="41" string="forsaken" />
            <token id="42" string="by" />
            <token id="43" string="their" />
            <token id="44" string="father" />
          </tokens>
        </chunking>
        <chunking id="3" string="Thomas and his brother" type="NP">
          <tokens>
            <token id="46" string="Thomas" />
            <token id="47" string="and" />
            <token id="48" string="his" />
            <token id="49" string="brother" />
          </tokens>
        </chunking>
        <chunking id="4" string="now firmly affixed to Clarence Thomas ' name" type="NP">
          <tokens>
            <token id="8" string="now" />
            <token id="9" string="firmly" />
            <token id="10" string="affixed" />
            <token id="11" string="to" />
            <token id="12" string="Clarence" />
            <token id="13" string="Thomas" />
            <token id="14" string="'" />
            <token id="15" string="name" />
          </tokens>
        </chunking>
        <chunking id="5" string="firmly affixed to Clarence Thomas ' name" type="VP">
          <tokens>
            <token id="9" string="firmly" />
            <token id="10" string="affixed" />
            <token id="11" string="to" />
            <token id="12" string="Clarence" />
            <token id="13" string="Thomas" />
            <token id="14" string="'" />
            <token id="15" string="name" />
          </tokens>
        </chunking>
        <chunking id="6" string="Thomas" type="NP">
          <tokens>
            <token id="46" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="7" string="Clarence Thomas ' name" type="NP">
          <tokens>
            <token id="12" string="Clarence" />
            <token id="13" string="Thomas" />
            <token id="14" string="'" />
            <token id="15" string="name" />
          </tokens>
        </chunking>
        <chunking id="8" string="were reared by strict Bible-believing grandparents who taught him to never say" type="VP">
          <tokens>
            <token id="50" string="were" />
            <token id="51" string="reared" />
            <token id="52" string="by" />
            <token id="53" string="strict" />
            <token id="54" string="Bible-believing" />
            <token id="55" string="grandparents" />
            <token id="56" string="who" />
            <token id="57" string="taught" />
            <token id="58" string="him" />
            <token id="59" string="to" />
            <token id="60" string="never" />
            <token id="61" string="say" />
          </tokens>
        </chunking>
        <chunking id="9" string="the story" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="story" />
          </tokens>
        </chunking>
        <chunking id="10" string="segregated Georgia" type="NP">
          <tokens>
            <token id="38" string="segregated" />
            <token id="39" string="Georgia" />
          </tokens>
        </chunking>
        <chunking id="11" string="tell the story of his life" type="VP">
          <tokens>
            <token id="21" string="tell" />
            <token id="22" string="the" />
            <token id="23" string="story" />
            <token id="24" string="of" />
            <token id="25" string="his" />
            <token id="26" string="life" />
          </tokens>
        </chunking>
        <chunking id="12" string="strict Bible-believing grandparents who taught him to never say" type="NP">
          <tokens>
            <token id="53" string="strict" />
            <token id="54" string="Bible-believing" />
            <token id="55" string="grandparents" />
            <token id="56" string="who" />
            <token id="57" string="taught" />
            <token id="58" string="him" />
            <token id="59" string="to" />
            <token id="60" string="never" />
            <token id="61" string="say" />
          </tokens>
        </chunking>
        <chunking id="13" string="to tell the story of his life" type="VP">
          <tokens>
            <token id="20" string="to" />
            <token id="21" string="tell" />
            <token id="22" string="the" />
            <token id="23" string="story" />
            <token id="24" string="of" />
            <token id="25" string="his" />
            <token id="26" string="life" />
          </tokens>
        </chunking>
        <chunking id="14" string="transformation." type="NP">
          <tokens>
            <token id="32" string="transformation." />
          </tokens>
        </chunking>
        <chunking id="15" string="their father" type="NP">
          <tokens>
            <token id="43" string="their" />
            <token id="44" string="father" />
          </tokens>
        </chunking>
        <chunking id="16" string="begin to tell the story of his life" type="VP">
          <tokens>
            <token id="19" string="begin" />
            <token id="20" string="to" />
            <token id="21" string="tell" />
            <token id="22" string="the" />
            <token id="23" string="story" />
            <token id="24" string="of" />
            <token id="25" string="his" />
            <token id="26" string="life" />
          </tokens>
        </chunking>
        <chunking id="17" string="segregated" type="ADJP">
          <tokens>
            <token id="38" string="segregated" />
          </tokens>
        </chunking>
        <chunking id="18" string="black conservative , '' now firmly affixed to Clarence Thomas ' name ," type="NP">
          <tokens>
            <token id="4" string="black" />
            <token id="5" string="conservative" />
            <token id="6" string="," />
            <token id="7" string="&quot;" />
            <token id="8" string="now" />
            <token id="9" string="firmly" />
            <token id="10" string="affixed" />
            <token id="11" string="to" />
            <token id="12" string="Clarence" />
            <token id="13" string="Thomas" />
            <token id="14" string="'" />
            <token id="15" string="name" />
            <token id="16" string="," />
          </tokens>
        </chunking>
        <chunking id="19" string="Clarence Thomas '" type="NP">
          <tokens>
            <token id="12" string="Clarence" />
            <token id="13" string="Thomas" />
            <token id="14" string="'" />
          </tokens>
        </chunking>
        <chunking id="20" string="reared by strict Bible-believing grandparents who taught him to never say" type="VP">
          <tokens>
            <token id="51" string="reared" />
            <token id="52" string="by" />
            <token id="53" string="strict" />
            <token id="54" string="Bible-believing" />
            <token id="55" string="grandparents" />
            <token id="56" string="who" />
            <token id="57" string="taught" />
            <token id="58" string="him" />
            <token id="59" string="to" />
            <token id="60" string="never" />
            <token id="61" string="say" />
          </tokens>
        </chunking>
        <chunking id="21" string="segregated Georgia , forsaken by their father" type="NP">
          <tokens>
            <token id="38" string="segregated" />
            <token id="39" string="Georgia" />
            <token id="40" string="," />
            <token id="41" string="forsaken" />
            <token id="42" string="by" />
            <token id="43" string="their" />
            <token id="44" string="father" />
          </tokens>
        </chunking>
        <chunking id="22" string="forsaken by their father" type="VP">
          <tokens>
            <token id="41" string="forsaken" />
            <token id="42" string="by" />
            <token id="43" string="their" />
            <token id="44" string="father" />
          </tokens>
        </chunking>
        <chunking id="23" string="I" type="NP">
          <tokens>
            <token id="64" string="I" />
          </tokens>
        </chunking>
        <chunking id="24" string="black conservative" type="NP">
          <tokens>
            <token id="4" string="black" />
            <token id="5" string="conservative" />
          </tokens>
        </chunking>
        <chunking id="25" string="barnyard" type="NP">
          <tokens>
            <token id="35" string="barnyard" />
          </tokens>
        </chunking>
        <chunking id="26" string="him" type="NP">
          <tokens>
            <token id="58" string="him" />
          </tokens>
        </chunking>
        <chunking id="27" string="ca n't" type="VP">
          <tokens>
            <token id="65" string="ca" />
            <token id="66" string="n't" />
          </tokens>
        </chunking>
        <chunking id="28" string="the story of his life" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="story" />
            <token id="24" string="of" />
            <token id="25" string="his" />
            <token id="26" string="life" />
          </tokens>
        </chunking>
        <chunking id="29" string="who taught him to never say" type="SBAR">
          <tokens>
            <token id="56" string="who" />
            <token id="57" string="taught" />
            <token id="58" string="him" />
            <token id="59" string="to" />
            <token id="60" string="never" />
            <token id="61" string="say" />
          </tokens>
        </chunking>
        <chunking id="30" string="his life" type="NP">
          <tokens>
            <token id="25" string="his" />
            <token id="26" string="life" />
          </tokens>
        </chunking>
        <chunking id="31" string="does not begin to tell the story of his life" type="VP">
          <tokens>
            <token id="17" string="does" />
            <token id="18" string="not" />
            <token id="19" string="begin" />
            <token id="20" string="to" />
            <token id="21" string="tell" />
            <token id="22" string="the" />
            <token id="23" string="story" />
            <token id="24" string="of" />
            <token id="25" string="his" />
            <token id="26" string="life" />
          </tokens>
        </chunking>
        <chunking id="32" string="strict Bible-believing grandparents" type="NP">
          <tokens>
            <token id="53" string="strict" />
            <token id="54" string="Bible-believing" />
            <token id="55" string="grandparents" />
          </tokens>
        </chunking>
        <chunking id="33" string="now" type="NP">
          <tokens>
            <token id="8" string="now" />
          </tokens>
        </chunking>
        <chunking id="34" string="poor" type="ADJP">
          <tokens>
            <token id="36" string="poor" />
          </tokens>
        </chunking>
        <chunking id="35" string="to never say" type="VP">
          <tokens>
            <token id="59" string="to" />
            <token id="60" string="never" />
            <token id="61" string="say" />
          </tokens>
        </chunking>
        <chunking id="36" string="taught him to never say" type="VP">
          <tokens>
            <token id="57" string="taught" />
            <token id="58" string="him" />
            <token id="59" string="to" />
            <token id="60" string="never" />
            <token id="61" string="say" />
          </tokens>
        </chunking>
        <chunking id="37" string="his brother" type="NP">
          <tokens>
            <token id="48" string="his" />
            <token id="49" string="brother" />
          </tokens>
        </chunking>
        <chunking id="38" string="The label" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="label" />
          </tokens>
        </chunking>
        <chunking id="39" string="never say" type="VP">
          <tokens>
            <token id="60" string="never" />
            <token id="61" string="say" />
          </tokens>
        </chunking>
        <chunking id="40" string="an American story" type="NP">
          <tokens>
            <token id="28" string="an" />
            <token id="29" string="American" />
            <token id="30" string="story" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">label</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">begin</governor>
          <dependent id="2">label</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">conservative</governor>
          <dependent id="4">black</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">begin</governor>
          <dependent id="5">conservative</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="5">conservative</governor>
          <dependent id="8">now</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">affixed</governor>
          <dependent id="9">firmly</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="8">now</governor>
          <dependent id="10">affixed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">name</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Thomas</governor>
          <dependent id="12">Clarence</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">name</governor>
          <dependent id="13">Thomas</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Thomas</governor>
          <dependent id="14">'</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">affixed</governor>
          <dependent id="15">name</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="19">begin</governor>
          <dependent id="17">does</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="19">begin</governor>
          <dependent id="18">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="65">ca</governor>
          <dependent id="19">begin</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">tell</governor>
          <dependent id="20">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="19">begin</governor>
          <dependent id="21">tell</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">story</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">tell</governor>
          <dependent id="23">story</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">life</governor>
          <dependent id="24">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="26">life</governor>
          <dependent id="25">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">story</governor>
          <dependent id="26">life</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">story</governor>
          <dependent id="28">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="30">story</governor>
          <dependent id="29">American</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="65">ca</governor>
          <dependent id="30">story</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">transformation.</governor>
          <dependent id="31">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">story</governor>
          <dependent id="32">transformation.</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="65">ca</governor>
          <dependent id="34">Born</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="36">poor</governor>
          <dependent id="35">barnyard</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="34">Born</governor>
          <dependent id="36">poor</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">Georgia</governor>
          <dependent id="37">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="39">Georgia</governor>
          <dependent id="38">segregated</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="34">Born</governor>
          <dependent id="39">Georgia</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="39">Georgia</governor>
          <dependent id="41">forsaken</dependent>
        </dependency>
        <dependency type="case">
          <governor id="44">father</governor>
          <dependent id="42">by</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="44">father</governor>
          <dependent id="43">their</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="41">forsaken</governor>
          <dependent id="44">father</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="51">reared</governor>
          <dependent id="46">Thomas</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="46">Thomas</governor>
          <dependent id="47">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="49">brother</governor>
          <dependent id="48">his</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="46">Thomas</governor>
          <dependent id="49">brother</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="51">reared</governor>
          <dependent id="50">were</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="65">ca</governor>
          <dependent id="51">reared</dependent>
        </dependency>
        <dependency type="case">
          <governor id="55">grandparents</governor>
          <dependent id="52">by</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="55">grandparents</governor>
          <dependent id="53">strict</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="55">grandparents</governor>
          <dependent id="54">Bible-believing</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="51">reared</governor>
          <dependent id="55">grandparents</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="57">taught</governor>
          <dependent id="56">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="55">grandparents</governor>
          <dependent id="57">taught</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="57">taught</governor>
          <dependent id="58">him</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="61">say</governor>
          <dependent id="59">to</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="61">say</governor>
          <dependent id="60">never</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="57">taught</governor>
          <dependent id="61">say</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="65">ca</governor>
          <dependent id="64">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="65">ca</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="65">ca</governor>
          <dependent id="66">n't</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="conservative" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="5" string="conservative" />
          </tokens>
        </entity>
        <entity id="2" string="Bible-believing" type="MISC" score="0.0">
          <tokens>
            <token id="54" string="Bible-believing" />
          </tokens>
        </entity>
        <entity id="3" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="8" string="now" />
          </tokens>
        </entity>
        <entity id="4" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="46" string="Thomas" />
          </tokens>
        </entity>
        <entity id="5" string="Georgia" type="LOCATION" score="0.0">
          <tokens>
            <token id="39" string="Georgia" />
          </tokens>
        </entity>
        <entity id="6" string="American" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="29" string="American" />
          </tokens>
        </entity>
        <entity id="7" string="Clarence Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Clarence" />
            <token id="13" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>Thomas and his brother made it in the white world.</content>
      <tokens>
        <token id="1" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="brother" lemma="brother" stem="brother" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="made" lemma="make" stem="made" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="white" lemma="white" stem="white" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Thomas)) (CC and) (NP (PRP$ his) (NN brother))) (VP (VBD made) (NP (PRP it)) (PP (IN in) (NP (DT the) (JJ white) (NN world)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Thomas and his brother" type="NP">
          <tokens>
            <token id="1" string="Thomas" />
            <token id="2" string="and" />
            <token id="3" string="his" />
            <token id="4" string="brother" />
          </tokens>
        </chunking>
        <chunking id="2" string="Thomas" type="NP">
          <tokens>
            <token id="1" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="3" string="the white world" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="white" />
            <token id="10" string="world" />
          </tokens>
        </chunking>
        <chunking id="4" string="his brother" type="NP">
          <tokens>
            <token id="3" string="his" />
            <token id="4" string="brother" />
          </tokens>
        </chunking>
        <chunking id="5" string="made it in the white world" type="VP">
          <tokens>
            <token id="5" string="made" />
            <token id="6" string="it" />
            <token id="7" string="in" />
            <token id="8" string="the" />
            <token id="9" string="white" />
            <token id="10" string="world" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="6" string="it" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">made</governor>
          <dependent id="1">Thomas</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="1">Thomas</governor>
          <dependent id="2">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">brother</governor>
          <dependent id="3">his</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="1">Thomas</governor>
          <dependent id="4">brother</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">made</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">made</governor>
          <dependent id="6">it</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">world</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">world</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">world</governor>
          <dependent id="9">white</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">made</governor>
          <dependent id="10">world</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>Their sister, reared by an aunt, had four children and went on welfare.</content>
      <tokens>
        <token id="1" string="Their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="sister" lemma="sister" stem="sister" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="reared" lemma="rear" stem="rear" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="aunt" lemma="aunt" stem="aunt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="four" lemma="four" stem="four" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="11" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="went" lemma="go" stem="went" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="welfare" lemma="welfare" stem="welfar" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (PRP$ Their) (NN sister)) (, ,) (VP (VBN reared) (PP (IN by) (NP (DT an) (NN aunt)))) (, ,)) (VP (VP (VBD had) (NP (CD four) (NNS children))) (CC and) (VP (VBD went) (PP (IN on) (NP (NN welfare))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="had four children" type="VP">
          <tokens>
            <token id="9" string="had" />
            <token id="10" string="four" />
            <token id="11" string="children" />
          </tokens>
        </chunking>
        <chunking id="2" string="went on welfare" type="VP">
          <tokens>
            <token id="13" string="went" />
            <token id="14" string="on" />
            <token id="15" string="welfare" />
          </tokens>
        </chunking>
        <chunking id="3" string="reared by an aunt" type="VP">
          <tokens>
            <token id="4" string="reared" />
            <token id="5" string="by" />
            <token id="6" string="an" />
            <token id="7" string="aunt" />
          </tokens>
        </chunking>
        <chunking id="4" string="four children" type="NP">
          <tokens>
            <token id="10" string="four" />
            <token id="11" string="children" />
          </tokens>
        </chunking>
        <chunking id="5" string="had four children and went on welfare" type="VP">
          <tokens>
            <token id="9" string="had" />
            <token id="10" string="four" />
            <token id="11" string="children" />
            <token id="12" string="and" />
            <token id="13" string="went" />
            <token id="14" string="on" />
            <token id="15" string="welfare" />
          </tokens>
        </chunking>
        <chunking id="6" string="Their sister , reared by an aunt ," type="NP">
          <tokens>
            <token id="1" string="Their" />
            <token id="2" string="sister" />
            <token id="3" string="," />
            <token id="4" string="reared" />
            <token id="5" string="by" />
            <token id="6" string="an" />
            <token id="7" string="aunt" />
            <token id="8" string="," />
          </tokens>
        </chunking>
        <chunking id="7" string="welfare" type="NP">
          <tokens>
            <token id="15" string="welfare" />
          </tokens>
        </chunking>
        <chunking id="8" string="an aunt" type="NP">
          <tokens>
            <token id="6" string="an" />
            <token id="7" string="aunt" />
          </tokens>
        </chunking>
        <chunking id="9" string="Their sister" type="NP">
          <tokens>
            <token id="1" string="Their" />
            <token id="2" string="sister" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="2">sister</governor>
          <dependent id="1">Their</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">had</governor>
          <dependent id="2">sister</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="2">sister</governor>
          <dependent id="4">reared</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">aunt</governor>
          <dependent id="5">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">aunt</governor>
          <dependent id="6">an</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">reared</governor>
          <dependent id="7">aunt</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">had</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="11">children</governor>
          <dependent id="10">four</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">had</governor>
          <dependent id="11">children</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">had</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">had</governor>
          <dependent id="13">went</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">welfare</governor>
          <dependent id="14">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">went</governor>
          <dependent id="15">welfare</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="four" type="NUMBER" score="0.0">
          <tokens>
            <token id="10" string="four" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>Thomas, 43, credits everything he has achieved to his grandparents.</content>
      <tokens>
        <token id="1" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="43" lemma="43" stem="43" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="true" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="credits" lemma="credit" stem="credit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="everything" lemma="everything" stem="everyth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="achieved" lemma="achieve" stem="achiev" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="grandparents" lemma="grandparent" stem="grandpar" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (NNP Thomas)) (, ,) (NP (CD 43)) (, ,) (NP (NP (NNS credits) (NN everything)) (SBAR (S (NP (PRP he)) (VP (VBZ has) (VP (VBN achieved) (PP (TO to) (NP (PRP$ his) (NNS grandparents)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="his grandparents" type="NP">
          <tokens>
            <token id="11" string="his" />
            <token id="12" string="grandparents" />
          </tokens>
        </chunking>
        <chunking id="2" string="credits everything" type="NP">
          <tokens>
            <token id="5" string="credits" />
            <token id="6" string="everything" />
          </tokens>
        </chunking>
        <chunking id="3" string="credits everything he has achieved to his grandparents" type="NP">
          <tokens>
            <token id="5" string="credits" />
            <token id="6" string="everything" />
            <token id="7" string="he" />
            <token id="8" string="has" />
            <token id="9" string="achieved" />
            <token id="10" string="to" />
            <token id="11" string="his" />
            <token id="12" string="grandparents" />
          </tokens>
        </chunking>
        <chunking id="4" string="Thomas" type="NP">
          <tokens>
            <token id="1" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="5" string="he has achieved to his grandparents" type="SBAR">
          <tokens>
            <token id="7" string="he" />
            <token id="8" string="has" />
            <token id="9" string="achieved" />
            <token id="10" string="to" />
            <token id="11" string="his" />
            <token id="12" string="grandparents" />
          </tokens>
        </chunking>
        <chunking id="6" string="achieved to his grandparents" type="VP">
          <tokens>
            <token id="9" string="achieved" />
            <token id="10" string="to" />
            <token id="11" string="his" />
            <token id="12" string="grandparents" />
          </tokens>
        </chunking>
        <chunking id="7" string="Thomas , 43 , credits everything he has achieved to his grandparents ." type="NP">
          <tokens>
            <token id="1" string="Thomas" />
            <token id="2" string="," />
            <token id="3" string="43" />
            <token id="4" string="," />
            <token id="5" string="credits" />
            <token id="6" string="everything" />
            <token id="7" string="he" />
            <token id="8" string="has" />
            <token id="9" string="achieved" />
            <token id="10" string="to" />
            <token id="11" string="his" />
            <token id="12" string="grandparents" />
            <token id="13" string="." />
          </tokens>
        </chunking>
        <chunking id="8" string="he" type="NP">
          <tokens>
            <token id="7" string="he" />
          </tokens>
        </chunking>
        <chunking id="9" string="has achieved to his grandparents" type="VP">
          <tokens>
            <token id="8" string="has" />
            <token id="9" string="achieved" />
            <token id="10" string="to" />
            <token id="11" string="his" />
            <token id="12" string="grandparents" />
          </tokens>
        </chunking>
        <chunking id="10" string="43" type="NP">
          <tokens>
            <token id="3" string="43" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">Thomas</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="1">Thomas</governor>
          <dependent id="3">43</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">everything</governor>
          <dependent id="5">credits</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="1">Thomas</governor>
          <dependent id="6">everything</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">achieved</governor>
          <dependent id="7">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">achieved</governor>
          <dependent id="8">has</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="6">everything</governor>
          <dependent id="9">achieved</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">grandparents</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">grandparents</governor>
          <dependent id="11">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">achieved</governor>
          <dependent id="12">grandparents</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Thomas" />
          </tokens>
        </entity>
        <entity id="2" string="43" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="43" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>He choked up twice on national television Monday when he mentioned them.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="choked" lemma="choke" stem="choke" pos="VBD" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="3" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="twice" lemma="twice" stem="twice" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="national" lemma="national" stem="nation" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="television" lemma="television" stem="televis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="Monday" lemma="Monday" stem="mondai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="9" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="mentioned" lemma="mention" stem="mention" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD choked) (PRT (RP up)) (ADVP (RB twice) (PP (IN on) (NP (JJ national) (NN television)))) (NP-TMP (NNP Monday)) (SBAR (WHADVP (WRB when)) (S (NP (PRP he)) (VP (VBD mentioned) (NP (PRP them)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="national television" type="NP">
          <tokens>
            <token id="6" string="national" />
            <token id="7" string="television" />
          </tokens>
        </chunking>
        <chunking id="2" string="when he mentioned them" type="SBAR">
          <tokens>
            <token id="9" string="when" />
            <token id="10" string="he" />
            <token id="11" string="mentioned" />
            <token id="12" string="them" />
          </tokens>
        </chunking>
        <chunking id="3" string="mentioned them" type="VP">
          <tokens>
            <token id="11" string="mentioned" />
            <token id="12" string="them" />
          </tokens>
        </chunking>
        <chunking id="4" string="choked up twice on national television Monday when he mentioned them" type="VP">
          <tokens>
            <token id="2" string="choked" />
            <token id="3" string="up" />
            <token id="4" string="twice" />
            <token id="5" string="on" />
            <token id="6" string="national" />
            <token id="7" string="television" />
            <token id="8" string="Monday" />
            <token id="9" string="when" />
            <token id="10" string="he" />
            <token id="11" string="mentioned" />
            <token id="12" string="them" />
          </tokens>
        </chunking>
        <chunking id="5" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="6" string="he" type="NP">
          <tokens>
            <token id="10" string="he" />
          </tokens>
        </chunking>
        <chunking id="7" string="them" type="NP">
          <tokens>
            <token id="12" string="them" />
          </tokens>
        </chunking>
        <chunking id="8" string="when" type="WHADVP">
          <tokens>
            <token id="9" string="when" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">choked</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">choked</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="2">choked</governor>
          <dependent id="3">up</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="2">choked</governor>
          <dependent id="4">twice</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">television</governor>
          <dependent id="5">on</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">television</governor>
          <dependent id="6">national</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">twice</governor>
          <dependent id="7">television</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="2">choked</governor>
          <dependent id="8">Monday</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">mentioned</governor>
          <dependent id="9">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">mentioned</governor>
          <dependent id="10">he</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="2">choked</governor>
          <dependent id="11">mentioned</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">mentioned</governor>
          <dependent id="12">them</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="choked" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="2" string="choked" />
          </tokens>
        </entity>
        <entity id="2" string="Monday" type="DATE" score="0.0">
          <tokens>
            <token id="8" string="Monday" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>In a hostile world, they taught him to rely on himself.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="hostile" lemma="hostile" stem="hostil" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="taught" lemma="teach" stem="taught" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="rely" lemma="rely" stem="reli" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="himself" lemma="himself" stem="himself" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (DT a) (JJ hostile) (NN world))) (, ,) (NP (PRP they)) (VP (VBD taught) (S (NP (PRP him)) (VP (TO to) (VP (VB rely) (PP (IN on) (NP (PRP himself))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="they" type="NP">
          <tokens>
            <token id="6" string="they" />
          </tokens>
        </chunking>
        <chunking id="2" string="taught him to rely on himself" type="VP">
          <tokens>
            <token id="7" string="taught" />
            <token id="8" string="him" />
            <token id="9" string="to" />
            <token id="10" string="rely" />
            <token id="11" string="on" />
            <token id="12" string="himself" />
          </tokens>
        </chunking>
        <chunking id="3" string="to rely on himself" type="VP">
          <tokens>
            <token id="9" string="to" />
            <token id="10" string="rely" />
            <token id="11" string="on" />
            <token id="12" string="himself" />
          </tokens>
        </chunking>
        <chunking id="4" string="him" type="NP">
          <tokens>
            <token id="8" string="him" />
          </tokens>
        </chunking>
        <chunking id="5" string="rely on himself" type="VP">
          <tokens>
            <token id="10" string="rely" />
            <token id="11" string="on" />
            <token id="12" string="himself" />
          </tokens>
        </chunking>
        <chunking id="6" string="himself" type="NP">
          <tokens>
            <token id="12" string="himself" />
          </tokens>
        </chunking>
        <chunking id="7" string="a hostile world" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="hostile" />
            <token id="4" string="world" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">world</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">world</governor>
          <dependent id="2">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">world</governor>
          <dependent id="3">hostile</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">taught</governor>
          <dependent id="4">world</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">taught</governor>
          <dependent id="6">they</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">taught</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">taught</governor>
          <dependent id="8">him</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">rely</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">taught</governor>
          <dependent id="10">rely</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">himself</governor>
          <dependent id="11">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">rely</governor>
          <dependent id="12">himself</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>They shaped his views on individualism, race and society, views that guide him today.</content>
      <tokens>
        <token id="1" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="shaped" lemma="shape" stem="shape" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="views" lemma="view" stem="view" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="individualism" lemma="individualism" stem="individu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="race" lemma="race" stem="race" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="society" lemma="society" stem="societi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="views" lemma="view" stem="view" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="guide" lemma="guide" stem="guid" pos="VBP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="16" string="today" lemma="today" stem="todai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP They)) (VP (VBD shaped) (NP (PRP$ his) (NNS views)) (PP (IN on) (NP (NP (NN individualism) (, ,) (NN race) (CC and) (NN society)) (, ,) (NP (NP (NNS views)) (SBAR (WHNP (WDT that)) (S (VP (VBP guide) (NP (PRP him)) (NP-TMP (NN today))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="1" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="individualism , race and society , views that guide him today" type="NP">
          <tokens>
            <token id="6" string="individualism" />
            <token id="7" string="," />
            <token id="8" string="race" />
            <token id="9" string="and" />
            <token id="10" string="society" />
            <token id="11" string="," />
            <token id="12" string="views" />
            <token id="13" string="that" />
            <token id="14" string="guide" />
            <token id="15" string="him" />
            <token id="16" string="today" />
          </tokens>
        </chunking>
        <chunking id="3" string="views that guide him today" type="NP">
          <tokens>
            <token id="12" string="views" />
            <token id="13" string="that" />
            <token id="14" string="guide" />
            <token id="15" string="him" />
            <token id="16" string="today" />
          </tokens>
        </chunking>
        <chunking id="4" string="that guide him today" type="SBAR">
          <tokens>
            <token id="13" string="that" />
            <token id="14" string="guide" />
            <token id="15" string="him" />
            <token id="16" string="today" />
          </tokens>
        </chunking>
        <chunking id="5" string="shaped his views on individualism , race and society , views that guide him today" type="VP">
          <tokens>
            <token id="2" string="shaped" />
            <token id="3" string="his" />
            <token id="4" string="views" />
            <token id="5" string="on" />
            <token id="6" string="individualism" />
            <token id="7" string="," />
            <token id="8" string="race" />
            <token id="9" string="and" />
            <token id="10" string="society" />
            <token id="11" string="," />
            <token id="12" string="views" />
            <token id="13" string="that" />
            <token id="14" string="guide" />
            <token id="15" string="him" />
            <token id="16" string="today" />
          </tokens>
        </chunking>
        <chunking id="6" string="guide him today" type="VP">
          <tokens>
            <token id="14" string="guide" />
            <token id="15" string="him" />
            <token id="16" string="today" />
          </tokens>
        </chunking>
        <chunking id="7" string="him" type="NP">
          <tokens>
            <token id="15" string="him" />
          </tokens>
        </chunking>
        <chunking id="8" string="individualism , race and society" type="NP">
          <tokens>
            <token id="6" string="individualism" />
            <token id="7" string="," />
            <token id="8" string="race" />
            <token id="9" string="and" />
            <token id="10" string="society" />
          </tokens>
        </chunking>
        <chunking id="9" string="views" type="NP">
          <tokens>
            <token id="12" string="views" />
          </tokens>
        </chunking>
        <chunking id="10" string="his views" type="NP">
          <tokens>
            <token id="3" string="his" />
            <token id="4" string="views" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">shaped</governor>
          <dependent id="1">They</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">shaped</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">views</governor>
          <dependent id="3">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">shaped</governor>
          <dependent id="4">views</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">individualism</governor>
          <dependent id="5">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">shaped</governor>
          <dependent id="6">individualism</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">individualism</governor>
          <dependent id="8">race</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">individualism</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">individualism</governor>
          <dependent id="10">society</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="6">individualism</governor>
          <dependent id="12">views</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">guide</governor>
          <dependent id="13">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="12">views</governor>
          <dependent id="14">guide</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">guide</governor>
          <dependent id="15">him</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="14">guide</governor>
          <dependent id="16">today</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="today" type="DATE" score="0.0">
          <tokens>
            <token id="16" string="today" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>&amp;quot;I was raised to survive under the totalitarianism of segregation,&amp;quot; Thomas wrote in a paper for the Heritage Foundation, a conservative public policy institute in Washington.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="raised" lemma="raise" stem="rais" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="survive" lemma="survive" stem="surviv" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="under" lemma="under" stem="under" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="totalitarianism" lemma="totalitarianism" stem="totalitarian" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="segregation" lemma="segregation" stem="segreg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="15" string="wrote" lemma="write" stem="wrote" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="paper" lemma="paper" stem="paper" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="Heritage" lemma="Heritage" stem="heritag" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="22" string="Foundation" lemma="Foundation" stem="foundat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="conservative" lemma="conservative" stem="conserv" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="26" string="public" lemma="public" stem="public" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="policy" lemma="policy" stem="polici" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="institute" lemma="institute" stem="institut" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="Washington" lemma="Washington" stem="washington" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP I)) (VP (VBD was) (VP (VBN raised) (S (VP (TO to) (VP (VB survive) (PP (IN under) (NP (NP (DT the) (NN totalitarianism)) (PP (IN of) (NP (NN segregation))))))))))) (, ,) ('' '') (NP (NNP Thomas)) (VP (VBD wrote) (PP (IN in) (NP (DT a) (NN paper))) (PP (IN for) (NP (NP (DT the) (NNP Heritage) (NNP Foundation)) (, ,) (NP (NP (DT a) (JJ conservative) (JJ public) (NN policy) (NN institute)) (PP (IN in) (NP (NNP Washington))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a paper" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="paper" />
          </tokens>
        </chunking>
        <chunking id="2" string="the Heritage Foundation , a conservative public policy institute in Washington" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="Heritage" />
            <token id="22" string="Foundation" />
            <token id="23" string="," />
            <token id="24" string="a" />
            <token id="25" string="conservative" />
            <token id="26" string="public" />
            <token id="27" string="policy" />
            <token id="28" string="institute" />
            <token id="29" string="in" />
            <token id="30" string="Washington" />
          </tokens>
        </chunking>
        <chunking id="3" string="Thomas" type="NP">
          <tokens>
            <token id="14" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="wrote in a paper for the Heritage Foundation , a conservative public policy institute in Washington" type="VP">
          <tokens>
            <token id="15" string="wrote" />
            <token id="16" string="in" />
            <token id="17" string="a" />
            <token id="18" string="paper" />
            <token id="19" string="for" />
            <token id="20" string="the" />
            <token id="21" string="Heritage" />
            <token id="22" string="Foundation" />
            <token id="23" string="," />
            <token id="24" string="a" />
            <token id="25" string="conservative" />
            <token id="26" string="public" />
            <token id="27" string="policy" />
            <token id="28" string="institute" />
            <token id="29" string="in" />
            <token id="30" string="Washington" />
          </tokens>
        </chunking>
        <chunking id="6" string="was raised to survive under the totalitarianism of segregation" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="raised" />
            <token id="5" string="to" />
            <token id="6" string="survive" />
            <token id="7" string="under" />
            <token id="8" string="the" />
            <token id="9" string="totalitarianism" />
            <token id="10" string="of" />
            <token id="11" string="segregation" />
          </tokens>
        </chunking>
        <chunking id="7" string="raised to survive under the totalitarianism of segregation" type="VP">
          <tokens>
            <token id="4" string="raised" />
            <token id="5" string="to" />
            <token id="6" string="survive" />
            <token id="7" string="under" />
            <token id="8" string="the" />
            <token id="9" string="totalitarianism" />
            <token id="10" string="of" />
            <token id="11" string="segregation" />
          </tokens>
        </chunking>
        <chunking id="8" string="Washington" type="NP">
          <tokens>
            <token id="30" string="Washington" />
          </tokens>
        </chunking>
        <chunking id="9" string="the Heritage Foundation" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="Heritage" />
            <token id="22" string="Foundation" />
          </tokens>
        </chunking>
        <chunking id="10" string="survive under the totalitarianism of segregation" type="VP">
          <tokens>
            <token id="6" string="survive" />
            <token id="7" string="under" />
            <token id="8" string="the" />
            <token id="9" string="totalitarianism" />
            <token id="10" string="of" />
            <token id="11" string="segregation" />
          </tokens>
        </chunking>
        <chunking id="11" string="to survive under the totalitarianism of segregation" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="survive" />
            <token id="7" string="under" />
            <token id="8" string="the" />
            <token id="9" string="totalitarianism" />
            <token id="10" string="of" />
            <token id="11" string="segregation" />
          </tokens>
        </chunking>
        <chunking id="12" string="a conservative public policy institute in Washington" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="conservative" />
            <token id="26" string="public" />
            <token id="27" string="policy" />
            <token id="28" string="institute" />
            <token id="29" string="in" />
            <token id="30" string="Washington" />
          </tokens>
        </chunking>
        <chunking id="13" string="the totalitarianism" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="totalitarianism" />
          </tokens>
        </chunking>
        <chunking id="14" string="the totalitarianism of segregation" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="totalitarianism" />
            <token id="10" string="of" />
            <token id="11" string="segregation" />
          </tokens>
        </chunking>
        <chunking id="15" string="a conservative public policy institute" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="conservative" />
            <token id="26" string="public" />
            <token id="27" string="policy" />
            <token id="28" string="institute" />
          </tokens>
        </chunking>
        <chunking id="16" string="segregation" type="NP">
          <tokens>
            <token id="11" string="segregation" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="4">raised</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">raised</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">wrote</governor>
          <dependent id="4">raised</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">survive</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">raised</governor>
          <dependent id="6">survive</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">totalitarianism</governor>
          <dependent id="7">under</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">totalitarianism</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">survive</governor>
          <dependent id="9">totalitarianism</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">segregation</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">totalitarianism</governor>
          <dependent id="11">segregation</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">wrote</governor>
          <dependent id="14">Thomas</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">wrote</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">paper</governor>
          <dependent id="16">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">paper</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">wrote</governor>
          <dependent id="18">paper</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">Foundation</governor>
          <dependent id="19">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">Foundation</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Foundation</governor>
          <dependent id="21">Heritage</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">wrote</governor>
          <dependent id="22">Foundation</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">institute</governor>
          <dependent id="24">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">institute</governor>
          <dependent id="25">conservative</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">institute</governor>
          <dependent id="26">public</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">institute</governor>
          <dependent id="27">policy</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="22">Foundation</governor>
          <dependent id="28">institute</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">Washington</governor>
          <dependent id="29">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">institute</governor>
          <dependent id="30">Washington</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Washington" type="LOCATION" score="0.0">
          <tokens>
            <token id="30" string="Washington" />
          </tokens>
        </entity>
        <entity id="2" string="conservative" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="25" string="conservative" />
          </tokens>
        </entity>
        <entity id="3" string="Heritage Foundation" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="21" string="Heritage" />
            <token id="22" string="Foundation" />
          </tokens>
        </entity>
        <entity id="4" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="false">
      <content>&amp;quot;We were raised to survive in spite of the dark, oppressive cloud of governmentally sanctioned bigotry.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="raised" lemma="raise" stem="rais" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="survive" lemma="survive" stem="surviv" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="spite" lemma="spite" stem="spite" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="dark" lemma="dark" stem="dark" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="oppressive" lemma="oppressive" stem="oppress" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="cloud" lemma="cloud" stem="cloud" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="governmentally" lemma="governmentally" stem="government" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="sanctioned" lemma="sanction" stem="sanction" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="bigotry" lemma="bigotry" stem="bigotri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP We)) (VP (VBD were) (VP (VBN raised) (S (VP (TO to) (VP (VB survive) (PP (IN in) (NP (NP (NN spite)) (PP (IN of) (NP (NP (DT the) (ADJP (JJ dark) (, ,) (JJ oppressive)) (NN cloud)) (PP (IN of) (NP (ADJP (RB governmentally) (VBN sanctioned)) (NN bigotry)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="governmentally sanctioned bigotry" type="NP">
          <tokens>
            <token id="16" string="governmentally" />
            <token id="17" string="sanctioned" />
            <token id="18" string="bigotry" />
          </tokens>
        </chunking>
        <chunking id="2" string="were raised to survive in spite of the dark , oppressive cloud of governmentally sanctioned bigotry" type="VP">
          <tokens>
            <token id="3" string="were" />
            <token id="4" string="raised" />
            <token id="5" string="to" />
            <token id="6" string="survive" />
            <token id="7" string="in" />
            <token id="8" string="spite" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="dark" />
            <token id="12" string="," />
            <token id="13" string="oppressive" />
            <token id="14" string="cloud" />
            <token id="15" string="of" />
            <token id="16" string="governmentally" />
            <token id="17" string="sanctioned" />
            <token id="18" string="bigotry" />
          </tokens>
        </chunking>
        <chunking id="3" string="governmentally sanctioned" type="ADJP">
          <tokens>
            <token id="16" string="governmentally" />
            <token id="17" string="sanctioned" />
          </tokens>
        </chunking>
        <chunking id="4" string="survive in spite of the dark , oppressive cloud of governmentally sanctioned bigotry" type="VP">
          <tokens>
            <token id="6" string="survive" />
            <token id="7" string="in" />
            <token id="8" string="spite" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="dark" />
            <token id="12" string="," />
            <token id="13" string="oppressive" />
            <token id="14" string="cloud" />
            <token id="15" string="of" />
            <token id="16" string="governmentally" />
            <token id="17" string="sanctioned" />
            <token id="18" string="bigotry" />
          </tokens>
        </chunking>
        <chunking id="5" string="raised to survive in spite of the dark , oppressive cloud of governmentally sanctioned bigotry" type="VP">
          <tokens>
            <token id="4" string="raised" />
            <token id="5" string="to" />
            <token id="6" string="survive" />
            <token id="7" string="in" />
            <token id="8" string="spite" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="dark" />
            <token id="12" string="," />
            <token id="13" string="oppressive" />
            <token id="14" string="cloud" />
            <token id="15" string="of" />
            <token id="16" string="governmentally" />
            <token id="17" string="sanctioned" />
            <token id="18" string="bigotry" />
          </tokens>
        </chunking>
        <chunking id="6" string="spite" type="NP">
          <tokens>
            <token id="8" string="spite" />
          </tokens>
        </chunking>
        <chunking id="7" string="the dark , oppressive cloud" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="dark" />
            <token id="12" string="," />
            <token id="13" string="oppressive" />
            <token id="14" string="cloud" />
          </tokens>
        </chunking>
        <chunking id="8" string="the dark , oppressive cloud of governmentally sanctioned bigotry" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="dark" />
            <token id="12" string="," />
            <token id="13" string="oppressive" />
            <token id="14" string="cloud" />
            <token id="15" string="of" />
            <token id="16" string="governmentally" />
            <token id="17" string="sanctioned" />
            <token id="18" string="bigotry" />
          </tokens>
        </chunking>
        <chunking id="9" string="to survive in spite of the dark , oppressive cloud of governmentally sanctioned bigotry" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="survive" />
            <token id="7" string="in" />
            <token id="8" string="spite" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="dark" />
            <token id="12" string="," />
            <token id="13" string="oppressive" />
            <token id="14" string="cloud" />
            <token id="15" string="of" />
            <token id="16" string="governmentally" />
            <token id="17" string="sanctioned" />
            <token id="18" string="bigotry" />
          </tokens>
        </chunking>
        <chunking id="10" string="spite of the dark , oppressive cloud of governmentally sanctioned bigotry" type="NP">
          <tokens>
            <token id="8" string="spite" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="dark" />
            <token id="12" string="," />
            <token id="13" string="oppressive" />
            <token id="14" string="cloud" />
            <token id="15" string="of" />
            <token id="16" string="governmentally" />
            <token id="17" string="sanctioned" />
            <token id="18" string="bigotry" />
          </tokens>
        </chunking>
        <chunking id="11" string="We" type="NP">
          <tokens>
            <token id="2" string="We" />
          </tokens>
        </chunking>
        <chunking id="12" string="dark , oppressive" type="ADJP">
          <tokens>
            <token id="11" string="dark" />
            <token id="12" string="," />
            <token id="13" string="oppressive" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="4">raised</governor>
          <dependent id="2">We</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">raised</governor>
          <dependent id="3">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">raised</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">survive</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">raised</governor>
          <dependent id="6">survive</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">cloud</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="7">in</governor>
          <dependent id="8">spite</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="7">in</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">cloud</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">oppressive</governor>
          <dependent id="11">dark</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">cloud</governor>
          <dependent id="13">oppressive</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">survive</governor>
          <dependent id="14">cloud</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">bigotry</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">sanctioned</governor>
          <dependent id="16">governmentally</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">bigotry</governor>
          <dependent id="17">sanctioned</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">cloud</governor>
          <dependent id="18">bigotry</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>Self-sufficiency, security; &amp;quot;Self-sufficiency and spiritual and emotional security were our tools to carve out and secure freedom,&amp;quot; he added.</content>
      <tokens>
        <token id="1" string="Self-sufficiency" lemma="self-sufficiency" stem="self-suffici" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="security" lemma="security" stem="secur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Self-sufficiency" lemma="self-sufficiency" stem="self-suffici" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="spiritual" lemma="spiritual" stem="spiritu" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="emotional" lemma="emotional" stem="emot" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="security" lemma="security" stem="secur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="our" lemma="we" stem="our" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="14" string="tools" lemma="tool" stem="tool" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="carve" lemma="carve" stem="carv" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="secure" lemma="secure" stem="secur" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="freedom" lemma="freedom" stem="freedom" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="added" lemma="add" stem="ad" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NN Self-sufficiency)) (, ,) (S (NP (NP (NP (NN security)) (: ;) (S (`` ``) (NP (NP (NN Self-sufficiency)) (CC and) (NP (JJ spiritual) (CC and) (JJ emotional) (NN security))) (VP (VBD were) (NP (PRP$ our) (NNS tools) (S (VP (TO to) (VP (VB carve) (PRT (RP out))))))))) (CC and) (NP (JJ secure) (NN freedom)))) (, ,) ('' '') (NP (PRP he)) (VP (VBD added)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="security ; `` Self-sufficiency and spiritual and emotional security were our tools to carve out" type="NP">
          <tokens>
            <token id="3" string="security" />
            <token id="4" string=";" />
            <token id="5" string="&quot;" />
            <token id="6" string="Self-sufficiency" />
            <token id="7" string="and" />
            <token id="8" string="spiritual" />
            <token id="9" string="and" />
            <token id="10" string="emotional" />
            <token id="11" string="security" />
            <token id="12" string="were" />
            <token id="13" string="our" />
            <token id="14" string="tools" />
            <token id="15" string="to" />
            <token id="16" string="carve" />
            <token id="17" string="out" />
          </tokens>
        </chunking>
        <chunking id="2" string="secure freedom" type="NP">
          <tokens>
            <token id="19" string="secure" />
            <token id="20" string="freedom" />
          </tokens>
        </chunking>
        <chunking id="3" string="spiritual and emotional security" type="NP">
          <tokens>
            <token id="8" string="spiritual" />
            <token id="9" string="and" />
            <token id="10" string="emotional" />
            <token id="11" string="security" />
          </tokens>
        </chunking>
        <chunking id="4" string="to carve out" type="VP">
          <tokens>
            <token id="15" string="to" />
            <token id="16" string="carve" />
            <token id="17" string="out" />
          </tokens>
        </chunking>
        <chunking id="5" string="security" type="NP">
          <tokens>
            <token id="3" string="security" />
          </tokens>
        </chunking>
        <chunking id="6" string="security ; `` Self-sufficiency and spiritual and emotional security were our tools to carve out and secure freedom" type="NP">
          <tokens>
            <token id="3" string="security" />
            <token id="4" string=";" />
            <token id="5" string="&quot;" />
            <token id="6" string="Self-sufficiency" />
            <token id="7" string="and" />
            <token id="8" string="spiritual" />
            <token id="9" string="and" />
            <token id="10" string="emotional" />
            <token id="11" string="security" />
            <token id="12" string="were" />
            <token id="13" string="our" />
            <token id="14" string="tools" />
            <token id="15" string="to" />
            <token id="16" string="carve" />
            <token id="17" string="out" />
            <token id="18" string="and" />
            <token id="19" string="secure" />
            <token id="20" string="freedom" />
          </tokens>
        </chunking>
        <chunking id="7" string="Self-sufficiency" type="NP">
          <tokens>
            <token id="1" string="Self-sufficiency" />
          </tokens>
        </chunking>
        <chunking id="8" string="our tools to carve out" type="NP">
          <tokens>
            <token id="13" string="our" />
            <token id="14" string="tools" />
            <token id="15" string="to" />
            <token id="16" string="carve" />
            <token id="17" string="out" />
          </tokens>
        </chunking>
        <chunking id="9" string="were our tools to carve out" type="VP">
          <tokens>
            <token id="12" string="were" />
            <token id="13" string="our" />
            <token id="14" string="tools" />
            <token id="15" string="to" />
            <token id="16" string="carve" />
            <token id="17" string="out" />
          </tokens>
        </chunking>
        <chunking id="10" string="Self-sufficiency and spiritual and emotional security" type="NP">
          <tokens>
            <token id="6" string="Self-sufficiency" />
            <token id="7" string="and" />
            <token id="8" string="spiritual" />
            <token id="9" string="and" />
            <token id="10" string="emotional" />
            <token id="11" string="security" />
          </tokens>
        </chunking>
        <chunking id="11" string="carve out" type="VP">
          <tokens>
            <token id="16" string="carve" />
            <token id="17" string="out" />
          </tokens>
        </chunking>
        <chunking id="12" string="added" type="VP">
          <tokens>
            <token id="24" string="added" />
          </tokens>
        </chunking>
        <chunking id="13" string="he" type="NP">
          <tokens>
            <token id="23" string="he" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="24">added</governor>
          <dependent id="1">Self-sufficiency</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="24">added</governor>
          <dependent id="3">security</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">tools</governor>
          <dependent id="6">Self-sufficiency</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">Self-sufficiency</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">security</governor>
          <dependent id="8">spiritual</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">spiritual</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">spiritual</governor>
          <dependent id="10">emotional</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">Self-sufficiency</governor>
          <dependent id="11">security</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">tools</governor>
          <dependent id="12">were</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">tools</governor>
          <dependent id="13">our</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="3">security</governor>
          <dependent id="14">tools</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">carve</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="14">tools</governor>
          <dependent id="16">carve</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="16">carve</governor>
          <dependent id="17">out</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">security</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">freedom</governor>
          <dependent id="19">secure</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">security</governor>
          <dependent id="20">freedom</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">added</governor>
          <dependent id="23">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="24">added</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>&amp;quot;Those who attempt to capture the daily counseling, oversight, common sense and vision of my grandparents in a governmental program are engaging in sheer folly.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="attempt" lemma="attempt" stem="attempt" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="capture" lemma="capture" stem="captur" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="daily" lemma="daily" stem="daili" pos="JJ" type="Word" isStopWord="false" ner="SET" is_referenced="false" is_refers="false" />
        <token id="9" string="counseling" lemma="counseling" stem="counsel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="oversight" lemma="oversight" stem="oversight" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="common" lemma="common" stem="common" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="sense" lemma="sense" stem="sens" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="vision" lemma="vision" stem="vision" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="grandparents" lemma="grandparent" stem="grandpar" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="governmental" lemma="governmental" stem="government" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="program" lemma="program" stem="program" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="engaging" lemma="engage" stem="engag" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="sheer" lemma="sheer" stem="sheer" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="folly" lemma="folly" stem="folli" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (NP (DT Those)) (SBAR (WHNP (WP who)) (S (VP (VBP attempt) (S (VP (TO to) (VP (VB capture) (NP (NP (DT the) (JJ daily) (NN counseling) (, ,) (NN oversight) (, ,) (JJ common) (NN sense) (CC and) (NN vision)) (PP (IN of) (NP (PRP$ my) (NNS grandparents)))) (PP (IN in) (NP (DT a) (JJ governmental) (NN program)))))))))) (VP (VBP are) (VP (VBG engaging) (PP (IN in) (NP (JJ sheer) (NN folly))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="to capture the daily counseling , oversight , common sense and vision of my grandparents in a governmental program" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="capture" />
            <token id="7" string="the" />
            <token id="8" string="daily" />
            <token id="9" string="counseling" />
            <token id="10" string="," />
            <token id="11" string="oversight" />
            <token id="12" string="," />
            <token id="13" string="common" />
            <token id="14" string="sense" />
            <token id="15" string="and" />
            <token id="16" string="vision" />
            <token id="17" string="of" />
            <token id="18" string="my" />
            <token id="19" string="grandparents" />
            <token id="20" string="in" />
            <token id="21" string="a" />
            <token id="22" string="governmental" />
            <token id="23" string="program" />
          </tokens>
        </chunking>
        <chunking id="2" string="engaging in sheer folly" type="VP">
          <tokens>
            <token id="25" string="engaging" />
            <token id="26" string="in" />
            <token id="27" string="sheer" />
            <token id="28" string="folly" />
          </tokens>
        </chunking>
        <chunking id="3" string="my grandparents" type="NP">
          <tokens>
            <token id="18" string="my" />
            <token id="19" string="grandparents" />
          </tokens>
        </chunking>
        <chunking id="4" string="the daily counseling , oversight , common sense and vision of my grandparents" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="daily" />
            <token id="9" string="counseling" />
            <token id="10" string="," />
            <token id="11" string="oversight" />
            <token id="12" string="," />
            <token id="13" string="common" />
            <token id="14" string="sense" />
            <token id="15" string="and" />
            <token id="16" string="vision" />
            <token id="17" string="of" />
            <token id="18" string="my" />
            <token id="19" string="grandparents" />
          </tokens>
        </chunking>
        <chunking id="5" string="who attempt to capture the daily counseling , oversight , common sense and vision of my grandparents in a governmental program" type="SBAR">
          <tokens>
            <token id="3" string="who" />
            <token id="4" string="attempt" />
            <token id="5" string="to" />
            <token id="6" string="capture" />
            <token id="7" string="the" />
            <token id="8" string="daily" />
            <token id="9" string="counseling" />
            <token id="10" string="," />
            <token id="11" string="oversight" />
            <token id="12" string="," />
            <token id="13" string="common" />
            <token id="14" string="sense" />
            <token id="15" string="and" />
            <token id="16" string="vision" />
            <token id="17" string="of" />
            <token id="18" string="my" />
            <token id="19" string="grandparents" />
            <token id="20" string="in" />
            <token id="21" string="a" />
            <token id="22" string="governmental" />
            <token id="23" string="program" />
          </tokens>
        </chunking>
        <chunking id="6" string="are engaging in sheer folly" type="VP">
          <tokens>
            <token id="24" string="are" />
            <token id="25" string="engaging" />
            <token id="26" string="in" />
            <token id="27" string="sheer" />
            <token id="28" string="folly" />
          </tokens>
        </chunking>
        <chunking id="7" string="Those who attempt to capture the daily counseling , oversight , common sense and vision of my grandparents in a governmental program" type="NP">
          <tokens>
            <token id="2" string="Those" />
            <token id="3" string="who" />
            <token id="4" string="attempt" />
            <token id="5" string="to" />
            <token id="6" string="capture" />
            <token id="7" string="the" />
            <token id="8" string="daily" />
            <token id="9" string="counseling" />
            <token id="10" string="," />
            <token id="11" string="oversight" />
            <token id="12" string="," />
            <token id="13" string="common" />
            <token id="14" string="sense" />
            <token id="15" string="and" />
            <token id="16" string="vision" />
            <token id="17" string="of" />
            <token id="18" string="my" />
            <token id="19" string="grandparents" />
            <token id="20" string="in" />
            <token id="21" string="a" />
            <token id="22" string="governmental" />
            <token id="23" string="program" />
          </tokens>
        </chunking>
        <chunking id="8" string="sheer folly" type="NP">
          <tokens>
            <token id="27" string="sheer" />
            <token id="28" string="folly" />
          </tokens>
        </chunking>
        <chunking id="9" string="attempt to capture the daily counseling , oversight , common sense and vision of my grandparents in a governmental program" type="VP">
          <tokens>
            <token id="4" string="attempt" />
            <token id="5" string="to" />
            <token id="6" string="capture" />
            <token id="7" string="the" />
            <token id="8" string="daily" />
            <token id="9" string="counseling" />
            <token id="10" string="," />
            <token id="11" string="oversight" />
            <token id="12" string="," />
            <token id="13" string="common" />
            <token id="14" string="sense" />
            <token id="15" string="and" />
            <token id="16" string="vision" />
            <token id="17" string="of" />
            <token id="18" string="my" />
            <token id="19" string="grandparents" />
            <token id="20" string="in" />
            <token id="21" string="a" />
            <token id="22" string="governmental" />
            <token id="23" string="program" />
          </tokens>
        </chunking>
        <chunking id="10" string="a governmental program" type="NP">
          <tokens>
            <token id="21" string="a" />
            <token id="22" string="governmental" />
            <token id="23" string="program" />
          </tokens>
        </chunking>
        <chunking id="11" string="Those" type="NP">
          <tokens>
            <token id="2" string="Those" />
          </tokens>
        </chunking>
        <chunking id="12" string="the daily counseling , oversight , common sense and vision" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="daily" />
            <token id="9" string="counseling" />
            <token id="10" string="," />
            <token id="11" string="oversight" />
            <token id="12" string="," />
            <token id="13" string="common" />
            <token id="14" string="sense" />
            <token id="15" string="and" />
            <token id="16" string="vision" />
          </tokens>
        </chunking>
        <chunking id="13" string="capture the daily counseling , oversight , common sense and vision of my grandparents in a governmental program" type="VP">
          <tokens>
            <token id="6" string="capture" />
            <token id="7" string="the" />
            <token id="8" string="daily" />
            <token id="9" string="counseling" />
            <token id="10" string="," />
            <token id="11" string="oversight" />
            <token id="12" string="," />
            <token id="13" string="common" />
            <token id="14" string="sense" />
            <token id="15" string="and" />
            <token id="16" string="vision" />
            <token id="17" string="of" />
            <token id="18" string="my" />
            <token id="19" string="grandparents" />
            <token id="20" string="in" />
            <token id="21" string="a" />
            <token id="22" string="governmental" />
            <token id="23" string="program" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="25">engaging</governor>
          <dependent id="2">Those</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">attempt</governor>
          <dependent id="3">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="2">Those</governor>
          <dependent id="4">attempt</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">capture</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">attempt</governor>
          <dependent id="6">capture</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">sense</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">sense</governor>
          <dependent id="8">daily</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">sense</governor>
          <dependent id="9">counseling</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">sense</governor>
          <dependent id="11">oversight</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">sense</governor>
          <dependent id="13">common</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">capture</governor>
          <dependent id="14">sense</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">sense</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">sense</governor>
          <dependent id="16">vision</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">grandparents</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">grandparents</governor>
          <dependent id="18">my</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">sense</governor>
          <dependent id="19">grandparents</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">program</governor>
          <dependent id="20">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">program</governor>
          <dependent id="21">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">program</governor>
          <dependent id="22">governmental</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">capture</governor>
          <dependent id="23">program</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="25">engaging</governor>
          <dependent id="24">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="25">engaging</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">folly</governor>
          <dependent id="26">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">folly</governor>
          <dependent id="27">sheer</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">engaging</governor>
          <dependent id="28">folly</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="daily" type="SET" score="0.0">
          <tokens>
            <token id="8" string="daily" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>; The very beliefs that have brought Thomas to the steps of the U.S. Supreme Court make him suspect to black political activists, veterans of the struggle to make government accountable for the wrongs done to blacks.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="beliefs" lemma="belief" stem="belief" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="brought" lemma="bring" stem="brought" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="steps" lemma="step" stem="step" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="U.S." lemma="U.S." stem="u.s." pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="15" string="Supreme" lemma="Supreme" stem="suprem" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="16" string="Court" lemma="Court" stem="court" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="17" string="make" lemma="make" stem="make" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="suspect" lemma="suspect" stem="suspect" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="political" lemma="political" stem="polit" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="activists" lemma="activist" stem="activist" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="veterans" lemma="veteran" stem="veteran" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="struggle" lemma="struggle" stem="struggl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="make" lemma="make" stem="make" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="government" lemma="government" stem="govern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="accountable" lemma="accountable" stem="account" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="wrongs" lemma="wrong" stem="wrong" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="done" lemma="do" stem="done" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="blacks" lemma="black" stem="black" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (: ;) (NP (NP (DT The) (RB very)) (SBAR (S (NP (NP (NNS beliefs)) (SBAR (WHNP (WDT that)) (S (VP (VBP have) (VP (VBN brought) (NP (NNP Thomas)) (PP (TO to) (NP (NP (DT the) (NNS steps)) (PP (IN of) (NP (DT the) (NNP U.S.) (NNP Supreme) (NNP Court)))))))))) (VP (VB make) (S (NP (PRP him)) (VP (VB suspect) (PP (TO to) (NP (NP (JJ black) (JJ political) (NNS activists)) (, ,) (NP (NP (NNS veterans)) (PP (IN of) (NP (DT the) (NN struggle)))))) (S (VP (TO to) (VP (VB make) (S (NP (NN government)) (ADJP (JJ accountable) (PP (IN for) (NP (NP (DT the) (NNS wrongs)) (VP (VBN done) (PP (TO to) (NP (NNS blacks))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="veterans of the struggle" type="NP">
          <tokens>
            <token id="25" string="veterans" />
            <token id="26" string="of" />
            <token id="27" string="the" />
            <token id="28" string="struggle" />
          </tokens>
        </chunking>
        <chunking id="2" string="to make government accountable for the wrongs done to blacks" type="VP">
          <tokens>
            <token id="29" string="to" />
            <token id="30" string="make" />
            <token id="31" string="government" />
            <token id="32" string="accountable" />
            <token id="33" string="for" />
            <token id="34" string="the" />
            <token id="35" string="wrongs" />
            <token id="36" string="done" />
            <token id="37" string="to" />
            <token id="38" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="3" string="Thomas" type="NP">
          <tokens>
            <token id="8" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="4" string="brought Thomas to the steps of the U.S. Supreme Court" type="VP">
          <tokens>
            <token id="7" string="brought" />
            <token id="8" string="Thomas" />
            <token id="9" string="to" />
            <token id="10" string="the" />
            <token id="11" string="steps" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="U.S." />
            <token id="15" string="Supreme" />
            <token id="16" string="Court" />
          </tokens>
        </chunking>
        <chunking id="5" string="accountable for the wrongs done to blacks" type="ADJP">
          <tokens>
            <token id="32" string="accountable" />
            <token id="33" string="for" />
            <token id="34" string="the" />
            <token id="35" string="wrongs" />
            <token id="36" string="done" />
            <token id="37" string="to" />
            <token id="38" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="6" string="beliefs" type="NP">
          <tokens>
            <token id="4" string="beliefs" />
          </tokens>
        </chunking>
        <chunking id="7" string="black political activists" type="NP">
          <tokens>
            <token id="21" string="black" />
            <token id="22" string="political" />
            <token id="23" string="activists" />
          </tokens>
        </chunking>
        <chunking id="8" string="the steps of the U.S. Supreme Court" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="steps" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="U.S." />
            <token id="15" string="Supreme" />
            <token id="16" string="Court" />
          </tokens>
        </chunking>
        <chunking id="9" string="have brought Thomas to the steps of the U.S. Supreme Court" type="VP">
          <tokens>
            <token id="6" string="have" />
            <token id="7" string="brought" />
            <token id="8" string="Thomas" />
            <token id="9" string="to" />
            <token id="10" string="the" />
            <token id="11" string="steps" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="U.S." />
            <token id="15" string="Supreme" />
            <token id="16" string="Court" />
          </tokens>
        </chunking>
        <chunking id="10" string="suspect to black political activists , veterans of the struggle to make government accountable for the wrongs done to blacks" type="VP">
          <tokens>
            <token id="19" string="suspect" />
            <token id="20" string="to" />
            <token id="21" string="black" />
            <token id="22" string="political" />
            <token id="23" string="activists" />
            <token id="24" string="," />
            <token id="25" string="veterans" />
            <token id="26" string="of" />
            <token id="27" string="the" />
            <token id="28" string="struggle" />
            <token id="29" string="to" />
            <token id="30" string="make" />
            <token id="31" string="government" />
            <token id="32" string="accountable" />
            <token id="33" string="for" />
            <token id="34" string="the" />
            <token id="35" string="wrongs" />
            <token id="36" string="done" />
            <token id="37" string="to" />
            <token id="38" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="11" string="that have brought Thomas to the steps of the U.S. Supreme Court" type="SBAR">
          <tokens>
            <token id="5" string="that" />
            <token id="6" string="have" />
            <token id="7" string="brought" />
            <token id="8" string="Thomas" />
            <token id="9" string="to" />
            <token id="10" string="the" />
            <token id="11" string="steps" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="U.S." />
            <token id="15" string="Supreme" />
            <token id="16" string="Court" />
          </tokens>
        </chunking>
        <chunking id="12" string="beliefs that have brought Thomas to the steps of the U.S. Supreme Court" type="NP">
          <tokens>
            <token id="4" string="beliefs" />
            <token id="5" string="that" />
            <token id="6" string="have" />
            <token id="7" string="brought" />
            <token id="8" string="Thomas" />
            <token id="9" string="to" />
            <token id="10" string="the" />
            <token id="11" string="steps" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="U.S." />
            <token id="15" string="Supreme" />
            <token id="16" string="Court" />
          </tokens>
        </chunking>
        <chunking id="13" string="make government accountable for the wrongs done to blacks" type="VP">
          <tokens>
            <token id="30" string="make" />
            <token id="31" string="government" />
            <token id="32" string="accountable" />
            <token id="33" string="for" />
            <token id="34" string="the" />
            <token id="35" string="wrongs" />
            <token id="36" string="done" />
            <token id="37" string="to" />
            <token id="38" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="14" string="the steps" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="steps" />
          </tokens>
        </chunking>
        <chunking id="15" string="make him suspect to black political activists , veterans of the struggle to make government accountable for the wrongs done to blacks" type="VP">
          <tokens>
            <token id="17" string="make" />
            <token id="18" string="him" />
            <token id="19" string="suspect" />
            <token id="20" string="to" />
            <token id="21" string="black" />
            <token id="22" string="political" />
            <token id="23" string="activists" />
            <token id="24" string="," />
            <token id="25" string="veterans" />
            <token id="26" string="of" />
            <token id="27" string="the" />
            <token id="28" string="struggle" />
            <token id="29" string="to" />
            <token id="30" string="make" />
            <token id="31" string="government" />
            <token id="32" string="accountable" />
            <token id="33" string="for" />
            <token id="34" string="the" />
            <token id="35" string="wrongs" />
            <token id="36" string="done" />
            <token id="37" string="to" />
            <token id="38" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="16" string="veterans" type="NP">
          <tokens>
            <token id="25" string="veterans" />
          </tokens>
        </chunking>
        <chunking id="17" string="; The very beliefs that have brought Thomas to the steps of the U.S. Supreme Court make him suspect to black political activists , veterans of the struggle to make government accountable for the wrongs done to blacks ." type="NP">
          <tokens>
            <token id="1" string=";" />
            <token id="2" string="The" />
            <token id="3" string="very" />
            <token id="4" string="beliefs" />
            <token id="5" string="that" />
            <token id="6" string="have" />
            <token id="7" string="brought" />
            <token id="8" string="Thomas" />
            <token id="9" string="to" />
            <token id="10" string="the" />
            <token id="11" string="steps" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="U.S." />
            <token id="15" string="Supreme" />
            <token id="16" string="Court" />
            <token id="17" string="make" />
            <token id="18" string="him" />
            <token id="19" string="suspect" />
            <token id="20" string="to" />
            <token id="21" string="black" />
            <token id="22" string="political" />
            <token id="23" string="activists" />
            <token id="24" string="," />
            <token id="25" string="veterans" />
            <token id="26" string="of" />
            <token id="27" string="the" />
            <token id="28" string="struggle" />
            <token id="29" string="to" />
            <token id="30" string="make" />
            <token id="31" string="government" />
            <token id="32" string="accountable" />
            <token id="33" string="for" />
            <token id="34" string="the" />
            <token id="35" string="wrongs" />
            <token id="36" string="done" />
            <token id="37" string="to" />
            <token id="38" string="blacks" />
            <token id="39" string="." />
          </tokens>
        </chunking>
        <chunking id="18" string="the wrongs done to blacks" type="NP">
          <tokens>
            <token id="34" string="the" />
            <token id="35" string="wrongs" />
            <token id="36" string="done" />
            <token id="37" string="to" />
            <token id="38" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="19" string="the wrongs" type="NP">
          <tokens>
            <token id="34" string="the" />
            <token id="35" string="wrongs" />
          </tokens>
        </chunking>
        <chunking id="20" string="blacks" type="NP">
          <tokens>
            <token id="38" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="21" string="the U.S. Supreme Court" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="U.S." />
            <token id="15" string="Supreme" />
            <token id="16" string="Court" />
          </tokens>
        </chunking>
        <chunking id="22" string="him" type="NP">
          <tokens>
            <token id="18" string="him" />
          </tokens>
        </chunking>
        <chunking id="23" string="black political activists , veterans of the struggle" type="NP">
          <tokens>
            <token id="21" string="black" />
            <token id="22" string="political" />
            <token id="23" string="activists" />
            <token id="24" string="," />
            <token id="25" string="veterans" />
            <token id="26" string="of" />
            <token id="27" string="the" />
            <token id="28" string="struggle" />
          </tokens>
        </chunking>
        <chunking id="24" string="The very beliefs that have brought Thomas to the steps of the U.S. Supreme Court make him suspect to black political activists , veterans of the struggle to make government accountable for the wrongs done to blacks" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="very" />
            <token id="4" string="beliefs" />
            <token id="5" string="that" />
            <token id="6" string="have" />
            <token id="7" string="brought" />
            <token id="8" string="Thomas" />
            <token id="9" string="to" />
            <token id="10" string="the" />
            <token id="11" string="steps" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="U.S." />
            <token id="15" string="Supreme" />
            <token id="16" string="Court" />
            <token id="17" string="make" />
            <token id="18" string="him" />
            <token id="19" string="suspect" />
            <token id="20" string="to" />
            <token id="21" string="black" />
            <token id="22" string="political" />
            <token id="23" string="activists" />
            <token id="24" string="," />
            <token id="25" string="veterans" />
            <token id="26" string="of" />
            <token id="27" string="the" />
            <token id="28" string="struggle" />
            <token id="29" string="to" />
            <token id="30" string="make" />
            <token id="31" string="government" />
            <token id="32" string="accountable" />
            <token id="33" string="for" />
            <token id="34" string="the" />
            <token id="35" string="wrongs" />
            <token id="36" string="done" />
            <token id="37" string="to" />
            <token id="38" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="25" string="done to blacks" type="VP">
          <tokens>
            <token id="36" string="done" />
            <token id="37" string="to" />
            <token id="38" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="26" string="government" type="NP">
          <tokens>
            <token id="31" string="government" />
          </tokens>
        </chunking>
        <chunking id="27" string="the struggle" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="struggle" />
          </tokens>
        </chunking>
        <chunking id="28" string="The very" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="very" />
          </tokens>
        </chunking>
        <chunking id="29" string="beliefs that have brought Thomas to the steps of the U.S. Supreme Court make him suspect to black political activists , veterans of the struggle to make government accountable for the wrongs done to blacks" type="SBAR">
          <tokens>
            <token id="4" string="beliefs" />
            <token id="5" string="that" />
            <token id="6" string="have" />
            <token id="7" string="brought" />
            <token id="8" string="Thomas" />
            <token id="9" string="to" />
            <token id="10" string="the" />
            <token id="11" string="steps" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="U.S." />
            <token id="15" string="Supreme" />
            <token id="16" string="Court" />
            <token id="17" string="make" />
            <token id="18" string="him" />
            <token id="19" string="suspect" />
            <token id="20" string="to" />
            <token id="21" string="black" />
            <token id="22" string="political" />
            <token id="23" string="activists" />
            <token id="24" string="," />
            <token id="25" string="veterans" />
            <token id="26" string="of" />
            <token id="27" string="the" />
            <token id="28" string="struggle" />
            <token id="29" string="to" />
            <token id="30" string="make" />
            <token id="31" string="government" />
            <token id="32" string="accountable" />
            <token id="33" string="for" />
            <token id="34" string="the" />
            <token id="35" string="wrongs" />
            <token id="36" string="done" />
            <token id="37" string="to" />
            <token id="38" string="blacks" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">very</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">very</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">make</governor>
          <dependent id="4">beliefs</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">brought</governor>
          <dependent id="5">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">brought</governor>
          <dependent id="6">have</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="4">beliefs</governor>
          <dependent id="7">brought</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">brought</governor>
          <dependent id="8">Thomas</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">steps</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">steps</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">brought</governor>
          <dependent id="11">steps</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">Court</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">Court</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Court</governor>
          <dependent id="14">U.S.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Court</governor>
          <dependent id="15">Supreme</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">steps</governor>
          <dependent id="16">Court</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="3">very</governor>
          <dependent id="17">make</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">suspect</governor>
          <dependent id="18">him</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">make</governor>
          <dependent id="19">suspect</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">activists</governor>
          <dependent id="20">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">activists</governor>
          <dependent id="21">black</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">activists</governor>
          <dependent id="22">political</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">suspect</governor>
          <dependent id="23">activists</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="23">activists</governor>
          <dependent id="25">veterans</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">struggle</governor>
          <dependent id="26">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">struggle</governor>
          <dependent id="27">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">veterans</governor>
          <dependent id="28">struggle</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="30">make</governor>
          <dependent id="29">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="19">suspect</governor>
          <dependent id="30">make</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="32">accountable</governor>
          <dependent id="31">government</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="30">make</governor>
          <dependent id="32">accountable</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">wrongs</governor>
          <dependent id="33">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">wrongs</governor>
          <dependent id="34">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">accountable</governor>
          <dependent id="35">wrongs</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="35">wrongs</governor>
          <dependent id="36">done</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">blacks</governor>
          <dependent id="37">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="36">done</governor>
          <dependent id="38">blacks</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Thomas" />
          </tokens>
        </entity>
        <entity id="2" string="U.S. Supreme Court" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="14" string="U.S." />
            <token id="15" string="Supreme" />
            <token id="16" string="Court" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>Yet as Washington Post journalist Juan Williams has pointed out, Thomas is firmly grounded in the black intellectual tradition of Booker T. Washington, who advocated education, self-reliance and mutual support as the principal means of advancement.</content>
      <tokens>
        <token id="1" string="Yet" lemma="yet" stem="yet" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Washington" lemma="Washington" stem="washington" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="4" string="Post" lemma="Post" stem="post" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="5" string="journalist" lemma="journalist" stem="journalist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="Juan" lemma="Juan" stem="juan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="7" string="Williams" lemma="Williams" stem="william" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="8" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="pointed" lemma="point" stem="point" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="13" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="firmly" lemma="firmly" stem="firmli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="grounded" lemma="ground" stem="ground" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="intellectual" lemma="intellectual" stem="intellectu" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="tradition" lemma="tradition" stem="tradit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="Booker" lemma="Booker" stem="booker" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="23" string="T." lemma="T." stem="t." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="24" string="Washington" lemma="Washington" stem="washington" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="advocated" lemma="advocate" stem="advoc" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="education" lemma="education" stem="educ" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="self-reliance" lemma="self-reliance" stem="self-reli" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="mutual" lemma="mutual" stem="mutual" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="support" lemma="support" stem="support" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="principal" lemma="principal" stem="princip" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="means" lemma="means" stem="mean" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="advancement" lemma="advancement" stem="advanc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (RB Yet) (SBAR (IN as) (S (NP (NNP Washington) (NNP Post) (NN journalist) (NNP Juan) (NNP Williams)) (VP (VBZ has) (VP (VBN pointed) (PRT (RP out)))))) (, ,) (NP (NNP Thomas)) (VP (VBZ is) (ADVP (RB firmly)) (VP (VBN grounded) (PP (IN in) (NP (NP (DT the) (JJ black) (JJ intellectual) (NN tradition)) (PP (IN of) (NP (NP (NNP Booker) (NNP T.) (NNP Washington)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD advocated) (NP (NN education) (, ,) (NN self-reliance) (CC and) (JJ mutual) (NN support)) (PP (IN as) (NP (NP (DT the) (JJ principal) (NNS means)) (PP (IN of) (NP (NN advancement)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the principal means" type="NP">
          <tokens>
            <token id="35" string="the" />
            <token id="36" string="principal" />
            <token id="37" string="means" />
          </tokens>
        </chunking>
        <chunking id="2" string="has pointed out" type="VP">
          <tokens>
            <token id="8" string="has" />
            <token id="9" string="pointed" />
            <token id="10" string="out" />
          </tokens>
        </chunking>
        <chunking id="3" string="is firmly grounded in the black intellectual tradition of Booker T. Washington , who advocated education , self-reliance and mutual support as the principal means of advancement" type="VP">
          <tokens>
            <token id="13" string="is" />
            <token id="14" string="firmly" />
            <token id="15" string="grounded" />
            <token id="16" string="in" />
            <token id="17" string="the" />
            <token id="18" string="black" />
            <token id="19" string="intellectual" />
            <token id="20" string="tradition" />
            <token id="21" string="of" />
            <token id="22" string="Booker" />
            <token id="23" string="T." />
            <token id="24" string="Washington" />
            <token id="25" string="," />
            <token id="26" string="who" />
            <token id="27" string="advocated" />
            <token id="28" string="education" />
            <token id="29" string="," />
            <token id="30" string="self-reliance" />
            <token id="31" string="and" />
            <token id="32" string="mutual" />
            <token id="33" string="support" />
            <token id="34" string="as" />
            <token id="35" string="the" />
            <token id="36" string="principal" />
            <token id="37" string="means" />
            <token id="38" string="of" />
            <token id="39" string="advancement" />
          </tokens>
        </chunking>
        <chunking id="4" string="Thomas" type="NP">
          <tokens>
            <token id="12" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="5" string="Washington Post journalist Juan Williams" type="NP">
          <tokens>
            <token id="3" string="Washington" />
            <token id="4" string="Post" />
            <token id="5" string="journalist" />
            <token id="6" string="Juan" />
            <token id="7" string="Williams" />
          </tokens>
        </chunking>
        <chunking id="6" string="pointed out" type="VP">
          <tokens>
            <token id="9" string="pointed" />
            <token id="10" string="out" />
          </tokens>
        </chunking>
        <chunking id="7" string="the black intellectual tradition" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="black" />
            <token id="19" string="intellectual" />
            <token id="20" string="tradition" />
          </tokens>
        </chunking>
        <chunking id="8" string="advancement" type="NP">
          <tokens>
            <token id="39" string="advancement" />
          </tokens>
        </chunking>
        <chunking id="9" string="grounded in the black intellectual tradition of Booker T. Washington , who advocated education , self-reliance and mutual support as the principal means of advancement" type="VP">
          <tokens>
            <token id="15" string="grounded" />
            <token id="16" string="in" />
            <token id="17" string="the" />
            <token id="18" string="black" />
            <token id="19" string="intellectual" />
            <token id="20" string="tradition" />
            <token id="21" string="of" />
            <token id="22" string="Booker" />
            <token id="23" string="T." />
            <token id="24" string="Washington" />
            <token id="25" string="," />
            <token id="26" string="who" />
            <token id="27" string="advocated" />
            <token id="28" string="education" />
            <token id="29" string="," />
            <token id="30" string="self-reliance" />
            <token id="31" string="and" />
            <token id="32" string="mutual" />
            <token id="33" string="support" />
            <token id="34" string="as" />
            <token id="35" string="the" />
            <token id="36" string="principal" />
            <token id="37" string="means" />
            <token id="38" string="of" />
            <token id="39" string="advancement" />
          </tokens>
        </chunking>
        <chunking id="10" string="advocated education , self-reliance and mutual support as the principal means of advancement" type="VP">
          <tokens>
            <token id="27" string="advocated" />
            <token id="28" string="education" />
            <token id="29" string="," />
            <token id="30" string="self-reliance" />
            <token id="31" string="and" />
            <token id="32" string="mutual" />
            <token id="33" string="support" />
            <token id="34" string="as" />
            <token id="35" string="the" />
            <token id="36" string="principal" />
            <token id="37" string="means" />
            <token id="38" string="of" />
            <token id="39" string="advancement" />
          </tokens>
        </chunking>
        <chunking id="11" string="the principal means of advancement" type="NP">
          <tokens>
            <token id="35" string="the" />
            <token id="36" string="principal" />
            <token id="37" string="means" />
            <token id="38" string="of" />
            <token id="39" string="advancement" />
          </tokens>
        </chunking>
        <chunking id="12" string="Booker T. Washington" type="NP">
          <tokens>
            <token id="22" string="Booker" />
            <token id="23" string="T." />
            <token id="24" string="Washington" />
          </tokens>
        </chunking>
        <chunking id="13" string="Booker T. Washington , who advocated education , self-reliance and mutual support as the principal means of advancement" type="NP">
          <tokens>
            <token id="22" string="Booker" />
            <token id="23" string="T." />
            <token id="24" string="Washington" />
            <token id="25" string="," />
            <token id="26" string="who" />
            <token id="27" string="advocated" />
            <token id="28" string="education" />
            <token id="29" string="," />
            <token id="30" string="self-reliance" />
            <token id="31" string="and" />
            <token id="32" string="mutual" />
            <token id="33" string="support" />
            <token id="34" string="as" />
            <token id="35" string="the" />
            <token id="36" string="principal" />
            <token id="37" string="means" />
            <token id="38" string="of" />
            <token id="39" string="advancement" />
          </tokens>
        </chunking>
        <chunking id="14" string="as Washington Post journalist Juan Williams has pointed out" type="SBAR">
          <tokens>
            <token id="2" string="as" />
            <token id="3" string="Washington" />
            <token id="4" string="Post" />
            <token id="5" string="journalist" />
            <token id="6" string="Juan" />
            <token id="7" string="Williams" />
            <token id="8" string="has" />
            <token id="9" string="pointed" />
            <token id="10" string="out" />
          </tokens>
        </chunking>
        <chunking id="15" string="education , self-reliance and mutual support" type="NP">
          <tokens>
            <token id="28" string="education" />
            <token id="29" string="," />
            <token id="30" string="self-reliance" />
            <token id="31" string="and" />
            <token id="32" string="mutual" />
            <token id="33" string="support" />
          </tokens>
        </chunking>
        <chunking id="16" string="the black intellectual tradition of Booker T. Washington , who advocated education , self-reliance and mutual support as the principal means of advancement" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="black" />
            <token id="19" string="intellectual" />
            <token id="20" string="tradition" />
            <token id="21" string="of" />
            <token id="22" string="Booker" />
            <token id="23" string="T." />
            <token id="24" string="Washington" />
            <token id="25" string="," />
            <token id="26" string="who" />
            <token id="27" string="advocated" />
            <token id="28" string="education" />
            <token id="29" string="," />
            <token id="30" string="self-reliance" />
            <token id="31" string="and" />
            <token id="32" string="mutual" />
            <token id="33" string="support" />
            <token id="34" string="as" />
            <token id="35" string="the" />
            <token id="36" string="principal" />
            <token id="37" string="means" />
            <token id="38" string="of" />
            <token id="39" string="advancement" />
          </tokens>
        </chunking>
        <chunking id="17" string="who advocated education , self-reliance and mutual support as the principal means of advancement" type="SBAR">
          <tokens>
            <token id="26" string="who" />
            <token id="27" string="advocated" />
            <token id="28" string="education" />
            <token id="29" string="," />
            <token id="30" string="self-reliance" />
            <token id="31" string="and" />
            <token id="32" string="mutual" />
            <token id="33" string="support" />
            <token id="34" string="as" />
            <token id="35" string="the" />
            <token id="36" string="principal" />
            <token id="37" string="means" />
            <token id="38" string="of" />
            <token id="39" string="advancement" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="15">grounded</governor>
          <dependent id="1">Yet</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">pointed</governor>
          <dependent id="2">as</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Williams</governor>
          <dependent id="3">Washington</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Williams</governor>
          <dependent id="4">Post</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Williams</governor>
          <dependent id="5">journalist</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Williams</governor>
          <dependent id="6">Juan</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">pointed</governor>
          <dependent id="7">Williams</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">pointed</governor>
          <dependent id="8">has</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="15">grounded</governor>
          <dependent id="9">pointed</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="9">pointed</governor>
          <dependent id="10">out</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="15">grounded</governor>
          <dependent id="12">Thomas</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="15">grounded</governor>
          <dependent id="13">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">grounded</governor>
          <dependent id="14">firmly</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">grounded</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">tradition</governor>
          <dependent id="16">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">tradition</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">tradition</governor>
          <dependent id="18">black</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">tradition</governor>
          <dependent id="19">intellectual</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">grounded</governor>
          <dependent id="20">tradition</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">Washington</governor>
          <dependent id="21">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">Washington</governor>
          <dependent id="22">Booker</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">Washington</governor>
          <dependent id="23">T.</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">tradition</governor>
          <dependent id="24">Washington</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">advocated</governor>
          <dependent id="26">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="24">Washington</governor>
          <dependent id="27">advocated</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">self-reliance</governor>
          <dependent id="28">education</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="33">support</governor>
          <dependent id="30">self-reliance</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="30">self-reliance</governor>
          <dependent id="31">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="30">self-reliance</governor>
          <dependent id="32">mutual</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="27">advocated</governor>
          <dependent id="33">support</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">means</governor>
          <dependent id="34">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="37">means</governor>
          <dependent id="35">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="37">means</governor>
          <dependent id="36">principal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">advocated</governor>
          <dependent id="37">means</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">advancement</governor>
          <dependent id="38">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="37">means</governor>
          <dependent id="39">advancement</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Juan Williams" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Juan" />
            <token id="7" string="Williams" />
          </tokens>
        </entity>
        <entity id="2" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Thomas" />
          </tokens>
        </entity>
        <entity id="3" string="Booker T. Washington" type="PERSON" score="0.0">
          <tokens>
            <token id="22" string="Booker" />
            <token id="23" string="T." />
            <token id="24" string="Washington" />
          </tokens>
        </entity>
        <entity id="4" string="Washington Post" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="3" string="Washington" />
            <token id="4" string="Post" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>Clarence Thomas was born June 23, 1948, in Pinpoint, Ga., a town in the marshes near Savannah.</content>
      <tokens>
        <token id="1" string="Clarence" lemma="Clarence" stem="clarenc" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="born" lemma="bear" stem="born" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="June" lemma="June" stem="june" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string="23" lemma="23" stem="23" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="8" string="1948" lemma="1948" stem="1948" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Pinpoint" lemma="Pinpoint" stem="pinpoint" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Ga." lemma="Ga." stem="ga." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="town" lemma="town" stem="town" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="marshes" lemma="marsh" stem="marsh" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="near" lemma="near" stem="near" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="Savannah" lemma="Savannah" stem="savannah" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Clarence) (NNP Thomas)) (VP (VBD was) (VP (VBN born) (NP-TMP (NNP June) (CD 23) (, ,) (CD 1948) (, ,)) (PP (IN in) (NP (NP (NNP Pinpoint) (, ,) (NNP Ga.)) (, ,) (NP (NP (DT a) (NN town)) (PP (IN in) (NP (NP (DT the) (NNS marshes)) (PP (IN near) (NP (NNP Savannah)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was born June 23 , 1948 , in Pinpoint , Ga. , a town in the marshes near Savannah" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="born" />
            <token id="5" string="June" />
            <token id="6" string="23" />
            <token id="7" string="," />
            <token id="8" string="1948" />
            <token id="9" string="," />
            <token id="10" string="in" />
            <token id="11" string="Pinpoint" />
            <token id="12" string="," />
            <token id="13" string="Ga." />
            <token id="14" string="," />
            <token id="15" string="a" />
            <token id="16" string="town" />
            <token id="17" string="in" />
            <token id="18" string="the" />
            <token id="19" string="marshes" />
            <token id="20" string="near" />
            <token id="21" string="Savannah" />
          </tokens>
        </chunking>
        <chunking id="2" string="the marshes" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="marshes" />
          </tokens>
        </chunking>
        <chunking id="3" string="born June 23 , 1948 , in Pinpoint , Ga. , a town in the marshes near Savannah" type="VP">
          <tokens>
            <token id="4" string="born" />
            <token id="5" string="June" />
            <token id="6" string="23" />
            <token id="7" string="," />
            <token id="8" string="1948" />
            <token id="9" string="," />
            <token id="10" string="in" />
            <token id="11" string="Pinpoint" />
            <token id="12" string="," />
            <token id="13" string="Ga." />
            <token id="14" string="," />
            <token id="15" string="a" />
            <token id="16" string="town" />
            <token id="17" string="in" />
            <token id="18" string="the" />
            <token id="19" string="marshes" />
            <token id="20" string="near" />
            <token id="21" string="Savannah" />
          </tokens>
        </chunking>
        <chunking id="4" string="Pinpoint , Ga. , a town in the marshes near Savannah" type="NP">
          <tokens>
            <token id="11" string="Pinpoint" />
            <token id="12" string="," />
            <token id="13" string="Ga." />
            <token id="14" string="," />
            <token id="15" string="a" />
            <token id="16" string="town" />
            <token id="17" string="in" />
            <token id="18" string="the" />
            <token id="19" string="marshes" />
            <token id="20" string="near" />
            <token id="21" string="Savannah" />
          </tokens>
        </chunking>
        <chunking id="5" string="a town in the marshes near Savannah" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="town" />
            <token id="17" string="in" />
            <token id="18" string="the" />
            <token id="19" string="marshes" />
            <token id="20" string="near" />
            <token id="21" string="Savannah" />
          </tokens>
        </chunking>
        <chunking id="6" string="the marshes near Savannah" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="marshes" />
            <token id="20" string="near" />
            <token id="21" string="Savannah" />
          </tokens>
        </chunking>
        <chunking id="7" string="Savannah" type="NP">
          <tokens>
            <token id="21" string="Savannah" />
          </tokens>
        </chunking>
        <chunking id="8" string="Pinpoint , Ga." type="NP">
          <tokens>
            <token id="11" string="Pinpoint" />
            <token id="12" string="," />
            <token id="13" string="Ga." />
          </tokens>
        </chunking>
        <chunking id="9" string="Clarence Thomas" type="NP">
          <tokens>
            <token id="1" string="Clarence" />
            <token id="2" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="10" string="a town" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="town" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Thomas</governor>
          <dependent id="1">Clarence</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="4">born</governor>
          <dependent id="2">Thomas</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">born</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">born</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="4">born</governor>
          <dependent id="5">June</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="5">June</governor>
          <dependent id="6">23</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="5">June</governor>
          <dependent id="8">1948</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Ga.</governor>
          <dependent id="10">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Ga.</governor>
          <dependent id="11">Pinpoint</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">born</governor>
          <dependent id="13">Ga.</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">town</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="13">Ga.</governor>
          <dependent id="16">town</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">marshes</governor>
          <dependent id="17">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">marshes</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">town</governor>
          <dependent id="19">marshes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">Savannah</governor>
          <dependent id="20">near</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">marshes</governor>
          <dependent id="21">Savannah</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ga." type="LOCATION" score="0.0">
          <tokens>
            <token id="13" string="Ga." />
          </tokens>
        </entity>
        <entity id="2" string="Savannah" type="LOCATION" score="0.0">
          <tokens>
            <token id="21" string="Savannah" />
          </tokens>
        </entity>
        <entity id="3" string="June 23 , 1948" type="DATE" score="0.0">
          <tokens>
            <token id="5" string="June" />
            <token id="6" string="23" />
            <token id="7" string="," />
            <token id="8" string="1948" />
          </tokens>
        </entity>
        <entity id="4" string="Clarence Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Clarence" />
            <token id="2" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>His mother, Leola, 18 at the time, lived in a house that had no plumbing.</content>
      <tokens>
        <token id="1" string="His" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="mother" lemma="mother" stem="mother" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Leola" lemma="Leola" stem="leola" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="18" lemma="18" stem="18" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="7" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="lived" lemma="live" stem="live" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="house" lemma="house" stem="hous" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="plumbing" lemma="plumbing" stem="plumb" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (PRP$ His) (NN mother)) (, ,) (NP (NNP Leola)) (, ,) (NP (NP (CD 18)) (PP (IN at) (NP (DT the) (NN time)))) (, ,)) (VP (VBD lived) (PP (IN in) (NP (NP (DT a) (NN house)) (SBAR (WHNP (WDT that)) (S (VP (VBD had) (NP (DT no) (NN plumbing)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="His mother , Leola , 18 at the time ," type="NP">
          <tokens>
            <token id="1" string="His" />
            <token id="2" string="mother" />
            <token id="3" string="," />
            <token id="4" string="Leola" />
            <token id="5" string="," />
            <token id="6" string="18" />
            <token id="7" string="at" />
            <token id="8" string="the" />
            <token id="9" string="time" />
            <token id="10" string="," />
          </tokens>
        </chunking>
        <chunking id="2" string="Leola" type="NP">
          <tokens>
            <token id="4" string="Leola" />
          </tokens>
        </chunking>
        <chunking id="3" string="a house" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="house" />
          </tokens>
        </chunking>
        <chunking id="4" string="18" type="NP">
          <tokens>
            <token id="6" string="18" />
          </tokens>
        </chunking>
        <chunking id="5" string="no plumbing" type="NP">
          <tokens>
            <token id="17" string="no" />
            <token id="18" string="plumbing" />
          </tokens>
        </chunking>
        <chunking id="6" string="the time" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="time" />
          </tokens>
        </chunking>
        <chunking id="7" string="lived in a house that had no plumbing" type="VP">
          <tokens>
            <token id="11" string="lived" />
            <token id="12" string="in" />
            <token id="13" string="a" />
            <token id="14" string="house" />
            <token id="15" string="that" />
            <token id="16" string="had" />
            <token id="17" string="no" />
            <token id="18" string="plumbing" />
          </tokens>
        </chunking>
        <chunking id="8" string="that had no plumbing" type="SBAR">
          <tokens>
            <token id="15" string="that" />
            <token id="16" string="had" />
            <token id="17" string="no" />
            <token id="18" string="plumbing" />
          </tokens>
        </chunking>
        <chunking id="9" string="had no plumbing" type="VP">
          <tokens>
            <token id="16" string="had" />
            <token id="17" string="no" />
            <token id="18" string="plumbing" />
          </tokens>
        </chunking>
        <chunking id="10" string="His mother" type="NP">
          <tokens>
            <token id="1" string="His" />
            <token id="2" string="mother" />
          </tokens>
        </chunking>
        <chunking id="11" string="18 at the time" type="NP">
          <tokens>
            <token id="6" string="18" />
            <token id="7" string="at" />
            <token id="8" string="the" />
            <token id="9" string="time" />
          </tokens>
        </chunking>
        <chunking id="12" string="a house that had no plumbing" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="house" />
            <token id="15" string="that" />
            <token id="16" string="had" />
            <token id="17" string="no" />
            <token id="18" string="plumbing" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="2">mother</governor>
          <dependent id="1">His</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">lived</governor>
          <dependent id="2">mother</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">mother</governor>
          <dependent id="4">Leola</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">mother</governor>
          <dependent id="6">18</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">time</governor>
          <dependent id="7">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">time</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">18</governor>
          <dependent id="9">time</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">lived</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">house</governor>
          <dependent id="12">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">house</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">lived</governor>
          <dependent id="14">house</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">had</governor>
          <dependent id="15">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="14">house</governor>
          <dependent id="16">had</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="18">plumbing</governor>
          <dependent id="17">no</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">had</governor>
          <dependent id="18">plumbing</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Leola" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Leola" />
          </tokens>
        </entity>
        <entity id="2" string="18" type="NUMBER" score="0.0">
          <tokens>
            <token id="6" string="18" />
          </tokens>
        </entity>
        <entity id="3" string="time" type="DATE" score="0.0">
          <tokens>
            <token id="9" string="time" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>Before Thomas&amp;apost; second birthday, his father moved to the North and left the family behind.</content>
      <tokens>
        <token id="1" string="Before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="second" lemma="second" stem="second" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="true" is_refers="false" />
        <token id="5" string="birthday" lemma="birthday" stem="birthdai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="father" lemma="father" stem="father" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="moved" lemma="move" stem="move" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="North" lemma="North" stem="north" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="left" lemma="leave" stem="left" pos="VBD" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="true" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="family" lemma="family" stem="famili" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="behind" lemma="behind" stem="behind" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN Before) (NP (NP (NNP Thomas) (POS ')) (JJ second) (NN birthday))) (, ,) (NP (PRP$ his) (NN father)) (VP (VP (VBD moved) (PP (TO to) (NP (DT the) (NNP North)))) (CC and) (VP (VBD left) (ADVP (NP (DT the) (NN family)) (IN behind)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="moved to the North" type="VP">
          <tokens>
            <token id="9" string="moved" />
            <token id="10" string="to" />
            <token id="11" string="the" />
            <token id="12" string="North" />
          </tokens>
        </chunking>
        <chunking id="2" string="Thomas '" type="NP">
          <tokens>
            <token id="2" string="Thomas" />
            <token id="3" string="'" />
          </tokens>
        </chunking>
        <chunking id="3" string="his father" type="NP">
          <tokens>
            <token id="7" string="his" />
            <token id="8" string="father" />
          </tokens>
        </chunking>
        <chunking id="4" string="the family" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="family" />
          </tokens>
        </chunking>
        <chunking id="5" string="moved to the North and left the family behind" type="VP">
          <tokens>
            <token id="9" string="moved" />
            <token id="10" string="to" />
            <token id="11" string="the" />
            <token id="12" string="North" />
            <token id="13" string="and" />
            <token id="14" string="left" />
            <token id="15" string="the" />
            <token id="16" string="family" />
            <token id="17" string="behind" />
          </tokens>
        </chunking>
        <chunking id="6" string="the North" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="North" />
          </tokens>
        </chunking>
        <chunking id="7" string="left the family behind" type="VP">
          <tokens>
            <token id="14" string="left" />
            <token id="15" string="the" />
            <token id="16" string="family" />
            <token id="17" string="behind" />
          </tokens>
        </chunking>
        <chunking id="8" string="Thomas ' second birthday" type="NP">
          <tokens>
            <token id="2" string="Thomas" />
            <token id="3" string="'" />
            <token id="4" string="second" />
            <token id="5" string="birthday" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="5">birthday</governor>
          <dependent id="1">Before</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">birthday</governor>
          <dependent id="2">Thomas</dependent>
        </dependency>
        <dependency type="case">
          <governor id="2">Thomas</governor>
          <dependent id="3">'</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">birthday</governor>
          <dependent id="4">second</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">moved</governor>
          <dependent id="5">birthday</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">father</governor>
          <dependent id="7">his</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">moved</governor>
          <dependent id="8">father</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">moved</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">North</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">North</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">moved</governor>
          <dependent id="12">North</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">moved</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">moved</governor>
          <dependent id="14">left</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">family</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">left</governor>
          <dependent id="16">family</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">family</governor>
          <dependent id="17">behind</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="left" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="14" string="left" />
          </tokens>
        </entity>
        <entity id="2" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Thomas" />
          </tokens>
        </entity>
        <entity id="3" string="second" type="ORDINAL" score="0.0">
          <tokens>
            <token id="4" string="second" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>His mother remarried, and her second husband did not want the children of her first marriage.</content>
      <tokens>
        <token id="1" string="His" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="mother" lemma="mother" stem="mother" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="remarried" lemma="remarry" stem="remarri" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="second" lemma="second" stem="second" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="8" string="husband" lemma="husband" stem="husband" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="want" lemma="want" stem="want" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="17" string="marriage" lemma="marriage" stem="marriag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP$ His) (NN mother)) (VP (VBD remarried))) (, ,) (CC and) (S (NP (PRP$ her) (JJ second) (NN husband)) (VP (VBD did) (RB not) (VP (VB want) (NP (NP (DT the) (NNS children)) (PP (IN of) (NP (PRP$ her) (JJ first) (NN marriage))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the children of her first marriage" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="children" />
            <token id="14" string="of" />
            <token id="15" string="her" />
            <token id="16" string="first" />
            <token id="17" string="marriage" />
          </tokens>
        </chunking>
        <chunking id="2" string="her second husband" type="NP">
          <tokens>
            <token id="6" string="her" />
            <token id="7" string="second" />
            <token id="8" string="husband" />
          </tokens>
        </chunking>
        <chunking id="3" string="the children" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="children" />
          </tokens>
        </chunking>
        <chunking id="4" string="her first marriage" type="NP">
          <tokens>
            <token id="15" string="her" />
            <token id="16" string="first" />
            <token id="17" string="marriage" />
          </tokens>
        </chunking>
        <chunking id="5" string="remarried" type="VP">
          <tokens>
            <token id="3" string="remarried" />
          </tokens>
        </chunking>
        <chunking id="6" string="His mother" type="NP">
          <tokens>
            <token id="1" string="His" />
            <token id="2" string="mother" />
          </tokens>
        </chunking>
        <chunking id="7" string="did not want the children of her first marriage" type="VP">
          <tokens>
            <token id="9" string="did" />
            <token id="10" string="not" />
            <token id="11" string="want" />
            <token id="12" string="the" />
            <token id="13" string="children" />
            <token id="14" string="of" />
            <token id="15" string="her" />
            <token id="16" string="first" />
            <token id="17" string="marriage" />
          </tokens>
        </chunking>
        <chunking id="8" string="want the children of her first marriage" type="VP">
          <tokens>
            <token id="11" string="want" />
            <token id="12" string="the" />
            <token id="13" string="children" />
            <token id="14" string="of" />
            <token id="15" string="her" />
            <token id="16" string="first" />
            <token id="17" string="marriage" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="2">mother</governor>
          <dependent id="1">His</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">remarried</governor>
          <dependent id="2">mother</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">remarried</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">remarried</governor>
          <dependent id="5">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">husband</governor>
          <dependent id="6">her</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">husband</governor>
          <dependent id="7">second</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">want</governor>
          <dependent id="8">husband</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">want</governor>
          <dependent id="9">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="11">want</governor>
          <dependent id="10">not</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">remarried</governor>
          <dependent id="11">want</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">children</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">want</governor>
          <dependent id="13">children</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">marriage</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="17">marriage</governor>
          <dependent id="15">her</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">marriage</governor>
          <dependent id="16">first</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">children</governor>
          <dependent id="17">marriage</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="16" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="second" type="ORDINAL" score="0.0">
          <tokens>
            <token id="7" string="second" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>Taken in by grandparents; At age 7, Thomas was sent to live with his grandparents.</content>
      <tokens>
        <token id="1" string="Taken" lemma="take" stem="taken" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="grandparents" lemma="grandparent" stem="grandpar" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="At" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="age" lemma="age" stem="ag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="7" lemma="7" stem="7" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="sent" lemma="send" stem="sent" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="live" lemma="live" stem="live" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="grandparents" lemma="grandparent" stem="grandpar" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VBN Taken) (PP (IN in) (PP (IN by) (NP (NNS grandparents)))))) (: ;) (S (PP (IN At) (NP (NN age) (CD 7))) (, ,) (NP (NNP Thomas)) (VP (VBD was) (VP (VBN sent) (S (VP (TO to) (VP (VB live) (PP (IN with) (NP (PRP$ his) (NNS grandparents))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="his grandparents" type="NP">
          <tokens>
            <token id="16" string="his" />
            <token id="17" string="grandparents" />
          </tokens>
        </chunking>
        <chunking id="2" string="age 7" type="NP">
          <tokens>
            <token id="7" string="age" />
            <token id="8" string="7" />
          </tokens>
        </chunking>
        <chunking id="3" string="sent to live with his grandparents" type="VP">
          <tokens>
            <token id="12" string="sent" />
            <token id="13" string="to" />
            <token id="14" string="live" />
            <token id="15" string="with" />
            <token id="16" string="his" />
            <token id="17" string="grandparents" />
          </tokens>
        </chunking>
        <chunking id="4" string="grandparents" type="NP">
          <tokens>
            <token id="4" string="grandparents" />
          </tokens>
        </chunking>
        <chunking id="5" string="to live with his grandparents" type="VP">
          <tokens>
            <token id="13" string="to" />
            <token id="14" string="live" />
            <token id="15" string="with" />
            <token id="16" string="his" />
            <token id="17" string="grandparents" />
          </tokens>
        </chunking>
        <chunking id="6" string="Thomas" type="NP">
          <tokens>
            <token id="10" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="7" string="live with his grandparents" type="VP">
          <tokens>
            <token id="14" string="live" />
            <token id="15" string="with" />
            <token id="16" string="his" />
            <token id="17" string="grandparents" />
          </tokens>
        </chunking>
        <chunking id="8" string="Taken in by grandparents" type="VP">
          <tokens>
            <token id="1" string="Taken" />
            <token id="2" string="in" />
            <token id="3" string="by" />
            <token id="4" string="grandparents" />
          </tokens>
        </chunking>
        <chunking id="9" string="was sent to live with his grandparents" type="VP">
          <tokens>
            <token id="11" string="was" />
            <token id="12" string="sent" />
            <token id="13" string="to" />
            <token id="14" string="live" />
            <token id="15" string="with" />
            <token id="16" string="his" />
            <token id="17" string="grandparents" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">Taken</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">grandparents</governor>
          <dependent id="2">in</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">grandparents</governor>
          <dependent id="3">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Taken</governor>
          <dependent id="4">grandparents</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">age</governor>
          <dependent id="6">At</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">sent</governor>
          <dependent id="7">age</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="7">age</governor>
          <dependent id="8">7</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="12">sent</governor>
          <dependent id="10">Thomas</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="12">sent</governor>
          <dependent id="11">was</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="1">Taken</governor>
          <dependent id="12">sent</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">live</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="12">sent</governor>
          <dependent id="14">live</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">grandparents</governor>
          <dependent id="15">with</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="17">grandparents</governor>
          <dependent id="16">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">live</governor>
          <dependent id="17">grandparents</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="7" type="NUMBER" score="0.0">
          <tokens>
            <token id="8" string="7" />
          </tokens>
        </entity>
        <entity id="2" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>His grandfather, Myers Anderson, had little formal schooling.</content>
      <tokens>
        <token id="1" string="His" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="2" string="grandfather" lemma="grandfather" stem="grandfath" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="Myers" lemma="Myers" stem="myer" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="5" string="Anderson" lemma="Anderson" stem="anderson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="little" lemma="little" stem="littl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="formal" lemma="formal" stem="formal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="schooling" lemma="schooling" stem="school" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (PRP$ His) (NN grandfather)) (, ,) (NP (NNP Myers) (NNP Anderson)) (, ,)) (VP (VBD had) (NP (JJ little) (JJ formal) (NN schooling))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Myers Anderson" type="NP">
          <tokens>
            <token id="4" string="Myers" />
            <token id="5" string="Anderson" />
          </tokens>
        </chunking>
        <chunking id="2" string="His grandfather , Myers Anderson ," type="NP">
          <tokens>
            <token id="1" string="His" />
            <token id="2" string="grandfather" />
            <token id="3" string="," />
            <token id="4" string="Myers" />
            <token id="5" string="Anderson" />
            <token id="6" string="," />
          </tokens>
        </chunking>
        <chunking id="3" string="little formal schooling" type="NP">
          <tokens>
            <token id="8" string="little" />
            <token id="9" string="formal" />
            <token id="10" string="schooling" />
          </tokens>
        </chunking>
        <chunking id="4" string="His grandfather" type="NP">
          <tokens>
            <token id="1" string="His" />
            <token id="2" string="grandfather" />
          </tokens>
        </chunking>
        <chunking id="5" string="had little formal schooling" type="VP">
          <tokens>
            <token id="7" string="had" />
            <token id="8" string="little" />
            <token id="9" string="formal" />
            <token id="10" string="schooling" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="2">grandfather</governor>
          <dependent id="1">His</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">had</governor>
          <dependent id="2">grandfather</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Anderson</governor>
          <dependent id="4">Myers</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">grandfather</governor>
          <dependent id="5">Anderson</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">had</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">schooling</governor>
          <dependent id="8">little</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">schooling</governor>
          <dependent id="9">formal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">had</governor>
          <dependent id="10">schooling</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Myers Anderson" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Myers" />
            <token id="5" string="Anderson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>But life had taught him a lot.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="life" lemma="life" stem="life" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="taught" lemma="teach" stem="taught" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="lot" lemma="lot" stem="lot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (NN life)) (VP (VBD had) (VP (VBN taught) (S (NP (PRP him)) (NP (DT a) (NN lot))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="taught him a lot" type="VP">
          <tokens>
            <token id="4" string="taught" />
            <token id="5" string="him" />
            <token id="6" string="a" />
            <token id="7" string="lot" />
          </tokens>
        </chunking>
        <chunking id="2" string="a lot" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="lot" />
          </tokens>
        </chunking>
        <chunking id="3" string="life" type="NP">
          <tokens>
            <token id="2" string="life" />
          </tokens>
        </chunking>
        <chunking id="4" string="him" type="NP">
          <tokens>
            <token id="5" string="him" />
          </tokens>
        </chunking>
        <chunking id="5" string="had taught him a lot" type="VP">
          <tokens>
            <token id="3" string="had" />
            <token id="4" string="taught" />
            <token id="5" string="him" />
            <token id="6" string="a" />
            <token id="7" string="lot" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="4">taught</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">taught</governor>
          <dependent id="2">life</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">taught</governor>
          <dependent id="3">had</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">taught</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">lot</governor>
          <dependent id="5">him</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">lot</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">taught</governor>
          <dependent id="7">lot</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>&amp;quot;He could barely read and write -- read enough to read the Bible,&amp;quot; Thomas said in a 1983 interview with the Washington Post.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="barely" lemma="barely" stem="bare" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="read" lemma="read" stem="read" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="write" lemma="write" stem="write" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="read" lemma="read" stem="read" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="enough" lemma="enough" stem="enough" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="read" lemma="read" stem="read" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Bible" lemma="Bible" stem="bibl" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="18" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="1983" lemma="1983" stem="1983" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="22" string="interview" lemma="interview" stem="interview" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="Washington" lemma="Washington" stem="washington" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="26" string="Post" lemma="Post" stem="post" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP He)) (VP (MD could) (ADVP (RB barely)) (VP (VP (VB read) (CC and) (VB write)) (: --) (VP (VB read) (ADVP (RB enough)) (S (VP (TO to) (VP (VB read) (NP (DT the) (NNP Bible))))))))) (, ,) ('' '') (NP (NNP Thomas)) (VP (VBD said) (PP (IN in) (NP (DT a) (CD 1983) (NN interview))) (PP (IN with) (NP (DT the) (NNP Washington) (NNP Post)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="said in a 1983 interview with the Washington Post" type="VP">
          <tokens>
            <token id="18" string="said" />
            <token id="19" string="in" />
            <token id="20" string="a" />
            <token id="21" string="1983" />
            <token id="22" string="interview" />
            <token id="23" string="with" />
            <token id="24" string="the" />
            <token id="25" string="Washington" />
            <token id="26" string="Post" />
          </tokens>
        </chunking>
        <chunking id="2" string="to read the Bible" type="VP">
          <tokens>
            <token id="11" string="to" />
            <token id="12" string="read" />
            <token id="13" string="the" />
            <token id="14" string="Bible" />
          </tokens>
        </chunking>
        <chunking id="3" string="read the Bible" type="VP">
          <tokens>
            <token id="12" string="read" />
            <token id="13" string="the" />
            <token id="14" string="Bible" />
          </tokens>
        </chunking>
        <chunking id="4" string="the Bible" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="Bible" />
          </tokens>
        </chunking>
        <chunking id="5" string="could barely read and write -- read enough to read the Bible" type="VP">
          <tokens>
            <token id="3" string="could" />
            <token id="4" string="barely" />
            <token id="5" string="read" />
            <token id="6" string="and" />
            <token id="7" string="write" />
            <token id="8" string="--" />
            <token id="9" string="read" />
            <token id="10" string="enough" />
            <token id="11" string="to" />
            <token id="12" string="read" />
            <token id="13" string="the" />
            <token id="14" string="Bible" />
          </tokens>
        </chunking>
        <chunking id="6" string="Thomas" type="NP">
          <tokens>
            <token id="17" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="7" string="read enough to read the Bible" type="VP">
          <tokens>
            <token id="9" string="read" />
            <token id="10" string="enough" />
            <token id="11" string="to" />
            <token id="12" string="read" />
            <token id="13" string="the" />
            <token id="14" string="Bible" />
          </tokens>
        </chunking>
        <chunking id="8" string="the Washington Post" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="Washington" />
            <token id="26" string="Post" />
          </tokens>
        </chunking>
        <chunking id="9" string="a 1983 interview" type="NP">
          <tokens>
            <token id="20" string="a" />
            <token id="21" string="1983" />
            <token id="22" string="interview" />
          </tokens>
        </chunking>
        <chunking id="10" string="He" type="NP">
          <tokens>
            <token id="2" string="He" />
          </tokens>
        </chunking>
        <chunking id="11" string="read and write -- read enough to read the Bible" type="VP">
          <tokens>
            <token id="5" string="read" />
            <token id="6" string="and" />
            <token id="7" string="write" />
            <token id="8" string="--" />
            <token id="9" string="read" />
            <token id="10" string="enough" />
            <token id="11" string="to" />
            <token id="12" string="read" />
            <token id="13" string="the" />
            <token id="14" string="Bible" />
          </tokens>
        </chunking>
        <chunking id="12" string="read and write" type="VP">
          <tokens>
            <token id="5" string="read" />
            <token id="6" string="and" />
            <token id="7" string="write" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">read</governor>
          <dependent id="2">He</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">read</governor>
          <dependent id="3">could</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">read</governor>
          <dependent id="4">barely</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="18">said</governor>
          <dependent id="5">read</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">read</governor>
          <dependent id="6">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">read</governor>
          <dependent id="7">write</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="5">read</governor>
          <dependent id="9">read</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">read</governor>
          <dependent id="10">enough</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">read</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">read</governor>
          <dependent id="12">read</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">Bible</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">read</governor>
          <dependent id="14">Bible</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">said</governor>
          <dependent id="17">Thomas</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">said</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">interview</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">interview</governor>
          <dependent id="20">a</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="22">interview</governor>
          <dependent id="21">1983</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">said</governor>
          <dependent id="22">interview</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">Post</governor>
          <dependent id="23">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">Post</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">Post</governor>
          <dependent id="25">Washington</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">said</governor>
          <dependent id="26">Post</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1983" type="DATE" score="0.0">
          <tokens>
            <token id="21" string="1983" />
          </tokens>
        </entity>
        <entity id="2" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="Thomas" />
          </tokens>
        </entity>
        <entity id="3" string="Washington Post" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="25" string="Washington" />
            <token id="26" string="Post" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>&amp;quot;But he was a tough old man.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="tough" lemma="tough" stem="tough" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="old" lemma="old" stem="old" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="man" lemma="man" stem="man" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (CC But) (NP (PRP he)) (VP (VBD was) (NP (DT a) (ADJP (JJ tough) (JJ old)) (NN man))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="was a tough old man" type="VP">
          <tokens>
            <token id="4" string="was" />
            <token id="5" string="a" />
            <token id="6" string="tough" />
            <token id="7" string="old" />
            <token id="8" string="man" />
          </tokens>
        </chunking>
        <chunking id="2" string="a tough old man" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="tough" />
            <token id="7" string="old" />
            <token id="8" string="man" />
          </tokens>
        </chunking>
        <chunking id="3" string="tough old" type="ADJP">
          <tokens>
            <token id="6" string="tough" />
            <token id="7" string="old" />
          </tokens>
        </chunking>
        <chunking id="4" string="he" type="NP">
          <tokens>
            <token id="3" string="he" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="8">man</governor>
          <dependent id="2">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">man</governor>
          <dependent id="3">he</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">man</governor>
          <dependent id="4">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">man</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">old</governor>
          <dependent id="6">tough</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">man</governor>
          <dependent id="7">old</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">man</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>; He elaborated in the Heritage Foundation paper: &amp;quot;Of course, I thought my grandparents were too rigid and their expectations were too high.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="elaborated" lemma="elaborate" stem="elabor" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Heritage" lemma="Heritage" stem="heritag" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="7" string="Foundation" lemma="Foundation" stem="foundat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="8" string="paper" lemma="paper" stem="paper" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="course" lemma="course" stem="cours" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="thought" lemma="think" stem="thought" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="grandparents" lemma="grandparent" stem="grandpar" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="too" lemma="too" stem="too" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="rigid" lemma="rigid" stem="rigid" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="expectations" lemma="expectation" stem="expect" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="too" lemma="too" stem="too" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="high" lemma="high" stem="high" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (NP (PRP He)) (VP (VBD elaborated) (PP (IN in) (NP (DT the) (NNP Heritage) (NNP Foundation) (NN paper))) (: :) (`` ``) (S (S (PP (IN Of) (NP (NN course))) (, ,) (NP (PRP I)) (VP (VBD thought) (SBAR (S (NP (PRP$ my) (NNS grandparents)) (VP (VBD were) (ADJP (RB too) (JJ rigid))))))) (CC and) (S (NP (PRP$ their) (NNS expectations)) (VP (VBD were) (ADJP (RB too) (JJ high)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="elaborated in the Heritage Foundation paper : `` Of course , I thought my grandparents were too rigid and their expectations were too high" type="VP">
          <tokens>
            <token id="3" string="elaborated" />
            <token id="4" string="in" />
            <token id="5" string="the" />
            <token id="6" string="Heritage" />
            <token id="7" string="Foundation" />
            <token id="8" string="paper" />
            <token id="9" string=":" />
            <token id="10" string="&quot;" />
            <token id="11" string="Of" />
            <token id="12" string="course" />
            <token id="13" string="," />
            <token id="14" string="I" />
            <token id="15" string="thought" />
            <token id="16" string="my" />
            <token id="17" string="grandparents" />
            <token id="18" string="were" />
            <token id="19" string="too" />
            <token id="20" string="rigid" />
            <token id="21" string="and" />
            <token id="22" string="their" />
            <token id="23" string="expectations" />
            <token id="24" string="were" />
            <token id="25" string="too" />
            <token id="26" string="high" />
          </tokens>
        </chunking>
        <chunking id="2" string="thought my grandparents were too rigid" type="VP">
          <tokens>
            <token id="15" string="thought" />
            <token id="16" string="my" />
            <token id="17" string="grandparents" />
            <token id="18" string="were" />
            <token id="19" string="too" />
            <token id="20" string="rigid" />
          </tokens>
        </chunking>
        <chunking id="3" string="their expectations" type="NP">
          <tokens>
            <token id="22" string="their" />
            <token id="23" string="expectations" />
          </tokens>
        </chunking>
        <chunking id="4" string="were too rigid" type="VP">
          <tokens>
            <token id="18" string="were" />
            <token id="19" string="too" />
            <token id="20" string="rigid" />
          </tokens>
        </chunking>
        <chunking id="5" string="the Heritage Foundation paper" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="Heritage" />
            <token id="7" string="Foundation" />
            <token id="8" string="paper" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="14" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="my grandparents" type="NP">
          <tokens>
            <token id="16" string="my" />
            <token id="17" string="grandparents" />
          </tokens>
        </chunking>
        <chunking id="8" string="my grandparents were too rigid" type="SBAR">
          <tokens>
            <token id="16" string="my" />
            <token id="17" string="grandparents" />
            <token id="18" string="were" />
            <token id="19" string="too" />
            <token id="20" string="rigid" />
          </tokens>
        </chunking>
        <chunking id="9" string="too high" type="ADJP">
          <tokens>
            <token id="25" string="too" />
            <token id="26" string="high" />
          </tokens>
        </chunking>
        <chunking id="10" string="too rigid" type="ADJP">
          <tokens>
            <token id="19" string="too" />
            <token id="20" string="rigid" />
          </tokens>
        </chunking>
        <chunking id="11" string="course" type="NP">
          <tokens>
            <token id="12" string="course" />
          </tokens>
        </chunking>
        <chunking id="12" string="were too high" type="VP">
          <tokens>
            <token id="24" string="were" />
            <token id="25" string="too" />
            <token id="26" string="high" />
          </tokens>
        </chunking>
        <chunking id="13" string="He" type="NP">
          <tokens>
            <token id="2" string="He" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">elaborated</governor>
          <dependent id="2">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">elaborated</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">paper</governor>
          <dependent id="4">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">paper</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">paper</governor>
          <dependent id="6">Heritage</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">paper</governor>
          <dependent id="7">Foundation</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">elaborated</governor>
          <dependent id="8">paper</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">course</governor>
          <dependent id="11">Of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">thought</governor>
          <dependent id="12">course</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">thought</governor>
          <dependent id="14">I</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">elaborated</governor>
          <dependent id="15">thought</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="17">grandparents</governor>
          <dependent id="16">my</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">rigid</governor>
          <dependent id="17">grandparents</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="20">rigid</governor>
          <dependent id="18">were</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">rigid</governor>
          <dependent id="19">too</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">thought</governor>
          <dependent id="20">rigid</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">thought</governor>
          <dependent id="21">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="23">expectations</governor>
          <dependent id="22">their</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">high</governor>
          <dependent id="23">expectations</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="26">high</governor>
          <dependent id="24">were</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="26">high</governor>
          <dependent id="25">too</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">thought</governor>
          <dependent id="26">high</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Heritage Foundation" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="6" string="Heritage" />
            <token id="7" string="Foundation" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>I also thought they were mean at times. . . .</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="thought" lemma="think" stem="thought" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="mean" lemma="mean" stem="mean" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="times" lemma="time" stem="time" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string=". . ." lemma="..." stem=". . ." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (ADVP (RB also)) (VP (VBD thought) (SBAR (S (NP (PRP they)) (VP (VBD were) (NP (NP (JJ mean)) (PP (IN at) (NP (NNS times)))))))) (: ...) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="thought they were mean at times" type="VP">
          <tokens>
            <token id="3" string="thought" />
            <token id="4" string="they" />
            <token id="5" string="were" />
            <token id="6" string="mean" />
            <token id="7" string="at" />
            <token id="8" string="times" />
          </tokens>
        </chunking>
        <chunking id="2" string="they were mean at times" type="SBAR">
          <tokens>
            <token id="4" string="they" />
            <token id="5" string="were" />
            <token id="6" string="mean" />
            <token id="7" string="at" />
            <token id="8" string="times" />
          </tokens>
        </chunking>
        <chunking id="3" string="they" type="NP">
          <tokens>
            <token id="4" string="they" />
          </tokens>
        </chunking>
        <chunking id="4" string="times" type="NP">
          <tokens>
            <token id="8" string="times" />
          </tokens>
        </chunking>
        <chunking id="5" string="mean" type="NP">
          <tokens>
            <token id="6" string="mean" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="mean at times" type="NP">
          <tokens>
            <token id="6" string="mean" />
            <token id="7" string="at" />
            <token id="8" string="times" />
          </tokens>
        </chunking>
        <chunking id="8" string="were mean at times" type="VP">
          <tokens>
            <token id="5" string="were" />
            <token id="6" string="mean" />
            <token id="7" string="at" />
            <token id="8" string="times" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">thought</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">thought</governor>
          <dependent id="2">also</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">thought</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">mean</governor>
          <dependent id="4">they</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">mean</governor>
          <dependent id="5">were</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">thought</governor>
          <dependent id="6">mean</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">times</governor>
          <dependent id="7">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">mean</governor>
          <dependent id="8">times</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>The most compassionate thing they did for us was teach us how to fend for ourselves in a hostile environment.&amp;quot;</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="most" lemma="most" stem="most" pos="RBS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="compassionate" lemma="compassionate" stem="compassion" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="thing" lemma="thing" stem="thing" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="us" lemma="we" stem="u" pos="PRP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="teach" lemma="teach" stem="teach" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="us" lemma="we" stem="u" pos="PRP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="how" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="fend" lemma="fend" stem="fend" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="ourselves" lemma="ourselves" stem="ourselv" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="hostile" lemma="hostile" stem="hostil" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="environment" lemma="environment" stem="environ" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT The) (ADJP (RBS most) (JJ compassionate)) (NN thing))) (NP (PRP they)) (VP (VBD did) (SBAR (IN for) (S (NP (PRP us)) (VP (VBD was) (S (VP (VB teach) (NP (PRP us)) (SBAR (WHADVP (WRB how)) (S (VP (TO to) (VP (VB fend) (PP (IN for) (NP (PRP ourselves))) (PP (IN in) (NP (DT a) (JJ hostile) (NN environment))))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="did for us was teach us how to fend for ourselves in a hostile environment" type="VP">
          <tokens>
            <token id="6" string="did" />
            <token id="7" string="for" />
            <token id="8" string="us" />
            <token id="9" string="was" />
            <token id="10" string="teach" />
            <token id="11" string="us" />
            <token id="12" string="how" />
            <token id="13" string="to" />
            <token id="14" string="fend" />
            <token id="15" string="for" />
            <token id="16" string="ourselves" />
            <token id="17" string="in" />
            <token id="18" string="a" />
            <token id="19" string="hostile" />
            <token id="20" string="environment" />
          </tokens>
        </chunking>
        <chunking id="2" string="to fend for ourselves in a hostile environment" type="VP">
          <tokens>
            <token id="13" string="to" />
            <token id="14" string="fend" />
            <token id="15" string="for" />
            <token id="16" string="ourselves" />
            <token id="17" string="in" />
            <token id="18" string="a" />
            <token id="19" string="hostile" />
            <token id="20" string="environment" />
          </tokens>
        </chunking>
        <chunking id="3" string="a hostile environment" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="hostile" />
            <token id="20" string="environment" />
          </tokens>
        </chunking>
        <chunking id="4" string="was teach us how to fend for ourselves in a hostile environment" type="VP">
          <tokens>
            <token id="9" string="was" />
            <token id="10" string="teach" />
            <token id="11" string="us" />
            <token id="12" string="how" />
            <token id="13" string="to" />
            <token id="14" string="fend" />
            <token id="15" string="for" />
            <token id="16" string="ourselves" />
            <token id="17" string="in" />
            <token id="18" string="a" />
            <token id="19" string="hostile" />
            <token id="20" string="environment" />
          </tokens>
        </chunking>
        <chunking id="5" string="how" type="WHADVP">
          <tokens>
            <token id="12" string="how" />
          </tokens>
        </chunking>
        <chunking id="6" string="ourselves" type="NP">
          <tokens>
            <token id="16" string="ourselves" />
          </tokens>
        </chunking>
        <chunking id="7" string="for us was teach us how to fend for ourselves in a hostile environment" type="SBAR">
          <tokens>
            <token id="7" string="for" />
            <token id="8" string="us" />
            <token id="9" string="was" />
            <token id="10" string="teach" />
            <token id="11" string="us" />
            <token id="12" string="how" />
            <token id="13" string="to" />
            <token id="14" string="fend" />
            <token id="15" string="for" />
            <token id="16" string="ourselves" />
            <token id="17" string="in" />
            <token id="18" string="a" />
            <token id="19" string="hostile" />
            <token id="20" string="environment" />
          </tokens>
        </chunking>
        <chunking id="8" string="they" type="NP">
          <tokens>
            <token id="5" string="they" />
          </tokens>
        </chunking>
        <chunking id="9" string="The most compassionate thing" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="most" />
            <token id="3" string="compassionate" />
            <token id="4" string="thing" />
          </tokens>
        </chunking>
        <chunking id="10" string="how to fend for ourselves in a hostile environment" type="SBAR">
          <tokens>
            <token id="12" string="how" />
            <token id="13" string="to" />
            <token id="14" string="fend" />
            <token id="15" string="for" />
            <token id="16" string="ourselves" />
            <token id="17" string="in" />
            <token id="18" string="a" />
            <token id="19" string="hostile" />
            <token id="20" string="environment" />
          </tokens>
        </chunking>
        <chunking id="11" string="teach us how to fend for ourselves in a hostile environment" type="VP">
          <tokens>
            <token id="10" string="teach" />
            <token id="11" string="us" />
            <token id="12" string="how" />
            <token id="13" string="to" />
            <token id="14" string="fend" />
            <token id="15" string="for" />
            <token id="16" string="ourselves" />
            <token id="17" string="in" />
            <token id="18" string="a" />
            <token id="19" string="hostile" />
            <token id="20" string="environment" />
          </tokens>
        </chunking>
        <chunking id="12" string="most compassionate" type="ADJP">
          <tokens>
            <token id="2" string="most" />
            <token id="3" string="compassionate" />
          </tokens>
        </chunking>
        <chunking id="13" string="us" type="NP">
          <tokens>
            <token id="8" string="us" />
          </tokens>
        </chunking>
        <chunking id="14" string="fend for ourselves in a hostile environment" type="VP">
          <tokens>
            <token id="14" string="fend" />
            <token id="15" string="for" />
            <token id="16" string="ourselves" />
            <token id="17" string="in" />
            <token id="18" string="a" />
            <token id="19" string="hostile" />
            <token id="20" string="environment" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">thing</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">compassionate</governor>
          <dependent id="2">most</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">thing</governor>
          <dependent id="3">compassionate</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="6">did</governor>
          <dependent id="4">thing</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">did</governor>
          <dependent id="5">they</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">did</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">was</governor>
          <dependent id="7">for</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">was</governor>
          <dependent id="8">us</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="6">did</governor>
          <dependent id="9">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">was</governor>
          <dependent id="10">teach</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">teach</governor>
          <dependent id="11">us</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">fend</governor>
          <dependent id="12">how</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">fend</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="10">teach</governor>
          <dependent id="14">fend</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">ourselves</governor>
          <dependent id="15">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">fend</governor>
          <dependent id="16">ourselves</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">environment</governor>
          <dependent id="17">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">environment</governor>
          <dependent id="18">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">environment</governor>
          <dependent id="19">hostile</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">fend</governor>
          <dependent id="20">environment</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="26" has_coreference="true">
      <content>; But the world that lay beyond the confines of poverty and segregation was not totally closed to Thomas.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="lay" lemma="lay" stem="lai" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="beyond" lemma="beyond" stem="beyond" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="confines" lemma="confines" stem="confin" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="poverty" lemma="poverty" stem="poverti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="segregation" lemma="segregation" stem="segreg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="totally" lemma="totally" stem="total" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="closed" lemma="close" stem="close" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (S (CC But) (NP (NP (DT the) (NN world)) (SBAR (WHNP (WDT that)) (S (VP (VBD lay) (PP (IN beyond) (NP (NP (DT the) (NNS confines)) (PP (IN of) (NP (NN poverty) (CC and) (NN segregation))))))))) (VP (VBD was) (RB not) (ADJP (RB totally) (VBN closed) (PP (TO to) (NP (NNP Thomas)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="poverty and segregation" type="NP">
          <tokens>
            <token id="11" string="poverty" />
            <token id="12" string="and" />
            <token id="13" string="segregation" />
          </tokens>
        </chunking>
        <chunking id="2" string="totally closed to Thomas" type="ADJP">
          <tokens>
            <token id="16" string="totally" />
            <token id="17" string="closed" />
            <token id="18" string="to" />
            <token id="19" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="3" string="lay beyond the confines of poverty and segregation" type="VP">
          <tokens>
            <token id="6" string="lay" />
            <token id="7" string="beyond" />
            <token id="8" string="the" />
            <token id="9" string="confines" />
            <token id="10" string="of" />
            <token id="11" string="poverty" />
            <token id="12" string="and" />
            <token id="13" string="segregation" />
          </tokens>
        </chunking>
        <chunking id="4" string="was not totally closed to Thomas" type="VP">
          <tokens>
            <token id="14" string="was" />
            <token id="15" string="not" />
            <token id="16" string="totally" />
            <token id="17" string="closed" />
            <token id="18" string="to" />
            <token id="19" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="5" string="Thomas" type="NP">
          <tokens>
            <token id="19" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="6" string="the world that lay beyond the confines of poverty and segregation" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="world" />
            <token id="5" string="that" />
            <token id="6" string="lay" />
            <token id="7" string="beyond" />
            <token id="8" string="the" />
            <token id="9" string="confines" />
            <token id="10" string="of" />
            <token id="11" string="poverty" />
            <token id="12" string="and" />
            <token id="13" string="segregation" />
          </tokens>
        </chunking>
        <chunking id="7" string="that lay beyond the confines of poverty and segregation" type="SBAR">
          <tokens>
            <token id="5" string="that" />
            <token id="6" string="lay" />
            <token id="7" string="beyond" />
            <token id="8" string="the" />
            <token id="9" string="confines" />
            <token id="10" string="of" />
            <token id="11" string="poverty" />
            <token id="12" string="and" />
            <token id="13" string="segregation" />
          </tokens>
        </chunking>
        <chunking id="8" string="the confines of poverty and segregation" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="confines" />
            <token id="10" string="of" />
            <token id="11" string="poverty" />
            <token id="12" string="and" />
            <token id="13" string="segregation" />
          </tokens>
        </chunking>
        <chunking id="9" string="the world" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="world" />
          </tokens>
        </chunking>
        <chunking id="10" string="the confines" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="confines" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="17">closed</governor>
          <dependent id="2">But</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">world</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="17">closed</governor>
          <dependent id="4">world</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">lay</governor>
          <dependent id="5">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="4">world</governor>
          <dependent id="6">lay</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">confines</governor>
          <dependent id="7">beyond</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">confines</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">lay</governor>
          <dependent id="9">confines</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">poverty</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">confines</governor>
          <dependent id="11">poverty</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">poverty</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">poverty</governor>
          <dependent id="13">segregation</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="17">closed</governor>
          <dependent id="14">was</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="17">closed</governor>
          <dependent id="15">not</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">closed</governor>
          <dependent id="16">totally</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">closed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">Thomas</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">closed</governor>
          <dependent id="19">Thomas</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="19" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>His grandfather, a Catholic, enrolled him in an all-black school run by the church.</content>
      <tokens>
        <token id="1" string="His" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="grandfather" lemma="grandfather" stem="grandfath" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="5" string="Catholic" lemma="Catholic" stem="cathol" pos="NNP" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="true" is_refers="true" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="enrolled" lemma="enrol" stem="enrol" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="all-black" lemma="all-black" stem="all-black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="school" lemma="school" stem="school" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="run" lemma="run" stem="run" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="church" lemma="church" stem="church" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (PRP$ His) (NN grandfather)) (, ,) (NP (DT a) (NNP Catholic)) (, ,)) (VP (VBD enrolled) (NP (PRP him)) (PP (IN in) (NP (NP (DT an) (JJ all-black) (NN school)) (VP (VBN run) (PP (IN by) (NP (DT the) (NN church))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="run by the church" type="VP">
          <tokens>
            <token id="13" string="run" />
            <token id="14" string="by" />
            <token id="15" string="the" />
            <token id="16" string="church" />
          </tokens>
        </chunking>
        <chunking id="2" string="an all-black school" type="NP">
          <tokens>
            <token id="10" string="an" />
            <token id="11" string="all-black" />
            <token id="12" string="school" />
          </tokens>
        </chunking>
        <chunking id="3" string="enrolled him in an all-black school run by the church" type="VP">
          <tokens>
            <token id="7" string="enrolled" />
            <token id="8" string="him" />
            <token id="9" string="in" />
            <token id="10" string="an" />
            <token id="11" string="all-black" />
            <token id="12" string="school" />
            <token id="13" string="run" />
            <token id="14" string="by" />
            <token id="15" string="the" />
            <token id="16" string="church" />
          </tokens>
        </chunking>
        <chunking id="4" string="the church" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="church" />
          </tokens>
        </chunking>
        <chunking id="5" string="His grandfather" type="NP">
          <tokens>
            <token id="1" string="His" />
            <token id="2" string="grandfather" />
          </tokens>
        </chunking>
        <chunking id="6" string="him" type="NP">
          <tokens>
            <token id="8" string="him" />
          </tokens>
        </chunking>
        <chunking id="7" string="a Catholic" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="Catholic" />
          </tokens>
        </chunking>
        <chunking id="8" string="His grandfather , a Catholic ," type="NP">
          <tokens>
            <token id="1" string="His" />
            <token id="2" string="grandfather" />
            <token id="3" string="," />
            <token id="4" string="a" />
            <token id="5" string="Catholic" />
            <token id="6" string="," />
          </tokens>
        </chunking>
        <chunking id="9" string="an all-black school run by the church" type="NP">
          <tokens>
            <token id="10" string="an" />
            <token id="11" string="all-black" />
            <token id="12" string="school" />
            <token id="13" string="run" />
            <token id="14" string="by" />
            <token id="15" string="the" />
            <token id="16" string="church" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="2">grandfather</governor>
          <dependent id="1">His</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">enrolled</governor>
          <dependent id="2">grandfather</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">Catholic</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">grandfather</governor>
          <dependent id="5">Catholic</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">enrolled</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">enrolled</governor>
          <dependent id="8">him</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">school</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">school</governor>
          <dependent id="10">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">school</governor>
          <dependent id="11">all-black</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">enrolled</governor>
          <dependent id="12">school</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="12">school</governor>
          <dependent id="13">run</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">church</governor>
          <dependent id="14">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">church</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">run</governor>
          <dependent id="16">church</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Catholic" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="5" string="Catholic" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="28" has_coreference="true">
      <content>On Monday, Thomas also made sure to thank &amp;quot;the nuns.&amp;quot;</content>
      <tokens>
        <token id="1" string="On" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Monday" lemma="Monday" stem="mondai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="5" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="made" lemma="make" stem="made" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="sure" lemma="sure" stem="sure" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="thank" lemma="thank" stem="thank" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="nuns" lemma="nun" stem="nun" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN On) (NP (NNP Monday))) (, ,) (NP (NNP Thomas)) (ADVP (RB also)) (VP (VBD made) (ADJP (JJ sure) (S (VP (TO to) (VP (VB thank) (`` ``) (NP (DT the) (NNS nuns))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="Thomas" type="NP">
          <tokens>
            <token id="4" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="2" string="made sure to thank `` the nuns" type="VP">
          <tokens>
            <token id="6" string="made" />
            <token id="7" string="sure" />
            <token id="8" string="to" />
            <token id="9" string="thank" />
            <token id="10" string="&quot;" />
            <token id="11" string="the" />
            <token id="12" string="nuns" />
          </tokens>
        </chunking>
        <chunking id="3" string="thank `` the nuns" type="VP">
          <tokens>
            <token id="9" string="thank" />
            <token id="10" string="&quot;" />
            <token id="11" string="the" />
            <token id="12" string="nuns" />
          </tokens>
        </chunking>
        <chunking id="4" string="the nuns" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="nuns" />
          </tokens>
        </chunking>
        <chunking id="5" string="Monday" type="NP">
          <tokens>
            <token id="2" string="Monday" />
          </tokens>
        </chunking>
        <chunking id="6" string="sure to thank `` the nuns" type="ADJP">
          <tokens>
            <token id="7" string="sure" />
            <token id="8" string="to" />
            <token id="9" string="thank" />
            <token id="10" string="&quot;" />
            <token id="11" string="the" />
            <token id="12" string="nuns" />
          </tokens>
        </chunking>
        <chunking id="7" string="to thank `` the nuns" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="thank" />
            <token id="10" string="&quot;" />
            <token id="11" string="the" />
            <token id="12" string="nuns" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">Monday</governor>
          <dependent id="1">On</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">made</governor>
          <dependent id="2">Monday</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">made</governor>
          <dependent id="4">Thomas</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">made</governor>
          <dependent id="5">also</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">made</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">made</governor>
          <dependent id="7">sure</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">thank</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">sure</governor>
          <dependent id="9">thank</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">nuns</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">thank</governor>
          <dependent id="12">nuns</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Thomas" />
          </tokens>
        </entity>
        <entity id="2" string="Monday" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="Monday" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="29" has_coreference="true">
      <content>; As a young man, he wanted to become a priest.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="As" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="young" lemma="young" stem="young" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="man" lemma="man" stem="man" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="wanted" lemma="want" stem="want" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="become" lemma="become" stem="becom" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="priest" lemma="priest" stem="priest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (PP (IN As) (NP (DT a) (JJ young) (NN man))) (, ,) (NP (PRP he)) (VP (VBD wanted) (S (VP (TO to) (VP (VB become) (NP (DT a) (NN priest)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a priest" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="priest" />
          </tokens>
        </chunking>
        <chunking id="2" string="wanted to become a priest" type="VP">
          <tokens>
            <token id="8" string="wanted" />
            <token id="9" string="to" />
            <token id="10" string="become" />
            <token id="11" string="a" />
            <token id="12" string="priest" />
          </tokens>
        </chunking>
        <chunking id="3" string="to become a priest" type="VP">
          <tokens>
            <token id="9" string="to" />
            <token id="10" string="become" />
            <token id="11" string="a" />
            <token id="12" string="priest" />
          </tokens>
        </chunking>
        <chunking id="4" string="a young man" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="young" />
            <token id="5" string="man" />
          </tokens>
        </chunking>
        <chunking id="5" string="he" type="NP">
          <tokens>
            <token id="7" string="he" />
          </tokens>
        </chunking>
        <chunking id="6" string="become a priest" type="VP">
          <tokens>
            <token id="10" string="become" />
            <token id="11" string="a" />
            <token id="12" string="priest" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="5">man</governor>
          <dependent id="2">As</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">man</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">man</governor>
          <dependent id="4">young</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">wanted</governor>
          <dependent id="5">man</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">wanted</governor>
          <dependent id="7">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">wanted</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">become</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">wanted</governor>
          <dependent id="10">become</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">priest</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="10">become</governor>
          <dependent id="12">priest</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="30" has_coreference="true">
      <content>In 1967, he was accepted at the all-white Immaculate Conception Seminary in Conception Junction, Mo.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="1967" lemma="1967" stem="1967" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="accepted" lemma="accept" stem="accept" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="all-white" lemma="all-white" stem="all-whit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="Immaculate" lemma="immaculate" stem="immacul" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="Conception" lemma="conception" stem="concept" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="Seminary" lemma="Seminary" stem="seminari" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Conception" lemma="conception" stem="concept" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="Junction" lemma="junction" stem="junction" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Mo" lemma="Mo." stem="mo" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (CD 1967))) (, ,) (NP (PRP he)) (VP (VBD was) (VP (VBN accepted) (PP (IN at) (NP (NP (DT the) (JJ all-white) (JJ Immaculate) (NN Conception) (NNP Seminary)) (PP (IN in) (NP (NP (NN Conception) (NN Junction)) (, ,) (NP (NNP Mo.)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the all-white Immaculate Conception Seminary in Conception Junction , Mo." type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="all-white" />
            <token id="10" string="Immaculate" />
            <token id="11" string="Conception" />
            <token id="12" string="Seminary" />
            <token id="13" string="in" />
            <token id="14" string="Conception" />
            <token id="15" string="Junction" />
            <token id="16" string="," />
            <token id="17" string="Mo" />
          </tokens>
        </chunking>
        <chunking id="2" string="accepted at the all-white Immaculate Conception Seminary in Conception Junction , Mo." type="VP">
          <tokens>
            <token id="6" string="accepted" />
            <token id="7" string="at" />
            <token id="8" string="the" />
            <token id="9" string="all-white" />
            <token id="10" string="Immaculate" />
            <token id="11" string="Conception" />
            <token id="12" string="Seminary" />
            <token id="13" string="in" />
            <token id="14" string="Conception" />
            <token id="15" string="Junction" />
            <token id="16" string="," />
            <token id="17" string="Mo" />
          </tokens>
        </chunking>
        <chunking id="3" string="Conception Junction , Mo." type="NP">
          <tokens>
            <token id="14" string="Conception" />
            <token id="15" string="Junction" />
            <token id="16" string="," />
            <token id="17" string="Mo" />
          </tokens>
        </chunking>
        <chunking id="4" string="was accepted at the all-white Immaculate Conception Seminary in Conception Junction , Mo." type="VP">
          <tokens>
            <token id="5" string="was" />
            <token id="6" string="accepted" />
            <token id="7" string="at" />
            <token id="8" string="the" />
            <token id="9" string="all-white" />
            <token id="10" string="Immaculate" />
            <token id="11" string="Conception" />
            <token id="12" string="Seminary" />
            <token id="13" string="in" />
            <token id="14" string="Conception" />
            <token id="15" string="Junction" />
            <token id="16" string="," />
            <token id="17" string="Mo" />
          </tokens>
        </chunking>
        <chunking id="5" string="the all-white Immaculate Conception Seminary" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="all-white" />
            <token id="10" string="Immaculate" />
            <token id="11" string="Conception" />
            <token id="12" string="Seminary" />
          </tokens>
        </chunking>
        <chunking id="6" string="Mo." type="NP">
          <tokens>
            <token id="17" string="Mo" />
          </tokens>
        </chunking>
        <chunking id="7" string="Conception Junction" type="NP">
          <tokens>
            <token id="14" string="Conception" />
            <token id="15" string="Junction" />
          </tokens>
        </chunking>
        <chunking id="8" string="he" type="NP">
          <tokens>
            <token id="4" string="he" />
          </tokens>
        </chunking>
        <chunking id="9" string="1967" type="NP">
          <tokens>
            <token id="2" string="1967" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">1967</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">accepted</governor>
          <dependent id="2">1967</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="6">accepted</governor>
          <dependent id="4">he</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">accepted</governor>
          <dependent id="5">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">accepted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Seminary</governor>
          <dependent id="7">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">Seminary</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">Seminary</governor>
          <dependent id="9">all-white</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">Seminary</governor>
          <dependent id="10">Immaculate</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Seminary</governor>
          <dependent id="11">Conception</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">accepted</governor>
          <dependent id="12">Seminary</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">Junction</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Junction</governor>
          <dependent id="14">Conception</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">Seminary</governor>
          <dependent id="15">Junction</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="15">Junction</governor>
          <dependent id="17">Mo.</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Mo" type="LOCATION" score="0.0">
          <tokens>
            <token id="17" string="Mo" />
          </tokens>
        </entity>
        <entity id="2" string="1967" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="1967" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="31" has_coreference="true">
      <content>He was in for a shock.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="shock" lemma="shock" stem="shock" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD was) (PP (IN in) (PP (IN for) (NP (DT a) (NN shock))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was in for a shock" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="in" />
            <token id="4" string="for" />
            <token id="5" string="a" />
            <token id="6" string="shock" />
          </tokens>
        </chunking>
        <chunking id="2" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="3" string="a shock" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="shock" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">shock</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">shock</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">shock</governor>
          <dependent id="3">in</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">shock</governor>
          <dependent id="4">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">shock</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">shock</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="32" has_coreference="true">
      <content>Other seminarians referred to him as the &amp;quot;black spot on a white horse.&amp;quot;</content>
      <tokens>
        <token id="1" string="Other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="seminarians" lemma="seminarian" stem="seminarian" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="referred" lemma="refer" stem="refer" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="spot" lemma="spot" stem="spot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="white" lemma="white" stem="white" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="horse" lemma="horse" stem="hors" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (FRAG (NP (NP (JJ Other) (NNS seminarians)) (VP (VBN referred) (PP (TO to) (NP (PRP him))) (PP (IN as) (NP (NP (DT the) (`` ``) (JJ black) (NN spot)) (PP (IN on) (NP (DT a) (JJ white) (NN horse))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="Other seminarians referred to him as the `` black spot on a white horse" type="NP">
          <tokens>
            <token id="1" string="Other" />
            <token id="2" string="seminarians" />
            <token id="3" string="referred" />
            <token id="4" string="to" />
            <token id="5" string="him" />
            <token id="6" string="as" />
            <token id="7" string="the" />
            <token id="8" string="&quot;" />
            <token id="9" string="black" />
            <token id="10" string="spot" />
            <token id="11" string="on" />
            <token id="12" string="a" />
            <token id="13" string="white" />
            <token id="14" string="horse" />
          </tokens>
        </chunking>
        <chunking id="2" string="the `` black spot" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="&quot;" />
            <token id="9" string="black" />
            <token id="10" string="spot" />
          </tokens>
        </chunking>
        <chunking id="3" string="a white horse" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="white" />
            <token id="14" string="horse" />
          </tokens>
        </chunking>
        <chunking id="4" string="the `` black spot on a white horse" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="&quot;" />
            <token id="9" string="black" />
            <token id="10" string="spot" />
            <token id="11" string="on" />
            <token id="12" string="a" />
            <token id="13" string="white" />
            <token id="14" string="horse" />
          </tokens>
        </chunking>
        <chunking id="5" string="Other seminarians" type="NP">
          <tokens>
            <token id="1" string="Other" />
            <token id="2" string="seminarians" />
          </tokens>
        </chunking>
        <chunking id="6" string="him" type="NP">
          <tokens>
            <token id="5" string="him" />
          </tokens>
        </chunking>
        <chunking id="7" string="referred to him as the `` black spot on a white horse" type="VP">
          <tokens>
            <token id="3" string="referred" />
            <token id="4" string="to" />
            <token id="5" string="him" />
            <token id="6" string="as" />
            <token id="7" string="the" />
            <token id="8" string="&quot;" />
            <token id="9" string="black" />
            <token id="10" string="spot" />
            <token id="11" string="on" />
            <token id="12" string="a" />
            <token id="13" string="white" />
            <token id="14" string="horse" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">seminarians</governor>
          <dependent id="1">Other</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">seminarians</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="2">seminarians</governor>
          <dependent id="3">referred</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">him</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">referred</governor>
          <dependent id="5">him</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">spot</governor>
          <dependent id="6">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">spot</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">spot</governor>
          <dependent id="9">black</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">referred</governor>
          <dependent id="10">spot</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">horse</governor>
          <dependent id="11">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">horse</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">horse</governor>
          <dependent id="13">white</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">spot</governor>
          <dependent id="14">horse</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="33" has_coreference="true">
      <content>Disgusted, he left at the end of his first year.</content>
      <tokens>
        <token id="1" string="Disgusted" lemma="disgust" stem="disgust" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="left" lemma="leave" stem="left" pos="VBD" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="5" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="end" lemma="end" stem="end" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="11" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (ADJP (VBN Disgusted))) (, ,) (NP (PRP he)) (VP (VBD left) (PP (IN at) (NP (NP (DT the) (NN end)) (PP (IN of) (NP (PRP$ his) (JJ first) (NN year)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the end of his first year" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="end" />
            <token id="8" string="of" />
            <token id="9" string="his" />
            <token id="10" string="first" />
            <token id="11" string="year" />
          </tokens>
        </chunking>
        <chunking id="2" string="the end" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="end" />
          </tokens>
        </chunking>
        <chunking id="3" string="Disgusted" type="ADJP">
          <tokens>
            <token id="1" string="Disgusted" />
          </tokens>
        </chunking>
        <chunking id="4" string="left at the end of his first year" type="VP">
          <tokens>
            <token id="4" string="left" />
            <token id="5" string="at" />
            <token id="6" string="the" />
            <token id="7" string="end" />
            <token id="8" string="of" />
            <token id="9" string="his" />
            <token id="10" string="first" />
            <token id="11" string="year" />
          </tokens>
        </chunking>
        <chunking id="5" string="his first year" type="NP">
          <tokens>
            <token id="9" string="his" />
            <token id="10" string="first" />
            <token id="11" string="year" />
          </tokens>
        </chunking>
        <chunking id="6" string="he" type="NP">
          <tokens>
            <token id="3" string="he" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="ccomp">
          <governor id="4">left</governor>
          <dependent id="1">Disgusted</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">left</governor>
          <dependent id="3">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">left</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">end</governor>
          <dependent id="5">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">end</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">left</governor>
          <dependent id="7">end</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">year</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">year</governor>
          <dependent id="9">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">year</governor>
          <dependent id="10">first</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">end</governor>
          <dependent id="11">year</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="left" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="4" string="left" />
          </tokens>
        </entity>
        <entity id="2" string="first year" type="DATE" score="0.0">
          <tokens>
            <token id="10" string="first" />
            <token id="11" string="year" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="34" has_coreference="true">
      <content>Flirts with &amp;apost;black power&amp;apost;; Thomas went on to attend Holy Cross College in Worcester, Mass.</content>
      <tokens>
        <token id="1" string="Flirts" lemma="Flirts" stem="flirt" pos="NNPS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="'" lemma="`" stem="'" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="power" lemma="power" stem="power" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="9" string="went" lemma="go" stem="went" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="attend" lemma="attend" stem="attend" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="Holy" lemma="Holy" stem="holi" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="14" string="Cross" lemma="Cross" stem="cross" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="15" string="College" lemma="College" stem="colleg" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="16" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Worcester" lemma="Worcester" stem="worcest" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Mass" lemma="Mass." stem="mass" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNPS Flirts)) (PP (IN with) (NP (NP (`` `) (JJ black) (NN power) ('' ')) (: ;) (NP (NNP Thomas))))) (VP (VBD went) (PP (IN on)) (S (VP (TO to) (VP (VB attend) (NP (NP (NNP Holy) (NNP Cross) (NNP College)) (PP (IN in) (NP (NNP Worcester) (, ,) (NNP Mass.)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="` black power ' ; Thomas" type="NP">
          <tokens>
            <token id="3" string="'" />
            <token id="4" string="black" />
            <token id="5" string="power" />
            <token id="6" string="'" />
            <token id="7" string=";" />
            <token id="8" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="2" string="` black power '" type="NP">
          <tokens>
            <token id="3" string="'" />
            <token id="4" string="black" />
            <token id="5" string="power" />
            <token id="6" string="'" />
          </tokens>
        </chunking>
        <chunking id="3" string="attend Holy Cross College in Worcester , Mass." type="VP">
          <tokens>
            <token id="12" string="attend" />
            <token id="13" string="Holy" />
            <token id="14" string="Cross" />
            <token id="15" string="College" />
            <token id="16" string="in" />
            <token id="17" string="Worcester" />
            <token id="18" string="," />
            <token id="19" string="Mass" />
          </tokens>
        </chunking>
        <chunking id="4" string="to attend Holy Cross College in Worcester , Mass." type="VP">
          <tokens>
            <token id="11" string="to" />
            <token id="12" string="attend" />
            <token id="13" string="Holy" />
            <token id="14" string="Cross" />
            <token id="15" string="College" />
            <token id="16" string="in" />
            <token id="17" string="Worcester" />
            <token id="18" string="," />
            <token id="19" string="Mass" />
          </tokens>
        </chunking>
        <chunking id="5" string="Flirts with ` black power ' ; Thomas" type="NP">
          <tokens>
            <token id="1" string="Flirts" />
            <token id="2" string="with" />
            <token id="3" string="'" />
            <token id="4" string="black" />
            <token id="5" string="power" />
            <token id="6" string="'" />
            <token id="7" string=";" />
            <token id="8" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="6" string="Thomas" type="NP">
          <tokens>
            <token id="8" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="7" string="Holy Cross College in Worcester , Mass." type="NP">
          <tokens>
            <token id="13" string="Holy" />
            <token id="14" string="Cross" />
            <token id="15" string="College" />
            <token id="16" string="in" />
            <token id="17" string="Worcester" />
            <token id="18" string="," />
            <token id="19" string="Mass" />
          </tokens>
        </chunking>
        <chunking id="8" string="went on to attend Holy Cross College in Worcester , Mass." type="VP">
          <tokens>
            <token id="9" string="went" />
            <token id="10" string="on" />
            <token id="11" string="to" />
            <token id="12" string="attend" />
            <token id="13" string="Holy" />
            <token id="14" string="Cross" />
            <token id="15" string="College" />
            <token id="16" string="in" />
            <token id="17" string="Worcester" />
            <token id="18" string="," />
            <token id="19" string="Mass" />
          </tokens>
        </chunking>
        <chunking id="9" string="Flirts" type="NP">
          <tokens>
            <token id="1" string="Flirts" />
          </tokens>
        </chunking>
        <chunking id="10" string="Worcester , Mass." type="NP">
          <tokens>
            <token id="17" string="Worcester" />
            <token id="18" string="," />
            <token id="19" string="Mass" />
          </tokens>
        </chunking>
        <chunking id="11" string="Holy Cross College" type="NP">
          <tokens>
            <token id="13" string="Holy" />
            <token id="14" string="Cross" />
            <token id="15" string="College" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="9">went</governor>
          <dependent id="1">Flirts</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">power</governor>
          <dependent id="2">with</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">power</governor>
          <dependent id="4">black</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Flirts</governor>
          <dependent id="5">power</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="5">power</governor>
          <dependent id="8">Thomas</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">went</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">went</governor>
          <dependent id="10">on</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">attend</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">went</governor>
          <dependent id="12">attend</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">College</governor>
          <dependent id="13">Holy</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">College</governor>
          <dependent id="14">Cross</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">attend</governor>
          <dependent id="15">College</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">Mass.</governor>
          <dependent id="16">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">Mass.</governor>
          <dependent id="17">Worcester</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">College</governor>
          <dependent id="19">Mass.</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Worcester" type="LOCATION" score="0.0">
          <tokens>
            <token id="17" string="Worcester" />
          </tokens>
        </entity>
        <entity id="2" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Thomas" />
          </tokens>
        </entity>
        <entity id="3" string="Mass" type="LOCATION" score="0.0">
          <tokens>
            <token id="19" string="Mass" />
          </tokens>
        </entity>
        <entity id="4" string="Holy Cross College" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="13" string="Holy" />
            <token id="14" string="Cross" />
            <token id="15" string="College" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="35" has_coreference="true">
      <content>In the 1960s, he flirted with the politics of &amp;quot;black power&amp;quot; and considered himself a follower of Malcolm X.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="1960s" lemma="1960" stem="1960" pos="NNS" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="flirted" lemma="flirt" stem="flirt" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="politics" lemma="politics" stem="polit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="power" lemma="power" stem="power" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="considered" lemma="consider" stem="consid" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="himself" lemma="himself" stem="himself" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="follower" lemma="follower" stem="follow" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="Malcolm" lemma="Malcolm" stem="malcolm" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="22" string="X" lemma="x" stem="x" pos="NN" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (DT the) (NNS 1960s))) (, ,) (NP (PRP he)) (VP (VP (VBD flirted) (PP (IN with) (NP (NP (DT the) (NNS politics)) (PP (IN of) (`` ``) (NP (JJ black) (NN power)) ('' ''))))) (CC and) (VP (VBN considered) (S (NP (PRP himself)) (NP (NP (DT a) (NN follower)) (PP (IN of) (NP (NNP Malcolm) (NN X))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the politics" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="politics" />
          </tokens>
        </chunking>
        <chunking id="2" string="the politics of `` black power ''" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="politics" />
            <token id="10" string="of" />
            <token id="11" string="&quot;" />
            <token id="12" string="black" />
            <token id="13" string="power" />
            <token id="14" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="3" string="a follower" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="follower" />
          </tokens>
        </chunking>
        <chunking id="4" string="a follower of Malcolm X" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="follower" />
            <token id="20" string="of" />
            <token id="21" string="Malcolm" />
            <token id="22" string="X" />
          </tokens>
        </chunking>
        <chunking id="5" string="considered himself a follower of Malcolm X" type="VP">
          <tokens>
            <token id="16" string="considered" />
            <token id="17" string="himself" />
            <token id="18" string="a" />
            <token id="19" string="follower" />
            <token id="20" string="of" />
            <token id="21" string="Malcolm" />
            <token id="22" string="X" />
          </tokens>
        </chunking>
        <chunking id="6" string="the 1960s" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="1960s" />
          </tokens>
        </chunking>
        <chunking id="7" string="Malcolm X" type="NP">
          <tokens>
            <token id="21" string="Malcolm" />
            <token id="22" string="X" />
          </tokens>
        </chunking>
        <chunking id="8" string="he" type="NP">
          <tokens>
            <token id="5" string="he" />
          </tokens>
        </chunking>
        <chunking id="9" string="flirted with the politics of `` black power ''" type="VP">
          <tokens>
            <token id="6" string="flirted" />
            <token id="7" string="with" />
            <token id="8" string="the" />
            <token id="9" string="politics" />
            <token id="10" string="of" />
            <token id="11" string="&quot;" />
            <token id="12" string="black" />
            <token id="13" string="power" />
            <token id="14" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="10" string="black power" type="NP">
          <tokens>
            <token id="12" string="black" />
            <token id="13" string="power" />
          </tokens>
        </chunking>
        <chunking id="11" string="himself" type="NP">
          <tokens>
            <token id="17" string="himself" />
          </tokens>
        </chunking>
        <chunking id="12" string="flirted with the politics of `` black power '' and considered himself a follower of Malcolm X" type="VP">
          <tokens>
            <token id="6" string="flirted" />
            <token id="7" string="with" />
            <token id="8" string="the" />
            <token id="9" string="politics" />
            <token id="10" string="of" />
            <token id="11" string="&quot;" />
            <token id="12" string="black" />
            <token id="13" string="power" />
            <token id="14" string="&quot;" />
            <token id="15" string="and" />
            <token id="16" string="considered" />
            <token id="17" string="himself" />
            <token id="18" string="a" />
            <token id="19" string="follower" />
            <token id="20" string="of" />
            <token id="21" string="Malcolm" />
            <token id="22" string="X" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">1960s</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">1960s</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">flirted</governor>
          <dependent id="3">1960s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">flirted</governor>
          <dependent id="5">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">flirted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">politics</governor>
          <dependent id="7">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">politics</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">flirted</governor>
          <dependent id="9">politics</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">power</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">power</governor>
          <dependent id="12">black</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">politics</governor>
          <dependent id="13">power</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">flirted</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">flirted</governor>
          <dependent id="16">considered</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">follower</governor>
          <dependent id="17">himself</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">follower</governor>
          <dependent id="18">a</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="16">considered</governor>
          <dependent id="19">follower</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">X</governor>
          <dependent id="20">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">X</governor>
          <dependent id="21">Malcolm</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">follower</governor>
          <dependent id="22">X</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="the 1960s" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="1960s" />
          </tokens>
        </entity>
        <entity id="2" string="Malcolm X" type="PERSON" score="0.0">
          <tokens>
            <token id="21" string="Malcolm" />
            <token id="22" string="X" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="36" has_coreference="true">
      <content>But his true interest was in the law.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="true" lemma="true" stem="true" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="interest" lemma="interest" stem="interest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="law" lemma="law" stem="law" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (PRP$ his) (JJ true) (NN interest)) (VP (VBD was) (PP (IN in) (NP (DT the) (NN law)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was in the law" type="VP">
          <tokens>
            <token id="5" string="was" />
            <token id="6" string="in" />
            <token id="7" string="the" />
            <token id="8" string="law" />
          </tokens>
        </chunking>
        <chunking id="2" string="the law" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="law" />
          </tokens>
        </chunking>
        <chunking id="3" string="his true interest" type="NP">
          <tokens>
            <token id="2" string="his" />
            <token id="3" string="true" />
            <token id="4" string="interest" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="8">law</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">interest</governor>
          <dependent id="2">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">interest</governor>
          <dependent id="3">true</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">law</governor>
          <dependent id="4">interest</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">law</governor>
          <dependent id="5">was</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">law</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">law</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">law</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="37" has_coreference="true">
      <content>He received his law degree from Yale University in 1974.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="received" lemma="receive" stem="receiv" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="law" lemma="law" stem="law" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="degree" lemma="degree" stem="degre" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Yale" lemma="Yale" stem="yale" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="8" string="University" lemma="University" stem="univers" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="1974" lemma="1974" stem="1974" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD received) (NP (PRP$ his) (NN law) (NN degree)) (PP (IN from) (NP (NNP Yale) (NNP University))) (PP (IN in) (NP (CD 1974)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Yale University" type="NP">
          <tokens>
            <token id="7" string="Yale" />
            <token id="8" string="University" />
          </tokens>
        </chunking>
        <chunking id="2" string="1974" type="NP">
          <tokens>
            <token id="10" string="1974" />
          </tokens>
        </chunking>
        <chunking id="3" string="received his law degree from Yale University in 1974" type="VP">
          <tokens>
            <token id="2" string="received" />
            <token id="3" string="his" />
            <token id="4" string="law" />
            <token id="5" string="degree" />
            <token id="6" string="from" />
            <token id="7" string="Yale" />
            <token id="8" string="University" />
            <token id="9" string="in" />
            <token id="10" string="1974" />
          </tokens>
        </chunking>
        <chunking id="4" string="his law degree" type="NP">
          <tokens>
            <token id="3" string="his" />
            <token id="4" string="law" />
            <token id="5" string="degree" />
          </tokens>
        </chunking>
        <chunking id="5" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">received</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">received</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">degree</governor>
          <dependent id="3">his</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">degree</governor>
          <dependent id="4">law</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">received</governor>
          <dependent id="5">degree</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">University</governor>
          <dependent id="6">from</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">University</governor>
          <dependent id="7">Yale</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">received</governor>
          <dependent id="8">University</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">1974</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">received</governor>
          <dependent id="10">1974</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Yale University" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="7" string="Yale" />
            <token id="8" string="University" />
          </tokens>
        </entity>
        <entity id="2" string="1974" type="DATE" score="0.0">
          <tokens>
            <token id="10" string="1974" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="38" has_coreference="true">
      <content>As a young lawyer, Thomas worked in the office of Missouri Attorney General John C. Danforth.</content>
      <tokens>
        <token id="1" string="As" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="young" lemma="young" stem="young" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="lawyer" lemma="lawyer" stem="lawyer" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="worked" lemma="work" stem="work" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="office" lemma="office" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Missouri" lemma="Missouri" stem="missouri" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="true" />
        <token id="13" string="Attorney" lemma="Attorney" stem="attornei" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="true" is_refers="false" />
        <token id="14" string="General" lemma="General" stem="gener" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="true" is_refers="false" />
        <token id="15" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="16" string="C." lemma="C." stem="c." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="17" string="Danforth" lemma="Danforth" stem="danforth" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN As) (NP (DT a) (JJ young) (NN lawyer))) (, ,) (NP (NNP Thomas)) (VP (VBD worked) (PP (IN in) (NP (NP (DT the) (NN office)) (PP (IN of) (NP (NNP Missouri) (NNP Attorney) (NNP General) (NNP John) (NNP C.) (NNP Danforth)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="worked in the office of Missouri Attorney General John C. Danforth" type="VP">
          <tokens>
            <token id="7" string="worked" />
            <token id="8" string="in" />
            <token id="9" string="the" />
            <token id="10" string="office" />
            <token id="11" string="of" />
            <token id="12" string="Missouri" />
            <token id="13" string="Attorney" />
            <token id="14" string="General" />
            <token id="15" string="John" />
            <token id="16" string="C." />
            <token id="17" string="Danforth" />
          </tokens>
        </chunking>
        <chunking id="2" string="the office of Missouri Attorney General John C. Danforth" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="office" />
            <token id="11" string="of" />
            <token id="12" string="Missouri" />
            <token id="13" string="Attorney" />
            <token id="14" string="General" />
            <token id="15" string="John" />
            <token id="16" string="C." />
            <token id="17" string="Danforth" />
          </tokens>
        </chunking>
        <chunking id="3" string="the office" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="office" />
          </tokens>
        </chunking>
        <chunking id="4" string="Missouri Attorney General John C. Danforth" type="NP">
          <tokens>
            <token id="12" string="Missouri" />
            <token id="13" string="Attorney" />
            <token id="14" string="General" />
            <token id="15" string="John" />
            <token id="16" string="C." />
            <token id="17" string="Danforth" />
          </tokens>
        </chunking>
        <chunking id="5" string="a young lawyer" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="young" />
            <token id="4" string="lawyer" />
          </tokens>
        </chunking>
        <chunking id="6" string="Thomas" type="NP">
          <tokens>
            <token id="6" string="Thomas" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">lawyer</governor>
          <dependent id="1">As</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">lawyer</governor>
          <dependent id="2">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">lawyer</governor>
          <dependent id="3">young</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">worked</governor>
          <dependent id="4">lawyer</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">worked</governor>
          <dependent id="6">Thomas</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">worked</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">office</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">office</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">worked</governor>
          <dependent id="10">office</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">Danforth</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Danforth</governor>
          <dependent id="12">Missouri</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Danforth</governor>
          <dependent id="13">Attorney</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Danforth</governor>
          <dependent id="14">General</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Danforth</governor>
          <dependent id="15">John</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Danforth</governor>
          <dependent id="16">C.</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">office</governor>
          <dependent id="17">Danforth</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Missouri" type="LOCATION" score="0.0">
          <tokens>
            <token id="12" string="Missouri" />
          </tokens>
        </entity>
        <entity id="2" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Thomas" />
          </tokens>
        </entity>
        <entity id="3" string="Attorney General" type="TITLE" score="0.0">
          <tokens>
            <token id="13" string="Attorney" />
            <token id="14" string="General" />
          </tokens>
        </entity>
        <entity id="4" string="John C. Danforth" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="John" />
            <token id="16" string="C." />
            <token id="17" string="Danforth" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="39" has_coreference="true">
      <content>He later joined Monsanto Co.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="later" lemma="later" stem="later" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="joined" lemma="join" stem="join" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="Monsanto" lemma="Monsanto" stem="monsanto" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="5" string="Co" lemma="Co." stem="co" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (ADVP (RB later)) (VP (VBD joined) (NP (NNP Monsanto) (NNP Co.))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Monsanto Co." type="NP">
          <tokens>
            <token id="4" string="Monsanto" />
            <token id="5" string="Co" />
          </tokens>
        </chunking>
        <chunking id="2" string="joined Monsanto Co." type="VP">
          <tokens>
            <token id="3" string="joined" />
            <token id="4" string="Monsanto" />
            <token id="5" string="Co" />
          </tokens>
        </chunking>
        <chunking id="3" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">joined</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">joined</governor>
          <dependent id="2">later</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">joined</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Co.</governor>
          <dependent id="4">Monsanto</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">joined</governor>
          <dependent id="5">Co.</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Monsanto Co" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="4" string="Monsanto" />
            <token id="5" string="Co" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="40" has_coreference="true">
      <content>Thomas&amp;apost; introduction to Washington came in 1979.</content>
      <tokens>
        <token id="1" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="introduction" lemma="introduction" stem="introduct" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Washington" lemma="Washington" stem="washington" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="6" string="came" lemma="come" stem="came" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="1979" lemma="1979" stem="1979" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NP (NNP Thomas) (POS ')) (NN introduction)) (PP (TO to) (NP (NNP Washington)))) (VP (VBD came) (PP (IN in) (NP (CD 1979)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Washington" type="NP">
          <tokens>
            <token id="5" string="Washington" />
          </tokens>
        </chunking>
        <chunking id="2" string="Thomas ' introduction" type="NP">
          <tokens>
            <token id="1" string="Thomas" />
            <token id="2" string="'" />
            <token id="3" string="introduction" />
          </tokens>
        </chunking>
        <chunking id="3" string="Thomas '" type="NP">
          <tokens>
            <token id="1" string="Thomas" />
            <token id="2" string="'" />
          </tokens>
        </chunking>
        <chunking id="4" string="came in 1979" type="VP">
          <tokens>
            <token id="6" string="came" />
            <token id="7" string="in" />
            <token id="8" string="1979" />
          </tokens>
        </chunking>
        <chunking id="5" string="Thomas ' introduction to Washington" type="NP">
          <tokens>
            <token id="1" string="Thomas" />
            <token id="2" string="'" />
            <token id="3" string="introduction" />
            <token id="4" string="to" />
            <token id="5" string="Washington" />
          </tokens>
        </chunking>
        <chunking id="6" string="1979" type="NP">
          <tokens>
            <token id="8" string="1979" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="3">introduction</governor>
          <dependent id="1">Thomas</dependent>
        </dependency>
        <dependency type="case">
          <governor id="1">Thomas</governor>
          <dependent id="2">'</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">came</governor>
          <dependent id="3">introduction</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">Washington</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">introduction</governor>
          <dependent id="5">Washington</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">came</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">1979</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">came</governor>
          <dependent id="8">1979</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Washington" type="LOCATION" score="0.0">
          <tokens>
            <token id="5" string="Washington" />
          </tokens>
        </entity>
        <entity id="2" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Thomas" />
          </tokens>
        </entity>
        <entity id="3" string="1979" type="DATE" score="0.0">
          <tokens>
            <token id="8" string="1979" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="41" has_coreference="true">
      <content>By then, Danforth was a Republican senator.</content>
      <tokens>
        <token id="1" string="By" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Danforth" lemma="Danforth" stem="danforth" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="5" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="Republican" lemma="republican" stem="republican" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="true" />
        <token id="8" string="senator" lemma="senator" stem="senat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN By) (NP (RB then))) (, ,) (NP (NNP Danforth)) (VP (VBD was) (NP (DT a) (JJ Republican) (NN senator))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Danforth" type="NP">
          <tokens>
            <token id="4" string="Danforth" />
          </tokens>
        </chunking>
        <chunking id="2" string="then" type="NP">
          <tokens>
            <token id="2" string="then" />
          </tokens>
        </chunking>
        <chunking id="3" string="was a Republican senator" type="VP">
          <tokens>
            <token id="5" string="was" />
            <token id="6" string="a" />
            <token id="7" string="Republican" />
            <token id="8" string="senator" />
          </tokens>
        </chunking>
        <chunking id="4" string="a Republican senator" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="Republican" />
            <token id="8" string="senator" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">then</governor>
          <dependent id="1">By</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">senator</governor>
          <dependent id="2">then</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">senator</governor>
          <dependent id="4">Danforth</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">senator</governor>
          <dependent id="5">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">senator</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">senator</governor>
          <dependent id="7">Republican</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">senator</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Danforth" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Danforth" />
          </tokens>
        </entity>
        <entity id="2" string="Republican" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="7" string="Republican" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="42" has_coreference="true">
      <content>Thomas, a former Democrat, joined his staff as a legislative assistant.</content>
      <tokens>
        <token id="1" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="former" lemma="former" stem="former" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="Democrat" lemma="Democrat" stem="democrat" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="joined" lemma="join" stem="join" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="staff" lemma="staff" stem="staff" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="legislative" lemma="legislative" stem="legisl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="assistant" lemma="assistant" stem="assist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Thomas)) (, ,) (NP (DT a) (JJ former) (NNP Democrat)) (, ,)) (VP (VBD joined) (NP (PRP$ his) (NN staff)) (PP (IN as) (NP (DT a) (JJ legislative) (NN assistant)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Thomas , a former Democrat ," type="NP">
          <tokens>
            <token id="1" string="Thomas" />
            <token id="2" string="," />
            <token id="3" string="a" />
            <token id="4" string="former" />
            <token id="5" string="Democrat" />
            <token id="6" string="," />
          </tokens>
        </chunking>
        <chunking id="2" string="Thomas" type="NP">
          <tokens>
            <token id="1" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="3" string="joined his staff as a legislative assistant" type="VP">
          <tokens>
            <token id="7" string="joined" />
            <token id="8" string="his" />
            <token id="9" string="staff" />
            <token id="10" string="as" />
            <token id="11" string="a" />
            <token id="12" string="legislative" />
            <token id="13" string="assistant" />
          </tokens>
        </chunking>
        <chunking id="4" string="his staff" type="NP">
          <tokens>
            <token id="8" string="his" />
            <token id="9" string="staff" />
          </tokens>
        </chunking>
        <chunking id="5" string="a legislative assistant" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="legislative" />
            <token id="13" string="assistant" />
          </tokens>
        </chunking>
        <chunking id="6" string="a former Democrat" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="former" />
            <token id="5" string="Democrat" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="7">joined</governor>
          <dependent id="1">Thomas</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">Democrat</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">Democrat</governor>
          <dependent id="4">former</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="1">Thomas</governor>
          <dependent id="5">Democrat</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">joined</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">staff</governor>
          <dependent id="8">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">joined</governor>
          <dependent id="9">staff</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">assistant</governor>
          <dependent id="10">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">assistant</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">assistant</governor>
          <dependent id="12">legislative</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">joined</governor>
          <dependent id="13">assistant</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Democrat" type="MISC" score="0.0">
          <tokens>
            <token id="5" string="Democrat" />
          </tokens>
        </entity>
        <entity id="2" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="43" has_coreference="true">
      <content>In 1982, after a year as assistant education secretary for civil rights, Thomas was named by President Reagan to lead the Equal Employment Opportunity Commission.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="1982" lemma="1982" stem="1982" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="6" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="7" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="assistant" lemma="assistant" stem="assist" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="education" lemma="education" stem="educ" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="secretary" lemma="secretary" stem="secretari" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="civil" lemma="civil" stem="civil" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="rights" lemma="rights" stem="right" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="16" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="named" lemma="name" stem="name" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="President" lemma="President" stem="presid" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="true" is_refers="false" />
        <token id="20" string="Reagan" lemma="Reagan" stem="reagan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="21" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="lead" lemma="lead" stem="lead" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="Equal" lemma="Equal" stem="equal" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="25" string="Employment" lemma="Employment" stem="employment" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="26" string="Opportunity" lemma="Opportunity" stem="opportun" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="27" string="Commission" lemma="Commission" stem="commiss" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (CD 1982))) (, ,) (PP (IN after) (NP (NP (DT a) (NN year)) (PP (IN as) (NP (NP (JJ assistant) (NN education) (NN secretary)) (PP (IN for) (NP (JJ civil) (NNS rights))))))) (, ,) (NP (NNP Thomas)) (VP (VBD was) (VP (VBN named) (PP (IN by) (NP (NNP President) (NNP Reagan))) (S (VP (TO to) (VP (VB lead) (NP (DT the) (NNP Equal) (NNP Employment) (NNP Opportunity) (NNP Commission))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Thomas" type="NP">
          <tokens>
            <token id="15" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="2" string="assistant education secretary" type="NP">
          <tokens>
            <token id="8" string="assistant" />
            <token id="9" string="education" />
            <token id="10" string="secretary" />
          </tokens>
        </chunking>
        <chunking id="3" string="President Reagan" type="NP">
          <tokens>
            <token id="19" string="President" />
            <token id="20" string="Reagan" />
          </tokens>
        </chunking>
        <chunking id="4" string="civil rights" type="NP">
          <tokens>
            <token id="12" string="civil" />
            <token id="13" string="rights" />
          </tokens>
        </chunking>
        <chunking id="5" string="to lead the Equal Employment Opportunity Commission" type="VP">
          <tokens>
            <token id="21" string="to" />
            <token id="22" string="lead" />
            <token id="23" string="the" />
            <token id="24" string="Equal" />
            <token id="25" string="Employment" />
            <token id="26" string="Opportunity" />
            <token id="27" string="Commission" />
          </tokens>
        </chunking>
        <chunking id="6" string="the Equal Employment Opportunity Commission" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="Equal" />
            <token id="25" string="Employment" />
            <token id="26" string="Opportunity" />
            <token id="27" string="Commission" />
          </tokens>
        </chunking>
        <chunking id="7" string="named by President Reagan to lead the Equal Employment Opportunity Commission" type="VP">
          <tokens>
            <token id="17" string="named" />
            <token id="18" string="by" />
            <token id="19" string="President" />
            <token id="20" string="Reagan" />
            <token id="21" string="to" />
            <token id="22" string="lead" />
            <token id="23" string="the" />
            <token id="24" string="Equal" />
            <token id="25" string="Employment" />
            <token id="26" string="Opportunity" />
            <token id="27" string="Commission" />
          </tokens>
        </chunking>
        <chunking id="8" string="1982" type="NP">
          <tokens>
            <token id="2" string="1982" />
          </tokens>
        </chunking>
        <chunking id="9" string="assistant education secretary for civil rights" type="NP">
          <tokens>
            <token id="8" string="assistant" />
            <token id="9" string="education" />
            <token id="10" string="secretary" />
            <token id="11" string="for" />
            <token id="12" string="civil" />
            <token id="13" string="rights" />
          </tokens>
        </chunking>
        <chunking id="10" string="was named by President Reagan to lead the Equal Employment Opportunity Commission" type="VP">
          <tokens>
            <token id="16" string="was" />
            <token id="17" string="named" />
            <token id="18" string="by" />
            <token id="19" string="President" />
            <token id="20" string="Reagan" />
            <token id="21" string="to" />
            <token id="22" string="lead" />
            <token id="23" string="the" />
            <token id="24" string="Equal" />
            <token id="25" string="Employment" />
            <token id="26" string="Opportunity" />
            <token id="27" string="Commission" />
          </tokens>
        </chunking>
        <chunking id="11" string="lead the Equal Employment Opportunity Commission" type="VP">
          <tokens>
            <token id="22" string="lead" />
            <token id="23" string="the" />
            <token id="24" string="Equal" />
            <token id="25" string="Employment" />
            <token id="26" string="Opportunity" />
            <token id="27" string="Commission" />
          </tokens>
        </chunking>
        <chunking id="12" string="a year" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="year" />
          </tokens>
        </chunking>
        <chunking id="13" string="a year as assistant education secretary for civil rights" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="year" />
            <token id="7" string="as" />
            <token id="8" string="assistant" />
            <token id="9" string="education" />
            <token id="10" string="secretary" />
            <token id="11" string="for" />
            <token id="12" string="civil" />
            <token id="13" string="rights" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">1982</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">named</governor>
          <dependent id="2">1982</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">year</governor>
          <dependent id="4">after</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">year</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">named</governor>
          <dependent id="6">year</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">secretary</governor>
          <dependent id="7">as</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">secretary</governor>
          <dependent id="8">assistant</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">secretary</governor>
          <dependent id="9">education</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">year</governor>
          <dependent id="10">secretary</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">rights</governor>
          <dependent id="11">for</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">rights</governor>
          <dependent id="12">civil</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">secretary</governor>
          <dependent id="13">rights</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="17">named</governor>
          <dependent id="15">Thomas</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="17">named</governor>
          <dependent id="16">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">named</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">Reagan</governor>
          <dependent id="18">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Reagan</governor>
          <dependent id="19">President</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">named</governor>
          <dependent id="20">Reagan</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">lead</governor>
          <dependent id="21">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="17">named</governor>
          <dependent id="22">lead</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">Commission</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">Commission</governor>
          <dependent id="24">Equal</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">Commission</governor>
          <dependent id="25">Employment</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">Commission</governor>
          <dependent id="26">Opportunity</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">lead</governor>
          <dependent id="27">Commission</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Equal Employment Opportunity Commission" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="24" string="Equal" />
            <token id="25" string="Employment" />
            <token id="26" string="Opportunity" />
            <token id="27" string="Commission" />
          </tokens>
        </entity>
        <entity id="2" string="1982" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="1982" />
          </tokens>
        </entity>
        <entity id="3" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="Thomas" />
          </tokens>
        </entity>
        <entity id="4" string="a year" type="DURATION" score="0.0">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="year" />
          </tokens>
        </entity>
        <entity id="5" string="President" type="TITLE" score="0.0">
          <tokens>
            <token id="19" string="President" />
          </tokens>
        </entity>
        <entity id="6" string="Reagan" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="Reagan" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="44" has_coreference="true">
      <content>His tenure at the commission, which investigates discrimination complaints, was controversial.</content>
      <tokens>
        <token id="1" string="His" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="tenure" lemma="tenure" stem="tenur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="commission" lemma="commission" stem="commiss" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="investigates" lemma="investigate" stem="investig" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="discrimination" lemma="discrimination" stem="discrimin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="complaints" lemma="complaint" stem="complaint" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="controversial" lemma="controversial" stem="controversi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (PRP$ His) (NN tenure)) (PP (IN at) (NP (DT the) (NN commission))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ investigates) (NP (NN discrimination) (NNS complaints))))) (, ,)) (VP (VBD was) (ADJP (JJ controversial))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the commission" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="commission" />
          </tokens>
        </chunking>
        <chunking id="2" string="investigates discrimination complaints" type="VP">
          <tokens>
            <token id="8" string="investigates" />
            <token id="9" string="discrimination" />
            <token id="10" string="complaints" />
          </tokens>
        </chunking>
        <chunking id="3" string="His tenure" type="NP">
          <tokens>
            <token id="1" string="His" />
            <token id="2" string="tenure" />
          </tokens>
        </chunking>
        <chunking id="4" string="His tenure at the commission , which investigates discrimination complaints ," type="NP">
          <tokens>
            <token id="1" string="His" />
            <token id="2" string="tenure" />
            <token id="3" string="at" />
            <token id="4" string="the" />
            <token id="5" string="commission" />
            <token id="6" string="," />
            <token id="7" string="which" />
            <token id="8" string="investigates" />
            <token id="9" string="discrimination" />
            <token id="10" string="complaints" />
            <token id="11" string="," />
          </tokens>
        </chunking>
        <chunking id="5" string="was controversial" type="VP">
          <tokens>
            <token id="12" string="was" />
            <token id="13" string="controversial" />
          </tokens>
        </chunking>
        <chunking id="6" string="which investigates discrimination complaints" type="SBAR">
          <tokens>
            <token id="7" string="which" />
            <token id="8" string="investigates" />
            <token id="9" string="discrimination" />
            <token id="10" string="complaints" />
          </tokens>
        </chunking>
        <chunking id="7" string="discrimination complaints" type="NP">
          <tokens>
            <token id="9" string="discrimination" />
            <token id="10" string="complaints" />
          </tokens>
        </chunking>
        <chunking id="8" string="controversial" type="ADJP">
          <tokens>
            <token id="13" string="controversial" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="2">tenure</governor>
          <dependent id="1">His</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">controversial</governor>
          <dependent id="2">tenure</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">commission</governor>
          <dependent id="3">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">commission</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">tenure</governor>
          <dependent id="5">commission</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">investigates</governor>
          <dependent id="7">which</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="2">tenure</governor>
          <dependent id="8">investigates</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">complaints</governor>
          <dependent id="9">discrimination</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">investigates</governor>
          <dependent id="10">complaints</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="13">controversial</governor>
          <dependent id="12">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">controversial</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="45" has_coreference="true">
      <content>Critics said the agency went soft under Thomas.</content>
      <tokens>
        <token id="1" string="Critics" lemma="critic" stem="critic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="agency" lemma="agency" stem="agenc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="went" lemma="go" stem="went" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="soft" lemma="soft" stem="soft" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="under" lemma="under" stem="under" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNS Critics)) (VP (VBD said) (SBAR (S (NP (DT the) (NN agency)) (VP (VBD went) (ADJP (JJ soft)) (PP (IN under) (NP (NNP Thomas))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the agency went soft under Thomas" type="SBAR">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="agency" />
            <token id="5" string="went" />
            <token id="6" string="soft" />
            <token id="7" string="under" />
            <token id="8" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="2" string="the agency" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="agency" />
          </tokens>
        </chunking>
        <chunking id="3" string="Thomas" type="NP">
          <tokens>
            <token id="8" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="4" string="Critics" type="NP">
          <tokens>
            <token id="1" string="Critics" />
          </tokens>
        </chunking>
        <chunking id="5" string="went soft under Thomas" type="VP">
          <tokens>
            <token id="5" string="went" />
            <token id="6" string="soft" />
            <token id="7" string="under" />
            <token id="8" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="6" string="said the agency went soft under Thomas" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="the" />
            <token id="4" string="agency" />
            <token id="5" string="went" />
            <token id="6" string="soft" />
            <token id="7" string="under" />
            <token id="8" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="7" string="soft" type="ADJP">
          <tokens>
            <token id="6" string="soft" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">Critics</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">agency</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">went</governor>
          <dependent id="4">agency</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="5">went</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">went</governor>
          <dependent id="6">soft</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">Thomas</governor>
          <dependent id="7">under</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">went</governor>
          <dependent id="8">Thomas</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="46" has_coreference="true">
      <content>Abandoning support for hiring goals and timetables, Thomas focused on resolving thousands of individual discrimination complaints.</content>
      <tokens>
        <token id="1" string="Abandoning" lemma="abandon" stem="abandon" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="support" lemma="support" stem="support" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="hiring" lemma="hire" stem="hire" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="goals" lemma="goal" stem="goal" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="timetables" lemma="timetable" stem="timet" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="10" string="focused" lemma="focus" stem="focus" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="resolving" lemma="resolve" stem="resolv" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="thousands" lemma="thousand" stem="thousand" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="individual" lemma="individual" stem="individu" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="discrimination" lemma="discrimination" stem="discrimin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="complaints" lemma="complaint" stem="complaint" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VBG Abandoning) (NP (NN support)) (PP (IN for) (S (VP (VBG hiring) (NP (NNS goals) (CC and) (NNS timetables))))))) (, ,) (NP (NNP Thomas)) (VP (VBD focused) (PP (IN on) (S (VP (VBG resolving) (NP (NP (NNS thousands)) (PP (IN of) (NP (JJ individual) (NN discrimination) (NNS complaints)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="thousands of individual discrimination complaints" type="NP">
          <tokens>
            <token id="13" string="thousands" />
            <token id="14" string="of" />
            <token id="15" string="individual" />
            <token id="16" string="discrimination" />
            <token id="17" string="complaints" />
          </tokens>
        </chunking>
        <chunking id="2" string="goals and timetables" type="NP">
          <tokens>
            <token id="5" string="goals" />
            <token id="6" string="and" />
            <token id="7" string="timetables" />
          </tokens>
        </chunking>
        <chunking id="3" string="hiring goals and timetables" type="VP">
          <tokens>
            <token id="4" string="hiring" />
            <token id="5" string="goals" />
            <token id="6" string="and" />
            <token id="7" string="timetables" />
          </tokens>
        </chunking>
        <chunking id="4" string="Thomas" type="NP">
          <tokens>
            <token id="9" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="5" string="individual discrimination complaints" type="NP">
          <tokens>
            <token id="15" string="individual" />
            <token id="16" string="discrimination" />
            <token id="17" string="complaints" />
          </tokens>
        </chunking>
        <chunking id="6" string="resolving thousands of individual discrimination complaints" type="VP">
          <tokens>
            <token id="12" string="resolving" />
            <token id="13" string="thousands" />
            <token id="14" string="of" />
            <token id="15" string="individual" />
            <token id="16" string="discrimination" />
            <token id="17" string="complaints" />
          </tokens>
        </chunking>
        <chunking id="7" string="focused on resolving thousands of individual discrimination complaints" type="VP">
          <tokens>
            <token id="10" string="focused" />
            <token id="11" string="on" />
            <token id="12" string="resolving" />
            <token id="13" string="thousands" />
            <token id="14" string="of" />
            <token id="15" string="individual" />
            <token id="16" string="discrimination" />
            <token id="17" string="complaints" />
          </tokens>
        </chunking>
        <chunking id="8" string="Abandoning support for hiring goals and timetables" type="VP">
          <tokens>
            <token id="1" string="Abandoning" />
            <token id="2" string="support" />
            <token id="3" string="for" />
            <token id="4" string="hiring" />
            <token id="5" string="goals" />
            <token id="6" string="and" />
            <token id="7" string="timetables" />
          </tokens>
        </chunking>
        <chunking id="9" string="support" type="NP">
          <tokens>
            <token id="2" string="support" />
          </tokens>
        </chunking>
        <chunking id="10" string="thousands" type="NP">
          <tokens>
            <token id="13" string="thousands" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advcl">
          <governor id="10">focused</governor>
          <dependent id="1">Abandoning</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="1">Abandoning</governor>
          <dependent id="2">support</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="4">hiring</governor>
          <dependent id="3">for</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="1">Abandoning</governor>
          <dependent id="4">hiring</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">hiring</governor>
          <dependent id="5">goals</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">goals</governor>
          <dependent id="6">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">goals</governor>
          <dependent id="7">timetables</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">focused</governor>
          <dependent id="9">Thomas</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">focused</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">resolving</governor>
          <dependent id="11">on</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="10">focused</governor>
          <dependent id="12">resolving</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">resolving</governor>
          <dependent id="13">thousands</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">complaints</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">complaints</governor>
          <dependent id="15">individual</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">complaints</governor>
          <dependent id="16">discrimination</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">thousands</governor>
          <dependent id="17">complaints</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="47" has_coreference="true">
      <content>He took credit for improving efficiency.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="took" lemma="take" stem="took" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="credit" lemma="credit" stem="credit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="improving" lemma="improve" stem="improv" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="efficiency" lemma="efficiency" stem="effici" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD took) (NP (NN credit)) (PP (IN for) (S (VP (VBG improving) (NP (NN efficiency)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="efficiency" type="NP">
          <tokens>
            <token id="6" string="efficiency" />
          </tokens>
        </chunking>
        <chunking id="2" string="improving efficiency" type="VP">
          <tokens>
            <token id="5" string="improving" />
            <token id="6" string="efficiency" />
          </tokens>
        </chunking>
        <chunking id="3" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="4" string="took credit for improving efficiency" type="VP">
          <tokens>
            <token id="2" string="took" />
            <token id="3" string="credit" />
            <token id="4" string="for" />
            <token id="5" string="improving" />
            <token id="6" string="efficiency" />
          </tokens>
        </chunking>
        <chunking id="5" string="credit" type="NP">
          <tokens>
            <token id="3" string="credit" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">took</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">took</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">took</governor>
          <dependent id="3">credit</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">improving</governor>
          <dependent id="4">for</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="2">took</governor>
          <dependent id="5">improving</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">improving</governor>
          <dependent id="6">efficiency</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="48" has_coreference="true">
      <content>When President Bush nominated Thomas to the U.S. Court of Appeals for the District of Columbia, a steppingstone to the Supreme Court, a contentious confirmation process was forecast.</content>
      <tokens>
        <token id="1" string="When" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="President" lemma="President" stem="presid" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="false" is_refers="false" />
        <token id="3" string="Bush" lemma="Bush" stem="bush" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="4" string="nominated" lemma="nominate" stem="nomin" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="U.S." lemma="U.S." stem="u.s." pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="9" string="Court" lemma="Court" stem="court" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="11" string="Appeals" lemma="Appeals" stem="appeal" pos="NNPS" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="12" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="14" string="District" lemma="District" stem="district" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="16" string="Columbia" lemma="Columbia" stem="columbia" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="steppingstone" lemma="steppingstone" stem="steppingston" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="Supreme" lemma="Supreme" stem="suprem" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="23" string="Court" lemma="Court" stem="court" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="contentious" lemma="contentious" stem="contenti" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="confirmation" lemma="confirmation" stem="confirm" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="process" lemma="process" stem="process" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="forecast" lemma="forecast" stem="forecast" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (WHADVP (WRB When)) (S (NP (NNP President) (NNP Bush)) (VP (VBD nominated) (NP (NNP Thomas)) (PP (TO to) (NP (NP (DT the) (NNP U.S.) (NNP Court)) (PP (IN of) (NP (NNPS Appeals))))) (PP (IN for) (NP (NP (DT the) (NNP District)) (PP (IN of) (NP (NP (NNP Columbia)) (, ,) (NP (NP (DT a) (NN steppingstone)) (PP (TO to) (NP (DT the) (NNP Supreme) (NNP Court))))))))))) (, ,) (NP (DT a) (JJ contentious) (NN confirmation) (NN process)) (VP (VBD was) (VP (VBN forecast))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Thomas" type="NP">
          <tokens>
            <token id="5" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="2" string="a contentious confirmation process" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="contentious" />
            <token id="27" string="confirmation" />
            <token id="28" string="process" />
          </tokens>
        </chunking>
        <chunking id="3" string="was forecast" type="VP">
          <tokens>
            <token id="29" string="was" />
            <token id="30" string="forecast" />
          </tokens>
        </chunking>
        <chunking id="4" string="President Bush" type="NP">
          <tokens>
            <token id="2" string="President" />
            <token id="3" string="Bush" />
          </tokens>
        </chunking>
        <chunking id="5" string="the U.S. Court of Appeals" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="U.S." />
            <token id="9" string="Court" />
            <token id="10" string="of" />
            <token id="11" string="Appeals" />
          </tokens>
        </chunking>
        <chunking id="6" string="a steppingstone to the Supreme Court" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="steppingstone" />
            <token id="20" string="to" />
            <token id="21" string="the" />
            <token id="22" string="Supreme" />
            <token id="23" string="Court" />
          </tokens>
        </chunking>
        <chunking id="7" string="forecast" type="VP">
          <tokens>
            <token id="30" string="forecast" />
          </tokens>
        </chunking>
        <chunking id="8" string="the District of Columbia , a steppingstone to the Supreme Court" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="District" />
            <token id="15" string="of" />
            <token id="16" string="Columbia" />
            <token id="17" string="," />
            <token id="18" string="a" />
            <token id="19" string="steppingstone" />
            <token id="20" string="to" />
            <token id="21" string="the" />
            <token id="22" string="Supreme" />
            <token id="23" string="Court" />
          </tokens>
        </chunking>
        <chunking id="9" string="nominated Thomas to the U.S. Court of Appeals for the District of Columbia , a steppingstone to the Supreme Court" type="VP">
          <tokens>
            <token id="4" string="nominated" />
            <token id="5" string="Thomas" />
            <token id="6" string="to" />
            <token id="7" string="the" />
            <token id="8" string="U.S." />
            <token id="9" string="Court" />
            <token id="10" string="of" />
            <token id="11" string="Appeals" />
            <token id="12" string="for" />
            <token id="13" string="the" />
            <token id="14" string="District" />
            <token id="15" string="of" />
            <token id="16" string="Columbia" />
            <token id="17" string="," />
            <token id="18" string="a" />
            <token id="19" string="steppingstone" />
            <token id="20" string="to" />
            <token id="21" string="the" />
            <token id="22" string="Supreme" />
            <token id="23" string="Court" />
          </tokens>
        </chunking>
        <chunking id="10" string="When President Bush nominated Thomas to the U.S. Court of Appeals for the District of Columbia , a steppingstone to the Supreme Court" type="SBAR">
          <tokens>
            <token id="1" string="When" />
            <token id="2" string="President" />
            <token id="3" string="Bush" />
            <token id="4" string="nominated" />
            <token id="5" string="Thomas" />
            <token id="6" string="to" />
            <token id="7" string="the" />
            <token id="8" string="U.S." />
            <token id="9" string="Court" />
            <token id="10" string="of" />
            <token id="11" string="Appeals" />
            <token id="12" string="for" />
            <token id="13" string="the" />
            <token id="14" string="District" />
            <token id="15" string="of" />
            <token id="16" string="Columbia" />
            <token id="17" string="," />
            <token id="18" string="a" />
            <token id="19" string="steppingstone" />
            <token id="20" string="to" />
            <token id="21" string="the" />
            <token id="22" string="Supreme" />
            <token id="23" string="Court" />
          </tokens>
        </chunking>
        <chunking id="11" string="Appeals" type="NP">
          <tokens>
            <token id="11" string="Appeals" />
          </tokens>
        </chunking>
        <chunking id="12" string="When" type="WHADVP">
          <tokens>
            <token id="1" string="When" />
          </tokens>
        </chunking>
        <chunking id="13" string="Columbia" type="NP">
          <tokens>
            <token id="16" string="Columbia" />
          </tokens>
        </chunking>
        <chunking id="14" string="Columbia , a steppingstone to the Supreme Court" type="NP">
          <tokens>
            <token id="16" string="Columbia" />
            <token id="17" string="," />
            <token id="18" string="a" />
            <token id="19" string="steppingstone" />
            <token id="20" string="to" />
            <token id="21" string="the" />
            <token id="22" string="Supreme" />
            <token id="23" string="Court" />
          </tokens>
        </chunking>
        <chunking id="15" string="the Supreme Court" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="Supreme" />
            <token id="23" string="Court" />
          </tokens>
        </chunking>
        <chunking id="16" string="the U.S. Court" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="U.S." />
            <token id="9" string="Court" />
          </tokens>
        </chunking>
        <chunking id="17" string="a steppingstone" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="steppingstone" />
          </tokens>
        </chunking>
        <chunking id="18" string="the District" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="District" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="4">nominated</governor>
          <dependent id="1">When</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Bush</governor>
          <dependent id="2">President</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">nominated</governor>
          <dependent id="3">Bush</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="30">forecast</governor>
          <dependent id="4">nominated</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">nominated</governor>
          <dependent id="5">Thomas</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Court</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">Court</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Court</governor>
          <dependent id="8">U.S.</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">nominated</governor>
          <dependent id="9">Court</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Appeals</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">Court</governor>
          <dependent id="11">Appeals</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">District</governor>
          <dependent id="12">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">District</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">nominated</governor>
          <dependent id="14">District</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">Columbia</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">District</governor>
          <dependent id="16">Columbia</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">steppingstone</governor>
          <dependent id="18">a</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="16">Columbia</governor>
          <dependent id="19">steppingstone</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">Court</governor>
          <dependent id="20">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">Court</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">Court</governor>
          <dependent id="22">Supreme</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">steppingstone</governor>
          <dependent id="23">Court</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">process</governor>
          <dependent id="25">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">process</governor>
          <dependent id="26">contentious</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">process</governor>
          <dependent id="27">confirmation</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="30">forecast</governor>
          <dependent id="28">process</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="30">forecast</governor>
          <dependent id="29">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="30">forecast</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Supreme Court" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="22" string="Supreme" />
            <token id="23" string="Court" />
          </tokens>
        </entity>
        <entity id="2" string="U.S. Court of Appeals for the District of Columbia" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="8" string="U.S." />
            <token id="9" string="Court" />
            <token id="10" string="of" />
            <token id="11" string="Appeals" />
            <token id="12" string="for" />
            <token id="13" string="the" />
            <token id="14" string="District" />
            <token id="15" string="of" />
            <token id="16" string="Columbia" />
          </tokens>
        </entity>
        <entity id="3" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Thomas" />
          </tokens>
        </entity>
        <entity id="4" string="Bush" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Bush" />
          </tokens>
        </entity>
        <entity id="5" string="President" type="TITLE" score="0.0">
          <tokens>
            <token id="2" string="President" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="49" has_coreference="true">
      <content>But the hearings went smoothly, perhaps because Thomas was never among the Reagan administration&amp;apost;s most outspoken critics of civil rights.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="hearings" lemma="hearing" stem="hear" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="went" lemma="go" stem="went" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="smoothly" lemma="smoothly" stem="smoothli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="perhaps" lemma="perhaps" stem="perhap" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="10" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="among" lemma="among" stem="among" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Reagan" lemma="Reagan" stem="reagan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="15" string="administration" lemma="administration" stem="administr" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="most" lemma="most" stem="most" pos="RBS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="outspoken" lemma="outspoken" stem="outspoken" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="critics" lemma="critic" stem="critic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="civil" lemma="civil" stem="civil" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="rights" lemma="rights" stem="right" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (DT the) (NNS hearings)) (VP (VBD went) (ADVP (RB smoothly)) (, ,) (SBAR (ADVP (RB perhaps)) (IN because) (S (NP (NNP Thomas)) (VP (VBD was) (ADVP (RB never)) (PP (IN among) (NP (NP (NP (DT the) (NNP Reagan) (NN administration) (POS 's)) (ADJP (RBS most) (JJ outspoken)) (NNS critics)) (PP (IN of) (NP (JJ civil) (NNS rights))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the hearings" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="hearings" />
          </tokens>
        </chunking>
        <chunking id="2" string="civil rights" type="NP">
          <tokens>
            <token id="21" string="civil" />
            <token id="22" string="rights" />
          </tokens>
        </chunking>
        <chunking id="3" string="the Reagan administration 's most outspoken critics of civil rights" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="Reagan" />
            <token id="15" string="administration" />
            <token id="16" string="'s" />
            <token id="17" string="most" />
            <token id="18" string="outspoken" />
            <token id="19" string="critics" />
            <token id="20" string="of" />
            <token id="21" string="civil" />
            <token id="22" string="rights" />
          </tokens>
        </chunking>
        <chunking id="4" string="went smoothly , perhaps because Thomas was never among the Reagan administration 's most outspoken critics of civil rights" type="VP">
          <tokens>
            <token id="4" string="went" />
            <token id="5" string="smoothly" />
            <token id="6" string="," />
            <token id="7" string="perhaps" />
            <token id="8" string="because" />
            <token id="9" string="Thomas" />
            <token id="10" string="was" />
            <token id="11" string="never" />
            <token id="12" string="among" />
            <token id="13" string="the" />
            <token id="14" string="Reagan" />
            <token id="15" string="administration" />
            <token id="16" string="'s" />
            <token id="17" string="most" />
            <token id="18" string="outspoken" />
            <token id="19" string="critics" />
            <token id="20" string="of" />
            <token id="21" string="civil" />
            <token id="22" string="rights" />
          </tokens>
        </chunking>
        <chunking id="5" string="perhaps because Thomas was never among the Reagan administration 's most outspoken critics of civil rights" type="SBAR">
          <tokens>
            <token id="7" string="perhaps" />
            <token id="8" string="because" />
            <token id="9" string="Thomas" />
            <token id="10" string="was" />
            <token id="11" string="never" />
            <token id="12" string="among" />
            <token id="13" string="the" />
            <token id="14" string="Reagan" />
            <token id="15" string="administration" />
            <token id="16" string="'s" />
            <token id="17" string="most" />
            <token id="18" string="outspoken" />
            <token id="19" string="critics" />
            <token id="20" string="of" />
            <token id="21" string="civil" />
            <token id="22" string="rights" />
          </tokens>
        </chunking>
        <chunking id="6" string="Thomas" type="NP">
          <tokens>
            <token id="9" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="7" string="the Reagan administration 's most outspoken critics" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="Reagan" />
            <token id="15" string="administration" />
            <token id="16" string="'s" />
            <token id="17" string="most" />
            <token id="18" string="outspoken" />
            <token id="19" string="critics" />
          </tokens>
        </chunking>
        <chunking id="8" string="was never among the Reagan administration 's most outspoken critics of civil rights" type="VP">
          <tokens>
            <token id="10" string="was" />
            <token id="11" string="never" />
            <token id="12" string="among" />
            <token id="13" string="the" />
            <token id="14" string="Reagan" />
            <token id="15" string="administration" />
            <token id="16" string="'s" />
            <token id="17" string="most" />
            <token id="18" string="outspoken" />
            <token id="19" string="critics" />
            <token id="20" string="of" />
            <token id="21" string="civil" />
            <token id="22" string="rights" />
          </tokens>
        </chunking>
        <chunking id="9" string="most outspoken" type="ADJP">
          <tokens>
            <token id="17" string="most" />
            <token id="18" string="outspoken" />
          </tokens>
        </chunking>
        <chunking id="10" string="the Reagan administration 's" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="Reagan" />
            <token id="15" string="administration" />
            <token id="16" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="4">went</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">hearings</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">went</governor>
          <dependent id="3">hearings</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">went</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">went</governor>
          <dependent id="5">smoothly</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">critics</governor>
          <dependent id="7">perhaps</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">critics</governor>
          <dependent id="8">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">critics</governor>
          <dependent id="9">Thomas</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="19">critics</governor>
          <dependent id="10">was</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="19">critics</governor>
          <dependent id="11">never</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">critics</governor>
          <dependent id="12">among</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">administration</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">administration</governor>
          <dependent id="14">Reagan</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">critics</governor>
          <dependent id="15">administration</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">administration</governor>
          <dependent id="16">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">outspoken</governor>
          <dependent id="17">most</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">critics</governor>
          <dependent id="18">outspoken</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">went</governor>
          <dependent id="19">critics</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">rights</governor>
          <dependent id="20">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">rights</governor>
          <dependent id="21">civil</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">critics</governor>
          <dependent id="22">rights</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Thomas" />
          </tokens>
        </entity>
        <entity id="2" string="Reagan" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Reagan" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="50" has_coreference="true">
      <content>He took his seat on the appeals court in March 1990.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="took" lemma="take" stem="took" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="seat" lemma="seat" stem="seat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="appeals" lemma="appeal" stem="appeal" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="court" lemma="court" stem="court" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="March" lemma="March" stem="march" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="11" string="1990" lemma="1990" stem="1990" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD took) (NP (PRP$ his) (NN seat)) (PP (IN on) (NP (DT the) (NNS appeals) (NN court))) (PP (IN in) (NP (NNP March) (CD 1990)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="took his seat on the appeals court in March 1990" type="VP">
          <tokens>
            <token id="2" string="took" />
            <token id="3" string="his" />
            <token id="4" string="seat" />
            <token id="5" string="on" />
            <token id="6" string="the" />
            <token id="7" string="appeals" />
            <token id="8" string="court" />
            <token id="9" string="in" />
            <token id="10" string="March" />
            <token id="11" string="1990" />
          </tokens>
        </chunking>
        <chunking id="2" string="the appeals court" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="appeals" />
            <token id="8" string="court" />
          </tokens>
        </chunking>
        <chunking id="3" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="4" string="his seat" type="NP">
          <tokens>
            <token id="3" string="his" />
            <token id="4" string="seat" />
          </tokens>
        </chunking>
        <chunking id="5" string="March 1990" type="NP">
          <tokens>
            <token id="10" string="March" />
            <token id="11" string="1990" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">took</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">took</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">seat</governor>
          <dependent id="3">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">took</governor>
          <dependent id="4">seat</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">court</governor>
          <dependent id="5">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">court</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">court</governor>
          <dependent id="7">appeals</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">took</governor>
          <dependent id="8">court</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">March</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">took</governor>
          <dependent id="10">March</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="10">March</governor>
          <dependent id="11">1990</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="March 1990" type="DATE" score="0.0">
          <tokens>
            <token id="10" string="March" />
            <token id="11" string="1990" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="51" has_coreference="true">
      <content>Thomas, who lives in suburban Virginia, is married and has a son.</content>
      <tokens>
        <token id="1" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="lives" lemma="live" stem="live" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="suburban" lemma="suburban" stem="suburban" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="Virginia" lemma="Virginia" stem="virginia" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="married" lemma="marry" stem="marri" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="son" lemma="son" stem="son" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Thomas)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBZ lives) (PP (IN in) (NP (JJ suburban) (NNP Virginia)))))) (, ,)) (VP (VP (VBZ is) (VP (VBN married))) (CC and) (VP (VBZ has) (NP (DT a) (NN son)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is married" type="VP">
          <tokens>
            <token id="9" string="is" />
            <token id="10" string="married" />
          </tokens>
        </chunking>
        <chunking id="2" string="has a son" type="VP">
          <tokens>
            <token id="12" string="has" />
            <token id="13" string="a" />
            <token id="14" string="son" />
          </tokens>
        </chunking>
        <chunking id="3" string="a son" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="son" />
          </tokens>
        </chunking>
        <chunking id="4" string="Thomas" type="NP">
          <tokens>
            <token id="1" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="5" string="who lives in suburban Virginia" type="SBAR">
          <tokens>
            <token id="3" string="who" />
            <token id="4" string="lives" />
            <token id="5" string="in" />
            <token id="6" string="suburban" />
            <token id="7" string="Virginia" />
          </tokens>
        </chunking>
        <chunking id="6" string="lives in suburban Virginia" type="VP">
          <tokens>
            <token id="4" string="lives" />
            <token id="5" string="in" />
            <token id="6" string="suburban" />
            <token id="7" string="Virginia" />
          </tokens>
        </chunking>
        <chunking id="7" string="married" type="VP">
          <tokens>
            <token id="10" string="married" />
          </tokens>
        </chunking>
        <chunking id="8" string="Thomas , who lives in suburban Virginia ," type="NP">
          <tokens>
            <token id="1" string="Thomas" />
            <token id="2" string="," />
            <token id="3" string="who" />
            <token id="4" string="lives" />
            <token id="5" string="in" />
            <token id="6" string="suburban" />
            <token id="7" string="Virginia" />
            <token id="8" string="," />
          </tokens>
        </chunking>
        <chunking id="9" string="suburban Virginia" type="NP">
          <tokens>
            <token id="6" string="suburban" />
            <token id="7" string="Virginia" />
          </tokens>
        </chunking>
        <chunking id="10" string="is married and has a son" type="VP">
          <tokens>
            <token id="9" string="is" />
            <token id="10" string="married" />
            <token id="11" string="and" />
            <token id="12" string="has" />
            <token id="13" string="a" />
            <token id="14" string="son" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="10">married</governor>
          <dependent id="1">Thomas</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">lives</governor>
          <dependent id="3">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="1">Thomas</governor>
          <dependent id="4">lives</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Virginia</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">Virginia</governor>
          <dependent id="6">suburban</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">lives</governor>
          <dependent id="7">Virginia</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="10">married</governor>
          <dependent id="9">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">married</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">married</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">married</governor>
          <dependent id="12">has</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">son</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">has</governor>
          <dependent id="14">son</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Thomas" />
          </tokens>
        </entity>
        <entity id="2" string="Virginia" type="LOCATION" score="0.0">
          <tokens>
            <token id="7" string="Virginia" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="52" has_coreference="true">
      <content>&amp;quot;In my view,&amp;quot; he said of his life Monday, &amp;quot;only in America could this have been possible.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="view" lemma="view" stem="view" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="life" lemma="life" stem="life" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="Monday" lemma="Monday" stem="mondai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="America" lemma="America" stem="america" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="18" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="possible" lemma="possible" stem="possibl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (PP (IN In) (NP (PRP$ my) (NN view))) (, ,) ('' '') (NP (PRP he)) (VP (VBD said) (PP (IN of) (NP (NP (PRP$ his) (NN life)) (NP-TMP (NNP Monday)))) (, ,) (`` ``) (S (ADJP (RB only) (PP (IN in) (NP (NNP America)))) (SBAR (SINV (MD could) (NP (DT this)) (VP (VB have) (VP (VBN been) (ADJP (JJ possible)))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="his life" type="NP">
          <tokens>
            <token id="10" string="his" />
            <token id="11" string="life" />
          </tokens>
        </chunking>
        <chunking id="2" string="my view" type="NP">
          <tokens>
            <token id="3" string="my" />
            <token id="4" string="view" />
          </tokens>
        </chunking>
        <chunking id="3" string="America" type="NP">
          <tokens>
            <token id="17" string="America" />
          </tokens>
        </chunking>
        <chunking id="4" string="been possible" type="VP">
          <tokens>
            <token id="21" string="been" />
            <token id="22" string="possible" />
          </tokens>
        </chunking>
        <chunking id="5" string="his life Monday" type="NP">
          <tokens>
            <token id="10" string="his" />
            <token id="11" string="life" />
            <token id="12" string="Monday" />
          </tokens>
        </chunking>
        <chunking id="6" string="possible" type="ADJP">
          <tokens>
            <token id="22" string="possible" />
          </tokens>
        </chunking>
        <chunking id="7" string="could this have been possible" type="SBAR">
          <tokens>
            <token id="18" string="could" />
            <token id="19" string="this" />
            <token id="20" string="have" />
            <token id="21" string="been" />
            <token id="22" string="possible" />
          </tokens>
        </chunking>
        <chunking id="8" string="this" type="NP">
          <tokens>
            <token id="19" string="this" />
          </tokens>
        </chunking>
        <chunking id="9" string="have been possible" type="VP">
          <tokens>
            <token id="20" string="have" />
            <token id="21" string="been" />
            <token id="22" string="possible" />
          </tokens>
        </chunking>
        <chunking id="10" string="he" type="NP">
          <tokens>
            <token id="7" string="he" />
          </tokens>
        </chunking>
        <chunking id="11" string="only in America" type="ADJP">
          <tokens>
            <token id="15" string="only" />
            <token id="16" string="in" />
            <token id="17" string="America" />
          </tokens>
        </chunking>
        <chunking id="12" string="said of his life Monday , `` only in America could this have been possible" type="VP">
          <tokens>
            <token id="8" string="said" />
            <token id="9" string="of" />
            <token id="10" string="his" />
            <token id="11" string="life" />
            <token id="12" string="Monday" />
            <token id="13" string="," />
            <token id="14" string="&quot;" />
            <token id="15" string="only" />
            <token id="16" string="in" />
            <token id="17" string="America" />
            <token id="18" string="could" />
            <token id="19" string="this" />
            <token id="20" string="have" />
            <token id="21" string="been" />
            <token id="22" string="possible" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">view</governor>
          <dependent id="2">In</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">view</governor>
          <dependent id="3">my</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">said</governor>
          <dependent id="4">view</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">said</governor>
          <dependent id="7">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">said</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">life</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">life</governor>
          <dependent id="10">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">said</governor>
          <dependent id="11">life</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="11">life</governor>
          <dependent id="12">Monday</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="22">possible</governor>
          <dependent id="15">only</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">America</governor>
          <dependent id="16">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">only</governor>
          <dependent id="17">America</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="22">possible</governor>
          <dependent id="18">could</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">possible</governor>
          <dependent id="19">this</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="22">possible</governor>
          <dependent id="20">have</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="22">possible</governor>
          <dependent id="21">been</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">said</governor>
          <dependent id="22">possible</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="America" type="LOCATION" score="0.0">
          <tokens>
            <token id="17" string="America" />
          </tokens>
        </entity>
        <entity id="2" string="Monday" type="DATE" score="0.0">
          <tokens>
            <token id="12" string="Monday" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="19-20" string="President Reagan" id_sentence="43" />
      <mentions>
        <mention ids_tokens="14" string="Reagan" id_sentence="49" />
      </mentions>
    </coreference>
    <coreference id="2" type="PROPER">
      <referenced ids_tokens="39" string="Georgia" id_sentence="1" />
      <mentions>
        <mention ids_tokens="13" string="Ga." id_sentence="14" />
        <mention ids_tokens="15-21" string="a town in the marshes near Savannah" id_sentence="14" />
      </mentions>
    </coreference>
    <coreference id="3" type="PROPER">
      <referenced ids_tokens="23-24-25-26-27" string="the Equal Employment Opportunity Commission" id_sentence="43" />
      <mentions>
        <mention ids_tokens="4-5" string="the commission" id_sentence="44" />
      </mentions>
    </coreference>
    <coreference id="4" type="NOMINAL">
      <referenced ids_tokens="1-2" string="The label" id_sentence="1" />
      <mentions>
        <mention ids_tokens="6" string="it" id_sentence="2" />
      </mentions>
    </coreference>
    <coreference id="5" type="PROPER">
      <referenced ids_tokens="12-13-14" string="Clarence Thomas '" id_sentence="1" />
      <mentions>
        <mention ids_tokens="1" string="Thomas" id_sentence="2" />
        <mention ids_tokens="3" string="his" id_sentence="2" />
        <mention ids_tokens="1-13" string="Thomas , 43 , credits everything he has achieved to his grandparents ." id_sentence="4" />
        <mention ids_tokens="1" string="Thomas" id_sentence="4" />
        <mention ids_tokens="7" string="he" id_sentence="4" />
        <mention ids_tokens="11" string="his" id_sentence="4" />
        <mention ids_tokens="1" string="He" id_sentence="5" />
        <mention ids_tokens="10" string="he" id_sentence="5" />
        <mention ids_tokens="8" string="him" id_sentence="6" />
        <mention ids_tokens="12" string="himself" id_sentence="6" />
        <mention ids_tokens="3" string="his" id_sentence="7" />
        <mention ids_tokens="15" string="him" id_sentence="7" />
        <mention ids_tokens="2" string="I" id_sentence="8" />
        <mention ids_tokens="14" string="Thomas" id_sentence="8" />
        <mention ids_tokens="13" string="our" id_sentence="10" />
        <mention ids_tokens="23" string="he" id_sentence="10" />
        <mention ids_tokens="18" string="my" id_sentence="11" />
        <mention ids_tokens="8" string="Thomas" id_sentence="12" />
        <mention ids_tokens="18" string="him" id_sentence="12" />
        <mention ids_tokens="12" string="Thomas" id_sentence="13" />
        <mention ids_tokens="1-2" string="Clarence Thomas" id_sentence="14" />
        <mention ids_tokens="1" string="His" id_sentence="15" />
        <mention ids_tokens="2-3" string="Thomas'" id_sentence="16" />
        <mention ids_tokens="7" string="his" id_sentence="16" />
        <mention ids_tokens="1" string="His" id_sentence="17" />
        <mention ids_tokens="10" string="Thomas" id_sentence="18" />
        <mention ids_tokens="16" string="his" id_sentence="18" />
        <mention ids_tokens="1" string="His" id_sentence="19" />
        <mention ids_tokens="2" string="He" id_sentence="21" />
        <mention ids_tokens="17" string="Thomas" id_sentence="21" />
        <mention ids_tokens="3" string="he" id_sentence="22" />
        <mention ids_tokens="5-8" string="a tough old man" id_sentence="22" />
        <mention ids_tokens="2" string="He" id_sentence="23" />
        <mention ids_tokens="14" string="I" id_sentence="23" />
        <mention ids_tokens="16" string="my" id_sentence="23" />
        <mention ids_tokens="1" string="I" id_sentence="24" />
        <mention ids_tokens="19" string="Thomas" id_sentence="26" />
        <mention ids_tokens="1" string="His" id_sentence="27" />
        <mention ids_tokens="4" string="Thomas" id_sentence="28" />
        <mention ids_tokens="8" string="Thomas" id_sentence="34" />
        <mention ids_tokens="5" string="he" id_sentence="35" />
        <mention ids_tokens="17" string="himself" id_sentence="35" />
        <mention ids_tokens="2" string="his" id_sentence="36" />
        <mention ids_tokens="1" string="He" id_sentence="37" />
        <mention ids_tokens="3" string="his" id_sentence="37" />
        <mention ids_tokens="6" string="Thomas" id_sentence="38" />
        <mention ids_tokens="1-2" string="Thomas'" id_sentence="40" />
        <mention ids_tokens="1-5" string="Thomas , a former Democrat" id_sentence="42" />
        <mention ids_tokens="1" string="Thomas" id_sentence="42" />
        <mention ids_tokens="8" string="his" id_sentence="42" />
        <mention ids_tokens="15" string="Thomas" id_sentence="43" />
        <mention ids_tokens="1" string="His" id_sentence="44" />
        <mention ids_tokens="8" string="Thomas" id_sentence="45" />
        <mention ids_tokens="9" string="Thomas" id_sentence="46" />
        <mention ids_tokens="1" string="He" id_sentence="47" />
        <mention ids_tokens="5" string="Thomas" id_sentence="48" />
        <mention ids_tokens="9" string="Thomas" id_sentence="49" />
        <mention ids_tokens="1" string="He" id_sentence="50" />
        <mention ids_tokens="3" string="his" id_sentence="50" />
        <mention ids_tokens="1-7" string="Thomas , who lives in suburban Virginia" id_sentence="51" />
        <mention ids_tokens="1" string="Thomas" id_sentence="51" />
        <mention ids_tokens="3" string="my" id_sentence="52" />
        <mention ids_tokens="7" string="he" id_sentence="52" />
        <mention ids_tokens="10" string="his" id_sentence="52" />
      </mentions>
    </coreference>
    <coreference id="6" type="NOMINAL">
      <referenced ids_tokens="43-44" string="their father" id_sentence="1" />
      <mentions>
        <mention ids_tokens="7-8" string="his father" id_sentence="16" />
      </mentions>
    </coreference>
    <coreference id="7" type="PROPER">
      <referenced ids_tokens="7-8-9-10-11" string="the U.S. Court of Appeals" id_sentence="48" />
      <mentions>
        <mention ids_tokens="6-8" string="the appeals court" id_sentence="50" />
      </mentions>
    </coreference>
    <coreference id="8" type="LIST">
      <referenced ids_tokens="46-47-48-49" string="Thomas and his brother" id_sentence="1" />
      <mentions>
        <mention ids_tokens="1" string="Their" id_sentence="3" />
      </mentions>
    </coreference>
    <coreference id="10" type="NOMINAL">
      <referenced ids_tokens="53-54-55-56-57-58-59-60-61" string="strict Bible-believing grandparents who taught him to never say" id_sentence="1" />
      <mentions>
        <mention ids_tokens="11-12" string="his grandparents" id_sentence="4" />
        <mention ids_tokens="12" string="them" id_sentence="5" />
        <mention ids_tokens="6" string="they" id_sentence="6" />
        <mention ids_tokens="1" string="They" id_sentence="7" />
        <mention ids_tokens="18-19" string="my grandparents" id_sentence="11" />
        <mention ids_tokens="4" string="grandparents" id_sentence="18" />
        <mention ids_tokens="16-17" string="his grandparents" id_sentence="18" />
        <mention ids_tokens="16-17" string="my grandparents" id_sentence="23" />
        <mention ids_tokens="22" string="their" id_sentence="23" />
        <mention ids_tokens="4" string="they" id_sentence="24" />
        <mention ids_tokens="5" string="they" id_sentence="25" />
      </mentions>
    </coreference>
    <coreference id="11" type="PROPER">
      <referenced ids_tokens="21-22" string="Heritage Foundation" id_sentence="8" />
      <mentions>
        <mention ids_tokens="64" string="I" id_sentence="1" />
      </mentions>
    </coreference>
    <coreference id="17" type="PROPER">
      <referenced ids_tokens="13-14-15-16" string="the U.S. Supreme Court" id_sentence="12" />
      <mentions>
        <mention ids_tokens="21-23" string="the Supreme Court" id_sentence="48" />
        <mention ids_tokens="22-23" string="Supreme Court" id_sentence="48" />
      </mentions>
    </coreference>
    <coreference id="19" type="PROPER">
      <referenced ids_tokens="24-25-26" string="the Washington Post" id_sentence="21" />
      <mentions>
        <mention ids_tokens="3-4" string="Washington Post" id_sentence="13" />
      </mentions>
    </coreference>
    <coreference id="20" type="PROPER">
      <referenced ids_tokens="4" string="Leola" id_sentence="15" />
      <mentions>
        <mention ids_tokens="1-2" string="His mother" id_sentence="17" />
        <mention ids_tokens="6" string="her" id_sentence="17" />
        <mention ids_tokens="15" string="her" id_sentence="17" />
      </mentions>
    </coreference>
    <coreference id="23" type="NOMINAL">
      <referenced ids_tokens="1-2-3-4-5" string="His grandfather , Myers Anderson" id_sentence="19" />
      <mentions>
        <mention ids_tokens="5" string="him" id_sentence="20" />
        <mention ids_tokens="1-5" string="His grandfather , a Catholic" id_sentence="27" />
      </mentions>
    </coreference>
    <coreference id="26" type="NOMINAL">
      <referenced ids_tokens="3-4-5" string="a young man" id_sentence="29" />
      <mentions>
        <mention ids_tokens="4" string="he" id_sentence="30" />
        <mention ids_tokens="1" string="He" id_sentence="31" />
        <mention ids_tokens="5" string="him" id_sentence="32" />
        <mention ids_tokens="3" string="he" id_sentence="33" />
        <mention ids_tokens="9" string="his" id_sentence="33" />
      </mentions>
    </coreference>
    <coreference id="27" type="PROPER">
      <referenced ids_tokens="17" string="Mo" id_sentence="30" />
      <mentions>
        <mention ids_tokens="12" string="Missouri" id_sentence="38" />
      </mentions>
    </coreference>
    <coreference id="28" type="NOMINAL">
      <referenced ids_tokens="2-3-4" string="a young lawyer" id_sentence="38" />
      <mentions>
        <mention ids_tokens="1" string="He" id_sentence="39" />
      </mentions>
    </coreference>
    <coreference id="29" type="PROPER">
      <referenced ids_tokens="12-13-14-15-16-17" string="Missouri Attorney General John C. Danforth" id_sentence="38" />
      <mentions>
        <mention ids_tokens="4" string="Danforth" id_sentence="41" />
        <mention ids_tokens="6-8" string="a Republican senator" id_sentence="41" />
      </mentions>
    </coreference>
  </coreferences>
</document>
