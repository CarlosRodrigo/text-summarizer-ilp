<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="SJMN91-06255434">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>Virginia Thomas is a soft-spoken, hard-working daughter of the heartland.</content>
      <tokens>
        <token id="1" string="Virginia" lemma="Virginia" stem="virginia" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="soft-spoken" lemma="soft-spoken" stem="soft-spoken" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="hard-working" lemma="hard-working" stem="hard-work" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="daughter" lemma="daughter" stem="daughter" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="heartland" lemma="heartland" stem="heartland" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Virginia) (NNP Thomas)) (VP (VBZ is) (NP (NP (DT a) (JJ soft-spoken) (, ,) (JJ hard-working) (NN daughter)) (PP (IN of) (NP (DT the) (NN heartland))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the heartland" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="heartland" />
          </tokens>
        </chunking>
        <chunking id="2" string="is a soft-spoken , hard-working daughter of the heartland" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="a" />
            <token id="5" string="soft-spoken" />
            <token id="6" string="," />
            <token id="7" string="hard-working" />
            <token id="8" string="daughter" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="heartland" />
          </tokens>
        </chunking>
        <chunking id="3" string="Virginia Thomas" type="NP">
          <tokens>
            <token id="1" string="Virginia" />
            <token id="2" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="4" string="a soft-spoken , hard-working daughter" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="soft-spoken" />
            <token id="6" string="," />
            <token id="7" string="hard-working" />
            <token id="8" string="daughter" />
          </tokens>
        </chunking>
        <chunking id="5" string="a soft-spoken , hard-working daughter of the heartland" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="soft-spoken" />
            <token id="6" string="," />
            <token id="7" string="hard-working" />
            <token id="8" string="daughter" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="heartland" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Thomas</governor>
          <dependent id="1">Virginia</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">daughter</governor>
          <dependent id="2">Thomas</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">daughter</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">daughter</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">daughter</governor>
          <dependent id="5">soft-spoken</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">daughter</governor>
          <dependent id="7">hard-working</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">daughter</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">heartland</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">heartland</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">daughter</governor>
          <dependent id="11">heartland</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Virginia Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Virginia" />
            <token id="2" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="false">
      <content>A brainy Omaha, Neb., lawyer who has scaled the sheer cliffs of professional Washington.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="brainy" lemma="brainy" stem="braini" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Omaha" lemma="omaha" stem="omaha" pos="NN" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Neb." lemma="Neb." stem="neb." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="lawyer" lemma="lawyer" stem="lawyer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="scaled" lemma="scale" stem="scale" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="sheer" lemma="sheer" stem="sheer" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="cliffs" lemma="cliff" stem="cliff" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="professional" lemma="professional" stem="profession" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="Washington" lemma="Washington" stem="washington" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (DT A) (JJ brainy) (NN Omaha)) (, ,) (NP (NNP Neb.)) (, ,) (NP (NP (NN lawyer)) (SBAR (WHNP (WP who)) (S (VP (VBZ has) (VP (VBN scaled) (NP (NP (DT the) (JJ sheer) (NNS cliffs)) (PP (IN of) (NP (JJ professional) (NNP Washington))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="A brainy Omaha" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="brainy" />
            <token id="3" string="Omaha" />
          </tokens>
        </chunking>
        <chunking id="2" string="lawyer who has scaled the sheer cliffs of professional Washington" type="NP">
          <tokens>
            <token id="7" string="lawyer" />
            <token id="8" string="who" />
            <token id="9" string="has" />
            <token id="10" string="scaled" />
            <token id="11" string="the" />
            <token id="12" string="sheer" />
            <token id="13" string="cliffs" />
            <token id="14" string="of" />
            <token id="15" string="professional" />
            <token id="16" string="Washington" />
          </tokens>
        </chunking>
        <chunking id="3" string="who has scaled the sheer cliffs of professional Washington" type="SBAR">
          <tokens>
            <token id="8" string="who" />
            <token id="9" string="has" />
            <token id="10" string="scaled" />
            <token id="11" string="the" />
            <token id="12" string="sheer" />
            <token id="13" string="cliffs" />
            <token id="14" string="of" />
            <token id="15" string="professional" />
            <token id="16" string="Washington" />
          </tokens>
        </chunking>
        <chunking id="4" string="professional Washington" type="NP">
          <tokens>
            <token id="15" string="professional" />
            <token id="16" string="Washington" />
          </tokens>
        </chunking>
        <chunking id="5" string="Neb." type="NP">
          <tokens>
            <token id="5" string="Neb." />
          </tokens>
        </chunking>
        <chunking id="6" string="the sheer cliffs of professional Washington" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="sheer" />
            <token id="13" string="cliffs" />
            <token id="14" string="of" />
            <token id="15" string="professional" />
            <token id="16" string="Washington" />
          </tokens>
        </chunking>
        <chunking id="7" string="scaled the sheer cliffs of professional Washington" type="VP">
          <tokens>
            <token id="10" string="scaled" />
            <token id="11" string="the" />
            <token id="12" string="sheer" />
            <token id="13" string="cliffs" />
            <token id="14" string="of" />
            <token id="15" string="professional" />
            <token id="16" string="Washington" />
          </tokens>
        </chunking>
        <chunking id="8" string="the sheer cliffs" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="sheer" />
            <token id="13" string="cliffs" />
          </tokens>
        </chunking>
        <chunking id="9" string="lawyer" type="NP">
          <tokens>
            <token id="7" string="lawyer" />
          </tokens>
        </chunking>
        <chunking id="10" string="has scaled the sheer cliffs of professional Washington" type="VP">
          <tokens>
            <token id="9" string="has" />
            <token id="10" string="scaled" />
            <token id="11" string="the" />
            <token id="12" string="sheer" />
            <token id="13" string="cliffs" />
            <token id="14" string="of" />
            <token id="15" string="professional" />
            <token id="16" string="Washington" />
          </tokens>
        </chunking>
        <chunking id="11" string="A brainy Omaha , Neb. , lawyer who has scaled the sheer cliffs of professional Washington ." type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="brainy" />
            <token id="3" string="Omaha" />
            <token id="4" string="," />
            <token id="5" string="Neb." />
            <token id="6" string="," />
            <token id="7" string="lawyer" />
            <token id="8" string="who" />
            <token id="9" string="has" />
            <token id="10" string="scaled" />
            <token id="11" string="the" />
            <token id="12" string="sheer" />
            <token id="13" string="cliffs" />
            <token id="14" string="of" />
            <token id="15" string="professional" />
            <token id="16" string="Washington" />
            <token id="17" string="." />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">Omaha</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">Omaha</governor>
          <dependent id="2">brainy</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">Omaha</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="3">Omaha</governor>
          <dependent id="5">Neb.</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="3">Omaha</governor>
          <dependent id="7">lawyer</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">scaled</governor>
          <dependent id="8">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">scaled</governor>
          <dependent id="9">has</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="7">lawyer</governor>
          <dependent id="10">scaled</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">cliffs</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">cliffs</governor>
          <dependent id="12">sheer</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">scaled</governor>
          <dependent id="13">cliffs</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">Washington</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">Washington</governor>
          <dependent id="15">professional</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">cliffs</governor>
          <dependent id="16">Washington</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Washington" type="LOCATION" score="0.0">
          <tokens>
            <token id="16" string="Washington" />
          </tokens>
        </entity>
        <entity id="2" string="Neb." type="LOCATION" score="0.0">
          <tokens>
            <token id="5" string="Neb." />
          </tokens>
        </entity>
        <entity id="3" string="Omaha" type="LOCATION" score="0.0">
          <tokens>
            <token id="3" string="Omaha" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="false">
      <content>A churchgoer who invites homeless people out to lunch.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="churchgoer" lemma="churchgoer" stem="churchgoer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="invites" lemma="invite" stem="invit" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="homeless" lemma="homeless" stem="homeless" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="out" lemma="out" stem="out" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="lunch" lemma="lunch" stem="lunch" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (DT A) (NN churchgoer) (SBAR (WHNP (WP who)) (S (VP (VBZ invites) (NP (JJ homeless) (NNS people)) (ADVP (IN out) (PP (TO to) (NP (NN lunch))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="A churchgoer who invites homeless people out to lunch ." type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="churchgoer" />
            <token id="3" string="who" />
            <token id="4" string="invites" />
            <token id="5" string="homeless" />
            <token id="6" string="people" />
            <token id="7" string="out" />
            <token id="8" string="to" />
            <token id="9" string="lunch" />
            <token id="10" string="." />
          </tokens>
        </chunking>
        <chunking id="2" string="lunch" type="NP">
          <tokens>
            <token id="9" string="lunch" />
          </tokens>
        </chunking>
        <chunking id="3" string="homeless people" type="NP">
          <tokens>
            <token id="5" string="homeless" />
            <token id="6" string="people" />
          </tokens>
        </chunking>
        <chunking id="4" string="invites homeless people out to lunch" type="VP">
          <tokens>
            <token id="4" string="invites" />
            <token id="5" string="homeless" />
            <token id="6" string="people" />
            <token id="7" string="out" />
            <token id="8" string="to" />
            <token id="9" string="lunch" />
          </tokens>
        </chunking>
        <chunking id="5" string="who invites homeless people out to lunch" type="SBAR">
          <tokens>
            <token id="3" string="who" />
            <token id="4" string="invites" />
            <token id="5" string="homeless" />
            <token id="6" string="people" />
            <token id="7" string="out" />
            <token id="8" string="to" />
            <token id="9" string="lunch" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">churchgoer</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">churchgoer</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">invites</governor>
          <dependent id="3">who</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">churchgoer</governor>
          <dependent id="4">invites</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">people</governor>
          <dependent id="5">homeless</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">invites</governor>
          <dependent id="6">people</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">invites</governor>
          <dependent id="7">out</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">lunch</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">out</governor>
          <dependent id="9">lunch</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>A good friend.; Why the fuss over Mrs. Supreme Court Nominee?</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="good" lemma="good" stem="good" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="friend." lemma="friend." stem="friend." pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Why" lemma="why" stem="why" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="fuss" lemma="fuss" stem="fuss" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Mrs." lemma="Mrs." stem="mrs." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="Supreme" lemma="Supreme" stem="suprem" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="11" string="Court" lemma="Court" stem="court" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="12" string="Nominee" lemma="Nominee" stem="nomine" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="13" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (FRAG (NP (DT A) (JJ good) (NN friend.)) (: ;) (FRAG (WHADVP (WRB Why)) (PP (NP (DT the) (NN fuss)) (PP (IN over) (NP (NNP Mrs.) (NNP Supreme) (NNP Court) (NNP Nominee))))) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the fuss" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="fuss" />
          </tokens>
        </chunking>
        <chunking id="2" string="A good friend." type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="good" />
            <token id="3" string="friend." />
          </tokens>
        </chunking>
        <chunking id="3" string="Why" type="WHADVP">
          <tokens>
            <token id="5" string="Why" />
          </tokens>
        </chunking>
        <chunking id="4" string="Mrs. Supreme Court Nominee" type="NP">
          <tokens>
            <token id="9" string="Mrs." />
            <token id="10" string="Supreme" />
            <token id="11" string="Court" />
            <token id="12" string="Nominee" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">friend.</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">friend.</governor>
          <dependent id="2">good</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">friend.</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="3">friend.</governor>
          <dependent id="5">Why</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">fuss</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">Why</governor>
          <dependent id="7">fuss</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Nominee</governor>
          <dependent id="8">over</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Nominee</governor>
          <dependent id="9">Mrs.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Nominee</governor>
          <dependent id="10">Supreme</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Nominee</governor>
          <dependent id="11">Court</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">fuss</governor>
          <dependent id="12">Nominee</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Supreme Court Nominee" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="10" string="Supreme" />
            <token id="11" string="Court" />
            <token id="12" string="Nominee" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>Her critics see her as more than the supportive spouse who&amp;apost;ll accompany her husband, Clarence, through his Senate confirmation hearings, which began Tuesday and are likely to run through next week.</content>
      <tokens>
        <token id="1" string="Her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="2" string="critics" lemma="critic" stem="critic" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="see" lemma="see" stem="see" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="supportive" lemma="supportive" stem="support" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="spouse" lemma="spouse" stem="spous" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="'ll" lemma="will" stem="'ll" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="accompany" lemma="accompany" stem="accompani" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="husband" lemma="husband" stem="husband" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Clarence" lemma="Clarence" stem="clarenc" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="Senate" lemma="Senate" stem="senat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="22" string="confirmation" lemma="confirmation" stem="confirm" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="hearings" lemma="hearing" stem="hear" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="began" lemma="begin" stem="began" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="Tuesday" lemma="Tuesday" stem="tuesdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="28" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="likely" lemma="likely" stem="like" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="run" lemma="run" stem="run" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="next" lemma="next" stem="next" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="35" string="week" lemma="week" stem="week" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP$ Her) (NNS critics)) (VP (VBP see) (NP (PRP$ her)) (PP (IN as) (PP (JJR more) (IN than) (NP (NP (DT the) (ADJP (JJ supportive)) (NN spouse)) (SBAR (WHNP (WP who)) (S (VP (MD 'll) (VP (VB accompany) (NP (NP (PRP$ her) (NN husband)) (, ,) (NP (NNP Clarence)) (, ,)) (PP (IN through) (NP (NP (PRP$ his) (NNP Senate) (NN confirmation) (NNS hearings)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VP (VBD began) (NP-TMP (NNP Tuesday))) (CC and) (VP (VBP are) (ADJP (JJ likely) (S (VP (TO to) (VP (VB run) (PP (IN through) (NP (JJ next) (NN week))))))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="supportive" type="ADJP">
          <tokens>
            <token id="9" string="supportive" />
          </tokens>
        </chunking>
        <chunking id="2" string="are likely to run through next week" type="VP">
          <tokens>
            <token id="29" string="are" />
            <token id="30" string="likely" />
            <token id="31" string="to" />
            <token id="32" string="run" />
            <token id="33" string="through" />
            <token id="34" string="next" />
            <token id="35" string="week" />
          </tokens>
        </chunking>
        <chunking id="3" string="accompany her husband , Clarence , through his Senate confirmation hearings , which began Tuesday and are likely to run through next week" type="VP">
          <tokens>
            <token id="13" string="accompany" />
            <token id="14" string="her" />
            <token id="15" string="husband" />
            <token id="16" string="," />
            <token id="17" string="Clarence" />
            <token id="18" string="," />
            <token id="19" string="through" />
            <token id="20" string="his" />
            <token id="21" string="Senate" />
            <token id="22" string="confirmation" />
            <token id="23" string="hearings" />
            <token id="24" string="," />
            <token id="25" string="which" />
            <token id="26" string="began" />
            <token id="27" string="Tuesday" />
            <token id="28" string="and" />
            <token id="29" string="are" />
            <token id="30" string="likely" />
            <token id="31" string="to" />
            <token id="32" string="run" />
            <token id="33" string="through" />
            <token id="34" string="next" />
            <token id="35" string="week" />
          </tokens>
        </chunking>
        <chunking id="4" string="see her as more than the supportive spouse who 'll accompany her husband , Clarence , through his Senate confirmation hearings , which began Tuesday and are likely to run through next week" type="VP">
          <tokens>
            <token id="3" string="see" />
            <token id="4" string="her" />
            <token id="5" string="as" />
            <token id="6" string="more" />
            <token id="7" string="than" />
            <token id="8" string="the" />
            <token id="9" string="supportive" />
            <token id="10" string="spouse" />
            <token id="11" string="who" />
            <token id="12" string="'ll" />
            <token id="13" string="accompany" />
            <token id="14" string="her" />
            <token id="15" string="husband" />
            <token id="16" string="," />
            <token id="17" string="Clarence" />
            <token id="18" string="," />
            <token id="19" string="through" />
            <token id="20" string="his" />
            <token id="21" string="Senate" />
            <token id="22" string="confirmation" />
            <token id="23" string="hearings" />
            <token id="24" string="," />
            <token id="25" string="which" />
            <token id="26" string="began" />
            <token id="27" string="Tuesday" />
            <token id="28" string="and" />
            <token id="29" string="are" />
            <token id="30" string="likely" />
            <token id="31" string="to" />
            <token id="32" string="run" />
            <token id="33" string="through" />
            <token id="34" string="next" />
            <token id="35" string="week" />
          </tokens>
        </chunking>
        <chunking id="5" string="began Tuesday" type="VP">
          <tokens>
            <token id="26" string="began" />
            <token id="27" string="Tuesday" />
          </tokens>
        </chunking>
        <chunking id="6" string="likely to run through next week" type="ADJP">
          <tokens>
            <token id="30" string="likely" />
            <token id="31" string="to" />
            <token id="32" string="run" />
            <token id="33" string="through" />
            <token id="34" string="next" />
            <token id="35" string="week" />
          </tokens>
        </chunking>
        <chunking id="7" string="Her critics" type="NP">
          <tokens>
            <token id="1" string="Her" />
            <token id="2" string="critics" />
          </tokens>
        </chunking>
        <chunking id="8" string="who 'll accompany her husband , Clarence , through his Senate confirmation hearings , which began Tuesday and are likely to run through next week" type="SBAR">
          <tokens>
            <token id="11" string="who" />
            <token id="12" string="'ll" />
            <token id="13" string="accompany" />
            <token id="14" string="her" />
            <token id="15" string="husband" />
            <token id="16" string="," />
            <token id="17" string="Clarence" />
            <token id="18" string="," />
            <token id="19" string="through" />
            <token id="20" string="his" />
            <token id="21" string="Senate" />
            <token id="22" string="confirmation" />
            <token id="23" string="hearings" />
            <token id="24" string="," />
            <token id="25" string="which" />
            <token id="26" string="began" />
            <token id="27" string="Tuesday" />
            <token id="28" string="and" />
            <token id="29" string="are" />
            <token id="30" string="likely" />
            <token id="31" string="to" />
            <token id="32" string="run" />
            <token id="33" string="through" />
            <token id="34" string="next" />
            <token id="35" string="week" />
          </tokens>
        </chunking>
        <chunking id="9" string="his Senate confirmation hearings , which began Tuesday and are likely to run through next week" type="NP">
          <tokens>
            <token id="20" string="his" />
            <token id="21" string="Senate" />
            <token id="22" string="confirmation" />
            <token id="23" string="hearings" />
            <token id="24" string="," />
            <token id="25" string="which" />
            <token id="26" string="began" />
            <token id="27" string="Tuesday" />
            <token id="28" string="and" />
            <token id="29" string="are" />
            <token id="30" string="likely" />
            <token id="31" string="to" />
            <token id="32" string="run" />
            <token id="33" string="through" />
            <token id="34" string="next" />
            <token id="35" string="week" />
          </tokens>
        </chunking>
        <chunking id="10" string="'ll accompany her husband , Clarence , through his Senate confirmation hearings , which began Tuesday and are likely to run through next week" type="VP">
          <tokens>
            <token id="12" string="'ll" />
            <token id="13" string="accompany" />
            <token id="14" string="her" />
            <token id="15" string="husband" />
            <token id="16" string="," />
            <token id="17" string="Clarence" />
            <token id="18" string="," />
            <token id="19" string="through" />
            <token id="20" string="his" />
            <token id="21" string="Senate" />
            <token id="22" string="confirmation" />
            <token id="23" string="hearings" />
            <token id="24" string="," />
            <token id="25" string="which" />
            <token id="26" string="began" />
            <token id="27" string="Tuesday" />
            <token id="28" string="and" />
            <token id="29" string="are" />
            <token id="30" string="likely" />
            <token id="31" string="to" />
            <token id="32" string="run" />
            <token id="33" string="through" />
            <token id="34" string="next" />
            <token id="35" string="week" />
          </tokens>
        </chunking>
        <chunking id="11" string="the supportive spouse" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="supportive" />
            <token id="10" string="spouse" />
          </tokens>
        </chunking>
        <chunking id="12" string="Clarence" type="NP">
          <tokens>
            <token id="17" string="Clarence" />
          </tokens>
        </chunking>
        <chunking id="13" string="which began Tuesday and are likely to run through next week" type="SBAR">
          <tokens>
            <token id="25" string="which" />
            <token id="26" string="began" />
            <token id="27" string="Tuesday" />
            <token id="28" string="and" />
            <token id="29" string="are" />
            <token id="30" string="likely" />
            <token id="31" string="to" />
            <token id="32" string="run" />
            <token id="33" string="through" />
            <token id="34" string="next" />
            <token id="35" string="week" />
          </tokens>
        </chunking>
        <chunking id="14" string="his Senate confirmation hearings" type="NP">
          <tokens>
            <token id="20" string="his" />
            <token id="21" string="Senate" />
            <token id="22" string="confirmation" />
            <token id="23" string="hearings" />
          </tokens>
        </chunking>
        <chunking id="15" string="the supportive spouse who 'll accompany her husband , Clarence , through his Senate confirmation hearings , which began Tuesday and are likely to run through next week" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="supportive" />
            <token id="10" string="spouse" />
            <token id="11" string="who" />
            <token id="12" string="'ll" />
            <token id="13" string="accompany" />
            <token id="14" string="her" />
            <token id="15" string="husband" />
            <token id="16" string="," />
            <token id="17" string="Clarence" />
            <token id="18" string="," />
            <token id="19" string="through" />
            <token id="20" string="his" />
            <token id="21" string="Senate" />
            <token id="22" string="confirmation" />
            <token id="23" string="hearings" />
            <token id="24" string="," />
            <token id="25" string="which" />
            <token id="26" string="began" />
            <token id="27" string="Tuesday" />
            <token id="28" string="and" />
            <token id="29" string="are" />
            <token id="30" string="likely" />
            <token id="31" string="to" />
            <token id="32" string="run" />
            <token id="33" string="through" />
            <token id="34" string="next" />
            <token id="35" string="week" />
          </tokens>
        </chunking>
        <chunking id="16" string="began Tuesday and are likely to run through next week" type="VP">
          <tokens>
            <token id="26" string="began" />
            <token id="27" string="Tuesday" />
            <token id="28" string="and" />
            <token id="29" string="are" />
            <token id="30" string="likely" />
            <token id="31" string="to" />
            <token id="32" string="run" />
            <token id="33" string="through" />
            <token id="34" string="next" />
            <token id="35" string="week" />
          </tokens>
        </chunking>
        <chunking id="17" string="her" type="NP">
          <tokens>
            <token id="4" string="her" />
          </tokens>
        </chunking>
        <chunking id="18" string="her husband , Clarence ," type="NP">
          <tokens>
            <token id="14" string="her" />
            <token id="15" string="husband" />
            <token id="16" string="," />
            <token id="17" string="Clarence" />
            <token id="18" string="," />
          </tokens>
        </chunking>
        <chunking id="19" string="next week" type="NP">
          <tokens>
            <token id="34" string="next" />
            <token id="35" string="week" />
          </tokens>
        </chunking>
        <chunking id="20" string="run through next week" type="VP">
          <tokens>
            <token id="32" string="run" />
            <token id="33" string="through" />
            <token id="34" string="next" />
            <token id="35" string="week" />
          </tokens>
        </chunking>
        <chunking id="21" string="to run through next week" type="VP">
          <tokens>
            <token id="31" string="to" />
            <token id="32" string="run" />
            <token id="33" string="through" />
            <token id="34" string="next" />
            <token id="35" string="week" />
          </tokens>
        </chunking>
        <chunking id="22" string="her husband" type="NP">
          <tokens>
            <token id="14" string="her" />
            <token id="15" string="husband" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="2">critics</governor>
          <dependent id="1">Her</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">see</governor>
          <dependent id="2">critics</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">see</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">see</governor>
          <dependent id="4">her</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">spouse</governor>
          <dependent id="5">as</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="10">spouse</governor>
          <dependent id="6">more</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">spouse</governor>
          <dependent id="7">than</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">spouse</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">spouse</governor>
          <dependent id="9">supportive</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">see</governor>
          <dependent id="10">spouse</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">accompany</governor>
          <dependent id="11">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">accompany</governor>
          <dependent id="12">'ll</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="10">spouse</governor>
          <dependent id="13">accompany</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">husband</governor>
          <dependent id="14">her</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">accompany</governor>
          <dependent id="15">husband</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="15">husband</governor>
          <dependent id="17">Clarence</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">hearings</governor>
          <dependent id="19">through</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="23">hearings</governor>
          <dependent id="20">his</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">hearings</governor>
          <dependent id="21">Senate</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">hearings</governor>
          <dependent id="22">confirmation</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">accompany</governor>
          <dependent id="23">hearings</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">began</governor>
          <dependent id="25">which</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="23">hearings</governor>
          <dependent id="26">began</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="26">began</governor>
          <dependent id="27">Tuesday</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="26">began</governor>
          <dependent id="28">and</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="30">likely</governor>
          <dependent id="29">are</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="26">began</governor>
          <dependent id="30">likely</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="32">run</governor>
          <dependent id="31">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="30">likely</governor>
          <dependent id="32">run</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">week</governor>
          <dependent id="33">through</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="35">week</governor>
          <dependent id="34">next</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">run</governor>
          <dependent id="35">week</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Senate" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="21" string="Senate" />
          </tokens>
        </entity>
        <entity id="2" string="next week" type="DATE" score="0.0">
          <tokens>
            <token id="34" string="next" />
            <token id="35" string="week" />
          </tokens>
        </entity>
        <entity id="3" string="Tuesday" type="DATE" score="0.0">
          <tokens>
            <token id="27" string="Tuesday" />
          </tokens>
        </entity>
        <entity id="4" string="Clarence" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="Clarence" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>They see a woman with strong opinions on issues that are bound to come before the court.</content>
      <tokens>
        <token id="1" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="see" lemma="see" stem="see" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="woman" lemma="woman" stem="woman" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="strong" lemma="strong" stem="strong" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="opinions" lemma="opinion" stem="opinion" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="issues" lemma="issue" stem="issu" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="bound" lemma="bind" stem="bound" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="come" lemma="come" stem="come" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="court" lemma="court" stem="court" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP They)) (VP (VBP see) (NP (NP (DT a) (NN woman)) (PP (IN with) (NP (JJ strong) (NNS opinions)))) (PP (IN on) (NP (NP (NNS issues)) (SBAR (WHNP (WDT that)) (S (VP (VBP are) (ADJP (VBN bound) (S (VP (TO to) (VP (VB come) (PP (IN before) (NP (DT the) (NN court))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="1" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="come before the court" type="VP">
          <tokens>
            <token id="14" string="come" />
            <token id="15" string="before" />
            <token id="16" string="the" />
            <token id="17" string="court" />
          </tokens>
        </chunking>
        <chunking id="3" string="that are bound to come before the court" type="SBAR">
          <tokens>
            <token id="10" string="that" />
            <token id="11" string="are" />
            <token id="12" string="bound" />
            <token id="13" string="to" />
            <token id="14" string="come" />
            <token id="15" string="before" />
            <token id="16" string="the" />
            <token id="17" string="court" />
          </tokens>
        </chunking>
        <chunking id="4" string="issues that are bound to come before the court" type="NP">
          <tokens>
            <token id="9" string="issues" />
            <token id="10" string="that" />
            <token id="11" string="are" />
            <token id="12" string="bound" />
            <token id="13" string="to" />
            <token id="14" string="come" />
            <token id="15" string="before" />
            <token id="16" string="the" />
            <token id="17" string="court" />
          </tokens>
        </chunking>
        <chunking id="5" string="strong opinions" type="NP">
          <tokens>
            <token id="6" string="strong" />
            <token id="7" string="opinions" />
          </tokens>
        </chunking>
        <chunking id="6" string="issues" type="NP">
          <tokens>
            <token id="9" string="issues" />
          </tokens>
        </chunking>
        <chunking id="7" string="the court" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="court" />
          </tokens>
        </chunking>
        <chunking id="8" string="see a woman with strong opinions on issues that are bound to come before the court" type="VP">
          <tokens>
            <token id="2" string="see" />
            <token id="3" string="a" />
            <token id="4" string="woman" />
            <token id="5" string="with" />
            <token id="6" string="strong" />
            <token id="7" string="opinions" />
            <token id="8" string="on" />
            <token id="9" string="issues" />
            <token id="10" string="that" />
            <token id="11" string="are" />
            <token id="12" string="bound" />
            <token id="13" string="to" />
            <token id="14" string="come" />
            <token id="15" string="before" />
            <token id="16" string="the" />
            <token id="17" string="court" />
          </tokens>
        </chunking>
        <chunking id="9" string="are bound to come before the court" type="VP">
          <tokens>
            <token id="11" string="are" />
            <token id="12" string="bound" />
            <token id="13" string="to" />
            <token id="14" string="come" />
            <token id="15" string="before" />
            <token id="16" string="the" />
            <token id="17" string="court" />
          </tokens>
        </chunking>
        <chunking id="10" string="to come before the court" type="VP">
          <tokens>
            <token id="13" string="to" />
            <token id="14" string="come" />
            <token id="15" string="before" />
            <token id="16" string="the" />
            <token id="17" string="court" />
          </tokens>
        </chunking>
        <chunking id="11" string="a woman" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="woman" />
          </tokens>
        </chunking>
        <chunking id="12" string="bound to come before the court" type="ADJP">
          <tokens>
            <token id="12" string="bound" />
            <token id="13" string="to" />
            <token id="14" string="come" />
            <token id="15" string="before" />
            <token id="16" string="the" />
            <token id="17" string="court" />
          </tokens>
        </chunking>
        <chunking id="13" string="a woman with strong opinions" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="woman" />
            <token id="5" string="with" />
            <token id="6" string="strong" />
            <token id="7" string="opinions" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">see</governor>
          <dependent id="1">They</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">see</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">woman</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">see</governor>
          <dependent id="4">woman</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">opinions</governor>
          <dependent id="5">with</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">opinions</governor>
          <dependent id="6">strong</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">woman</governor>
          <dependent id="7">opinions</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">issues</governor>
          <dependent id="8">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">see</governor>
          <dependent id="9">issues</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="12">bound</governor>
          <dependent id="10">that</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="12">bound</governor>
          <dependent id="11">are</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="9">issues</governor>
          <dependent id="12">bound</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">come</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="12">bound</governor>
          <dependent id="14">come</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">court</governor>
          <dependent id="15">before</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">court</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">come</governor>
          <dependent id="17">court</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>Some women&amp;apost;s-rights activists are upset by her lobbying against such issues as comparable-worth legislation.</content>
      <tokens>
        <token id="1" string="Some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="women" lemma="woman" stem="women" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="-" lemma="-" stem="-" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="rights" lemma="rights" stem="right" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="activists" lemma="activist" stem="activist" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="upset" lemma="upset" stem="upset" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="lobbying" lemma="lobbying" stem="lobbi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="issues" lemma="issue" stem="issu" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="comparable-worth" lemma="comparable-worth" stem="comparable-worth" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="legislation" lemma="legislation" stem="legisl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (DT Some) (NP (NNS women) (POS 's))) (: -) (NP (NP (NNS rights)) (SBAR (S (NP (NNS activists)) (VP (VBP are) (VP (VBN upset) (PP (IN by) (NP (NP (PRP$ her) (NN lobbying)) (PP (IN against) (NP (JJ such) (NNS issues))))) (PP (IN as) (NP (JJ comparable-worth) (NN legislation)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="her lobbying" type="NP">
          <tokens>
            <token id="10" string="her" />
            <token id="11" string="lobbying" />
          </tokens>
        </chunking>
        <chunking id="2" string="Some women 's - rights activists are upset by her lobbying against such issues as comparable-worth legislation ." type="NP">
          <tokens>
            <token id="1" string="Some" />
            <token id="2" string="women" />
            <token id="3" string="'s" />
            <token id="4" string="-" />
            <token id="5" string="rights" />
            <token id="6" string="activists" />
            <token id="7" string="are" />
            <token id="8" string="upset" />
            <token id="9" string="by" />
            <token id="10" string="her" />
            <token id="11" string="lobbying" />
            <token id="12" string="against" />
            <token id="13" string="such" />
            <token id="14" string="issues" />
            <token id="15" string="as" />
            <token id="16" string="comparable-worth" />
            <token id="17" string="legislation" />
            <token id="18" string="." />
          </tokens>
        </chunking>
        <chunking id="3" string="upset by her lobbying against such issues as comparable-worth legislation" type="VP">
          <tokens>
            <token id="8" string="upset" />
            <token id="9" string="by" />
            <token id="10" string="her" />
            <token id="11" string="lobbying" />
            <token id="12" string="against" />
            <token id="13" string="such" />
            <token id="14" string="issues" />
            <token id="15" string="as" />
            <token id="16" string="comparable-worth" />
            <token id="17" string="legislation" />
          </tokens>
        </chunking>
        <chunking id="4" string="activists are upset by her lobbying against such issues as comparable-worth legislation" type="SBAR">
          <tokens>
            <token id="6" string="activists" />
            <token id="7" string="are" />
            <token id="8" string="upset" />
            <token id="9" string="by" />
            <token id="10" string="her" />
            <token id="11" string="lobbying" />
            <token id="12" string="against" />
            <token id="13" string="such" />
            <token id="14" string="issues" />
            <token id="15" string="as" />
            <token id="16" string="comparable-worth" />
            <token id="17" string="legislation" />
          </tokens>
        </chunking>
        <chunking id="5" string="are upset by her lobbying against such issues as comparable-worth legislation" type="VP">
          <tokens>
            <token id="7" string="are" />
            <token id="8" string="upset" />
            <token id="9" string="by" />
            <token id="10" string="her" />
            <token id="11" string="lobbying" />
            <token id="12" string="against" />
            <token id="13" string="such" />
            <token id="14" string="issues" />
            <token id="15" string="as" />
            <token id="16" string="comparable-worth" />
            <token id="17" string="legislation" />
          </tokens>
        </chunking>
        <chunking id="6" string="women 's" type="NP">
          <tokens>
            <token id="2" string="women" />
            <token id="3" string="'s" />
          </tokens>
        </chunking>
        <chunking id="7" string="rights activists are upset by her lobbying against such issues as comparable-worth legislation" type="NP">
          <tokens>
            <token id="5" string="rights" />
            <token id="6" string="activists" />
            <token id="7" string="are" />
            <token id="8" string="upset" />
            <token id="9" string="by" />
            <token id="10" string="her" />
            <token id="11" string="lobbying" />
            <token id="12" string="against" />
            <token id="13" string="such" />
            <token id="14" string="issues" />
            <token id="15" string="as" />
            <token id="16" string="comparable-worth" />
            <token id="17" string="legislation" />
          </tokens>
        </chunking>
        <chunking id="8" string="such issues" type="NP">
          <tokens>
            <token id="13" string="such" />
            <token id="14" string="issues" />
          </tokens>
        </chunking>
        <chunking id="9" string="Some women 's" type="NP">
          <tokens>
            <token id="1" string="Some" />
            <token id="2" string="women" />
            <token id="3" string="'s" />
          </tokens>
        </chunking>
        <chunking id="10" string="comparable-worth legislation" type="NP">
          <tokens>
            <token id="16" string="comparable-worth" />
            <token id="17" string="legislation" />
          </tokens>
        </chunking>
        <chunking id="11" string="activists" type="NP">
          <tokens>
            <token id="6" string="activists" />
          </tokens>
        </chunking>
        <chunking id="12" string="rights" type="NP">
          <tokens>
            <token id="5" string="rights" />
          </tokens>
        </chunking>
        <chunking id="13" string="her lobbying against such issues" type="NP">
          <tokens>
            <token id="10" string="her" />
            <token id="11" string="lobbying" />
            <token id="12" string="against" />
            <token id="13" string="such" />
            <token id="14" string="issues" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">women</governor>
          <dependent id="1">Some</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">women</dependent>
        </dependency>
        <dependency type="case">
          <governor id="2">women</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="2">women</governor>
          <dependent id="5">rights</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="8">upset</governor>
          <dependent id="6">activists</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="8">upset</governor>
          <dependent id="7">are</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="5">rights</governor>
          <dependent id="8">upset</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">lobbying</governor>
          <dependent id="9">by</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">lobbying</governor>
          <dependent id="10">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">upset</governor>
          <dependent id="11">lobbying</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">issues</governor>
          <dependent id="12">against</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">issues</governor>
          <dependent id="13">such</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">lobbying</governor>
          <dependent id="14">issues</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">legislation</governor>
          <dependent id="15">as</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">legislation</governor>
          <dependent id="16">comparable-worth</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">upset</governor>
          <dependent id="17">legislation</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>Some religious rights groups are troubled by her anti-cult activities in light of her former involvement with Lifespring, a motivational group.</content>
      <tokens>
        <token id="1" string="Some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="religious" lemma="religious" stem="religi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="rights" lemma="rights" stem="right" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="groups" lemma="group" stem="group" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="troubled" lemma="trouble" stem="troubl" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="anti-cult" lemma="anti-cult" stem="anti-cult" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="activities" lemma="activity" stem="activ" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="light" lemma="light" stem="light" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="15" string="former" lemma="former" stem="former" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="involvement" lemma="involvement" stem="involv" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Lifespring" lemma="lifespring" stem="lifespr" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="motivational" lemma="motivational" stem="motiv" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="group" lemma="group" stem="group" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT Some) (JJ religious) (NNS rights) (NNS groups)) (VP (VBP are) (VP (VBN troubled) (PP (IN by) (NP (PRP$ her) (JJ anti-cult) (NNS activities))) (PP (IN in) (NP (NP (NN light)) (PP (IN of) (NP (PRP$ her) (JJ former) (NN involvement))))) (PP (IN with) (NP (NP (NN Lifespring)) (, ,) (NP (DT a) (JJ motivational) (NN group)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Lifespring" type="NP">
          <tokens>
            <token id="18" string="Lifespring" />
          </tokens>
        </chunking>
        <chunking id="2" string="her anti-cult activities" type="NP">
          <tokens>
            <token id="8" string="her" />
            <token id="9" string="anti-cult" />
            <token id="10" string="activities" />
          </tokens>
        </chunking>
        <chunking id="3" string="troubled by her anti-cult activities in light of her former involvement with Lifespring , a motivational group" type="VP">
          <tokens>
            <token id="6" string="troubled" />
            <token id="7" string="by" />
            <token id="8" string="her" />
            <token id="9" string="anti-cult" />
            <token id="10" string="activities" />
            <token id="11" string="in" />
            <token id="12" string="light" />
            <token id="13" string="of" />
            <token id="14" string="her" />
            <token id="15" string="former" />
            <token id="16" string="involvement" />
            <token id="17" string="with" />
            <token id="18" string="Lifespring" />
            <token id="19" string="," />
            <token id="20" string="a" />
            <token id="21" string="motivational" />
            <token id="22" string="group" />
          </tokens>
        </chunking>
        <chunking id="4" string="Lifespring , a motivational group" type="NP">
          <tokens>
            <token id="18" string="Lifespring" />
            <token id="19" string="," />
            <token id="20" string="a" />
            <token id="21" string="motivational" />
            <token id="22" string="group" />
          </tokens>
        </chunking>
        <chunking id="5" string="light" type="NP">
          <tokens>
            <token id="12" string="light" />
          </tokens>
        </chunking>
        <chunking id="6" string="are troubled by her anti-cult activities in light of her former involvement with Lifespring , a motivational group" type="VP">
          <tokens>
            <token id="5" string="are" />
            <token id="6" string="troubled" />
            <token id="7" string="by" />
            <token id="8" string="her" />
            <token id="9" string="anti-cult" />
            <token id="10" string="activities" />
            <token id="11" string="in" />
            <token id="12" string="light" />
            <token id="13" string="of" />
            <token id="14" string="her" />
            <token id="15" string="former" />
            <token id="16" string="involvement" />
            <token id="17" string="with" />
            <token id="18" string="Lifespring" />
            <token id="19" string="," />
            <token id="20" string="a" />
            <token id="21" string="motivational" />
            <token id="22" string="group" />
          </tokens>
        </chunking>
        <chunking id="7" string="Some religious rights groups" type="NP">
          <tokens>
            <token id="1" string="Some" />
            <token id="2" string="religious" />
            <token id="3" string="rights" />
            <token id="4" string="groups" />
          </tokens>
        </chunking>
        <chunking id="8" string="a motivational group" type="NP">
          <tokens>
            <token id="20" string="a" />
            <token id="21" string="motivational" />
            <token id="22" string="group" />
          </tokens>
        </chunking>
        <chunking id="9" string="light of her former involvement" type="NP">
          <tokens>
            <token id="12" string="light" />
            <token id="13" string="of" />
            <token id="14" string="her" />
            <token id="15" string="former" />
            <token id="16" string="involvement" />
          </tokens>
        </chunking>
        <chunking id="10" string="her former involvement" type="NP">
          <tokens>
            <token id="14" string="her" />
            <token id="15" string="former" />
            <token id="16" string="involvement" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">groups</governor>
          <dependent id="1">Some</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">groups</governor>
          <dependent id="2">religious</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">groups</governor>
          <dependent id="3">rights</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="6">troubled</governor>
          <dependent id="4">groups</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">troubled</governor>
          <dependent id="5">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">troubled</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">activities</governor>
          <dependent id="7">by</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">activities</governor>
          <dependent id="8">her</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">activities</governor>
          <dependent id="9">anti-cult</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">troubled</governor>
          <dependent id="10">activities</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">light</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">troubled</governor>
          <dependent id="12">light</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">involvement</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">involvement</governor>
          <dependent id="14">her</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">involvement</governor>
          <dependent id="15">former</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">light</governor>
          <dependent id="16">involvement</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Lifespring</governor>
          <dependent id="17">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">troubled</governor>
          <dependent id="18">Lifespring</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">group</governor>
          <dependent id="20">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">group</governor>
          <dependent id="21">motivational</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="18">Lifespring</governor>
          <dependent id="22">group</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>Skin color an issue; Even the color of her skin is being used to determine the content of Clarence Thomas&amp;apost;s character.</content>
      <tokens>
        <token id="1" string="Skin" lemma="skin" stem="skin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="color" lemma="color" stem="color" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="issue" lemma="issue" stem="issu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="color" lemma="color" stem="color" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="skin" lemma="skin" stem="skin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="being" lemma="be" stem="be" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="used" lemma="use" stem="us" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="determine" lemma="determine" stem="determin" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="content" lemma="content" stem="content" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Clarence" lemma="Clarence" stem="clarenc" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="21" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="22" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="character" lemma="character" stem="charact" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NP (NN Skin) (NN color)) (NP (DT an) (NN issue))) (: ;) (NP (NP (RB Even) (DT the) (NN color)) (PP (IN of) (NP (PRP$ her) (NN skin))))) (VP (VBZ is) (VP (VBG being) (VP (VBN used) (S (VP (TO to) (VP (VB determine) (NP (NP (DT the) (NN content)) (PP (IN of) (NP (NP (NNP Clarence) (NNP Thomas) (POS 's)) (NN character)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Even the color" type="NP">
          <tokens>
            <token id="6" string="Even" />
            <token id="7" string="the" />
            <token id="8" string="color" />
          </tokens>
        </chunking>
        <chunking id="2" string="Clarence Thomas 's" type="NP">
          <tokens>
            <token id="20" string="Clarence" />
            <token id="21" string="Thomas" />
            <token id="22" string="'s" />
          </tokens>
        </chunking>
        <chunking id="3" string="used to determine the content of Clarence Thomas 's character" type="VP">
          <tokens>
            <token id="14" string="used" />
            <token id="15" string="to" />
            <token id="16" string="determine" />
            <token id="17" string="the" />
            <token id="18" string="content" />
            <token id="19" string="of" />
            <token id="20" string="Clarence" />
            <token id="21" string="Thomas" />
            <token id="22" string="'s" />
            <token id="23" string="character" />
          </tokens>
        </chunking>
        <chunking id="4" string="Skin color" type="NP">
          <tokens>
            <token id="1" string="Skin" />
            <token id="2" string="color" />
          </tokens>
        </chunking>
        <chunking id="5" string="determine the content of Clarence Thomas 's character" type="VP">
          <tokens>
            <token id="16" string="determine" />
            <token id="17" string="the" />
            <token id="18" string="content" />
            <token id="19" string="of" />
            <token id="20" string="Clarence" />
            <token id="21" string="Thomas" />
            <token id="22" string="'s" />
            <token id="23" string="character" />
          </tokens>
        </chunking>
        <chunking id="6" string="Skin color an issue ; Even the color of her skin" type="NP">
          <tokens>
            <token id="1" string="Skin" />
            <token id="2" string="color" />
            <token id="3" string="an" />
            <token id="4" string="issue" />
            <token id="5" string=";" />
            <token id="6" string="Even" />
            <token id="7" string="the" />
            <token id="8" string="color" />
            <token id="9" string="of" />
            <token id="10" string="her" />
            <token id="11" string="skin" />
          </tokens>
        </chunking>
        <chunking id="7" string="being used to determine the content of Clarence Thomas 's character" type="VP">
          <tokens>
            <token id="13" string="being" />
            <token id="14" string="used" />
            <token id="15" string="to" />
            <token id="16" string="determine" />
            <token id="17" string="the" />
            <token id="18" string="content" />
            <token id="19" string="of" />
            <token id="20" string="Clarence" />
            <token id="21" string="Thomas" />
            <token id="22" string="'s" />
            <token id="23" string="character" />
          </tokens>
        </chunking>
        <chunking id="8" string="Skin color an issue" type="NP">
          <tokens>
            <token id="1" string="Skin" />
            <token id="2" string="color" />
            <token id="3" string="an" />
            <token id="4" string="issue" />
          </tokens>
        </chunking>
        <chunking id="9" string="Clarence Thomas 's character" type="NP">
          <tokens>
            <token id="20" string="Clarence" />
            <token id="21" string="Thomas" />
            <token id="22" string="'s" />
            <token id="23" string="character" />
          </tokens>
        </chunking>
        <chunking id="10" string="her skin" type="NP">
          <tokens>
            <token id="10" string="her" />
            <token id="11" string="skin" />
          </tokens>
        </chunking>
        <chunking id="11" string="to determine the content of Clarence Thomas 's character" type="VP">
          <tokens>
            <token id="15" string="to" />
            <token id="16" string="determine" />
            <token id="17" string="the" />
            <token id="18" string="content" />
            <token id="19" string="of" />
            <token id="20" string="Clarence" />
            <token id="21" string="Thomas" />
            <token id="22" string="'s" />
            <token id="23" string="character" />
          </tokens>
        </chunking>
        <chunking id="12" string="the content" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="content" />
          </tokens>
        </chunking>
        <chunking id="13" string="Even the color of her skin" type="NP">
          <tokens>
            <token id="6" string="Even" />
            <token id="7" string="the" />
            <token id="8" string="color" />
            <token id="9" string="of" />
            <token id="10" string="her" />
            <token id="11" string="skin" />
          </tokens>
        </chunking>
        <chunking id="14" string="an issue" type="NP">
          <tokens>
            <token id="3" string="an" />
            <token id="4" string="issue" />
          </tokens>
        </chunking>
        <chunking id="15" string="is being used to determine the content of Clarence Thomas 's character" type="VP">
          <tokens>
            <token id="12" string="is" />
            <token id="13" string="being" />
            <token id="14" string="used" />
            <token id="15" string="to" />
            <token id="16" string="determine" />
            <token id="17" string="the" />
            <token id="18" string="content" />
            <token id="19" string="of" />
            <token id="20" string="Clarence" />
            <token id="21" string="Thomas" />
            <token id="22" string="'s" />
            <token id="23" string="character" />
          </tokens>
        </chunking>
        <chunking id="16" string="the content of Clarence Thomas 's character" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="content" />
            <token id="19" string="of" />
            <token id="20" string="Clarence" />
            <token id="21" string="Thomas" />
            <token id="22" string="'s" />
            <token id="23" string="character" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">color</governor>
          <dependent id="1">Skin</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="14">used</governor>
          <dependent id="2">color</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">issue</governor>
          <dependent id="3">an</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="2">color</governor>
          <dependent id="4">issue</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">color</governor>
          <dependent id="6">Even</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">color</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="2">color</governor>
          <dependent id="8">color</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">skin</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">skin</governor>
          <dependent id="10">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">color</governor>
          <dependent id="11">skin</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">used</governor>
          <dependent id="12">is</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="14">used</governor>
          <dependent id="13">being</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">used</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">determine</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="14">used</governor>
          <dependent id="16">determine</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">content</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">determine</governor>
          <dependent id="18">content</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">character</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">Thomas</governor>
          <dependent id="20">Clarence</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="23">character</governor>
          <dependent id="21">Thomas</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">Thomas</governor>
          <dependent id="22">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">content</governor>
          <dependent id="23">character</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Clarence Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="Clarence" />
            <token id="21" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>The fact that she is white has drawn criticism from some blacks who see the marriage as evidence that Clarence Thomas has rejected his roots.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="fact" lemma="fact" stem="fact" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="white" lemma="white" stem="white" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="drawn" lemma="draw" stem="drawn" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="criticism" lemma="criticism" stem="critic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="blacks" lemma="black" stem="black" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="see" lemma="see" stem="see" pos="VBP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="marriage" lemma="marriage" stem="marriag" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="evidence" lemma="evidence" stem="evid" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="Clarence" lemma="Clarence" stem="clarenc" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="21" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="22" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="rejected" lemma="reject" stem="reject" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="25" string="roots" lemma="root" stem="root" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NN fact)) (SBAR (IN that) (S (NP (PRP she)) (VP (VBZ is) (ADJP (JJ white)))))) (VP (VBZ has) (VP (VBN drawn) (NP (NN criticism)) (PP (IN from) (NP (NP (DT some) (NNS blacks)) (SBAR (WHNP (WP who)) (S (VP (VBP see) (NP (DT the) (NN marriage)) (PP (IN as) (NP (NN evidence))) (SBAR (IN that) (S (NP (NNP Clarence) (NNP Thomas)) (VP (VBZ has) (VP (VBN rejected) (NP (PRP$ his) (NNS roots))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that Clarence Thomas has rejected his roots" type="SBAR">
          <tokens>
            <token id="19" string="that" />
            <token id="20" string="Clarence" />
            <token id="21" string="Thomas" />
            <token id="22" string="has" />
            <token id="23" string="rejected" />
            <token id="24" string="his" />
            <token id="25" string="roots" />
          </tokens>
        </chunking>
        <chunking id="2" string="evidence" type="NP">
          <tokens>
            <token id="18" string="evidence" />
          </tokens>
        </chunking>
        <chunking id="3" string="has rejected his roots" type="VP">
          <tokens>
            <token id="22" string="has" />
            <token id="23" string="rejected" />
            <token id="24" string="his" />
            <token id="25" string="roots" />
          </tokens>
        </chunking>
        <chunking id="4" string="that she is white" type="SBAR">
          <tokens>
            <token id="3" string="that" />
            <token id="4" string="she" />
            <token id="5" string="is" />
            <token id="6" string="white" />
          </tokens>
        </chunking>
        <chunking id="5" string="his roots" type="NP">
          <tokens>
            <token id="24" string="his" />
            <token id="25" string="roots" />
          </tokens>
        </chunking>
        <chunking id="6" string="The fact that she is white" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="fact" />
            <token id="3" string="that" />
            <token id="4" string="she" />
            <token id="5" string="is" />
            <token id="6" string="white" />
          </tokens>
        </chunking>
        <chunking id="7" string="has drawn criticism from some blacks who see the marriage as evidence that Clarence Thomas has rejected his roots" type="VP">
          <tokens>
            <token id="7" string="has" />
            <token id="8" string="drawn" />
            <token id="9" string="criticism" />
            <token id="10" string="from" />
            <token id="11" string="some" />
            <token id="12" string="blacks" />
            <token id="13" string="who" />
            <token id="14" string="see" />
            <token id="15" string="the" />
            <token id="16" string="marriage" />
            <token id="17" string="as" />
            <token id="18" string="evidence" />
            <token id="19" string="that" />
            <token id="20" string="Clarence" />
            <token id="21" string="Thomas" />
            <token id="22" string="has" />
            <token id="23" string="rejected" />
            <token id="24" string="his" />
            <token id="25" string="roots" />
          </tokens>
        </chunking>
        <chunking id="8" string="The fact" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="fact" />
          </tokens>
        </chunking>
        <chunking id="9" string="who see the marriage as evidence that Clarence Thomas has rejected his roots" type="SBAR">
          <tokens>
            <token id="13" string="who" />
            <token id="14" string="see" />
            <token id="15" string="the" />
            <token id="16" string="marriage" />
            <token id="17" string="as" />
            <token id="18" string="evidence" />
            <token id="19" string="that" />
            <token id="20" string="Clarence" />
            <token id="21" string="Thomas" />
            <token id="22" string="has" />
            <token id="23" string="rejected" />
            <token id="24" string="his" />
            <token id="25" string="roots" />
          </tokens>
        </chunking>
        <chunking id="10" string="she" type="NP">
          <tokens>
            <token id="4" string="she" />
          </tokens>
        </chunking>
        <chunking id="11" string="some blacks" type="NP">
          <tokens>
            <token id="11" string="some" />
            <token id="12" string="blacks" />
          </tokens>
        </chunking>
        <chunking id="12" string="is white" type="VP">
          <tokens>
            <token id="5" string="is" />
            <token id="6" string="white" />
          </tokens>
        </chunking>
        <chunking id="13" string="the marriage" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="marriage" />
          </tokens>
        </chunking>
        <chunking id="14" string="see the marriage as evidence that Clarence Thomas has rejected his roots" type="VP">
          <tokens>
            <token id="14" string="see" />
            <token id="15" string="the" />
            <token id="16" string="marriage" />
            <token id="17" string="as" />
            <token id="18" string="evidence" />
            <token id="19" string="that" />
            <token id="20" string="Clarence" />
            <token id="21" string="Thomas" />
            <token id="22" string="has" />
            <token id="23" string="rejected" />
            <token id="24" string="his" />
            <token id="25" string="roots" />
          </tokens>
        </chunking>
        <chunking id="15" string="white" type="ADJP">
          <tokens>
            <token id="6" string="white" />
          </tokens>
        </chunking>
        <chunking id="16" string="rejected his roots" type="VP">
          <tokens>
            <token id="23" string="rejected" />
            <token id="24" string="his" />
            <token id="25" string="roots" />
          </tokens>
        </chunking>
        <chunking id="17" string="criticism" type="NP">
          <tokens>
            <token id="9" string="criticism" />
          </tokens>
        </chunking>
        <chunking id="18" string="drawn criticism from some blacks who see the marriage as evidence that Clarence Thomas has rejected his roots" type="VP">
          <tokens>
            <token id="8" string="drawn" />
            <token id="9" string="criticism" />
            <token id="10" string="from" />
            <token id="11" string="some" />
            <token id="12" string="blacks" />
            <token id="13" string="who" />
            <token id="14" string="see" />
            <token id="15" string="the" />
            <token id="16" string="marriage" />
            <token id="17" string="as" />
            <token id="18" string="evidence" />
            <token id="19" string="that" />
            <token id="20" string="Clarence" />
            <token id="21" string="Thomas" />
            <token id="22" string="has" />
            <token id="23" string="rejected" />
            <token id="24" string="his" />
            <token id="25" string="roots" />
          </tokens>
        </chunking>
        <chunking id="19" string="some blacks who see the marriage as evidence that Clarence Thomas has rejected his roots" type="NP">
          <tokens>
            <token id="11" string="some" />
            <token id="12" string="blacks" />
            <token id="13" string="who" />
            <token id="14" string="see" />
            <token id="15" string="the" />
            <token id="16" string="marriage" />
            <token id="17" string="as" />
            <token id="18" string="evidence" />
            <token id="19" string="that" />
            <token id="20" string="Clarence" />
            <token id="21" string="Thomas" />
            <token id="22" string="has" />
            <token id="23" string="rejected" />
            <token id="24" string="his" />
            <token id="25" string="roots" />
          </tokens>
        </chunking>
        <chunking id="20" string="Clarence Thomas" type="NP">
          <tokens>
            <token id="20" string="Clarence" />
            <token id="21" string="Thomas" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">fact</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">drawn</governor>
          <dependent id="2">fact</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">white</governor>
          <dependent id="3">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">white</governor>
          <dependent id="4">she</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">white</governor>
          <dependent id="5">is</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="2">fact</governor>
          <dependent id="6">white</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">drawn</governor>
          <dependent id="7">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">drawn</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">drawn</governor>
          <dependent id="9">criticism</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">blacks</governor>
          <dependent id="10">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">blacks</governor>
          <dependent id="11">some</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">drawn</governor>
          <dependent id="12">blacks</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">see</governor>
          <dependent id="13">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="12">blacks</governor>
          <dependent id="14">see</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">marriage</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">see</governor>
          <dependent id="16">marriage</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">evidence</governor>
          <dependent id="17">as</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">see</governor>
          <dependent id="18">evidence</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">rejected</governor>
          <dependent id="19">that</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">Thomas</governor>
          <dependent id="20">Clarence</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">rejected</governor>
          <dependent id="21">Thomas</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="23">rejected</governor>
          <dependent id="22">has</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">see</governor>
          <dependent id="23">rejected</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="25">roots</governor>
          <dependent id="24">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">rejected</governor>
          <dependent id="25">roots</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Clarence Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="Clarence" />
            <token id="21" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>In their respective careers, the Thomases have embraced the view that women and minorities are hindered, rather than helped, by affirmative action and government programs.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="respective" lemma="respective" stem="respect" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="careers" lemma="career" stem="career" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="Thomases" lemma="Thomases" stem="thomas" pos="NNPS" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="8" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="embraced" lemma="embrace" stem="embrac" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="view" lemma="view" stem="view" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="women" lemma="woman" stem="women" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="minorities" lemma="minority" stem="minor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="hindered" lemma="hinder" stem="hinder" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="rather" lemma="rather" stem="rather" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="helped" lemma="help" stem="help" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="affirmative" lemma="affirmative" stem="affirm" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="action" lemma="action" stem="action" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="government" lemma="government" stem="govern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="programs" lemma="program" stem="program" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (PRP$ their) (JJ respective) (NNS careers))) (, ,) (NP (DT the) (NNPS Thomases)) (VP (VBP have) (VP (VP (VBN embraced) (NP (DT the) (NN view)) (SBAR (IN that) (S (NP (NNS women) (CC and) (NNS minorities)) (VP (VBP are) (VP (VBN hindered)))))) (, ,) (CONJP (RB rather) (IN than)) (VP (VBN helped) (, ,) (PP (IN by) (NP (JJ affirmative) (NN action) (CC and) (NN government) (NNS programs)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the Thomases" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="Thomases" />
          </tokens>
        </chunking>
        <chunking id="2" string="are hindered" type="VP">
          <tokens>
            <token id="16" string="are" />
            <token id="17" string="hindered" />
          </tokens>
        </chunking>
        <chunking id="3" string="embraced the view that women and minorities are hindered" type="VP">
          <tokens>
            <token id="9" string="embraced" />
            <token id="10" string="the" />
            <token id="11" string="view" />
            <token id="12" string="that" />
            <token id="13" string="women" />
            <token id="14" string="and" />
            <token id="15" string="minorities" />
            <token id="16" string="are" />
            <token id="17" string="hindered" />
          </tokens>
        </chunking>
        <chunking id="4" string="helped , by affirmative action and government programs" type="VP">
          <tokens>
            <token id="21" string="helped" />
            <token id="22" string="," />
            <token id="23" string="by" />
            <token id="24" string="affirmative" />
            <token id="25" string="action" />
            <token id="26" string="and" />
            <token id="27" string="government" />
            <token id="28" string="programs" />
          </tokens>
        </chunking>
        <chunking id="5" string="affirmative action and government programs" type="NP">
          <tokens>
            <token id="24" string="affirmative" />
            <token id="25" string="action" />
            <token id="26" string="and" />
            <token id="27" string="government" />
            <token id="28" string="programs" />
          </tokens>
        </chunking>
        <chunking id="6" string="embraced the view that women and minorities are hindered , rather than helped , by affirmative action and government programs" type="VP">
          <tokens>
            <token id="9" string="embraced" />
            <token id="10" string="the" />
            <token id="11" string="view" />
            <token id="12" string="that" />
            <token id="13" string="women" />
            <token id="14" string="and" />
            <token id="15" string="minorities" />
            <token id="16" string="are" />
            <token id="17" string="hindered" />
            <token id="18" string="," />
            <token id="19" string="rather" />
            <token id="20" string="than" />
            <token id="21" string="helped" />
            <token id="22" string="," />
            <token id="23" string="by" />
            <token id="24" string="affirmative" />
            <token id="25" string="action" />
            <token id="26" string="and" />
            <token id="27" string="government" />
            <token id="28" string="programs" />
          </tokens>
        </chunking>
        <chunking id="7" string="the view" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="view" />
          </tokens>
        </chunking>
        <chunking id="8" string="their respective careers" type="NP">
          <tokens>
            <token id="2" string="their" />
            <token id="3" string="respective" />
            <token id="4" string="careers" />
          </tokens>
        </chunking>
        <chunking id="9" string="women and minorities" type="NP">
          <tokens>
            <token id="13" string="women" />
            <token id="14" string="and" />
            <token id="15" string="minorities" />
          </tokens>
        </chunking>
        <chunking id="10" string="have embraced the view that women and minorities are hindered , rather than helped , by affirmative action and government programs" type="VP">
          <tokens>
            <token id="8" string="have" />
            <token id="9" string="embraced" />
            <token id="10" string="the" />
            <token id="11" string="view" />
            <token id="12" string="that" />
            <token id="13" string="women" />
            <token id="14" string="and" />
            <token id="15" string="minorities" />
            <token id="16" string="are" />
            <token id="17" string="hindered" />
            <token id="18" string="," />
            <token id="19" string="rather" />
            <token id="20" string="than" />
            <token id="21" string="helped" />
            <token id="22" string="," />
            <token id="23" string="by" />
            <token id="24" string="affirmative" />
            <token id="25" string="action" />
            <token id="26" string="and" />
            <token id="27" string="government" />
            <token id="28" string="programs" />
          </tokens>
        </chunking>
        <chunking id="11" string="that women and minorities are hindered" type="SBAR">
          <tokens>
            <token id="12" string="that" />
            <token id="13" string="women" />
            <token id="14" string="and" />
            <token id="15" string="minorities" />
            <token id="16" string="are" />
            <token id="17" string="hindered" />
          </tokens>
        </chunking>
        <chunking id="12" string="hindered" type="VP">
          <tokens>
            <token id="17" string="hindered" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">careers</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">careers</governor>
          <dependent id="2">their</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">careers</governor>
          <dependent id="3">respective</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">embraced</governor>
          <dependent id="4">careers</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">Thomases</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">embraced</governor>
          <dependent id="7">Thomases</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">embraced</governor>
          <dependent id="8">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">embraced</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">view</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">embraced</governor>
          <dependent id="11">view</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">hindered</governor>
          <dependent id="12">that</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="17">hindered</governor>
          <dependent id="13">women</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">women</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">women</governor>
          <dependent id="15">minorities</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="17">hindered</governor>
          <dependent id="16">are</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">embraced</governor>
          <dependent id="17">hindered</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">embraced</governor>
          <dependent id="19">rather</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="19">rather</governor>
          <dependent id="20">than</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">embraced</governor>
          <dependent id="21">helped</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">action</governor>
          <dependent id="23">by</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">action</governor>
          <dependent id="24">affirmative</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">helped</governor>
          <dependent id="25">action</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="25">action</governor>
          <dependent id="26">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">programs</governor>
          <dependent id="27">government</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="25">action</governor>
          <dependent id="28">programs</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Thomases" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Thomases" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>True equality is achieved by holding everyone to the same standard, they believe.</content>
      <tokens>
        <token id="1" string="True" lemma="true" stem="true" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="equality" lemma="equality" stem="equal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="achieved" lemma="achieve" stem="achiev" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="holding" lemma="hold" stem="hold" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="everyone" lemma="everyone" stem="everyon" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="same" lemma="same" stem="same" pos="JJ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="standard" lemma="standard" stem="standard" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="believe" lemma="believe" stem="believ" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (ADVP (JJ True)) (NP (NN equality)) (VP (VBZ is) (VP (VBN achieved) (PP (IN by) (NP (NP (VBG holding) (NN everyone)) (PP (TO to) (NP (DT the) (JJ same) (NN standard)))))))) (, ,) (NP (PRP they)) (VP (VBP believe)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="they" type="NP">
          <tokens>
            <token id="13" string="they" />
          </tokens>
        </chunking>
        <chunking id="2" string="achieved by holding everyone to the same standard" type="VP">
          <tokens>
            <token id="4" string="achieved" />
            <token id="5" string="by" />
            <token id="6" string="holding" />
            <token id="7" string="everyone" />
            <token id="8" string="to" />
            <token id="9" string="the" />
            <token id="10" string="same" />
            <token id="11" string="standard" />
          </tokens>
        </chunking>
        <chunking id="3" string="the same standard" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="same" />
            <token id="11" string="standard" />
          </tokens>
        </chunking>
        <chunking id="4" string="holding everyone" type="NP">
          <tokens>
            <token id="6" string="holding" />
            <token id="7" string="everyone" />
          </tokens>
        </chunking>
        <chunking id="5" string="holding everyone to the same standard" type="NP">
          <tokens>
            <token id="6" string="holding" />
            <token id="7" string="everyone" />
            <token id="8" string="to" />
            <token id="9" string="the" />
            <token id="10" string="same" />
            <token id="11" string="standard" />
          </tokens>
        </chunking>
        <chunking id="6" string="believe" type="VP">
          <tokens>
            <token id="14" string="believe" />
          </tokens>
        </chunking>
        <chunking id="7" string="equality" type="NP">
          <tokens>
            <token id="2" string="equality" />
          </tokens>
        </chunking>
        <chunking id="8" string="is achieved by holding everyone to the same standard" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="achieved" />
            <token id="5" string="by" />
            <token id="6" string="holding" />
            <token id="7" string="everyone" />
            <token id="8" string="to" />
            <token id="9" string="the" />
            <token id="10" string="same" />
            <token id="11" string="standard" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="4">achieved</governor>
          <dependent id="1">True</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="4">achieved</governor>
          <dependent id="2">equality</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">achieved</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">believe</governor>
          <dependent id="4">achieved</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">everyone</governor>
          <dependent id="5">by</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">everyone</governor>
          <dependent id="6">holding</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">achieved</governor>
          <dependent id="7">everyone</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">standard</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">standard</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">standard</governor>
          <dependent id="10">same</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">everyone</governor>
          <dependent id="11">standard</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">believe</governor>
          <dependent id="13">they</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">believe</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>&amp;quot;I don&amp;apost;t think it&amp;apost;s fair to say she&amp;apost;s anti-women&amp;apost;s rights,&amp;quot; said Ricky Silberman, vice chairwoman of the EEOC and a friend of the Thomases.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="think" lemma="think" stem="think" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="fair" lemma="fair" stem="fair" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="say" lemma="say" stem="sai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="anti-women" lemma="anti-women" stem="anti-women" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="rights" lemma="rights" stem="right" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="Ricky" lemma="Ricky" stem="ricki" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="20" string="Silberman" lemma="Silberman" stem="silberman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="vice" lemma="vice" stem="vice" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="chairwoman" lemma="chairwoman" stem="chairwoman" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="EEOC" lemma="EEOC" stem="eeoc" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="27" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="friend" lemma="friend" stem="friend" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="Thomases" lemma="Thomases" stem="thomas" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (PRP I)) (VP (VBP do) (RB n't) (VP (VB think) (SBAR (S (NP (PRP it)) (VP (VBZ 's) (ADJP (JJ fair) (S (VP (TO to) (VP (VB say) (SBAR (S (NP (PRP she)) (VP (VBZ 's) (NP (NP (JJ anti-women) (POS 's)) (NNS rights))))))))))))))) (, ,) ('' '') (VP (VBD said)) (NP (NP (NNP Ricky) (NNP Silberman)) (, ,) (NP (NP (NP (NN vice) (NN chairwoman)) (PP (IN of) (NP (DT the) (NNP EEOC)))) (CC and) (NP (NP (DT a) (NN friend)) (PP (IN of) (NP (DT the) (NNP Thomases)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="do n't think it 's fair to say she 's anti-women 's rights" type="VP">
          <tokens>
            <token id="3" string="do" />
            <token id="4" string="n't" />
            <token id="5" string="think" />
            <token id="6" string="it" />
            <token id="7" string="'s" />
            <token id="8" string="fair" />
            <token id="9" string="to" />
            <token id="10" string="say" />
            <token id="11" string="she" />
            <token id="12" string="'s" />
            <token id="13" string="anti-women" />
            <token id="14" string="'s" />
            <token id="15" string="rights" />
          </tokens>
        </chunking>
        <chunking id="2" string="a friend" type="NP">
          <tokens>
            <token id="28" string="a" />
            <token id="29" string="friend" />
          </tokens>
        </chunking>
        <chunking id="3" string="Ricky Silberman" type="NP">
          <tokens>
            <token id="19" string="Ricky" />
            <token id="20" string="Silberman" />
          </tokens>
        </chunking>
        <chunking id="4" string="a friend of the Thomases" type="NP">
          <tokens>
            <token id="28" string="a" />
            <token id="29" string="friend" />
            <token id="30" string="of" />
            <token id="31" string="the" />
            <token id="32" string="Thomases" />
          </tokens>
        </chunking>
        <chunking id="5" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="6" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="vice chairwoman of the EEOC" type="NP">
          <tokens>
            <token id="22" string="vice" />
            <token id="23" string="chairwoman" />
            <token id="24" string="of" />
            <token id="25" string="the" />
            <token id="26" string="EEOC" />
          </tokens>
        </chunking>
        <chunking id="8" string="say she 's anti-women 's rights" type="VP">
          <tokens>
            <token id="10" string="say" />
            <token id="11" string="she" />
            <token id="12" string="'s" />
            <token id="13" string="anti-women" />
            <token id="14" string="'s" />
            <token id="15" string="rights" />
          </tokens>
        </chunking>
        <chunking id="9" string="she" type="NP">
          <tokens>
            <token id="11" string="she" />
          </tokens>
        </chunking>
        <chunking id="10" string="the EEOC" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="EEOC" />
          </tokens>
        </chunking>
        <chunking id="11" string="the Thomases" type="NP">
          <tokens>
            <token id="31" string="the" />
            <token id="32" string="Thomases" />
          </tokens>
        </chunking>
        <chunking id="12" string="it 's fair to say she 's anti-women 's rights" type="SBAR">
          <tokens>
            <token id="6" string="it" />
            <token id="7" string="'s" />
            <token id="8" string="fair" />
            <token id="9" string="to" />
            <token id="10" string="say" />
            <token id="11" string="she" />
            <token id="12" string="'s" />
            <token id="13" string="anti-women" />
            <token id="14" string="'s" />
            <token id="15" string="rights" />
          </tokens>
        </chunking>
        <chunking id="13" string="'s fair to say she 's anti-women 's rights" type="VP">
          <tokens>
            <token id="7" string="'s" />
            <token id="8" string="fair" />
            <token id="9" string="to" />
            <token id="10" string="say" />
            <token id="11" string="she" />
            <token id="12" string="'s" />
            <token id="13" string="anti-women" />
            <token id="14" string="'s" />
            <token id="15" string="rights" />
          </tokens>
        </chunking>
        <chunking id="14" string="anti-women 's rights" type="NP">
          <tokens>
            <token id="13" string="anti-women" />
            <token id="14" string="'s" />
            <token id="15" string="rights" />
          </tokens>
        </chunking>
        <chunking id="15" string="vice chairwoman" type="NP">
          <tokens>
            <token id="22" string="vice" />
            <token id="23" string="chairwoman" />
          </tokens>
        </chunking>
        <chunking id="16" string="think it 's fair to say she 's anti-women 's rights" type="VP">
          <tokens>
            <token id="5" string="think" />
            <token id="6" string="it" />
            <token id="7" string="'s" />
            <token id="8" string="fair" />
            <token id="9" string="to" />
            <token id="10" string="say" />
            <token id="11" string="she" />
            <token id="12" string="'s" />
            <token id="13" string="anti-women" />
            <token id="14" string="'s" />
            <token id="15" string="rights" />
          </tokens>
        </chunking>
        <chunking id="17" string="Ricky Silberman , vice chairwoman of the EEOC and a friend of the Thomases" type="NP">
          <tokens>
            <token id="19" string="Ricky" />
            <token id="20" string="Silberman" />
            <token id="21" string="," />
            <token id="22" string="vice" />
            <token id="23" string="chairwoman" />
            <token id="24" string="of" />
            <token id="25" string="the" />
            <token id="26" string="EEOC" />
            <token id="27" string="and" />
            <token id="28" string="a" />
            <token id="29" string="friend" />
            <token id="30" string="of" />
            <token id="31" string="the" />
            <token id="32" string="Thomases" />
          </tokens>
        </chunking>
        <chunking id="18" string="'s anti-women 's rights" type="VP">
          <tokens>
            <token id="12" string="'s" />
            <token id="13" string="anti-women" />
            <token id="14" string="'s" />
            <token id="15" string="rights" />
          </tokens>
        </chunking>
        <chunking id="19" string="anti-women 's" type="NP">
          <tokens>
            <token id="13" string="anti-women" />
            <token id="14" string="'s" />
          </tokens>
        </chunking>
        <chunking id="20" string="said" type="VP">
          <tokens>
            <token id="18" string="said" />
          </tokens>
        </chunking>
        <chunking id="21" string="fair to say she 's anti-women 's rights" type="ADJP">
          <tokens>
            <token id="8" string="fair" />
            <token id="9" string="to" />
            <token id="10" string="say" />
            <token id="11" string="she" />
            <token id="12" string="'s" />
            <token id="13" string="anti-women" />
            <token id="14" string="'s" />
            <token id="15" string="rights" />
          </tokens>
        </chunking>
        <chunking id="22" string="to say she 's anti-women 's rights" type="VP">
          <tokens>
            <token id="9" string="to" />
            <token id="10" string="say" />
            <token id="11" string="she" />
            <token id="12" string="'s" />
            <token id="13" string="anti-women" />
            <token id="14" string="'s" />
            <token id="15" string="rights" />
          </tokens>
        </chunking>
        <chunking id="23" string="vice chairwoman of the EEOC and a friend of the Thomases" type="NP">
          <tokens>
            <token id="22" string="vice" />
            <token id="23" string="chairwoman" />
            <token id="24" string="of" />
            <token id="25" string="the" />
            <token id="26" string="EEOC" />
            <token id="27" string="and" />
            <token id="28" string="a" />
            <token id="29" string="friend" />
            <token id="30" string="of" />
            <token id="31" string="the" />
            <token id="32" string="Thomases" />
          </tokens>
        </chunking>
        <chunking id="24" string="she 's anti-women 's rights" type="SBAR">
          <tokens>
            <token id="11" string="she" />
            <token id="12" string="'s" />
            <token id="13" string="anti-women" />
            <token id="14" string="'s" />
            <token id="15" string="rights" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">think</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">think</governor>
          <dependent id="3">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">think</governor>
          <dependent id="4">n't</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="18">said</governor>
          <dependent id="5">think</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">fair</governor>
          <dependent id="6">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">fair</governor>
          <dependent id="7">'s</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">think</governor>
          <dependent id="8">fair</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">say</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">fair</governor>
          <dependent id="10">say</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">rights</governor>
          <dependent id="11">she</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="15">rights</governor>
          <dependent id="12">'s</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">rights</governor>
          <dependent id="13">anti-women</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">anti-women</governor>
          <dependent id="14">'s</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">say</governor>
          <dependent id="15">rights</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Silberman</governor>
          <dependent id="19">Ricky</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">said</governor>
          <dependent id="20">Silberman</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">chairwoman</governor>
          <dependent id="22">vice</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="20">Silberman</governor>
          <dependent id="23">chairwoman</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">EEOC</governor>
          <dependent id="24">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">EEOC</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">chairwoman</governor>
          <dependent id="26">EEOC</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="23">chairwoman</governor>
          <dependent id="27">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">friend</governor>
          <dependent id="28">a</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="23">chairwoman</governor>
          <dependent id="29">friend</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">Thomases</governor>
          <dependent id="30">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">Thomases</governor>
          <dependent id="31">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">friend</governor>
          <dependent id="32">Thomases</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="EEOC" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="26" string="EEOC" />
          </tokens>
        </entity>
        <entity id="2" string="Thomases" type="PERSON" score="0.0">
          <tokens>
            <token id="32" string="Thomases" />
          </tokens>
        </entity>
        <entity id="3" string="Ricky Silberman" type="PERSON" score="0.0">
          <tokens>
            <token id="19" string="Ricky" />
            <token id="20" string="Silberman" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>She said Virginia Thomas opposed legislation on comparable worth because it would have involved the government in determining wages, which is &amp;quot;not good for the economy, not good for workers, not good for women.&amp;quot;</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Virginia" lemma="Virginia" stem="virginia" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="4" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="5" string="opposed" lemma="oppose" stem="oppos" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="legislation" lemma="legislation" stem="legisl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="comparable" lemma="comparable" stem="compar" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="worth" lemma="worth" stem="worth" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="involved" lemma="involve" stem="involv" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="government" lemma="government" stem="govern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="determining" lemma="determine" stem="determin" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="wages" lemma="wages" stem="wage" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="good" lemma="good" stem="good" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="economy" lemma="economy" stem="economi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="good" lemma="good" stem="good" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="workers" lemma="worker" stem="worker" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="good" lemma="good" stem="good" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="women" lemma="woman" stem="women" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="39" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP She)) (VP (VBD said) (SBAR (S (NP (NNP Virginia) (NNP Thomas)) (VP (VBD opposed) (NP (NN legislation)) (PP (IN on) (ADJP (ADJP (JJ comparable) (JJ worth)) (SBAR (IN because) (S (NP (PRP it)) (VP (MD would) (VP (VB have) (VP (VBN involved) (NP (DT the) (NN government)) (PP (IN in) (S (VP (VBG determining) (NP (NP (NNS wages)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (`` ``) (RB not) (ADJP (ADJP (JJ good) (PP (IN for) (NP (DT the) (NN economy)))) (, ,) (ADJP (RB not) (JJ good) (PP (IN for) (NP (NNS workers)))) (, ,) (ADJP (RB not) (JJ good)) (PP (IN for) (NP (NNS women)))))))))))))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="which is `` not good for the economy , not good for workers , not good for women" type="SBAR">
          <tokens>
            <token id="21" string="which" />
            <token id="22" string="is" />
            <token id="23" string="&quot;" />
            <token id="24" string="not" />
            <token id="25" string="good" />
            <token id="26" string="for" />
            <token id="27" string="the" />
            <token id="28" string="economy" />
            <token id="29" string="," />
            <token id="30" string="not" />
            <token id="31" string="good" />
            <token id="32" string="for" />
            <token id="33" string="workers" />
            <token id="34" string="," />
            <token id="35" string="not" />
            <token id="36" string="good" />
            <token id="37" string="for" />
            <token id="38" string="women" />
          </tokens>
        </chunking>
        <chunking id="2" string="have involved the government in determining wages , which is `` not good for the economy , not good for workers , not good for women" type="VP">
          <tokens>
            <token id="13" string="have" />
            <token id="14" string="involved" />
            <token id="15" string="the" />
            <token id="16" string="government" />
            <token id="17" string="in" />
            <token id="18" string="determining" />
            <token id="19" string="wages" />
            <token id="20" string="," />
            <token id="21" string="which" />
            <token id="22" string="is" />
            <token id="23" string="&quot;" />
            <token id="24" string="not" />
            <token id="25" string="good" />
            <token id="26" string="for" />
            <token id="27" string="the" />
            <token id="28" string="economy" />
            <token id="29" string="," />
            <token id="30" string="not" />
            <token id="31" string="good" />
            <token id="32" string="for" />
            <token id="33" string="workers" />
            <token id="34" string="," />
            <token id="35" string="not" />
            <token id="36" string="good" />
            <token id="37" string="for" />
            <token id="38" string="women" />
          </tokens>
        </chunking>
        <chunking id="3" string="comparable worth because it would have involved the government in determining wages , which is `` not good for the economy , not good for workers , not good for women" type="ADJP">
          <tokens>
            <token id="8" string="comparable" />
            <token id="9" string="worth" />
            <token id="10" string="because" />
            <token id="11" string="it" />
            <token id="12" string="would" />
            <token id="13" string="have" />
            <token id="14" string="involved" />
            <token id="15" string="the" />
            <token id="16" string="government" />
            <token id="17" string="in" />
            <token id="18" string="determining" />
            <token id="19" string="wages" />
            <token id="20" string="," />
            <token id="21" string="which" />
            <token id="22" string="is" />
            <token id="23" string="&quot;" />
            <token id="24" string="not" />
            <token id="25" string="good" />
            <token id="26" string="for" />
            <token id="27" string="the" />
            <token id="28" string="economy" />
            <token id="29" string="," />
            <token id="30" string="not" />
            <token id="31" string="good" />
            <token id="32" string="for" />
            <token id="33" string="workers" />
            <token id="34" string="," />
            <token id="35" string="not" />
            <token id="36" string="good" />
            <token id="37" string="for" />
            <token id="38" string="women" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="11" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="would have involved the government in determining wages , which is `` not good for the economy , not good for workers , not good for women" type="VP">
          <tokens>
            <token id="12" string="would" />
            <token id="13" string="have" />
            <token id="14" string="involved" />
            <token id="15" string="the" />
            <token id="16" string="government" />
            <token id="17" string="in" />
            <token id="18" string="determining" />
            <token id="19" string="wages" />
            <token id="20" string="," />
            <token id="21" string="which" />
            <token id="22" string="is" />
            <token id="23" string="&quot;" />
            <token id="24" string="not" />
            <token id="25" string="good" />
            <token id="26" string="for" />
            <token id="27" string="the" />
            <token id="28" string="economy" />
            <token id="29" string="," />
            <token id="30" string="not" />
            <token id="31" string="good" />
            <token id="32" string="for" />
            <token id="33" string="workers" />
            <token id="34" string="," />
            <token id="35" string="not" />
            <token id="36" string="good" />
            <token id="37" string="for" />
            <token id="38" string="women" />
          </tokens>
        </chunking>
        <chunking id="6" string="comparable worth" type="ADJP">
          <tokens>
            <token id="8" string="comparable" />
            <token id="9" string="worth" />
          </tokens>
        </chunking>
        <chunking id="7" string="involved the government in determining wages , which is `` not good for the economy , not good for workers , not good for women" type="VP">
          <tokens>
            <token id="14" string="involved" />
            <token id="15" string="the" />
            <token id="16" string="government" />
            <token id="17" string="in" />
            <token id="18" string="determining" />
            <token id="19" string="wages" />
            <token id="20" string="," />
            <token id="21" string="which" />
            <token id="22" string="is" />
            <token id="23" string="&quot;" />
            <token id="24" string="not" />
            <token id="25" string="good" />
            <token id="26" string="for" />
            <token id="27" string="the" />
            <token id="28" string="economy" />
            <token id="29" string="," />
            <token id="30" string="not" />
            <token id="31" string="good" />
            <token id="32" string="for" />
            <token id="33" string="workers" />
            <token id="34" string="," />
            <token id="35" string="not" />
            <token id="36" string="good" />
            <token id="37" string="for" />
            <token id="38" string="women" />
          </tokens>
        </chunking>
        <chunking id="8" string="wages" type="NP">
          <tokens>
            <token id="19" string="wages" />
          </tokens>
        </chunking>
        <chunking id="9" string="said Virginia Thomas opposed legislation on comparable worth because it would have involved the government in determining wages , which is `` not good for the economy , not good for workers , not good for women" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="Virginia" />
            <token id="4" string="Thomas" />
            <token id="5" string="opposed" />
            <token id="6" string="legislation" />
            <token id="7" string="on" />
            <token id="8" string="comparable" />
            <token id="9" string="worth" />
            <token id="10" string="because" />
            <token id="11" string="it" />
            <token id="12" string="would" />
            <token id="13" string="have" />
            <token id="14" string="involved" />
            <token id="15" string="the" />
            <token id="16" string="government" />
            <token id="17" string="in" />
            <token id="18" string="determining" />
            <token id="19" string="wages" />
            <token id="20" string="," />
            <token id="21" string="which" />
            <token id="22" string="is" />
            <token id="23" string="&quot;" />
            <token id="24" string="not" />
            <token id="25" string="good" />
            <token id="26" string="for" />
            <token id="27" string="the" />
            <token id="28" string="economy" />
            <token id="29" string="," />
            <token id="30" string="not" />
            <token id="31" string="good" />
            <token id="32" string="for" />
            <token id="33" string="workers" />
            <token id="34" string="," />
            <token id="35" string="not" />
            <token id="36" string="good" />
            <token id="37" string="for" />
            <token id="38" string="women" />
          </tokens>
        </chunking>
        <chunking id="10" string="the government" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="government" />
          </tokens>
        </chunking>
        <chunking id="11" string="women" type="NP">
          <tokens>
            <token id="38" string="women" />
          </tokens>
        </chunking>
        <chunking id="12" string="good for the economy" type="ADJP">
          <tokens>
            <token id="25" string="good" />
            <token id="26" string="for" />
            <token id="27" string="the" />
            <token id="28" string="economy" />
          </tokens>
        </chunking>
        <chunking id="13" string="the economy" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="economy" />
          </tokens>
        </chunking>
        <chunking id="14" string="Virginia Thomas opposed legislation on comparable worth because it would have involved the government in determining wages , which is `` not good for the economy , not good for workers , not good for women" type="SBAR">
          <tokens>
            <token id="3" string="Virginia" />
            <token id="4" string="Thomas" />
            <token id="5" string="opposed" />
            <token id="6" string="legislation" />
            <token id="7" string="on" />
            <token id="8" string="comparable" />
            <token id="9" string="worth" />
            <token id="10" string="because" />
            <token id="11" string="it" />
            <token id="12" string="would" />
            <token id="13" string="have" />
            <token id="14" string="involved" />
            <token id="15" string="the" />
            <token id="16" string="government" />
            <token id="17" string="in" />
            <token id="18" string="determining" />
            <token id="19" string="wages" />
            <token id="20" string="," />
            <token id="21" string="which" />
            <token id="22" string="is" />
            <token id="23" string="&quot;" />
            <token id="24" string="not" />
            <token id="25" string="good" />
            <token id="26" string="for" />
            <token id="27" string="the" />
            <token id="28" string="economy" />
            <token id="29" string="," />
            <token id="30" string="not" />
            <token id="31" string="good" />
            <token id="32" string="for" />
            <token id="33" string="workers" />
            <token id="34" string="," />
            <token id="35" string="not" />
            <token id="36" string="good" />
            <token id="37" string="for" />
            <token id="38" string="women" />
          </tokens>
        </chunking>
        <chunking id="15" string="opposed legislation on comparable worth because it would have involved the government in determining wages , which is `` not good for the economy , not good for workers , not good for women" type="VP">
          <tokens>
            <token id="5" string="opposed" />
            <token id="6" string="legislation" />
            <token id="7" string="on" />
            <token id="8" string="comparable" />
            <token id="9" string="worth" />
            <token id="10" string="because" />
            <token id="11" string="it" />
            <token id="12" string="would" />
            <token id="13" string="have" />
            <token id="14" string="involved" />
            <token id="15" string="the" />
            <token id="16" string="government" />
            <token id="17" string="in" />
            <token id="18" string="determining" />
            <token id="19" string="wages" />
            <token id="20" string="," />
            <token id="21" string="which" />
            <token id="22" string="is" />
            <token id="23" string="&quot;" />
            <token id="24" string="not" />
            <token id="25" string="good" />
            <token id="26" string="for" />
            <token id="27" string="the" />
            <token id="28" string="economy" />
            <token id="29" string="," />
            <token id="30" string="not" />
            <token id="31" string="good" />
            <token id="32" string="for" />
            <token id="33" string="workers" />
            <token id="34" string="," />
            <token id="35" string="not" />
            <token id="36" string="good" />
            <token id="37" string="for" />
            <token id="38" string="women" />
          </tokens>
        </chunking>
        <chunking id="16" string="wages , which is `` not good for the economy , not good for workers , not good for women" type="NP">
          <tokens>
            <token id="19" string="wages" />
            <token id="20" string="," />
            <token id="21" string="which" />
            <token id="22" string="is" />
            <token id="23" string="&quot;" />
            <token id="24" string="not" />
            <token id="25" string="good" />
            <token id="26" string="for" />
            <token id="27" string="the" />
            <token id="28" string="economy" />
            <token id="29" string="," />
            <token id="30" string="not" />
            <token id="31" string="good" />
            <token id="32" string="for" />
            <token id="33" string="workers" />
            <token id="34" string="," />
            <token id="35" string="not" />
            <token id="36" string="good" />
            <token id="37" string="for" />
            <token id="38" string="women" />
          </tokens>
        </chunking>
        <chunking id="17" string="not good for workers" type="ADJP">
          <tokens>
            <token id="30" string="not" />
            <token id="31" string="good" />
            <token id="32" string="for" />
            <token id="33" string="workers" />
          </tokens>
        </chunking>
        <chunking id="18" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
        <chunking id="19" string="because it would have involved the government in determining wages , which is `` not good for the economy , not good for workers , not good for women" type="SBAR">
          <tokens>
            <token id="10" string="because" />
            <token id="11" string="it" />
            <token id="12" string="would" />
            <token id="13" string="have" />
            <token id="14" string="involved" />
            <token id="15" string="the" />
            <token id="16" string="government" />
            <token id="17" string="in" />
            <token id="18" string="determining" />
            <token id="19" string="wages" />
            <token id="20" string="," />
            <token id="21" string="which" />
            <token id="22" string="is" />
            <token id="23" string="&quot;" />
            <token id="24" string="not" />
            <token id="25" string="good" />
            <token id="26" string="for" />
            <token id="27" string="the" />
            <token id="28" string="economy" />
            <token id="29" string="," />
            <token id="30" string="not" />
            <token id="31" string="good" />
            <token id="32" string="for" />
            <token id="33" string="workers" />
            <token id="34" string="," />
            <token id="35" string="not" />
            <token id="36" string="good" />
            <token id="37" string="for" />
            <token id="38" string="women" />
          </tokens>
        </chunking>
        <chunking id="20" string="not good" type="ADJP">
          <tokens>
            <token id="35" string="not" />
            <token id="36" string="good" />
          </tokens>
        </chunking>
        <chunking id="21" string="Virginia Thomas" type="NP">
          <tokens>
            <token id="3" string="Virginia" />
            <token id="4" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="22" string="is `` not good for the economy , not good for workers , not good for women" type="VP">
          <tokens>
            <token id="22" string="is" />
            <token id="23" string="&quot;" />
            <token id="24" string="not" />
            <token id="25" string="good" />
            <token id="26" string="for" />
            <token id="27" string="the" />
            <token id="28" string="economy" />
            <token id="29" string="," />
            <token id="30" string="not" />
            <token id="31" string="good" />
            <token id="32" string="for" />
            <token id="33" string="workers" />
            <token id="34" string="," />
            <token id="35" string="not" />
            <token id="36" string="good" />
            <token id="37" string="for" />
            <token id="38" string="women" />
          </tokens>
        </chunking>
        <chunking id="23" string="workers" type="NP">
          <tokens>
            <token id="33" string="workers" />
          </tokens>
        </chunking>
        <chunking id="24" string="legislation" type="NP">
          <tokens>
            <token id="6" string="legislation" />
          </tokens>
        </chunking>
        <chunking id="25" string="determining wages , which is `` not good for the economy , not good for workers , not good for women" type="VP">
          <tokens>
            <token id="18" string="determining" />
            <token id="19" string="wages" />
            <token id="20" string="," />
            <token id="21" string="which" />
            <token id="22" string="is" />
            <token id="23" string="&quot;" />
            <token id="24" string="not" />
            <token id="25" string="good" />
            <token id="26" string="for" />
            <token id="27" string="the" />
            <token id="28" string="economy" />
            <token id="29" string="," />
            <token id="30" string="not" />
            <token id="31" string="good" />
            <token id="32" string="for" />
            <token id="33" string="workers" />
            <token id="34" string="," />
            <token id="35" string="not" />
            <token id="36" string="good" />
            <token id="37" string="for" />
            <token id="38" string="women" />
          </tokens>
        </chunking>
        <chunking id="26" string="good for the economy , not good for workers , not good for women" type="ADJP">
          <tokens>
            <token id="25" string="good" />
            <token id="26" string="for" />
            <token id="27" string="the" />
            <token id="28" string="economy" />
            <token id="29" string="," />
            <token id="30" string="not" />
            <token id="31" string="good" />
            <token id="32" string="for" />
            <token id="33" string="workers" />
            <token id="34" string="," />
            <token id="35" string="not" />
            <token id="36" string="good" />
            <token id="37" string="for" />
            <token id="38" string="women" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Thomas</governor>
          <dependent id="3">Virginia</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">opposed</governor>
          <dependent id="4">Thomas</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="5">opposed</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">opposed</governor>
          <dependent id="6">legislation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">worth</governor>
          <dependent id="7">on</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">worth</governor>
          <dependent id="8">comparable</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">opposed</governor>
          <dependent id="9">worth</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">involved</governor>
          <dependent id="10">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">involved</governor>
          <dependent id="11">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">involved</governor>
          <dependent id="12">would</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">involved</governor>
          <dependent id="13">have</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">worth</governor>
          <dependent id="14">involved</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">government</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">involved</governor>
          <dependent id="16">government</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">determining</governor>
          <dependent id="17">in</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="14">involved</governor>
          <dependent id="18">determining</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">determining</governor>
          <dependent id="19">wages</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">good</governor>
          <dependent id="21">which</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="25">good</governor>
          <dependent id="22">is</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="25">good</governor>
          <dependent id="24">not</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="19">wages</governor>
          <dependent id="25">good</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">economy</governor>
          <dependent id="26">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">economy</governor>
          <dependent id="27">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">good</governor>
          <dependent id="28">economy</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="31">good</governor>
          <dependent id="30">not</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="25">good</governor>
          <dependent id="31">good</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">workers</governor>
          <dependent id="32">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">good</governor>
          <dependent id="33">workers</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="36">good</governor>
          <dependent id="35">not</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="25">good</governor>
          <dependent id="36">good</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">women</governor>
          <dependent id="37">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">good</governor>
          <dependent id="38">women</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Virginia Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Virginia" />
            <token id="4" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>; Conservative viewpoint; Virginia Thomas has represented the conservative viewpoint in her jobs as a staffer for a Republican congressman, spokeswoman at the U.S. Chamber of Congress and deputy assistant secretary at the Department of Labor.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Conservative" lemma="conservative" stem="conserv" pos="NN" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="3" string="viewpoint" lemma="viewpoint" stem="viewpoint" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Virginia" lemma="Virginia" stem="virginia" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="6" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="7" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="represented" lemma="represent" stem="repres" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="conservative" lemma="conservative" stem="conserv" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="11" string="viewpoint" lemma="viewpoint" stem="viewpoint" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="jobs" lemma="job" stem="job" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="staffer" lemma="staffer" stem="staffer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Republican" lemma="republican" stem="republican" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="21" string="congressman" lemma="congressman" stem="congressman" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="spokeswoman" lemma="spokeswoman" stem="spokeswoman" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="U.S." lemma="U.S." stem="u.s." pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="27" string="Chamber" lemma="Chamber" stem="chamber" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="28" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="29" string="Congress" lemma="Congress" stem="congress" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="30" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="deputy" lemma="deputy" stem="deputi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="assistant" lemma="assistant" stem="assist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="secretary" lemma="secretary" stem="secretari" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="Department" lemma="Department" stem="depart" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="37" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="38" string="Labor" lemma="Labor" stem="labor" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="39" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (NP (NP (NN Conservative) (NN viewpoint)) (: ;) (NP (NNP Virginia) (NNP Thomas))) (VP (VBZ has) (VP (VBN represented) (NP (NP (DT the) (JJ conservative) (NN viewpoint)) (PP (IN in) (NP (PRP$ her) (NNS jobs)))) (PP (IN as) (NP (NP (NP (DT a) (NN staffer)) (PP (IN for) (NP (DT a) (JJ Republican) (NN congressman)))) (, ,) (NP (NP (NN spokeswoman)) (PP (IN at) (NP (NP (DT the) (NNP U.S.) (NNP Chamber)) (PP (IN of) (NP (NNP Congress)))))) (CC and) (NP (NP (NN deputy) (NN assistant) (NN secretary)) (PP (IN at) (NP (NP (DT the) (NNP Department)) (PP (IN of) (NP (NNP Labor)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the U.S. Chamber of Congress" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="U.S." />
            <token id="27" string="Chamber" />
            <token id="28" string="of" />
            <token id="29" string="Congress" />
          </tokens>
        </chunking>
        <chunking id="2" string="spokeswoman" type="NP">
          <tokens>
            <token id="23" string="spokeswoman" />
          </tokens>
        </chunking>
        <chunking id="3" string="has represented the conservative viewpoint in her jobs as a staffer for a Republican congressman , spokeswoman at the U.S. Chamber of Congress and deputy assistant secretary at the Department of Labor" type="VP">
          <tokens>
            <token id="7" string="has" />
            <token id="8" string="represented" />
            <token id="9" string="the" />
            <token id="10" string="conservative" />
            <token id="11" string="viewpoint" />
            <token id="12" string="in" />
            <token id="13" string="her" />
            <token id="14" string="jobs" />
            <token id="15" string="as" />
            <token id="16" string="a" />
            <token id="17" string="staffer" />
            <token id="18" string="for" />
            <token id="19" string="a" />
            <token id="20" string="Republican" />
            <token id="21" string="congressman" />
            <token id="22" string="," />
            <token id="23" string="spokeswoman" />
            <token id="24" string="at" />
            <token id="25" string="the" />
            <token id="26" string="U.S." />
            <token id="27" string="Chamber" />
            <token id="28" string="of" />
            <token id="29" string="Congress" />
            <token id="30" string="and" />
            <token id="31" string="deputy" />
            <token id="32" string="assistant" />
            <token id="33" string="secretary" />
            <token id="34" string="at" />
            <token id="35" string="the" />
            <token id="36" string="Department" />
            <token id="37" string="of" />
            <token id="38" string="Labor" />
          </tokens>
        </chunking>
        <chunking id="4" string="represented the conservative viewpoint in her jobs as a staffer for a Republican congressman , spokeswoman at the U.S. Chamber of Congress and deputy assistant secretary at the Department of Labor" type="VP">
          <tokens>
            <token id="8" string="represented" />
            <token id="9" string="the" />
            <token id="10" string="conservative" />
            <token id="11" string="viewpoint" />
            <token id="12" string="in" />
            <token id="13" string="her" />
            <token id="14" string="jobs" />
            <token id="15" string="as" />
            <token id="16" string="a" />
            <token id="17" string="staffer" />
            <token id="18" string="for" />
            <token id="19" string="a" />
            <token id="20" string="Republican" />
            <token id="21" string="congressman" />
            <token id="22" string="," />
            <token id="23" string="spokeswoman" />
            <token id="24" string="at" />
            <token id="25" string="the" />
            <token id="26" string="U.S." />
            <token id="27" string="Chamber" />
            <token id="28" string="of" />
            <token id="29" string="Congress" />
            <token id="30" string="and" />
            <token id="31" string="deputy" />
            <token id="32" string="assistant" />
            <token id="33" string="secretary" />
            <token id="34" string="at" />
            <token id="35" string="the" />
            <token id="36" string="Department" />
            <token id="37" string="of" />
            <token id="38" string="Labor" />
          </tokens>
        </chunking>
        <chunking id="5" string="spokeswoman at the U.S. Chamber of Congress" type="NP">
          <tokens>
            <token id="23" string="spokeswoman" />
            <token id="24" string="at" />
            <token id="25" string="the" />
            <token id="26" string="U.S." />
            <token id="27" string="Chamber" />
            <token id="28" string="of" />
            <token id="29" string="Congress" />
          </tokens>
        </chunking>
        <chunking id="6" string="the Department" type="NP">
          <tokens>
            <token id="35" string="the" />
            <token id="36" string="Department" />
          </tokens>
        </chunking>
        <chunking id="7" string="the conservative viewpoint in her jobs" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="conservative" />
            <token id="11" string="viewpoint" />
            <token id="12" string="in" />
            <token id="13" string="her" />
            <token id="14" string="jobs" />
          </tokens>
        </chunking>
        <chunking id="8" string="the conservative viewpoint" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="conservative" />
            <token id="11" string="viewpoint" />
          </tokens>
        </chunking>
        <chunking id="9" string="deputy assistant secretary" type="NP">
          <tokens>
            <token id="31" string="deputy" />
            <token id="32" string="assistant" />
            <token id="33" string="secretary" />
          </tokens>
        </chunking>
        <chunking id="10" string="her jobs" type="NP">
          <tokens>
            <token id="13" string="her" />
            <token id="14" string="jobs" />
          </tokens>
        </chunking>
        <chunking id="11" string="the Department of Labor" type="NP">
          <tokens>
            <token id="35" string="the" />
            <token id="36" string="Department" />
            <token id="37" string="of" />
            <token id="38" string="Labor" />
          </tokens>
        </chunking>
        <chunking id="12" string="Congress" type="NP">
          <tokens>
            <token id="29" string="Congress" />
          </tokens>
        </chunking>
        <chunking id="13" string="Labor" type="NP">
          <tokens>
            <token id="38" string="Labor" />
          </tokens>
        </chunking>
        <chunking id="14" string="a staffer" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="staffer" />
          </tokens>
        </chunking>
        <chunking id="15" string="Virginia Thomas" type="NP">
          <tokens>
            <token id="5" string="Virginia" />
            <token id="6" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="16" string="the U.S. Chamber" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="U.S." />
            <token id="27" string="Chamber" />
          </tokens>
        </chunking>
        <chunking id="17" string="deputy assistant secretary at the Department of Labor" type="NP">
          <tokens>
            <token id="31" string="deputy" />
            <token id="32" string="assistant" />
            <token id="33" string="secretary" />
            <token id="34" string="at" />
            <token id="35" string="the" />
            <token id="36" string="Department" />
            <token id="37" string="of" />
            <token id="38" string="Labor" />
          </tokens>
        </chunking>
        <chunking id="18" string="a staffer for a Republican congressman , spokeswoman at the U.S. Chamber of Congress and deputy assistant secretary at the Department of Labor" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="staffer" />
            <token id="18" string="for" />
            <token id="19" string="a" />
            <token id="20" string="Republican" />
            <token id="21" string="congressman" />
            <token id="22" string="," />
            <token id="23" string="spokeswoman" />
            <token id="24" string="at" />
            <token id="25" string="the" />
            <token id="26" string="U.S." />
            <token id="27" string="Chamber" />
            <token id="28" string="of" />
            <token id="29" string="Congress" />
            <token id="30" string="and" />
            <token id="31" string="deputy" />
            <token id="32" string="assistant" />
            <token id="33" string="secretary" />
            <token id="34" string="at" />
            <token id="35" string="the" />
            <token id="36" string="Department" />
            <token id="37" string="of" />
            <token id="38" string="Labor" />
          </tokens>
        </chunking>
        <chunking id="19" string="a staffer for a Republican congressman" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="staffer" />
            <token id="18" string="for" />
            <token id="19" string="a" />
            <token id="20" string="Republican" />
            <token id="21" string="congressman" />
          </tokens>
        </chunking>
        <chunking id="20" string="Conservative viewpoint" type="NP">
          <tokens>
            <token id="2" string="Conservative" />
            <token id="3" string="viewpoint" />
          </tokens>
        </chunking>
        <chunking id="21" string="a Republican congressman" type="NP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="Republican" />
            <token id="21" string="congressman" />
          </tokens>
        </chunking>
        <chunking id="22" string="Conservative viewpoint ; Virginia Thomas" type="NP">
          <tokens>
            <token id="2" string="Conservative" />
            <token id="3" string="viewpoint" />
            <token id="4" string=";" />
            <token id="5" string="Virginia" />
            <token id="6" string="Thomas" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">viewpoint</governor>
          <dependent id="2">Conservative</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">represented</governor>
          <dependent id="3">viewpoint</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Thomas</governor>
          <dependent id="5">Virginia</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="3">viewpoint</governor>
          <dependent id="6">Thomas</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">represented</governor>
          <dependent id="7">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">represented</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">viewpoint</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">viewpoint</governor>
          <dependent id="10">conservative</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">represented</governor>
          <dependent id="11">viewpoint</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">jobs</governor>
          <dependent id="12">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">jobs</governor>
          <dependent id="13">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">viewpoint</governor>
          <dependent id="14">jobs</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">staffer</governor>
          <dependent id="15">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">staffer</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">represented</governor>
          <dependent id="17">staffer</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">congressman</governor>
          <dependent id="18">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">congressman</governor>
          <dependent id="19">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">congressman</governor>
          <dependent id="20">Republican</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">staffer</governor>
          <dependent id="21">congressman</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">staffer</governor>
          <dependent id="23">spokeswoman</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">Chamber</governor>
          <dependent id="24">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">Chamber</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">Chamber</governor>
          <dependent id="26">U.S.</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">spokeswoman</governor>
          <dependent id="27">Chamber</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">Congress</governor>
          <dependent id="28">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">Chamber</governor>
          <dependent id="29">Congress</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">staffer</governor>
          <dependent id="30">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="33">secretary</governor>
          <dependent id="31">deputy</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="33">secretary</governor>
          <dependent id="32">assistant</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">staffer</governor>
          <dependent id="33">secretary</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">Department</governor>
          <dependent id="34">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="36">Department</governor>
          <dependent id="35">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">secretary</governor>
          <dependent id="36">Department</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">Labor</governor>
          <dependent id="37">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="36">Department</governor>
          <dependent id="38">Labor</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="U.S. Chamber of Congress" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="26" string="U.S." />
            <token id="27" string="Chamber" />
            <token id="28" string="of" />
            <token id="29" string="Congress" />
          </tokens>
        </entity>
        <entity id="2" string="conservative" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="10" string="conservative" />
          </tokens>
        </entity>
        <entity id="3" string="Virginia Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Virginia" />
            <token id="6" string="Thomas" />
          </tokens>
        </entity>
        <entity id="4" string="Conservative" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="2" string="Conservative" />
          </tokens>
        </entity>
        <entity id="5" string="Republican" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="20" string="Republican" />
          </tokens>
        </entity>
        <entity id="6" string="Department of Labor" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="36" string="Department" />
            <token id="37" string="of" />
            <token id="38" string="Labor" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>Clarence Thomas advocates a colorblind society, and his marriage may be an example of that philosophy.</content>
      <tokens>
        <token id="1" string="Clarence" lemma="Clarence" stem="clarenc" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="advocates" lemma="advocate" stem="advoc" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="colorblind" lemma="colorblind" stem="colorblind" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="society" lemma="society" stem="societi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="marriage" lemma="marriage" stem="marriag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="example" lemma="example" stem="exampl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="philosophy" lemma="philosophy" stem="philosophi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNP Clarence) (NNP Thomas)) (VP (VBZ advocates) (NP (DT a) (JJ colorblind) (NN society)))) (, ,) (CC and) (S (NP (PRP$ his) (NN marriage)) (VP (MD may) (VP (VB be) (NP (NP (DT an) (NN example)) (PP (IN of) (NP (DT that) (NN philosophy))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="an example" type="NP">
          <tokens>
            <token id="13" string="an" />
            <token id="14" string="example" />
          </tokens>
        </chunking>
        <chunking id="2" string="be an example of that philosophy" type="VP">
          <tokens>
            <token id="12" string="be" />
            <token id="13" string="an" />
            <token id="14" string="example" />
            <token id="15" string="of" />
            <token id="16" string="that" />
            <token id="17" string="philosophy" />
          </tokens>
        </chunking>
        <chunking id="3" string="an example of that philosophy" type="NP">
          <tokens>
            <token id="13" string="an" />
            <token id="14" string="example" />
            <token id="15" string="of" />
            <token id="16" string="that" />
            <token id="17" string="philosophy" />
          </tokens>
        </chunking>
        <chunking id="4" string="may be an example of that philosophy" type="VP">
          <tokens>
            <token id="11" string="may" />
            <token id="12" string="be" />
            <token id="13" string="an" />
            <token id="14" string="example" />
            <token id="15" string="of" />
            <token id="16" string="that" />
            <token id="17" string="philosophy" />
          </tokens>
        </chunking>
        <chunking id="5" string="advocates a colorblind society" type="VP">
          <tokens>
            <token id="3" string="advocates" />
            <token id="4" string="a" />
            <token id="5" string="colorblind" />
            <token id="6" string="society" />
          </tokens>
        </chunking>
        <chunking id="6" string="his marriage" type="NP">
          <tokens>
            <token id="9" string="his" />
            <token id="10" string="marriage" />
          </tokens>
        </chunking>
        <chunking id="7" string="that philosophy" type="NP">
          <tokens>
            <token id="16" string="that" />
            <token id="17" string="philosophy" />
          </tokens>
        </chunking>
        <chunking id="8" string="a colorblind society" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="colorblind" />
            <token id="6" string="society" />
          </tokens>
        </chunking>
        <chunking id="9" string="Clarence Thomas" type="NP">
          <tokens>
            <token id="1" string="Clarence" />
            <token id="2" string="Thomas" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Thomas</governor>
          <dependent id="1">Clarence</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">advocates</governor>
          <dependent id="2">Thomas</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">advocates</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">society</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">society</governor>
          <dependent id="5">colorblind</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">advocates</governor>
          <dependent id="6">society</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">advocates</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">marriage</governor>
          <dependent id="9">his</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">example</governor>
          <dependent id="10">marriage</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">example</governor>
          <dependent id="11">may</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">example</governor>
          <dependent id="12">be</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">example</governor>
          <dependent id="13">an</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">advocates</governor>
          <dependent id="14">example</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">philosophy</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">philosophy</governor>
          <dependent id="16">that</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">example</governor>
          <dependent id="17">philosophy</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Clarence Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Clarence" />
            <token id="2" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="false">
      <content>But others see a different symbolism.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="others" lemma="other" stem="other" pos="NNS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="see" lemma="see" stem="see" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="different" lemma="different" stem="differ" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="symbolism" lemma="symbolism" stem="symbol" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (NNS others)) (VP (VBP see) (NP (DT a) (JJ different) (NN symbolism))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="see a different symbolism" type="VP">
          <tokens>
            <token id="3" string="see" />
            <token id="4" string="a" />
            <token id="5" string="different" />
            <token id="6" string="symbolism" />
          </tokens>
        </chunking>
        <chunking id="2" string="a different symbolism" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="different" />
            <token id="6" string="symbolism" />
          </tokens>
        </chunking>
        <chunking id="3" string="others" type="NP">
          <tokens>
            <token id="2" string="others" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="3">see</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">see</governor>
          <dependent id="2">others</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">see</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">symbolism</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">symbolism</governor>
          <dependent id="5">different</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">see</governor>
          <dependent id="6">symbolism</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>&amp;quot;His marrying a white woman is a sign of his rejection of the black community,&amp;quot; said Russell Adams, chairman of Howard University&amp;apost;s department of Afro-American studies.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="His" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="marrying" lemma="marry" stem="marri" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="white" lemma="white" stem="white" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="woman" lemma="woman" stem="woman" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="sign" lemma="sign" stem="sign" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="rejection" lemma="rejection" stem="reject" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="black" lemma="black" stem="black" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="community" lemma="community" stem="commun" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="Russell" lemma="Russell" stem="russel" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="21" string="Adams" lemma="Adams" stem="adam" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="chairman" lemma="chairman" stem="chairman" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="Howard" lemma="Howard" stem="howard" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="26" string="University" lemma="University" stem="univers" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="27" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="department" lemma="department" stem="depart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="Afro-American" lemma="afro-american" stem="afro-american" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="31" string="studies" lemma="study" stem="studi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (NP (PRP$ His)) (VP (VBG marrying) (NP (DT a) (JJ white) (NN woman)))) (VP (VBZ is) (NP (NP (DT a) (NN sign)) (PP (IN of) (NP (NP (PRP$ his) (NN rejection)) (PP (IN of) (NP (DT the) (JJ black) (NN community)))))))) (, ,) ('' '') (VP (VBD said)) (NP (NP (NNP Russell) (NNP Adams)) (, ,) (NP (NP (NN chairman)) (PP (IN of) (NP (NP (NP (NNP Howard) (NNP University) (POS 's)) (NN department)) (PP (IN of) (NP (JJ Afro-American) (NNS studies))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a white woman" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="white" />
            <token id="6" string="woman" />
          </tokens>
        </chunking>
        <chunking id="2" string="Howard University 's department of Afro-American studies" type="NP">
          <tokens>
            <token id="25" string="Howard" />
            <token id="26" string="University" />
            <token id="27" string="'s" />
            <token id="28" string="department" />
            <token id="29" string="of" />
            <token id="30" string="Afro-American" />
            <token id="31" string="studies" />
          </tokens>
        </chunking>
        <chunking id="3" string="a sign" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="sign" />
          </tokens>
        </chunking>
        <chunking id="4" string="Russell Adams" type="NP">
          <tokens>
            <token id="20" string="Russell" />
            <token id="21" string="Adams" />
          </tokens>
        </chunking>
        <chunking id="5" string="marrying a white woman" type="VP">
          <tokens>
            <token id="3" string="marrying" />
            <token id="4" string="a" />
            <token id="5" string="white" />
            <token id="6" string="woman" />
          </tokens>
        </chunking>
        <chunking id="6" string="is a sign of his rejection of the black community" type="VP">
          <tokens>
            <token id="7" string="is" />
            <token id="8" string="a" />
            <token id="9" string="sign" />
            <token id="10" string="of" />
            <token id="11" string="his" />
            <token id="12" string="rejection" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="black" />
            <token id="16" string="community" />
          </tokens>
        </chunking>
        <chunking id="7" string="chairman" type="NP">
          <tokens>
            <token id="23" string="chairman" />
          </tokens>
        </chunking>
        <chunking id="8" string="Howard University 's" type="NP">
          <tokens>
            <token id="25" string="Howard" />
            <token id="26" string="University" />
            <token id="27" string="'s" />
          </tokens>
        </chunking>
        <chunking id="9" string="His" type="NP">
          <tokens>
            <token id="2" string="His" />
          </tokens>
        </chunking>
        <chunking id="10" string="a sign of his rejection of the black community" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="sign" />
            <token id="10" string="of" />
            <token id="11" string="his" />
            <token id="12" string="rejection" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="black" />
            <token id="16" string="community" />
          </tokens>
        </chunking>
        <chunking id="11" string="Howard University 's department" type="NP">
          <tokens>
            <token id="25" string="Howard" />
            <token id="26" string="University" />
            <token id="27" string="'s" />
            <token id="28" string="department" />
          </tokens>
        </chunking>
        <chunking id="12" string="His marrying a white woman" type="NP">
          <tokens>
            <token id="2" string="His" />
            <token id="3" string="marrying" />
            <token id="4" string="a" />
            <token id="5" string="white" />
            <token id="6" string="woman" />
          </tokens>
        </chunking>
        <chunking id="13" string="the black community" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="black" />
            <token id="16" string="community" />
          </tokens>
        </chunking>
        <chunking id="14" string="his rejection" type="NP">
          <tokens>
            <token id="11" string="his" />
            <token id="12" string="rejection" />
          </tokens>
        </chunking>
        <chunking id="15" string="his rejection of the black community" type="NP">
          <tokens>
            <token id="11" string="his" />
            <token id="12" string="rejection" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="black" />
            <token id="16" string="community" />
          </tokens>
        </chunking>
        <chunking id="16" string="Afro-American studies" type="NP">
          <tokens>
            <token id="30" string="Afro-American" />
            <token id="31" string="studies" />
          </tokens>
        </chunking>
        <chunking id="17" string="said" type="VP">
          <tokens>
            <token id="19" string="said" />
          </tokens>
        </chunking>
        <chunking id="18" string="Russell Adams , chairman of Howard University 's department of Afro-American studies" type="NP">
          <tokens>
            <token id="20" string="Russell" />
            <token id="21" string="Adams" />
            <token id="22" string="," />
            <token id="23" string="chairman" />
            <token id="24" string="of" />
            <token id="25" string="Howard" />
            <token id="26" string="University" />
            <token id="27" string="'s" />
            <token id="28" string="department" />
            <token id="29" string="of" />
            <token id="30" string="Afro-American" />
            <token id="31" string="studies" />
          </tokens>
        </chunking>
        <chunking id="19" string="chairman of Howard University 's department of Afro-American studies" type="NP">
          <tokens>
            <token id="23" string="chairman" />
            <token id="24" string="of" />
            <token id="25" string="Howard" />
            <token id="26" string="University" />
            <token id="27" string="'s" />
            <token id="28" string="department" />
            <token id="29" string="of" />
            <token id="30" string="Afro-American" />
            <token id="31" string="studies" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="9">sign</governor>
          <dependent id="2">His</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="2">His</governor>
          <dependent id="3">marrying</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">woman</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">woman</governor>
          <dependent id="5">white</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">marrying</governor>
          <dependent id="6">woman</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="9">sign</governor>
          <dependent id="7">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">sign</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">said</governor>
          <dependent id="9">sign</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">rejection</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">rejection</governor>
          <dependent id="11">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">sign</governor>
          <dependent id="12">rejection</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">community</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">community</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">community</governor>
          <dependent id="15">black</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">rejection</governor>
          <dependent id="16">community</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="19">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">Adams</governor>
          <dependent id="20">Russell</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">said</governor>
          <dependent id="21">Adams</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="21">Adams</governor>
          <dependent id="23">chairman</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">department</governor>
          <dependent id="24">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">University</governor>
          <dependent id="25">Howard</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="28">department</governor>
          <dependent id="26">University</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">University</governor>
          <dependent id="27">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">chairman</governor>
          <dependent id="28">department</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">studies</governor>
          <dependent id="29">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">studies</governor>
          <dependent id="30">Afro-American</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">department</governor>
          <dependent id="31">studies</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Afro-American" type="MISC" score="0.0">
          <tokens>
            <token id="30" string="Afro-American" />
          </tokens>
        </entity>
        <entity id="2" string="Russell Adams" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="Russell" />
            <token id="21" string="Adams" />
          </tokens>
        </entity>
        <entity id="3" string="Howard University" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="25" string="Howard" />
            <token id="26" string="University" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="false">
      <content>&amp;quot;Great justices have had community roots that served as a basis for understanding the Constitution.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Great" lemma="great" stem="great" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="justices" lemma="justice" stem="justic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="had" lemma="have" stem="had" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="community" lemma="community" stem="commun" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="roots" lemma="root" stem="root" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="served" lemma="serve" stem="serv" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="basis" lemma="basis" stem="basi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="understanding" lemma="understand" stem="understand" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="Constitution" lemma="Constitution" stem="constitut" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (JJ Great) (NNS justices)) (VP (VBP have) (VP (VBN had) (NP (NP (NN community) (NNS roots)) (SBAR (WHNP (WDT that)) (S (VP (VBD served) (PP (IN as) (NP (DT a) (NN basis))) (PP (IN for) (S (VP (VBG understanding) (NP (DT the) (NNP Constitution))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="had community roots that served as a basis for understanding the Constitution" type="VP">
          <tokens>
            <token id="5" string="had" />
            <token id="6" string="community" />
            <token id="7" string="roots" />
            <token id="8" string="that" />
            <token id="9" string="served" />
            <token id="10" string="as" />
            <token id="11" string="a" />
            <token id="12" string="basis" />
            <token id="13" string="for" />
            <token id="14" string="understanding" />
            <token id="15" string="the" />
            <token id="16" string="Constitution" />
          </tokens>
        </chunking>
        <chunking id="2" string="Great justices" type="NP">
          <tokens>
            <token id="2" string="Great" />
            <token id="3" string="justices" />
          </tokens>
        </chunking>
        <chunking id="3" string="have had community roots that served as a basis for understanding the Constitution" type="VP">
          <tokens>
            <token id="4" string="have" />
            <token id="5" string="had" />
            <token id="6" string="community" />
            <token id="7" string="roots" />
            <token id="8" string="that" />
            <token id="9" string="served" />
            <token id="10" string="as" />
            <token id="11" string="a" />
            <token id="12" string="basis" />
            <token id="13" string="for" />
            <token id="14" string="understanding" />
            <token id="15" string="the" />
            <token id="16" string="Constitution" />
          </tokens>
        </chunking>
        <chunking id="4" string="understanding the Constitution" type="VP">
          <tokens>
            <token id="14" string="understanding" />
            <token id="15" string="the" />
            <token id="16" string="Constitution" />
          </tokens>
        </chunking>
        <chunking id="5" string="a basis" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="basis" />
          </tokens>
        </chunking>
        <chunking id="6" string="the Constitution" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="Constitution" />
          </tokens>
        </chunking>
        <chunking id="7" string="community roots that served as a basis for understanding the Constitution" type="NP">
          <tokens>
            <token id="6" string="community" />
            <token id="7" string="roots" />
            <token id="8" string="that" />
            <token id="9" string="served" />
            <token id="10" string="as" />
            <token id="11" string="a" />
            <token id="12" string="basis" />
            <token id="13" string="for" />
            <token id="14" string="understanding" />
            <token id="15" string="the" />
            <token id="16" string="Constitution" />
          </tokens>
        </chunking>
        <chunking id="8" string="that served as a basis for understanding the Constitution" type="SBAR">
          <tokens>
            <token id="8" string="that" />
            <token id="9" string="served" />
            <token id="10" string="as" />
            <token id="11" string="a" />
            <token id="12" string="basis" />
            <token id="13" string="for" />
            <token id="14" string="understanding" />
            <token id="15" string="the" />
            <token id="16" string="Constitution" />
          </tokens>
        </chunking>
        <chunking id="9" string="community roots" type="NP">
          <tokens>
            <token id="6" string="community" />
            <token id="7" string="roots" />
          </tokens>
        </chunking>
        <chunking id="10" string="served as a basis for understanding the Constitution" type="VP">
          <tokens>
            <token id="9" string="served" />
            <token id="10" string="as" />
            <token id="11" string="a" />
            <token id="12" string="basis" />
            <token id="13" string="for" />
            <token id="14" string="understanding" />
            <token id="15" string="the" />
            <token id="16" string="Constitution" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="3">justices</governor>
          <dependent id="2">Great</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">had</governor>
          <dependent id="3">justices</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">had</governor>
          <dependent id="4">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">had</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">roots</governor>
          <dependent id="6">community</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">had</governor>
          <dependent id="7">roots</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">served</governor>
          <dependent id="8">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="7">roots</governor>
          <dependent id="9">served</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">basis</governor>
          <dependent id="10">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">basis</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">served</governor>
          <dependent id="12">basis</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">understanding</governor>
          <dependent id="13">for</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">served</governor>
          <dependent id="14">understanding</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">Constitution</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">understanding</governor>
          <dependent id="16">Constitution</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>Clarence&amp;apost;s lack of a sense of community makes his nomination troubling.&amp;quot;</content>
      <tokens>
        <token id="1" string="Clarence" lemma="Clarence" stem="clarenc" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="lack" lemma="lack" stem="lack" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="sense" lemma="sense" stem="sens" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="community" lemma="community" stem="commun" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="makes" lemma="make" stem="make" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="nomination" lemma="nomination" stem="nomin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="troubling" lemma="trouble" stem="troubl" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NP (NNP Clarence) (POS 's)) (NN lack)) (PP (IN of) (NP (NP (DT a) (NN sense)) (PP (IN of) (NP (NN community)))))) (VP (VBZ makes) (S (NP (PRP$ his) (NN nomination)) (NP (VBG troubling)))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="Clarence 's" type="NP">
          <tokens>
            <token id="1" string="Clarence" />
            <token id="2" string="'s" />
          </tokens>
        </chunking>
        <chunking id="2" string="Clarence 's lack of a sense of community" type="NP">
          <tokens>
            <token id="1" string="Clarence" />
            <token id="2" string="'s" />
            <token id="3" string="lack" />
            <token id="4" string="of" />
            <token id="5" string="a" />
            <token id="6" string="sense" />
            <token id="7" string="of" />
            <token id="8" string="community" />
          </tokens>
        </chunking>
        <chunking id="3" string="a sense of community" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="sense" />
            <token id="7" string="of" />
            <token id="8" string="community" />
          </tokens>
        </chunking>
        <chunking id="4" string="a sense" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="sense" />
          </tokens>
        </chunking>
        <chunking id="5" string="his nomination" type="NP">
          <tokens>
            <token id="10" string="his" />
            <token id="11" string="nomination" />
          </tokens>
        </chunking>
        <chunking id="6" string="Clarence 's lack" type="NP">
          <tokens>
            <token id="1" string="Clarence" />
            <token id="2" string="'s" />
            <token id="3" string="lack" />
          </tokens>
        </chunking>
        <chunking id="7" string="troubling" type="NP">
          <tokens>
            <token id="12" string="troubling" />
          </tokens>
        </chunking>
        <chunking id="8" string="community" type="NP">
          <tokens>
            <token id="8" string="community" />
          </tokens>
        </chunking>
        <chunking id="9" string="makes his nomination troubling" type="VP">
          <tokens>
            <token id="9" string="makes" />
            <token id="10" string="his" />
            <token id="11" string="nomination" />
            <token id="12" string="troubling" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="3">lack</governor>
          <dependent id="1">Clarence</dependent>
        </dependency>
        <dependency type="case">
          <governor id="1">Clarence</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">makes</governor>
          <dependent id="3">lack</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">sense</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">sense</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">lack</governor>
          <dependent id="6">sense</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">community</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">sense</governor>
          <dependent id="8">community</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">makes</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">nomination</governor>
          <dependent id="10">his</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">troubling</governor>
          <dependent id="11">nomination</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">makes</governor>
          <dependent id="12">troubling</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Clarence" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Clarence" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="false">
      <content>; Religious leaders wonder; Some religious leaders are troubled as well.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Religious" lemma="religious" stem="religi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="leaders" lemma="leader" stem="leader" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="wonder" lemma="wonder" stem="wonder" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="religious" lemma="religious" stem="religi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="leaders" lemma="leader" stem="leader" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="troubled" lemma="trouble" stem="troubl" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="as" lemma="as" stem="a" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="well" lemma="well" stem="well" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (S (NP (JJ Religious) (NNS leaders)) (VP (VBP wonder))) (: ;) (S (NP (DT Some) (JJ religious) (NNS leaders)) (VP (VBP are) (VP (VBN troubled) (ADVP (RB as) (RB well))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Religious leaders" type="NP">
          <tokens>
            <token id="2" string="Religious" />
            <token id="3" string="leaders" />
          </tokens>
        </chunking>
        <chunking id="2" string="are troubled as well" type="VP">
          <tokens>
            <token id="9" string="are" />
            <token id="10" string="troubled" />
            <token id="11" string="as" />
            <token id="12" string="well" />
          </tokens>
        </chunking>
        <chunking id="3" string="wonder" type="VP">
          <tokens>
            <token id="4" string="wonder" />
          </tokens>
        </chunking>
        <chunking id="4" string="troubled as well" type="VP">
          <tokens>
            <token id="10" string="troubled" />
            <token id="11" string="as" />
            <token id="12" string="well" />
          </tokens>
        </chunking>
        <chunking id="5" string="Some religious leaders" type="NP">
          <tokens>
            <token id="6" string="Some" />
            <token id="7" string="religious" />
            <token id="8" string="leaders" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="3">leaders</governor>
          <dependent id="2">Religious</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">wonder</governor>
          <dependent id="3">leaders</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">wonder</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">leaders</governor>
          <dependent id="6">Some</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">leaders</governor>
          <dependent id="7">religious</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="10">troubled</governor>
          <dependent id="8">leaders</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="10">troubled</governor>
          <dependent id="9">are</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="4">wonder</governor>
          <dependent id="10">troubled</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">troubled</governor>
          <dependent id="11">as</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="11">as</governor>
          <dependent id="12">well</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>Dean Kelley, the National Council of Churches&amp;apost; counselor on religious liberty, wrote a critique of Clarence Thomas that was used as grounds for his organization&amp;apost;s opposition to the Supreme Court nominee.</content>
      <tokens>
        <token id="1" string="Dean" lemma="Dean" stem="dean" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Kelley" lemma="Kelley" stem="kellei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="National" lemma="National" stem="nation" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="6" string="Council" lemma="Council" stem="council" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="8" string="Churches" lemma="Churches" stem="church" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="9" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="counselor" lemma="counselor" stem="counselor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="religious" lemma="religious" stem="religi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="liberty" lemma="liberty" stem="liberti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="wrote" lemma="write" stem="wrote" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="critique" lemma="critique" stem="critiqu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Clarence" lemma="Clarence" stem="clarenc" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="20" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="21" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="used" lemma="use" stem="us" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="24" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="grounds" lemma="grounds" stem="ground" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="26" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="28" string="organization" lemma="organization" stem="organ" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="29" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="30" string="opposition" lemma="opposition" stem="opposit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="31" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="32" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="33" string="Supreme" lemma="Supreme" stem="suprem" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="34" string="Court" lemma="Court" stem="court" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="35" string="nominee" lemma="nominee" stem="nomine" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Dean) (NNP Kelley)) (, ,) (NP (NP (DT the) (NNP National) (NNP Council)) (PP (IN of) (NP (NP (NP (NNP Churches) (POS ')) (NN counselor)) (PP (IN on) (NP (JJ religious) (NN liberty)))))) (, ,)) (VP (VBD wrote) (NP (NP (DT a) (NN critique)) (PP (IN of) (NP (NP (NNP Clarence) (NNP Thomas)) (SBAR (WHNP (WDT that)) (S (VP (VBD was) (VP (VBN used) (PP (IN as) (NP (NP (NNS grounds)) (PP (IN for) (NP (NP (PRP$ his) (NN organization) (POS 's)) (NN opposition))))) (PP (TO to) (NP (DT the) (NNP Supreme) (NNP Court) (NN nominee))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Churches ' counselor" type="NP">
          <tokens>
            <token id="8" string="Churches" />
            <token id="9" string="'" />
            <token id="10" string="counselor" />
          </tokens>
        </chunking>
        <chunking id="2" string="wrote a critique of Clarence Thomas that was used as grounds for his organization 's opposition to the Supreme Court nominee" type="VP">
          <tokens>
            <token id="15" string="wrote" />
            <token id="16" string="a" />
            <token id="17" string="critique" />
            <token id="18" string="of" />
            <token id="19" string="Clarence" />
            <token id="20" string="Thomas" />
            <token id="21" string="that" />
            <token id="22" string="was" />
            <token id="23" string="used" />
            <token id="24" string="as" />
            <token id="25" string="grounds" />
            <token id="26" string="for" />
            <token id="27" string="his" />
            <token id="28" string="organization" />
            <token id="29" string="'s" />
            <token id="30" string="opposition" />
            <token id="31" string="to" />
            <token id="32" string="the" />
            <token id="33" string="Supreme" />
            <token id="34" string="Court" />
            <token id="35" string="nominee" />
          </tokens>
        </chunking>
        <chunking id="3" string="the Supreme Court nominee" type="NP">
          <tokens>
            <token id="32" string="the" />
            <token id="33" string="Supreme" />
            <token id="34" string="Court" />
            <token id="35" string="nominee" />
          </tokens>
        </chunking>
        <chunking id="4" string="that was used as grounds for his organization 's opposition to the Supreme Court nominee" type="SBAR">
          <tokens>
            <token id="21" string="that" />
            <token id="22" string="was" />
            <token id="23" string="used" />
            <token id="24" string="as" />
            <token id="25" string="grounds" />
            <token id="26" string="for" />
            <token id="27" string="his" />
            <token id="28" string="organization" />
            <token id="29" string="'s" />
            <token id="30" string="opposition" />
            <token id="31" string="to" />
            <token id="32" string="the" />
            <token id="33" string="Supreme" />
            <token id="34" string="Court" />
            <token id="35" string="nominee" />
          </tokens>
        </chunking>
        <chunking id="5" string="his organization 's opposition" type="NP">
          <tokens>
            <token id="27" string="his" />
            <token id="28" string="organization" />
            <token id="29" string="'s" />
            <token id="30" string="opposition" />
          </tokens>
        </chunking>
        <chunking id="6" string="Clarence Thomas that was used as grounds for his organization 's opposition to the Supreme Court nominee" type="NP">
          <tokens>
            <token id="19" string="Clarence" />
            <token id="20" string="Thomas" />
            <token id="21" string="that" />
            <token id="22" string="was" />
            <token id="23" string="used" />
            <token id="24" string="as" />
            <token id="25" string="grounds" />
            <token id="26" string="for" />
            <token id="27" string="his" />
            <token id="28" string="organization" />
            <token id="29" string="'s" />
            <token id="30" string="opposition" />
            <token id="31" string="to" />
            <token id="32" string="the" />
            <token id="33" string="Supreme" />
            <token id="34" string="Court" />
            <token id="35" string="nominee" />
          </tokens>
        </chunking>
        <chunking id="7" string="grounds for his organization 's opposition" type="NP">
          <tokens>
            <token id="25" string="grounds" />
            <token id="26" string="for" />
            <token id="27" string="his" />
            <token id="28" string="organization" />
            <token id="29" string="'s" />
            <token id="30" string="opposition" />
          </tokens>
        </chunking>
        <chunking id="8" string="Churches ' counselor on religious liberty" type="NP">
          <tokens>
            <token id="8" string="Churches" />
            <token id="9" string="'" />
            <token id="10" string="counselor" />
            <token id="11" string="on" />
            <token id="12" string="religious" />
            <token id="13" string="liberty" />
          </tokens>
        </chunking>
        <chunking id="9" string="a critique" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="critique" />
          </tokens>
        </chunking>
        <chunking id="10" string="his organization 's" type="NP">
          <tokens>
            <token id="27" string="his" />
            <token id="28" string="organization" />
            <token id="29" string="'s" />
          </tokens>
        </chunking>
        <chunking id="11" string="the National Council of Churches ' counselor on religious liberty" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="National" />
            <token id="6" string="Council" />
            <token id="7" string="of" />
            <token id="8" string="Churches" />
            <token id="9" string="'" />
            <token id="10" string="counselor" />
            <token id="11" string="on" />
            <token id="12" string="religious" />
            <token id="13" string="liberty" />
          </tokens>
        </chunking>
        <chunking id="12" string="Dean Kelley" type="NP">
          <tokens>
            <token id="1" string="Dean" />
            <token id="2" string="Kelley" />
          </tokens>
        </chunking>
        <chunking id="13" string="Dean Kelley , the National Council of Churches ' counselor on religious liberty ," type="NP">
          <tokens>
            <token id="1" string="Dean" />
            <token id="2" string="Kelley" />
            <token id="3" string="," />
            <token id="4" string="the" />
            <token id="5" string="National" />
            <token id="6" string="Council" />
            <token id="7" string="of" />
            <token id="8" string="Churches" />
            <token id="9" string="'" />
            <token id="10" string="counselor" />
            <token id="11" string="on" />
            <token id="12" string="religious" />
            <token id="13" string="liberty" />
            <token id="14" string="," />
          </tokens>
        </chunking>
        <chunking id="14" string="Churches '" type="NP">
          <tokens>
            <token id="8" string="Churches" />
            <token id="9" string="'" />
          </tokens>
        </chunking>
        <chunking id="15" string="grounds" type="NP">
          <tokens>
            <token id="25" string="grounds" />
          </tokens>
        </chunking>
        <chunking id="16" string="a critique of Clarence Thomas that was used as grounds for his organization 's opposition to the Supreme Court nominee" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="critique" />
            <token id="18" string="of" />
            <token id="19" string="Clarence" />
            <token id="20" string="Thomas" />
            <token id="21" string="that" />
            <token id="22" string="was" />
            <token id="23" string="used" />
            <token id="24" string="as" />
            <token id="25" string="grounds" />
            <token id="26" string="for" />
            <token id="27" string="his" />
            <token id="28" string="organization" />
            <token id="29" string="'s" />
            <token id="30" string="opposition" />
            <token id="31" string="to" />
            <token id="32" string="the" />
            <token id="33" string="Supreme" />
            <token id="34" string="Court" />
            <token id="35" string="nominee" />
          </tokens>
        </chunking>
        <chunking id="17" string="was used as grounds for his organization 's opposition to the Supreme Court nominee" type="VP">
          <tokens>
            <token id="22" string="was" />
            <token id="23" string="used" />
            <token id="24" string="as" />
            <token id="25" string="grounds" />
            <token id="26" string="for" />
            <token id="27" string="his" />
            <token id="28" string="organization" />
            <token id="29" string="'s" />
            <token id="30" string="opposition" />
            <token id="31" string="to" />
            <token id="32" string="the" />
            <token id="33" string="Supreme" />
            <token id="34" string="Court" />
            <token id="35" string="nominee" />
          </tokens>
        </chunking>
        <chunking id="18" string="the National Council" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="National" />
            <token id="6" string="Council" />
          </tokens>
        </chunking>
        <chunking id="19" string="used as grounds for his organization 's opposition to the Supreme Court nominee" type="VP">
          <tokens>
            <token id="23" string="used" />
            <token id="24" string="as" />
            <token id="25" string="grounds" />
            <token id="26" string="for" />
            <token id="27" string="his" />
            <token id="28" string="organization" />
            <token id="29" string="'s" />
            <token id="30" string="opposition" />
            <token id="31" string="to" />
            <token id="32" string="the" />
            <token id="33" string="Supreme" />
            <token id="34" string="Court" />
            <token id="35" string="nominee" />
          </tokens>
        </chunking>
        <chunking id="20" string="religious liberty" type="NP">
          <tokens>
            <token id="12" string="religious" />
            <token id="13" string="liberty" />
          </tokens>
        </chunking>
        <chunking id="21" string="Clarence Thomas" type="NP">
          <tokens>
            <token id="19" string="Clarence" />
            <token id="20" string="Thomas" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Kelley</governor>
          <dependent id="1">Dean</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">wrote</governor>
          <dependent id="2">Kelley</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">Council</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Council</governor>
          <dependent id="5">National</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">Kelley</governor>
          <dependent id="6">Council</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">counselor</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">counselor</governor>
          <dependent id="8">Churches</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">Churches</governor>
          <dependent id="9">'</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">Council</governor>
          <dependent id="10">counselor</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">liberty</governor>
          <dependent id="11">on</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">liberty</governor>
          <dependent id="12">religious</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">counselor</governor>
          <dependent id="13">liberty</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">wrote</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">critique</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">wrote</governor>
          <dependent id="17">critique</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">Thomas</governor>
          <dependent id="18">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Thomas</governor>
          <dependent id="19">Clarence</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">critique</governor>
          <dependent id="20">Thomas</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="23">used</governor>
          <dependent id="21">that</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="23">used</governor>
          <dependent id="22">was</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="20">Thomas</governor>
          <dependent id="23">used</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">grounds</governor>
          <dependent id="24">as</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">used</governor>
          <dependent id="25">grounds</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">opposition</governor>
          <dependent id="26">for</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="28">organization</governor>
          <dependent id="27">his</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="30">opposition</governor>
          <dependent id="28">organization</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">organization</governor>
          <dependent id="29">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">grounds</governor>
          <dependent id="30">opposition</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">nominee</governor>
          <dependent id="31">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">nominee</governor>
          <dependent id="32">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">nominee</governor>
          <dependent id="33">Supreme</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">nominee</governor>
          <dependent id="34">Court</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">used</governor>
          <dependent id="35">nominee</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Supreme Court" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="33" string="Supreme" />
            <token id="34" string="Court" />
          </tokens>
        </entity>
        <entity id="2" string="Dean Kelley" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Dean" />
            <token id="2" string="Kelley" />
          </tokens>
        </entity>
        <entity id="3" string="National Council of Churches" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="5" string="National" />
            <token id="6" string="Council" />
            <token id="7" string="of" />
            <token id="8" string="Churches" />
          </tokens>
        </entity>
        <entity id="4" string="Clarence Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="19" string="Clarence" />
            <token id="20" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>The author did not mention Virginia Thomas in his text, but has said he was concerned about her involvement in the Cult Awareness Network (CAN), a Chicago-based organization that says it educates the public about &amp;quot;destructive&amp;quot; cults.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="author" lemma="author" stem="author" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="mention" lemma="mention" stem="mention" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="Virginia" lemma="Virginia" stem="virginia" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="7" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="text" lemma="text" stem="text" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="said" lemma="say" stem="said" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="concerned" lemma="concern" stem="concern" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="involvement" lemma="involvement" stem="involv" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="Cult" lemma="Cult" stem="cult" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="Awareness" lemma="Awareness" stem="aware" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="Network" lemma="Network" stem="network" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="27" string="CAN" lemma="CAN" stem="can" pos="NNP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="28" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="29" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="Chicago-based" lemma="chicago-based" stem="chicago-bas" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="32" string="organization" lemma="organization" stem="organ" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="36" string="educates" lemma="educate" stem="educ" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="public" lemma="public" stem="public" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="destructive" lemma="destructive" stem="destruct" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="cults" lemma="cult" stem="cult" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN author)) (VP (VP (VBD did) (RB not) (VP (VB mention) (NP (NP (NNP Virginia) (NNP Thomas)) (PP (IN in) (NP (PRP$ his) (NN text)))))) (, ,) (CC but) (VP (VBZ has) (VP (VBN said) (SBAR (S (NP (PRP he)) (VP (VBD was) (VP (VBN concerned) (PP (IN about) (NP (PRP$ her) (NN involvement))) (PP (IN in) (NP (NP (NP (DT the) (NNP Cult) (NNP Awareness) (NNP Network)) (PRN (-LRB- -LRB-) (NP (NNP CAN)) (-RRB- -RRB-))) (, ,) (NP (NP (DT a) (JJ Chicago-based) (NN organization)) (SBAR (WHNP (WDT that)) (S (VP (VBZ says) (SBAR (S (NP (PRP it)) (VP (VBZ educates) (NP (DT the) (JJ public)) (PP (IN about) (NP (`` ``) (JJ destructive) ('' '') (NNS cults))))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a Chicago-based organization that says it educates the public about `` destructive '' cults" type="NP">
          <tokens>
            <token id="30" string="a" />
            <token id="31" string="Chicago-based" />
            <token id="32" string="organization" />
            <token id="33" string="that" />
            <token id="34" string="says" />
            <token id="35" string="it" />
            <token id="36" string="educates" />
            <token id="37" string="the" />
            <token id="38" string="public" />
            <token id="39" string="about" />
            <token id="40" string="&quot;" />
            <token id="41" string="destructive" />
            <token id="42" string="&quot;" />
            <token id="43" string="cults" />
          </tokens>
        </chunking>
        <chunking id="2" string="the Cult Awareness Network -LRB- CAN -RRB-" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="Cult" />
            <token id="24" string="Awareness" />
            <token id="25" string="Network" />
            <token id="26" string="(" />
            <token id="27" string="CAN" />
            <token id="28" string=")" />
          </tokens>
        </chunking>
        <chunking id="3" string="it educates the public about `` destructive '' cults" type="SBAR">
          <tokens>
            <token id="35" string="it" />
            <token id="36" string="educates" />
            <token id="37" string="the" />
            <token id="38" string="public" />
            <token id="39" string="about" />
            <token id="40" string="&quot;" />
            <token id="41" string="destructive" />
            <token id="42" string="&quot;" />
            <token id="43" string="cults" />
          </tokens>
        </chunking>
        <chunking id="4" string="his text" type="NP">
          <tokens>
            <token id="9" string="his" />
            <token id="10" string="text" />
          </tokens>
        </chunking>
        <chunking id="5" string="has said he was concerned about her involvement in the Cult Awareness Network -LRB- CAN -RRB- , a Chicago-based organization that says it educates the public about `` destructive '' cults" type="VP">
          <tokens>
            <token id="13" string="has" />
            <token id="14" string="said" />
            <token id="15" string="he" />
            <token id="16" string="was" />
            <token id="17" string="concerned" />
            <token id="18" string="about" />
            <token id="19" string="her" />
            <token id="20" string="involvement" />
            <token id="21" string="in" />
            <token id="22" string="the" />
            <token id="23" string="Cult" />
            <token id="24" string="Awareness" />
            <token id="25" string="Network" />
            <token id="26" string="(" />
            <token id="27" string="CAN" />
            <token id="28" string=")" />
            <token id="29" string="," />
            <token id="30" string="a" />
            <token id="31" string="Chicago-based" />
            <token id="32" string="organization" />
            <token id="33" string="that" />
            <token id="34" string="says" />
            <token id="35" string="it" />
            <token id="36" string="educates" />
            <token id="37" string="the" />
            <token id="38" string="public" />
            <token id="39" string="about" />
            <token id="40" string="&quot;" />
            <token id="41" string="destructive" />
            <token id="42" string="&quot;" />
            <token id="43" string="cults" />
          </tokens>
        </chunking>
        <chunking id="6" string="did not mention Virginia Thomas in his text" type="VP">
          <tokens>
            <token id="3" string="did" />
            <token id="4" string="not" />
            <token id="5" string="mention" />
            <token id="6" string="Virginia" />
            <token id="7" string="Thomas" />
            <token id="8" string="in" />
            <token id="9" string="his" />
            <token id="10" string="text" />
          </tokens>
        </chunking>
        <chunking id="7" string="educates the public about `` destructive '' cults" type="VP">
          <tokens>
            <token id="36" string="educates" />
            <token id="37" string="the" />
            <token id="38" string="public" />
            <token id="39" string="about" />
            <token id="40" string="&quot;" />
            <token id="41" string="destructive" />
            <token id="42" string="&quot;" />
            <token id="43" string="cults" />
          </tokens>
        </chunking>
        <chunking id="8" string="the Cult Awareness Network -LRB- CAN -RRB- , a Chicago-based organization that says it educates the public about `` destructive '' cults" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="Cult" />
            <token id="24" string="Awareness" />
            <token id="25" string="Network" />
            <token id="26" string="(" />
            <token id="27" string="CAN" />
            <token id="28" string=")" />
            <token id="29" string="," />
            <token id="30" string="a" />
            <token id="31" string="Chicago-based" />
            <token id="32" string="organization" />
            <token id="33" string="that" />
            <token id="34" string="says" />
            <token id="35" string="it" />
            <token id="36" string="educates" />
            <token id="37" string="the" />
            <token id="38" string="public" />
            <token id="39" string="about" />
            <token id="40" string="&quot;" />
            <token id="41" string="destructive" />
            <token id="42" string="&quot;" />
            <token id="43" string="cults" />
          </tokens>
        </chunking>
        <chunking id="9" string="said he was concerned about her involvement in the Cult Awareness Network -LRB- CAN -RRB- , a Chicago-based organization that says it educates the public about `` destructive '' cults" type="VP">
          <tokens>
            <token id="14" string="said" />
            <token id="15" string="he" />
            <token id="16" string="was" />
            <token id="17" string="concerned" />
            <token id="18" string="about" />
            <token id="19" string="her" />
            <token id="20" string="involvement" />
            <token id="21" string="in" />
            <token id="22" string="the" />
            <token id="23" string="Cult" />
            <token id="24" string="Awareness" />
            <token id="25" string="Network" />
            <token id="26" string="(" />
            <token id="27" string="CAN" />
            <token id="28" string=")" />
            <token id="29" string="," />
            <token id="30" string="a" />
            <token id="31" string="Chicago-based" />
            <token id="32" string="organization" />
            <token id="33" string="that" />
            <token id="34" string="says" />
            <token id="35" string="it" />
            <token id="36" string="educates" />
            <token id="37" string="the" />
            <token id="38" string="public" />
            <token id="39" string="about" />
            <token id="40" string="&quot;" />
            <token id="41" string="destructive" />
            <token id="42" string="&quot;" />
            <token id="43" string="cults" />
          </tokens>
        </chunking>
        <chunking id="10" string="it" type="NP">
          <tokens>
            <token id="35" string="it" />
          </tokens>
        </chunking>
        <chunking id="11" string="was concerned about her involvement in the Cult Awareness Network -LRB- CAN -RRB- , a Chicago-based organization that says it educates the public about `` destructive '' cults" type="VP">
          <tokens>
            <token id="16" string="was" />
            <token id="17" string="concerned" />
            <token id="18" string="about" />
            <token id="19" string="her" />
            <token id="20" string="involvement" />
            <token id="21" string="in" />
            <token id="22" string="the" />
            <token id="23" string="Cult" />
            <token id="24" string="Awareness" />
            <token id="25" string="Network" />
            <token id="26" string="(" />
            <token id="27" string="CAN" />
            <token id="28" string=")" />
            <token id="29" string="," />
            <token id="30" string="a" />
            <token id="31" string="Chicago-based" />
            <token id="32" string="organization" />
            <token id="33" string="that" />
            <token id="34" string="says" />
            <token id="35" string="it" />
            <token id="36" string="educates" />
            <token id="37" string="the" />
            <token id="38" string="public" />
            <token id="39" string="about" />
            <token id="40" string="&quot;" />
            <token id="41" string="destructive" />
            <token id="42" string="&quot;" />
            <token id="43" string="cults" />
          </tokens>
        </chunking>
        <chunking id="12" string="CAN" type="NP">
          <tokens>
            <token id="27" string="CAN" />
          </tokens>
        </chunking>
        <chunking id="13" string="that says it educates the public about `` destructive '' cults" type="SBAR">
          <tokens>
            <token id="33" string="that" />
            <token id="34" string="says" />
            <token id="35" string="it" />
            <token id="36" string="educates" />
            <token id="37" string="the" />
            <token id="38" string="public" />
            <token id="39" string="about" />
            <token id="40" string="&quot;" />
            <token id="41" string="destructive" />
            <token id="42" string="&quot;" />
            <token id="43" string="cults" />
          </tokens>
        </chunking>
        <chunking id="14" string="her involvement" type="NP">
          <tokens>
            <token id="19" string="her" />
            <token id="20" string="involvement" />
          </tokens>
        </chunking>
        <chunking id="15" string="did not mention Virginia Thomas in his text , but has said he was concerned about her involvement in the Cult Awareness Network -LRB- CAN -RRB- , a Chicago-based organization that says it educates the public about `` destructive '' cults" type="VP">
          <tokens>
            <token id="3" string="did" />
            <token id="4" string="not" />
            <token id="5" string="mention" />
            <token id="6" string="Virginia" />
            <token id="7" string="Thomas" />
            <token id="8" string="in" />
            <token id="9" string="his" />
            <token id="10" string="text" />
            <token id="11" string="," />
            <token id="12" string="but" />
            <token id="13" string="has" />
            <token id="14" string="said" />
            <token id="15" string="he" />
            <token id="16" string="was" />
            <token id="17" string="concerned" />
            <token id="18" string="about" />
            <token id="19" string="her" />
            <token id="20" string="involvement" />
            <token id="21" string="in" />
            <token id="22" string="the" />
            <token id="23" string="Cult" />
            <token id="24" string="Awareness" />
            <token id="25" string="Network" />
            <token id="26" string="(" />
            <token id="27" string="CAN" />
            <token id="28" string=")" />
            <token id="29" string="," />
            <token id="30" string="a" />
            <token id="31" string="Chicago-based" />
            <token id="32" string="organization" />
            <token id="33" string="that" />
            <token id="34" string="says" />
            <token id="35" string="it" />
            <token id="36" string="educates" />
            <token id="37" string="the" />
            <token id="38" string="public" />
            <token id="39" string="about" />
            <token id="40" string="&quot;" />
            <token id="41" string="destructive" />
            <token id="42" string="&quot;" />
            <token id="43" string="cults" />
          </tokens>
        </chunking>
        <chunking id="16" string="he" type="NP">
          <tokens>
            <token id="15" string="he" />
          </tokens>
        </chunking>
        <chunking id="17" string="the public" type="NP">
          <tokens>
            <token id="37" string="the" />
            <token id="38" string="public" />
          </tokens>
        </chunking>
        <chunking id="18" string="The author" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="author" />
          </tokens>
        </chunking>
        <chunking id="19" string="says it educates the public about `` destructive '' cults" type="VP">
          <tokens>
            <token id="34" string="says" />
            <token id="35" string="it" />
            <token id="36" string="educates" />
            <token id="37" string="the" />
            <token id="38" string="public" />
            <token id="39" string="about" />
            <token id="40" string="&quot;" />
            <token id="41" string="destructive" />
            <token id="42" string="&quot;" />
            <token id="43" string="cults" />
          </tokens>
        </chunking>
        <chunking id="20" string="Virginia Thomas in his text" type="NP">
          <tokens>
            <token id="6" string="Virginia" />
            <token id="7" string="Thomas" />
            <token id="8" string="in" />
            <token id="9" string="his" />
            <token id="10" string="text" />
          </tokens>
        </chunking>
        <chunking id="21" string="he was concerned about her involvement in the Cult Awareness Network -LRB- CAN -RRB- , a Chicago-based organization that says it educates the public about `` destructive '' cults" type="SBAR">
          <tokens>
            <token id="15" string="he" />
            <token id="16" string="was" />
            <token id="17" string="concerned" />
            <token id="18" string="about" />
            <token id="19" string="her" />
            <token id="20" string="involvement" />
            <token id="21" string="in" />
            <token id="22" string="the" />
            <token id="23" string="Cult" />
            <token id="24" string="Awareness" />
            <token id="25" string="Network" />
            <token id="26" string="(" />
            <token id="27" string="CAN" />
            <token id="28" string=")" />
            <token id="29" string="," />
            <token id="30" string="a" />
            <token id="31" string="Chicago-based" />
            <token id="32" string="organization" />
            <token id="33" string="that" />
            <token id="34" string="says" />
            <token id="35" string="it" />
            <token id="36" string="educates" />
            <token id="37" string="the" />
            <token id="38" string="public" />
            <token id="39" string="about" />
            <token id="40" string="&quot;" />
            <token id="41" string="destructive" />
            <token id="42" string="&quot;" />
            <token id="43" string="cults" />
          </tokens>
        </chunking>
        <chunking id="22" string="concerned about her involvement in the Cult Awareness Network -LRB- CAN -RRB- , a Chicago-based organization that says it educates the public about `` destructive '' cults" type="VP">
          <tokens>
            <token id="17" string="concerned" />
            <token id="18" string="about" />
            <token id="19" string="her" />
            <token id="20" string="involvement" />
            <token id="21" string="in" />
            <token id="22" string="the" />
            <token id="23" string="Cult" />
            <token id="24" string="Awareness" />
            <token id="25" string="Network" />
            <token id="26" string="(" />
            <token id="27" string="CAN" />
            <token id="28" string=")" />
            <token id="29" string="," />
            <token id="30" string="a" />
            <token id="31" string="Chicago-based" />
            <token id="32" string="organization" />
            <token id="33" string="that" />
            <token id="34" string="says" />
            <token id="35" string="it" />
            <token id="36" string="educates" />
            <token id="37" string="the" />
            <token id="38" string="public" />
            <token id="39" string="about" />
            <token id="40" string="&quot;" />
            <token id="41" string="destructive" />
            <token id="42" string="&quot;" />
            <token id="43" string="cults" />
          </tokens>
        </chunking>
        <chunking id="23" string="the Cult Awareness Network" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="Cult" />
            <token id="24" string="Awareness" />
            <token id="25" string="Network" />
          </tokens>
        </chunking>
        <chunking id="24" string="a Chicago-based organization" type="NP">
          <tokens>
            <token id="30" string="a" />
            <token id="31" string="Chicago-based" />
            <token id="32" string="organization" />
          </tokens>
        </chunking>
        <chunking id="25" string="`` destructive '' cults" type="NP">
          <tokens>
            <token id="40" string="&quot;" />
            <token id="41" string="destructive" />
            <token id="42" string="&quot;" />
            <token id="43" string="cults" />
          </tokens>
        </chunking>
        <chunking id="26" string="Virginia Thomas" type="NP">
          <tokens>
            <token id="6" string="Virginia" />
            <token id="7" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="27" string="mention Virginia Thomas in his text" type="VP">
          <tokens>
            <token id="5" string="mention" />
            <token id="6" string="Virginia" />
            <token id="7" string="Thomas" />
            <token id="8" string="in" />
            <token id="9" string="his" />
            <token id="10" string="text" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">author</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">mention</governor>
          <dependent id="2">author</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">mention</governor>
          <dependent id="3">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">mention</governor>
          <dependent id="4">not</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">mention</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Thomas</governor>
          <dependent id="6">Virginia</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">mention</governor>
          <dependent id="7">Thomas</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">text</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">text</governor>
          <dependent id="9">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">Thomas</governor>
          <dependent id="10">text</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">mention</governor>
          <dependent id="12">but</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">said</governor>
          <dependent id="13">has</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">mention</governor>
          <dependent id="14">said</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="17">concerned</governor>
          <dependent id="15">he</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="17">concerned</governor>
          <dependent id="16">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">said</governor>
          <dependent id="17">concerned</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">involvement</governor>
          <dependent id="18">about</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="20">involvement</governor>
          <dependent id="19">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">concerned</governor>
          <dependent id="20">involvement</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">Network</governor>
          <dependent id="21">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">Network</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">Network</governor>
          <dependent id="23">Cult</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">Network</governor>
          <dependent id="24">Awareness</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">concerned</governor>
          <dependent id="25">Network</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="25">Network</governor>
          <dependent id="27">CAN</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">organization</governor>
          <dependent id="30">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="32">organization</governor>
          <dependent id="31">Chicago-based</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="25">Network</governor>
          <dependent id="32">organization</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="34">says</governor>
          <dependent id="33">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="32">organization</governor>
          <dependent id="34">says</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="36">educates</governor>
          <dependent id="35">it</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="34">says</governor>
          <dependent id="36">educates</dependent>
        </dependency>
        <dependency type="det">
          <governor id="38">public</governor>
          <dependent id="37">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="36">educates</governor>
          <dependent id="38">public</dependent>
        </dependency>
        <dependency type="case">
          <governor id="43">cults</governor>
          <dependent id="39">about</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="43">cults</governor>
          <dependent id="41">destructive</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="36">educates</governor>
          <dependent id="43">cults</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Virginia Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Virginia" />
            <token id="7" string="Thomas" />
          </tokens>
        </entity>
        <entity id="2" string="Chicago-based" type="MISC" score="0.0">
          <tokens>
            <token id="31" string="Chicago-based" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>That involvement, he said, might affect her husband&amp;apost;s handling of religious-liberty cases if he shares her views on the subject.</content>
      <tokens>
        <token id="1" string="That" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="involvement" lemma="involvement" stem="involv" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="might" lemma="might" stem="might" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="affect" lemma="affect" stem="affect" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="husband" lemma="husband" stem="husband" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="handling" lemma="handling" stem="handl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="religious-liberty" lemma="religious-liberty" stem="religious-liberti" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="cases" lemma="case" stem="case" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="shares" lemma="share" stem="share" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="views" lemma="view" stem="view" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="subject" lemma="subject" stem="subject" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT That) (NN involvement)) (PRN (, ,) (S (NP (PRP he)) (VP (VBD said))) (, ,)) (VP (MD might) (VP (VB affect) (NP (NP (NP (PRP$ her) (NN husband) (POS 's)) (NN handling)) (PP (IN of) (NP (JJ religious-liberty) (NNS cases)))) (SBAR (IN if) (S (NP (PRP he)) (VP (VBZ shares) (NP (PRP$ her) (NNS views)) (PP (IN on) (NP (DT the) (NN subject)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="That involvement" type="NP">
          <tokens>
            <token id="1" string="That" />
            <token id="2" string="involvement" />
          </tokens>
        </chunking>
        <chunking id="2" string="might affect her husband 's handling of religious-liberty cases if he shares her views on the subject" type="VP">
          <tokens>
            <token id="7" string="might" />
            <token id="8" string="affect" />
            <token id="9" string="her" />
            <token id="10" string="husband" />
            <token id="11" string="'s" />
            <token id="12" string="handling" />
            <token id="13" string="of" />
            <token id="14" string="religious-liberty" />
            <token id="15" string="cases" />
            <token id="16" string="if" />
            <token id="17" string="he" />
            <token id="18" string="shares" />
            <token id="19" string="her" />
            <token id="20" string="views" />
            <token id="21" string="on" />
            <token id="22" string="the" />
            <token id="23" string="subject" />
          </tokens>
        </chunking>
        <chunking id="3" string="her husband 's handling" type="NP">
          <tokens>
            <token id="9" string="her" />
            <token id="10" string="husband" />
            <token id="11" string="'s" />
            <token id="12" string="handling" />
          </tokens>
        </chunking>
        <chunking id="4" string="affect her husband 's handling of religious-liberty cases if he shares her views on the subject" type="VP">
          <tokens>
            <token id="8" string="affect" />
            <token id="9" string="her" />
            <token id="10" string="husband" />
            <token id="11" string="'s" />
            <token id="12" string="handling" />
            <token id="13" string="of" />
            <token id="14" string="religious-liberty" />
            <token id="15" string="cases" />
            <token id="16" string="if" />
            <token id="17" string="he" />
            <token id="18" string="shares" />
            <token id="19" string="her" />
            <token id="20" string="views" />
            <token id="21" string="on" />
            <token id="22" string="the" />
            <token id="23" string="subject" />
          </tokens>
        </chunking>
        <chunking id="5" string="if he shares her views on the subject" type="SBAR">
          <tokens>
            <token id="16" string="if" />
            <token id="17" string="he" />
            <token id="18" string="shares" />
            <token id="19" string="her" />
            <token id="20" string="views" />
            <token id="21" string="on" />
            <token id="22" string="the" />
            <token id="23" string="subject" />
          </tokens>
        </chunking>
        <chunking id="6" string="her husband 's handling of religious-liberty cases" type="NP">
          <tokens>
            <token id="9" string="her" />
            <token id="10" string="husband" />
            <token id="11" string="'s" />
            <token id="12" string="handling" />
            <token id="13" string="of" />
            <token id="14" string="religious-liberty" />
            <token id="15" string="cases" />
          </tokens>
        </chunking>
        <chunking id="7" string="her views" type="NP">
          <tokens>
            <token id="19" string="her" />
            <token id="20" string="views" />
          </tokens>
        </chunking>
        <chunking id="8" string="shares her views on the subject" type="VP">
          <tokens>
            <token id="18" string="shares" />
            <token id="19" string="her" />
            <token id="20" string="views" />
            <token id="21" string="on" />
            <token id="22" string="the" />
            <token id="23" string="subject" />
          </tokens>
        </chunking>
        <chunking id="9" string="the subject" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="subject" />
          </tokens>
        </chunking>
        <chunking id="10" string="religious-liberty cases" type="NP">
          <tokens>
            <token id="14" string="religious-liberty" />
            <token id="15" string="cases" />
          </tokens>
        </chunking>
        <chunking id="11" string="he" type="NP">
          <tokens>
            <token id="4" string="he" />
          </tokens>
        </chunking>
        <chunking id="12" string="said" type="VP">
          <tokens>
            <token id="5" string="said" />
          </tokens>
        </chunking>
        <chunking id="13" string="her husband 's" type="NP">
          <tokens>
            <token id="9" string="her" />
            <token id="10" string="husband" />
            <token id="11" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">involvement</governor>
          <dependent id="1">That</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">affect</governor>
          <dependent id="2">involvement</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">said</governor>
          <dependent id="4">he</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="8">affect</governor>
          <dependent id="5">said</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">affect</governor>
          <dependent id="7">might</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">affect</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">husband</governor>
          <dependent id="9">her</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">handling</governor>
          <dependent id="10">husband</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">husband</governor>
          <dependent id="11">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">affect</governor>
          <dependent id="12">handling</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">cases</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">cases</governor>
          <dependent id="14">religious-liberty</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">handling</governor>
          <dependent id="15">cases</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">shares</governor>
          <dependent id="16">if</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">shares</governor>
          <dependent id="17">he</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="8">affect</governor>
          <dependent id="18">shares</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="20">views</governor>
          <dependent id="19">her</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">shares</governor>
          <dependent id="20">views</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">subject</governor>
          <dependent id="21">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">subject</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">shares</governor>
          <dependent id="23">subject</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>During the early &amp;apost;80s, Virginia Thomas enrolled in Lifespring, a self-help course that challenges students to take responsibility for their lives.</content>
      <tokens>
        <token id="1" string="During" lemma="during" stem="dure" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="early" lemma="early" stem="earli" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="'80s" lemma="'80" stem="'80" pos="NNS" type="Word" isStopWord="false" ner="SET" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Virginia" lemma="Virginia" stem="virginia" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="7" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="8" string="enrolled" lemma="enrol" stem="enrol" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Lifespring" lemma="Lifespring" stem="lifespr" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="self-help" lemma="self-help" stem="self-help" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="course" lemma="course" stem="cours" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="challenges" lemma="challenge" stem="challeng" pos="VBZ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="students" lemma="student" stem="student" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="take" lemma="take" stem="take" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="responsibility" lemma="responsibility" stem="respons" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="lives" lemma="life" stem="live" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN During) (NP (DT the) (JJ early) (NNS '80s))) (, ,) (NP (NNP Virginia) (NNP Thomas)) (VP (VBD enrolled) (PP (IN in) (NP (NP (NNP Lifespring)) (, ,) (NP (NP (DT a) (JJ self-help) (NN course)) (SBAR (WHNP (WDT that)) (S (VP (VBZ challenges) (S (NP (NNS students)) (VP (TO to) (VP (VB take) (NP (NN responsibility)) (PP (IN for) (NP (PRP$ their) (NNS lives))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Lifespring" type="NP">
          <tokens>
            <token id="10" string="Lifespring" />
          </tokens>
        </chunking>
        <chunking id="2" string="a self-help course that challenges students to take responsibility for their lives" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="self-help" />
            <token id="14" string="course" />
            <token id="15" string="that" />
            <token id="16" string="challenges" />
            <token id="17" string="students" />
            <token id="18" string="to" />
            <token id="19" string="take" />
            <token id="20" string="responsibility" />
            <token id="21" string="for" />
            <token id="22" string="their" />
            <token id="23" string="lives" />
          </tokens>
        </chunking>
        <chunking id="3" string="to take responsibility for their lives" type="VP">
          <tokens>
            <token id="18" string="to" />
            <token id="19" string="take" />
            <token id="20" string="responsibility" />
            <token id="21" string="for" />
            <token id="22" string="their" />
            <token id="23" string="lives" />
          </tokens>
        </chunking>
        <chunking id="4" string="that challenges students to take responsibility for their lives" type="SBAR">
          <tokens>
            <token id="15" string="that" />
            <token id="16" string="challenges" />
            <token id="17" string="students" />
            <token id="18" string="to" />
            <token id="19" string="take" />
            <token id="20" string="responsibility" />
            <token id="21" string="for" />
            <token id="22" string="their" />
            <token id="23" string="lives" />
          </tokens>
        </chunking>
        <chunking id="5" string="students" type="NP">
          <tokens>
            <token id="17" string="students" />
          </tokens>
        </chunking>
        <chunking id="6" string="enrolled in Lifespring , a self-help course that challenges students to take responsibility for their lives" type="VP">
          <tokens>
            <token id="8" string="enrolled" />
            <token id="9" string="in" />
            <token id="10" string="Lifespring" />
            <token id="11" string="," />
            <token id="12" string="a" />
            <token id="13" string="self-help" />
            <token id="14" string="course" />
            <token id="15" string="that" />
            <token id="16" string="challenges" />
            <token id="17" string="students" />
            <token id="18" string="to" />
            <token id="19" string="take" />
            <token id="20" string="responsibility" />
            <token id="21" string="for" />
            <token id="22" string="their" />
            <token id="23" string="lives" />
          </tokens>
        </chunking>
        <chunking id="7" string="Virginia Thomas" type="NP">
          <tokens>
            <token id="6" string="Virginia" />
            <token id="7" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="8" string="Lifespring , a self-help course that challenges students to take responsibility for their lives" type="NP">
          <tokens>
            <token id="10" string="Lifespring" />
            <token id="11" string="," />
            <token id="12" string="a" />
            <token id="13" string="self-help" />
            <token id="14" string="course" />
            <token id="15" string="that" />
            <token id="16" string="challenges" />
            <token id="17" string="students" />
            <token id="18" string="to" />
            <token id="19" string="take" />
            <token id="20" string="responsibility" />
            <token id="21" string="for" />
            <token id="22" string="their" />
            <token id="23" string="lives" />
          </tokens>
        </chunking>
        <chunking id="9" string="challenges students to take responsibility for their lives" type="VP">
          <tokens>
            <token id="16" string="challenges" />
            <token id="17" string="students" />
            <token id="18" string="to" />
            <token id="19" string="take" />
            <token id="20" string="responsibility" />
            <token id="21" string="for" />
            <token id="22" string="their" />
            <token id="23" string="lives" />
          </tokens>
        </chunking>
        <chunking id="10" string="responsibility" type="NP">
          <tokens>
            <token id="20" string="responsibility" />
          </tokens>
        </chunking>
        <chunking id="11" string="their lives" type="NP">
          <tokens>
            <token id="22" string="their" />
            <token id="23" string="lives" />
          </tokens>
        </chunking>
        <chunking id="12" string="the early '80s" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="early" />
            <token id="4" string="'80s" />
          </tokens>
        </chunking>
        <chunking id="13" string="take responsibility for their lives" type="VP">
          <tokens>
            <token id="19" string="take" />
            <token id="20" string="responsibility" />
            <token id="21" string="for" />
            <token id="22" string="their" />
            <token id="23" string="lives" />
          </tokens>
        </chunking>
        <chunking id="14" string="a self-help course" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="self-help" />
            <token id="14" string="course" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">'80s</governor>
          <dependent id="1">During</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">'80s</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">'80s</governor>
          <dependent id="3">early</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">enrolled</governor>
          <dependent id="4">'80s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Thomas</governor>
          <dependent id="6">Virginia</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">enrolled</governor>
          <dependent id="7">Thomas</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">enrolled</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Lifespring</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">enrolled</governor>
          <dependent id="10">Lifespring</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">course</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">course</governor>
          <dependent id="13">self-help</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="10">Lifespring</governor>
          <dependent id="14">course</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">challenges</governor>
          <dependent id="15">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="14">course</governor>
          <dependent id="16">challenges</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">challenges</governor>
          <dependent id="17">students</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">take</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="16">challenges</governor>
          <dependent id="19">take</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">take</governor>
          <dependent id="20">responsibility</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">lives</governor>
          <dependent id="21">for</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="23">lives</governor>
          <dependent id="22">their</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">take</governor>
          <dependent id="23">lives</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="'80s" type="SET" score="0.0">
          <tokens>
            <token id="4" string="'80s" />
          </tokens>
        </entity>
        <entity id="2" string="Virginia Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Virginia" />
            <token id="7" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="26" has_coreference="true">
      <content>A small percentage of the program&amp;apost;s 300,000 graduates have been deeply disturbed by Lifespring&amp;apost;s methods, which involve intense emotional self-examination.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="small" lemma="small" stem="small" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="percentage" lemma="percentage" stem="percentag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="program" lemma="program" stem="program" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="300,000" lemma="300,000" stem="300,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="9" string="graduates" lemma="graduate" stem="graduat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="deeply" lemma="deeply" stem="deepli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="disturbed" lemma="disturb" stem="disturb" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Lifespring" lemma="lifespring" stem="lifespr" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="methods" lemma="method" stem="method" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="involve" lemma="involve" stem="involv" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="intense" lemma="intense" stem="intens" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="emotional" lemma="emotional" stem="emot" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="self-examination" lemma="self-examination" stem="self-examin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT A) (JJ small) (NN percentage)) (PP (IN of) (NP (NP (DT the) (NN program) (POS 's)) (CD 300,000) (NNS graduates)))) (VP (VBP have) (VP (VBN been) (VP (ADVP (RB deeply)) (VBN disturbed) (PP (IN by) (NP (NP (NP (NN Lifespring) (POS 's)) (NNS methods)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBP involve) (NP (JJ intense) (JJ emotional) (NN self-examination)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="A small percentage of the program 's 300,000 graduates" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="small" />
            <token id="3" string="percentage" />
            <token id="4" string="of" />
            <token id="5" string="the" />
            <token id="6" string="program" />
            <token id="7" string="'s" />
            <token id="8" string="300,000" />
            <token id="9" string="graduates" />
          </tokens>
        </chunking>
        <chunking id="2" string="the program 's" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="program" />
            <token id="7" string="'s" />
          </tokens>
        </chunking>
        <chunking id="3" string="which involve intense emotional self-examination" type="SBAR">
          <tokens>
            <token id="19" string="which" />
            <token id="20" string="involve" />
            <token id="21" string="intense" />
            <token id="22" string="emotional" />
            <token id="23" string="self-examination" />
          </tokens>
        </chunking>
        <chunking id="4" string="intense emotional self-examination" type="NP">
          <tokens>
            <token id="21" string="intense" />
            <token id="22" string="emotional" />
            <token id="23" string="self-examination" />
          </tokens>
        </chunking>
        <chunking id="5" string="Lifespring 's methods , which involve intense emotional self-examination" type="NP">
          <tokens>
            <token id="15" string="Lifespring" />
            <token id="16" string="'s" />
            <token id="17" string="methods" />
            <token id="18" string="," />
            <token id="19" string="which" />
            <token id="20" string="involve" />
            <token id="21" string="intense" />
            <token id="22" string="emotional" />
            <token id="23" string="self-examination" />
          </tokens>
        </chunking>
        <chunking id="6" string="involve intense emotional self-examination" type="VP">
          <tokens>
            <token id="20" string="involve" />
            <token id="21" string="intense" />
            <token id="22" string="emotional" />
            <token id="23" string="self-examination" />
          </tokens>
        </chunking>
        <chunking id="7" string="A small percentage" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="small" />
            <token id="3" string="percentage" />
          </tokens>
        </chunking>
        <chunking id="8" string="Lifespring 's" type="NP">
          <tokens>
            <token id="15" string="Lifespring" />
            <token id="16" string="'s" />
          </tokens>
        </chunking>
        <chunking id="9" string="been deeply disturbed by Lifespring 's methods , which involve intense emotional self-examination" type="VP">
          <tokens>
            <token id="11" string="been" />
            <token id="12" string="deeply" />
            <token id="13" string="disturbed" />
            <token id="14" string="by" />
            <token id="15" string="Lifespring" />
            <token id="16" string="'s" />
            <token id="17" string="methods" />
            <token id="18" string="," />
            <token id="19" string="which" />
            <token id="20" string="involve" />
            <token id="21" string="intense" />
            <token id="22" string="emotional" />
            <token id="23" string="self-examination" />
          </tokens>
        </chunking>
        <chunking id="10" string="have been deeply disturbed by Lifespring 's methods , which involve intense emotional self-examination" type="VP">
          <tokens>
            <token id="10" string="have" />
            <token id="11" string="been" />
            <token id="12" string="deeply" />
            <token id="13" string="disturbed" />
            <token id="14" string="by" />
            <token id="15" string="Lifespring" />
            <token id="16" string="'s" />
            <token id="17" string="methods" />
            <token id="18" string="," />
            <token id="19" string="which" />
            <token id="20" string="involve" />
            <token id="21" string="intense" />
            <token id="22" string="emotional" />
            <token id="23" string="self-examination" />
          </tokens>
        </chunking>
        <chunking id="11" string="Lifespring 's methods" type="NP">
          <tokens>
            <token id="15" string="Lifespring" />
            <token id="16" string="'s" />
            <token id="17" string="methods" />
          </tokens>
        </chunking>
        <chunking id="12" string="the program 's 300,000 graduates" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="program" />
            <token id="7" string="'s" />
            <token id="8" string="300,000" />
            <token id="9" string="graduates" />
          </tokens>
        </chunking>
        <chunking id="13" string="deeply disturbed by Lifespring 's methods , which involve intense emotional self-examination" type="VP">
          <tokens>
            <token id="12" string="deeply" />
            <token id="13" string="disturbed" />
            <token id="14" string="by" />
            <token id="15" string="Lifespring" />
            <token id="16" string="'s" />
            <token id="17" string="methods" />
            <token id="18" string="," />
            <token id="19" string="which" />
            <token id="20" string="involve" />
            <token id="21" string="intense" />
            <token id="22" string="emotional" />
            <token id="23" string="self-examination" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">percentage</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">percentage</governor>
          <dependent id="2">small</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="13">disturbed</governor>
          <dependent id="3">percentage</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">graduates</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">program</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">graduates</governor>
          <dependent id="6">program</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">program</governor>
          <dependent id="7">'s</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="9">graduates</governor>
          <dependent id="8">300,000</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">percentage</governor>
          <dependent id="9">graduates</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">disturbed</governor>
          <dependent id="10">have</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="13">disturbed</governor>
          <dependent id="11">been</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">disturbed</governor>
          <dependent id="12">deeply</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">disturbed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">methods</governor>
          <dependent id="14">by</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="17">methods</governor>
          <dependent id="15">Lifespring</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">Lifespring</governor>
          <dependent id="16">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">disturbed</governor>
          <dependent id="17">methods</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">involve</governor>
          <dependent id="19">which</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="17">methods</governor>
          <dependent id="20">involve</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">self-examination</governor>
          <dependent id="21">intense</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">self-examination</governor>
          <dependent id="22">emotional</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">involve</governor>
          <dependent id="23">self-examination</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="300,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="8" string="300,000" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>A clean break; Virginia Thomas was troubled by some of Lifespring&amp;apost;s activities and eventually broke with the organization.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="clean" lemma="clean" stem="clean" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="break" lemma="break" stem="break" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Virginia" lemma="Virginia" stem="virginia" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="6" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="7" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="troubled" lemma="trouble" stem="troubl" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Lifespring" lemma="Lifespring" stem="lifespr" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="activities" lemma="activity" stem="activ" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="eventually" lemma="eventually" stem="eventu" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="broke" lemma="break" stem="broke" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="organization" lemma="organization" stem="organ" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (DT A) (JJ clean) (NN break)) (: ;) (S (NP (NNP Virginia) (NNP Thomas)) (VP (VP (VBD was) (VP (VBN troubled) (PP (IN by) (NP (NP (DT some)) (PP (IN of) (NP (NP (NNP Lifespring) (POS 's)) (NNS activities))))))) (CC and) (VP (ADVP (RB eventually)) (VBD broke) (PP (IN with) (NP (DT the) (NN organization)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the organization" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="organization" />
          </tokens>
        </chunking>
        <chunking id="2" string="A clean break" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="clean" />
            <token id="3" string="break" />
          </tokens>
        </chunking>
        <chunking id="3" string="was troubled by some of Lifespring 's activities" type="VP">
          <tokens>
            <token id="7" string="was" />
            <token id="8" string="troubled" />
            <token id="9" string="by" />
            <token id="10" string="some" />
            <token id="11" string="of" />
            <token id="12" string="Lifespring" />
            <token id="13" string="'s" />
            <token id="14" string="activities" />
          </tokens>
        </chunking>
        <chunking id="4" string="Virginia Thomas" type="NP">
          <tokens>
            <token id="5" string="Virginia" />
            <token id="6" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="5" string="troubled by some of Lifespring 's activities" type="VP">
          <tokens>
            <token id="8" string="troubled" />
            <token id="9" string="by" />
            <token id="10" string="some" />
            <token id="11" string="of" />
            <token id="12" string="Lifespring" />
            <token id="13" string="'s" />
            <token id="14" string="activities" />
          </tokens>
        </chunking>
        <chunking id="6" string="some" type="NP">
          <tokens>
            <token id="10" string="some" />
          </tokens>
        </chunking>
        <chunking id="7" string="some of Lifespring 's activities" type="NP">
          <tokens>
            <token id="10" string="some" />
            <token id="11" string="of" />
            <token id="12" string="Lifespring" />
            <token id="13" string="'s" />
            <token id="14" string="activities" />
          </tokens>
        </chunking>
        <chunking id="8" string="was troubled by some of Lifespring 's activities and eventually broke with the organization" type="VP">
          <tokens>
            <token id="7" string="was" />
            <token id="8" string="troubled" />
            <token id="9" string="by" />
            <token id="10" string="some" />
            <token id="11" string="of" />
            <token id="12" string="Lifespring" />
            <token id="13" string="'s" />
            <token id="14" string="activities" />
            <token id="15" string="and" />
            <token id="16" string="eventually" />
            <token id="17" string="broke" />
            <token id="18" string="with" />
            <token id="19" string="the" />
            <token id="20" string="organization" />
          </tokens>
        </chunking>
        <chunking id="9" string="eventually broke with the organization" type="VP">
          <tokens>
            <token id="16" string="eventually" />
            <token id="17" string="broke" />
            <token id="18" string="with" />
            <token id="19" string="the" />
            <token id="20" string="organization" />
          </tokens>
        </chunking>
        <chunking id="10" string="Lifespring 's activities" type="NP">
          <tokens>
            <token id="12" string="Lifespring" />
            <token id="13" string="'s" />
            <token id="14" string="activities" />
          </tokens>
        </chunking>
        <chunking id="11" string="A clean break ; Virginia Thomas was troubled by some of Lifespring 's activities and eventually broke with the organization ." type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="clean" />
            <token id="3" string="break" />
            <token id="4" string=";" />
            <token id="5" string="Virginia" />
            <token id="6" string="Thomas" />
            <token id="7" string="was" />
            <token id="8" string="troubled" />
            <token id="9" string="by" />
            <token id="10" string="some" />
            <token id="11" string="of" />
            <token id="12" string="Lifespring" />
            <token id="13" string="'s" />
            <token id="14" string="activities" />
            <token id="15" string="and" />
            <token id="16" string="eventually" />
            <token id="17" string="broke" />
            <token id="18" string="with" />
            <token id="19" string="the" />
            <token id="20" string="organization" />
            <token id="21" string="." />
          </tokens>
        </chunking>
        <chunking id="12" string="Lifespring 's" type="NP">
          <tokens>
            <token id="12" string="Lifespring" />
            <token id="13" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">break</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">break</governor>
          <dependent id="2">clean</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">break</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Thomas</governor>
          <dependent id="5">Virginia</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="8">troubled</governor>
          <dependent id="6">Thomas</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="8">troubled</governor>
          <dependent id="7">was</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="3">break</governor>
          <dependent id="8">troubled</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">some</governor>
          <dependent id="9">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">troubled</governor>
          <dependent id="10">some</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">activities</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">activities</governor>
          <dependent id="12">Lifespring</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Lifespring</governor>
          <dependent id="13">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">some</governor>
          <dependent id="14">activities</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">troubled</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">broke</governor>
          <dependent id="16">eventually</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">troubled</governor>
          <dependent id="17">broke</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">organization</governor>
          <dependent id="18">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">organization</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">broke</governor>
          <dependent id="20">organization</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Virginia Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Virginia" />
            <token id="6" string="Thomas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="28" has_coreference="true">
      <content>Since 1985, she has been a public advocate against cult activities.</content>
      <tokens>
        <token id="1" string="Since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="1985" lemma="1985" stem="1985" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="public" lemma="public" stem="public" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="advocate" lemma="advocate" stem="advoc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="cult" lemma="cult" stem="cult" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="activities" lemma="activity" stem="activ" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN Since) (NP (CD 1985))) (, ,) (NP (PRP she)) (VP (VBZ has) (VP (VBN been) (NP (NP (DT a) (JJ public) (NN advocate)) (PP (IN against) (NP (NN cult) (NNS activities)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a public advocate against cult activities" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="public" />
            <token id="9" string="advocate" />
            <token id="10" string="against" />
            <token id="11" string="cult" />
            <token id="12" string="activities" />
          </tokens>
        </chunking>
        <chunking id="2" string="1985" type="NP">
          <tokens>
            <token id="2" string="1985" />
          </tokens>
        </chunking>
        <chunking id="3" string="been a public advocate against cult activities" type="VP">
          <tokens>
            <token id="6" string="been" />
            <token id="7" string="a" />
            <token id="8" string="public" />
            <token id="9" string="advocate" />
            <token id="10" string="against" />
            <token id="11" string="cult" />
            <token id="12" string="activities" />
          </tokens>
        </chunking>
        <chunking id="4" string="has been a public advocate against cult activities" type="VP">
          <tokens>
            <token id="5" string="has" />
            <token id="6" string="been" />
            <token id="7" string="a" />
            <token id="8" string="public" />
            <token id="9" string="advocate" />
            <token id="10" string="against" />
            <token id="11" string="cult" />
            <token id="12" string="activities" />
          </tokens>
        </chunking>
        <chunking id="5" string="a public advocate" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="public" />
            <token id="9" string="advocate" />
          </tokens>
        </chunking>
        <chunking id="6" string="cult activities" type="NP">
          <tokens>
            <token id="11" string="cult" />
            <token id="12" string="activities" />
          </tokens>
        </chunking>
        <chunking id="7" string="she" type="NP">
          <tokens>
            <token id="4" string="she" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">1985</governor>
          <dependent id="1">Since</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">advocate</governor>
          <dependent id="2">1985</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">advocate</governor>
          <dependent id="4">she</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">advocate</governor>
          <dependent id="5">has</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="9">advocate</governor>
          <dependent id="6">been</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">advocate</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">advocate</governor>
          <dependent id="8">public</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">advocate</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">activities</governor>
          <dependent id="10">against</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">activities</governor>
          <dependent id="11">cult</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">advocate</governor>
          <dependent id="12">activities</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1985" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="1985" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="29" has_coreference="true">
      <content>When she served as a labor-relations attorney at the U.S. Chamber of Commerce from 1985 to 1989, she represented the interests of the business community at congressional hearings on such issues as comparable worth, affirmative action and federal child-care legislation.</content>
      <tokens>
        <token id="1" string="When" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="served" lemma="serve" stem="serv" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="labor-relations" lemma="labor-relations" stem="labor-rel" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="attorney" lemma="attorney" stem="attornei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="U.S." lemma="U.S." stem="u.s." pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="11" string="Chamber" lemma="Chamber" stem="chamber" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="13" string="Commerce" lemma="Commerce" stem="commerc" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="14" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="1985" lemma="1985" stem="1985" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="17" string="1989" lemma="1989" stem="1989" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="represented" lemma="represent" stem="repres" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="interests" lemma="interest" stem="interest" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="business" lemma="business" stem="busi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="community" lemma="community" stem="commun" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="congressional" lemma="congressional" stem="congression" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="hearings" lemma="hearing" stem="hear" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="issues" lemma="issue" stem="issu" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="comparable" lemma="comparable" stem="compar" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="worth" lemma="worth" stem="worth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="affirmative" lemma="affirmative" stem="affirm" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="action" lemma="action" stem="action" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="federal" lemma="federal" stem="feder" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="child-care" lemma="child-care" stem="child-car" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="legislation" lemma="legislation" stem="legisl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (WHADVP (WRB When)) (S (NP (PRP she)) (VP (VBD served) (PP (IN as) (NP (NP (DT a) (JJ labor-relations) (NN attorney)) (PP (IN at) (NP (NP (DT the) (NNP U.S.) (NNP Chamber)) (PP (IN of) (NP (NNP Commerce))))))) (PP (IN from) (NP (CD 1985) (TO to) (CD 1989)))))) (, ,) (NP (PRP she)) (VP (VBD represented) (NP (NP (DT the) (NNS interests)) (PP (IN of) (NP (DT the) (NN business) (NN community)))) (PP (IN at) (NP (NP (JJ congressional) (NNS hearings)) (PP (IN on) (NP (JJ such) (NNS issues))))) (PP (IN as) (NP (NP (JJ comparable) (NN worth)) (, ,) (NP (JJ affirmative) (NN action)) (CC and) (NP (JJ federal) (JJ child-care) (NN legislation))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a labor-relations attorney" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="labor-relations" />
            <token id="7" string="attorney" />
          </tokens>
        </chunking>
        <chunking id="2" string="When she served as a labor-relations attorney at the U.S. Chamber of Commerce from 1985 to 1989" type="SBAR">
          <tokens>
            <token id="1" string="When" />
            <token id="2" string="she" />
            <token id="3" string="served" />
            <token id="4" string="as" />
            <token id="5" string="a" />
            <token id="6" string="labor-relations" />
            <token id="7" string="attorney" />
            <token id="8" string="at" />
            <token id="9" string="the" />
            <token id="10" string="U.S." />
            <token id="11" string="Chamber" />
            <token id="12" string="of" />
            <token id="13" string="Commerce" />
            <token id="14" string="from" />
            <token id="15" string="1985" />
            <token id="16" string="to" />
            <token id="17" string="1989" />
          </tokens>
        </chunking>
        <chunking id="3" string="comparable worth , affirmative action and federal child-care legislation" type="NP">
          <tokens>
            <token id="34" string="comparable" />
            <token id="35" string="worth" />
            <token id="36" string="," />
            <token id="37" string="affirmative" />
            <token id="38" string="action" />
            <token id="39" string="and" />
            <token id="40" string="federal" />
            <token id="41" string="child-care" />
            <token id="42" string="legislation" />
          </tokens>
        </chunking>
        <chunking id="4" string="Commerce" type="NP">
          <tokens>
            <token id="13" string="Commerce" />
          </tokens>
        </chunking>
        <chunking id="5" string="federal child-care legislation" type="NP">
          <tokens>
            <token id="40" string="federal" />
            <token id="41" string="child-care" />
            <token id="42" string="legislation" />
          </tokens>
        </chunking>
        <chunking id="6" string="the business community" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="business" />
            <token id="26" string="community" />
          </tokens>
        </chunking>
        <chunking id="7" string="congressional hearings" type="NP">
          <tokens>
            <token id="28" string="congressional" />
            <token id="29" string="hearings" />
          </tokens>
        </chunking>
        <chunking id="8" string="comparable worth" type="NP">
          <tokens>
            <token id="34" string="comparable" />
            <token id="35" string="worth" />
          </tokens>
        </chunking>
        <chunking id="9" string="she" type="NP">
          <tokens>
            <token id="2" string="she" />
          </tokens>
        </chunking>
        <chunking id="10" string="represented the interests of the business community at congressional hearings on such issues as comparable worth , affirmative action and federal child-care legislation" type="VP">
          <tokens>
            <token id="20" string="represented" />
            <token id="21" string="the" />
            <token id="22" string="interests" />
            <token id="23" string="of" />
            <token id="24" string="the" />
            <token id="25" string="business" />
            <token id="26" string="community" />
            <token id="27" string="at" />
            <token id="28" string="congressional" />
            <token id="29" string="hearings" />
            <token id="30" string="on" />
            <token id="31" string="such" />
            <token id="32" string="issues" />
            <token id="33" string="as" />
            <token id="34" string="comparable" />
            <token id="35" string="worth" />
            <token id="36" string="," />
            <token id="37" string="affirmative" />
            <token id="38" string="action" />
            <token id="39" string="and" />
            <token id="40" string="federal" />
            <token id="41" string="child-care" />
            <token id="42" string="legislation" />
          </tokens>
        </chunking>
        <chunking id="11" string="such issues" type="NP">
          <tokens>
            <token id="31" string="such" />
            <token id="32" string="issues" />
          </tokens>
        </chunking>
        <chunking id="12" string="When" type="WHADVP">
          <tokens>
            <token id="1" string="When" />
          </tokens>
        </chunking>
        <chunking id="13" string="the interests" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="interests" />
          </tokens>
        </chunking>
        <chunking id="14" string="served as a labor-relations attorney at the U.S. Chamber of Commerce from 1985 to 1989" type="VP">
          <tokens>
            <token id="3" string="served" />
            <token id="4" string="as" />
            <token id="5" string="a" />
            <token id="6" string="labor-relations" />
            <token id="7" string="attorney" />
            <token id="8" string="at" />
            <token id="9" string="the" />
            <token id="10" string="U.S." />
            <token id="11" string="Chamber" />
            <token id="12" string="of" />
            <token id="13" string="Commerce" />
            <token id="14" string="from" />
            <token id="15" string="1985" />
            <token id="16" string="to" />
            <token id="17" string="1989" />
          </tokens>
        </chunking>
        <chunking id="15" string="the interests of the business community" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="interests" />
            <token id="23" string="of" />
            <token id="24" string="the" />
            <token id="25" string="business" />
            <token id="26" string="community" />
          </tokens>
        </chunking>
        <chunking id="16" string="a labor-relations attorney at the U.S. Chamber of Commerce" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="labor-relations" />
            <token id="7" string="attorney" />
            <token id="8" string="at" />
            <token id="9" string="the" />
            <token id="10" string="U.S." />
            <token id="11" string="Chamber" />
            <token id="12" string="of" />
            <token id="13" string="Commerce" />
          </tokens>
        </chunking>
        <chunking id="17" string="the U.S. Chamber" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="U.S." />
            <token id="11" string="Chamber" />
          </tokens>
        </chunking>
        <chunking id="18" string="1985 to 1989" type="NP">
          <tokens>
            <token id="15" string="1985" />
            <token id="16" string="to" />
            <token id="17" string="1989" />
          </tokens>
        </chunking>
        <chunking id="19" string="congressional hearings on such issues" type="NP">
          <tokens>
            <token id="28" string="congressional" />
            <token id="29" string="hearings" />
            <token id="30" string="on" />
            <token id="31" string="such" />
            <token id="32" string="issues" />
          </tokens>
        </chunking>
        <chunking id="20" string="affirmative action" type="NP">
          <tokens>
            <token id="37" string="affirmative" />
            <token id="38" string="action" />
          </tokens>
        </chunking>
        <chunking id="21" string="the U.S. Chamber of Commerce" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="U.S." />
            <token id="11" string="Chamber" />
            <token id="12" string="of" />
            <token id="13" string="Commerce" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="3">served</governor>
          <dependent id="1">When</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">served</governor>
          <dependent id="2">she</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="20">represented</governor>
          <dependent id="3">served</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">attorney</governor>
          <dependent id="4">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">attorney</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">attorney</governor>
          <dependent id="6">labor-relations</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">served</governor>
          <dependent id="7">attorney</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Chamber</governor>
          <dependent id="8">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">Chamber</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Chamber</governor>
          <dependent id="10">U.S.</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">attorney</governor>
          <dependent id="11">Chamber</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Commerce</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">Chamber</governor>
          <dependent id="13">Commerce</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">1989</governor>
          <dependent id="14">from</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="17">1989</governor>
          <dependent id="15">1985</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="17">1989</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">served</governor>
          <dependent id="17">1989</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">represented</governor>
          <dependent id="19">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="20">represented</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">interests</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">represented</governor>
          <dependent id="22">interests</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">community</governor>
          <dependent id="23">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">community</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">community</governor>
          <dependent id="25">business</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">interests</governor>
          <dependent id="26">community</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">hearings</governor>
          <dependent id="27">at</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">hearings</governor>
          <dependent id="28">congressional</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">represented</governor>
          <dependent id="29">hearings</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">issues</governor>
          <dependent id="30">on</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="32">issues</governor>
          <dependent id="31">such</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">hearings</governor>
          <dependent id="32">issues</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">worth</governor>
          <dependent id="33">as</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="35">worth</governor>
          <dependent id="34">comparable</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">represented</governor>
          <dependent id="35">worth</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="38">action</governor>
          <dependent id="37">affirmative</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="35">worth</governor>
          <dependent id="38">action</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="35">worth</governor>
          <dependent id="39">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="42">legislation</governor>
          <dependent id="40">federal</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="42">legislation</governor>
          <dependent id="41">child-care</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="35">worth</governor>
          <dependent id="42">legislation</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1985 to 1989" type="DATE" score="0.0">
          <tokens>
            <token id="15" string="1985" />
            <token id="16" string="to" />
            <token id="17" string="1989" />
          </tokens>
        </entity>
        <entity id="2" string="U.S. Chamber of Commerce" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="10" string="U.S." />
            <token id="11" string="Chamber" />
            <token id="12" string="of" />
            <token id="13" string="Commerce" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="1-2" string="Virginia Thomas" id_sentence="1" />
      <mentions>
        <mention ids_tokens="13" string="her" id_sentence="15" />
        <mention ids_tokens="4" string="she" id_sentence="28" />
        <mention ids_tokens="7-12" string="a public advocate against cult activities" id_sentence="28" />
        <mention ids_tokens="2" string="she" id_sentence="29" />
        <mention ids_tokens="19" string="she" id_sentence="29" />
      </mentions>
    </coreference>
    <coreference id="2" type="NOMINAL">
      <referenced ids_tokens="1-2-3" string="A good friend." id_sentence="4" />
      <mentions>
        <mention ids_tokens="1" string="Her" id_sentence="5" />
        <mention ids_tokens="4" string="her" id_sentence="5" />
        <mention ids_tokens="14" string="her" id_sentence="5" />
      </mentions>
    </coreference>
    <coreference id="3" type="PROPER">
      <referenced ids_tokens="9-10-11-12" string="Mrs. Supreme Court Nominee" id_sentence="4" />
      <mentions>
        <mention ids_tokens="32-35" string="the Supreme Court nominee" id_sentence="22" />
      </mentions>
    </coreference>
    <coreference id="4" type="NOMINAL">
      <referenced ids_tokens="1-2" string="Her critics" id_sentence="5" />
      <mentions>
        <mention ids_tokens="1" string="They" id_sentence="6" />
      </mentions>
    </coreference>
    <coreference id="5" type="PROPER">
      <referenced ids_tokens="17" string="Clarence" id_sentence="5" />
      <mentions>
        <mention ids_tokens="1-2" string="Clarence's" id_sentence="20" />
        <mention ids_tokens="10" string="his" id_sentence="20" />
        <mention ids_tokens="9-11" string="her husband's" id_sentence="24" />
      </mentions>
    </coreference>
    <coreference id="6" type="NOMINAL">
      <referenced ids_tokens="3-4-5-6-7" string="a woman with strong opinions" id_sentence="6" />
      <mentions>
        <mention ids_tokens="10" string="her" id_sentence="7" />
        <mention ids_tokens="8" string="her" id_sentence="8" />
        <mention ids_tokens="14" string="her" id_sentence="8" />
        <mention ids_tokens="10" string="her" id_sentence="9" />
        <mention ids_tokens="4" string="she" id_sentence="10" />
      </mentions>
    </coreference>
    <coreference id="7" type="NOMINAL">
      <referenced ids_tokens="14-15-16" string="her former involvement" id_sentence="8" />
      <mentions>
        <mention ids_tokens="19-20" string="her involvement" id_sentence="23" />
        <mention ids_tokens="35" string="it" id_sentence="23" />
        <mention ids_tokens="1-2" string="That involvement" id_sentence="24" />
      </mentions>
    </coreference>
    <coreference id="8" type="PROPER">
      <referenced ids_tokens="10-11-12-13-14-15-16-17-18-19-20-21-22-23" string="Lifespring , a self-help course that challenges students to take responsibility for their lives" id_sentence="25" />
      <mentions>
        <mention ids_tokens="18-22" string="Lifespring , a motivational group" id_sentence="8" />
        <mention ids_tokens="15-16" string="Lifespring's" id_sentence="26" />
        <mention ids_tokens="12-13" string="Lifespring's" id_sentence="27" />
      </mentions>
    </coreference>
    <coreference id="9" type="PROPER">
      <referenced ids_tokens="20-21-22" string="Clarence Thomas 's" id_sentence="9" />
      <mentions>
        <mention ids_tokens="20-21" string="Clarence Thomas" id_sentence="10" />
        <mention ids_tokens="24" string="his" id_sentence="10" />
        <mention ids_tokens="1-2" string="Clarence Thomas" id_sentence="16" />
        <mention ids_tokens="9" string="his" id_sentence="16" />
        <mention ids_tokens="2-6" string="His marrying a white woman" id_sentence="18" />
        <mention ids_tokens="11" string="his" id_sentence="18" />
        <mention ids_tokens="19-35" string="Clarence Thomas that was used as grounds for his organization's opposition to the Supreme Court nominee" id_sentence="22" />
      </mentions>
    </coreference>
    <coreference id="10" type="NOMINAL">
      <referenced ids_tokens="11-12-13-14-15-16-17-18-19-20-21-22-23-24-25" string="some blacks who see the marriage as evidence that Clarence Thomas has rejected his roots" id_sentence="10" />
      <mentions>
        <mention ids_tokens="2" string="their" id_sentence="11" />
        <mention ids_tokens="13" string="they" id_sentence="12" />
      </mentions>
    </coreference>
    <coreference id="11" type="NOMINAL">
      <referenced ids_tokens="15-16" string="the marriage" id_sentence="10" />
      <mentions>
        <mention ids_tokens="9-10" string="his marriage" id_sentence="16" />
        <mention ids_tokens="13-17" string="an example of that philosophy" id_sentence="16" />
      </mentions>
    </coreference>
    <coreference id="13" type="NOMINAL">
      <referenced ids_tokens="38" string="women" id_sentence="14" />
      <mentions>
        <mention ids_tokens="13-15" string="women and minorities" id_sentence="11" />
      </mentions>
    </coreference>
    <coreference id="14" type="NOMINAL">
      <referenced ids_tokens="6-7-8-9-10-11" string="holding everyone to the same standard" id_sentence="12" />
      <mentions>
        <mention ids_tokens="11" string="she" id_sentence="13" />
      </mentions>
    </coreference>
    <coreference id="15" type="NOMINAL">
      <referenced ids_tokens="9-10-11" string="the same standard" id_sentence="12" />
      <mentions>
        <mention ids_tokens="6" string="it" id_sentence="13" />
        <mention ids_tokens="11" string="it" id_sentence="14" />
      </mentions>
    </coreference>
    <coreference id="16" type="NOMINAL">
      <referenced ids_tokens="13-14" string="anti-women 's" id_sentence="13" />
      <mentions>
        <mention ids_tokens="1" string="She" id_sentence="14" />
      </mentions>
    </coreference>
    <coreference id="19" type="NOMINAL">
      <referenced ids_tokens="1-2" string="The author" id_sentence="23" />
      <mentions>
        <mention ids_tokens="4" string="he" id_sentence="24" />
        <mention ids_tokens="17" string="he" id_sentence="24" />
      </mentions>
    </coreference>
    <coreference id="20" type="PROPER">
      <referenced ids_tokens="6-7-8-9-10" string="Virginia Thomas in his text" id_sentence="23" />
      <mentions>
        <mention ids_tokens="9" string="her" id_sentence="24" />
        <mention ids_tokens="19" string="her" id_sentence="24" />
      </mentions>
    </coreference>
    <coreference id="21" type="PROPER">
      <referenced ids_tokens="22-23-24-25-26-27-28" string="the Cult Awareness Network ( CAN )" id_sentence="23" />
      <mentions>
        <mention ids_tokens="19-20" string="the organization" id_sentence="27" />
      </mentions>
    </coreference>
  </coreferences>
</document>
