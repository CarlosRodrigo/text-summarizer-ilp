<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="LA093089-0076">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>In a blow to California and other states with large immigrant populations, the Senate voted Friday to bar the Census Bureau from counting illegal aliens in the 1990 population count.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="blow" lemma="blow" stem="blow" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="California" lemma="California" stem="california" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="6" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="states" lemma="state" stem="state" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="large" lemma="large" stem="larg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="immigrant" lemma="immigrant" stem="immigr" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="populations" lemma="population" stem="popul" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="Senate" lemma="Senate" stem="senat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="16" string="voted" lemma="vote" stem="vote" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="Friday" lemma="Friday" stem="fridai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="bar" lemma="bar" stem="bar" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="Census" lemma="Census" stem="censu" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="22" string="Bureau" lemma="Bureau" stem="bureau" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="23" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="counting" lemma="count" stem="count" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="aliens" lemma="alien" stem="alien" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="29" string="1990" lemma="1990" stem="1990" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="30" string="population" lemma="population" stem="popul" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="31" string="count" lemma="count" stem="count" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (NP (NP (DT a) (NN blow)) (PP (TO to) (NP (NNP California)))) (CC and) (NP (NP (JJ other) (NNS states)) (PP (IN with) (NP (JJ large) (JJ immigrant) (NNS populations)))))) (, ,) (NP (DT the) (NNP Senate)) (VP (VBD voted) (NP-TMP (NNP Friday)) (S (VP (TO to) (VP (VB bar) (NP (DT the) (NNP Census) (NNP Bureau)) (PP (IN from) (S (VP (VBG counting) (NP (JJ illegal) (NNS aliens)) (PP (IN in) (NP (DT the) (CD 1990) (NN population) (NN count)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="illegal aliens" type="NP">
          <tokens>
            <token id="25" string="illegal" />
            <token id="26" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="2" string="California" type="NP">
          <tokens>
            <token id="5" string="California" />
          </tokens>
        </chunking>
        <chunking id="3" string="a blow to California and other states with large immigrant populations" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="blow" />
            <token id="4" string="to" />
            <token id="5" string="California" />
            <token id="6" string="and" />
            <token id="7" string="other" />
            <token id="8" string="states" />
            <token id="9" string="with" />
            <token id="10" string="large" />
            <token id="11" string="immigrant" />
            <token id="12" string="populations" />
          </tokens>
        </chunking>
        <chunking id="4" string="the Census Bureau" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="Census" />
            <token id="22" string="Bureau" />
          </tokens>
        </chunking>
        <chunking id="5" string="a blow" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="blow" />
          </tokens>
        </chunking>
        <chunking id="6" string="other states" type="NP">
          <tokens>
            <token id="7" string="other" />
            <token id="8" string="states" />
          </tokens>
        </chunking>
        <chunking id="7" string="a blow to California" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="blow" />
            <token id="4" string="to" />
            <token id="5" string="California" />
          </tokens>
        </chunking>
        <chunking id="8" string="the 1990 population count" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="1990" />
            <token id="30" string="population" />
            <token id="31" string="count" />
          </tokens>
        </chunking>
        <chunking id="9" string="bar the Census Bureau from counting illegal aliens in the 1990 population count" type="VP">
          <tokens>
            <token id="19" string="bar" />
            <token id="20" string="the" />
            <token id="21" string="Census" />
            <token id="22" string="Bureau" />
            <token id="23" string="from" />
            <token id="24" string="counting" />
            <token id="25" string="illegal" />
            <token id="26" string="aliens" />
            <token id="27" string="in" />
            <token id="28" string="the" />
            <token id="29" string="1990" />
            <token id="30" string="population" />
            <token id="31" string="count" />
          </tokens>
        </chunking>
        <chunking id="10" string="voted Friday to bar the Census Bureau from counting illegal aliens in the 1990 population count" type="VP">
          <tokens>
            <token id="16" string="voted" />
            <token id="17" string="Friday" />
            <token id="18" string="to" />
            <token id="19" string="bar" />
            <token id="20" string="the" />
            <token id="21" string="Census" />
            <token id="22" string="Bureau" />
            <token id="23" string="from" />
            <token id="24" string="counting" />
            <token id="25" string="illegal" />
            <token id="26" string="aliens" />
            <token id="27" string="in" />
            <token id="28" string="the" />
            <token id="29" string="1990" />
            <token id="30" string="population" />
            <token id="31" string="count" />
          </tokens>
        </chunking>
        <chunking id="11" string="the Senate" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="Senate" />
          </tokens>
        </chunking>
        <chunking id="12" string="large immigrant populations" type="NP">
          <tokens>
            <token id="10" string="large" />
            <token id="11" string="immigrant" />
            <token id="12" string="populations" />
          </tokens>
        </chunking>
        <chunking id="13" string="other states with large immigrant populations" type="NP">
          <tokens>
            <token id="7" string="other" />
            <token id="8" string="states" />
            <token id="9" string="with" />
            <token id="10" string="large" />
            <token id="11" string="immigrant" />
            <token id="12" string="populations" />
          </tokens>
        </chunking>
        <chunking id="14" string="to bar the Census Bureau from counting illegal aliens in the 1990 population count" type="VP">
          <tokens>
            <token id="18" string="to" />
            <token id="19" string="bar" />
            <token id="20" string="the" />
            <token id="21" string="Census" />
            <token id="22" string="Bureau" />
            <token id="23" string="from" />
            <token id="24" string="counting" />
            <token id="25" string="illegal" />
            <token id="26" string="aliens" />
            <token id="27" string="in" />
            <token id="28" string="the" />
            <token id="29" string="1990" />
            <token id="30" string="population" />
            <token id="31" string="count" />
          </tokens>
        </chunking>
        <chunking id="15" string="counting illegal aliens in the 1990 population count" type="VP">
          <tokens>
            <token id="24" string="counting" />
            <token id="25" string="illegal" />
            <token id="26" string="aliens" />
            <token id="27" string="in" />
            <token id="28" string="the" />
            <token id="29" string="1990" />
            <token id="30" string="population" />
            <token id="31" string="count" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">blow</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">blow</governor>
          <dependent id="2">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">voted</governor>
          <dependent id="3">blow</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">California</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">blow</governor>
          <dependent id="5">California</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">blow</governor>
          <dependent id="6">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">states</governor>
          <dependent id="7">other</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">blow</governor>
          <dependent id="8">states</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">populations</governor>
          <dependent id="9">with</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">populations</governor>
          <dependent id="10">large</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">populations</governor>
          <dependent id="11">immigrant</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">states</governor>
          <dependent id="12">populations</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">Senate</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">voted</governor>
          <dependent id="15">Senate</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">voted</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="16">voted</governor>
          <dependent id="17">Friday</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">bar</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="16">voted</governor>
          <dependent id="19">bar</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">Bureau</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Bureau</governor>
          <dependent id="21">Census</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">bar</governor>
          <dependent id="22">Bureau</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">counting</governor>
          <dependent id="23">from</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="19">bar</governor>
          <dependent id="24">counting</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">aliens</governor>
          <dependent id="25">illegal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">counting</governor>
          <dependent id="26">aliens</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">count</governor>
          <dependent id="27">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">count</governor>
          <dependent id="28">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="31">count</governor>
          <dependent id="29">1990</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">count</governor>
          <dependent id="30">population</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">counting</governor>
          <dependent id="31">count</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Senate" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="15" string="Senate" />
          </tokens>
        </entity>
        <entity id="2" string="California" type="LOCATION" score="0.0">
          <tokens>
            <token id="5" string="California" />
          </tokens>
        </entity>
        <entity id="3" string="Friday" type="DATE" score="0.0">
          <tokens>
            <token id="17" string="Friday" />
          </tokens>
        </entity>
        <entity id="4" string="1990" type="DATE" score="0.0">
          <tokens>
            <token id="29" string="1990" />
          </tokens>
        </entity>
        <entity id="5" string="Census Bureau" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="21" string="Census" />
            <token id="22" string="Bureau" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>The action came on a voice vote, despite arguments from the Bush Administration and other opponents that it is both unconstitutional and unworkable.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="action" lemma="action" stem="action" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="came" lemma="come" stem="came" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="voice" lemma="voice" stem="voic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="vote" lemma="vote" stem="vote" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="despite" lemma="despite" stem="despit" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="arguments" lemma="argument" stem="argument" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Bush" lemma="Bush" stem="bush" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="14" string="Administration" lemma="Administration" stem="administr" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="opponents" lemma="opponent" stem="oppon" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="both" lemma="both" stem="both" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="unconstitutional" lemma="unconstitutional" stem="unconstitut" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="unworkable" lemma="unworkable" stem="unwork" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN action)) (VP (VBD came) (PP (IN on) (NP (DT a) (NN voice) (NN vote))) (, ,) (PP (IN despite) (NP (NP (NP (NNS arguments)) (PP (IN from) (NP (DT the) (NNP Bush) (NNP Administration)))) (CC and) (NP (NP (JJ other) (NNS opponents)) (SBAR (IN that) (S (NP (PRP it)) (VP (VBZ is) (ADJP (DT both) (JJ unconstitutional) (CC and) (JJ unworkable))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is both unconstitutional and unworkable" type="VP">
          <tokens>
            <token id="20" string="is" />
            <token id="21" string="both" />
            <token id="22" string="unconstitutional" />
            <token id="23" string="and" />
            <token id="24" string="unworkable" />
          </tokens>
        </chunking>
        <chunking id="2" string="both unconstitutional and unworkable" type="ADJP">
          <tokens>
            <token id="21" string="both" />
            <token id="22" string="unconstitutional" />
            <token id="23" string="and" />
            <token id="24" string="unworkable" />
          </tokens>
        </chunking>
        <chunking id="3" string="it" type="NP">
          <tokens>
            <token id="19" string="it" />
          </tokens>
        </chunking>
        <chunking id="4" string="other opponents" type="NP">
          <tokens>
            <token id="16" string="other" />
            <token id="17" string="opponents" />
          </tokens>
        </chunking>
        <chunking id="5" string="the Bush Administration" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="Bush" />
            <token id="14" string="Administration" />
          </tokens>
        </chunking>
        <chunking id="6" string="that it is both unconstitutional and unworkable" type="SBAR">
          <tokens>
            <token id="18" string="that" />
            <token id="19" string="it" />
            <token id="20" string="is" />
            <token id="21" string="both" />
            <token id="22" string="unconstitutional" />
            <token id="23" string="and" />
            <token id="24" string="unworkable" />
          </tokens>
        </chunking>
        <chunking id="7" string="a voice vote" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="voice" />
            <token id="7" string="vote" />
          </tokens>
        </chunking>
        <chunking id="8" string="arguments from the Bush Administration" type="NP">
          <tokens>
            <token id="10" string="arguments" />
            <token id="11" string="from" />
            <token id="12" string="the" />
            <token id="13" string="Bush" />
            <token id="14" string="Administration" />
          </tokens>
        </chunking>
        <chunking id="9" string="other opponents that it is both unconstitutional and unworkable" type="NP">
          <tokens>
            <token id="16" string="other" />
            <token id="17" string="opponents" />
            <token id="18" string="that" />
            <token id="19" string="it" />
            <token id="20" string="is" />
            <token id="21" string="both" />
            <token id="22" string="unconstitutional" />
            <token id="23" string="and" />
            <token id="24" string="unworkable" />
          </tokens>
        </chunking>
        <chunking id="10" string="The action" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="action" />
          </tokens>
        </chunking>
        <chunking id="11" string="arguments" type="NP">
          <tokens>
            <token id="10" string="arguments" />
          </tokens>
        </chunking>
        <chunking id="12" string="came on a voice vote , despite arguments from the Bush Administration and other opponents that it is both unconstitutional and unworkable" type="VP">
          <tokens>
            <token id="3" string="came" />
            <token id="4" string="on" />
            <token id="5" string="a" />
            <token id="6" string="voice" />
            <token id="7" string="vote" />
            <token id="8" string="," />
            <token id="9" string="despite" />
            <token id="10" string="arguments" />
            <token id="11" string="from" />
            <token id="12" string="the" />
            <token id="13" string="Bush" />
            <token id="14" string="Administration" />
            <token id="15" string="and" />
            <token id="16" string="other" />
            <token id="17" string="opponents" />
            <token id="18" string="that" />
            <token id="19" string="it" />
            <token id="20" string="is" />
            <token id="21" string="both" />
            <token id="22" string="unconstitutional" />
            <token id="23" string="and" />
            <token id="24" string="unworkable" />
          </tokens>
        </chunking>
        <chunking id="13" string="arguments from the Bush Administration and other opponents that it is both unconstitutional and unworkable" type="NP">
          <tokens>
            <token id="10" string="arguments" />
            <token id="11" string="from" />
            <token id="12" string="the" />
            <token id="13" string="Bush" />
            <token id="14" string="Administration" />
            <token id="15" string="and" />
            <token id="16" string="other" />
            <token id="17" string="opponents" />
            <token id="18" string="that" />
            <token id="19" string="it" />
            <token id="20" string="is" />
            <token id="21" string="both" />
            <token id="22" string="unconstitutional" />
            <token id="23" string="and" />
            <token id="24" string="unworkable" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">action</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">came</governor>
          <dependent id="2">action</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">came</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">vote</governor>
          <dependent id="4">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">vote</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">vote</governor>
          <dependent id="6">voice</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">came</governor>
          <dependent id="7">vote</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">arguments</governor>
          <dependent id="9">despite</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">came</governor>
          <dependent id="10">arguments</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Administration</governor>
          <dependent id="11">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">Administration</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Administration</governor>
          <dependent id="13">Bush</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">arguments</governor>
          <dependent id="14">Administration</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">arguments</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">opponents</governor>
          <dependent id="16">other</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">arguments</governor>
          <dependent id="17">opponents</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">unconstitutional</governor>
          <dependent id="18">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">unconstitutional</governor>
          <dependent id="19">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="22">unconstitutional</governor>
          <dependent id="20">is</dependent>
        </dependency>
        <dependency type="cc:preconj">
          <governor id="22">unconstitutional</governor>
          <dependent id="21">both</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="17">opponents</governor>
          <dependent id="22">unconstitutional</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="22">unconstitutional</governor>
          <dependent id="23">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="22">unconstitutional</governor>
          <dependent id="24">unworkable</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Bush" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Bush" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>Just before the voice vote, the senators voted, 50 to 41, against killing the proposal to bar aliens from the count.</content>
      <tokens>
        <token id="1" string="Just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="voice" lemma="voice" stem="voic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="vote" lemma="vote" stem="vote" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="senators" lemma="senator" stem="senat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="voted" lemma="vote" stem="vote" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="50" lemma="50" stem="50" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="41" lemma="41" stem="41" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="killing" lemma="kill" stem="kill" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="proposal" lemma="proposal" stem="propos" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="bar" lemma="bar" stem="bar" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="aliens" lemma="alien" stem="alien" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="count" lemma="count" stem="count" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (RB Just) (IN before) (NP (DT the) (NN voice) (NN vote))) (, ,) (NP (DT the) (NNS senators)) (VP (VP (VBD voted)) (, ,) (NP (NP (QP (CD 50) (TO to) (CD 41))) (, ,) (PP (IN against) (S (VP (VBG killing) (NP (DT the) (NN proposal)) (PP (TO to) (NP (NN bar) (NNS aliens))) (PP (IN from) (NP (DT the) (NN count)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the proposal" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="proposal" />
          </tokens>
        </chunking>
        <chunking id="2" string="the voice vote" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="voice" />
            <token id="5" string="vote" />
          </tokens>
        </chunking>
        <chunking id="3" string="the senators" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="senators" />
          </tokens>
        </chunking>
        <chunking id="4" string="voted , 50 to 41 , against killing the proposal to bar aliens from the count" type="VP">
          <tokens>
            <token id="9" string="voted" />
            <token id="10" string="," />
            <token id="11" string="50" />
            <token id="12" string="to" />
            <token id="13" string="41" />
            <token id="14" string="," />
            <token id="15" string="against" />
            <token id="16" string="killing" />
            <token id="17" string="the" />
            <token id="18" string="proposal" />
            <token id="19" string="to" />
            <token id="20" string="bar" />
            <token id="21" string="aliens" />
            <token id="22" string="from" />
            <token id="23" string="the" />
            <token id="24" string="count" />
          </tokens>
        </chunking>
        <chunking id="5" string="50 to 41" type="NP">
          <tokens>
            <token id="11" string="50" />
            <token id="12" string="to" />
            <token id="13" string="41" />
          </tokens>
        </chunking>
        <chunking id="6" string="voted" type="VP">
          <tokens>
            <token id="9" string="voted" />
          </tokens>
        </chunking>
        <chunking id="7" string="bar aliens" type="NP">
          <tokens>
            <token id="20" string="bar" />
            <token id="21" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="8" string="killing the proposal to bar aliens from the count" type="VP">
          <tokens>
            <token id="16" string="killing" />
            <token id="17" string="the" />
            <token id="18" string="proposal" />
            <token id="19" string="to" />
            <token id="20" string="bar" />
            <token id="21" string="aliens" />
            <token id="22" string="from" />
            <token id="23" string="the" />
            <token id="24" string="count" />
          </tokens>
        </chunking>
        <chunking id="9" string="the count" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="count" />
          </tokens>
        </chunking>
        <chunking id="10" string="50 to 41 , against killing the proposal to bar aliens from the count" type="NP">
          <tokens>
            <token id="11" string="50" />
            <token id="12" string="to" />
            <token id="13" string="41" />
            <token id="14" string="," />
            <token id="15" string="against" />
            <token id="16" string="killing" />
            <token id="17" string="the" />
            <token id="18" string="proposal" />
            <token id="19" string="to" />
            <token id="20" string="bar" />
            <token id="21" string="aliens" />
            <token id="22" string="from" />
            <token id="23" string="the" />
            <token id="24" string="count" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="5">vote</governor>
          <dependent id="1">Just</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">vote</governor>
          <dependent id="2">before</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">vote</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">vote</governor>
          <dependent id="4">voice</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">voted</governor>
          <dependent id="5">vote</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">senators</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">voted</governor>
          <dependent id="8">senators</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">voted</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">41</governor>
          <dependent id="11">50</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="13">41</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">voted</governor>
          <dependent id="13">41</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">killing</governor>
          <dependent id="15">against</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="13">41</governor>
          <dependent id="16">killing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">proposal</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">killing</governor>
          <dependent id="18">proposal</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">aliens</governor>
          <dependent id="19">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">aliens</governor>
          <dependent id="20">bar</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">killing</governor>
          <dependent id="21">aliens</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">count</governor>
          <dependent id="22">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">count</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">killing</governor>
          <dependent id="24">count</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="50" type="NUMBER" score="0.0">
          <tokens>
            <token id="11" string="50" />
          </tokens>
        </entity>
        <entity id="2" string="41" type="NUMBER" score="0.0">
          <tokens>
            <token id="13" string="41" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>A Senate-House conference committee will decide whether the prohibition against including illegal immigrants in the census totals will be retained or dropped from a $17.4-billion appropriations bill for the State, Justice and Commerce departments.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Senate-House" lemma="senate-house" stem="senate-hous" pos="JJ" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="3" string="conference" lemma="conference" stem="confer" pos="NN" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="4" string="committee" lemma="committee" stem="committe" pos="NN" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="5" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="decide" lemma="decide" stem="decid" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="whether" lemma="whether" stem="whether" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="prohibition" lemma="prohibition" stem="prohibit" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="including" lemma="include" stem="includ" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="immigrants" lemma="immigrant" stem="immigr" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="census" lemma="census" stem="censu" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="totals" lemma="total" stem="total" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="retained" lemma="retain" stem="retain" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="dropped" lemma="drop" stem="drop" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="26" string="17.4-billion" lemma="17.4-billion" stem="17.4-billion" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="27" string="appropriations" lemma="appropriation" stem="appropri" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="bill" lemma="bill" stem="bill" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="State" lemma="State" stem="state" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="32" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="Justice" lemma="Justice" stem="justic" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="34" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="Commerce" lemma="Commerce" stem="commerc" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="36" string="departments" lemma="department" stem="depart" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT A) (JJ Senate-House) (NN conference) (NN committee)) (VP (MD will) (VP (VB decide) (SBAR (IN whether) (S (NP (NP (DT the) (NN prohibition)) (PP (IN against) (S (VP (VBG including) (NP (JJ illegal) (NNS immigrants)) (PP (IN in) (NP (DT the) (NN census) (NNS totals))))))) (VP (MD will) (VP (VB be) (VP (VBN retained) (CC or) (VBN dropped) (PP (IN from) (NP (NP (DT a) ($ $) (CD 17.4-billion) (NNS appropriations) (NN bill)) (PP (IN for) (NP (DT the) (NNP State) (, ,) (NNP Justice) (CC and) (NNP Commerce) (NNS departments)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a $ 17.4-billion appropriations bill" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="$" />
            <token id="26" string="17.4-billion" />
            <token id="27" string="appropriations" />
            <token id="28" string="bill" />
          </tokens>
        </chunking>
        <chunking id="2" string="the prohibition" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="prohibition" />
          </tokens>
        </chunking>
        <chunking id="3" string="the prohibition against including illegal immigrants in the census totals" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="prohibition" />
            <token id="10" string="against" />
            <token id="11" string="including" />
            <token id="12" string="illegal" />
            <token id="13" string="immigrants" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="census" />
            <token id="17" string="totals" />
          </tokens>
        </chunking>
        <chunking id="4" string="retained or dropped from a $ 17.4-billion appropriations bill for the State , Justice and Commerce departments" type="VP">
          <tokens>
            <token id="20" string="retained" />
            <token id="21" string="or" />
            <token id="22" string="dropped" />
            <token id="23" string="from" />
            <token id="24" string="a" />
            <token id="25" string="$" />
            <token id="26" string="17.4-billion" />
            <token id="27" string="appropriations" />
            <token id="28" string="bill" />
            <token id="29" string="for" />
            <token id="30" string="the" />
            <token id="31" string="State" />
            <token id="32" string="," />
            <token id="33" string="Justice" />
            <token id="34" string="and" />
            <token id="35" string="Commerce" />
            <token id="36" string="departments" />
          </tokens>
        </chunking>
        <chunking id="5" string="including illegal immigrants in the census totals" type="VP">
          <tokens>
            <token id="11" string="including" />
            <token id="12" string="illegal" />
            <token id="13" string="immigrants" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="census" />
            <token id="17" string="totals" />
          </tokens>
        </chunking>
        <chunking id="6" string="be retained or dropped from a $ 17.4-billion appropriations bill for the State , Justice and Commerce departments" type="VP">
          <tokens>
            <token id="19" string="be" />
            <token id="20" string="retained" />
            <token id="21" string="or" />
            <token id="22" string="dropped" />
            <token id="23" string="from" />
            <token id="24" string="a" />
            <token id="25" string="$" />
            <token id="26" string="17.4-billion" />
            <token id="27" string="appropriations" />
            <token id="28" string="bill" />
            <token id="29" string="for" />
            <token id="30" string="the" />
            <token id="31" string="State" />
            <token id="32" string="," />
            <token id="33" string="Justice" />
            <token id="34" string="and" />
            <token id="35" string="Commerce" />
            <token id="36" string="departments" />
          </tokens>
        </chunking>
        <chunking id="7" string="illegal immigrants" type="NP">
          <tokens>
            <token id="12" string="illegal" />
            <token id="13" string="immigrants" />
          </tokens>
        </chunking>
        <chunking id="8" string="will decide whether the prohibition against including illegal immigrants in the census totals will be retained or dropped from a $ 17.4-billion appropriations bill for the State , Justice and Commerce departments" type="VP">
          <tokens>
            <token id="5" string="will" />
            <token id="6" string="decide" />
            <token id="7" string="whether" />
            <token id="8" string="the" />
            <token id="9" string="prohibition" />
            <token id="10" string="against" />
            <token id="11" string="including" />
            <token id="12" string="illegal" />
            <token id="13" string="immigrants" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="census" />
            <token id="17" string="totals" />
            <token id="18" string="will" />
            <token id="19" string="be" />
            <token id="20" string="retained" />
            <token id="21" string="or" />
            <token id="22" string="dropped" />
            <token id="23" string="from" />
            <token id="24" string="a" />
            <token id="25" string="$" />
            <token id="26" string="17.4-billion" />
            <token id="27" string="appropriations" />
            <token id="28" string="bill" />
            <token id="29" string="for" />
            <token id="30" string="the" />
            <token id="31" string="State" />
            <token id="32" string="," />
            <token id="33" string="Justice" />
            <token id="34" string="and" />
            <token id="35" string="Commerce" />
            <token id="36" string="departments" />
          </tokens>
        </chunking>
        <chunking id="9" string="will be retained or dropped from a $ 17.4-billion appropriations bill for the State , Justice and Commerce departments" type="VP">
          <tokens>
            <token id="18" string="will" />
            <token id="19" string="be" />
            <token id="20" string="retained" />
            <token id="21" string="or" />
            <token id="22" string="dropped" />
            <token id="23" string="from" />
            <token id="24" string="a" />
            <token id="25" string="$" />
            <token id="26" string="17.4-billion" />
            <token id="27" string="appropriations" />
            <token id="28" string="bill" />
            <token id="29" string="for" />
            <token id="30" string="the" />
            <token id="31" string="State" />
            <token id="32" string="," />
            <token id="33" string="Justice" />
            <token id="34" string="and" />
            <token id="35" string="Commerce" />
            <token id="36" string="departments" />
          </tokens>
        </chunking>
        <chunking id="10" string="a $ 17.4-billion appropriations bill for the State , Justice and Commerce departments" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="$" />
            <token id="26" string="17.4-billion" />
            <token id="27" string="appropriations" />
            <token id="28" string="bill" />
            <token id="29" string="for" />
            <token id="30" string="the" />
            <token id="31" string="State" />
            <token id="32" string="," />
            <token id="33" string="Justice" />
            <token id="34" string="and" />
            <token id="35" string="Commerce" />
            <token id="36" string="departments" />
          </tokens>
        </chunking>
        <chunking id="11" string="decide whether the prohibition against including illegal immigrants in the census totals will be retained or dropped from a $ 17.4-billion appropriations bill for the State , Justice and Commerce departments" type="VP">
          <tokens>
            <token id="6" string="decide" />
            <token id="7" string="whether" />
            <token id="8" string="the" />
            <token id="9" string="prohibition" />
            <token id="10" string="against" />
            <token id="11" string="including" />
            <token id="12" string="illegal" />
            <token id="13" string="immigrants" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="census" />
            <token id="17" string="totals" />
            <token id="18" string="will" />
            <token id="19" string="be" />
            <token id="20" string="retained" />
            <token id="21" string="or" />
            <token id="22" string="dropped" />
            <token id="23" string="from" />
            <token id="24" string="a" />
            <token id="25" string="$" />
            <token id="26" string="17.4-billion" />
            <token id="27" string="appropriations" />
            <token id="28" string="bill" />
            <token id="29" string="for" />
            <token id="30" string="the" />
            <token id="31" string="State" />
            <token id="32" string="," />
            <token id="33" string="Justice" />
            <token id="34" string="and" />
            <token id="35" string="Commerce" />
            <token id="36" string="departments" />
          </tokens>
        </chunking>
        <chunking id="12" string="A Senate-House conference committee" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="Senate-House" />
            <token id="3" string="conference" />
            <token id="4" string="committee" />
          </tokens>
        </chunking>
        <chunking id="13" string="the census totals" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="census" />
            <token id="17" string="totals" />
          </tokens>
        </chunking>
        <chunking id="14" string="the State , Justice and Commerce departments" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="State" />
            <token id="32" string="," />
            <token id="33" string="Justice" />
            <token id="34" string="and" />
            <token id="35" string="Commerce" />
            <token id="36" string="departments" />
          </tokens>
        </chunking>
        <chunking id="15" string="whether the prohibition against including illegal immigrants in the census totals will be retained or dropped from a $ 17.4-billion appropriations bill for the State , Justice and Commerce departments" type="SBAR">
          <tokens>
            <token id="7" string="whether" />
            <token id="8" string="the" />
            <token id="9" string="prohibition" />
            <token id="10" string="against" />
            <token id="11" string="including" />
            <token id="12" string="illegal" />
            <token id="13" string="immigrants" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="census" />
            <token id="17" string="totals" />
            <token id="18" string="will" />
            <token id="19" string="be" />
            <token id="20" string="retained" />
            <token id="21" string="or" />
            <token id="22" string="dropped" />
            <token id="23" string="from" />
            <token id="24" string="a" />
            <token id="25" string="$" />
            <token id="26" string="17.4-billion" />
            <token id="27" string="appropriations" />
            <token id="28" string="bill" />
            <token id="29" string="for" />
            <token id="30" string="the" />
            <token id="31" string="State" />
            <token id="32" string="," />
            <token id="33" string="Justice" />
            <token id="34" string="and" />
            <token id="35" string="Commerce" />
            <token id="36" string="departments" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">committee</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">committee</governor>
          <dependent id="2">Senate-House</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">committee</governor>
          <dependent id="3">conference</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">decide</governor>
          <dependent id="4">committee</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">decide</governor>
          <dependent id="5">will</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">decide</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">retained</governor>
          <dependent id="7">whether</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">prohibition</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="20">retained</governor>
          <dependent id="9">prohibition</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">including</governor>
          <dependent id="10">against</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="9">prohibition</governor>
          <dependent id="11">including</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">immigrants</governor>
          <dependent id="12">illegal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">including</governor>
          <dependent id="13">immigrants</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">totals</governor>
          <dependent id="14">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">totals</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">totals</governor>
          <dependent id="16">census</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">including</governor>
          <dependent id="17">totals</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="20">retained</governor>
          <dependent id="18">will</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="20">retained</governor>
          <dependent id="19">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">decide</governor>
          <dependent id="20">retained</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="20">retained</governor>
          <dependent id="21">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="20">retained</governor>
          <dependent id="22">dropped</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">bill</governor>
          <dependent id="23">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">bill</governor>
          <dependent id="24">a</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="28">bill</governor>
          <dependent id="25">$</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="28">bill</governor>
          <dependent id="26">17.4-billion</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">bill</governor>
          <dependent id="27">appropriations</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">retained</governor>
          <dependent id="28">bill</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">departments</governor>
          <dependent id="29">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="36">departments</governor>
          <dependent id="30">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="36">departments</governor>
          <dependent id="31">State</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="31">State</governor>
          <dependent id="33">Justice</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="31">State</governor>
          <dependent id="34">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="31">State</governor>
          <dependent id="35">Commerce</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">bill</governor>
          <dependent id="36">departments</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Justice" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="33" string="Justice" />
          </tokens>
        </entity>
        <entity id="2" string="State" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="31" string="State" />
          </tokens>
        </entity>
        <entity id="3" string="Senate-House conference committee" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="2" string="Senate-House" />
            <token id="3" string="conference" />
            <token id="4" string="committee" />
          </tokens>
        </entity>
        <entity id="4" string="Commerce" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="35" string="Commerce" />
          </tokens>
        </entity>
        <entity id="5" string="$ 17.4-billion" type="MONEY" score="0.0">
          <tokens>
            <token id="25" string="$" />
            <token id="26" string="17.4-billion" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>Even if the prohibition survives, Secretary of Commerce Robert A. Mosbacher has said that he would ask President Bush to veto any bill that comes to his desk with such a provision.</content>
      <tokens>
        <token id="1" string="Even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="prohibition" lemma="prohibition" stem="prohibit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="survives" lemma="survive" stem="surviv" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Secretary" lemma="Secretary" stem="secretari" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="Commerce" lemma="Commerce" stem="commerc" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="Robert" lemma="Robert" stem="robert" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="11" string="A." lemma="A." stem="a." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="12" string="Mosbacher" lemma="Mosbacher" stem="mosbach" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="13" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="ask" lemma="ask" stem="ask" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="President" lemma="President" stem="presid" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="true" is_refers="false" />
        <token id="20" string="Bush" lemma="Bush" stem="bush" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="21" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="veto" lemma="veto" stem="veto" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="bill" lemma="bill" stem="bill" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="comes" lemma="come" stem="come" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="desk" lemma="desk" stem="desk" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="provision" lemma="provision" stem="provis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (RB Even) (IN if) (S (NP (DT the) (NN prohibition)) (VP (VBZ survives)))) (, ,) (NP (NP (NNP Secretary)) (PP (IN of) (NP (NNP Commerce) (NNP Robert) (NNP A.) (NNP Mosbacher)))) (VP (VBZ has) (VP (VBD said) (SBAR (IN that) (S (NP (PRP he)) (VP (MD would) (VP (VB ask) (S (NP (NNP President) (NNP Bush)) (VP (TO to) (VP (VB veto) (NP (NP (DT any) (NN bill)) (SBAR (WHNP (WDT that)) (S (VP (VBZ comes) (PP (TO to) (NP (PRP$ his) (NN desk))) (PP (IN with) (NP (JJ such) (DT a) (NN provision)))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the prohibition" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="prohibition" />
          </tokens>
        </chunking>
        <chunking id="2" string="such a provision" type="NP">
          <tokens>
            <token id="31" string="such" />
            <token id="32" string="a" />
            <token id="33" string="provision" />
          </tokens>
        </chunking>
        <chunking id="3" string="President Bush" type="NP">
          <tokens>
            <token id="19" string="President" />
            <token id="20" string="Bush" />
          </tokens>
        </chunking>
        <chunking id="4" string="Secretary" type="NP">
          <tokens>
            <token id="7" string="Secretary" />
          </tokens>
        </chunking>
        <chunking id="5" string="has said that he would ask President Bush to veto any bill that comes to his desk with such a provision" type="VP">
          <tokens>
            <token id="13" string="has" />
            <token id="14" string="said" />
            <token id="15" string="that" />
            <token id="16" string="he" />
            <token id="17" string="would" />
            <token id="18" string="ask" />
            <token id="19" string="President" />
            <token id="20" string="Bush" />
            <token id="21" string="to" />
            <token id="22" string="veto" />
            <token id="23" string="any" />
            <token id="24" string="bill" />
            <token id="25" string="that" />
            <token id="26" string="comes" />
            <token id="27" string="to" />
            <token id="28" string="his" />
            <token id="29" string="desk" />
            <token id="30" string="with" />
            <token id="31" string="such" />
            <token id="32" string="a" />
            <token id="33" string="provision" />
          </tokens>
        </chunking>
        <chunking id="6" string="ask President Bush to veto any bill that comes to his desk with such a provision" type="VP">
          <tokens>
            <token id="18" string="ask" />
            <token id="19" string="President" />
            <token id="20" string="Bush" />
            <token id="21" string="to" />
            <token id="22" string="veto" />
            <token id="23" string="any" />
            <token id="24" string="bill" />
            <token id="25" string="that" />
            <token id="26" string="comes" />
            <token id="27" string="to" />
            <token id="28" string="his" />
            <token id="29" string="desk" />
            <token id="30" string="with" />
            <token id="31" string="such" />
            <token id="32" string="a" />
            <token id="33" string="provision" />
          </tokens>
        </chunking>
        <chunking id="7" string="to veto any bill that comes to his desk with such a provision" type="VP">
          <tokens>
            <token id="21" string="to" />
            <token id="22" string="veto" />
            <token id="23" string="any" />
            <token id="24" string="bill" />
            <token id="25" string="that" />
            <token id="26" string="comes" />
            <token id="27" string="to" />
            <token id="28" string="his" />
            <token id="29" string="desk" />
            <token id="30" string="with" />
            <token id="31" string="such" />
            <token id="32" string="a" />
            <token id="33" string="provision" />
          </tokens>
        </chunking>
        <chunking id="8" string="veto any bill that comes to his desk with such a provision" type="VP">
          <tokens>
            <token id="22" string="veto" />
            <token id="23" string="any" />
            <token id="24" string="bill" />
            <token id="25" string="that" />
            <token id="26" string="comes" />
            <token id="27" string="to" />
            <token id="28" string="his" />
            <token id="29" string="desk" />
            <token id="30" string="with" />
            <token id="31" string="such" />
            <token id="32" string="a" />
            <token id="33" string="provision" />
          </tokens>
        </chunking>
        <chunking id="9" string="any bill" type="NP">
          <tokens>
            <token id="23" string="any" />
            <token id="24" string="bill" />
          </tokens>
        </chunking>
        <chunking id="10" string="Commerce Robert A. Mosbacher" type="NP">
          <tokens>
            <token id="9" string="Commerce" />
            <token id="10" string="Robert" />
            <token id="11" string="A." />
            <token id="12" string="Mosbacher" />
          </tokens>
        </chunking>
        <chunking id="11" string="said that he would ask President Bush to veto any bill that comes to his desk with such a provision" type="VP">
          <tokens>
            <token id="14" string="said" />
            <token id="15" string="that" />
            <token id="16" string="he" />
            <token id="17" string="would" />
            <token id="18" string="ask" />
            <token id="19" string="President" />
            <token id="20" string="Bush" />
            <token id="21" string="to" />
            <token id="22" string="veto" />
            <token id="23" string="any" />
            <token id="24" string="bill" />
            <token id="25" string="that" />
            <token id="26" string="comes" />
            <token id="27" string="to" />
            <token id="28" string="his" />
            <token id="29" string="desk" />
            <token id="30" string="with" />
            <token id="31" string="such" />
            <token id="32" string="a" />
            <token id="33" string="provision" />
          </tokens>
        </chunking>
        <chunking id="12" string="his desk" type="NP">
          <tokens>
            <token id="28" string="his" />
            <token id="29" string="desk" />
          </tokens>
        </chunking>
        <chunking id="13" string="that comes to his desk with such a provision" type="SBAR">
          <tokens>
            <token id="25" string="that" />
            <token id="26" string="comes" />
            <token id="27" string="to" />
            <token id="28" string="his" />
            <token id="29" string="desk" />
            <token id="30" string="with" />
            <token id="31" string="such" />
            <token id="32" string="a" />
            <token id="33" string="provision" />
          </tokens>
        </chunking>
        <chunking id="14" string="any bill that comes to his desk with such a provision" type="NP">
          <tokens>
            <token id="23" string="any" />
            <token id="24" string="bill" />
            <token id="25" string="that" />
            <token id="26" string="comes" />
            <token id="27" string="to" />
            <token id="28" string="his" />
            <token id="29" string="desk" />
            <token id="30" string="with" />
            <token id="31" string="such" />
            <token id="32" string="a" />
            <token id="33" string="provision" />
          </tokens>
        </chunking>
        <chunking id="15" string="that he would ask President Bush to veto any bill that comes to his desk with such a provision" type="SBAR">
          <tokens>
            <token id="15" string="that" />
            <token id="16" string="he" />
            <token id="17" string="would" />
            <token id="18" string="ask" />
            <token id="19" string="President" />
            <token id="20" string="Bush" />
            <token id="21" string="to" />
            <token id="22" string="veto" />
            <token id="23" string="any" />
            <token id="24" string="bill" />
            <token id="25" string="that" />
            <token id="26" string="comes" />
            <token id="27" string="to" />
            <token id="28" string="his" />
            <token id="29" string="desk" />
            <token id="30" string="with" />
            <token id="31" string="such" />
            <token id="32" string="a" />
            <token id="33" string="provision" />
          </tokens>
        </chunking>
        <chunking id="16" string="Even if the prohibition survives" type="SBAR">
          <tokens>
            <token id="1" string="Even" />
            <token id="2" string="if" />
            <token id="3" string="the" />
            <token id="4" string="prohibition" />
            <token id="5" string="survives" />
          </tokens>
        </chunking>
        <chunking id="17" string="survives" type="VP">
          <tokens>
            <token id="5" string="survives" />
          </tokens>
        </chunking>
        <chunking id="18" string="comes to his desk with such a provision" type="VP">
          <tokens>
            <token id="26" string="comes" />
            <token id="27" string="to" />
            <token id="28" string="his" />
            <token id="29" string="desk" />
            <token id="30" string="with" />
            <token id="31" string="such" />
            <token id="32" string="a" />
            <token id="33" string="provision" />
          </tokens>
        </chunking>
        <chunking id="19" string="he" type="NP">
          <tokens>
            <token id="16" string="he" />
          </tokens>
        </chunking>
        <chunking id="20" string="would ask President Bush to veto any bill that comes to his desk with such a provision" type="VP">
          <tokens>
            <token id="17" string="would" />
            <token id="18" string="ask" />
            <token id="19" string="President" />
            <token id="20" string="Bush" />
            <token id="21" string="to" />
            <token id="22" string="veto" />
            <token id="23" string="any" />
            <token id="24" string="bill" />
            <token id="25" string="that" />
            <token id="26" string="comes" />
            <token id="27" string="to" />
            <token id="28" string="his" />
            <token id="29" string="desk" />
            <token id="30" string="with" />
            <token id="31" string="such" />
            <token id="32" string="a" />
            <token id="33" string="provision" />
          </tokens>
        </chunking>
        <chunking id="21" string="Secretary of Commerce Robert A. Mosbacher" type="NP">
          <tokens>
            <token id="7" string="Secretary" />
            <token id="8" string="of" />
            <token id="9" string="Commerce" />
            <token id="10" string="Robert" />
            <token id="11" string="A." />
            <token id="12" string="Mosbacher" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="5">survives</governor>
          <dependent id="1">Even</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">survives</governor>
          <dependent id="2">if</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">prohibition</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">survives</governor>
          <dependent id="4">prohibition</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="14">said</governor>
          <dependent id="5">survives</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">said</governor>
          <dependent id="7">Secretary</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Mosbacher</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Mosbacher</governor>
          <dependent id="9">Commerce</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Mosbacher</governor>
          <dependent id="10">Robert</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Mosbacher</governor>
          <dependent id="11">A.</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">Secretary</governor>
          <dependent id="12">Mosbacher</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">said</governor>
          <dependent id="13">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">said</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">ask</governor>
          <dependent id="15">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">ask</governor>
          <dependent id="16">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">ask</governor>
          <dependent id="17">would</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">said</governor>
          <dependent id="18">ask</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Bush</governor>
          <dependent id="19">President</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">ask</governor>
          <dependent id="20">Bush</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">veto</governor>
          <dependent id="21">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="18">ask</governor>
          <dependent id="22">veto</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">bill</governor>
          <dependent id="23">any</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">veto</governor>
          <dependent id="24">bill</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">comes</governor>
          <dependent id="25">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="24">bill</governor>
          <dependent id="26">comes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">desk</governor>
          <dependent id="27">to</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="29">desk</governor>
          <dependent id="28">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">comes</governor>
          <dependent id="29">desk</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">provision</governor>
          <dependent id="30">with</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="33">provision</governor>
          <dependent id="31">such</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">provision</governor>
          <dependent id="32">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">comes</governor>
          <dependent id="33">provision</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Bush" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="Bush" />
          </tokens>
        </entity>
        <entity id="2" string="President" type="TITLE" score="0.0">
          <tokens>
            <token id="19" string="President" />
          </tokens>
        </entity>
        <entity id="3" string="Robert A. Mosbacher" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Robert" />
            <token id="11" string="A." />
            <token id="12" string="Mosbacher" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>At stake are the number of seats in Congress for California, Florida, New York, Illinois, Pennsylvania and other states that will be reapportioned on the basis of next year&amp;apost;s census.</content>
      <tokens>
        <token id="1" string="At" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="stake" lemma="stake" stem="stake" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="number" lemma="number" stem="number" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="seats" lemma="seat" stem="seat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Congress" lemma="Congress" stem="congress" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="10" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="California" lemma="California" stem="california" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="Florida" lemma="Florida" stem="florida" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="New" lemma="New" stem="new" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="16" string="York" lemma="York" stem="york" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="Illinois" lemma="Illinois" stem="illinoi" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="Pennsylvania" lemma="Pennsylvania" stem="pennsylvania" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="21" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="states" lemma="state" stem="state" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="24" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="reapportioned" lemma="reapportion" stem="reapport" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="basis" lemma="basis" stem="basi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="next" lemma="next" stem="next" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="33" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="34" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="census" lemma="census" stem="censu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (PP (IN At) (NP (NN stake))) (VP (VBP are)) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NP (NNS seats)) (PP (IN in) (NP (NNP Congress))))) (PP (IN for) (NP (NP (NNP California)) (, ,) (NP (NNP Florida)) (, ,) (NP (NNP New) (NNP York)) (, ,) (NP (NNP Illinois)) (, ,) (NP (NNP Pennsylvania)) (CC and) (NP (JJ other) (NNS states)))) (SBAR (WHNP (WDT that)) (S (VP (MD will) (VP (VB be) (VP (VBN reapportioned) (PP (IN on) (NP (NP (DT the) (NN basis)) (PP (IN of) (NP (NP-TMP (JJ next) (NN year) (POS 's)) (NN census))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="New York" type="NP">
          <tokens>
            <token id="15" string="New" />
            <token id="16" string="York" />
          </tokens>
        </chunking>
        <chunking id="2" string="California" type="NP">
          <tokens>
            <token id="11" string="California" />
          </tokens>
        </chunking>
        <chunking id="3" string="that will be reapportioned on the basis of next year 's census" type="SBAR">
          <tokens>
            <token id="24" string="that" />
            <token id="25" string="will" />
            <token id="26" string="be" />
            <token id="27" string="reapportioned" />
            <token id="28" string="on" />
            <token id="29" string="the" />
            <token id="30" string="basis" />
            <token id="31" string="of" />
            <token id="32" string="next" />
            <token id="33" string="year" />
            <token id="34" string="'s" />
            <token id="35" string="census" />
          </tokens>
        </chunking>
        <chunking id="4" string="the number of seats in Congress for California , Florida , New York , Illinois , Pennsylvania and other states that will be reapportioned on the basis of next year 's census" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="number" />
            <token id="6" string="of" />
            <token id="7" string="seats" />
            <token id="8" string="in" />
            <token id="9" string="Congress" />
            <token id="10" string="for" />
            <token id="11" string="California" />
            <token id="12" string="," />
            <token id="13" string="Florida" />
            <token id="14" string="," />
            <token id="15" string="New" />
            <token id="16" string="York" />
            <token id="17" string="," />
            <token id="18" string="Illinois" />
            <token id="19" string="," />
            <token id="20" string="Pennsylvania" />
            <token id="21" string="and" />
            <token id="22" string="other" />
            <token id="23" string="states" />
            <token id="24" string="that" />
            <token id="25" string="will" />
            <token id="26" string="be" />
            <token id="27" string="reapportioned" />
            <token id="28" string="on" />
            <token id="29" string="the" />
            <token id="30" string="basis" />
            <token id="31" string="of" />
            <token id="32" string="next" />
            <token id="33" string="year" />
            <token id="34" string="'s" />
            <token id="35" string="census" />
          </tokens>
        </chunking>
        <chunking id="5" string="other states" type="NP">
          <tokens>
            <token id="22" string="other" />
            <token id="23" string="states" />
          </tokens>
        </chunking>
        <chunking id="6" string="Pennsylvania" type="NP">
          <tokens>
            <token id="20" string="Pennsylvania" />
          </tokens>
        </chunking>
        <chunking id="7" string="be reapportioned on the basis of next year 's census" type="VP">
          <tokens>
            <token id="26" string="be" />
            <token id="27" string="reapportioned" />
            <token id="28" string="on" />
            <token id="29" string="the" />
            <token id="30" string="basis" />
            <token id="31" string="of" />
            <token id="32" string="next" />
            <token id="33" string="year" />
            <token id="34" string="'s" />
            <token id="35" string="census" />
          </tokens>
        </chunking>
        <chunking id="8" string="Florida" type="NP">
          <tokens>
            <token id="13" string="Florida" />
          </tokens>
        </chunking>
        <chunking id="9" string="seats" type="NP">
          <tokens>
            <token id="7" string="seats" />
          </tokens>
        </chunking>
        <chunking id="10" string="Congress" type="NP">
          <tokens>
            <token id="9" string="Congress" />
          </tokens>
        </chunking>
        <chunking id="11" string="seats in Congress" type="NP">
          <tokens>
            <token id="7" string="seats" />
            <token id="8" string="in" />
            <token id="9" string="Congress" />
          </tokens>
        </chunking>
        <chunking id="12" string="the basis" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="basis" />
          </tokens>
        </chunking>
        <chunking id="13" string="next year 's census" type="NP">
          <tokens>
            <token id="32" string="next" />
            <token id="33" string="year" />
            <token id="34" string="'s" />
            <token id="35" string="census" />
          </tokens>
        </chunking>
        <chunking id="14" string="are" type="VP">
          <tokens>
            <token id="3" string="are" />
          </tokens>
        </chunking>
        <chunking id="15" string="stake" type="NP">
          <tokens>
            <token id="2" string="stake" />
          </tokens>
        </chunking>
        <chunking id="16" string="the basis of next year 's census" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="basis" />
            <token id="31" string="of" />
            <token id="32" string="next" />
            <token id="33" string="year" />
            <token id="34" string="'s" />
            <token id="35" string="census" />
          </tokens>
        </chunking>
        <chunking id="17" string="reapportioned on the basis of next year 's census" type="VP">
          <tokens>
            <token id="27" string="reapportioned" />
            <token id="28" string="on" />
            <token id="29" string="the" />
            <token id="30" string="basis" />
            <token id="31" string="of" />
            <token id="32" string="next" />
            <token id="33" string="year" />
            <token id="34" string="'s" />
            <token id="35" string="census" />
          </tokens>
        </chunking>
        <chunking id="18" string="Illinois" type="NP">
          <tokens>
            <token id="18" string="Illinois" />
          </tokens>
        </chunking>
        <chunking id="19" string="will be reapportioned on the basis of next year 's census" type="VP">
          <tokens>
            <token id="25" string="will" />
            <token id="26" string="be" />
            <token id="27" string="reapportioned" />
            <token id="28" string="on" />
            <token id="29" string="the" />
            <token id="30" string="basis" />
            <token id="31" string="of" />
            <token id="32" string="next" />
            <token id="33" string="year" />
            <token id="34" string="'s" />
            <token id="35" string="census" />
          </tokens>
        </chunking>
        <chunking id="20" string="the number" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="number" />
          </tokens>
        </chunking>
        <chunking id="21" string="California , Florida , New York , Illinois , Pennsylvania and other states" type="NP">
          <tokens>
            <token id="11" string="California" />
            <token id="12" string="," />
            <token id="13" string="Florida" />
            <token id="14" string="," />
            <token id="15" string="New" />
            <token id="16" string="York" />
            <token id="17" string="," />
            <token id="18" string="Illinois" />
            <token id="19" string="," />
            <token id="20" string="Pennsylvania" />
            <token id="21" string="and" />
            <token id="22" string="other" />
            <token id="23" string="states" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">stake</governor>
          <dependent id="1">At</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">are</governor>
          <dependent id="2">stake</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">are</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">number</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">are</governor>
          <dependent id="5">number</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">seats</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">number</governor>
          <dependent id="7">seats</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Congress</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">seats</governor>
          <dependent id="9">Congress</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">California</governor>
          <dependent id="10">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">number</governor>
          <dependent id="11">California</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">California</governor>
          <dependent id="13">Florida</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">York</governor>
          <dependent id="15">New</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">California</governor>
          <dependent id="16">York</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">California</governor>
          <dependent id="18">Illinois</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">California</governor>
          <dependent id="20">Pennsylvania</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">California</governor>
          <dependent id="21">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">states</governor>
          <dependent id="22">other</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">California</governor>
          <dependent id="23">states</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="27">reapportioned</governor>
          <dependent id="24">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="27">reapportioned</governor>
          <dependent id="25">will</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="27">reapportioned</governor>
          <dependent id="26">be</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="5">number</governor>
          <dependent id="27">reapportioned</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">basis</governor>
          <dependent id="28">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">basis</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">reapportioned</governor>
          <dependent id="30">basis</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">census</governor>
          <dependent id="31">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="33">year</governor>
          <dependent id="32">next</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="35">census</governor>
          <dependent id="33">year</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">year</governor>
          <dependent id="34">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">basis</governor>
          <dependent id="35">census</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="New York" type="LOCATION" score="0.0">
          <tokens>
            <token id="15" string="New" />
            <token id="16" string="York" />
          </tokens>
        </entity>
        <entity id="2" string="California" type="LOCATION" score="0.0">
          <tokens>
            <token id="11" string="California" />
          </tokens>
        </entity>
        <entity id="3" string="Illinois" type="LOCATION" score="0.0">
          <tokens>
            <token id="18" string="Illinois" />
          </tokens>
        </entity>
        <entity id="4" string="Pennsylvania" type="LOCATION" score="0.0">
          <tokens>
            <token id="20" string="Pennsylvania" />
          </tokens>
        </entity>
        <entity id="5" string="Florida" type="LOCATION" score="0.0">
          <tokens>
            <token id="13" string="Florida" />
          </tokens>
        </entity>
        <entity id="6" string="next year" type="DATE" score="0.0">
          <tokens>
            <token id="32" string="next" />
            <token id="33" string="year" />
          </tokens>
        </entity>
        <entity id="7" string="Congress" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="9" string="Congress" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>Federal aid to states also is frequently based on population counts, so millions of dollars in grants and other funds made available on a per capita basis would be affected.</content>
      <tokens>
        <token id="1" string="Federal" lemma="Federal" stem="feder" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="aid" lemma="aid" stem="aid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="states" lemma="state" stem="state" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="frequently" lemma="frequently" stem="frequent" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="based" lemma="base" stem="base" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="population" lemma="population" stem="popul" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="counts" lemma="count" stem="count" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="millions" lemma="million" stem="million" pos="NNS" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="16" string="dollars" lemma="dollar" stem="dollar" pos="NNS" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="17" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="grants" lemma="grant" stem="grant" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="funds" lemma="fund" stem="fund" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="made" lemma="make" stem="made" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="available" lemma="available" stem="avail" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="per" lemma="per" stem="per" pos="FW" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="capita" lemma="capita" stem="capita" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="basis" lemma="basis" stem="basi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="affected" lemma="affect" stem="affect" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Federal) (NN aid)) (PP (TO to) (NP (NNS states)))) (ADVP (RB also)) (VP (VBZ is) (ADVP (RB frequently)) (VP (VBN based) (PP (IN on) (NP (NP (NN population) (NNS counts)) (, ,) (NP (NP (QP (RB so) (NNS millions))) (PP (IN of) (NP (NP (NNS dollars)) (PP (IN in) (NP (NP (NNS grants)) (CC and) (NP (JJ other) (NNS funds)))))) (VP (VBN made) (ADJP (JJ available)) (PP (IN on) (NP (NP (DT a) (FW per) (NN capita) (NN basis)) (SBAR (S (VP (MD would) (VP (VB be) (VP (VBN affected)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="grants" type="NP">
          <tokens>
            <token id="18" string="grants" />
          </tokens>
        </chunking>
        <chunking id="2" string="Federal aid to states" type="NP">
          <tokens>
            <token id="1" string="Federal" />
            <token id="2" string="aid" />
            <token id="3" string="to" />
            <token id="4" string="states" />
          </tokens>
        </chunking>
        <chunking id="3" string="population counts , so millions of dollars in grants and other funds made available on a per capita basis would be affected" type="NP">
          <tokens>
            <token id="10" string="population" />
            <token id="11" string="counts" />
            <token id="12" string="," />
            <token id="13" string="so" />
            <token id="14" string="millions" />
            <token id="15" string="of" />
            <token id="16" string="dollars" />
            <token id="17" string="in" />
            <token id="18" string="grants" />
            <token id="19" string="and" />
            <token id="20" string="other" />
            <token id="21" string="funds" />
            <token id="22" string="made" />
            <token id="23" string="available" />
            <token id="24" string="on" />
            <token id="25" string="a" />
            <token id="26" string="per" />
            <token id="27" string="capita" />
            <token id="28" string="basis" />
            <token id="29" string="would" />
            <token id="30" string="be" />
            <token id="31" string="affected" />
          </tokens>
        </chunking>
        <chunking id="4" string="so millions of dollars in grants and other funds made available on a per capita basis would be affected" type="NP">
          <tokens>
            <token id="13" string="so" />
            <token id="14" string="millions" />
            <token id="15" string="of" />
            <token id="16" string="dollars" />
            <token id="17" string="in" />
            <token id="18" string="grants" />
            <token id="19" string="and" />
            <token id="20" string="other" />
            <token id="21" string="funds" />
            <token id="22" string="made" />
            <token id="23" string="available" />
            <token id="24" string="on" />
            <token id="25" string="a" />
            <token id="26" string="per" />
            <token id="27" string="capita" />
            <token id="28" string="basis" />
            <token id="29" string="would" />
            <token id="30" string="be" />
            <token id="31" string="affected" />
          </tokens>
        </chunking>
        <chunking id="5" string="a per capita basis would be affected" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="per" />
            <token id="27" string="capita" />
            <token id="28" string="basis" />
            <token id="29" string="would" />
            <token id="30" string="be" />
            <token id="31" string="affected" />
          </tokens>
        </chunking>
        <chunking id="6" string="available" type="ADJP">
          <tokens>
            <token id="23" string="available" />
          </tokens>
        </chunking>
        <chunking id="7" string="a per capita basis" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="per" />
            <token id="27" string="capita" />
            <token id="28" string="basis" />
          </tokens>
        </chunking>
        <chunking id="8" string="affected" type="VP">
          <tokens>
            <token id="31" string="affected" />
          </tokens>
        </chunking>
        <chunking id="9" string="is frequently based on population counts , so millions of dollars in grants and other funds made available on a per capita basis would be affected" type="VP">
          <tokens>
            <token id="6" string="is" />
            <token id="7" string="frequently" />
            <token id="8" string="based" />
            <token id="9" string="on" />
            <token id="10" string="population" />
            <token id="11" string="counts" />
            <token id="12" string="," />
            <token id="13" string="so" />
            <token id="14" string="millions" />
            <token id="15" string="of" />
            <token id="16" string="dollars" />
            <token id="17" string="in" />
            <token id="18" string="grants" />
            <token id="19" string="and" />
            <token id="20" string="other" />
            <token id="21" string="funds" />
            <token id="22" string="made" />
            <token id="23" string="available" />
            <token id="24" string="on" />
            <token id="25" string="a" />
            <token id="26" string="per" />
            <token id="27" string="capita" />
            <token id="28" string="basis" />
            <token id="29" string="would" />
            <token id="30" string="be" />
            <token id="31" string="affected" />
          </tokens>
        </chunking>
        <chunking id="10" string="dollars" type="NP">
          <tokens>
            <token id="16" string="dollars" />
          </tokens>
        </chunking>
        <chunking id="11" string="states" type="NP">
          <tokens>
            <token id="4" string="states" />
          </tokens>
        </chunking>
        <chunking id="12" string="population counts" type="NP">
          <tokens>
            <token id="10" string="population" />
            <token id="11" string="counts" />
          </tokens>
        </chunking>
        <chunking id="13" string="dollars in grants and other funds" type="NP">
          <tokens>
            <token id="16" string="dollars" />
            <token id="17" string="in" />
            <token id="18" string="grants" />
            <token id="19" string="and" />
            <token id="20" string="other" />
            <token id="21" string="funds" />
          </tokens>
        </chunking>
        <chunking id="14" string="based on population counts , so millions of dollars in grants and other funds made available on a per capita basis would be affected" type="VP">
          <tokens>
            <token id="8" string="based" />
            <token id="9" string="on" />
            <token id="10" string="population" />
            <token id="11" string="counts" />
            <token id="12" string="," />
            <token id="13" string="so" />
            <token id="14" string="millions" />
            <token id="15" string="of" />
            <token id="16" string="dollars" />
            <token id="17" string="in" />
            <token id="18" string="grants" />
            <token id="19" string="and" />
            <token id="20" string="other" />
            <token id="21" string="funds" />
            <token id="22" string="made" />
            <token id="23" string="available" />
            <token id="24" string="on" />
            <token id="25" string="a" />
            <token id="26" string="per" />
            <token id="27" string="capita" />
            <token id="28" string="basis" />
            <token id="29" string="would" />
            <token id="30" string="be" />
            <token id="31" string="affected" />
          </tokens>
        </chunking>
        <chunking id="15" string="made available on a per capita basis would be affected" type="VP">
          <tokens>
            <token id="22" string="made" />
            <token id="23" string="available" />
            <token id="24" string="on" />
            <token id="25" string="a" />
            <token id="26" string="per" />
            <token id="27" string="capita" />
            <token id="28" string="basis" />
            <token id="29" string="would" />
            <token id="30" string="be" />
            <token id="31" string="affected" />
          </tokens>
        </chunking>
        <chunking id="16" string="so millions" type="NP">
          <tokens>
            <token id="13" string="so" />
            <token id="14" string="millions" />
          </tokens>
        </chunking>
        <chunking id="17" string="other funds" type="NP">
          <tokens>
            <token id="20" string="other" />
            <token id="21" string="funds" />
          </tokens>
        </chunking>
        <chunking id="18" string="Federal aid" type="NP">
          <tokens>
            <token id="1" string="Federal" />
            <token id="2" string="aid" />
          </tokens>
        </chunking>
        <chunking id="19" string="would be affected" type="SBAR">
          <tokens>
            <token id="29" string="would" />
            <token id="30" string="be" />
            <token id="31" string="affected" />
          </tokens>
        </chunking>
        <chunking id="20" string="be affected" type="VP">
          <tokens>
            <token id="30" string="be" />
            <token id="31" string="affected" />
          </tokens>
        </chunking>
        <chunking id="21" string="grants and other funds" type="NP">
          <tokens>
            <token id="18" string="grants" />
            <token id="19" string="and" />
            <token id="20" string="other" />
            <token id="21" string="funds" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">aid</governor>
          <dependent id="1">Federal</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="8">based</governor>
          <dependent id="2">aid</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">states</governor>
          <dependent id="3">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">aid</governor>
          <dependent id="4">states</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">based</governor>
          <dependent id="5">also</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="8">based</governor>
          <dependent id="6">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">based</governor>
          <dependent id="7">frequently</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">based</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">counts</governor>
          <dependent id="9">on</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">counts</governor>
          <dependent id="10">population</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">based</governor>
          <dependent id="11">counts</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">millions</governor>
          <dependent id="13">so</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="11">counts</governor>
          <dependent id="14">millions</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">dollars</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">millions</governor>
          <dependent id="16">dollars</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">grants</governor>
          <dependent id="17">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">dollars</governor>
          <dependent id="18">grants</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="18">grants</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">funds</governor>
          <dependent id="20">other</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">grants</governor>
          <dependent id="21">funds</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="14">millions</governor>
          <dependent id="22">made</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="22">made</governor>
          <dependent id="23">available</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">basis</governor>
          <dependent id="24">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">basis</governor>
          <dependent id="25">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">basis</governor>
          <dependent id="26">per</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">basis</governor>
          <dependent id="27">capita</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">made</governor>
          <dependent id="28">basis</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="31">affected</governor>
          <dependent id="29">would</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="31">affected</governor>
          <dependent id="30">be</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="28">basis</governor>
          <dependent id="31">affected</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="millions of dollars" type="MONEY" score="0.0">
          <tokens>
            <token id="14" string="millions" />
            <token id="15" string="of" />
            <token id="16" string="dollars" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>The issue cuts across partisan lines in the Senate, with Minority Leader Bob Dole (R-Kan.)</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="issue" lemma="issue" stem="issu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="cuts" lemma="cut" stem="cut" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="across" lemma="across" stem="across" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="partisan" lemma="partisan" stem="partisan" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="lines" lemma="line" stem="line" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Senate" lemma="Senate" stem="senat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Minority" lemma="Minority" stem="minor" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="Leader" lemma="Leader" stem="leader" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="true" is_refers="false" />
        <token id="14" string="Bob" lemma="Bob" stem="bob" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="15" string="Dole" lemma="Dole" stem="dole" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="16" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="R-Kan" lemma="R-Kan" stem="r-kan" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN issue)) (VP (VBZ cuts) (PP (IN across) (NP (NP (JJ partisan) (NNS lines)) (PP (IN in) (NP (DT the) (NNP Senate))))) (, ,) (PP (IN with) (NP (NP (NNP Minority) (NNP Leader) (NNP Bob) (NNP Dole)) (PRN (-LRB- -LRB-) (NP (NNP R-Kan) (. .)) (-RRB- -RRB-)))))))</syntactictree>
      <chunkings>
        <chunking id="1" string="cuts across partisan lines in the Senate , with Minority Leader Bob Dole -LRB- R-Kan . -RRB-" type="VP">
          <tokens>
            <token id="3" string="cuts" />
            <token id="4" string="across" />
            <token id="5" string="partisan" />
            <token id="6" string="lines" />
            <token id="7" string="in" />
            <token id="8" string="the" />
            <token id="9" string="Senate" />
            <token id="10" string="," />
            <token id="11" string="with" />
            <token id="12" string="Minority" />
            <token id="13" string="Leader" />
            <token id="14" string="Bob" />
            <token id="15" string="Dole" />
            <token id="16" string="(" />
            <token id="17" string="R-Kan" />
            <token id="18" string="." />
            <token id="19" string=")" />
          </tokens>
        </chunking>
        <chunking id="2" string="partisan lines in the Senate" type="NP">
          <tokens>
            <token id="5" string="partisan" />
            <token id="6" string="lines" />
            <token id="7" string="in" />
            <token id="8" string="the" />
            <token id="9" string="Senate" />
          </tokens>
        </chunking>
        <chunking id="3" string="the Senate" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="Senate" />
          </tokens>
        </chunking>
        <chunking id="4" string="The issue" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="issue" />
          </tokens>
        </chunking>
        <chunking id="5" string="Minority Leader Bob Dole" type="NP">
          <tokens>
            <token id="12" string="Minority" />
            <token id="13" string="Leader" />
            <token id="14" string="Bob" />
            <token id="15" string="Dole" />
          </tokens>
        </chunking>
        <chunking id="6" string="Minority Leader Bob Dole -LRB- R-Kan . -RRB-" type="NP">
          <tokens>
            <token id="12" string="Minority" />
            <token id="13" string="Leader" />
            <token id="14" string="Bob" />
            <token id="15" string="Dole" />
            <token id="16" string="(" />
            <token id="17" string="R-Kan" />
            <token id="18" string="." />
            <token id="19" string=")" />
          </tokens>
        </chunking>
        <chunking id="7" string="partisan lines" type="NP">
          <tokens>
            <token id="5" string="partisan" />
            <token id="6" string="lines" />
          </tokens>
        </chunking>
        <chunking id="8" string="R-Kan ." type="NP">
          <tokens>
            <token id="17" string="R-Kan" />
            <token id="18" string="." />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">issue</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">cuts</governor>
          <dependent id="2">issue</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">cuts</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">lines</governor>
          <dependent id="4">across</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">lines</governor>
          <dependent id="5">partisan</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">cuts</governor>
          <dependent id="6">lines</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Senate</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">Senate</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">lines</governor>
          <dependent id="9">Senate</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">Dole</governor>
          <dependent id="11">with</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Dole</governor>
          <dependent id="12">Minority</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Dole</governor>
          <dependent id="13">Leader</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Dole</governor>
          <dependent id="14">Bob</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">cuts</governor>
          <dependent id="15">Dole</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="15">Dole</governor>
          <dependent id="17">R-Kan</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Senate" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="9" string="Senate" />
          </tokens>
        </entity>
        <entity id="2" string="Bob Dole" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Bob" />
            <token id="15" string="Dole" />
          </tokens>
        </entity>
        <entity id="3" string="Leader" type="TITLE" score="0.0">
          <tokens>
            <token id="13" string="Leader" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>arguing against the White House position on grounds that including illegal aliens in the census is unfair to American citizens.</content>
      <tokens>
        <token id="1" string="arguing" lemma="argue" stem="argu" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="White" lemma="White" stem="white" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="5" string="House" lemma="House" stem="hous" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="6" string="position" lemma="position" stem="posit" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="grounds" lemma="grounds" stem="ground" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="including" lemma="include" stem="includ" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="aliens" lemma="alien" stem="alien" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="census" lemma="census" stem="censu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="unfair" lemma="unfair" stem="unfair" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="American" lemma="american" stem="american" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="20" string="citizens" lemma="citizen" stem="citizen" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VBG arguing) (PP (IN against) (NP (DT the) (NNP White) (NNP House) (NN position))) (PP (IN on) (NP (NP (NNS grounds)) (SBAR (WHNP (WDT that)) (S (VP (VBG including) (NP (JJ illegal) (NNS aliens)) (PP (IN in) (NP (DT the) (NN census)))))))))) (VP (VBZ is) (ADJP (JJ unfair) (PP (TO to) (NP (JJ American) (NNS citizens))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="illegal aliens" type="NP">
          <tokens>
            <token id="11" string="illegal" />
            <token id="12" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="2" string="American citizens" type="NP">
          <tokens>
            <token id="19" string="American" />
            <token id="20" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="3" string="that including illegal aliens in the census" type="SBAR">
          <tokens>
            <token id="9" string="that" />
            <token id="10" string="including" />
            <token id="11" string="illegal" />
            <token id="12" string="aliens" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="census" />
          </tokens>
        </chunking>
        <chunking id="4" string="grounds" type="NP">
          <tokens>
            <token id="8" string="grounds" />
          </tokens>
        </chunking>
        <chunking id="5" string="the census" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="census" />
          </tokens>
        </chunking>
        <chunking id="6" string="arguing against the White House position on grounds that including illegal aliens in the census" type="VP">
          <tokens>
            <token id="1" string="arguing" />
            <token id="2" string="against" />
            <token id="3" string="the" />
            <token id="4" string="White" />
            <token id="5" string="House" />
            <token id="6" string="position" />
            <token id="7" string="on" />
            <token id="8" string="grounds" />
            <token id="9" string="that" />
            <token id="10" string="including" />
            <token id="11" string="illegal" />
            <token id="12" string="aliens" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="census" />
          </tokens>
        </chunking>
        <chunking id="7" string="including illegal aliens in the census" type="VP">
          <tokens>
            <token id="10" string="including" />
            <token id="11" string="illegal" />
            <token id="12" string="aliens" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="census" />
          </tokens>
        </chunking>
        <chunking id="8" string="the White House position" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="White" />
            <token id="5" string="House" />
            <token id="6" string="position" />
          </tokens>
        </chunking>
        <chunking id="9" string="unfair to American citizens" type="ADJP">
          <tokens>
            <token id="17" string="unfair" />
            <token id="18" string="to" />
            <token id="19" string="American" />
            <token id="20" string="citizens" />
          </tokens>
        </chunking>
        <chunking id="10" string="grounds that including illegal aliens in the census" type="NP">
          <tokens>
            <token id="8" string="grounds" />
            <token id="9" string="that" />
            <token id="10" string="including" />
            <token id="11" string="illegal" />
            <token id="12" string="aliens" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="census" />
          </tokens>
        </chunking>
        <chunking id="11" string="is unfair to American citizens" type="VP">
          <tokens>
            <token id="16" string="is" />
            <token id="17" string="unfair" />
            <token id="18" string="to" />
            <token id="19" string="American" />
            <token id="20" string="citizens" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="csubj">
          <governor id="17">unfair</governor>
          <dependent id="1">arguing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">position</governor>
          <dependent id="2">against</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">position</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">position</governor>
          <dependent id="4">White</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">position</governor>
          <dependent id="5">House</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">arguing</governor>
          <dependent id="6">position</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">grounds</governor>
          <dependent id="7">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">arguing</governor>
          <dependent id="8">grounds</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">including</governor>
          <dependent id="9">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="8">grounds</governor>
          <dependent id="10">including</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">aliens</governor>
          <dependent id="11">illegal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">including</governor>
          <dependent id="12">aliens</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">census</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">census</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">including</governor>
          <dependent id="15">census</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="17">unfair</governor>
          <dependent id="16">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">unfair</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">citizens</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">citizens</governor>
          <dependent id="19">American</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">unfair</governor>
          <dependent id="20">citizens</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="White House" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="4" string="White" />
            <token id="5" string="House" />
          </tokens>
        </entity>
        <entity id="2" string="American" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="19" string="American" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>Loss of Seats Cited &amp;quot;Some states will lose congressional seats because of illegal aliens,&amp;quot; Dole argued.</content>
      <tokens>
        <token id="1" string="Loss" lemma="loss" stem="loss" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Seats" lemma="seat" stem="seat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="Cited" lemma="cite" stem="cite" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="states" lemma="state" stem="state" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="lose" lemma="lose" stem="lose" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="congressional" lemma="congressional" stem="congression" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="seats" lemma="seat" stem="seat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="aliens" lemma="alien" stem="alien" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Dole" lemma="Dole" stem="dole" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="19" string="argued" lemma="argue" stem="argu" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (NN Loss)) (PP (IN of) (NP (NP (NNS Seats)) (VP (VBN Cited) (S (`` ``) (NP (DT Some) (NNS states))))))) (VP (MD will) (VP (VB lose) (NP (JJ congressional) (NNS seats)) (PP (IN because) (PP (IN of) (NP (JJ illegal) (NNS aliens))))))) (, ,) ('' '') (NP (NNP Dole)) (VP (VBD argued)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Some states" type="NP">
          <tokens>
            <token id="6" string="Some" />
            <token id="7" string="states" />
          </tokens>
        </chunking>
        <chunking id="2" string="argued" type="VP">
          <tokens>
            <token id="19" string="argued" />
          </tokens>
        </chunking>
        <chunking id="3" string="illegal aliens" type="NP">
          <tokens>
            <token id="14" string="illegal" />
            <token id="15" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="4" string="Dole" type="NP">
          <tokens>
            <token id="18" string="Dole" />
          </tokens>
        </chunking>
        <chunking id="5" string="Cited `` Some states" type="VP">
          <tokens>
            <token id="4" string="Cited" />
            <token id="5" string="&quot;" />
            <token id="6" string="Some" />
            <token id="7" string="states" />
          </tokens>
        </chunking>
        <chunking id="6" string="Loss" type="NP">
          <tokens>
            <token id="1" string="Loss" />
          </tokens>
        </chunking>
        <chunking id="7" string="Loss of Seats Cited `` Some states" type="NP">
          <tokens>
            <token id="1" string="Loss" />
            <token id="2" string="of" />
            <token id="3" string="Seats" />
            <token id="4" string="Cited" />
            <token id="5" string="&quot;" />
            <token id="6" string="Some" />
            <token id="7" string="states" />
          </tokens>
        </chunking>
        <chunking id="8" string="Seats Cited `` Some states" type="NP">
          <tokens>
            <token id="3" string="Seats" />
            <token id="4" string="Cited" />
            <token id="5" string="&quot;" />
            <token id="6" string="Some" />
            <token id="7" string="states" />
          </tokens>
        </chunking>
        <chunking id="9" string="congressional seats" type="NP">
          <tokens>
            <token id="10" string="congressional" />
            <token id="11" string="seats" />
          </tokens>
        </chunking>
        <chunking id="10" string="Seats" type="NP">
          <tokens>
            <token id="3" string="Seats" />
          </tokens>
        </chunking>
        <chunking id="11" string="will lose congressional seats because of illegal aliens" type="VP">
          <tokens>
            <token id="8" string="will" />
            <token id="9" string="lose" />
            <token id="10" string="congressional" />
            <token id="11" string="seats" />
            <token id="12" string="because" />
            <token id="13" string="of" />
            <token id="14" string="illegal" />
            <token id="15" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="12" string="lose congressional seats because of illegal aliens" type="VP">
          <tokens>
            <token id="9" string="lose" />
            <token id="10" string="congressional" />
            <token id="11" string="seats" />
            <token id="12" string="because" />
            <token id="13" string="of" />
            <token id="14" string="illegal" />
            <token id="15" string="aliens" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="9">lose</governor>
          <dependent id="1">Loss</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">Seats</governor>
          <dependent id="2">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Loss</governor>
          <dependent id="3">Seats</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="3">Seats</governor>
          <dependent id="4">Cited</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">states</governor>
          <dependent id="6">Some</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">Cited</governor>
          <dependent id="7">states</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">lose</governor>
          <dependent id="8">will</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">argued</governor>
          <dependent id="9">lose</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">seats</governor>
          <dependent id="10">congressional</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">lose</governor>
          <dependent id="11">seats</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">aliens</governor>
          <dependent id="12">because</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">aliens</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">aliens</governor>
          <dependent id="14">illegal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">lose</governor>
          <dependent id="15">aliens</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">argued</governor>
          <dependent id="18">Dole</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="19">argued</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Dole" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Dole" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>Sen. Thad Cochran (R-Miss.)</content>
      <tokens>
        <token id="1" string="Sen." lemma="Sen." stem="sen." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="Thad" lemma="Thad" stem="thad" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="Cochran" lemma="Cochran" stem="cochran" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="R-Miss" lemma="R-Miss" stem="r-miss" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (NNP Sen.) (NNP Thad) (NNP Cochran)) (PRN (-LRB- -LRB-) (NP (NNP R-Miss) (. .)) (-RRB- -RRB-))))</syntactictree>
      <chunkings>
        <chunking id="1" string="Sen. Thad Cochran -LRB- R-Miss . -RRB-" type="NP">
          <tokens>
            <token id="1" string="Sen." />
            <token id="2" string="Thad" />
            <token id="3" string="Cochran" />
            <token id="4" string="(" />
            <token id="5" string="R-Miss" />
            <token id="6" string="." />
            <token id="7" string=")" />
          </tokens>
        </chunking>
        <chunking id="2" string="Sen. Thad Cochran" type="NP">
          <tokens>
            <token id="1" string="Sen." />
            <token id="2" string="Thad" />
            <token id="3" string="Cochran" />
          </tokens>
        </chunking>
        <chunking id="3" string="R-Miss ." type="NP">
          <tokens>
            <token id="5" string="R-Miss" />
            <token id="6" string="." />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Cochran</governor>
          <dependent id="1">Sen.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Cochran</governor>
          <dependent id="2">Thad</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">Cochran</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="3">Cochran</governor>
          <dependent id="5">R-Miss</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Thad Cochran" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Thad" />
            <token id="3" string="Cochran" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>said that Georgia and Indiana both lost House seats after the 1980 Census, and California and New York -- centers of illegal immigration -- each gained seats.</content>
      <tokens>
        <token id="1" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Georgia" lemma="Georgia" stem="georgia" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="4" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Indiana" lemma="Indiana" stem="indiana" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="6" string="both" lemma="both" stem="both" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="lost" lemma="lose" stem="lost" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="House" lemma="House" stem="hous" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="9" string="seats" lemma="seat" stem="seat" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="1980" lemma="1980" stem="1980" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="13" string="Census" lemma="Census" stem="censu" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="California" lemma="California" stem="california" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="New" lemma="New" stem="new" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="19" string="York" lemma="York" stem="york" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="20" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="centers" lemma="center" stem="center" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="immigration" lemma="immigration" stem="immigr" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="each" lemma="each" stem="each" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="gained" lemma="gain" stem="gain" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="seats" lemma="seat" stem="seat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VBD said) (SBAR (IN that) (S (NP (NNP Georgia) (CC and) (NNP Indiana)) (ADVP (CC both)) (VP (VBD lost) (NP (NNP House) (NNS seats)) (PP (IN after) (NP (NP (DT the) (CD 1980) (NNP Census)) (, ,) (CC and) (NP (NNP California) (CC and) (NNP New) (NNP York)) (PRN (: --) (NP (NP (NNS centers)) (PP (IN of) (NP (JJ illegal) (NN immigration)))) (: --))))))))) (NP (DT each)) (VP (VBD gained) (NP (NNS seats))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="House seats" type="NP">
          <tokens>
            <token id="8" string="House" />
            <token id="9" string="seats" />
          </tokens>
        </chunking>
        <chunking id="2" string="that Georgia and Indiana both lost House seats after the 1980 Census , and California and New York -- centers of illegal immigration --" type="SBAR">
          <tokens>
            <token id="2" string="that" />
            <token id="3" string="Georgia" />
            <token id="4" string="and" />
            <token id="5" string="Indiana" />
            <token id="6" string="both" />
            <token id="7" string="lost" />
            <token id="8" string="House" />
            <token id="9" string="seats" />
            <token id="10" string="after" />
            <token id="11" string="the" />
            <token id="12" string="1980" />
            <token id="13" string="Census" />
            <token id="14" string="," />
            <token id="15" string="and" />
            <token id="16" string="California" />
            <token id="17" string="and" />
            <token id="18" string="New" />
            <token id="19" string="York" />
            <token id="20" string="--" />
            <token id="21" string="centers" />
            <token id="22" string="of" />
            <token id="23" string="illegal" />
            <token id="24" string="immigration" />
            <token id="25" string="--" />
          </tokens>
        </chunking>
        <chunking id="3" string="gained seats" type="VP">
          <tokens>
            <token id="27" string="gained" />
            <token id="28" string="seats" />
          </tokens>
        </chunking>
        <chunking id="4" string="illegal immigration" type="NP">
          <tokens>
            <token id="23" string="illegal" />
            <token id="24" string="immigration" />
          </tokens>
        </chunking>
        <chunking id="5" string="the 1980 Census" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="1980" />
            <token id="13" string="Census" />
          </tokens>
        </chunking>
        <chunking id="6" string="seats" type="NP">
          <tokens>
            <token id="28" string="seats" />
          </tokens>
        </chunking>
        <chunking id="7" string="each" type="NP">
          <tokens>
            <token id="26" string="each" />
          </tokens>
        </chunking>
        <chunking id="8" string="California and New York" type="NP">
          <tokens>
            <token id="16" string="California" />
            <token id="17" string="and" />
            <token id="18" string="New" />
            <token id="19" string="York" />
          </tokens>
        </chunking>
        <chunking id="9" string="the 1980 Census , and California and New York -- centers of illegal immigration --" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="1980" />
            <token id="13" string="Census" />
            <token id="14" string="," />
            <token id="15" string="and" />
            <token id="16" string="California" />
            <token id="17" string="and" />
            <token id="18" string="New" />
            <token id="19" string="York" />
            <token id="20" string="--" />
            <token id="21" string="centers" />
            <token id="22" string="of" />
            <token id="23" string="illegal" />
            <token id="24" string="immigration" />
            <token id="25" string="--" />
          </tokens>
        </chunking>
        <chunking id="10" string="Georgia and Indiana" type="NP">
          <tokens>
            <token id="3" string="Georgia" />
            <token id="4" string="and" />
            <token id="5" string="Indiana" />
          </tokens>
        </chunking>
        <chunking id="11" string="lost House seats after the 1980 Census , and California and New York -- centers of illegal immigration --" type="VP">
          <tokens>
            <token id="7" string="lost" />
            <token id="8" string="House" />
            <token id="9" string="seats" />
            <token id="10" string="after" />
            <token id="11" string="the" />
            <token id="12" string="1980" />
            <token id="13" string="Census" />
            <token id="14" string="," />
            <token id="15" string="and" />
            <token id="16" string="California" />
            <token id="17" string="and" />
            <token id="18" string="New" />
            <token id="19" string="York" />
            <token id="20" string="--" />
            <token id="21" string="centers" />
            <token id="22" string="of" />
            <token id="23" string="illegal" />
            <token id="24" string="immigration" />
            <token id="25" string="--" />
          </tokens>
        </chunking>
        <chunking id="12" string="centers of illegal immigration" type="NP">
          <tokens>
            <token id="21" string="centers" />
            <token id="22" string="of" />
            <token id="23" string="illegal" />
            <token id="24" string="immigration" />
          </tokens>
        </chunking>
        <chunking id="13" string="centers" type="NP">
          <tokens>
            <token id="21" string="centers" />
          </tokens>
        </chunking>
        <chunking id="14" string="said that Georgia and Indiana both lost House seats after the 1980 Census , and California and New York -- centers of illegal immigration --" type="VP">
          <tokens>
            <token id="1" string="said" />
            <token id="2" string="that" />
            <token id="3" string="Georgia" />
            <token id="4" string="and" />
            <token id="5" string="Indiana" />
            <token id="6" string="both" />
            <token id="7" string="lost" />
            <token id="8" string="House" />
            <token id="9" string="seats" />
            <token id="10" string="after" />
            <token id="11" string="the" />
            <token id="12" string="1980" />
            <token id="13" string="Census" />
            <token id="14" string="," />
            <token id="15" string="and" />
            <token id="16" string="California" />
            <token id="17" string="and" />
            <token id="18" string="New" />
            <token id="19" string="York" />
            <token id="20" string="--" />
            <token id="21" string="centers" />
            <token id="22" string="of" />
            <token id="23" string="illegal" />
            <token id="24" string="immigration" />
            <token id="25" string="--" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="dep">
          <governor id="27">gained</governor>
          <dependent id="1">said</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">lost</governor>
          <dependent id="2">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">lost</governor>
          <dependent id="3">Georgia</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">Georgia</governor>
          <dependent id="4">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">Georgia</governor>
          <dependent id="5">Indiana</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">lost</governor>
          <dependent id="6">both</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="1">said</governor>
          <dependent id="7">lost</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">seats</governor>
          <dependent id="8">House</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">lost</governor>
          <dependent id="9">seats</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Census</governor>
          <dependent id="10">after</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">Census</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="13">Census</governor>
          <dependent id="12">1980</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">lost</governor>
          <dependent id="13">Census</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">Census</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">York</governor>
          <dependent id="16">California</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">California</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">California</governor>
          <dependent id="18">New</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">Census</governor>
          <dependent id="19">York</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="13">Census</governor>
          <dependent id="21">centers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">immigration</governor>
          <dependent id="22">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">immigration</governor>
          <dependent id="23">illegal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">centers</governor>
          <dependent id="24">immigration</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">gained</governor>
          <dependent id="26">each</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="27">gained</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="27">gained</governor>
          <dependent id="28">seats</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="New York" type="LOCATION" score="0.0">
          <tokens>
            <token id="18" string="New" />
            <token id="19" string="York" />
          </tokens>
        </entity>
        <entity id="2" string="California" type="LOCATION" score="0.0">
          <tokens>
            <token id="16" string="California" />
          </tokens>
        </entity>
        <entity id="3" string="House" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="8" string="House" />
          </tokens>
        </entity>
        <entity id="4" string="Indiana" type="LOCATION" score="0.0">
          <tokens>
            <token id="5" string="Indiana" />
          </tokens>
        </entity>
        <entity id="5" string="Georgia" type="LOCATION" score="0.0">
          <tokens>
            <token id="3" string="Georgia" />
          </tokens>
        </entity>
        <entity id="6" string="1980" type="DATE" score="0.0">
          <tokens>
            <token id="12" string="1980" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>&amp;quot;The bottom line is illegal aliens ought to be deported, not counted,&amp;quot; Cochran said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="bottom" lemma="bottom" stem="bottom" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="line" lemma="line" stem="line" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="aliens" lemma="alien" stem="alien" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="ought" lemma="ought" stem="ought" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="deported" lemma="deport" stem="deport" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="counted" lemma="count" stem="count" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Cochran" lemma="Cochran" stem="cochran" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="18" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (DT The) (JJ bottom) (NN line)) (VP (VBZ is) (ADJP (JJ illegal) (SBAR (S (NP (NNS aliens)) (VP (MD ought) (S (VP (TO to) (VP (VB be) (VP (VBN deported))))) (, ,) (VP (RB not) (VBN counted)))))))) (, ,) ('' '') (NP (NNP Cochran)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="aliens" type="NP">
          <tokens>
            <token id="7" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="2" string="be deported" type="VP">
          <tokens>
            <token id="10" string="be" />
            <token id="11" string="deported" />
          </tokens>
        </chunking>
        <chunking id="3" string="Cochran" type="NP">
          <tokens>
            <token id="17" string="Cochran" />
          </tokens>
        </chunking>
        <chunking id="4" string="aliens ought to be deported , not counted" type="SBAR">
          <tokens>
            <token id="7" string="aliens" />
            <token id="8" string="ought" />
            <token id="9" string="to" />
            <token id="10" string="be" />
            <token id="11" string="deported" />
            <token id="12" string="," />
            <token id="13" string="not" />
            <token id="14" string="counted" />
          </tokens>
        </chunking>
        <chunking id="5" string="ought to be deported , not counted" type="VP">
          <tokens>
            <token id="8" string="ought" />
            <token id="9" string="to" />
            <token id="10" string="be" />
            <token id="11" string="deported" />
            <token id="12" string="," />
            <token id="13" string="not" />
            <token id="14" string="counted" />
          </tokens>
        </chunking>
        <chunking id="6" string="illegal aliens ought to be deported , not counted" type="ADJP">
          <tokens>
            <token id="6" string="illegal" />
            <token id="7" string="aliens" />
            <token id="8" string="ought" />
            <token id="9" string="to" />
            <token id="10" string="be" />
            <token id="11" string="deported" />
            <token id="12" string="," />
            <token id="13" string="not" />
            <token id="14" string="counted" />
          </tokens>
        </chunking>
        <chunking id="7" string="is illegal aliens ought to be deported , not counted" type="VP">
          <tokens>
            <token id="5" string="is" />
            <token id="6" string="illegal" />
            <token id="7" string="aliens" />
            <token id="8" string="ought" />
            <token id="9" string="to" />
            <token id="10" string="be" />
            <token id="11" string="deported" />
            <token id="12" string="," />
            <token id="13" string="not" />
            <token id="14" string="counted" />
          </tokens>
        </chunking>
        <chunking id="8" string="to be deported" type="VP">
          <tokens>
            <token id="9" string="to" />
            <token id="10" string="be" />
            <token id="11" string="deported" />
          </tokens>
        </chunking>
        <chunking id="9" string="deported" type="VP">
          <tokens>
            <token id="11" string="deported" />
          </tokens>
        </chunking>
        <chunking id="10" string="not counted" type="VP">
          <tokens>
            <token id="13" string="not" />
            <token id="14" string="counted" />
          </tokens>
        </chunking>
        <chunking id="11" string="said" type="VP">
          <tokens>
            <token id="18" string="said" />
          </tokens>
        </chunking>
        <chunking id="12" string="The bottom line" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="bottom" />
            <token id="4" string="line" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">line</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">line</governor>
          <dependent id="3">bottom</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">illegal</governor>
          <dependent id="4">line</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">illegal</governor>
          <dependent id="5">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="18">said</governor>
          <dependent id="6">illegal</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">counted</governor>
          <dependent id="7">aliens</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">counted</governor>
          <dependent id="8">ought</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">deported</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="11">deported</governor>
          <dependent id="10">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="14">counted</governor>
          <dependent id="11">deported</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="14">counted</governor>
          <dependent id="13">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">illegal</governor>
          <dependent id="14">counted</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">said</governor>
          <dependent id="17">Cochran</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Cochran" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="Cochran" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>Sen. Pete Wilson (R-Calif.)</content>
      <tokens>
        <token id="1" string="Sen." lemma="Sen." stem="sen." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="Pete" lemma="Pete" stem="pete" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="Wilson" lemma="Wilson" stem="wilson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="R-Calif" lemma="R-Calif" stem="r-calif" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (NNP Sen.) (NNP Pete) (NNP Wilson)) (PRN (-LRB- -LRB-) (NP (NNP R-Calif) (. .)) (-RRB- -RRB-))))</syntactictree>
      <chunkings>
        <chunking id="1" string="Sen. Pete Wilson -LRB- R-Calif . -RRB-" type="NP">
          <tokens>
            <token id="1" string="Sen." />
            <token id="2" string="Pete" />
            <token id="3" string="Wilson" />
            <token id="4" string="(" />
            <token id="5" string="R-Calif" />
            <token id="6" string="." />
            <token id="7" string=")" />
          </tokens>
        </chunking>
        <chunking id="2" string="R-Calif ." type="NP">
          <tokens>
            <token id="5" string="R-Calif" />
            <token id="6" string="." />
          </tokens>
        </chunking>
        <chunking id="3" string="Sen. Pete Wilson" type="NP">
          <tokens>
            <token id="1" string="Sen." />
            <token id="2" string="Pete" />
            <token id="3" string="Wilson" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Wilson</governor>
          <dependent id="1">Sen.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Wilson</governor>
          <dependent id="2">Pete</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">Wilson</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="3">Wilson</governor>
          <dependent id="5">R-Calif</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Pete Wilson" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Pete" />
            <token id="3" string="Wilson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="false">
      <content>countered that excluding illegal residents from the decennial census is unfair to the states that have suffered from a huge influx of immigration beyond the legal limits.</content>
      <tokens>
        <token id="1" string="countered" lemma="counter" stem="counter" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="excluding" lemma="exclude" stem="exclud" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="residents" lemma="resident" stem="resid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="decennial" lemma="decennial" stem="decenni" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="census" lemma="census" stem="censu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="unfair" lemma="unfair" stem="unfair" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="states" lemma="state" stem="state" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="suffered" lemma="suffer" stem="suffer" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="huge" lemma="huge" stem="huge" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="influx" lemma="influx" stem="influx" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="immigration" lemma="immigration" stem="immigr" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="beyond" lemma="beyond" stem="beyond" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="legal" lemma="legal" stem="legal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="limits" lemma="limit" stem="limit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (VP (VBD countered) (SBAR (IN that) (S (S (VP (VBG excluding) (NP (JJ illegal) (NNS residents)) (PP (IN from) (NP (DT the) (JJ decennial) (NN census))))) (VP (VBZ is) (ADJP (JJ unfair) (PP (TO to) (NP (NP (DT the) (NNS states)) (SBAR (WHNP (WDT that)) (S (VP (VBP have) (VP (VBN suffered) (PP (IN from) (NP (NP (DT a) (JJ huge) (NN influx)) (PP (IN of) (NP (NN immigration))))) (PP (IN beyond) (NP (DT the) (JJ legal) (NNS limits)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a huge influx of immigration" type="NP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="huge" />
            <token id="21" string="influx" />
            <token id="22" string="of" />
            <token id="23" string="immigration" />
          </tokens>
        </chunking>
        <chunking id="2" string="immigration" type="NP">
          <tokens>
            <token id="23" string="immigration" />
          </tokens>
        </chunking>
        <chunking id="3" string="a huge influx" type="NP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="huge" />
            <token id="21" string="influx" />
          </tokens>
        </chunking>
        <chunking id="4" string="the states that have suffered from a huge influx of immigration beyond the legal limits" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="states" />
            <token id="15" string="that" />
            <token id="16" string="have" />
            <token id="17" string="suffered" />
            <token id="18" string="from" />
            <token id="19" string="a" />
            <token id="20" string="huge" />
            <token id="21" string="influx" />
            <token id="22" string="of" />
            <token id="23" string="immigration" />
            <token id="24" string="beyond" />
            <token id="25" string="the" />
            <token id="26" string="legal" />
            <token id="27" string="limits" />
          </tokens>
        </chunking>
        <chunking id="5" string="illegal residents" type="NP">
          <tokens>
            <token id="4" string="illegal" />
            <token id="5" string="residents" />
          </tokens>
        </chunking>
        <chunking id="6" string="excluding illegal residents from the decennial census" type="VP">
          <tokens>
            <token id="3" string="excluding" />
            <token id="4" string="illegal" />
            <token id="5" string="residents" />
            <token id="6" string="from" />
            <token id="7" string="the" />
            <token id="8" string="decennial" />
            <token id="9" string="census" />
          </tokens>
        </chunking>
        <chunking id="7" string="unfair to the states that have suffered from a huge influx of immigration beyond the legal limits" type="ADJP">
          <tokens>
            <token id="11" string="unfair" />
            <token id="12" string="to" />
            <token id="13" string="the" />
            <token id="14" string="states" />
            <token id="15" string="that" />
            <token id="16" string="have" />
            <token id="17" string="suffered" />
            <token id="18" string="from" />
            <token id="19" string="a" />
            <token id="20" string="huge" />
            <token id="21" string="influx" />
            <token id="22" string="of" />
            <token id="23" string="immigration" />
            <token id="24" string="beyond" />
            <token id="25" string="the" />
            <token id="26" string="legal" />
            <token id="27" string="limits" />
          </tokens>
        </chunking>
        <chunking id="8" string="the states" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="states" />
          </tokens>
        </chunking>
        <chunking id="9" string="suffered from a huge influx of immigration beyond the legal limits" type="VP">
          <tokens>
            <token id="17" string="suffered" />
            <token id="18" string="from" />
            <token id="19" string="a" />
            <token id="20" string="huge" />
            <token id="21" string="influx" />
            <token id="22" string="of" />
            <token id="23" string="immigration" />
            <token id="24" string="beyond" />
            <token id="25" string="the" />
            <token id="26" string="legal" />
            <token id="27" string="limits" />
          </tokens>
        </chunking>
        <chunking id="10" string="that excluding illegal residents from the decennial census is unfair to the states that have suffered from a huge influx of immigration beyond the legal limits" type="SBAR">
          <tokens>
            <token id="2" string="that" />
            <token id="3" string="excluding" />
            <token id="4" string="illegal" />
            <token id="5" string="residents" />
            <token id="6" string="from" />
            <token id="7" string="the" />
            <token id="8" string="decennial" />
            <token id="9" string="census" />
            <token id="10" string="is" />
            <token id="11" string="unfair" />
            <token id="12" string="to" />
            <token id="13" string="the" />
            <token id="14" string="states" />
            <token id="15" string="that" />
            <token id="16" string="have" />
            <token id="17" string="suffered" />
            <token id="18" string="from" />
            <token id="19" string="a" />
            <token id="20" string="huge" />
            <token id="21" string="influx" />
            <token id="22" string="of" />
            <token id="23" string="immigration" />
            <token id="24" string="beyond" />
            <token id="25" string="the" />
            <token id="26" string="legal" />
            <token id="27" string="limits" />
          </tokens>
        </chunking>
        <chunking id="11" string="that have suffered from a huge influx of immigration beyond the legal limits" type="SBAR">
          <tokens>
            <token id="15" string="that" />
            <token id="16" string="have" />
            <token id="17" string="suffered" />
            <token id="18" string="from" />
            <token id="19" string="a" />
            <token id="20" string="huge" />
            <token id="21" string="influx" />
            <token id="22" string="of" />
            <token id="23" string="immigration" />
            <token id="24" string="beyond" />
            <token id="25" string="the" />
            <token id="26" string="legal" />
            <token id="27" string="limits" />
          </tokens>
        </chunking>
        <chunking id="12" string="countered that excluding illegal residents from the decennial census is unfair to the states that have suffered from a huge influx of immigration beyond the legal limits" type="VP">
          <tokens>
            <token id="1" string="countered" />
            <token id="2" string="that" />
            <token id="3" string="excluding" />
            <token id="4" string="illegal" />
            <token id="5" string="residents" />
            <token id="6" string="from" />
            <token id="7" string="the" />
            <token id="8" string="decennial" />
            <token id="9" string="census" />
            <token id="10" string="is" />
            <token id="11" string="unfair" />
            <token id="12" string="to" />
            <token id="13" string="the" />
            <token id="14" string="states" />
            <token id="15" string="that" />
            <token id="16" string="have" />
            <token id="17" string="suffered" />
            <token id="18" string="from" />
            <token id="19" string="a" />
            <token id="20" string="huge" />
            <token id="21" string="influx" />
            <token id="22" string="of" />
            <token id="23" string="immigration" />
            <token id="24" string="beyond" />
            <token id="25" string="the" />
            <token id="26" string="legal" />
            <token id="27" string="limits" />
          </tokens>
        </chunking>
        <chunking id="13" string="have suffered from a huge influx of immigration beyond the legal limits" type="VP">
          <tokens>
            <token id="16" string="have" />
            <token id="17" string="suffered" />
            <token id="18" string="from" />
            <token id="19" string="a" />
            <token id="20" string="huge" />
            <token id="21" string="influx" />
            <token id="22" string="of" />
            <token id="23" string="immigration" />
            <token id="24" string="beyond" />
            <token id="25" string="the" />
            <token id="26" string="legal" />
            <token id="27" string="limits" />
          </tokens>
        </chunking>
        <chunking id="14" string="is unfair to the states that have suffered from a huge influx of immigration beyond the legal limits" type="VP">
          <tokens>
            <token id="10" string="is" />
            <token id="11" string="unfair" />
            <token id="12" string="to" />
            <token id="13" string="the" />
            <token id="14" string="states" />
            <token id="15" string="that" />
            <token id="16" string="have" />
            <token id="17" string="suffered" />
            <token id="18" string="from" />
            <token id="19" string="a" />
            <token id="20" string="huge" />
            <token id="21" string="influx" />
            <token id="22" string="of" />
            <token id="23" string="immigration" />
            <token id="24" string="beyond" />
            <token id="25" string="the" />
            <token id="26" string="legal" />
            <token id="27" string="limits" />
          </tokens>
        </chunking>
        <chunking id="15" string="the decennial census" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="decennial" />
            <token id="9" string="census" />
          </tokens>
        </chunking>
        <chunking id="16" string="the legal limits" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="legal" />
            <token id="27" string="limits" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">countered</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">unfair</governor>
          <dependent id="2">that</dependent>
        </dependency>
        <dependency type="csubj">
          <governor id="11">unfair</governor>
          <dependent id="3">excluding</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">residents</governor>
          <dependent id="4">illegal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">excluding</governor>
          <dependent id="5">residents</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">census</governor>
          <dependent id="6">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">census</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">census</governor>
          <dependent id="8">decennial</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">excluding</governor>
          <dependent id="9">census</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">unfair</governor>
          <dependent id="10">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="1">countered</governor>
          <dependent id="11">unfair</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">states</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">states</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">unfair</governor>
          <dependent id="14">states</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">suffered</governor>
          <dependent id="15">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="17">suffered</governor>
          <dependent id="16">have</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="14">states</governor>
          <dependent id="17">suffered</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">influx</governor>
          <dependent id="18">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">influx</governor>
          <dependent id="19">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">influx</governor>
          <dependent id="20">huge</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">suffered</governor>
          <dependent id="21">influx</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">immigration</governor>
          <dependent id="22">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">influx</governor>
          <dependent id="23">immigration</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">limits</governor>
          <dependent id="24">beyond</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">limits</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">limits</governor>
          <dependent id="26">legal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">suffered</governor>
          <dependent id="27">limits</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>&amp;quot;There are enormous additional costs for states who have had a surge of population,&amp;quot; Wilson said, adding that those states should receive additional federal aid to cope with the added problems.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="enormous" lemma="enormous" stem="enorm" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="additional" lemma="additional" stem="addit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="costs" lemma="cost" stem="cost" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="states" lemma="state" stem="state" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="had" lemma="have" stem="had" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="surge" lemma="surge" stem="surg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="population" lemma="population" stem="popul" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Wilson" lemma="Wilson" stem="wilson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="19" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="adding" lemma="add" stem="ad" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="states" lemma="state" stem="state" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="should" lemma="should" stem="should" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="receive" lemma="receive" stem="receiv" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="additional" lemma="additional" stem="addit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="federal" lemma="federal" stem="feder" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="aid" lemma="aid" stem="aid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="cope" lemma="cope" stem="cope" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="added" lemma="add" stem="ad" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="problems" lemma="problem" stem="problem" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (EX There)) (VP (VBP are) (NP (NP (JJ enormous) (JJ additional) (NNS costs)) (PP (IN for) (NP (NP (NNS states)) (SBAR (WHNP (WP who)) (S (VP (VBP have) (VP (VBN had) (NP (NP (DT a) (NN surge)) (PP (IN of) (NP (NN population))))))))))))) (, ,) ('' '') (NP (NNP Wilson)) (VP (VBD said) (, ,) (S (VP (VBG adding) (SBAR (IN that) (S (NP (DT those) (NNS states)) (VP (MD should) (VP (VB receive) (NP (JJ additional) (JJ federal) (NN aid)) (S (VP (TO to) (VP (VB cope) (PP (IN with) (NP (DT the) (VBN added) (NNS problems))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="who have had a surge of population" type="SBAR">
          <tokens>
            <token id="9" string="who" />
            <token id="10" string="have" />
            <token id="11" string="had" />
            <token id="12" string="a" />
            <token id="13" string="surge" />
            <token id="14" string="of" />
            <token id="15" string="population" />
          </tokens>
        </chunking>
        <chunking id="2" string="said , adding that those states should receive additional federal aid to cope with the added problems" type="VP">
          <tokens>
            <token id="19" string="said" />
            <token id="20" string="," />
            <token id="21" string="adding" />
            <token id="22" string="that" />
            <token id="23" string="those" />
            <token id="24" string="states" />
            <token id="25" string="should" />
            <token id="26" string="receive" />
            <token id="27" string="additional" />
            <token id="28" string="federal" />
            <token id="29" string="aid" />
            <token id="30" string="to" />
            <token id="31" string="cope" />
            <token id="32" string="with" />
            <token id="33" string="the" />
            <token id="34" string="added" />
            <token id="35" string="problems" />
          </tokens>
        </chunking>
        <chunking id="3" string="enormous additional costs for states who have had a surge of population" type="NP">
          <tokens>
            <token id="4" string="enormous" />
            <token id="5" string="additional" />
            <token id="6" string="costs" />
            <token id="7" string="for" />
            <token id="8" string="states" />
            <token id="9" string="who" />
            <token id="10" string="have" />
            <token id="11" string="had" />
            <token id="12" string="a" />
            <token id="13" string="surge" />
            <token id="14" string="of" />
            <token id="15" string="population" />
          </tokens>
        </chunking>
        <chunking id="4" string="receive additional federal aid to cope with the added problems" type="VP">
          <tokens>
            <token id="26" string="receive" />
            <token id="27" string="additional" />
            <token id="28" string="federal" />
            <token id="29" string="aid" />
            <token id="30" string="to" />
            <token id="31" string="cope" />
            <token id="32" string="with" />
            <token id="33" string="the" />
            <token id="34" string="added" />
            <token id="35" string="problems" />
          </tokens>
        </chunking>
        <chunking id="5" string="Wilson" type="NP">
          <tokens>
            <token id="18" string="Wilson" />
          </tokens>
        </chunking>
        <chunking id="6" string="that those states should receive additional federal aid to cope with the added problems" type="SBAR">
          <tokens>
            <token id="22" string="that" />
            <token id="23" string="those" />
            <token id="24" string="states" />
            <token id="25" string="should" />
            <token id="26" string="receive" />
            <token id="27" string="additional" />
            <token id="28" string="federal" />
            <token id="29" string="aid" />
            <token id="30" string="to" />
            <token id="31" string="cope" />
            <token id="32" string="with" />
            <token id="33" string="the" />
            <token id="34" string="added" />
            <token id="35" string="problems" />
          </tokens>
        </chunking>
        <chunking id="7" string="should receive additional federal aid to cope with the added problems" type="VP">
          <tokens>
            <token id="25" string="should" />
            <token id="26" string="receive" />
            <token id="27" string="additional" />
            <token id="28" string="federal" />
            <token id="29" string="aid" />
            <token id="30" string="to" />
            <token id="31" string="cope" />
            <token id="32" string="with" />
            <token id="33" string="the" />
            <token id="34" string="added" />
            <token id="35" string="problems" />
          </tokens>
        </chunking>
        <chunking id="8" string="states" type="NP">
          <tokens>
            <token id="8" string="states" />
          </tokens>
        </chunking>
        <chunking id="9" string="had a surge of population" type="VP">
          <tokens>
            <token id="11" string="had" />
            <token id="12" string="a" />
            <token id="13" string="surge" />
            <token id="14" string="of" />
            <token id="15" string="population" />
          </tokens>
        </chunking>
        <chunking id="10" string="a surge" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="surge" />
          </tokens>
        </chunking>
        <chunking id="11" string="are enormous additional costs for states who have had a surge of population" type="VP">
          <tokens>
            <token id="3" string="are" />
            <token id="4" string="enormous" />
            <token id="5" string="additional" />
            <token id="6" string="costs" />
            <token id="7" string="for" />
            <token id="8" string="states" />
            <token id="9" string="who" />
            <token id="10" string="have" />
            <token id="11" string="had" />
            <token id="12" string="a" />
            <token id="13" string="surge" />
            <token id="14" string="of" />
            <token id="15" string="population" />
          </tokens>
        </chunking>
        <chunking id="12" string="population" type="NP">
          <tokens>
            <token id="15" string="population" />
          </tokens>
        </chunking>
        <chunking id="13" string="additional federal aid" type="NP">
          <tokens>
            <token id="27" string="additional" />
            <token id="28" string="federal" />
            <token id="29" string="aid" />
          </tokens>
        </chunking>
        <chunking id="14" string="a surge of population" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="surge" />
            <token id="14" string="of" />
            <token id="15" string="population" />
          </tokens>
        </chunking>
        <chunking id="15" string="There" type="NP">
          <tokens>
            <token id="2" string="There" />
          </tokens>
        </chunking>
        <chunking id="16" string="enormous additional costs" type="NP">
          <tokens>
            <token id="4" string="enormous" />
            <token id="5" string="additional" />
            <token id="6" string="costs" />
          </tokens>
        </chunking>
        <chunking id="17" string="the added problems" type="NP">
          <tokens>
            <token id="33" string="the" />
            <token id="34" string="added" />
            <token id="35" string="problems" />
          </tokens>
        </chunking>
        <chunking id="18" string="states who have had a surge of population" type="NP">
          <tokens>
            <token id="8" string="states" />
            <token id="9" string="who" />
            <token id="10" string="have" />
            <token id="11" string="had" />
            <token id="12" string="a" />
            <token id="13" string="surge" />
            <token id="14" string="of" />
            <token id="15" string="population" />
          </tokens>
        </chunking>
        <chunking id="19" string="cope with the added problems" type="VP">
          <tokens>
            <token id="31" string="cope" />
            <token id="32" string="with" />
            <token id="33" string="the" />
            <token id="34" string="added" />
            <token id="35" string="problems" />
          </tokens>
        </chunking>
        <chunking id="20" string="have had a surge of population" type="VP">
          <tokens>
            <token id="10" string="have" />
            <token id="11" string="had" />
            <token id="12" string="a" />
            <token id="13" string="surge" />
            <token id="14" string="of" />
            <token id="15" string="population" />
          </tokens>
        </chunking>
        <chunking id="21" string="those states" type="NP">
          <tokens>
            <token id="23" string="those" />
            <token id="24" string="states" />
          </tokens>
        </chunking>
        <chunking id="22" string="to cope with the added problems" type="VP">
          <tokens>
            <token id="30" string="to" />
            <token id="31" string="cope" />
            <token id="32" string="with" />
            <token id="33" string="the" />
            <token id="34" string="added" />
            <token id="35" string="problems" />
          </tokens>
        </chunking>
        <chunking id="23" string="adding that those states should receive additional federal aid to cope with the added problems" type="VP">
          <tokens>
            <token id="21" string="adding" />
            <token id="22" string="that" />
            <token id="23" string="those" />
            <token id="24" string="states" />
            <token id="25" string="should" />
            <token id="26" string="receive" />
            <token id="27" string="additional" />
            <token id="28" string="federal" />
            <token id="29" string="aid" />
            <token id="30" string="to" />
            <token id="31" string="cope" />
            <token id="32" string="with" />
            <token id="33" string="the" />
            <token id="34" string="added" />
            <token id="35" string="problems" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="3">are</governor>
          <dependent id="2">There</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">said</governor>
          <dependent id="3">are</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">costs</governor>
          <dependent id="4">enormous</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">costs</governor>
          <dependent id="5">additional</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">are</governor>
          <dependent id="6">costs</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">states</governor>
          <dependent id="7">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">costs</governor>
          <dependent id="8">states</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">had</governor>
          <dependent id="9">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">had</governor>
          <dependent id="10">have</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="8">states</governor>
          <dependent id="11">had</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">surge</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">had</governor>
          <dependent id="13">surge</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">population</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">surge</governor>
          <dependent id="15">population</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">said</governor>
          <dependent id="18">Wilson</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="19">said</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="19">said</governor>
          <dependent id="21">adding</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="26">receive</governor>
          <dependent id="22">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">states</governor>
          <dependent id="23">those</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">receive</governor>
          <dependent id="24">states</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="26">receive</governor>
          <dependent id="25">should</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="21">adding</governor>
          <dependent id="26">receive</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">aid</governor>
          <dependent id="27">additional</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">aid</governor>
          <dependent id="28">federal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="26">receive</governor>
          <dependent id="29">aid</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="31">cope</governor>
          <dependent id="30">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="26">receive</governor>
          <dependent id="31">cope</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">problems</governor>
          <dependent id="32">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">problems</governor>
          <dependent id="33">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="35">problems</governor>
          <dependent id="34">added</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">cope</governor>
          <dependent id="35">problems</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Wilson" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Wilson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="false">
      <content>Opponents of a ban on counting illegal aliens said that a ban is impractical because the Census Bureau already has printed questionnaires that do not contain any question about legality of residence.</content>
      <tokens>
        <token id="1" string="Opponents" lemma="opponent" stem="opponent" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="ban" lemma="ban" stem="ban" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="counting" lemma="count" stem="count" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="illegal" lemma="illegal" stem="illeg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="aliens" lemma="alien" stem="alien" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="ban" lemma="ban" stem="ban" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="impractical" lemma="impractical" stem="impract" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Census" lemma="Census" stem="censu" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="18" string="Bureau" lemma="Bureau" stem="bureau" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="19" string="already" lemma="already" stem="alreadi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="printed" lemma="print" stem="print" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="questionnaires" lemma="questionnaire" stem="questionnair" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="contain" lemma="contain" stem="contain" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="question" lemma="question" stem="question" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="legality" lemma="legality" stem="legal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="residence" lemma="residence" stem="resid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNS Opponents)) (PP (IN of) (NP (NP (DT a) (NN ban)) (PP (IN on) (NP (VBG counting) (JJ illegal) (NNS aliens)))))) (VP (VBD said) (SBAR (IN that) (S (NP (DT a) (NN ban)) (VP (VBZ is) (ADJP (JJ impractical)) (SBAR (IN because) (S (NP (DT the) (NNP Census) (NNP Bureau)) (ADVP (RB already)) (VP (VBZ has) (VP (VBN printed) (NP (NP (NNS questionnaires)) (SBAR (WHNP (WDT that)) (S (VP (VBP do) (RB not) (VP (VB contain) (NP (DT any) (NN question)) (PP (IN about) (NP (NP (NN legality)) (PP (IN of) (NP (NN residence)))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="any question" type="NP">
          <tokens>
            <token id="27" string="any" />
            <token id="28" string="question" />
          </tokens>
        </chunking>
        <chunking id="2" string="because the Census Bureau already has printed questionnaires that do not contain any question about legality of residence" type="SBAR">
          <tokens>
            <token id="15" string="because" />
            <token id="16" string="the" />
            <token id="17" string="Census" />
            <token id="18" string="Bureau" />
            <token id="19" string="already" />
            <token id="20" string="has" />
            <token id="21" string="printed" />
            <token id="22" string="questionnaires" />
            <token id="23" string="that" />
            <token id="24" string="do" />
            <token id="25" string="not" />
            <token id="26" string="contain" />
            <token id="27" string="any" />
            <token id="28" string="question" />
            <token id="29" string="about" />
            <token id="30" string="legality" />
            <token id="31" string="of" />
            <token id="32" string="residence" />
          </tokens>
        </chunking>
        <chunking id="3" string="said that a ban is impractical because the Census Bureau already has printed questionnaires that do not contain any question about legality of residence" type="VP">
          <tokens>
            <token id="9" string="said" />
            <token id="10" string="that" />
            <token id="11" string="a" />
            <token id="12" string="ban" />
            <token id="13" string="is" />
            <token id="14" string="impractical" />
            <token id="15" string="because" />
            <token id="16" string="the" />
            <token id="17" string="Census" />
            <token id="18" string="Bureau" />
            <token id="19" string="already" />
            <token id="20" string="has" />
            <token id="21" string="printed" />
            <token id="22" string="questionnaires" />
            <token id="23" string="that" />
            <token id="24" string="do" />
            <token id="25" string="not" />
            <token id="26" string="contain" />
            <token id="27" string="any" />
            <token id="28" string="question" />
            <token id="29" string="about" />
            <token id="30" string="legality" />
            <token id="31" string="of" />
            <token id="32" string="residence" />
          </tokens>
        </chunking>
        <chunking id="4" string="legality of residence" type="NP">
          <tokens>
            <token id="30" string="legality" />
            <token id="31" string="of" />
            <token id="32" string="residence" />
          </tokens>
        </chunking>
        <chunking id="5" string="the Census Bureau" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="Census" />
            <token id="18" string="Bureau" />
          </tokens>
        </chunking>
        <chunking id="6" string="a ban on counting illegal aliens" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="ban" />
            <token id="5" string="on" />
            <token id="6" string="counting" />
            <token id="7" string="illegal" />
            <token id="8" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="7" string="a ban" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="ban" />
          </tokens>
        </chunking>
        <chunking id="8" string="that do not contain any question about legality of residence" type="SBAR">
          <tokens>
            <token id="23" string="that" />
            <token id="24" string="do" />
            <token id="25" string="not" />
            <token id="26" string="contain" />
            <token id="27" string="any" />
            <token id="28" string="question" />
            <token id="29" string="about" />
            <token id="30" string="legality" />
            <token id="31" string="of" />
            <token id="32" string="residence" />
          </tokens>
        </chunking>
        <chunking id="9" string="contain any question about legality of residence" type="VP">
          <tokens>
            <token id="26" string="contain" />
            <token id="27" string="any" />
            <token id="28" string="question" />
            <token id="29" string="about" />
            <token id="30" string="legality" />
            <token id="31" string="of" />
            <token id="32" string="residence" />
          </tokens>
        </chunking>
        <chunking id="10" string="is impractical because the Census Bureau already has printed questionnaires that do not contain any question about legality of residence" type="VP">
          <tokens>
            <token id="13" string="is" />
            <token id="14" string="impractical" />
            <token id="15" string="because" />
            <token id="16" string="the" />
            <token id="17" string="Census" />
            <token id="18" string="Bureau" />
            <token id="19" string="already" />
            <token id="20" string="has" />
            <token id="21" string="printed" />
            <token id="22" string="questionnaires" />
            <token id="23" string="that" />
            <token id="24" string="do" />
            <token id="25" string="not" />
            <token id="26" string="contain" />
            <token id="27" string="any" />
            <token id="28" string="question" />
            <token id="29" string="about" />
            <token id="30" string="legality" />
            <token id="31" string="of" />
            <token id="32" string="residence" />
          </tokens>
        </chunking>
        <chunking id="11" string="questionnaires" type="NP">
          <tokens>
            <token id="22" string="questionnaires" />
          </tokens>
        </chunking>
        <chunking id="12" string="questionnaires that do not contain any question about legality of residence" type="NP">
          <tokens>
            <token id="22" string="questionnaires" />
            <token id="23" string="that" />
            <token id="24" string="do" />
            <token id="25" string="not" />
            <token id="26" string="contain" />
            <token id="27" string="any" />
            <token id="28" string="question" />
            <token id="29" string="about" />
            <token id="30" string="legality" />
            <token id="31" string="of" />
            <token id="32" string="residence" />
          </tokens>
        </chunking>
        <chunking id="13" string="counting illegal aliens" type="NP">
          <tokens>
            <token id="6" string="counting" />
            <token id="7" string="illegal" />
            <token id="8" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="14" string="legality" type="NP">
          <tokens>
            <token id="30" string="legality" />
          </tokens>
        </chunking>
        <chunking id="15" string="Opponents of a ban on counting illegal aliens" type="NP">
          <tokens>
            <token id="1" string="Opponents" />
            <token id="2" string="of" />
            <token id="3" string="a" />
            <token id="4" string="ban" />
            <token id="5" string="on" />
            <token id="6" string="counting" />
            <token id="7" string="illegal" />
            <token id="8" string="aliens" />
          </tokens>
        </chunking>
        <chunking id="16" string="Opponents" type="NP">
          <tokens>
            <token id="1" string="Opponents" />
          </tokens>
        </chunking>
        <chunking id="17" string="printed questionnaires that do not contain any question about legality of residence" type="VP">
          <tokens>
            <token id="21" string="printed" />
            <token id="22" string="questionnaires" />
            <token id="23" string="that" />
            <token id="24" string="do" />
            <token id="25" string="not" />
            <token id="26" string="contain" />
            <token id="27" string="any" />
            <token id="28" string="question" />
            <token id="29" string="about" />
            <token id="30" string="legality" />
            <token id="31" string="of" />
            <token id="32" string="residence" />
          </tokens>
        </chunking>
        <chunking id="18" string="that a ban is impractical because the Census Bureau already has printed questionnaires that do not contain any question about legality of residence" type="SBAR">
          <tokens>
            <token id="10" string="that" />
            <token id="11" string="a" />
            <token id="12" string="ban" />
            <token id="13" string="is" />
            <token id="14" string="impractical" />
            <token id="15" string="because" />
            <token id="16" string="the" />
            <token id="17" string="Census" />
            <token id="18" string="Bureau" />
            <token id="19" string="already" />
            <token id="20" string="has" />
            <token id="21" string="printed" />
            <token id="22" string="questionnaires" />
            <token id="23" string="that" />
            <token id="24" string="do" />
            <token id="25" string="not" />
            <token id="26" string="contain" />
            <token id="27" string="any" />
            <token id="28" string="question" />
            <token id="29" string="about" />
            <token id="30" string="legality" />
            <token id="31" string="of" />
            <token id="32" string="residence" />
          </tokens>
        </chunking>
        <chunking id="19" string="impractical" type="ADJP">
          <tokens>
            <token id="14" string="impractical" />
          </tokens>
        </chunking>
        <chunking id="20" string="has printed questionnaires that do not contain any question about legality of residence" type="VP">
          <tokens>
            <token id="20" string="has" />
            <token id="21" string="printed" />
            <token id="22" string="questionnaires" />
            <token id="23" string="that" />
            <token id="24" string="do" />
            <token id="25" string="not" />
            <token id="26" string="contain" />
            <token id="27" string="any" />
            <token id="28" string="question" />
            <token id="29" string="about" />
            <token id="30" string="legality" />
            <token id="31" string="of" />
            <token id="32" string="residence" />
          </tokens>
        </chunking>
        <chunking id="21" string="do not contain any question about legality of residence" type="VP">
          <tokens>
            <token id="24" string="do" />
            <token id="25" string="not" />
            <token id="26" string="contain" />
            <token id="27" string="any" />
            <token id="28" string="question" />
            <token id="29" string="about" />
            <token id="30" string="legality" />
            <token id="31" string="of" />
            <token id="32" string="residence" />
          </tokens>
        </chunking>
        <chunking id="22" string="residence" type="NP">
          <tokens>
            <token id="32" string="residence" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="9">said</governor>
          <dependent id="1">Opponents</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">ban</governor>
          <dependent id="2">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">ban</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Opponents</governor>
          <dependent id="4">ban</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">aliens</governor>
          <dependent id="5">on</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">aliens</governor>
          <dependent id="6">counting</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">aliens</governor>
          <dependent id="7">illegal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">ban</governor>
          <dependent id="8">aliens</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">said</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">impractical</governor>
          <dependent id="10">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">ban</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">impractical</governor>
          <dependent id="12">ban</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">impractical</governor>
          <dependent id="13">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">said</governor>
          <dependent id="14">impractical</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">printed</governor>
          <dependent id="15">because</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">Bureau</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Bureau</governor>
          <dependent id="17">Census</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">printed</governor>
          <dependent id="18">Bureau</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="21">printed</governor>
          <dependent id="19">already</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">printed</governor>
          <dependent id="20">has</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="14">impractical</governor>
          <dependent id="21">printed</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">printed</governor>
          <dependent id="22">questionnaires</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">contain</governor>
          <dependent id="23">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="26">contain</governor>
          <dependent id="24">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="26">contain</governor>
          <dependent id="25">not</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="22">questionnaires</governor>
          <dependent id="26">contain</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">question</governor>
          <dependent id="27">any</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="26">contain</governor>
          <dependent id="28">question</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">legality</governor>
          <dependent id="29">about</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">contain</governor>
          <dependent id="30">legality</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">residence</governor>
          <dependent id="31">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">legality</governor>
          <dependent id="32">residence</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Census Bureau" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="17" string="Census" />
            <token id="18" string="Bureau" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>For 190 years, said Sen. Daniel Patrick Moynihan (D-N.Y.), the federal government has counted all inhabitants without regard to citizenship in accordance with the Constitution&amp;apost;s provisions.</content>
      <tokens>
        <token id="1" string="For" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="190" lemma="190" stem="190" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="3" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="Sen." lemma="Sen." stem="sen." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="Daniel" lemma="Daniel" stem="daniel" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="8" string="Patrick" lemma="Patrick" stem="patrick" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="9" string="Moynihan" lemma="Moynihan" stem="moynihan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="10" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="D-N.Y." lemma="D-N.Y." stem="d-n.y." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="federal" lemma="federal" stem="feder" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="government" lemma="government" stem="govern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="counted" lemma="count" stem="count" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="inhabitants" lemma="inhabitant" stem="inhabit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="without" lemma="without" stem="without" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="regard" lemma="regard" stem="regard" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="citizenship" lemma="citizenship" stem="citizenship" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="accordance" lemma="accordance" stem="accord" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="Constitution" lemma="Constitution" stem="constitut" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="provisions" lemma="provision" stem="provis" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN For) (NP (CD 190) (NNS years))) (PRN (, ,) (SINV (VP (VBD said)) (NP (NP (NNP Sen.) (NNP Daniel) (NNP Patrick) (NNP Moynihan)) (PRN (-LRB- -LRB-) (NP (NNP D-N.Y.)) (-RRB- -RRB-)))) (, ,)) (NP (DT the) (JJ federal) (NN government)) (VP (VBZ has) (VP (VBN counted) (NP (DT all) (NNS inhabitants)) (PP (IN without) (NP (NN regard))) (PP (TO to) (NP (NP (NN citizenship)) (PP (IN in) (NP (NN accordance))))) (PP (IN with) (NP (NP (DT the) (NNP Constitution) (POS 's)) (NNS provisions))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="citizenship" type="NP">
          <tokens>
            <token id="24" string="citizenship" />
          </tokens>
        </chunking>
        <chunking id="2" string="the federal government" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="federal" />
            <token id="16" string="government" />
          </tokens>
        </chunking>
        <chunking id="3" string="accordance" type="NP">
          <tokens>
            <token id="26" string="accordance" />
          </tokens>
        </chunking>
        <chunking id="4" string="the Constitution 's" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="Constitution" />
            <token id="30" string="'s" />
          </tokens>
        </chunking>
        <chunking id="5" string="190 years" type="NP">
          <tokens>
            <token id="2" string="190" />
            <token id="3" string="years" />
          </tokens>
        </chunking>
        <chunking id="6" string="Sen. Daniel Patrick Moynihan" type="NP">
          <tokens>
            <token id="6" string="Sen." />
            <token id="7" string="Daniel" />
            <token id="8" string="Patrick" />
            <token id="9" string="Moynihan" />
          </tokens>
        </chunking>
        <chunking id="7" string="has counted all inhabitants without regard to citizenship in accordance with the Constitution 's provisions" type="VP">
          <tokens>
            <token id="17" string="has" />
            <token id="18" string="counted" />
            <token id="19" string="all" />
            <token id="20" string="inhabitants" />
            <token id="21" string="without" />
            <token id="22" string="regard" />
            <token id="23" string="to" />
            <token id="24" string="citizenship" />
            <token id="25" string="in" />
            <token id="26" string="accordance" />
            <token id="27" string="with" />
            <token id="28" string="the" />
            <token id="29" string="Constitution" />
            <token id="30" string="'s" />
            <token id="31" string="provisions" />
          </tokens>
        </chunking>
        <chunking id="8" string="Sen. Daniel Patrick Moynihan -LRB- D-N.Y. -RRB-" type="NP">
          <tokens>
            <token id="6" string="Sen." />
            <token id="7" string="Daniel" />
            <token id="8" string="Patrick" />
            <token id="9" string="Moynihan" />
            <token id="10" string="(" />
            <token id="11" string="D-N.Y." />
            <token id="12" string=")" />
          </tokens>
        </chunking>
        <chunking id="9" string="citizenship in accordance" type="NP">
          <tokens>
            <token id="24" string="citizenship" />
            <token id="25" string="in" />
            <token id="26" string="accordance" />
          </tokens>
        </chunking>
        <chunking id="10" string="all inhabitants" type="NP">
          <tokens>
            <token id="19" string="all" />
            <token id="20" string="inhabitants" />
          </tokens>
        </chunking>
        <chunking id="11" string="the Constitution 's provisions" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="Constitution" />
            <token id="30" string="'s" />
            <token id="31" string="provisions" />
          </tokens>
        </chunking>
        <chunking id="12" string="regard" type="NP">
          <tokens>
            <token id="22" string="regard" />
          </tokens>
        </chunking>
        <chunking id="13" string="counted all inhabitants without regard to citizenship in accordance with the Constitution 's provisions" type="VP">
          <tokens>
            <token id="18" string="counted" />
            <token id="19" string="all" />
            <token id="20" string="inhabitants" />
            <token id="21" string="without" />
            <token id="22" string="regard" />
            <token id="23" string="to" />
            <token id="24" string="citizenship" />
            <token id="25" string="in" />
            <token id="26" string="accordance" />
            <token id="27" string="with" />
            <token id="28" string="the" />
            <token id="29" string="Constitution" />
            <token id="30" string="'s" />
            <token id="31" string="provisions" />
          </tokens>
        </chunking>
        <chunking id="14" string="D-N.Y." type="NP">
          <tokens>
            <token id="11" string="D-N.Y." />
          </tokens>
        </chunking>
        <chunking id="15" string="said" type="VP">
          <tokens>
            <token id="5" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">years</governor>
          <dependent id="1">For</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="3">years</governor>
          <dependent id="2">190</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">counted</governor>
          <dependent id="3">years</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="18">counted</governor>
          <dependent id="5">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Moynihan</governor>
          <dependent id="6">Sen.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Moynihan</governor>
          <dependent id="7">Daniel</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Moynihan</governor>
          <dependent id="8">Patrick</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">said</governor>
          <dependent id="9">Moynihan</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="9">Moynihan</governor>
          <dependent id="11">D-N.Y.</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">government</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">government</governor>
          <dependent id="15">federal</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">counted</governor>
          <dependent id="16">government</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">counted</governor>
          <dependent id="17">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">counted</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">inhabitants</governor>
          <dependent id="19">all</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">counted</governor>
          <dependent id="20">inhabitants</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">regard</governor>
          <dependent id="21">without</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">counted</governor>
          <dependent id="22">regard</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">citizenship</governor>
          <dependent id="23">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">counted</governor>
          <dependent id="24">citizenship</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">accordance</governor>
          <dependent id="25">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">citizenship</governor>
          <dependent id="26">accordance</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">provisions</governor>
          <dependent id="27">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">Constitution</governor>
          <dependent id="28">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="31">provisions</governor>
          <dependent id="29">Constitution</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">Constitution</governor>
          <dependent id="30">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">counted</governor>
          <dependent id="31">provisions</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="190 years" type="DURATION" score="0.0">
          <tokens>
            <token id="2" string="190" />
            <token id="3" string="years" />
          </tokens>
        </entity>
        <entity id="2" string="Daniel Patrick Moynihan" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Daniel" />
            <token id="8" string="Patrick" />
            <token id="9" string="Moynihan" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>&amp;quot;Fiddling with the numbers&amp;quot; now will destroy confidence in the census results, he added.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Fiddling" lemma="fiddle" stem="fiddl" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="numbers" lemma="number" stem="number" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="8" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="destroy" lemma="destroy" stem="destroi" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="confidence" lemma="confidence" stem="confid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="census" lemma="census" stem="censu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="results" lemma="result" stem="result" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="added" lemma="add" stem="ad" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (`` ``) (S (VP (VBG Fiddling) (PP (IN with) (NP (DT the) (NNS numbers))))) ('' '') (VP (ADVP (RB now)) (MD will) (VP (VB destroy) (NP (NN confidence)) (PP (IN in) (NP (NP (DT the) (NN census)) (VP (VBZ results))))))) (, ,) (NP (PRP he)) (VP (VBD added)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="now will destroy confidence in the census results" type="VP">
          <tokens>
            <token id="7" string="now" />
            <token id="8" string="will" />
            <token id="9" string="destroy" />
            <token id="10" string="confidence" />
            <token id="11" string="in" />
            <token id="12" string="the" />
            <token id="13" string="census" />
            <token id="14" string="results" />
          </tokens>
        </chunking>
        <chunking id="2" string="the numbers" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="numbers" />
          </tokens>
        </chunking>
        <chunking id="3" string="destroy confidence in the census results" type="VP">
          <tokens>
            <token id="9" string="destroy" />
            <token id="10" string="confidence" />
            <token id="11" string="in" />
            <token id="12" string="the" />
            <token id="13" string="census" />
            <token id="14" string="results" />
          </tokens>
        </chunking>
        <chunking id="4" string="confidence" type="NP">
          <tokens>
            <token id="10" string="confidence" />
          </tokens>
        </chunking>
        <chunking id="5" string="the census results" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="census" />
            <token id="14" string="results" />
          </tokens>
        </chunking>
        <chunking id="6" string="the census" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="census" />
          </tokens>
        </chunking>
        <chunking id="7" string="added" type="VP">
          <tokens>
            <token id="17" string="added" />
          </tokens>
        </chunking>
        <chunking id="8" string="Fiddling with the numbers" type="VP">
          <tokens>
            <token id="2" string="Fiddling" />
            <token id="3" string="with" />
            <token id="4" string="the" />
            <token id="5" string="numbers" />
          </tokens>
        </chunking>
        <chunking id="9" string="he" type="NP">
          <tokens>
            <token id="16" string="he" />
          </tokens>
        </chunking>
        <chunking id="10" string="results" type="VP">
          <tokens>
            <token id="14" string="results" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="csubj">
          <governor id="9">destroy</governor>
          <dependent id="2">Fiddling</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">numbers</governor>
          <dependent id="3">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">numbers</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">Fiddling</governor>
          <dependent id="5">numbers</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">destroy</governor>
          <dependent id="7">now</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">destroy</governor>
          <dependent id="8">will</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">added</governor>
          <dependent id="9">destroy</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">destroy</governor>
          <dependent id="10">confidence</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">census</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">census</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">destroy</governor>
          <dependent id="13">census</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="13">census</governor>
          <dependent id="14">results</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">added</governor>
          <dependent id="16">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">added</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="7" string="now" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>The Senate&amp;apost;s action was sharply criticized by Undersecretary of Commerce Michael Darby, but he voiced hope that it would be reversed by a Senate-House conference.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="2" string="Senate" lemma="Senate" stem="senat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="3" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="4" string="action" lemma="action" stem="action" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="sharply" lemma="sharply" stem="sharpli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="criticized" lemma="criticize" stem="critic" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Undersecretary" lemma="Undersecretary" stem="undersecretari" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="Commerce" lemma="Commerce" stem="commerc" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="Michael" lemma="Michael" stem="michael" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="13" string="Darby" lemma="Darby" stem="darbi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="voiced" lemma="voice" stem="voic" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="hope" lemma="hope" stem="hope" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="reversed" lemma="reverse" stem="revers" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="Senate-House" lemma="senate-house" stem="senate-hous" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="conference" lemma="conference" stem="confer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (DT The) (NNP Senate) (POS 's)) (NN action)) (VP (VBD was) (ADVP (RB sharply)) (VP (VBN criticized) (PP (IN by) (NP (NP (NNP Undersecretary)) (PP (IN of) (NP (NNP Commerce) (NNP Michael) (NNP Darby)))))))) (, ,) (CC but) (S (NP (PRP he)) (VP (VBD voiced) (NP (NN hope)) (SBAR (IN that) (S (NP (PRP it)) (VP (MD would) (VP (VB be) (VP (VBN reversed) (PP (IN by) (NP (DT a) (JJ Senate-House) (NN conference)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="voiced hope that it would be reversed by a Senate-House conference" type="VP">
          <tokens>
            <token id="17" string="voiced" />
            <token id="18" string="hope" />
            <token id="19" string="that" />
            <token id="20" string="it" />
            <token id="21" string="would" />
            <token id="22" string="be" />
            <token id="23" string="reversed" />
            <token id="24" string="by" />
            <token id="25" string="a" />
            <token id="26" string="Senate-House" />
            <token id="27" string="conference" />
          </tokens>
        </chunking>
        <chunking id="2" string="Commerce Michael Darby" type="NP">
          <tokens>
            <token id="11" string="Commerce" />
            <token id="12" string="Michael" />
            <token id="13" string="Darby" />
          </tokens>
        </chunking>
        <chunking id="3" string="it" type="NP">
          <tokens>
            <token id="20" string="it" />
          </tokens>
        </chunking>
        <chunking id="4" string="hope" type="NP">
          <tokens>
            <token id="18" string="hope" />
          </tokens>
        </chunking>
        <chunking id="5" string="that it would be reversed by a Senate-House conference" type="SBAR">
          <tokens>
            <token id="19" string="that" />
            <token id="20" string="it" />
            <token id="21" string="would" />
            <token id="22" string="be" />
            <token id="23" string="reversed" />
            <token id="24" string="by" />
            <token id="25" string="a" />
            <token id="26" string="Senate-House" />
            <token id="27" string="conference" />
          </tokens>
        </chunking>
        <chunking id="6" string="would be reversed by a Senate-House conference" type="VP">
          <tokens>
            <token id="21" string="would" />
            <token id="22" string="be" />
            <token id="23" string="reversed" />
            <token id="24" string="by" />
            <token id="25" string="a" />
            <token id="26" string="Senate-House" />
            <token id="27" string="conference" />
          </tokens>
        </chunking>
        <chunking id="7" string="criticized by Undersecretary of Commerce Michael Darby" type="VP">
          <tokens>
            <token id="7" string="criticized" />
            <token id="8" string="by" />
            <token id="9" string="Undersecretary" />
            <token id="10" string="of" />
            <token id="11" string="Commerce" />
            <token id="12" string="Michael" />
            <token id="13" string="Darby" />
          </tokens>
        </chunking>
        <chunking id="8" string="Undersecretary" type="NP">
          <tokens>
            <token id="9" string="Undersecretary" />
          </tokens>
        </chunking>
        <chunking id="9" string="The Senate 's action" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Senate" />
            <token id="3" string="'s" />
            <token id="4" string="action" />
          </tokens>
        </chunking>
        <chunking id="10" string="Undersecretary of Commerce Michael Darby" type="NP">
          <tokens>
            <token id="9" string="Undersecretary" />
            <token id="10" string="of" />
            <token id="11" string="Commerce" />
            <token id="12" string="Michael" />
            <token id="13" string="Darby" />
          </tokens>
        </chunking>
        <chunking id="11" string="be reversed by a Senate-House conference" type="VP">
          <tokens>
            <token id="22" string="be" />
            <token id="23" string="reversed" />
            <token id="24" string="by" />
            <token id="25" string="a" />
            <token id="26" string="Senate-House" />
            <token id="27" string="conference" />
          </tokens>
        </chunking>
        <chunking id="12" string="reversed by a Senate-House conference" type="VP">
          <tokens>
            <token id="23" string="reversed" />
            <token id="24" string="by" />
            <token id="25" string="a" />
            <token id="26" string="Senate-House" />
            <token id="27" string="conference" />
          </tokens>
        </chunking>
        <chunking id="13" string="The Senate 's" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Senate" />
            <token id="3" string="'s" />
          </tokens>
        </chunking>
        <chunking id="14" string="he" type="NP">
          <tokens>
            <token id="16" string="he" />
          </tokens>
        </chunking>
        <chunking id="15" string="a Senate-House conference" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="Senate-House" />
            <token id="27" string="conference" />
          </tokens>
        </chunking>
        <chunking id="16" string="was sharply criticized by Undersecretary of Commerce Michael Darby" type="VP">
          <tokens>
            <token id="5" string="was" />
            <token id="6" string="sharply" />
            <token id="7" string="criticized" />
            <token id="8" string="by" />
            <token id="9" string="Undersecretary" />
            <token id="10" string="of" />
            <token id="11" string="Commerce" />
            <token id="12" string="Michael" />
            <token id="13" string="Darby" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">Senate</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">action</governor>
          <dependent id="2">Senate</dependent>
        </dependency>
        <dependency type="case">
          <governor id="2">Senate</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="7">criticized</governor>
          <dependent id="4">action</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="7">criticized</governor>
          <dependent id="5">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">criticized</governor>
          <dependent id="6">sharply</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">criticized</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Undersecretary</governor>
          <dependent id="8">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">criticized</governor>
          <dependent id="9">Undersecretary</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Darby</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Darby</governor>
          <dependent id="11">Commerce</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Darby</governor>
          <dependent id="12">Michael</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">Undersecretary</governor>
          <dependent id="13">Darby</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">criticized</governor>
          <dependent id="15">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">voiced</governor>
          <dependent id="16">he</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">criticized</governor>
          <dependent id="17">voiced</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">voiced</governor>
          <dependent id="18">hope</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">reversed</governor>
          <dependent id="19">that</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="23">reversed</governor>
          <dependent id="20">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="23">reversed</governor>
          <dependent id="21">would</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="23">reversed</governor>
          <dependent id="22">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">voiced</governor>
          <dependent id="23">reversed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">conference</governor>
          <dependent id="24">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">conference</governor>
          <dependent id="25">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">conference</governor>
          <dependent id="26">Senate-House</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">reversed</governor>
          <dependent id="27">conference</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Senate" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="2" string="Senate" />
          </tokens>
        </entity>
        <entity id="2" string="Michael Darby" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Michael" />
            <token id="13" string="Darby" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>&amp;quot;There really is a widespread realization that this would not only be unconstitutional but literally impossible,&amp;quot; Darby said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="really" lemma="really" stem="realli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="widespread" lemma="widespread" stem="widespread" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="realization" lemma="realization" stem="realiz" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="unconstitutional" lemma="unconstitutional" stem="unconstitut" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="literally" lemma="literally" stem="liter" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="impossible" lemma="impossible" stem="imposs" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Darby" lemma="Darby" stem="darbi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="21" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (EX There)) (ADVP (RB really)) (VP (VBZ is) (NP (DT a) (JJ widespread) (NN realization)) (SBAR (IN that) (S (NP (DT this)) (VP (MD would) (RB not) (ADVP (RB only)) (VP (VB be) (ADJP (ADJP (JJ unconstitutional)) (CC but) (ADJP (ADVP (RB literally)) (JJ impossible))))))))) (, ,) ('' '') (NP (NNP Darby)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="be unconstitutional but literally impossible" type="VP">
          <tokens>
            <token id="13" string="be" />
            <token id="14" string="unconstitutional" />
            <token id="15" string="but" />
            <token id="16" string="literally" />
            <token id="17" string="impossible" />
          </tokens>
        </chunking>
        <chunking id="2" string="There" type="NP">
          <tokens>
            <token id="2" string="There" />
          </tokens>
        </chunking>
        <chunking id="3" string="that this would not only be unconstitutional but literally impossible" type="SBAR">
          <tokens>
            <token id="8" string="that" />
            <token id="9" string="this" />
            <token id="10" string="would" />
            <token id="11" string="not" />
            <token id="12" string="only" />
            <token id="13" string="be" />
            <token id="14" string="unconstitutional" />
            <token id="15" string="but" />
            <token id="16" string="literally" />
            <token id="17" string="impossible" />
          </tokens>
        </chunking>
        <chunking id="4" string="Darby" type="NP">
          <tokens>
            <token id="20" string="Darby" />
          </tokens>
        </chunking>
        <chunking id="5" string="unconstitutional but literally impossible" type="ADJP">
          <tokens>
            <token id="14" string="unconstitutional" />
            <token id="15" string="but" />
            <token id="16" string="literally" />
            <token id="17" string="impossible" />
          </tokens>
        </chunking>
        <chunking id="6" string="literally impossible" type="ADJP">
          <tokens>
            <token id="16" string="literally" />
            <token id="17" string="impossible" />
          </tokens>
        </chunking>
        <chunking id="7" string="this" type="NP">
          <tokens>
            <token id="9" string="this" />
          </tokens>
        </chunking>
        <chunking id="8" string="would not only be unconstitutional but literally impossible" type="VP">
          <tokens>
            <token id="10" string="would" />
            <token id="11" string="not" />
            <token id="12" string="only" />
            <token id="13" string="be" />
            <token id="14" string="unconstitutional" />
            <token id="15" string="but" />
            <token id="16" string="literally" />
            <token id="17" string="impossible" />
          </tokens>
        </chunking>
        <chunking id="9" string="a widespread realization" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="widespread" />
            <token id="7" string="realization" />
          </tokens>
        </chunking>
        <chunking id="10" string="said" type="VP">
          <tokens>
            <token id="21" string="said" />
          </tokens>
        </chunking>
        <chunking id="11" string="is a widespread realization that this would not only be unconstitutional but literally impossible" type="VP">
          <tokens>
            <token id="4" string="is" />
            <token id="5" string="a" />
            <token id="6" string="widespread" />
            <token id="7" string="realization" />
            <token id="8" string="that" />
            <token id="9" string="this" />
            <token id="10" string="would" />
            <token id="11" string="not" />
            <token id="12" string="only" />
            <token id="13" string="be" />
            <token id="14" string="unconstitutional" />
            <token id="15" string="but" />
            <token id="16" string="literally" />
            <token id="17" string="impossible" />
          </tokens>
        </chunking>
        <chunking id="12" string="unconstitutional" type="ADJP">
          <tokens>
            <token id="14" string="unconstitutional" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="4">is</governor>
          <dependent id="2">There</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">is</governor>
          <dependent id="3">really</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="21">said</governor>
          <dependent id="4">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">realization</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">realization</governor>
          <dependent id="6">widespread</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">is</governor>
          <dependent id="7">realization</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">unconstitutional</governor>
          <dependent id="8">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">unconstitutional</governor>
          <dependent id="9">this</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">unconstitutional</governor>
          <dependent id="10">would</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="14">unconstitutional</governor>
          <dependent id="11">not</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">unconstitutional</governor>
          <dependent id="12">only</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">unconstitutional</governor>
          <dependent id="13">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">is</governor>
          <dependent id="14">unconstitutional</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">unconstitutional</governor>
          <dependent id="15">but</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">impossible</governor>
          <dependent id="16">literally</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">unconstitutional</governor>
          <dependent id="17">impossible</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">said</governor>
          <dependent id="20">Darby</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="21">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Darby" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="Darby" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>But he added that he is &amp;quot;optimistic, cautiously optimistic,&amp;quot; that House conferees would resist the Senate-approved ban and not force Bush to veto the legislation.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="added" lemma="add" stem="ad" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="optimistic" lemma="optimistic" stem="optimist" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="cautiously" lemma="cautiously" stem="cautious" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="optimistic" lemma="optimistic" stem="optimist" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="House" lemma="House" stem="hous" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="16" string="conferees" lemma="conferee" stem="confere" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="resist" lemma="resist" stem="resist" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Senate-approved" lemma="senate-approved" stem="senate-approv" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="21" string="ban" lemma="ban" stem="ban" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="force" lemma="force" stem="forc" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="Bush" lemma="Bush" stem="bush" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="26" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="veto" lemma="veto" stem="veto" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="legislation" lemma="legislation" stem="legisl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (PRP he)) (VP (VBD added) (SBAR (IN that) (S (NP (PRP he)) (VP (VBZ is) (ADJP (`` ``) (JJ optimistic) (, ,) (RB cautiously) (JJ optimistic)) (, ,) ('' '') (SBAR (IN that) (S (NP (NNP House) (NNS conferees)) (VP (MD would) (VP (VP (VB resist) (NP (DT the) (JJ Senate-approved) (NN ban))) (CC and) (RB not) (VP (VB force) (S (NP (NNP Bush)) (VP (TO to) (VP (VB veto) (NP (DT the) (NN legislation)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="added that he is `` optimistic , cautiously optimistic , '' that House conferees would resist the Senate-approved ban and not force Bush to veto the legislation" type="VP">
          <tokens>
            <token id="3" string="added" />
            <token id="4" string="that" />
            <token id="5" string="he" />
            <token id="6" string="is" />
            <token id="7" string="&quot;" />
            <token id="8" string="optimistic" />
            <token id="9" string="," />
            <token id="10" string="cautiously" />
            <token id="11" string="optimistic" />
            <token id="12" string="," />
            <token id="13" string="&quot;" />
            <token id="14" string="that" />
            <token id="15" string="House" />
            <token id="16" string="conferees" />
            <token id="17" string="would" />
            <token id="18" string="resist" />
            <token id="19" string="the" />
            <token id="20" string="Senate-approved" />
            <token id="21" string="ban" />
            <token id="22" string="and" />
            <token id="23" string="not" />
            <token id="24" string="force" />
            <token id="25" string="Bush" />
            <token id="26" string="to" />
            <token id="27" string="veto" />
            <token id="28" string="the" />
            <token id="29" string="legislation" />
          </tokens>
        </chunking>
        <chunking id="2" string="veto the legislation" type="VP">
          <tokens>
            <token id="27" string="veto" />
            <token id="28" string="the" />
            <token id="29" string="legislation" />
          </tokens>
        </chunking>
        <chunking id="3" string="the Senate-approved ban" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="Senate-approved" />
            <token id="21" string="ban" />
          </tokens>
        </chunking>
        <chunking id="4" string="`` optimistic , cautiously optimistic" type="ADJP">
          <tokens>
            <token id="7" string="&quot;" />
            <token id="8" string="optimistic" />
            <token id="9" string="," />
            <token id="10" string="cautiously" />
            <token id="11" string="optimistic" />
          </tokens>
        </chunking>
        <chunking id="5" string="is `` optimistic , cautiously optimistic , '' that House conferees would resist the Senate-approved ban and not force Bush to veto the legislation" type="VP">
          <tokens>
            <token id="6" string="is" />
            <token id="7" string="&quot;" />
            <token id="8" string="optimistic" />
            <token id="9" string="," />
            <token id="10" string="cautiously" />
            <token id="11" string="optimistic" />
            <token id="12" string="," />
            <token id="13" string="&quot;" />
            <token id="14" string="that" />
            <token id="15" string="House" />
            <token id="16" string="conferees" />
            <token id="17" string="would" />
            <token id="18" string="resist" />
            <token id="19" string="the" />
            <token id="20" string="Senate-approved" />
            <token id="21" string="ban" />
            <token id="22" string="and" />
            <token id="23" string="not" />
            <token id="24" string="force" />
            <token id="25" string="Bush" />
            <token id="26" string="to" />
            <token id="27" string="veto" />
            <token id="28" string="the" />
            <token id="29" string="legislation" />
          </tokens>
        </chunking>
        <chunking id="6" string="would resist the Senate-approved ban and not force Bush to veto the legislation" type="VP">
          <tokens>
            <token id="17" string="would" />
            <token id="18" string="resist" />
            <token id="19" string="the" />
            <token id="20" string="Senate-approved" />
            <token id="21" string="ban" />
            <token id="22" string="and" />
            <token id="23" string="not" />
            <token id="24" string="force" />
            <token id="25" string="Bush" />
            <token id="26" string="to" />
            <token id="27" string="veto" />
            <token id="28" string="the" />
            <token id="29" string="legislation" />
          </tokens>
        </chunking>
        <chunking id="7" string="resist the Senate-approved ban and not force Bush to veto the legislation" type="VP">
          <tokens>
            <token id="18" string="resist" />
            <token id="19" string="the" />
            <token id="20" string="Senate-approved" />
            <token id="21" string="ban" />
            <token id="22" string="and" />
            <token id="23" string="not" />
            <token id="24" string="force" />
            <token id="25" string="Bush" />
            <token id="26" string="to" />
            <token id="27" string="veto" />
            <token id="28" string="the" />
            <token id="29" string="legislation" />
          </tokens>
        </chunking>
        <chunking id="8" string="to veto the legislation" type="VP">
          <tokens>
            <token id="26" string="to" />
            <token id="27" string="veto" />
            <token id="28" string="the" />
            <token id="29" string="legislation" />
          </tokens>
        </chunking>
        <chunking id="9" string="House conferees" type="NP">
          <tokens>
            <token id="15" string="House" />
            <token id="16" string="conferees" />
          </tokens>
        </chunking>
        <chunking id="10" string="Bush" type="NP">
          <tokens>
            <token id="25" string="Bush" />
          </tokens>
        </chunking>
        <chunking id="11" string="resist the Senate-approved ban" type="VP">
          <tokens>
            <token id="18" string="resist" />
            <token id="19" string="the" />
            <token id="20" string="Senate-approved" />
            <token id="21" string="ban" />
          </tokens>
        </chunking>
        <chunking id="12" string="that he is `` optimistic , cautiously optimistic , '' that House conferees would resist the Senate-approved ban and not force Bush to veto the legislation" type="SBAR">
          <tokens>
            <token id="4" string="that" />
            <token id="5" string="he" />
            <token id="6" string="is" />
            <token id="7" string="&quot;" />
            <token id="8" string="optimistic" />
            <token id="9" string="," />
            <token id="10" string="cautiously" />
            <token id="11" string="optimistic" />
            <token id="12" string="," />
            <token id="13" string="&quot;" />
            <token id="14" string="that" />
            <token id="15" string="House" />
            <token id="16" string="conferees" />
            <token id="17" string="would" />
            <token id="18" string="resist" />
            <token id="19" string="the" />
            <token id="20" string="Senate-approved" />
            <token id="21" string="ban" />
            <token id="22" string="and" />
            <token id="23" string="not" />
            <token id="24" string="force" />
            <token id="25" string="Bush" />
            <token id="26" string="to" />
            <token id="27" string="veto" />
            <token id="28" string="the" />
            <token id="29" string="legislation" />
          </tokens>
        </chunking>
        <chunking id="13" string="that House conferees would resist the Senate-approved ban and not force Bush to veto the legislation" type="SBAR">
          <tokens>
            <token id="14" string="that" />
            <token id="15" string="House" />
            <token id="16" string="conferees" />
            <token id="17" string="would" />
            <token id="18" string="resist" />
            <token id="19" string="the" />
            <token id="20" string="Senate-approved" />
            <token id="21" string="ban" />
            <token id="22" string="and" />
            <token id="23" string="not" />
            <token id="24" string="force" />
            <token id="25" string="Bush" />
            <token id="26" string="to" />
            <token id="27" string="veto" />
            <token id="28" string="the" />
            <token id="29" string="legislation" />
          </tokens>
        </chunking>
        <chunking id="14" string="the legislation" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="legislation" />
          </tokens>
        </chunking>
        <chunking id="15" string="he" type="NP">
          <tokens>
            <token id="2" string="he" />
          </tokens>
        </chunking>
        <chunking id="16" string="force Bush to veto the legislation" type="VP">
          <tokens>
            <token id="24" string="force" />
            <token id="25" string="Bush" />
            <token id="26" string="to" />
            <token id="27" string="veto" />
            <token id="28" string="the" />
            <token id="29" string="legislation" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="3">added</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">added</governor>
          <dependent id="2">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">added</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">optimistic</governor>
          <dependent id="4">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">optimistic</governor>
          <dependent id="5">he</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">optimistic</governor>
          <dependent id="6">is</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">optimistic</governor>
          <dependent id="8">optimistic</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">optimistic</governor>
          <dependent id="10">cautiously</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">added</governor>
          <dependent id="11">optimistic</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">resist</governor>
          <dependent id="14">that</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">conferees</governor>
          <dependent id="15">House</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">resist</governor>
          <dependent id="16">conferees</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">resist</governor>
          <dependent id="17">would</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">optimistic</governor>
          <dependent id="18">resist</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">ban</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">ban</governor>
          <dependent id="20">Senate-approved</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">resist</governor>
          <dependent id="21">ban</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="18">resist</governor>
          <dependent id="22">and</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="24">force</governor>
          <dependent id="23">not</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">resist</governor>
          <dependent id="24">force</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">force</governor>
          <dependent id="25">Bush</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="27">veto</governor>
          <dependent id="26">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="24">force</governor>
          <dependent id="27">veto</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">legislation</governor>
          <dependent id="28">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="27">veto</governor>
          <dependent id="29">legislation</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="House" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="15" string="House" />
          </tokens>
        </entity>
        <entity id="2" string="Bush" type="PERSON" score="0.0">
          <tokens>
            <token id="25" string="Bush" />
          </tokens>
        </entity>
        <entity id="3" string="Senate-approved" type="MISC" score="0.0">
          <tokens>
            <token id="20" string="Senate-approved" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>Mario Moreno, head of the Mexican American Legal Defense Fund, said he was shocked by the Senate&amp;apost;s decision.</content>
      <tokens>
        <token id="1" string="Mario" lemma="Mario" stem="mario" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Moreno" lemma="Moreno" stem="moreno" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="head" lemma="head" stem="head" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="Mexican" lemma="mexican" stem="mexican" pos="JJ" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="8" string="American" lemma="american" stem="american" pos="JJ" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="9" string="Legal" lemma="Legal" stem="legal" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="10" string="Defense" lemma="Defense" stem="defens" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="11" string="Fund" lemma="Fund" stem="fund" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="shocked" lemma="shock" stem="shock" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="Senate" lemma="Senate" stem="senat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="20" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="decision" lemma="decision" stem="decis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Mario) (NNP Moreno)) (, ,) (NP (NP (NP (NN head)) (PP (IN of) (NP (DT the) (JJ Mexican) (JJ American) (NNP Legal)))) (NP (NNP Defense) (NNP Fund))) (, ,)) (VP (VBD said) (SBAR (S (NP (PRP he)) (VP (VBD was) (VP (VBN shocked) (PP (IN by) (NP (NP (DT the) (NNP Senate) (POS 's)) (NN decision)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="said he was shocked by the Senate 's decision" type="VP">
          <tokens>
            <token id="13" string="said" />
            <token id="14" string="he" />
            <token id="15" string="was" />
            <token id="16" string="shocked" />
            <token id="17" string="by" />
            <token id="18" string="the" />
            <token id="19" string="Senate" />
            <token id="20" string="'s" />
            <token id="21" string="decision" />
          </tokens>
        </chunking>
        <chunking id="2" string="head of the Mexican American Legal Defense Fund" type="NP">
          <tokens>
            <token id="4" string="head" />
            <token id="5" string="of" />
            <token id="6" string="the" />
            <token id="7" string="Mexican" />
            <token id="8" string="American" />
            <token id="9" string="Legal" />
            <token id="10" string="Defense" />
            <token id="11" string="Fund" />
          </tokens>
        </chunking>
        <chunking id="3" string="shocked by the Senate 's decision" type="VP">
          <tokens>
            <token id="16" string="shocked" />
            <token id="17" string="by" />
            <token id="18" string="the" />
            <token id="19" string="Senate" />
            <token id="20" string="'s" />
            <token id="21" string="decision" />
          </tokens>
        </chunking>
        <chunking id="4" string="he was shocked by the Senate 's decision" type="SBAR">
          <tokens>
            <token id="14" string="he" />
            <token id="15" string="was" />
            <token id="16" string="shocked" />
            <token id="17" string="by" />
            <token id="18" string="the" />
            <token id="19" string="Senate" />
            <token id="20" string="'s" />
            <token id="21" string="decision" />
          </tokens>
        </chunking>
        <chunking id="5" string="Mario Moreno" type="NP">
          <tokens>
            <token id="1" string="Mario" />
            <token id="2" string="Moreno" />
          </tokens>
        </chunking>
        <chunking id="6" string="was shocked by the Senate 's decision" type="VP">
          <tokens>
            <token id="15" string="was" />
            <token id="16" string="shocked" />
            <token id="17" string="by" />
            <token id="18" string="the" />
            <token id="19" string="Senate" />
            <token id="20" string="'s" />
            <token id="21" string="decision" />
          </tokens>
        </chunking>
        <chunking id="7" string="head" type="NP">
          <tokens>
            <token id="4" string="head" />
          </tokens>
        </chunking>
        <chunking id="8" string="the Senate 's decision" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="Senate" />
            <token id="20" string="'s" />
            <token id="21" string="decision" />
          </tokens>
        </chunking>
        <chunking id="9" string="the Mexican American Legal" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="Mexican" />
            <token id="8" string="American" />
            <token id="9" string="Legal" />
          </tokens>
        </chunking>
        <chunking id="10" string="Mario Moreno , head of the Mexican American Legal Defense Fund ," type="NP">
          <tokens>
            <token id="1" string="Mario" />
            <token id="2" string="Moreno" />
            <token id="3" string="," />
            <token id="4" string="head" />
            <token id="5" string="of" />
            <token id="6" string="the" />
            <token id="7" string="Mexican" />
            <token id="8" string="American" />
            <token id="9" string="Legal" />
            <token id="10" string="Defense" />
            <token id="11" string="Fund" />
            <token id="12" string="," />
          </tokens>
        </chunking>
        <chunking id="11" string="the Senate 's" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="Senate" />
            <token id="20" string="'s" />
          </tokens>
        </chunking>
        <chunking id="12" string="head of the Mexican American Legal" type="NP">
          <tokens>
            <token id="4" string="head" />
            <token id="5" string="of" />
            <token id="6" string="the" />
            <token id="7" string="Mexican" />
            <token id="8" string="American" />
            <token id="9" string="Legal" />
          </tokens>
        </chunking>
        <chunking id="13" string="he" type="NP">
          <tokens>
            <token id="14" string="he" />
          </tokens>
        </chunking>
        <chunking id="14" string="Defense Fund" type="NP">
          <tokens>
            <token id="10" string="Defense" />
            <token id="11" string="Fund" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Moreno</governor>
          <dependent id="1">Mario</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">said</governor>
          <dependent id="2">Moreno</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">Moreno</governor>
          <dependent id="4">head</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Legal</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">Legal</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">Legal</governor>
          <dependent id="7">Mexican</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">Legal</governor>
          <dependent id="8">American</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">head</governor>
          <dependent id="9">Legal</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Fund</governor>
          <dependent id="10">Defense</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">head</governor>
          <dependent id="11">Fund</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">said</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="16">shocked</governor>
          <dependent id="14">he</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="16">shocked</governor>
          <dependent id="15">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">said</governor>
          <dependent id="16">shocked</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">decision</governor>
          <dependent id="17">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">Senate</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="21">decision</governor>
          <dependent id="19">Senate</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">Senate</governor>
          <dependent id="20">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">shocked</governor>
          <dependent id="21">decision</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Senate" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="19" string="Senate" />
          </tokens>
        </entity>
        <entity id="2" string="Mexican American Legal Defense Fund" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="7" string="Mexican" />
            <token id="8" string="American" />
            <token id="9" string="Legal" />
            <token id="10" string="Defense" />
            <token id="11" string="Fund" />
          </tokens>
        </entity>
        <entity id="3" string="Mario Moreno" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Mario" />
            <token id="2" string="Moreno" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>&amp;quot;It is going to have a dramatic and disastrous impact in the Hispanic community,&amp;quot; Moreno said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="dramatic" lemma="dramatic" stem="dramat" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="disastrous" lemma="disastrous" stem="disastr" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="impact" lemma="impact" stem="impact" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Hispanic" lemma="hispanic" stem="hispan" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="15" string="community" lemma="community" stem="commun" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Moreno" lemma="Moreno" stem="moreno" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="19" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP It)) (VP (VBZ is) (VP (VBG going) (S (VP (TO to) (VP (VB have) (NP (NP (DT a) (ADJP (JJ dramatic) (CC and) (JJ disastrous)) (NN impact)) (PP (IN in) (NP (DT the) (JJ Hispanic) (NN community)))))))))) (, ,) ('' '') (NP (NNP Moreno)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is going to have a dramatic and disastrous impact in the Hispanic community" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="going" />
            <token id="5" string="to" />
            <token id="6" string="have" />
            <token id="7" string="a" />
            <token id="8" string="dramatic" />
            <token id="9" string="and" />
            <token id="10" string="disastrous" />
            <token id="11" string="impact" />
            <token id="12" string="in" />
            <token id="13" string="the" />
            <token id="14" string="Hispanic" />
            <token id="15" string="community" />
          </tokens>
        </chunking>
        <chunking id="2" string="dramatic and disastrous" type="ADJP">
          <tokens>
            <token id="8" string="dramatic" />
            <token id="9" string="and" />
            <token id="10" string="disastrous" />
          </tokens>
        </chunking>
        <chunking id="3" string="Moreno" type="NP">
          <tokens>
            <token id="18" string="Moreno" />
          </tokens>
        </chunking>
        <chunking id="4" string="to have a dramatic and disastrous impact in the Hispanic community" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="have" />
            <token id="7" string="a" />
            <token id="8" string="dramatic" />
            <token id="9" string="and" />
            <token id="10" string="disastrous" />
            <token id="11" string="impact" />
            <token id="12" string="in" />
            <token id="13" string="the" />
            <token id="14" string="Hispanic" />
            <token id="15" string="community" />
          </tokens>
        </chunking>
        <chunking id="5" string="have a dramatic and disastrous impact in the Hispanic community" type="VP">
          <tokens>
            <token id="6" string="have" />
            <token id="7" string="a" />
            <token id="8" string="dramatic" />
            <token id="9" string="and" />
            <token id="10" string="disastrous" />
            <token id="11" string="impact" />
            <token id="12" string="in" />
            <token id="13" string="the" />
            <token id="14" string="Hispanic" />
            <token id="15" string="community" />
          </tokens>
        </chunking>
        <chunking id="6" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="7" string="going to have a dramatic and disastrous impact in the Hispanic community" type="VP">
          <tokens>
            <token id="4" string="going" />
            <token id="5" string="to" />
            <token id="6" string="have" />
            <token id="7" string="a" />
            <token id="8" string="dramatic" />
            <token id="9" string="and" />
            <token id="10" string="disastrous" />
            <token id="11" string="impact" />
            <token id="12" string="in" />
            <token id="13" string="the" />
            <token id="14" string="Hispanic" />
            <token id="15" string="community" />
          </tokens>
        </chunking>
        <chunking id="8" string="a dramatic and disastrous impact" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="dramatic" />
            <token id="9" string="and" />
            <token id="10" string="disastrous" />
            <token id="11" string="impact" />
          </tokens>
        </chunking>
        <chunking id="9" string="said" type="VP">
          <tokens>
            <token id="19" string="said" />
          </tokens>
        </chunking>
        <chunking id="10" string="the Hispanic community" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="Hispanic" />
            <token id="15" string="community" />
          </tokens>
        </chunking>
        <chunking id="11" string="a dramatic and disastrous impact in the Hispanic community" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="dramatic" />
            <token id="9" string="and" />
            <token id="10" string="disastrous" />
            <token id="11" string="impact" />
            <token id="12" string="in" />
            <token id="13" string="the" />
            <token id="14" string="Hispanic" />
            <token id="15" string="community" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">going</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">going</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">said</governor>
          <dependent id="4">going</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">have</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">going</governor>
          <dependent id="6">have</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">impact</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">impact</governor>
          <dependent id="8">dramatic</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">dramatic</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">dramatic</governor>
          <dependent id="10">disastrous</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">have</governor>
          <dependent id="11">impact</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">community</governor>
          <dependent id="12">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">community</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">community</governor>
          <dependent id="14">Hispanic</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">impact</governor>
          <dependent id="15">community</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">said</governor>
          <dependent id="18">Moreno</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="19">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Moreno" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Moreno" />
          </tokens>
        </entity>
        <entity id="2" string="Hispanic" type="MISC" score="0.0">
          <tokens>
            <token id="14" string="Hispanic" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>&amp;quot;People are going to be discouraged from participating.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="People" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="discouraged" lemma="discourage" stem="discourag" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="participating" lemma="participate" stem="particip" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (NNS People)) (VP (VBP are) (VP (VBG going) (S (VP (TO to) (VP (VB be) (VP (VBN discouraged) (PP (IN from) (S (VP (VBG participating)))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="discouraged from participating" type="VP">
          <tokens>
            <token id="7" string="discouraged" />
            <token id="8" string="from" />
            <token id="9" string="participating" />
          </tokens>
        </chunking>
        <chunking id="2" string="be discouraged from participating" type="VP">
          <tokens>
            <token id="6" string="be" />
            <token id="7" string="discouraged" />
            <token id="8" string="from" />
            <token id="9" string="participating" />
          </tokens>
        </chunking>
        <chunking id="3" string="are going to be discouraged from participating" type="VP">
          <tokens>
            <token id="3" string="are" />
            <token id="4" string="going" />
            <token id="5" string="to" />
            <token id="6" string="be" />
            <token id="7" string="discouraged" />
            <token id="8" string="from" />
            <token id="9" string="participating" />
          </tokens>
        </chunking>
        <chunking id="4" string="going to be discouraged from participating" type="VP">
          <tokens>
            <token id="4" string="going" />
            <token id="5" string="to" />
            <token id="6" string="be" />
            <token id="7" string="discouraged" />
            <token id="8" string="from" />
            <token id="9" string="participating" />
          </tokens>
        </chunking>
        <chunking id="5" string="People" type="NP">
          <tokens>
            <token id="2" string="People" />
          </tokens>
        </chunking>
        <chunking id="6" string="to be discouraged from participating" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="be" />
            <token id="7" string="discouraged" />
            <token id="8" string="from" />
            <token id="9" string="participating" />
          </tokens>
        </chunking>
        <chunking id="7" string="participating" type="VP">
          <tokens>
            <token id="9" string="participating" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">going</governor>
          <dependent id="2">People</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">going</governor>
          <dependent id="3">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">going</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">discouraged</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="7">discouraged</governor>
          <dependent id="6">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">going</governor>
          <dependent id="7">discouraged</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">participating</governor>
          <dependent id="8">from</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">discouraged</governor>
          <dependent id="9">participating</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="26" has_coreference="true">
      <content>A Census Bureau spokesman took a more dispassionate view, however.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Census" lemma="Census" stem="censu" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="3" string="Bureau" lemma="Bureau" stem="bureau" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="4" string="spokesman" lemma="spokesman" stem="spokesman" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="took" lemma="take" stem="took" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="dispassionate" lemma="dispassionate" stem="dispassion" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="view" lemma="view" stem="view" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="however" lemma="however" stem="howev" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT A) (NNP Census) (NNP Bureau) (NN spokesman)) (VP (VBD took) (NP (DT a) (ADJP (RBR more) (JJ dispassionate)) (NN view)) (, ,) (ADVP (RB however))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a more dispassionate view" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="more" />
            <token id="8" string="dispassionate" />
            <token id="9" string="view" />
          </tokens>
        </chunking>
        <chunking id="2" string="A Census Bureau spokesman" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="Census" />
            <token id="3" string="Bureau" />
            <token id="4" string="spokesman" />
          </tokens>
        </chunking>
        <chunking id="3" string="more dispassionate" type="ADJP">
          <tokens>
            <token id="7" string="more" />
            <token id="8" string="dispassionate" />
          </tokens>
        </chunking>
        <chunking id="4" string="took a more dispassionate view , however" type="VP">
          <tokens>
            <token id="5" string="took" />
            <token id="6" string="a" />
            <token id="7" string="more" />
            <token id="8" string="dispassionate" />
            <token id="9" string="view" />
            <token id="10" string="," />
            <token id="11" string="however" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">spokesman</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">spokesman</governor>
          <dependent id="2">Census</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">spokesman</governor>
          <dependent id="3">Bureau</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">took</governor>
          <dependent id="4">spokesman</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">took</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">view</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">dispassionate</governor>
          <dependent id="7">more</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">view</governor>
          <dependent id="8">dispassionate</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">took</governor>
          <dependent id="9">view</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">took</governor>
          <dependent id="11">however</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Census Bureau" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="2" string="Census" />
            <token id="3" string="Bureau" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>&amp;quot;Our position is that we count everybody at their place of residence,&amp;quot; said bureau spokesman James Gorman.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Our" lemma="we" stem="our" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="3" string="position" lemma="position" stem="posit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="count" lemma="count" stem="count" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="everybody" lemma="everybody" stem="everybodi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="place" lemma="place" stem="place" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="residence" lemma="residence" stem="resid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="bureau" lemma="bureau" stem="bureau" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="spokesman" lemma="spokesman" stem="spokesman" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="James" lemma="James" stem="jame" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="20" string="Gorman" lemma="Gorman" stem="gorman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (PRP$ Our) (NN position)) (VP (VBZ is) (SBAR (IN that) (S (NP (PRP we)) (VP (VBP count) (NP (NN everybody)) (PP (IN at) (NP (NP (PRP$ their) (NN place)) (PP (IN of) (NP (NN residence)))))))))) (, ,) ('' '') (VP (VBD said)) (NP (NN bureau) (NN spokesman) (NNP James) (NNP Gorman)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Our position" type="NP">
          <tokens>
            <token id="2" string="Our" />
            <token id="3" string="position" />
          </tokens>
        </chunking>
        <chunking id="2" string="their place" type="NP">
          <tokens>
            <token id="10" string="their" />
            <token id="11" string="place" />
          </tokens>
        </chunking>
        <chunking id="3" string="everybody" type="NP">
          <tokens>
            <token id="8" string="everybody" />
          </tokens>
        </chunking>
        <chunking id="4" string="count everybody at their place of residence" type="VP">
          <tokens>
            <token id="7" string="count" />
            <token id="8" string="everybody" />
            <token id="9" string="at" />
            <token id="10" string="their" />
            <token id="11" string="place" />
            <token id="12" string="of" />
            <token id="13" string="residence" />
          </tokens>
        </chunking>
        <chunking id="5" string="their place of residence" type="NP">
          <tokens>
            <token id="10" string="their" />
            <token id="11" string="place" />
            <token id="12" string="of" />
            <token id="13" string="residence" />
          </tokens>
        </chunking>
        <chunking id="6" string="is that we count everybody at their place of residence" type="VP">
          <tokens>
            <token id="4" string="is" />
            <token id="5" string="that" />
            <token id="6" string="we" />
            <token id="7" string="count" />
            <token id="8" string="everybody" />
            <token id="9" string="at" />
            <token id="10" string="their" />
            <token id="11" string="place" />
            <token id="12" string="of" />
            <token id="13" string="residence" />
          </tokens>
        </chunking>
        <chunking id="7" string="bureau spokesman James Gorman" type="NP">
          <tokens>
            <token id="17" string="bureau" />
            <token id="18" string="spokesman" />
            <token id="19" string="James" />
            <token id="20" string="Gorman" />
          </tokens>
        </chunking>
        <chunking id="8" string="that we count everybody at their place of residence" type="SBAR">
          <tokens>
            <token id="5" string="that" />
            <token id="6" string="we" />
            <token id="7" string="count" />
            <token id="8" string="everybody" />
            <token id="9" string="at" />
            <token id="10" string="their" />
            <token id="11" string="place" />
            <token id="12" string="of" />
            <token id="13" string="residence" />
          </tokens>
        </chunking>
        <chunking id="9" string="we" type="NP">
          <tokens>
            <token id="6" string="we" />
          </tokens>
        </chunking>
        <chunking id="10" string="said" type="VP">
          <tokens>
            <token id="16" string="said" />
          </tokens>
        </chunking>
        <chunking id="11" string="residence" type="NP">
          <tokens>
            <token id="13" string="residence" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="3">position</governor>
          <dependent id="2">Our</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">is</governor>
          <dependent id="3">position</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">said</governor>
          <dependent id="4">is</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">count</governor>
          <dependent id="5">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">count</governor>
          <dependent id="6">we</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">is</governor>
          <dependent id="7">count</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">count</governor>
          <dependent id="8">everybody</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">place</governor>
          <dependent id="9">at</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">place</governor>
          <dependent id="10">their</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">count</governor>
          <dependent id="11">place</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">residence</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">place</governor>
          <dependent id="13">residence</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Gorman</governor>
          <dependent id="17">bureau</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Gorman</governor>
          <dependent id="18">spokesman</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Gorman</governor>
          <dependent id="19">James</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">said</governor>
          <dependent id="20">Gorman</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="James Gorman" type="PERSON" score="0.0">
          <tokens>
            <token id="19" string="James" />
            <token id="20" string="Gorman" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="28" has_coreference="true">
      <content>&amp;quot;If Congress passes a law that says we will or will not count people, we will do what it says.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="If" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Congress" lemma="Congress" stem="congress" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="4" string="passes" lemma="pass" stem="pass" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="law" lemma="law" stem="law" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="count" lemma="count" stem="count" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="do" lemma="do" stem="do" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (SBAR (IN If) (S (NP (NNP Congress)) (VP (VBZ passes) (NP (NP (DT a) (NN law)) (SBAR (WHNP (WDT that)) (S (VP (VBZ says) (SBAR (S (NP (PRP we)) (VP (MD will) (CC or) (MD will) (RB not) (VP (VB count) (NP (NNS people))))))))))))) (, ,) (NP (PRP we)) (VP (MD will) (VP (VB do) (SBAR (WHNP (WP what)) (S (NP (PRP it)) (VP (VBZ says)))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="If Congress passes a law that says we will or will not count people" type="SBAR">
          <tokens>
            <token id="2" string="If" />
            <token id="3" string="Congress" />
            <token id="4" string="passes" />
            <token id="5" string="a" />
            <token id="6" string="law" />
            <token id="7" string="that" />
            <token id="8" string="says" />
            <token id="9" string="we" />
            <token id="10" string="will" />
            <token id="11" string="or" />
            <token id="12" string="will" />
            <token id="13" string="not" />
            <token id="14" string="count" />
            <token id="15" string="people" />
          </tokens>
        </chunking>
        <chunking id="2" string="we will or will not count people" type="SBAR">
          <tokens>
            <token id="9" string="we" />
            <token id="10" string="will" />
            <token id="11" string="or" />
            <token id="12" string="will" />
            <token id="13" string="not" />
            <token id="14" string="count" />
            <token id="15" string="people" />
          </tokens>
        </chunking>
        <chunking id="3" string="a law" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="law" />
          </tokens>
        </chunking>
        <chunking id="4" string="do what it says" type="VP">
          <tokens>
            <token id="19" string="do" />
            <token id="20" string="what" />
            <token id="21" string="it" />
            <token id="22" string="says" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="21" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="will or will not count people" type="VP">
          <tokens>
            <token id="10" string="will" />
            <token id="11" string="or" />
            <token id="12" string="will" />
            <token id="13" string="not" />
            <token id="14" string="count" />
            <token id="15" string="people" />
          </tokens>
        </chunking>
        <chunking id="7" string="people" type="NP">
          <tokens>
            <token id="15" string="people" />
          </tokens>
        </chunking>
        <chunking id="8" string="we" type="NP">
          <tokens>
            <token id="9" string="we" />
          </tokens>
        </chunking>
        <chunking id="9" string="Congress" type="NP">
          <tokens>
            <token id="3" string="Congress" />
          </tokens>
        </chunking>
        <chunking id="10" string="what it says" type="SBAR">
          <tokens>
            <token id="20" string="what" />
            <token id="21" string="it" />
            <token id="22" string="says" />
          </tokens>
        </chunking>
        <chunking id="11" string="says" type="VP">
          <tokens>
            <token id="22" string="says" />
          </tokens>
        </chunking>
        <chunking id="12" string="that says we will or will not count people" type="SBAR">
          <tokens>
            <token id="7" string="that" />
            <token id="8" string="says" />
            <token id="9" string="we" />
            <token id="10" string="will" />
            <token id="11" string="or" />
            <token id="12" string="will" />
            <token id="13" string="not" />
            <token id="14" string="count" />
            <token id="15" string="people" />
          </tokens>
        </chunking>
        <chunking id="13" string="says we will or will not count people" type="VP">
          <tokens>
            <token id="8" string="says" />
            <token id="9" string="we" />
            <token id="10" string="will" />
            <token id="11" string="or" />
            <token id="12" string="will" />
            <token id="13" string="not" />
            <token id="14" string="count" />
            <token id="15" string="people" />
          </tokens>
        </chunking>
        <chunking id="14" string="a law that says we will or will not count people" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="law" />
            <token id="7" string="that" />
            <token id="8" string="says" />
            <token id="9" string="we" />
            <token id="10" string="will" />
            <token id="11" string="or" />
            <token id="12" string="will" />
            <token id="13" string="not" />
            <token id="14" string="count" />
            <token id="15" string="people" />
          </tokens>
        </chunking>
        <chunking id="15" string="will do what it says" type="VP">
          <tokens>
            <token id="18" string="will" />
            <token id="19" string="do" />
            <token id="20" string="what" />
            <token id="21" string="it" />
            <token id="22" string="says" />
          </tokens>
        </chunking>
        <chunking id="16" string="count people" type="VP">
          <tokens>
            <token id="14" string="count" />
            <token id="15" string="people" />
          </tokens>
        </chunking>
        <chunking id="17" string="passes a law that says we will or will not count people" type="VP">
          <tokens>
            <token id="4" string="passes" />
            <token id="5" string="a" />
            <token id="6" string="law" />
            <token id="7" string="that" />
            <token id="8" string="says" />
            <token id="9" string="we" />
            <token id="10" string="will" />
            <token id="11" string="or" />
            <token id="12" string="will" />
            <token id="13" string="not" />
            <token id="14" string="count" />
            <token id="15" string="people" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="4">passes</governor>
          <dependent id="2">If</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">passes</governor>
          <dependent id="3">Congress</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="19">do</governor>
          <dependent id="4">passes</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">law</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">passes</governor>
          <dependent id="6">law</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">says</governor>
          <dependent id="7">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="6">law</governor>
          <dependent id="8">says</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">count</governor>
          <dependent id="9">we</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">count</governor>
          <dependent id="10">will</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">count</governor>
          <dependent id="11">or</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">count</governor>
          <dependent id="12">will</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="14">count</governor>
          <dependent id="13">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">says</governor>
          <dependent id="14">count</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">count</governor>
          <dependent id="15">people</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">do</governor>
          <dependent id="17">we</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="19">do</governor>
          <dependent id="18">will</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="19">do</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">says</governor>
          <dependent id="20">what</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">says</governor>
          <dependent id="21">it</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">do</governor>
          <dependent id="22">says</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Congress" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="3" string="Congress" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="2" type="PROPER">
      <referenced ids_tokens="14-15" string="the Senate" id_sentence="1" />
      <mentions>
        <mention ids_tokens="9" string="Senate" id_sentence="8" />
        <mention ids_tokens="1-3" string="The Senate's" id_sentence="20" />
        <mention ids_tokens="18-20" string="the Senate's" id_sentence="23" />
      </mentions>
    </coreference>
    <coreference id="3" type="PROPER">
      <referenced ids_tokens="20-21-22" string="the Census Bureau" id_sentence="1" />
      <mentions>
        <mention ids_tokens="2-3" string="Census Bureau" id_sentence="26" />
      </mentions>
    </coreference>
    <coreference id="4" type="NOMINAL">
      <referenced ids_tokens="25-26" string="illegal aliens" id_sentence="1" />
      <mentions>
        <mention ids_tokens="7" string="aliens" id_sentence="13" />
      </mentions>
    </coreference>
    <coreference id="5" type="NOMINAL">
      <referenced ids_tokens="28-29-30-31" string="the 1990 population count" id_sentence="1" />
      <mentions>
        <mention ids_tokens="23-24" string="the count" id_sentence="3" />
      </mentions>
    </coreference>
    <coreference id="6" type="PROPER">
      <referenced ids_tokens="19-20" string="President Bush" id_sentence="5" />
      <mentions>
        <mention ids_tokens="13" string="Bush" id_sentence="2" />
        <mention ids_tokens="25" string="Bush" id_sentence="22" />
      </mentions>
    </coreference>
    <coreference id="8" type="NOMINAL">
      <referenced ids_tokens="5-6-7" string="a voice vote" id_sentence="2" />
      <mentions>
        <mention ids_tokens="3-5" string="the voice vote" id_sentence="3" />
      </mentions>
    </coreference>
    <coreference id="9" type="NOMINAL">
      <referenced ids_tokens="8-9-10-11-12-13-14-15-16-17" string="the prohibition against including illegal immigrants in the census totals" id_sentence="4" />
      <mentions>
        <mention ids_tokens="3-4" string="the prohibition" id_sentence="5" />
      </mentions>
    </coreference>
    <coreference id="11" type="PROPER">
      <referenced ids_tokens="9" string="Congress" id_sentence="6" />
      <mentions>
        <mention ids_tokens="21" string="it" id_sentence="28" />
      </mentions>
    </coreference>
    <coreference id="12" type="LIST">
      <referenced ids_tokens="16-17-18-19" string="California and New York" id_sentence="12" />
      <mentions>
        <mention ids_tokens="11-23" string="California , Florida , New York , Illinois , Pennsylvania and other states" id_sentence="6" />
      </mentions>
    </coreference>
    <coreference id="13" type="NOMINAL">
      <referenced ids_tokens="23-24" string="those states" id_sentence="16" />
      <mentions>
        <mention ids_tokens="4" string="states" id_sentence="7" />
      </mentions>
    </coreference>
    <coreference id="14" type="PROPER">
      <referenced ids_tokens="12-13-14-15-16-17-18-19" string="Minority Leader Bob Dole ( R-Kan . )" id_sentence="8" />
      <mentions>
        <mention ids_tokens="18" string="Dole" id_sentence="10" />
      </mentions>
    </coreference>
    <coreference id="15" type="PROPER">
      <referenced ids_tokens="4-5" string="White House" id_sentence="9" />
      <mentions>
        <mention ids_tokens="8" string="House" id_sentence="12" />
        <mention ids_tokens="15" string="House" id_sentence="22" />
      </mentions>
    </coreference>
    <coreference id="16" type="NOMINAL">
      <referenced ids_tokens="3-4-5-6" string="the White House position" id_sentence="9" />
      <mentions>
        <mention ids_tokens="2-3" string="Our position" id_sentence="27" />
      </mentions>
    </coreference>
    <coreference id="17" type="PROPER">
      <referenced ids_tokens="1-2-3-4-5-6-7" string="Sen. Thad Cochran ( R-Miss . )" id_sentence="11" />
      <mentions>
        <mention ids_tokens="17" string="Cochran" id_sentence="13" />
      </mentions>
    </coreference>
    <coreference id="19" type="PROPER">
      <referenced ids_tokens="1-2-3-4-5-6-7" string="Sen. Pete Wilson ( R-Calif . )" id_sentence="14" />
      <mentions>
        <mention ids_tokens="18" string="Wilson" id_sentence="16" />
      </mentions>
    </coreference>
    <coreference id="20" type="PROPER">
      <referenced ids_tokens="6-7-8-9-10-11-12" string="Sen. Daniel Patrick Moynihan ( D-N.Y. )" id_sentence="18" />
      <mentions>
        <mention ids_tokens="16" string="he" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="21" type="PROPER">
      <referenced ids_tokens="12-13" string="Michael Darby" id_sentence="20" />
      <mentions>
        <mention ids_tokens="20" string="Darby" id_sentence="21" />
        <mention ids_tokens="2" string="he" id_sentence="22" />
        <mention ids_tokens="5" string="he" id_sentence="22" />
      </mentions>
    </coreference>
    <coreference id="24" type="PROPER">
      <referenced ids_tokens="1-2" string="Mario Moreno" id_sentence="23" />
      <mentions>
        <mention ids_tokens="18" string="Moreno" id_sentence="24" />
      </mentions>
    </coreference>
    <coreference id="25" type="PROPER">
      <referenced ids_tokens="6-7-8-9" string="the Mexican American Legal" id_sentence="23" />
      <mentions>
        <mention ids_tokens="2" string="It" id_sentence="24" />
      </mentions>
    </coreference>
    <coreference id="26" type="NOMINAL">
      <referenced ids_tokens="2" string="People" id_sentence="25" />
      <mentions>
        <mention ids_tokens="10" string="their" id_sentence="27" />
      </mentions>
    </coreference>
    <coreference id="27" type="PRONOMINAL">
      <referenced ids_tokens="2" string="Our" id_sentence="27" />
      <mentions>
        <mention ids_tokens="9" string="we" id_sentence="28" />
        <mention ids_tokens="17" string="we" id_sentence="28" />
      </mentions>
    </coreference>
  </coreferences>
</document>
