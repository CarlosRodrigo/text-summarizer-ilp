<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="LA101090-0017">
  <sentences>
    <sentence id="1" has_coreference="false">
      <content>There is a recurring temptation in American politics to wreak vengeance on one&amp;apost;s adversaries by overhauling the political institutions that they dominate.</content>
      <tokens>
        <token id="1" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="recurring" lemma="recur" stem="recur" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="temptation" lemma="temptation" stem="temptat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="American" lemma="american" stem="american" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="8" string="politics" lemma="politics" stem="polit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="wreak" lemma="wreak" stem="wreak" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="vengeance" lemma="vengeance" stem="vengeanc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="14" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="adversaries" lemma="adversary" stem="adversari" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="overhauling" lemma="overhaul" stem="overhaul" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="political" lemma="political" stem="polit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="institutions" lemma="institution" stem="institut" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="dominate" lemma="dominate" stem="domin" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (EX There)) (VP (VBZ is) (NP (NP (DT a) (VBG recurring) (NN temptation)) (PP (IN in) (NP (JJ American) (NNS politics))) (S (VP (TO to) (VP (VB wreak) (NP (NP (NN vengeance)) (PP (IN on) (NP (NP (CD one) (POS 's)) (NNS adversaries)))) (PP (IN by) (S (VP (VBG overhauling) (NP (DT the) (JJ political) (NNS institutions)) (SBAR (IN that) (S (NP (PRP they)) (VP (VBP dominate)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="one 's" type="NP">
          <tokens>
            <token id="13" string="one" />
            <token id="14" string="'s" />
          </tokens>
        </chunking>
        <chunking id="2" string="vengeance" type="NP">
          <tokens>
            <token id="11" string="vengeance" />
          </tokens>
        </chunking>
        <chunking id="3" string="one 's adversaries" type="NP">
          <tokens>
            <token id="13" string="one" />
            <token id="14" string="'s" />
            <token id="15" string="adversaries" />
          </tokens>
        </chunking>
        <chunking id="4" string="a recurring temptation in American politics to wreak vengeance on one 's adversaries by overhauling the political institutions that they dominate" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="recurring" />
            <token id="5" string="temptation" />
            <token id="6" string="in" />
            <token id="7" string="American" />
            <token id="8" string="politics" />
            <token id="9" string="to" />
            <token id="10" string="wreak" />
            <token id="11" string="vengeance" />
            <token id="12" string="on" />
            <token id="13" string="one" />
            <token id="14" string="'s" />
            <token id="15" string="adversaries" />
            <token id="16" string="by" />
            <token id="17" string="overhauling" />
            <token id="18" string="the" />
            <token id="19" string="political" />
            <token id="20" string="institutions" />
            <token id="21" string="that" />
            <token id="22" string="they" />
            <token id="23" string="dominate" />
          </tokens>
        </chunking>
        <chunking id="5" string="American politics" type="NP">
          <tokens>
            <token id="7" string="American" />
            <token id="8" string="politics" />
          </tokens>
        </chunking>
        <chunking id="6" string="to wreak vengeance on one 's adversaries by overhauling the political institutions that they dominate" type="VP">
          <tokens>
            <token id="9" string="to" />
            <token id="10" string="wreak" />
            <token id="11" string="vengeance" />
            <token id="12" string="on" />
            <token id="13" string="one" />
            <token id="14" string="'s" />
            <token id="15" string="adversaries" />
            <token id="16" string="by" />
            <token id="17" string="overhauling" />
            <token id="18" string="the" />
            <token id="19" string="political" />
            <token id="20" string="institutions" />
            <token id="21" string="that" />
            <token id="22" string="they" />
            <token id="23" string="dominate" />
          </tokens>
        </chunking>
        <chunking id="7" string="dominate" type="VP">
          <tokens>
            <token id="23" string="dominate" />
          </tokens>
        </chunking>
        <chunking id="8" string="they" type="NP">
          <tokens>
            <token id="22" string="they" />
          </tokens>
        </chunking>
        <chunking id="9" string="vengeance on one 's adversaries" type="NP">
          <tokens>
            <token id="11" string="vengeance" />
            <token id="12" string="on" />
            <token id="13" string="one" />
            <token id="14" string="'s" />
            <token id="15" string="adversaries" />
          </tokens>
        </chunking>
        <chunking id="10" string="There" type="NP">
          <tokens>
            <token id="1" string="There" />
          </tokens>
        </chunking>
        <chunking id="11" string="is a recurring temptation in American politics to wreak vengeance on one 's adversaries by overhauling the political institutions that they dominate" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="a" />
            <token id="4" string="recurring" />
            <token id="5" string="temptation" />
            <token id="6" string="in" />
            <token id="7" string="American" />
            <token id="8" string="politics" />
            <token id="9" string="to" />
            <token id="10" string="wreak" />
            <token id="11" string="vengeance" />
            <token id="12" string="on" />
            <token id="13" string="one" />
            <token id="14" string="'s" />
            <token id="15" string="adversaries" />
            <token id="16" string="by" />
            <token id="17" string="overhauling" />
            <token id="18" string="the" />
            <token id="19" string="political" />
            <token id="20" string="institutions" />
            <token id="21" string="that" />
            <token id="22" string="they" />
            <token id="23" string="dominate" />
          </tokens>
        </chunking>
        <chunking id="12" string="a recurring temptation" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="recurring" />
            <token id="5" string="temptation" />
          </tokens>
        </chunking>
        <chunking id="13" string="the political institutions" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="political" />
            <token id="20" string="institutions" />
          </tokens>
        </chunking>
        <chunking id="14" string="that they dominate" type="SBAR">
          <tokens>
            <token id="21" string="that" />
            <token id="22" string="they" />
            <token id="23" string="dominate" />
          </tokens>
        </chunking>
        <chunking id="15" string="wreak vengeance on one 's adversaries by overhauling the political institutions that they dominate" type="VP">
          <tokens>
            <token id="10" string="wreak" />
            <token id="11" string="vengeance" />
            <token id="12" string="on" />
            <token id="13" string="one" />
            <token id="14" string="'s" />
            <token id="15" string="adversaries" />
            <token id="16" string="by" />
            <token id="17" string="overhauling" />
            <token id="18" string="the" />
            <token id="19" string="political" />
            <token id="20" string="institutions" />
            <token id="21" string="that" />
            <token id="22" string="they" />
            <token id="23" string="dominate" />
          </tokens>
        </chunking>
        <chunking id="16" string="overhauling the political institutions that they dominate" type="VP">
          <tokens>
            <token id="17" string="overhauling" />
            <token id="18" string="the" />
            <token id="19" string="political" />
            <token id="20" string="institutions" />
            <token id="21" string="that" />
            <token id="22" string="they" />
            <token id="23" string="dominate" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="2">is</governor>
          <dependent id="1">There</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">temptation</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">temptation</governor>
          <dependent id="4">recurring</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="2">is</governor>
          <dependent id="5">temptation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">politics</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">politics</governor>
          <dependent id="7">American</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">temptation</governor>
          <dependent id="8">politics</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">wreak</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="5">temptation</governor>
          <dependent id="10">wreak</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">wreak</governor>
          <dependent id="11">vengeance</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">adversaries</governor>
          <dependent id="12">on</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">adversaries</governor>
          <dependent id="13">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">one</governor>
          <dependent id="14">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">vengeance</governor>
          <dependent id="15">adversaries</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">overhauling</governor>
          <dependent id="16">by</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="10">wreak</governor>
          <dependent id="17">overhauling</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">institutions</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">institutions</governor>
          <dependent id="19">political</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">overhauling</governor>
          <dependent id="20">institutions</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">dominate</governor>
          <dependent id="21">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">dominate</governor>
          <dependent id="22">they</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">overhauling</governor>
          <dependent id="23">dominate</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="13" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="American" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="7" string="American" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>What usually results from this ill-considered radical surgery is that the very people who scheduled the operations end up in the recovery room.</content>
      <tokens>
        <token id="1" string="What" lemma="what" stem="what" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="usually" lemma="usually" stem="usual" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="results" lemma="result" stem="result" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="ill-considered" lemma="ill-considered" stem="ill-consid" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="radical" lemma="radical" stem="radic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="surgery" lemma="surgery" stem="surgeri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="very" lemma="very" stem="veri" pos="JJ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="scheduled" lemma="schedule" stem="schedul" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="operations" lemma="operation" stem="oper" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="end" lemma="end" stem="end" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="recovery" lemma="recovery" stem="recoveri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="room" lemma="room" stem="room" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (SBAR (WHNP (WDT What)) (S (ADVP (RB usually)) (VP (VBZ results) (PP (IN from) (NP (DT this) (JJ ill-considered) (NN radical) (NN surgery))))))) (VP (VBZ is) (SBAR (IN that) (S (NP (NP (DT the) (JJ very) (NNS people)) (SBAR (WHNP (WP who)) (S (VP (VBD scheduled) (NP (DT the) (NNS operations)))))) (VP (VBP end) (PRT (RP up)) (PP (IN in) (NP (DT the) (NN recovery) (NN room))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="What usually results from this ill-considered radical surgery" type="NP">
          <tokens>
            <token id="1" string="What" />
            <token id="2" string="usually" />
            <token id="3" string="results" />
            <token id="4" string="from" />
            <token id="5" string="this" />
            <token id="6" string="ill-considered" />
            <token id="7" string="radical" />
            <token id="8" string="surgery" />
          </tokens>
        </chunking>
        <chunking id="2" string="this ill-considered radical surgery" type="NP">
          <tokens>
            <token id="5" string="this" />
            <token id="6" string="ill-considered" />
            <token id="7" string="radical" />
            <token id="8" string="surgery" />
          </tokens>
        </chunking>
        <chunking id="3" string="that the very people who scheduled the operations end up in the recovery room" type="SBAR">
          <tokens>
            <token id="10" string="that" />
            <token id="11" string="the" />
            <token id="12" string="very" />
            <token id="13" string="people" />
            <token id="14" string="who" />
            <token id="15" string="scheduled" />
            <token id="16" string="the" />
            <token id="17" string="operations" />
            <token id="18" string="end" />
            <token id="19" string="up" />
            <token id="20" string="in" />
            <token id="21" string="the" />
            <token id="22" string="recovery" />
            <token id="23" string="room" />
          </tokens>
        </chunking>
        <chunking id="4" string="the very people" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="very" />
            <token id="13" string="people" />
          </tokens>
        </chunking>
        <chunking id="5" string="is that the very people who scheduled the operations end up in the recovery room" type="VP">
          <tokens>
            <token id="9" string="is" />
            <token id="10" string="that" />
            <token id="11" string="the" />
            <token id="12" string="very" />
            <token id="13" string="people" />
            <token id="14" string="who" />
            <token id="15" string="scheduled" />
            <token id="16" string="the" />
            <token id="17" string="operations" />
            <token id="18" string="end" />
            <token id="19" string="up" />
            <token id="20" string="in" />
            <token id="21" string="the" />
            <token id="22" string="recovery" />
            <token id="23" string="room" />
          </tokens>
        </chunking>
        <chunking id="6" string="the very people who scheduled the operations" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="very" />
            <token id="13" string="people" />
            <token id="14" string="who" />
            <token id="15" string="scheduled" />
            <token id="16" string="the" />
            <token id="17" string="operations" />
          </tokens>
        </chunking>
        <chunking id="7" string="the operations" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="operations" />
          </tokens>
        </chunking>
        <chunking id="8" string="results from this ill-considered radical surgery" type="VP">
          <tokens>
            <token id="3" string="results" />
            <token id="4" string="from" />
            <token id="5" string="this" />
            <token id="6" string="ill-considered" />
            <token id="7" string="radical" />
            <token id="8" string="surgery" />
          </tokens>
        </chunking>
        <chunking id="9" string="the recovery room" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="recovery" />
            <token id="23" string="room" />
          </tokens>
        </chunking>
        <chunking id="10" string="who scheduled the operations" type="SBAR">
          <tokens>
            <token id="14" string="who" />
            <token id="15" string="scheduled" />
            <token id="16" string="the" />
            <token id="17" string="operations" />
          </tokens>
        </chunking>
        <chunking id="11" string="scheduled the operations" type="VP">
          <tokens>
            <token id="15" string="scheduled" />
            <token id="16" string="the" />
            <token id="17" string="operations" />
          </tokens>
        </chunking>
        <chunking id="12" string="end up in the recovery room" type="VP">
          <tokens>
            <token id="18" string="end" />
            <token id="19" string="up" />
            <token id="20" string="in" />
            <token id="21" string="the" />
            <token id="22" string="recovery" />
            <token id="23" string="room" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">results</governor>
          <dependent id="1">What</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">results</governor>
          <dependent id="2">usually</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">is</governor>
          <dependent id="3">results</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">surgery</governor>
          <dependent id="4">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">surgery</governor>
          <dependent id="5">this</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">surgery</governor>
          <dependent id="6">ill-considered</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">surgery</governor>
          <dependent id="7">radical</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">results</governor>
          <dependent id="8">surgery</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">is</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">end</governor>
          <dependent id="10">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">people</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">people</governor>
          <dependent id="12">very</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">end</governor>
          <dependent id="13">people</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">scheduled</governor>
          <dependent id="14">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="13">people</governor>
          <dependent id="15">scheduled</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">operations</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">scheduled</governor>
          <dependent id="17">operations</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">is</governor>
          <dependent id="18">end</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="18">end</governor>
          <dependent id="19">up</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">room</governor>
          <dependent id="20">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">room</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">room</governor>
          <dependent id="22">recovery</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">end</governor>
          <dependent id="23">room</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>Franklin D. Roosevelt&amp;apost;s plan to expand the Supreme Court in 1937 to dilute the votes of conservatives resulted in the creation of an opposing political coalition that lived on after the controversy to plague every subsequent Democratic President.</content>
      <tokens>
        <token id="1" string="Franklin" lemma="Franklin" stem="franklin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="2" string="D." lemma="D." stem="d." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="3" string="Roosevelt" lemma="Roosevelt" stem="roosevelt" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="4" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="plan" lemma="plan" stem="plan" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="expand" lemma="expand" stem="expand" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Supreme" lemma="Supreme" stem="suprem" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="10" string="Court" lemma="Court" stem="court" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="1937" lemma="1937" stem="1937" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="dilute" lemma="dilute" stem="dilut" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="votes" lemma="vote" stem="vote" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="conservatives" lemma="conservative" stem="conserv" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="resulted" lemma="result" stem="result" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="creation" lemma="creation" stem="creation" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="opposing" lemma="oppose" stem="oppos" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="political" lemma="political" stem="polit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="coalition" lemma="coalition" stem="coalit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="lived" lemma="live" stem="live" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="controversy" lemma="controversy" stem="controversi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="plague" lemma="plague" stem="plagu" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="every" lemma="every" stem="everi" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="subsequent" lemma="subsequent" stem="subsequ" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="Democratic" lemma="democratic" stem="democrat" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="39" string="President" lemma="President" stem="presid" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="false" is_refers="false" />
        <token id="40" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Franklin) (NNP D.) (NNP Roosevelt) (POS 's)) (NN plan) (S (VP (TO to) (VP (VB expand) (NP (NP (DT the) (NNP Supreme) (NNP Court)) (PP (IN in) (NP (CD 1937)))) (S (VP (TO to) (VP (VB dilute) (NP (NP (DT the) (NNS votes)) (PP (IN of) (NP (NNS conservatives))))))))))) (VP (VBD resulted) (PP (IN in) (NP (NP (DT the) (NN creation)) (PP (IN of) (NP (NP (DT an) (VBG opposing) (JJ political) (NN coalition)) (SBAR (WHNP (WDT that)) (S (VP (VBD lived) (PP (IN on) (IN after) (NP (DT the) (NN controversy) (S (VP (TO to) (VP (VB plague) (NP (DT every) (ADJP (JJ subsequent) (JJ Democratic)) (NNP President))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the Supreme Court in 1937" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="Supreme" />
            <token id="10" string="Court" />
            <token id="11" string="in" />
            <token id="12" string="1937" />
          </tokens>
        </chunking>
        <chunking id="2" string="that lived on after the controversy to plague every subsequent Democratic President" type="SBAR">
          <tokens>
            <token id="28" string="that" />
            <token id="29" string="lived" />
            <token id="30" string="on" />
            <token id="31" string="after" />
            <token id="32" string="the" />
            <token id="33" string="controversy" />
            <token id="34" string="to" />
            <token id="35" string="plague" />
            <token id="36" string="every" />
            <token id="37" string="subsequent" />
            <token id="38" string="Democratic" />
            <token id="39" string="President" />
          </tokens>
        </chunking>
        <chunking id="3" string="dilute the votes of conservatives" type="VP">
          <tokens>
            <token id="14" string="dilute" />
            <token id="15" string="the" />
            <token id="16" string="votes" />
            <token id="17" string="of" />
            <token id="18" string="conservatives" />
          </tokens>
        </chunking>
        <chunking id="4" string="the votes of conservatives" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="votes" />
            <token id="17" string="of" />
            <token id="18" string="conservatives" />
          </tokens>
        </chunking>
        <chunking id="5" string="expand the Supreme Court in 1937 to dilute the votes of conservatives" type="VP">
          <tokens>
            <token id="7" string="expand" />
            <token id="8" string="the" />
            <token id="9" string="Supreme" />
            <token id="10" string="Court" />
            <token id="11" string="in" />
            <token id="12" string="1937" />
            <token id="13" string="to" />
            <token id="14" string="dilute" />
            <token id="15" string="the" />
            <token id="16" string="votes" />
            <token id="17" string="of" />
            <token id="18" string="conservatives" />
          </tokens>
        </chunking>
        <chunking id="6" string="an opposing political coalition that lived on after the controversy to plague every subsequent Democratic President" type="NP">
          <tokens>
            <token id="24" string="an" />
            <token id="25" string="opposing" />
            <token id="26" string="political" />
            <token id="27" string="coalition" />
            <token id="28" string="that" />
            <token id="29" string="lived" />
            <token id="30" string="on" />
            <token id="31" string="after" />
            <token id="32" string="the" />
            <token id="33" string="controversy" />
            <token id="34" string="to" />
            <token id="35" string="plague" />
            <token id="36" string="every" />
            <token id="37" string="subsequent" />
            <token id="38" string="Democratic" />
            <token id="39" string="President" />
          </tokens>
        </chunking>
        <chunking id="7" string="the creation of an opposing political coalition that lived on after the controversy to plague every subsequent Democratic President" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="creation" />
            <token id="23" string="of" />
            <token id="24" string="an" />
            <token id="25" string="opposing" />
            <token id="26" string="political" />
            <token id="27" string="coalition" />
            <token id="28" string="that" />
            <token id="29" string="lived" />
            <token id="30" string="on" />
            <token id="31" string="after" />
            <token id="32" string="the" />
            <token id="33" string="controversy" />
            <token id="34" string="to" />
            <token id="35" string="plague" />
            <token id="36" string="every" />
            <token id="37" string="subsequent" />
            <token id="38" string="Democratic" />
            <token id="39" string="President" />
          </tokens>
        </chunking>
        <chunking id="8" string="every subsequent Democratic President" type="NP">
          <tokens>
            <token id="36" string="every" />
            <token id="37" string="subsequent" />
            <token id="38" string="Democratic" />
            <token id="39" string="President" />
          </tokens>
        </chunking>
        <chunking id="9" string="the controversy to plague every subsequent Democratic President" type="NP">
          <tokens>
            <token id="32" string="the" />
            <token id="33" string="controversy" />
            <token id="34" string="to" />
            <token id="35" string="plague" />
            <token id="36" string="every" />
            <token id="37" string="subsequent" />
            <token id="38" string="Democratic" />
            <token id="39" string="President" />
          </tokens>
        </chunking>
        <chunking id="10" string="conservatives" type="NP">
          <tokens>
            <token id="18" string="conservatives" />
          </tokens>
        </chunking>
        <chunking id="11" string="to plague every subsequent Democratic President" type="VP">
          <tokens>
            <token id="34" string="to" />
            <token id="35" string="plague" />
            <token id="36" string="every" />
            <token id="37" string="subsequent" />
            <token id="38" string="Democratic" />
            <token id="39" string="President" />
          </tokens>
        </chunking>
        <chunking id="12" string="the Supreme Court" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="Supreme" />
            <token id="10" string="Court" />
          </tokens>
        </chunking>
        <chunking id="13" string="subsequent Democratic" type="ADJP">
          <tokens>
            <token id="37" string="subsequent" />
            <token id="38" string="Democratic" />
          </tokens>
        </chunking>
        <chunking id="14" string="plague every subsequent Democratic President" type="VP">
          <tokens>
            <token id="35" string="plague" />
            <token id="36" string="every" />
            <token id="37" string="subsequent" />
            <token id="38" string="Democratic" />
            <token id="39" string="President" />
          </tokens>
        </chunking>
        <chunking id="15" string="Franklin D. Roosevelt 's plan to expand the Supreme Court in 1937 to dilute the votes of conservatives" type="NP">
          <tokens>
            <token id="1" string="Franklin" />
            <token id="2" string="D." />
            <token id="3" string="Roosevelt" />
            <token id="4" string="'s" />
            <token id="5" string="plan" />
            <token id="6" string="to" />
            <token id="7" string="expand" />
            <token id="8" string="the" />
            <token id="9" string="Supreme" />
            <token id="10" string="Court" />
            <token id="11" string="in" />
            <token id="12" string="1937" />
            <token id="13" string="to" />
            <token id="14" string="dilute" />
            <token id="15" string="the" />
            <token id="16" string="votes" />
            <token id="17" string="of" />
            <token id="18" string="conservatives" />
          </tokens>
        </chunking>
        <chunking id="16" string="Franklin D. Roosevelt 's" type="NP">
          <tokens>
            <token id="1" string="Franklin" />
            <token id="2" string="D." />
            <token id="3" string="Roosevelt" />
            <token id="4" string="'s" />
          </tokens>
        </chunking>
        <chunking id="17" string="the votes" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="votes" />
          </tokens>
        </chunking>
        <chunking id="18" string="lived on after the controversy to plague every subsequent Democratic President" type="VP">
          <tokens>
            <token id="29" string="lived" />
            <token id="30" string="on" />
            <token id="31" string="after" />
            <token id="32" string="the" />
            <token id="33" string="controversy" />
            <token id="34" string="to" />
            <token id="35" string="plague" />
            <token id="36" string="every" />
            <token id="37" string="subsequent" />
            <token id="38" string="Democratic" />
            <token id="39" string="President" />
          </tokens>
        </chunking>
        <chunking id="19" string="1937" type="NP">
          <tokens>
            <token id="12" string="1937" />
          </tokens>
        </chunking>
        <chunking id="20" string="the creation" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="creation" />
          </tokens>
        </chunking>
        <chunking id="21" string="an opposing political coalition" type="NP">
          <tokens>
            <token id="24" string="an" />
            <token id="25" string="opposing" />
            <token id="26" string="political" />
            <token id="27" string="coalition" />
          </tokens>
        </chunking>
        <chunking id="22" string="to expand the Supreme Court in 1937 to dilute the votes of conservatives" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="expand" />
            <token id="8" string="the" />
            <token id="9" string="Supreme" />
            <token id="10" string="Court" />
            <token id="11" string="in" />
            <token id="12" string="1937" />
            <token id="13" string="to" />
            <token id="14" string="dilute" />
            <token id="15" string="the" />
            <token id="16" string="votes" />
            <token id="17" string="of" />
            <token id="18" string="conservatives" />
          </tokens>
        </chunking>
        <chunking id="23" string="to dilute the votes of conservatives" type="VP">
          <tokens>
            <token id="13" string="to" />
            <token id="14" string="dilute" />
            <token id="15" string="the" />
            <token id="16" string="votes" />
            <token id="17" string="of" />
            <token id="18" string="conservatives" />
          </tokens>
        </chunking>
        <chunking id="24" string="resulted in the creation of an opposing political coalition that lived on after the controversy to plague every subsequent Democratic President" type="VP">
          <tokens>
            <token id="19" string="resulted" />
            <token id="20" string="in" />
            <token id="21" string="the" />
            <token id="22" string="creation" />
            <token id="23" string="of" />
            <token id="24" string="an" />
            <token id="25" string="opposing" />
            <token id="26" string="political" />
            <token id="27" string="coalition" />
            <token id="28" string="that" />
            <token id="29" string="lived" />
            <token id="30" string="on" />
            <token id="31" string="after" />
            <token id="32" string="the" />
            <token id="33" string="controversy" />
            <token id="34" string="to" />
            <token id="35" string="plague" />
            <token id="36" string="every" />
            <token id="37" string="subsequent" />
            <token id="38" string="Democratic" />
            <token id="39" string="President" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Roosevelt</governor>
          <dependent id="1">Franklin</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Roosevelt</governor>
          <dependent id="2">D.</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">plan</governor>
          <dependent id="3">Roosevelt</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">Roosevelt</governor>
          <dependent id="4">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">resulted</governor>
          <dependent id="5">plan</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">expand</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="5">plan</governor>
          <dependent id="7">expand</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">Court</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Court</governor>
          <dependent id="9">Supreme</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">expand</governor>
          <dependent id="10">Court</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">1937</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">Court</governor>
          <dependent id="12">1937</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">dilute</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">expand</governor>
          <dependent id="14">dilute</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">votes</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">dilute</governor>
          <dependent id="16">votes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">conservatives</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">votes</governor>
          <dependent id="18">conservatives</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="19">resulted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">creation</governor>
          <dependent id="20">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">creation</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">resulted</governor>
          <dependent id="22">creation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">coalition</governor>
          <dependent id="23">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">coalition</governor>
          <dependent id="24">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">coalition</governor>
          <dependent id="25">opposing</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">coalition</governor>
          <dependent id="26">political</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">creation</governor>
          <dependent id="27">coalition</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">lived</governor>
          <dependent id="28">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="27">coalition</governor>
          <dependent id="29">lived</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">controversy</governor>
          <dependent id="30">on</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">controversy</governor>
          <dependent id="31">after</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">controversy</governor>
          <dependent id="32">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">lived</governor>
          <dependent id="33">controversy</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="35">plague</governor>
          <dependent id="34">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="33">controversy</governor>
          <dependent id="35">plague</dependent>
        </dependency>
        <dependency type="det">
          <governor id="39">President</governor>
          <dependent id="36">every</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="38">Democratic</governor>
          <dependent id="37">subsequent</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="39">President</governor>
          <dependent id="38">Democratic</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="35">plague</governor>
          <dependent id="39">President</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Supreme Court" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="9" string="Supreme" />
            <token id="10" string="Court" />
          </tokens>
        </entity>
        <entity id="2" string="Franklin D. Roosevelt" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Franklin" />
            <token id="2" string="D." />
            <token id="3" string="Roosevelt" />
          </tokens>
        </entity>
        <entity id="3" string="Democratic" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="38" string="Democratic" />
          </tokens>
        </entity>
        <entity id="4" string="1937" type="DATE" score="0.0">
          <tokens>
            <token id="12" string="1937" />
          </tokens>
        </entity>
        <entity id="5" string="President" type="TITLE" score="0.0">
          <tokens>
            <token id="39" string="President" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>The Republicans in 1951 wanted to ensure that there would never be another F.D.R., so they pushed through the 22nd Amendment limiting presidents to two terms.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="Republicans" lemma="Republicans" stem="republican" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="3" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="1951" lemma="1951" stem="1951" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="5" string="wanted" lemma="want" stem="want" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="ensure" lemma="ensure" stem="ensur" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="another" lemma="another" stem="anoth" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="F.D.R." lemma="F.D.R." stem="f.d.r." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="so" lemma="so" stem="so" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="pushed" lemma="push" stem="push" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="22nd" lemma="22nd" stem="22nd" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="22" string="Amendment" lemma="amendment" stem="amendment" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="limiting" lemma="limit" stem="limit" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="presidents" lemma="president" stem="presid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="27" string="terms" lemma="term" stem="term" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (DT The) (NNPS Republicans)) (PP (IN in) (NP (CD 1951)))) (VP (VBD wanted) (S (VP (TO to) (VP (VB ensure) (SBAR (IN that) (S (NP (EX there)) (VP (MD would) (ADVP (RB never)) (VP (VB be) (NP (DT another) (NNP F.D.R.))))))))))) (, ,) (IN so) (S (NP (PRP they)) (VP (VBD pushed) (PP (IN through) (NP (DT the) (JJ 22nd) (NN Amendment))) (S (VP (VBG limiting) (NP (NNS presidents)) (PP (TO to) (NP (CD two) (NNS terms))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The Republicans" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Republicans" />
          </tokens>
        </chunking>
        <chunking id="2" string="that there would never be another F.D.R." type="SBAR">
          <tokens>
            <token id="8" string="that" />
            <token id="9" string="there" />
            <token id="10" string="would" />
            <token id="11" string="never" />
            <token id="12" string="be" />
            <token id="13" string="another" />
            <token id="14" string="F.D.R." />
          </tokens>
        </chunking>
        <chunking id="3" string="the 22nd Amendment" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="22nd" />
            <token id="22" string="Amendment" />
          </tokens>
        </chunking>
        <chunking id="4" string="to ensure that there would never be another F.D.R." type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="ensure" />
            <token id="8" string="that" />
            <token id="9" string="there" />
            <token id="10" string="would" />
            <token id="11" string="never" />
            <token id="12" string="be" />
            <token id="13" string="another" />
            <token id="14" string="F.D.R." />
          </tokens>
        </chunking>
        <chunking id="5" string="limiting presidents to two terms" type="VP">
          <tokens>
            <token id="23" string="limiting" />
            <token id="24" string="presidents" />
            <token id="25" string="to" />
            <token id="26" string="two" />
            <token id="27" string="terms" />
          </tokens>
        </chunking>
        <chunking id="6" string="presidents" type="NP">
          <tokens>
            <token id="24" string="presidents" />
          </tokens>
        </chunking>
        <chunking id="7" string="pushed through the 22nd Amendment limiting presidents to two terms" type="VP">
          <tokens>
            <token id="18" string="pushed" />
            <token id="19" string="through" />
            <token id="20" string="the" />
            <token id="21" string="22nd" />
            <token id="22" string="Amendment" />
            <token id="23" string="limiting" />
            <token id="24" string="presidents" />
            <token id="25" string="to" />
            <token id="26" string="two" />
            <token id="27" string="terms" />
          </tokens>
        </chunking>
        <chunking id="8" string="ensure that there would never be another F.D.R." type="VP">
          <tokens>
            <token id="7" string="ensure" />
            <token id="8" string="that" />
            <token id="9" string="there" />
            <token id="10" string="would" />
            <token id="11" string="never" />
            <token id="12" string="be" />
            <token id="13" string="another" />
            <token id="14" string="F.D.R." />
          </tokens>
        </chunking>
        <chunking id="9" string="there" type="NP">
          <tokens>
            <token id="9" string="there" />
          </tokens>
        </chunking>
        <chunking id="10" string="they" type="NP">
          <tokens>
            <token id="17" string="they" />
          </tokens>
        </chunking>
        <chunking id="11" string="1951" type="NP">
          <tokens>
            <token id="4" string="1951" />
          </tokens>
        </chunking>
        <chunking id="12" string="another F.D.R." type="NP">
          <tokens>
            <token id="13" string="another" />
            <token id="14" string="F.D.R." />
          </tokens>
        </chunking>
        <chunking id="13" string="wanted to ensure that there would never be another F.D.R." type="VP">
          <tokens>
            <token id="5" string="wanted" />
            <token id="6" string="to" />
            <token id="7" string="ensure" />
            <token id="8" string="that" />
            <token id="9" string="there" />
            <token id="10" string="would" />
            <token id="11" string="never" />
            <token id="12" string="be" />
            <token id="13" string="another" />
            <token id="14" string="F.D.R." />
          </tokens>
        </chunking>
        <chunking id="14" string="The Republicans in 1951" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Republicans" />
            <token id="3" string="in" />
            <token id="4" string="1951" />
          </tokens>
        </chunking>
        <chunking id="15" string="be another F.D.R." type="VP">
          <tokens>
            <token id="12" string="be" />
            <token id="13" string="another" />
            <token id="14" string="F.D.R." />
          </tokens>
        </chunking>
        <chunking id="16" string="two terms" type="NP">
          <tokens>
            <token id="26" string="two" />
            <token id="27" string="terms" />
          </tokens>
        </chunking>
        <chunking id="17" string="would never be another F.D.R." type="VP">
          <tokens>
            <token id="10" string="would" />
            <token id="11" string="never" />
            <token id="12" string="be" />
            <token id="13" string="another" />
            <token id="14" string="F.D.R." />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">Republicans</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">wanted</governor>
          <dependent id="2">Republicans</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">1951</governor>
          <dependent id="3">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">Republicans</governor>
          <dependent id="4">1951</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">wanted</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">ensure</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">wanted</governor>
          <dependent id="7">ensure</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">F.D.R.</governor>
          <dependent id="8">that</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="14">F.D.R.</governor>
          <dependent id="9">there</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">F.D.R.</governor>
          <dependent id="10">would</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="14">F.D.R.</governor>
          <dependent id="11">never</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">F.D.R.</governor>
          <dependent id="12">be</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">F.D.R.</governor>
          <dependent id="13">another</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">ensure</governor>
          <dependent id="14">F.D.R.</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="5">wanted</governor>
          <dependent id="16">so</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">pushed</governor>
          <dependent id="17">they</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="5">wanted</governor>
          <dependent id="18">pushed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">Amendment</governor>
          <dependent id="19">through</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">Amendment</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">Amendment</governor>
          <dependent id="21">22nd</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">pushed</governor>
          <dependent id="22">Amendment</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="18">pushed</governor>
          <dependent id="23">limiting</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">limiting</governor>
          <dependent id="24">presidents</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">terms</governor>
          <dependent id="25">to</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="27">terms</governor>
          <dependent id="26">two</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">limiting</governor>
          <dependent id="27">terms</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Republicans" type="MISC" score="0.0">
          <tokens>
            <token id="2" string="Republicans" />
          </tokens>
        </entity>
        <entity id="2" string="22nd" type="ORDINAL" score="0.0">
          <tokens>
            <token id="21" string="22nd" />
          </tokens>
        </entity>
        <entity id="3" string="1951" type="DATE" score="0.0">
          <tokens>
            <token id="4" string="1951" />
          </tokens>
        </entity>
        <entity id="4" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="26" string="two" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="false">
      <content>The first President to come under the restriction was Dwight D. Eisenhower, a Republican who might very well have won a third term.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="true" is_refers="false" />
        <token id="3" string="President" lemma="president" stem="presid" pos="NN" type="Word" isStopWord="false" ner="TITLE" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="come" lemma="come" stem="come" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="under" lemma="under" stem="under" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="restriction" lemma="restriction" stem="restrict" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Dwight" lemma="Dwight" stem="dwight" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="11" string="D." lemma="D." stem="d." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="12" string="Eisenhower" lemma="Eisenhower" stem="eisenhow" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Republican" lemma="Republican" stem="republican" pos="NNP" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="16" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="might" lemma="might" stem="might" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="well" lemma="well" stem="well" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="won" lemma="win" stem="won" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="third" lemma="third" stem="third" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="24" string="term" lemma="term" stem="term" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (JJ first) (NN President) (S (VP (TO to) (VP (VB come) (PP (IN under) (NP (DT the) (NN restriction))))))) (VP (VBD was) (NP (NP (NNP Dwight) (NNP D.) (NNP Eisenhower)) (, ,) (NP (NP (DT a) (NNP Republican)) (SBAR (WHNP (WP who)) (S (VP (MD might) (ADVP (RB very) (RB well)) (VP (VB have) (VP (VBN won) (NP (DT a) (JJ third) (NN term)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a Republican" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="Republican" />
          </tokens>
        </chunking>
        <chunking id="2" string="was Dwight D. Eisenhower , a Republican who might very well have won a third term" type="VP">
          <tokens>
            <token id="9" string="was" />
            <token id="10" string="Dwight" />
            <token id="11" string="D." />
            <token id="12" string="Eisenhower" />
            <token id="13" string="," />
            <token id="14" string="a" />
            <token id="15" string="Republican" />
            <token id="16" string="who" />
            <token id="17" string="might" />
            <token id="18" string="very" />
            <token id="19" string="well" />
            <token id="20" string="have" />
            <token id="21" string="won" />
            <token id="22" string="a" />
            <token id="23" string="third" />
            <token id="24" string="term" />
          </tokens>
        </chunking>
        <chunking id="3" string="a Republican who might very well have won a third term" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="Republican" />
            <token id="16" string="who" />
            <token id="17" string="might" />
            <token id="18" string="very" />
            <token id="19" string="well" />
            <token id="20" string="have" />
            <token id="21" string="won" />
            <token id="22" string="a" />
            <token id="23" string="third" />
            <token id="24" string="term" />
          </tokens>
        </chunking>
        <chunking id="4" string="who might very well have won a third term" type="SBAR">
          <tokens>
            <token id="16" string="who" />
            <token id="17" string="might" />
            <token id="18" string="very" />
            <token id="19" string="well" />
            <token id="20" string="have" />
            <token id="21" string="won" />
            <token id="22" string="a" />
            <token id="23" string="third" />
            <token id="24" string="term" />
          </tokens>
        </chunking>
        <chunking id="5" string="have won a third term" type="VP">
          <tokens>
            <token id="20" string="have" />
            <token id="21" string="won" />
            <token id="22" string="a" />
            <token id="23" string="third" />
            <token id="24" string="term" />
          </tokens>
        </chunking>
        <chunking id="6" string="Dwight D. Eisenhower , a Republican who might very well have won a third term" type="NP">
          <tokens>
            <token id="10" string="Dwight" />
            <token id="11" string="D." />
            <token id="12" string="Eisenhower" />
            <token id="13" string="," />
            <token id="14" string="a" />
            <token id="15" string="Republican" />
            <token id="16" string="who" />
            <token id="17" string="might" />
            <token id="18" string="very" />
            <token id="19" string="well" />
            <token id="20" string="have" />
            <token id="21" string="won" />
            <token id="22" string="a" />
            <token id="23" string="third" />
            <token id="24" string="term" />
          </tokens>
        </chunking>
        <chunking id="7" string="Dwight D. Eisenhower" type="NP">
          <tokens>
            <token id="10" string="Dwight" />
            <token id="11" string="D." />
            <token id="12" string="Eisenhower" />
          </tokens>
        </chunking>
        <chunking id="8" string="come under the restriction" type="VP">
          <tokens>
            <token id="5" string="come" />
            <token id="6" string="under" />
            <token id="7" string="the" />
            <token id="8" string="restriction" />
          </tokens>
        </chunking>
        <chunking id="9" string="to come under the restriction" type="VP">
          <tokens>
            <token id="4" string="to" />
            <token id="5" string="come" />
            <token id="6" string="under" />
            <token id="7" string="the" />
            <token id="8" string="restriction" />
          </tokens>
        </chunking>
        <chunking id="10" string="might very well have won a third term" type="VP">
          <tokens>
            <token id="17" string="might" />
            <token id="18" string="very" />
            <token id="19" string="well" />
            <token id="20" string="have" />
            <token id="21" string="won" />
            <token id="22" string="a" />
            <token id="23" string="third" />
            <token id="24" string="term" />
          </tokens>
        </chunking>
        <chunking id="11" string="The first President to come under the restriction" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="first" />
            <token id="3" string="President" />
            <token id="4" string="to" />
            <token id="5" string="come" />
            <token id="6" string="under" />
            <token id="7" string="the" />
            <token id="8" string="restriction" />
          </tokens>
        </chunking>
        <chunking id="12" string="won a third term" type="VP">
          <tokens>
            <token id="21" string="won" />
            <token id="22" string="a" />
            <token id="23" string="third" />
            <token id="24" string="term" />
          </tokens>
        </chunking>
        <chunking id="13" string="a third term" type="NP">
          <tokens>
            <token id="22" string="a" />
            <token id="23" string="third" />
            <token id="24" string="term" />
          </tokens>
        </chunking>
        <chunking id="14" string="the restriction" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="restriction" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">President</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">President</governor>
          <dependent id="2">first</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">Eisenhower</governor>
          <dependent id="3">President</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">come</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="3">President</governor>
          <dependent id="5">come</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">restriction</governor>
          <dependent id="6">under</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">restriction</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">come</governor>
          <dependent id="8">restriction</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">Eisenhower</governor>
          <dependent id="9">was</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Eisenhower</governor>
          <dependent id="10">Dwight</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Eisenhower</governor>
          <dependent id="11">D.</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">Eisenhower</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">Republican</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="12">Eisenhower</governor>
          <dependent id="15">Republican</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">won</governor>
          <dependent id="16">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">won</governor>
          <dependent id="17">might</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">well</governor>
          <dependent id="18">very</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="21">won</governor>
          <dependent id="19">well</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">won</governor>
          <dependent id="20">have</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="15">Republican</governor>
          <dependent id="21">won</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">term</governor>
          <dependent id="22">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">term</governor>
          <dependent id="23">third</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">won</governor>
          <dependent id="24">term</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="2" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="Dwight D. Eisenhower" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Dwight" />
            <token id="11" string="D." />
            <token id="12" string="Eisenhower" />
          </tokens>
        </entity>
        <entity id="3" string="third" type="ORDINAL" score="0.0">
          <tokens>
            <token id="23" string="third" />
          </tokens>
        </entity>
        <entity id="4" string="Republican" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="15" string="Republican" />
          </tokens>
        </entity>
        <entity id="5" string="President" type="TITLE" score="0.0">
          <tokens>
            <token id="3" string="President" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>The latest institutional patients to be wheeled into the shock-trauma unit are the state legislatures.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="latest" lemma="latest" stem="latest" pos="JJS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="institutional" lemma="institutional" stem="institut" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="patients" lemma="patient" stem="patient" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="wheeled" lemma="wheel" stem="wheel" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="shock-trauma" lemma="shock-trauma" stem="shock-trauma" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="unit" lemma="unit" stem="unit" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="state" lemma="state" stem="state" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="legislatures" lemma="legislature" stem="legislatur" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (JJS latest) (JJ institutional) (NNS patients)) (SBAR (S (VP (TO to) (VP (VB be) (VP (VBN wheeled) (PP (IN into) (NP (DT the) (JJ shock-trauma) (NN unit))))))))) (VP (VBP are) (NP (DT the) (NN state) (NNS legislatures))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="be wheeled into the shock-trauma unit" type="VP">
          <tokens>
            <token id="6" string="be" />
            <token id="7" string="wheeled" />
            <token id="8" string="into" />
            <token id="9" string="the" />
            <token id="10" string="shock-trauma" />
            <token id="11" string="unit" />
          </tokens>
        </chunking>
        <chunking id="2" string="The latest institutional patients" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="latest" />
            <token id="3" string="institutional" />
            <token id="4" string="patients" />
          </tokens>
        </chunking>
        <chunking id="3" string="to be wheeled into the shock-trauma unit" type="SBAR">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="be" />
            <token id="7" string="wheeled" />
            <token id="8" string="into" />
            <token id="9" string="the" />
            <token id="10" string="shock-trauma" />
            <token id="11" string="unit" />
          </tokens>
        </chunking>
        <chunking id="4" string="wheeled into the shock-trauma unit" type="VP">
          <tokens>
            <token id="7" string="wheeled" />
            <token id="8" string="into" />
            <token id="9" string="the" />
            <token id="10" string="shock-trauma" />
            <token id="11" string="unit" />
          </tokens>
        </chunking>
        <chunking id="5" string="are the state legislatures" type="VP">
          <tokens>
            <token id="12" string="are" />
            <token id="13" string="the" />
            <token id="14" string="state" />
            <token id="15" string="legislatures" />
          </tokens>
        </chunking>
        <chunking id="6" string="the state legislatures" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="state" />
            <token id="15" string="legislatures" />
          </tokens>
        </chunking>
        <chunking id="7" string="The latest institutional patients to be wheeled into the shock-trauma unit" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="latest" />
            <token id="3" string="institutional" />
            <token id="4" string="patients" />
            <token id="5" string="to" />
            <token id="6" string="be" />
            <token id="7" string="wheeled" />
            <token id="8" string="into" />
            <token id="9" string="the" />
            <token id="10" string="shock-trauma" />
            <token id="11" string="unit" />
          </tokens>
        </chunking>
        <chunking id="8" string="the shock-trauma unit" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="shock-trauma" />
            <token id="11" string="unit" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">patients</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">patients</governor>
          <dependent id="2">latest</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">patients</governor>
          <dependent id="3">institutional</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">legislatures</governor>
          <dependent id="4">patients</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">wheeled</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="7">wheeled</governor>
          <dependent id="6">be</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="4">patients</governor>
          <dependent id="7">wheeled</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">unit</governor>
          <dependent id="8">into</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">unit</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">unit</governor>
          <dependent id="10">shock-trauma</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">wheeled</governor>
          <dependent id="11">unit</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="15">legislatures</governor>
          <dependent id="12">are</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">legislatures</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">legislatures</governor>
          <dependent id="14">state</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">legislatures</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>The quack therapy being performed on them is the imposition of limits on the number of terms that state lawmakers can serve.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="quack" lemma="quack" stem="quack" pos="UH" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="therapy" lemma="therapy" stem="therapi" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="being" lemma="be" stem="be" pos="VBG" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="performed" lemma="perform" stem="perform" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="8" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="imposition" lemma="imposition" stem="imposit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="limits" lemma="limit" stem="limit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="number" lemma="number" stem="number" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="terms" lemma="term" stem="term" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="state" lemma="state" stem="state" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="lawmakers" lemma="lawmaker" stem="lawmak" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="serve" lemma="serve" stem="serv" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (UH quack) (NN therapy)) (VP (VBG being) (VP (VBN performed) (PP (IN on) (NP (PRP them)))))) (VP (VBZ is) (NP (NP (DT the) (NN imposition)) (PP (IN of) (NP (NP (NNS limits)) (PP (IN on) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NP (NNS terms)) (SBAR (WHNP (WDT that)) (S (VP (VBP state) (SBAR (S (NP (NNS lawmakers)) (VP (MD can) (VP (VB serve)))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the imposition" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="imposition" />
          </tokens>
        </chunking>
        <chunking id="2" string="The quack therapy being performed on them" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="quack" />
            <token id="3" string="therapy" />
            <token id="4" string="being" />
            <token id="5" string="performed" />
            <token id="6" string="on" />
            <token id="7" string="them" />
          </tokens>
        </chunking>
        <chunking id="3" string="limits on the number of terms that state lawmakers can serve" type="NP">
          <tokens>
            <token id="12" string="limits" />
            <token id="13" string="on" />
            <token id="14" string="the" />
            <token id="15" string="number" />
            <token id="16" string="of" />
            <token id="17" string="terms" />
            <token id="18" string="that" />
            <token id="19" string="state" />
            <token id="20" string="lawmakers" />
            <token id="21" string="can" />
            <token id="22" string="serve" />
          </tokens>
        </chunking>
        <chunking id="4" string="performed on them" type="VP">
          <tokens>
            <token id="5" string="performed" />
            <token id="6" string="on" />
            <token id="7" string="them" />
          </tokens>
        </chunking>
        <chunking id="5" string="serve" type="VP">
          <tokens>
            <token id="22" string="serve" />
          </tokens>
        </chunking>
        <chunking id="6" string="can serve" type="VP">
          <tokens>
            <token id="21" string="can" />
            <token id="22" string="serve" />
          </tokens>
        </chunking>
        <chunking id="7" string="them" type="NP">
          <tokens>
            <token id="7" string="them" />
          </tokens>
        </chunking>
        <chunking id="8" string="the imposition of limits on the number of terms that state lawmakers can serve" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="imposition" />
            <token id="11" string="of" />
            <token id="12" string="limits" />
            <token id="13" string="on" />
            <token id="14" string="the" />
            <token id="15" string="number" />
            <token id="16" string="of" />
            <token id="17" string="terms" />
            <token id="18" string="that" />
            <token id="19" string="state" />
            <token id="20" string="lawmakers" />
            <token id="21" string="can" />
            <token id="22" string="serve" />
          </tokens>
        </chunking>
        <chunking id="9" string="that state lawmakers can serve" type="SBAR">
          <tokens>
            <token id="18" string="that" />
            <token id="19" string="state" />
            <token id="20" string="lawmakers" />
            <token id="21" string="can" />
            <token id="22" string="serve" />
          </tokens>
        </chunking>
        <chunking id="10" string="lawmakers" type="NP">
          <tokens>
            <token id="20" string="lawmakers" />
          </tokens>
        </chunking>
        <chunking id="11" string="limits" type="NP">
          <tokens>
            <token id="12" string="limits" />
          </tokens>
        </chunking>
        <chunking id="12" string="the number of terms that state lawmakers can serve" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="number" />
            <token id="16" string="of" />
            <token id="17" string="terms" />
            <token id="18" string="that" />
            <token id="19" string="state" />
            <token id="20" string="lawmakers" />
            <token id="21" string="can" />
            <token id="22" string="serve" />
          </tokens>
        </chunking>
        <chunking id="13" string="being performed on them" type="VP">
          <tokens>
            <token id="4" string="being" />
            <token id="5" string="performed" />
            <token id="6" string="on" />
            <token id="7" string="them" />
          </tokens>
        </chunking>
        <chunking id="14" string="lawmakers can serve" type="SBAR">
          <tokens>
            <token id="20" string="lawmakers" />
            <token id="21" string="can" />
            <token id="22" string="serve" />
          </tokens>
        </chunking>
        <chunking id="15" string="The quack therapy" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="quack" />
            <token id="3" string="therapy" />
          </tokens>
        </chunking>
        <chunking id="16" string="terms" type="NP">
          <tokens>
            <token id="17" string="terms" />
          </tokens>
        </chunking>
        <chunking id="17" string="terms that state lawmakers can serve" type="NP">
          <tokens>
            <token id="17" string="terms" />
            <token id="18" string="that" />
            <token id="19" string="state" />
            <token id="20" string="lawmakers" />
            <token id="21" string="can" />
            <token id="22" string="serve" />
          </tokens>
        </chunking>
        <chunking id="18" string="the number" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="number" />
          </tokens>
        </chunking>
        <chunking id="19" string="state lawmakers can serve" type="VP">
          <tokens>
            <token id="19" string="state" />
            <token id="20" string="lawmakers" />
            <token id="21" string="can" />
            <token id="22" string="serve" />
          </tokens>
        </chunking>
        <chunking id="20" string="is the imposition of limits on the number of terms that state lawmakers can serve" type="VP">
          <tokens>
            <token id="8" string="is" />
            <token id="9" string="the" />
            <token id="10" string="imposition" />
            <token id="11" string="of" />
            <token id="12" string="limits" />
            <token id="13" string="on" />
            <token id="14" string="the" />
            <token id="15" string="number" />
            <token id="16" string="of" />
            <token id="17" string="terms" />
            <token id="18" string="that" />
            <token id="19" string="state" />
            <token id="20" string="lawmakers" />
            <token id="21" string="can" />
            <token id="22" string="serve" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">therapy</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="3">therapy</governor>
          <dependent id="2">quack</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">imposition</governor>
          <dependent id="3">therapy</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">performed</governor>
          <dependent id="4">being</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="3">therapy</governor>
          <dependent id="5">performed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">them</governor>
          <dependent id="6">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">performed</governor>
          <dependent id="7">them</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="10">imposition</governor>
          <dependent id="8">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">imposition</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">imposition</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">limits</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">imposition</governor>
          <dependent id="12">limits</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">number</governor>
          <dependent id="13">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">number</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">limits</governor>
          <dependent id="15">number</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">terms</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">number</governor>
          <dependent id="17">terms</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">state</governor>
          <dependent id="18">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="17">terms</governor>
          <dependent id="19">state</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">serve</governor>
          <dependent id="20">lawmakers</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="22">serve</governor>
          <dependent id="21">can</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">state</governor>
          <dependent id="22">serve</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>The first cut took place on Sept. 18, when Oklahoma voters endorsed overwhelmingly a ballot initiative limiting state lawmakers to 12 years&amp;apost; service.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="true" is_refers="false" />
        <token id="3" string="cut" lemma="cut" stem="cut" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="took" lemma="take" stem="took" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="place" lemma="place" stem="place" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Sept." lemma="Sept." stem="sept." pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="8" string="18" lemma="18" stem="18" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Oklahoma" lemma="Oklahoma" stem="oklahoma" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="true" />
        <token id="12" string="voters" lemma="voter" stem="voter" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="endorsed" lemma="endorse" stem="endors" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="overwhelmingly" lemma="overwhelmingly" stem="overwhelmingli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="ballot" lemma="ballot" stem="ballot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="initiative" lemma="initiative" stem="initi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="limiting" lemma="limit" stem="limit" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="state" lemma="state" stem="state" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="lawmakers" lemma="lawmaker" stem="lawmak" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="12" lemma="12" stem="12" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="23" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="24" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="service" lemma="service" stem="servic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (JJ first) (NN cut)) (VP (VBD took) (NP (NN place)) (PP (IN on) (NP (NP (NNP Sept.) (CD 18)) (, ,) (SBAR (WHADVP (WRB when)) (S (NP (NNP Oklahoma) (NNS voters)) (VP (VBD endorsed) (ADVP (RB overwhelmingly)) (NP (NP (DT a) (NN ballot) (NN initiative)) (VP (VBG limiting) (NP (NN state) (NNS lawmakers)) (PP (TO to) (NP (NP (CD 12) (NNS years) (POS ')) (NN service))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Sept. 18 , when Oklahoma voters endorsed overwhelmingly a ballot initiative limiting state lawmakers to 12 years ' service" type="NP">
          <tokens>
            <token id="7" string="Sept." />
            <token id="8" string="18" />
            <token id="9" string="," />
            <token id="10" string="when" />
            <token id="11" string="Oklahoma" />
            <token id="12" string="voters" />
            <token id="13" string="endorsed" />
            <token id="14" string="overwhelmingly" />
            <token id="15" string="a" />
            <token id="16" string="ballot" />
            <token id="17" string="initiative" />
            <token id="18" string="limiting" />
            <token id="19" string="state" />
            <token id="20" string="lawmakers" />
            <token id="21" string="to" />
            <token id="22" string="12" />
            <token id="23" string="years" />
            <token id="24" string="'" />
            <token id="25" string="service" />
          </tokens>
        </chunking>
        <chunking id="2" string="took place on Sept. 18 , when Oklahoma voters endorsed overwhelmingly a ballot initiative limiting state lawmakers to 12 years ' service" type="VP">
          <tokens>
            <token id="4" string="took" />
            <token id="5" string="place" />
            <token id="6" string="on" />
            <token id="7" string="Sept." />
            <token id="8" string="18" />
            <token id="9" string="," />
            <token id="10" string="when" />
            <token id="11" string="Oklahoma" />
            <token id="12" string="voters" />
            <token id="13" string="endorsed" />
            <token id="14" string="overwhelmingly" />
            <token id="15" string="a" />
            <token id="16" string="ballot" />
            <token id="17" string="initiative" />
            <token id="18" string="limiting" />
            <token id="19" string="state" />
            <token id="20" string="lawmakers" />
            <token id="21" string="to" />
            <token id="22" string="12" />
            <token id="23" string="years" />
            <token id="24" string="'" />
            <token id="25" string="service" />
          </tokens>
        </chunking>
        <chunking id="3" string="Sept. 18" type="NP">
          <tokens>
            <token id="7" string="Sept." />
            <token id="8" string="18" />
          </tokens>
        </chunking>
        <chunking id="4" string="a ballot initiative limiting state lawmakers to 12 years ' service" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="ballot" />
            <token id="17" string="initiative" />
            <token id="18" string="limiting" />
            <token id="19" string="state" />
            <token id="20" string="lawmakers" />
            <token id="21" string="to" />
            <token id="22" string="12" />
            <token id="23" string="years" />
            <token id="24" string="'" />
            <token id="25" string="service" />
          </tokens>
        </chunking>
        <chunking id="5" string="a ballot initiative" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="ballot" />
            <token id="17" string="initiative" />
          </tokens>
        </chunking>
        <chunking id="6" string="The first cut" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="first" />
            <token id="3" string="cut" />
          </tokens>
        </chunking>
        <chunking id="7" string="when" type="WHADVP">
          <tokens>
            <token id="10" string="when" />
          </tokens>
        </chunking>
        <chunking id="8" string="when Oklahoma voters endorsed overwhelmingly a ballot initiative limiting state lawmakers to 12 years ' service" type="SBAR">
          <tokens>
            <token id="10" string="when" />
            <token id="11" string="Oklahoma" />
            <token id="12" string="voters" />
            <token id="13" string="endorsed" />
            <token id="14" string="overwhelmingly" />
            <token id="15" string="a" />
            <token id="16" string="ballot" />
            <token id="17" string="initiative" />
            <token id="18" string="limiting" />
            <token id="19" string="state" />
            <token id="20" string="lawmakers" />
            <token id="21" string="to" />
            <token id="22" string="12" />
            <token id="23" string="years" />
            <token id="24" string="'" />
            <token id="25" string="service" />
          </tokens>
        </chunking>
        <chunking id="9" string="endorsed overwhelmingly a ballot initiative limiting state lawmakers to 12 years ' service" type="VP">
          <tokens>
            <token id="13" string="endorsed" />
            <token id="14" string="overwhelmingly" />
            <token id="15" string="a" />
            <token id="16" string="ballot" />
            <token id="17" string="initiative" />
            <token id="18" string="limiting" />
            <token id="19" string="state" />
            <token id="20" string="lawmakers" />
            <token id="21" string="to" />
            <token id="22" string="12" />
            <token id="23" string="years" />
            <token id="24" string="'" />
            <token id="25" string="service" />
          </tokens>
        </chunking>
        <chunking id="10" string="12 years '" type="NP">
          <tokens>
            <token id="22" string="12" />
            <token id="23" string="years" />
            <token id="24" string="'" />
          </tokens>
        </chunking>
        <chunking id="11" string="Oklahoma voters" type="NP">
          <tokens>
            <token id="11" string="Oklahoma" />
            <token id="12" string="voters" />
          </tokens>
        </chunking>
        <chunking id="12" string="place" type="NP">
          <tokens>
            <token id="5" string="place" />
          </tokens>
        </chunking>
        <chunking id="13" string="limiting state lawmakers to 12 years ' service" type="VP">
          <tokens>
            <token id="18" string="limiting" />
            <token id="19" string="state" />
            <token id="20" string="lawmakers" />
            <token id="21" string="to" />
            <token id="22" string="12" />
            <token id="23" string="years" />
            <token id="24" string="'" />
            <token id="25" string="service" />
          </tokens>
        </chunking>
        <chunking id="14" string="state lawmakers" type="NP">
          <tokens>
            <token id="19" string="state" />
            <token id="20" string="lawmakers" />
          </tokens>
        </chunking>
        <chunking id="15" string="12 years ' service" type="NP">
          <tokens>
            <token id="22" string="12" />
            <token id="23" string="years" />
            <token id="24" string="'" />
            <token id="25" string="service" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">cut</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">cut</governor>
          <dependent id="2">first</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">took</governor>
          <dependent id="3">cut</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">took</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">took</governor>
          <dependent id="5">place</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Sept.</governor>
          <dependent id="6">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">took</governor>
          <dependent id="7">Sept.</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="7">Sept.</governor>
          <dependent id="8">18</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">endorsed</governor>
          <dependent id="10">when</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">voters</governor>
          <dependent id="11">Oklahoma</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">endorsed</governor>
          <dependent id="12">voters</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="7">Sept.</governor>
          <dependent id="13">endorsed</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">endorsed</governor>
          <dependent id="14">overwhelmingly</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">initiative</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">initiative</governor>
          <dependent id="16">ballot</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">endorsed</governor>
          <dependent id="17">initiative</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="17">initiative</governor>
          <dependent id="18">limiting</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">lawmakers</governor>
          <dependent id="19">state</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">limiting</governor>
          <dependent id="20">lawmakers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">service</governor>
          <dependent id="21">to</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="23">years</governor>
          <dependent id="22">12</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="25">service</governor>
          <dependent id="23">years</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">years</governor>
          <dependent id="24">'</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">limiting</governor>
          <dependent id="25">service</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="2" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="Oklahoma" type="LOCATION" score="0.0">
          <tokens>
            <token id="11" string="Oklahoma" />
          </tokens>
        </entity>
        <entity id="3" string="12 years" type="DURATION" score="0.0">
          <tokens>
            <token id="22" string="12" />
            <token id="23" string="years" />
          </tokens>
        </entity>
        <entity id="4" string="Sept. 18" type="DATE" score="0.0">
          <tokens>
            <token id="7" string="Sept." />
            <token id="8" string="18" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>By itself, the term limitation in Oklahoma might be written off as a cranky act of vengeance in a state not renowned as a political trend-setter, but similar measures will be voted on in November in California and Colorado.</content>
      <tokens>
        <token id="1" string="By" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="itself" lemma="itself" stem="itself" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="term" lemma="term" stem="term" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="limitation" lemma="limitation" stem="limit" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="Oklahoma" lemma="Oklahoma" stem="oklahoma" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="true" />
        <token id="9" string="might" lemma="might" stem="might" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="written" lemma="write" stem="written" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="off" lemma="off" stem="off" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="cranky" lemma="cranky" stem="cranki" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="act" lemma="act" stem="act" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="vengeance" lemma="vengeance" stem="vengeanc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="state" lemma="state" stem="state" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="renowned" lemma="renown" stem="renown" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="political" lemma="political" stem="polit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="trend-setter" lemma="trend-setter" stem="trend-sett" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="similar" lemma="similar" stem="similar" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="measures" lemma="measure" stem="measur" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="voted" lemma="vote" stem="vote" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="November" lemma="November" stem="novemb" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="38" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="California" lemma="California" stem="california" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="40" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="Colorado" lemma="Colorado" stem="colorado" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="42" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (PP (IN By) (NP (PRP itself))) (, ,) (NP (NP (DT the) (NN term) (NN limitation)) (PP (IN in) (NP (NNP Oklahoma)))) (VP (MD might) (VP (VB be) (VP (VBN written) (PRT (RP off)) (PP (IN as) (NP (NP (DT a) (JJ cranky) (NN act)) (PP (IN of) (NP (NN vengeance))))) (PP (IN in) (NP (NP (DT a) (NN state)) (VP (RB not) (VBN renowned) (PP (IN as) (NP (DT a) (JJ political) (NN trend-setter)))))))))) (, ,) (CC but) (S (NP (JJ similar) (NNS measures)) (VP (MD will) (VP (VB be) (VP (VBN voted) (PP (IN on) (IN in) (NP (NP (NNP November)) (PP (IN in) (NP (NNP California) (CC and) (NNP Colorado))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Oklahoma" type="NP">
          <tokens>
            <token id="8" string="Oklahoma" />
          </tokens>
        </chunking>
        <chunking id="2" string="vengeance" type="NP">
          <tokens>
            <token id="18" string="vengeance" />
          </tokens>
        </chunking>
        <chunking id="3" string="a political trend-setter" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="political" />
            <token id="27" string="trend-setter" />
          </tokens>
        </chunking>
        <chunking id="4" string="the term limitation in Oklahoma" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="term" />
            <token id="6" string="limitation" />
            <token id="7" string="in" />
            <token id="8" string="Oklahoma" />
          </tokens>
        </chunking>
        <chunking id="5" string="a cranky act of vengeance" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="cranky" />
            <token id="16" string="act" />
            <token id="17" string="of" />
            <token id="18" string="vengeance" />
          </tokens>
        </chunking>
        <chunking id="6" string="be written off as a cranky act of vengeance in a state not renowned as a political trend-setter" type="VP">
          <tokens>
            <token id="10" string="be" />
            <token id="11" string="written" />
            <token id="12" string="off" />
            <token id="13" string="as" />
            <token id="14" string="a" />
            <token id="15" string="cranky" />
            <token id="16" string="act" />
            <token id="17" string="of" />
            <token id="18" string="vengeance" />
            <token id="19" string="in" />
            <token id="20" string="a" />
            <token id="21" string="state" />
            <token id="22" string="not" />
            <token id="23" string="renowned" />
            <token id="24" string="as" />
            <token id="25" string="a" />
            <token id="26" string="political" />
            <token id="27" string="trend-setter" />
          </tokens>
        </chunking>
        <chunking id="7" string="the term limitation" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="term" />
            <token id="6" string="limitation" />
          </tokens>
        </chunking>
        <chunking id="8" string="voted on in November in California and Colorado" type="VP">
          <tokens>
            <token id="34" string="voted" />
            <token id="35" string="on" />
            <token id="36" string="in" />
            <token id="37" string="November" />
            <token id="38" string="in" />
            <token id="39" string="California" />
            <token id="40" string="and" />
            <token id="41" string="Colorado" />
          </tokens>
        </chunking>
        <chunking id="9" string="a cranky act" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="cranky" />
            <token id="16" string="act" />
          </tokens>
        </chunking>
        <chunking id="10" string="will be voted on in November in California and Colorado" type="VP">
          <tokens>
            <token id="32" string="will" />
            <token id="33" string="be" />
            <token id="34" string="voted" />
            <token id="35" string="on" />
            <token id="36" string="in" />
            <token id="37" string="November" />
            <token id="38" string="in" />
            <token id="39" string="California" />
            <token id="40" string="and" />
            <token id="41" string="Colorado" />
          </tokens>
        </chunking>
        <chunking id="11" string="written off as a cranky act of vengeance in a state not renowned as a political trend-setter" type="VP">
          <tokens>
            <token id="11" string="written" />
            <token id="12" string="off" />
            <token id="13" string="as" />
            <token id="14" string="a" />
            <token id="15" string="cranky" />
            <token id="16" string="act" />
            <token id="17" string="of" />
            <token id="18" string="vengeance" />
            <token id="19" string="in" />
            <token id="20" string="a" />
            <token id="21" string="state" />
            <token id="22" string="not" />
            <token id="23" string="renowned" />
            <token id="24" string="as" />
            <token id="25" string="a" />
            <token id="26" string="political" />
            <token id="27" string="trend-setter" />
          </tokens>
        </chunking>
        <chunking id="12" string="a state not renowned as a political trend-setter" type="NP">
          <tokens>
            <token id="20" string="a" />
            <token id="21" string="state" />
            <token id="22" string="not" />
            <token id="23" string="renowned" />
            <token id="24" string="as" />
            <token id="25" string="a" />
            <token id="26" string="political" />
            <token id="27" string="trend-setter" />
          </tokens>
        </chunking>
        <chunking id="13" string="itself" type="NP">
          <tokens>
            <token id="2" string="itself" />
          </tokens>
        </chunking>
        <chunking id="14" string="a state" type="NP">
          <tokens>
            <token id="20" string="a" />
            <token id="21" string="state" />
          </tokens>
        </chunking>
        <chunking id="15" string="might be written off as a cranky act of vengeance in a state not renowned as a political trend-setter" type="VP">
          <tokens>
            <token id="9" string="might" />
            <token id="10" string="be" />
            <token id="11" string="written" />
            <token id="12" string="off" />
            <token id="13" string="as" />
            <token id="14" string="a" />
            <token id="15" string="cranky" />
            <token id="16" string="act" />
            <token id="17" string="of" />
            <token id="18" string="vengeance" />
            <token id="19" string="in" />
            <token id="20" string="a" />
            <token id="21" string="state" />
            <token id="22" string="not" />
            <token id="23" string="renowned" />
            <token id="24" string="as" />
            <token id="25" string="a" />
            <token id="26" string="political" />
            <token id="27" string="trend-setter" />
          </tokens>
        </chunking>
        <chunking id="16" string="not renowned as a political trend-setter" type="VP">
          <tokens>
            <token id="22" string="not" />
            <token id="23" string="renowned" />
            <token id="24" string="as" />
            <token id="25" string="a" />
            <token id="26" string="political" />
            <token id="27" string="trend-setter" />
          </tokens>
        </chunking>
        <chunking id="17" string="California and Colorado" type="NP">
          <tokens>
            <token id="39" string="California" />
            <token id="40" string="and" />
            <token id="41" string="Colorado" />
          </tokens>
        </chunking>
        <chunking id="18" string="November" type="NP">
          <tokens>
            <token id="37" string="November" />
          </tokens>
        </chunking>
        <chunking id="19" string="similar measures" type="NP">
          <tokens>
            <token id="30" string="similar" />
            <token id="31" string="measures" />
          </tokens>
        </chunking>
        <chunking id="20" string="be voted on in November in California and Colorado" type="VP">
          <tokens>
            <token id="33" string="be" />
            <token id="34" string="voted" />
            <token id="35" string="on" />
            <token id="36" string="in" />
            <token id="37" string="November" />
            <token id="38" string="in" />
            <token id="39" string="California" />
            <token id="40" string="and" />
            <token id="41" string="Colorado" />
          </tokens>
        </chunking>
        <chunking id="21" string="November in California and Colorado" type="NP">
          <tokens>
            <token id="37" string="November" />
            <token id="38" string="in" />
            <token id="39" string="California" />
            <token id="40" string="and" />
            <token id="41" string="Colorado" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">itself</governor>
          <dependent id="1">By</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">written</governor>
          <dependent id="2">itself</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">limitation</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">limitation</governor>
          <dependent id="5">term</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="11">written</governor>
          <dependent id="6">limitation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">Oklahoma</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">limitation</governor>
          <dependent id="8">Oklahoma</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">written</governor>
          <dependent id="9">might</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="11">written</governor>
          <dependent id="10">be</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">written</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="11">written</governor>
          <dependent id="12">off</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">act</governor>
          <dependent id="13">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">act</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">act</governor>
          <dependent id="15">cranky</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">written</governor>
          <dependent id="16">act</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">vengeance</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">act</governor>
          <dependent id="18">vengeance</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">state</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">state</governor>
          <dependent id="20">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">written</governor>
          <dependent id="21">state</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="23">renowned</governor>
          <dependent id="22">not</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="21">state</governor>
          <dependent id="23">renowned</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">trend-setter</governor>
          <dependent id="24">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">trend-setter</governor>
          <dependent id="25">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">trend-setter</governor>
          <dependent id="26">political</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">renowned</governor>
          <dependent id="27">trend-setter</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">written</governor>
          <dependent id="29">but</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">measures</governor>
          <dependent id="30">similar</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="34">voted</governor>
          <dependent id="31">measures</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="34">voted</governor>
          <dependent id="32">will</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="34">voted</governor>
          <dependent id="33">be</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">written</governor>
          <dependent id="34">voted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">November</governor>
          <dependent id="35">on</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">November</governor>
          <dependent id="36">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="34">voted</governor>
          <dependent id="37">November</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">California</governor>
          <dependent id="38">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="37">November</governor>
          <dependent id="39">California</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="39">California</governor>
          <dependent id="40">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="39">California</governor>
          <dependent id="41">Colorado</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Oklahoma" type="LOCATION" score="0.0">
          <tokens>
            <token id="8" string="Oklahoma" />
          </tokens>
        </entity>
        <entity id="2" string="California" type="LOCATION" score="0.0">
          <tokens>
            <token id="39" string="California" />
          </tokens>
        </entity>
        <entity id="3" string="Colorado" type="LOCATION" score="0.0">
          <tokens>
            <token id="41" string="Colorado" />
          </tokens>
        </entity>
        <entity id="4" string="November" type="DATE" score="0.0">
          <tokens>
            <token id="37" string="November" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>Eager for straws in the wind in an otherwise trendless political year, some journalists have seen in the Oklahoma vote a backlash against incumbents, a manifestation of public alienation and an ominous sign to the Democrats, the party that holds the largest number of legislative seats.</content>
      <tokens>
        <token id="1" string="Eager" lemma="Eager" stem="eager" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="straws" lemma="straw" stem="straw" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="wind" lemma="wind" stem="wind" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="otherwise" lemma="otherwise" stem="otherwis" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="trendless" lemma="trendless" stem="trendless" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="political" lemma="political" stem="polit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="journalists" lemma="journalist" stem="journalist" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="seen" lemma="see" stem="seen" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="Oklahoma" lemma="Oklahoma" stem="oklahoma" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="21" string="vote" lemma="vote" stem="vote" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="backlash" lemma="backlash" stem="backlash" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="incumbents" lemma="incumbent" stem="incumb" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="manifestation" lemma="manifestation" stem="manifest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="public" lemma="public" stem="public" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="alienation" lemma="alienation" stem="alien" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="ominous" lemma="ominous" stem="omin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="sign" lemma="sign" stem="sign" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="Democrats" lemma="Democrats" stem="democrat" pos="NNPS" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="39" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="party" lemma="party" stem="parti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="holds" lemma="hold" stem="hold" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="largest" lemma="largest" stem="largest" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="46" string="number" lemma="number" stem="number" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="47" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="48" string="legislative" lemma="legislative" stem="legisl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="49" string="seats" lemma="seat" stem="seat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="50" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (NNP Eager) (PP (IN for) (NP (NP (NNS straws)) (PP (IN in) (NP (NP (DT the) (NN wind)) (PP (IN in) (NP (DT an) (ADJP (RB otherwise) (JJ trendless)) (JJ political) (NN year))))))))) (, ,) (NP (DT some) (NNS journalists)) (VP (VBP have) (VP (VBN seen) (PP (IN in) (NP (DT the) (NNP Oklahoma))) (S (VP (VB vote) (NP (DT a) (NN backlash)) (PP (IN against) (NP (NP (NNS incumbents)) (, ,) (NP (NP (DT a) (NN manifestation)) (PP (IN of) (NP (JJ public) (NN alienation)))) (CC and) (NP (NP (DT an) (JJ ominous) (NN sign)) (PP (TO to) (NP (DT the) (NNPS Democrats)))))) (, ,) (NP (NP (DT the) (NN party)) (SBAR (WHNP (WDT that)) (S (VP (VBZ holds) (NP (NP (DT the) (JJS largest) (NN number)) (PP (IN of) (NP (JJ legislative) (NNS seats)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the party that holds the largest number of legislative seats" type="NP">
          <tokens>
            <token id="40" string="the" />
            <token id="41" string="party" />
            <token id="42" string="that" />
            <token id="43" string="holds" />
            <token id="44" string="the" />
            <token id="45" string="largest" />
            <token id="46" string="number" />
            <token id="47" string="of" />
            <token id="48" string="legislative" />
            <token id="49" string="seats" />
          </tokens>
        </chunking>
        <chunking id="2" string="the Oklahoma" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="Oklahoma" />
          </tokens>
        </chunking>
        <chunking id="3" string="the wind in an otherwise trendless political year" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="wind" />
            <token id="7" string="in" />
            <token id="8" string="an" />
            <token id="9" string="otherwise" />
            <token id="10" string="trendless" />
            <token id="11" string="political" />
            <token id="12" string="year" />
          </tokens>
        </chunking>
        <chunking id="4" string="have seen in the Oklahoma vote a backlash against incumbents , a manifestation of public alienation and an ominous sign to the Democrats , the party that holds the largest number of legislative seats" type="VP">
          <tokens>
            <token id="16" string="have" />
            <token id="17" string="seen" />
            <token id="18" string="in" />
            <token id="19" string="the" />
            <token id="20" string="Oklahoma" />
            <token id="21" string="vote" />
            <token id="22" string="a" />
            <token id="23" string="backlash" />
            <token id="24" string="against" />
            <token id="25" string="incumbents" />
            <token id="26" string="," />
            <token id="27" string="a" />
            <token id="28" string="manifestation" />
            <token id="29" string="of" />
            <token id="30" string="public" />
            <token id="31" string="alienation" />
            <token id="32" string="and" />
            <token id="33" string="an" />
            <token id="34" string="ominous" />
            <token id="35" string="sign" />
            <token id="36" string="to" />
            <token id="37" string="the" />
            <token id="38" string="Democrats" />
            <token id="39" string="," />
            <token id="40" string="the" />
            <token id="41" string="party" />
            <token id="42" string="that" />
            <token id="43" string="holds" />
            <token id="44" string="the" />
            <token id="45" string="largest" />
            <token id="46" string="number" />
            <token id="47" string="of" />
            <token id="48" string="legislative" />
            <token id="49" string="seats" />
          </tokens>
        </chunking>
        <chunking id="5" string="vote a backlash against incumbents , a manifestation of public alienation and an ominous sign to the Democrats , the party that holds the largest number of legislative seats" type="VP">
          <tokens>
            <token id="21" string="vote" />
            <token id="22" string="a" />
            <token id="23" string="backlash" />
            <token id="24" string="against" />
            <token id="25" string="incumbents" />
            <token id="26" string="," />
            <token id="27" string="a" />
            <token id="28" string="manifestation" />
            <token id="29" string="of" />
            <token id="30" string="public" />
            <token id="31" string="alienation" />
            <token id="32" string="and" />
            <token id="33" string="an" />
            <token id="34" string="ominous" />
            <token id="35" string="sign" />
            <token id="36" string="to" />
            <token id="37" string="the" />
            <token id="38" string="Democrats" />
            <token id="39" string="," />
            <token id="40" string="the" />
            <token id="41" string="party" />
            <token id="42" string="that" />
            <token id="43" string="holds" />
            <token id="44" string="the" />
            <token id="45" string="largest" />
            <token id="46" string="number" />
            <token id="47" string="of" />
            <token id="48" string="legislative" />
            <token id="49" string="seats" />
          </tokens>
        </chunking>
        <chunking id="6" string="the Democrats" type="NP">
          <tokens>
            <token id="37" string="the" />
            <token id="38" string="Democrats" />
          </tokens>
        </chunking>
        <chunking id="7" string="the wind" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="wind" />
          </tokens>
        </chunking>
        <chunking id="8" string="seen in the Oklahoma vote a backlash against incumbents , a manifestation of public alienation and an ominous sign to the Democrats , the party that holds the largest number of legislative seats" type="VP">
          <tokens>
            <token id="17" string="seen" />
            <token id="18" string="in" />
            <token id="19" string="the" />
            <token id="20" string="Oklahoma" />
            <token id="21" string="vote" />
            <token id="22" string="a" />
            <token id="23" string="backlash" />
            <token id="24" string="against" />
            <token id="25" string="incumbents" />
            <token id="26" string="," />
            <token id="27" string="a" />
            <token id="28" string="manifestation" />
            <token id="29" string="of" />
            <token id="30" string="public" />
            <token id="31" string="alienation" />
            <token id="32" string="and" />
            <token id="33" string="an" />
            <token id="34" string="ominous" />
            <token id="35" string="sign" />
            <token id="36" string="to" />
            <token id="37" string="the" />
            <token id="38" string="Democrats" />
            <token id="39" string="," />
            <token id="40" string="the" />
            <token id="41" string="party" />
            <token id="42" string="that" />
            <token id="43" string="holds" />
            <token id="44" string="the" />
            <token id="45" string="largest" />
            <token id="46" string="number" />
            <token id="47" string="of" />
            <token id="48" string="legislative" />
            <token id="49" string="seats" />
          </tokens>
        </chunking>
        <chunking id="9" string="the party" type="NP">
          <tokens>
            <token id="40" string="the" />
            <token id="41" string="party" />
          </tokens>
        </chunking>
        <chunking id="10" string="Eager for straws in the wind in an otherwise trendless political year" type="VP">
          <tokens>
            <token id="1" string="Eager" />
            <token id="2" string="for" />
            <token id="3" string="straws" />
            <token id="4" string="in" />
            <token id="5" string="the" />
            <token id="6" string="wind" />
            <token id="7" string="in" />
            <token id="8" string="an" />
            <token id="9" string="otherwise" />
            <token id="10" string="trendless" />
            <token id="11" string="political" />
            <token id="12" string="year" />
          </tokens>
        </chunking>
        <chunking id="11" string="incumbents" type="NP">
          <tokens>
            <token id="25" string="incumbents" />
          </tokens>
        </chunking>
        <chunking id="12" string="holds the largest number of legislative seats" type="VP">
          <tokens>
            <token id="43" string="holds" />
            <token id="44" string="the" />
            <token id="45" string="largest" />
            <token id="46" string="number" />
            <token id="47" string="of" />
            <token id="48" string="legislative" />
            <token id="49" string="seats" />
          </tokens>
        </chunking>
        <chunking id="13" string="legislative seats" type="NP">
          <tokens>
            <token id="48" string="legislative" />
            <token id="49" string="seats" />
          </tokens>
        </chunking>
        <chunking id="14" string="straws" type="NP">
          <tokens>
            <token id="3" string="straws" />
          </tokens>
        </chunking>
        <chunking id="15" string="a manifestation of public alienation" type="NP">
          <tokens>
            <token id="27" string="a" />
            <token id="28" string="manifestation" />
            <token id="29" string="of" />
            <token id="30" string="public" />
            <token id="31" string="alienation" />
          </tokens>
        </chunking>
        <chunking id="16" string="a manifestation" type="NP">
          <tokens>
            <token id="27" string="a" />
            <token id="28" string="manifestation" />
          </tokens>
        </chunking>
        <chunking id="17" string="straws in the wind in an otherwise trendless political year" type="NP">
          <tokens>
            <token id="3" string="straws" />
            <token id="4" string="in" />
            <token id="5" string="the" />
            <token id="6" string="wind" />
            <token id="7" string="in" />
            <token id="8" string="an" />
            <token id="9" string="otherwise" />
            <token id="10" string="trendless" />
            <token id="11" string="political" />
            <token id="12" string="year" />
          </tokens>
        </chunking>
        <chunking id="18" string="incumbents , a manifestation of public alienation and an ominous sign to the Democrats" type="NP">
          <tokens>
            <token id="25" string="incumbents" />
            <token id="26" string="," />
            <token id="27" string="a" />
            <token id="28" string="manifestation" />
            <token id="29" string="of" />
            <token id="30" string="public" />
            <token id="31" string="alienation" />
            <token id="32" string="and" />
            <token id="33" string="an" />
            <token id="34" string="ominous" />
            <token id="35" string="sign" />
            <token id="36" string="to" />
            <token id="37" string="the" />
            <token id="38" string="Democrats" />
          </tokens>
        </chunking>
        <chunking id="19" string="an ominous sign" type="NP">
          <tokens>
            <token id="33" string="an" />
            <token id="34" string="ominous" />
            <token id="35" string="sign" />
          </tokens>
        </chunking>
        <chunking id="20" string="the largest number of legislative seats" type="NP">
          <tokens>
            <token id="44" string="the" />
            <token id="45" string="largest" />
            <token id="46" string="number" />
            <token id="47" string="of" />
            <token id="48" string="legislative" />
            <token id="49" string="seats" />
          </tokens>
        </chunking>
        <chunking id="21" string="an ominous sign to the Democrats" type="NP">
          <tokens>
            <token id="33" string="an" />
            <token id="34" string="ominous" />
            <token id="35" string="sign" />
            <token id="36" string="to" />
            <token id="37" string="the" />
            <token id="38" string="Democrats" />
          </tokens>
        </chunking>
        <chunking id="22" string="an otherwise trendless political year" type="NP">
          <tokens>
            <token id="8" string="an" />
            <token id="9" string="otherwise" />
            <token id="10" string="trendless" />
            <token id="11" string="political" />
            <token id="12" string="year" />
          </tokens>
        </chunking>
        <chunking id="23" string="the largest number" type="NP">
          <tokens>
            <token id="44" string="the" />
            <token id="45" string="largest" />
            <token id="46" string="number" />
          </tokens>
        </chunking>
        <chunking id="24" string="otherwise trendless" type="ADJP">
          <tokens>
            <token id="9" string="otherwise" />
            <token id="10" string="trendless" />
          </tokens>
        </chunking>
        <chunking id="25" string="a backlash" type="NP">
          <tokens>
            <token id="22" string="a" />
            <token id="23" string="backlash" />
          </tokens>
        </chunking>
        <chunking id="26" string="public alienation" type="NP">
          <tokens>
            <token id="30" string="public" />
            <token id="31" string="alienation" />
          </tokens>
        </chunking>
        <chunking id="27" string="that holds the largest number of legislative seats" type="SBAR">
          <tokens>
            <token id="42" string="that" />
            <token id="43" string="holds" />
            <token id="44" string="the" />
            <token id="45" string="largest" />
            <token id="46" string="number" />
            <token id="47" string="of" />
            <token id="48" string="legislative" />
            <token id="49" string="seats" />
          </tokens>
        </chunking>
        <chunking id="28" string="some journalists" type="NP">
          <tokens>
            <token id="14" string="some" />
            <token id="15" string="journalists" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="ccomp">
          <governor id="17">seen</governor>
          <dependent id="1">Eager</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">straws</governor>
          <dependent id="2">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Eager</governor>
          <dependent id="3">straws</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">wind</governor>
          <dependent id="4">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">wind</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">straws</governor>
          <dependent id="6">wind</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">year</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">year</governor>
          <dependent id="8">an</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">trendless</governor>
          <dependent id="9">otherwise</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">year</governor>
          <dependent id="10">trendless</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">year</governor>
          <dependent id="11">political</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">wind</governor>
          <dependent id="12">year</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">journalists</governor>
          <dependent id="14">some</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">seen</governor>
          <dependent id="15">journalists</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="17">seen</governor>
          <dependent id="16">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">seen</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">Oklahoma</governor>
          <dependent id="18">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">Oklahoma</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">seen</governor>
          <dependent id="20">Oklahoma</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">seen</governor>
          <dependent id="21">vote</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">backlash</governor>
          <dependent id="22">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">vote</governor>
          <dependent id="23">backlash</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">incumbents</governor>
          <dependent id="24">against</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">vote</governor>
          <dependent id="25">incumbents</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">manifestation</governor>
          <dependent id="27">a</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="25">incumbents</governor>
          <dependent id="28">manifestation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">alienation</governor>
          <dependent id="29">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">alienation</governor>
          <dependent id="30">public</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">manifestation</governor>
          <dependent id="31">alienation</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="25">incumbents</governor>
          <dependent id="32">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">sign</governor>
          <dependent id="33">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="35">sign</governor>
          <dependent id="34">ominous</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="25">incumbents</governor>
          <dependent id="35">sign</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">Democrats</governor>
          <dependent id="36">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="38">Democrats</governor>
          <dependent id="37">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="35">sign</governor>
          <dependent id="38">Democrats</dependent>
        </dependency>
        <dependency type="det">
          <governor id="41">party</governor>
          <dependent id="40">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">vote</governor>
          <dependent id="41">party</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="43">holds</governor>
          <dependent id="42">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="41">party</governor>
          <dependent id="43">holds</dependent>
        </dependency>
        <dependency type="det">
          <governor id="46">number</governor>
          <dependent id="44">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="46">number</governor>
          <dependent id="45">largest</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="43">holds</governor>
          <dependent id="46">number</dependent>
        </dependency>
        <dependency type="case">
          <governor id="49">seats</governor>
          <dependent id="47">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="49">seats</governor>
          <dependent id="48">legislative</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="46">number</governor>
          <dependent id="49">seats</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Democrats" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="38" string="Democrats" />
          </tokens>
        </entity>
        <entity id="2" string="Oklahoma" type="LOCATION" score="0.0">
          <tokens>
            <token id="20" string="Oklahoma" />
          </tokens>
        </entity>
        <entity id="3" string="year" type="DURATION" score="0.0">
          <tokens>
            <token id="12" string="year" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>The Oklahoma referendum is none of these.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="Oklahoma" lemma="Oklahoma" stem="oklahoma" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="true" />
        <token id="3" string="referendum" lemma="referendum" stem="referendum" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="none" lemma="none" stem="none" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="these" lemma="these" stem="these" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNP Oklahoma) (NN referendum)) (VP (VBZ is) (NP (NP (NN none)) (PP (IN of) (NP (DT these))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is none of these" type="VP">
          <tokens>
            <token id="4" string="is" />
            <token id="5" string="none" />
            <token id="6" string="of" />
            <token id="7" string="these" />
          </tokens>
        </chunking>
        <chunking id="2" string="these" type="NP">
          <tokens>
            <token id="7" string="these" />
          </tokens>
        </chunking>
        <chunking id="3" string="The Oklahoma referendum" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Oklahoma" />
            <token id="3" string="referendum" />
          </tokens>
        </chunking>
        <chunking id="4" string="none" type="NP">
          <tokens>
            <token id="5" string="none" />
          </tokens>
        </chunking>
        <chunking id="5" string="none of these" type="NP">
          <tokens>
            <token id="5" string="none" />
            <token id="6" string="of" />
            <token id="7" string="these" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">referendum</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">referendum</governor>
          <dependent id="2">Oklahoma</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">none</governor>
          <dependent id="3">referendum</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">none</governor>
          <dependent id="4">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">none</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">these</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">none</governor>
          <dependent id="7">these</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Oklahoma" type="LOCATION" score="0.0">
          <tokens>
            <token id="2" string="Oklahoma" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>It is, rather, the kind of minor political tempest that gets highlighted briefly by the media, is copied in a few places and then disappears.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="rather" lemma="rather" stem="rather" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="kind" lemma="kind" stem="kind" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="minor" lemma="minor" stem="minor" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="political" lemma="political" stem="polit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="tempest" lemma="tempest" stem="tempest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="gets" lemma="get" stem="get" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="highlighted" lemma="highlight" stem="highlight" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="briefly" lemma="briefly" stem="briefli" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="media" lemma="media" stem="media" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="copied" lemma="copy" stem="copi" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="few" lemma="few" stem="few" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="places" lemma="place" stem="place" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="disappears" lemma="disappear" stem="disappear" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBZ is) (, ,) (ADVP (RB rather)) (, ,) (S (NP (NP (DT the) (NN kind)) (PP (IN of) (NP (NP (JJ minor) (JJ political) (NN tempest)) (SBAR (WHNP (WDT that)) (S (VP (VP (VBZ gets) (VP (VBN highlighted) (ADVP (NN briefly)) (PP (IN by) (NP (DT the) (NNS media))))) (, ,) (VP (VBZ is) (VP (VBN copied) (PP (IN in) (NP (DT a) (JJ few) (NNS places))))) (CC and) (VP (ADVP (RB then)) (VBZ disappears)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the kind of minor political tempest that gets highlighted briefly by the media , is copied in a few places and then disappears" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="kind" />
            <token id="8" string="of" />
            <token id="9" string="minor" />
            <token id="10" string="political" />
            <token id="11" string="tempest" />
            <token id="12" string="that" />
            <token id="13" string="gets" />
            <token id="14" string="highlighted" />
            <token id="15" string="briefly" />
            <token id="16" string="by" />
            <token id="17" string="the" />
            <token id="18" string="media" />
            <token id="19" string="," />
            <token id="20" string="is" />
            <token id="21" string="copied" />
            <token id="22" string="in" />
            <token id="23" string="a" />
            <token id="24" string="few" />
            <token id="25" string="places" />
            <token id="26" string="and" />
            <token id="27" string="then" />
            <token id="28" string="disappears" />
          </tokens>
        </chunking>
        <chunking id="2" string="minor political tempest that gets highlighted briefly by the media , is copied in a few places and then disappears" type="NP">
          <tokens>
            <token id="9" string="minor" />
            <token id="10" string="political" />
            <token id="11" string="tempest" />
            <token id="12" string="that" />
            <token id="13" string="gets" />
            <token id="14" string="highlighted" />
            <token id="15" string="briefly" />
            <token id="16" string="by" />
            <token id="17" string="the" />
            <token id="18" string="media" />
            <token id="19" string="," />
            <token id="20" string="is" />
            <token id="21" string="copied" />
            <token id="22" string="in" />
            <token id="23" string="a" />
            <token id="24" string="few" />
            <token id="25" string="places" />
            <token id="26" string="and" />
            <token id="27" string="then" />
            <token id="28" string="disappears" />
          </tokens>
        </chunking>
        <chunking id="3" string="gets highlighted briefly by the media , is copied in a few places and then disappears" type="VP">
          <tokens>
            <token id="13" string="gets" />
            <token id="14" string="highlighted" />
            <token id="15" string="briefly" />
            <token id="16" string="by" />
            <token id="17" string="the" />
            <token id="18" string="media" />
            <token id="19" string="," />
            <token id="20" string="is" />
            <token id="21" string="copied" />
            <token id="22" string="in" />
            <token id="23" string="a" />
            <token id="24" string="few" />
            <token id="25" string="places" />
            <token id="26" string="and" />
            <token id="27" string="then" />
            <token id="28" string="disappears" />
          </tokens>
        </chunking>
        <chunking id="4" string="is , rather , the kind of minor political tempest that gets highlighted briefly by the media , is copied in a few places and then disappears" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="," />
            <token id="4" string="rather" />
            <token id="5" string="," />
            <token id="6" string="the" />
            <token id="7" string="kind" />
            <token id="8" string="of" />
            <token id="9" string="minor" />
            <token id="10" string="political" />
            <token id="11" string="tempest" />
            <token id="12" string="that" />
            <token id="13" string="gets" />
            <token id="14" string="highlighted" />
            <token id="15" string="briefly" />
            <token id="16" string="by" />
            <token id="17" string="the" />
            <token id="18" string="media" />
            <token id="19" string="," />
            <token id="20" string="is" />
            <token id="21" string="copied" />
            <token id="22" string="in" />
            <token id="23" string="a" />
            <token id="24" string="few" />
            <token id="25" string="places" />
            <token id="26" string="and" />
            <token id="27" string="then" />
            <token id="28" string="disappears" />
          </tokens>
        </chunking>
        <chunking id="5" string="highlighted briefly by the media" type="VP">
          <tokens>
            <token id="14" string="highlighted" />
            <token id="15" string="briefly" />
            <token id="16" string="by" />
            <token id="17" string="the" />
            <token id="18" string="media" />
          </tokens>
        </chunking>
        <chunking id="6" string="the media" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="media" />
          </tokens>
        </chunking>
        <chunking id="7" string="a few places" type="NP">
          <tokens>
            <token id="23" string="a" />
            <token id="24" string="few" />
            <token id="25" string="places" />
          </tokens>
        </chunking>
        <chunking id="8" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="9" string="then disappears" type="VP">
          <tokens>
            <token id="27" string="then" />
            <token id="28" string="disappears" />
          </tokens>
        </chunking>
        <chunking id="10" string="minor political tempest" type="NP">
          <tokens>
            <token id="9" string="minor" />
            <token id="10" string="political" />
            <token id="11" string="tempest" />
          </tokens>
        </chunking>
        <chunking id="11" string="copied in a few places" type="VP">
          <tokens>
            <token id="21" string="copied" />
            <token id="22" string="in" />
            <token id="23" string="a" />
            <token id="24" string="few" />
            <token id="25" string="places" />
          </tokens>
        </chunking>
        <chunking id="12" string="gets highlighted briefly by the media" type="VP">
          <tokens>
            <token id="13" string="gets" />
            <token id="14" string="highlighted" />
            <token id="15" string="briefly" />
            <token id="16" string="by" />
            <token id="17" string="the" />
            <token id="18" string="media" />
          </tokens>
        </chunking>
        <chunking id="13" string="that gets highlighted briefly by the media , is copied in a few places and then disappears" type="SBAR">
          <tokens>
            <token id="12" string="that" />
            <token id="13" string="gets" />
            <token id="14" string="highlighted" />
            <token id="15" string="briefly" />
            <token id="16" string="by" />
            <token id="17" string="the" />
            <token id="18" string="media" />
            <token id="19" string="," />
            <token id="20" string="is" />
            <token id="21" string="copied" />
            <token id="22" string="in" />
            <token id="23" string="a" />
            <token id="24" string="few" />
            <token id="25" string="places" />
            <token id="26" string="and" />
            <token id="27" string="then" />
            <token id="28" string="disappears" />
          </tokens>
        </chunking>
        <chunking id="14" string="the kind" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="kind" />
          </tokens>
        </chunking>
        <chunking id="15" string="is copied in a few places" type="VP">
          <tokens>
            <token id="20" string="is" />
            <token id="21" string="copied" />
            <token id="22" string="in" />
            <token id="23" string="a" />
            <token id="24" string="few" />
            <token id="25" string="places" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">is</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="2">is</governor>
          <dependent id="4">rather</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">kind</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="2">is</governor>
          <dependent id="7">kind</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">tempest</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">tempest</governor>
          <dependent id="9">minor</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">tempest</governor>
          <dependent id="10">political</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">kind</governor>
          <dependent id="11">tempest</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="14">highlighted</governor>
          <dependent id="12">that</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="14">highlighted</governor>
          <dependent id="13">gets</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="11">tempest</governor>
          <dependent id="14">highlighted</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">highlighted</governor>
          <dependent id="15">briefly</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">media</governor>
          <dependent id="16">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">media</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">highlighted</governor>
          <dependent id="18">media</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="21">copied</governor>
          <dependent id="20">is</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">highlighted</governor>
          <dependent id="21">copied</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">places</governor>
          <dependent id="22">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">places</governor>
          <dependent id="23">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">places</governor>
          <dependent id="24">few</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">copied</governor>
          <dependent id="25">places</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">highlighted</governor>
          <dependent id="26">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="28">disappears</governor>
          <dependent id="27">then</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">highlighted</governor>
          <dependent id="28">disappears</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>It is Republicans, naturally enough, who seem to be the most enthusiastic puffers of term limitation, since they have the most to gain, at least in the short term, from an indiscriminate clean-out of the nation&amp;apost;s deliberative bodies.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Republicans" lemma="Republicans" stem="republican" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="naturally" lemma="naturally" stem="natur" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="enough" lemma="enough" stem="enough" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="seem" lemma="seem" stem="seem" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="13" string="most" lemma="most" stem="most" pos="RBS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="14" string="enthusiastic" lemma="enthusiastic" stem="enthusiast" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="15" string="puffers" lemma="puffer" stem="puffer" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="17" string="term" lemma="term" stem="term" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="18" string="limitation" lemma="limitation" stem="limit" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="most" lemma="most" stem="most" pos="RBS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="gain" lemma="gain" stem="gain" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="27" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="28" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="29" string="least" lemma="least" stem="least" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="30" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="32" string="short" lemma="short" stem="short" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="33" string="term" lemma="term" stem="term" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="34" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="35" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="36" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="37" string="indiscriminate" lemma="indiscriminate" stem="indiscrimin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="38" string="clean-out" lemma="clean-out" stem="clean-out" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="39" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="40" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="41" string="nation" lemma="nation" stem="nation" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="42" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="43" string="deliberative" lemma="deliberative" stem="delib" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="44" string="bodies" lemma="body" stem="bodi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="45" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBZ is) (NP (NP (NNPS Republicans)) (, ,) (ADJP (RB naturally) (RB enough)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBP seem) (S (VP (TO to) (VP (VB be) (NP (NP (DT the) (ADJP (RBS most) (JJ enthusiastic)) (NNS puffers)) (PP (IN of) (NP (NN term) (NN limitation)))) (, ,) (SBAR (IN since) (S (NP (PRP they)) (VP (VBP have) (NP (DT the) (RBS most)))))))) (S (VP (TO to) (VP (VB gain) (, ,) (ADVP (ADVP (IN at) (JJS least)) (PP (IN in) (NP (DT the) (JJ short) (NN term)))) (, ,) (PP (IN from) (NP (NP (DT an) (JJ indiscriminate) (NN clean-out)) (PP (IN of) (NP (NP (DT the) (NN nation) (POS 's)) (JJ deliberative) (NNS bodies))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the nation 's deliberative bodies" type="NP">
          <tokens>
            <token id="40" string="the" />
            <token id="41" string="nation" />
            <token id="42" string="'s" />
            <token id="43" string="deliberative" />
            <token id="44" string="bodies" />
          </tokens>
        </chunking>
        <chunking id="2" string="who seem to be the most enthusiastic puffers of term limitation , since they have the most to gain , at least in the short term , from an indiscriminate clean-out of the nation 's deliberative bodies" type="SBAR">
          <tokens>
            <token id="8" string="who" />
            <token id="9" string="seem" />
            <token id="10" string="to" />
            <token id="11" string="be" />
            <token id="12" string="the" />
            <token id="13" string="most" />
            <token id="14" string="enthusiastic" />
            <token id="15" string="puffers" />
            <token id="16" string="of" />
            <token id="17" string="term" />
            <token id="18" string="limitation" />
            <token id="19" string="," />
            <token id="20" string="since" />
            <token id="21" string="they" />
            <token id="22" string="have" />
            <token id="23" string="the" />
            <token id="24" string="most" />
            <token id="25" string="to" />
            <token id="26" string="gain" />
            <token id="27" string="," />
            <token id="28" string="at" />
            <token id="29" string="least" />
            <token id="30" string="in" />
            <token id="31" string="the" />
            <token id="32" string="short" />
            <token id="33" string="term" />
            <token id="34" string="," />
            <token id="35" string="from" />
            <token id="36" string="an" />
            <token id="37" string="indiscriminate" />
            <token id="38" string="clean-out" />
            <token id="39" string="of" />
            <token id="40" string="the" />
            <token id="41" string="nation" />
            <token id="42" string="'s" />
            <token id="43" string="deliberative" />
            <token id="44" string="bodies" />
          </tokens>
        </chunking>
        <chunking id="3" string="the most enthusiastic puffers" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="most" />
            <token id="14" string="enthusiastic" />
            <token id="15" string="puffers" />
          </tokens>
        </chunking>
        <chunking id="4" string="to gain , at least in the short term , from an indiscriminate clean-out of the nation 's deliberative bodies" type="VP">
          <tokens>
            <token id="25" string="to" />
            <token id="26" string="gain" />
            <token id="27" string="," />
            <token id="28" string="at" />
            <token id="29" string="least" />
            <token id="30" string="in" />
            <token id="31" string="the" />
            <token id="32" string="short" />
            <token id="33" string="term" />
            <token id="34" string="," />
            <token id="35" string="from" />
            <token id="36" string="an" />
            <token id="37" string="indiscriminate" />
            <token id="38" string="clean-out" />
            <token id="39" string="of" />
            <token id="40" string="the" />
            <token id="41" string="nation" />
            <token id="42" string="'s" />
            <token id="43" string="deliberative" />
            <token id="44" string="bodies" />
          </tokens>
        </chunking>
        <chunking id="5" string="to be the most enthusiastic puffers of term limitation , since they have the most" type="VP">
          <tokens>
            <token id="10" string="to" />
            <token id="11" string="be" />
            <token id="12" string="the" />
            <token id="13" string="most" />
            <token id="14" string="enthusiastic" />
            <token id="15" string="puffers" />
            <token id="16" string="of" />
            <token id="17" string="term" />
            <token id="18" string="limitation" />
            <token id="19" string="," />
            <token id="20" string="since" />
            <token id="21" string="they" />
            <token id="22" string="have" />
            <token id="23" string="the" />
            <token id="24" string="most" />
          </tokens>
        </chunking>
        <chunking id="6" string="Republicans , naturally enough , who seem to be the most enthusiastic puffers of term limitation , since they have the most to gain , at least in the short term , from an indiscriminate clean-out of the nation 's deliberative bodies" type="NP">
          <tokens>
            <token id="3" string="Republicans" />
            <token id="4" string="," />
            <token id="5" string="naturally" />
            <token id="6" string="enough" />
            <token id="7" string="," />
            <token id="8" string="who" />
            <token id="9" string="seem" />
            <token id="10" string="to" />
            <token id="11" string="be" />
            <token id="12" string="the" />
            <token id="13" string="most" />
            <token id="14" string="enthusiastic" />
            <token id="15" string="puffers" />
            <token id="16" string="of" />
            <token id="17" string="term" />
            <token id="18" string="limitation" />
            <token id="19" string="," />
            <token id="20" string="since" />
            <token id="21" string="they" />
            <token id="22" string="have" />
            <token id="23" string="the" />
            <token id="24" string="most" />
            <token id="25" string="to" />
            <token id="26" string="gain" />
            <token id="27" string="," />
            <token id="28" string="at" />
            <token id="29" string="least" />
            <token id="30" string="in" />
            <token id="31" string="the" />
            <token id="32" string="short" />
            <token id="33" string="term" />
            <token id="34" string="," />
            <token id="35" string="from" />
            <token id="36" string="an" />
            <token id="37" string="indiscriminate" />
            <token id="38" string="clean-out" />
            <token id="39" string="of" />
            <token id="40" string="the" />
            <token id="41" string="nation" />
            <token id="42" string="'s" />
            <token id="43" string="deliberative" />
            <token id="44" string="bodies" />
          </tokens>
        </chunking>
        <chunking id="7" string="most enthusiastic" type="ADJP">
          <tokens>
            <token id="13" string="most" />
            <token id="14" string="enthusiastic" />
          </tokens>
        </chunking>
        <chunking id="8" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="9" string="gain , at least in the short term , from an indiscriminate clean-out of the nation 's deliberative bodies" type="VP">
          <tokens>
            <token id="26" string="gain" />
            <token id="27" string="," />
            <token id="28" string="at" />
            <token id="29" string="least" />
            <token id="30" string="in" />
            <token id="31" string="the" />
            <token id="32" string="short" />
            <token id="33" string="term" />
            <token id="34" string="," />
            <token id="35" string="from" />
            <token id="36" string="an" />
            <token id="37" string="indiscriminate" />
            <token id="38" string="clean-out" />
            <token id="39" string="of" />
            <token id="40" string="the" />
            <token id="41" string="nation" />
            <token id="42" string="'s" />
            <token id="43" string="deliberative" />
            <token id="44" string="bodies" />
          </tokens>
        </chunking>
        <chunking id="10" string="an indiscriminate clean-out of the nation 's deliberative bodies" type="NP">
          <tokens>
            <token id="36" string="an" />
            <token id="37" string="indiscriminate" />
            <token id="38" string="clean-out" />
            <token id="39" string="of" />
            <token id="40" string="the" />
            <token id="41" string="nation" />
            <token id="42" string="'s" />
            <token id="43" string="deliberative" />
            <token id="44" string="bodies" />
          </tokens>
        </chunking>
        <chunking id="11" string="be the most enthusiastic puffers of term limitation , since they have the most" type="VP">
          <tokens>
            <token id="11" string="be" />
            <token id="12" string="the" />
            <token id="13" string="most" />
            <token id="14" string="enthusiastic" />
            <token id="15" string="puffers" />
            <token id="16" string="of" />
            <token id="17" string="term" />
            <token id="18" string="limitation" />
            <token id="19" string="," />
            <token id="20" string="since" />
            <token id="21" string="they" />
            <token id="22" string="have" />
            <token id="23" string="the" />
            <token id="24" string="most" />
          </tokens>
        </chunking>
        <chunking id="12" string="the nation 's" type="NP">
          <tokens>
            <token id="40" string="the" />
            <token id="41" string="nation" />
            <token id="42" string="'s" />
          </tokens>
        </chunking>
        <chunking id="13" string="Republicans" type="NP">
          <tokens>
            <token id="3" string="Republicans" />
          </tokens>
        </chunking>
        <chunking id="14" string="they" type="NP">
          <tokens>
            <token id="21" string="they" />
          </tokens>
        </chunking>
        <chunking id="15" string="the most" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="most" />
          </tokens>
        </chunking>
        <chunking id="16" string="the most enthusiastic puffers of term limitation" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="most" />
            <token id="14" string="enthusiastic" />
            <token id="15" string="puffers" />
            <token id="16" string="of" />
            <token id="17" string="term" />
            <token id="18" string="limitation" />
          </tokens>
        </chunking>
        <chunking id="17" string="have the most" type="VP">
          <tokens>
            <token id="22" string="have" />
            <token id="23" string="the" />
            <token id="24" string="most" />
          </tokens>
        </chunking>
        <chunking id="18" string="since they have the most" type="SBAR">
          <tokens>
            <token id="20" string="since" />
            <token id="21" string="they" />
            <token id="22" string="have" />
            <token id="23" string="the" />
            <token id="24" string="most" />
          </tokens>
        </chunking>
        <chunking id="19" string="seem to be the most enthusiastic puffers of term limitation , since they have the most to gain , at least in the short term , from an indiscriminate clean-out of the nation 's deliberative bodies" type="VP">
          <tokens>
            <token id="9" string="seem" />
            <token id="10" string="to" />
            <token id="11" string="be" />
            <token id="12" string="the" />
            <token id="13" string="most" />
            <token id="14" string="enthusiastic" />
            <token id="15" string="puffers" />
            <token id="16" string="of" />
            <token id="17" string="term" />
            <token id="18" string="limitation" />
            <token id="19" string="," />
            <token id="20" string="since" />
            <token id="21" string="they" />
            <token id="22" string="have" />
            <token id="23" string="the" />
            <token id="24" string="most" />
            <token id="25" string="to" />
            <token id="26" string="gain" />
            <token id="27" string="," />
            <token id="28" string="at" />
            <token id="29" string="least" />
            <token id="30" string="in" />
            <token id="31" string="the" />
            <token id="32" string="short" />
            <token id="33" string="term" />
            <token id="34" string="," />
            <token id="35" string="from" />
            <token id="36" string="an" />
            <token id="37" string="indiscriminate" />
            <token id="38" string="clean-out" />
            <token id="39" string="of" />
            <token id="40" string="the" />
            <token id="41" string="nation" />
            <token id="42" string="'s" />
            <token id="43" string="deliberative" />
            <token id="44" string="bodies" />
          </tokens>
        </chunking>
        <chunking id="20" string="term limitation" type="NP">
          <tokens>
            <token id="17" string="term" />
            <token id="18" string="limitation" />
          </tokens>
        </chunking>
        <chunking id="21" string="naturally enough" type="ADJP">
          <tokens>
            <token id="5" string="naturally" />
            <token id="6" string="enough" />
          </tokens>
        </chunking>
        <chunking id="22" string="the short term" type="NP">
          <tokens>
            <token id="31" string="the" />
            <token id="32" string="short" />
            <token id="33" string="term" />
          </tokens>
        </chunking>
        <chunking id="23" string="is Republicans , naturally enough , who seem to be the most enthusiastic puffers of term limitation , since they have the most to gain , at least in the short term , from an indiscriminate clean-out of the nation 's deliberative bodies" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="Republicans" />
            <token id="4" string="," />
            <token id="5" string="naturally" />
            <token id="6" string="enough" />
            <token id="7" string="," />
            <token id="8" string="who" />
            <token id="9" string="seem" />
            <token id="10" string="to" />
            <token id="11" string="be" />
            <token id="12" string="the" />
            <token id="13" string="most" />
            <token id="14" string="enthusiastic" />
            <token id="15" string="puffers" />
            <token id="16" string="of" />
            <token id="17" string="term" />
            <token id="18" string="limitation" />
            <token id="19" string="," />
            <token id="20" string="since" />
            <token id="21" string="they" />
            <token id="22" string="have" />
            <token id="23" string="the" />
            <token id="24" string="most" />
            <token id="25" string="to" />
            <token id="26" string="gain" />
            <token id="27" string="," />
            <token id="28" string="at" />
            <token id="29" string="least" />
            <token id="30" string="in" />
            <token id="31" string="the" />
            <token id="32" string="short" />
            <token id="33" string="term" />
            <token id="34" string="," />
            <token id="35" string="from" />
            <token id="36" string="an" />
            <token id="37" string="indiscriminate" />
            <token id="38" string="clean-out" />
            <token id="39" string="of" />
            <token id="40" string="the" />
            <token id="41" string="nation" />
            <token id="42" string="'s" />
            <token id="43" string="deliberative" />
            <token id="44" string="bodies" />
          </tokens>
        </chunking>
        <chunking id="24" string="an indiscriminate clean-out" type="NP">
          <tokens>
            <token id="36" string="an" />
            <token id="37" string="indiscriminate" />
            <token id="38" string="clean-out" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">Republicans</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="3">Republicans</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">Republicans</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">enough</governor>
          <dependent id="5">naturally</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">Republicans</governor>
          <dependent id="6">enough</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">seem</governor>
          <dependent id="8">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="3">Republicans</governor>
          <dependent id="9">seem</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">puffers</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="15">puffers</governor>
          <dependent id="11">be</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">puffers</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">enthusiastic</governor>
          <dependent id="13">most</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">puffers</governor>
          <dependent id="14">enthusiastic</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">seem</governor>
          <dependent id="15">puffers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">limitation</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">limitation</governor>
          <dependent id="17">term</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">puffers</governor>
          <dependent id="18">limitation</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">have</governor>
          <dependent id="20">since</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">have</governor>
          <dependent id="21">they</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="15">puffers</governor>
          <dependent id="22">have</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">have</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="23">the</governor>
          <dependent id="24">most</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="26">gain</governor>
          <dependent id="25">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">seem</governor>
          <dependent id="26">gain</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="26">gain</governor>
          <dependent id="28">at</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="28">at</governor>
          <dependent id="29">least</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">term</governor>
          <dependent id="30">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">term</governor>
          <dependent id="31">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="33">term</governor>
          <dependent id="32">short</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">at</governor>
          <dependent id="33">term</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">clean-out</governor>
          <dependent id="35">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="38">clean-out</governor>
          <dependent id="36">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="38">clean-out</governor>
          <dependent id="37">indiscriminate</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">gain</governor>
          <dependent id="38">clean-out</dependent>
        </dependency>
        <dependency type="case">
          <governor id="44">bodies</governor>
          <dependent id="39">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="41">nation</governor>
          <dependent id="40">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="44">bodies</governor>
          <dependent id="41">nation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="41">nation</governor>
          <dependent id="42">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="44">bodies</governor>
          <dependent id="43">deliberative</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="38">clean-out</governor>
          <dependent id="44">bodies</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Republicans" type="MISC" score="0.0">
          <tokens>
            <token id="3" string="Republicans" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>What makes term limitation such a singularly inappropriate tool is the almost total lack of connection between the fancied sins of the lawmakers and the discipline proposed.</content>
      <tokens>
        <token id="1" string="What" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="makes" lemma="make" stem="make" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="term" lemma="term" stem="term" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="limitation" lemma="limitation" stem="limit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="singularly" lemma="singularly" stem="singularli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="inappropriate" lemma="inappropriate" stem="inappropri" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="tool" lemma="tool" stem="tool" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="almost" lemma="almost" stem="almost" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="total" lemma="total" stem="total" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="lack" lemma="lack" stem="lack" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="connection" lemma="connection" stem="connect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="between" lemma="between" stem="between" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="fancied" lemma="fancied" stem="fanci" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="sins" lemma="sin" stem="sin" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="lawmakers" lemma="lawmaker" stem="lawmak" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="24" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="discipline" lemma="discipline" stem="disciplin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="proposed" lemma="propose" stem="propos" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SBARQ (WHNP (WP What)) (SQ (VP (VBZ makes) (NP (NN term) (NN limitation)) (PP (JJ such) (NP (NP (DT a) (ADJP (RB singularly) (JJ inappropriate)) (NN tool)) (SBAR (S (VP (VBZ is) (NP (NP (DT the) (RB almost) (JJ total) (NN lack)) (PP (IN of) (NP (NP (NN connection)) (PP (IN between) (NP (NP (DT the) (JJ fancied) (NNS sins)) (PP (IN of) (NP (NP (DT the) (NNS lawmakers)) (CC and) (NP (DT the) (NN discipline) (VBN proposed)))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the almost total lack of connection between the fancied sins of the lawmakers and the discipline proposed" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="almost" />
            <token id="13" string="total" />
            <token id="14" string="lack" />
            <token id="15" string="of" />
            <token id="16" string="connection" />
            <token id="17" string="between" />
            <token id="18" string="the" />
            <token id="19" string="fancied" />
            <token id="20" string="sins" />
            <token id="21" string="of" />
            <token id="22" string="the" />
            <token id="23" string="lawmakers" />
            <token id="24" string="and" />
            <token id="25" string="the" />
            <token id="26" string="discipline" />
            <token id="27" string="proposed" />
          </tokens>
        </chunking>
        <chunking id="2" string="singularly inappropriate" type="ADJP">
          <tokens>
            <token id="7" string="singularly" />
            <token id="8" string="inappropriate" />
          </tokens>
        </chunking>
        <chunking id="3" string="the discipline proposed" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="discipline" />
            <token id="27" string="proposed" />
          </tokens>
        </chunking>
        <chunking id="4" string="makes term limitation such a singularly inappropriate tool is the almost total lack of connection between the fancied sins of the lawmakers and the discipline proposed" type="VP">
          <tokens>
            <token id="2" string="makes" />
            <token id="3" string="term" />
            <token id="4" string="limitation" />
            <token id="5" string="such" />
            <token id="6" string="a" />
            <token id="7" string="singularly" />
            <token id="8" string="inappropriate" />
            <token id="9" string="tool" />
            <token id="10" string="is" />
            <token id="11" string="the" />
            <token id="12" string="almost" />
            <token id="13" string="total" />
            <token id="14" string="lack" />
            <token id="15" string="of" />
            <token id="16" string="connection" />
            <token id="17" string="between" />
            <token id="18" string="the" />
            <token id="19" string="fancied" />
            <token id="20" string="sins" />
            <token id="21" string="of" />
            <token id="22" string="the" />
            <token id="23" string="lawmakers" />
            <token id="24" string="and" />
            <token id="25" string="the" />
            <token id="26" string="discipline" />
            <token id="27" string="proposed" />
          </tokens>
        </chunking>
        <chunking id="5" string="the lawmakers and the discipline proposed" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="lawmakers" />
            <token id="24" string="and" />
            <token id="25" string="the" />
            <token id="26" string="discipline" />
            <token id="27" string="proposed" />
          </tokens>
        </chunking>
        <chunking id="6" string="a singularly inappropriate tool" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="singularly" />
            <token id="8" string="inappropriate" />
            <token id="9" string="tool" />
          </tokens>
        </chunking>
        <chunking id="7" string="is the almost total lack of connection between the fancied sins of the lawmakers and the discipline proposed" type="SBAR">
          <tokens>
            <token id="10" string="is" />
            <token id="11" string="the" />
            <token id="12" string="almost" />
            <token id="13" string="total" />
            <token id="14" string="lack" />
            <token id="15" string="of" />
            <token id="16" string="connection" />
            <token id="17" string="between" />
            <token id="18" string="the" />
            <token id="19" string="fancied" />
            <token id="20" string="sins" />
            <token id="21" string="of" />
            <token id="22" string="the" />
            <token id="23" string="lawmakers" />
            <token id="24" string="and" />
            <token id="25" string="the" />
            <token id="26" string="discipline" />
            <token id="27" string="proposed" />
          </tokens>
        </chunking>
        <chunking id="8" string="the almost total lack" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="almost" />
            <token id="13" string="total" />
            <token id="14" string="lack" />
          </tokens>
        </chunking>
        <chunking id="9" string="the fancied sins" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="fancied" />
            <token id="20" string="sins" />
          </tokens>
        </chunking>
        <chunking id="10" string="the lawmakers" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="lawmakers" />
          </tokens>
        </chunking>
        <chunking id="11" string="term limitation" type="NP">
          <tokens>
            <token id="3" string="term" />
            <token id="4" string="limitation" />
          </tokens>
        </chunking>
        <chunking id="12" string="a singularly inappropriate tool is the almost total lack of connection between the fancied sins of the lawmakers and the discipline proposed" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="singularly" />
            <token id="8" string="inappropriate" />
            <token id="9" string="tool" />
            <token id="10" string="is" />
            <token id="11" string="the" />
            <token id="12" string="almost" />
            <token id="13" string="total" />
            <token id="14" string="lack" />
            <token id="15" string="of" />
            <token id="16" string="connection" />
            <token id="17" string="between" />
            <token id="18" string="the" />
            <token id="19" string="fancied" />
            <token id="20" string="sins" />
            <token id="21" string="of" />
            <token id="22" string="the" />
            <token id="23" string="lawmakers" />
            <token id="24" string="and" />
            <token id="25" string="the" />
            <token id="26" string="discipline" />
            <token id="27" string="proposed" />
          </tokens>
        </chunking>
        <chunking id="13" string="connection" type="NP">
          <tokens>
            <token id="16" string="connection" />
          </tokens>
        </chunking>
        <chunking id="14" string="connection between the fancied sins of the lawmakers and the discipline proposed" type="NP">
          <tokens>
            <token id="16" string="connection" />
            <token id="17" string="between" />
            <token id="18" string="the" />
            <token id="19" string="fancied" />
            <token id="20" string="sins" />
            <token id="21" string="of" />
            <token id="22" string="the" />
            <token id="23" string="lawmakers" />
            <token id="24" string="and" />
            <token id="25" string="the" />
            <token id="26" string="discipline" />
            <token id="27" string="proposed" />
          </tokens>
        </chunking>
        <chunking id="15" string="the fancied sins of the lawmakers and the discipline proposed" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="fancied" />
            <token id="20" string="sins" />
            <token id="21" string="of" />
            <token id="22" string="the" />
            <token id="23" string="lawmakers" />
            <token id="24" string="and" />
            <token id="25" string="the" />
            <token id="26" string="discipline" />
            <token id="27" string="proposed" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">makes</governor>
          <dependent id="1">What</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">makes</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">limitation</governor>
          <dependent id="3">term</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">makes</governor>
          <dependent id="4">limitation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">tool</governor>
          <dependent id="5">such</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">tool</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">inappropriate</governor>
          <dependent id="7">singularly</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">tool</governor>
          <dependent id="8">inappropriate</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">makes</governor>
          <dependent id="9">tool</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">lack</governor>
          <dependent id="10">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">lack</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">lack</governor>
          <dependent id="12">almost</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">lack</governor>
          <dependent id="13">total</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="9">tool</governor>
          <dependent id="14">lack</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">connection</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">lack</governor>
          <dependent id="16">connection</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">sins</governor>
          <dependent id="17">between</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">sins</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">sins</governor>
          <dependent id="19">fancied</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">connection</governor>
          <dependent id="20">sins</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">lawmakers</governor>
          <dependent id="21">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">lawmakers</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">sins</governor>
          <dependent id="23">lawmakers</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="23">lawmakers</governor>
          <dependent id="24">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">discipline</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="23">lawmakers</governor>
          <dependent id="26">discipline</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">discipline</governor>
          <dependent id="27">proposed</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>The very weakness and vulnerability to corruption that have often plagued state legislatures usually result from the amateurism of lawmakers -- the quality that term-limitation backers now assert as a virtue.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="weakness" lemma="weakness" stem="weak" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="vulnerability" lemma="vulnerability" stem="vulner" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="corruption" lemma="corruption" stem="corrupt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="often" lemma="often" stem="often" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="plagued" lemma="plague" stem="plagu" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="state" lemma="state" stem="state" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="legislatures" lemma="legislature" stem="legislatur" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="usually" lemma="usually" stem="usual" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="result" lemma="result" stem="result" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="amateurism" lemma="amateurism" stem="amateur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="lawmakers" lemma="lawmaker" stem="lawmak" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="quality" lemma="quality" stem="qualiti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="term-limitation" lemma="term-limitation" stem="term-limit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="backers" lemma="backer" stem="backer" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="28" string="assert" lemma="assert" stem="assert" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="virtue" lemma="virtue" stem="virtu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (RB very) (NN weakness)) (CC and) (NP (NP (NN vulnerability)) (PP (TO to) (NP (NN corruption))) (SBAR (WHNP (WDT that)) (S (VP (VBP have) (ADVP (RB often)) (VP (VBN plagued) (NP (NN state) (NNS legislatures)))))))) (ADVP (RB usually)) (VP (VBP result) (PP (IN from) (NP (NP (DT the) (NN amateurism)) (PP (IN of) (NP (NP (NNS lawmakers)) (: --) (NP (NP (DT the) (NN quality)) (SBAR (WHNP (WDT that)) (S (NP (JJ term-limitation) (NNS backers)) (ADVP (RB now)) (VP (VBP assert) (PP (IN as) (NP (DT a) (NN virtue)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the quality that term-limitation backers now assert as a virtue" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="quality" />
            <token id="24" string="that" />
            <token id="25" string="term-limitation" />
            <token id="26" string="backers" />
            <token id="27" string="now" />
            <token id="28" string="assert" />
            <token id="29" string="as" />
            <token id="30" string="a" />
            <token id="31" string="virtue" />
          </tokens>
        </chunking>
        <chunking id="2" string="the quality" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="quality" />
          </tokens>
        </chunking>
        <chunking id="3" string="state legislatures" type="NP">
          <tokens>
            <token id="12" string="state" />
            <token id="13" string="legislatures" />
          </tokens>
        </chunking>
        <chunking id="4" string="vulnerability" type="NP">
          <tokens>
            <token id="5" string="vulnerability" />
          </tokens>
        </chunking>
        <chunking id="5" string="the amateurism" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="amateurism" />
          </tokens>
        </chunking>
        <chunking id="6" string="vulnerability to corruption that have often plagued state legislatures" type="NP">
          <tokens>
            <token id="5" string="vulnerability" />
            <token id="6" string="to" />
            <token id="7" string="corruption" />
            <token id="8" string="that" />
            <token id="9" string="have" />
            <token id="10" string="often" />
            <token id="11" string="plagued" />
            <token id="12" string="state" />
            <token id="13" string="legislatures" />
          </tokens>
        </chunking>
        <chunking id="7" string="have often plagued state legislatures" type="VP">
          <tokens>
            <token id="9" string="have" />
            <token id="10" string="often" />
            <token id="11" string="plagued" />
            <token id="12" string="state" />
            <token id="13" string="legislatures" />
          </tokens>
        </chunking>
        <chunking id="8" string="result from the amateurism of lawmakers -- the quality that term-limitation backers now assert as a virtue" type="VP">
          <tokens>
            <token id="15" string="result" />
            <token id="16" string="from" />
            <token id="17" string="the" />
            <token id="18" string="amateurism" />
            <token id="19" string="of" />
            <token id="20" string="lawmakers" />
            <token id="21" string="--" />
            <token id="22" string="the" />
            <token id="23" string="quality" />
            <token id="24" string="that" />
            <token id="25" string="term-limitation" />
            <token id="26" string="backers" />
            <token id="27" string="now" />
            <token id="28" string="assert" />
            <token id="29" string="as" />
            <token id="30" string="a" />
            <token id="31" string="virtue" />
          </tokens>
        </chunking>
        <chunking id="9" string="lawmakers -- the quality that term-limitation backers now assert as a virtue" type="NP">
          <tokens>
            <token id="20" string="lawmakers" />
            <token id="21" string="--" />
            <token id="22" string="the" />
            <token id="23" string="quality" />
            <token id="24" string="that" />
            <token id="25" string="term-limitation" />
            <token id="26" string="backers" />
            <token id="27" string="now" />
            <token id="28" string="assert" />
            <token id="29" string="as" />
            <token id="30" string="a" />
            <token id="31" string="virtue" />
          </tokens>
        </chunking>
        <chunking id="10" string="plagued state legislatures" type="VP">
          <tokens>
            <token id="11" string="plagued" />
            <token id="12" string="state" />
            <token id="13" string="legislatures" />
          </tokens>
        </chunking>
        <chunking id="11" string="lawmakers" type="NP">
          <tokens>
            <token id="20" string="lawmakers" />
          </tokens>
        </chunking>
        <chunking id="12" string="that term-limitation backers now assert as a virtue" type="SBAR">
          <tokens>
            <token id="24" string="that" />
            <token id="25" string="term-limitation" />
            <token id="26" string="backers" />
            <token id="27" string="now" />
            <token id="28" string="assert" />
            <token id="29" string="as" />
            <token id="30" string="a" />
            <token id="31" string="virtue" />
          </tokens>
        </chunking>
        <chunking id="13" string="that have often plagued state legislatures" type="SBAR">
          <tokens>
            <token id="8" string="that" />
            <token id="9" string="have" />
            <token id="10" string="often" />
            <token id="11" string="plagued" />
            <token id="12" string="state" />
            <token id="13" string="legislatures" />
          </tokens>
        </chunking>
        <chunking id="14" string="a virtue" type="NP">
          <tokens>
            <token id="30" string="a" />
            <token id="31" string="virtue" />
          </tokens>
        </chunking>
        <chunking id="15" string="term-limitation backers" type="NP">
          <tokens>
            <token id="25" string="term-limitation" />
            <token id="26" string="backers" />
          </tokens>
        </chunking>
        <chunking id="16" string="the amateurism of lawmakers -- the quality that term-limitation backers now assert as a virtue" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="amateurism" />
            <token id="19" string="of" />
            <token id="20" string="lawmakers" />
            <token id="21" string="--" />
            <token id="22" string="the" />
            <token id="23" string="quality" />
            <token id="24" string="that" />
            <token id="25" string="term-limitation" />
            <token id="26" string="backers" />
            <token id="27" string="now" />
            <token id="28" string="assert" />
            <token id="29" string="as" />
            <token id="30" string="a" />
            <token id="31" string="virtue" />
          </tokens>
        </chunking>
        <chunking id="17" string="The very weakness" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="very" />
            <token id="3" string="weakness" />
          </tokens>
        </chunking>
        <chunking id="18" string="corruption" type="NP">
          <tokens>
            <token id="7" string="corruption" />
          </tokens>
        </chunking>
        <chunking id="19" string="assert as a virtue" type="VP">
          <tokens>
            <token id="28" string="assert" />
            <token id="29" string="as" />
            <token id="30" string="a" />
            <token id="31" string="virtue" />
          </tokens>
        </chunking>
        <chunking id="20" string="The very weakness and vulnerability to corruption that have often plagued state legislatures" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="very" />
            <token id="3" string="weakness" />
            <token id="4" string="and" />
            <token id="5" string="vulnerability" />
            <token id="6" string="to" />
            <token id="7" string="corruption" />
            <token id="8" string="that" />
            <token id="9" string="have" />
            <token id="10" string="often" />
            <token id="11" string="plagued" />
            <token id="12" string="state" />
            <token id="13" string="legislatures" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">weakness</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">weakness</governor>
          <dependent id="2">very</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">result</governor>
          <dependent id="3">weakness</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">weakness</governor>
          <dependent id="4">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">weakness</governor>
          <dependent id="5">vulnerability</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">corruption</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">vulnerability</governor>
          <dependent id="7">corruption</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">plagued</governor>
          <dependent id="8">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">plagued</governor>
          <dependent id="9">have</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">plagued</governor>
          <dependent id="10">often</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="5">vulnerability</governor>
          <dependent id="11">plagued</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">legislatures</governor>
          <dependent id="12">state</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">plagued</governor>
          <dependent id="13">legislatures</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">result</governor>
          <dependent id="14">usually</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">result</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">amateurism</governor>
          <dependent id="16">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">amateurism</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">result</governor>
          <dependent id="18">amateurism</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">lawmakers</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">amateurism</governor>
          <dependent id="20">lawmakers</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">quality</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="20">lawmakers</governor>
          <dependent id="23">quality</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="28">assert</governor>
          <dependent id="24">that</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">backers</governor>
          <dependent id="25">term-limitation</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">assert</governor>
          <dependent id="26">backers</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="28">assert</governor>
          <dependent id="27">now</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="23">quality</governor>
          <dependent id="28">assert</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">virtue</governor>
          <dependent id="29">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">virtue</governor>
          <dependent id="30">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">assert</governor>
          <dependent id="31">virtue</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="27" string="now" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>Where state legislators are underpaid, have no professional staffs and meet rarely, they usually come under the sway of full-time governors, executive-branch bureaucrats and highly paid lobbyists.</content>
      <tokens>
        <token id="1" string="Where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="state" lemma="state" stem="state" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="legislators" lemma="legislator" stem="legisl" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="underpaid" lemma="underpaid" stem="underpaid" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="professional" lemma="professional" stem="profession" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="staffs" lemma="staff" stem="staff" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="meet" lemma="meet" stem="meet" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="rarely" lemma="rarely" stem="rare" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="usually" lemma="usually" stem="usual" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="come" lemma="come" stem="come" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="under" lemma="under" stem="under" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="sway" lemma="sway" stem="swai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="full-time" lemma="full-time" stem="full-tim" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="governors" lemma="governor" stem="governor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="executive-branch" lemma="executive-branch" stem="executive-branch" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="bureaucrats" lemma="bureaucrat" stem="bureaucrat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="highly" lemma="highly" stem="highli" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="paid" lemma="pay" stem="paid" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="30" string="lobbyists" lemma="lobbyist" stem="lobbyist" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (WHADVP (WRB Where)) (S (NP (NN state) (NNS legislators)) (VP (VP (VBP are) (ADJP (JJ underpaid))) (, ,) (VP (VBP have) (NP (DT no) (JJ professional) (NNS staffs))) (CC and) (VP (VB meet) (ADVP (RB rarely)))))) (, ,) (NP (PRP they)) (ADVP (RB usually)) (VP (VBP come) (ADVP (IN under) (DT the)) (VP (VB sway) (PP (IN of) (NP (NP (JJ full-time) (NNS governors)) (, ,) (NP (JJ executive-branch) (NNS bureaucrats)) (CC and) (NP (ADJP (RB highly) (VBN paid)) (NNS lobbyists)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="full-time governors , executive-branch bureaucrats and highly paid lobbyists" type="NP">
          <tokens>
            <token id="22" string="full-time" />
            <token id="23" string="governors" />
            <token id="24" string="," />
            <token id="25" string="executive-branch" />
            <token id="26" string="bureaucrats" />
            <token id="27" string="and" />
            <token id="28" string="highly" />
            <token id="29" string="paid" />
            <token id="30" string="lobbyists" />
          </tokens>
        </chunking>
        <chunking id="2" string="highly paid" type="ADJP">
          <tokens>
            <token id="28" string="highly" />
            <token id="29" string="paid" />
          </tokens>
        </chunking>
        <chunking id="3" string="are underpaid" type="VP">
          <tokens>
            <token id="4" string="are" />
            <token id="5" string="underpaid" />
          </tokens>
        </chunking>
        <chunking id="4" string="no professional staffs" type="NP">
          <tokens>
            <token id="8" string="no" />
            <token id="9" string="professional" />
            <token id="10" string="staffs" />
          </tokens>
        </chunking>
        <chunking id="5" string="come under the sway of full-time governors , executive-branch bureaucrats and highly paid lobbyists" type="VP">
          <tokens>
            <token id="17" string="come" />
            <token id="18" string="under" />
            <token id="19" string="the" />
            <token id="20" string="sway" />
            <token id="21" string="of" />
            <token id="22" string="full-time" />
            <token id="23" string="governors" />
            <token id="24" string="," />
            <token id="25" string="executive-branch" />
            <token id="26" string="bureaucrats" />
            <token id="27" string="and" />
            <token id="28" string="highly" />
            <token id="29" string="paid" />
            <token id="30" string="lobbyists" />
          </tokens>
        </chunking>
        <chunking id="6" string="underpaid" type="ADJP">
          <tokens>
            <token id="5" string="underpaid" />
          </tokens>
        </chunking>
        <chunking id="7" string="are underpaid , have no professional staffs and meet rarely" type="VP">
          <tokens>
            <token id="4" string="are" />
            <token id="5" string="underpaid" />
            <token id="6" string="," />
            <token id="7" string="have" />
            <token id="8" string="no" />
            <token id="9" string="professional" />
            <token id="10" string="staffs" />
            <token id="11" string="and" />
            <token id="12" string="meet" />
            <token id="13" string="rarely" />
          </tokens>
        </chunking>
        <chunking id="8" string="have no professional staffs" type="VP">
          <tokens>
            <token id="7" string="have" />
            <token id="8" string="no" />
            <token id="9" string="professional" />
            <token id="10" string="staffs" />
          </tokens>
        </chunking>
        <chunking id="9" string="executive-branch bureaucrats" type="NP">
          <tokens>
            <token id="25" string="executive-branch" />
            <token id="26" string="bureaucrats" />
          </tokens>
        </chunking>
        <chunking id="10" string="they" type="NP">
          <tokens>
            <token id="15" string="they" />
          </tokens>
        </chunking>
        <chunking id="11" string="state legislators" type="NP">
          <tokens>
            <token id="2" string="state" />
            <token id="3" string="legislators" />
          </tokens>
        </chunking>
        <chunking id="12" string="sway of full-time governors , executive-branch bureaucrats and highly paid lobbyists" type="VP">
          <tokens>
            <token id="20" string="sway" />
            <token id="21" string="of" />
            <token id="22" string="full-time" />
            <token id="23" string="governors" />
            <token id="24" string="," />
            <token id="25" string="executive-branch" />
            <token id="26" string="bureaucrats" />
            <token id="27" string="and" />
            <token id="28" string="highly" />
            <token id="29" string="paid" />
            <token id="30" string="lobbyists" />
          </tokens>
        </chunking>
        <chunking id="13" string="meet rarely" type="VP">
          <tokens>
            <token id="12" string="meet" />
            <token id="13" string="rarely" />
          </tokens>
        </chunking>
        <chunking id="14" string="Where" type="WHADVP">
          <tokens>
            <token id="1" string="Where" />
          </tokens>
        </chunking>
        <chunking id="15" string="full-time governors" type="NP">
          <tokens>
            <token id="22" string="full-time" />
            <token id="23" string="governors" />
          </tokens>
        </chunking>
        <chunking id="16" string="highly paid lobbyists" type="NP">
          <tokens>
            <token id="28" string="highly" />
            <token id="29" string="paid" />
            <token id="30" string="lobbyists" />
          </tokens>
        </chunking>
        <chunking id="17" string="Where state legislators are underpaid , have no professional staffs and meet rarely" type="SBAR">
          <tokens>
            <token id="1" string="Where" />
            <token id="2" string="state" />
            <token id="3" string="legislators" />
            <token id="4" string="are" />
            <token id="5" string="underpaid" />
            <token id="6" string="," />
            <token id="7" string="have" />
            <token id="8" string="no" />
            <token id="9" string="professional" />
            <token id="10" string="staffs" />
            <token id="11" string="and" />
            <token id="12" string="meet" />
            <token id="13" string="rarely" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="5">underpaid</governor>
          <dependent id="1">Where</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">legislators</governor>
          <dependent id="2">state</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">underpaid</governor>
          <dependent id="3">legislators</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">underpaid</governor>
          <dependent id="4">are</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="17">come</governor>
          <dependent id="5">underpaid</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">underpaid</governor>
          <dependent id="7">have</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="10">staffs</governor>
          <dependent id="8">no</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">staffs</governor>
          <dependent id="9">professional</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">have</governor>
          <dependent id="10">staffs</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">underpaid</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">underpaid</governor>
          <dependent id="12">meet</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">meet</governor>
          <dependent id="13">rarely</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">come</governor>
          <dependent id="15">they</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">come</governor>
          <dependent id="16">usually</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">come</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">the</governor>
          <dependent id="18">under</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">come</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="17">come</governor>
          <dependent id="20">sway</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">governors</governor>
          <dependent id="21">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">governors</governor>
          <dependent id="22">full-time</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">sway</governor>
          <dependent id="23">governors</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">bureaucrats</governor>
          <dependent id="25">executive-branch</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="23">governors</governor>
          <dependent id="26">bureaucrats</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="23">governors</governor>
          <dependent id="27">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="29">paid</governor>
          <dependent id="28">highly</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="30">lobbyists</governor>
          <dependent id="29">paid</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="23">governors</governor>
          <dependent id="30">lobbyists</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="17" has_coreference="false">
      <content>Indeed, the goal of legislative reformers for the past 50 years has been more professionalism in the state assemblies, not less.</content>
      <tokens>
        <token id="1" string="Indeed" lemma="indeed" stem="indeed" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="goal" lemma="goal" stem="goal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="legislative" lemma="legislative" stem="legisl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="reformers" lemma="reformer" stem="reform" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="10" string="past" lemma="past" stem="past" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="11" string="50" lemma="50" stem="50" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="12" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="13" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="professionalism" lemma="professionalism" stem="profession" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="state" lemma="state" stem="state" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="assemblies" lemma="assembly" stem="assembli" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="less" lemma="less" stem="less" pos="RBR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Indeed)) (, ,) (NP (NP (DT the) (NN goal)) (PP (IN of) (NP (NP (JJ legislative) (NNS reformers)) (PP (IN for) (NP (DT the) (JJ past) (CD 50) (NNS years)))))) (VP (VBZ has) (VP (VBN been) (NP (NP (JJR more) (NN professionalism)) (PP (IN in) (NP (DT the) (NN state) (NNS assemblies)))) (, ,) (ADVP (RB not) (RBR less)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="legislative reformers for the past 50 years" type="NP">
          <tokens>
            <token id="6" string="legislative" />
            <token id="7" string="reformers" />
            <token id="8" string="for" />
            <token id="9" string="the" />
            <token id="10" string="past" />
            <token id="11" string="50" />
            <token id="12" string="years" />
          </tokens>
        </chunking>
        <chunking id="2" string="more professionalism in the state assemblies" type="NP">
          <tokens>
            <token id="15" string="more" />
            <token id="16" string="professionalism" />
            <token id="17" string="in" />
            <token id="18" string="the" />
            <token id="19" string="state" />
            <token id="20" string="assemblies" />
          </tokens>
        </chunking>
        <chunking id="3" string="the state assemblies" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="state" />
            <token id="20" string="assemblies" />
          </tokens>
        </chunking>
        <chunking id="4" string="legislative reformers" type="NP">
          <tokens>
            <token id="6" string="legislative" />
            <token id="7" string="reformers" />
          </tokens>
        </chunking>
        <chunking id="5" string="has been more professionalism in the state assemblies , not less" type="VP">
          <tokens>
            <token id="13" string="has" />
            <token id="14" string="been" />
            <token id="15" string="more" />
            <token id="16" string="professionalism" />
            <token id="17" string="in" />
            <token id="18" string="the" />
            <token id="19" string="state" />
            <token id="20" string="assemblies" />
            <token id="21" string="," />
            <token id="22" string="not" />
            <token id="23" string="less" />
          </tokens>
        </chunking>
        <chunking id="6" string="the past 50 years" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="past" />
            <token id="11" string="50" />
            <token id="12" string="years" />
          </tokens>
        </chunking>
        <chunking id="7" string="the goal" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="goal" />
          </tokens>
        </chunking>
        <chunking id="8" string="more professionalism" type="NP">
          <tokens>
            <token id="15" string="more" />
            <token id="16" string="professionalism" />
          </tokens>
        </chunking>
        <chunking id="9" string="the goal of legislative reformers for the past 50 years" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="goal" />
            <token id="5" string="of" />
            <token id="6" string="legislative" />
            <token id="7" string="reformers" />
            <token id="8" string="for" />
            <token id="9" string="the" />
            <token id="10" string="past" />
            <token id="11" string="50" />
            <token id="12" string="years" />
          </tokens>
        </chunking>
        <chunking id="10" string="been more professionalism in the state assemblies , not less" type="VP">
          <tokens>
            <token id="14" string="been" />
            <token id="15" string="more" />
            <token id="16" string="professionalism" />
            <token id="17" string="in" />
            <token id="18" string="the" />
            <token id="19" string="state" />
            <token id="20" string="assemblies" />
            <token id="21" string="," />
            <token id="22" string="not" />
            <token id="23" string="less" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="16">professionalism</governor>
          <dependent id="1">Indeed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">goal</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">professionalism</governor>
          <dependent id="4">goal</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">reformers</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">reformers</governor>
          <dependent id="6">legislative</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">goal</governor>
          <dependent id="7">reformers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">years</governor>
          <dependent id="8">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">years</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">years</governor>
          <dependent id="10">past</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="12">years</governor>
          <dependent id="11">50</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">reformers</governor>
          <dependent id="12">years</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">professionalism</governor>
          <dependent id="13">has</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="16">professionalism</governor>
          <dependent id="14">been</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">professionalism</governor>
          <dependent id="15">more</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">professionalism</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">assemblies</governor>
          <dependent id="17">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">assemblies</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">assemblies</governor>
          <dependent id="19">state</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">professionalism</governor>
          <dependent id="20">assemblies</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="23">less</governor>
          <dependent id="22">not</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">professionalism</governor>
          <dependent id="23">less</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="the past 50 years" type="DURATION" score="0.0">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="past" />
            <token id="11" string="50" />
            <token id="12" string="years" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>By turning out the legislators every 12 years -- or even worse, every six years -- you pretty much guarantee that those who are elected won&amp;apost;t have much of a stake in their jobs.</content>
      <tokens>
        <token id="1" string="By" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="turning" lemma="turn" stem="turn" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="legislators" lemma="legislator" stem="legisl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="every" lemma="every" stem="everi" pos="DT" type="Word" isStopWord="false" ner="SET" is_referenced="false" is_refers="true" />
        <token id="7" string="12" lemma="12" stem="12" pos="CD" type="Number" isStopWord="false" ner="SET" is_referenced="false" is_refers="true" />
        <token id="8" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="SET" is_referenced="false" is_refers="true" />
        <token id="9" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="worse" lemma="worse" stem="wors" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="every" lemma="every" stem="everi" pos="DT" type="Word" isStopWord="false" ner="SET" is_referenced="false" is_refers="false" />
        <token id="15" string="six" lemma="six" stem="six" pos="CD" type="Word" isStopWord="false" ner="SET" is_referenced="false" is_refers="false" />
        <token id="16" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="SET" is_referenced="false" is_refers="false" />
        <token id="17" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="pretty" lemma="pretty" stem="pretti" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="much" lemma="much" stem="much" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="guarantee" lemma="guarantee" stem="guarante" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="26" string="elected" lemma="elect" stem="elect" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="wo" lemma="will" stem="wo" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="much" lemma="much" stem="much" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="stake" lemma="stake" stem="stake" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="jobs" lemma="job" stem="job" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN By) (S (VP (VBG turning) (PRT (RP out)) (NP (NP (DT the) (NNS legislators)) (ADJP (DT every) (ADJP (CD 12) (NNS years)) (: --) (CC or) (ADJP (RB even) (JJR worse))))))) (, ,) (NP (NP (DT every) (CD six) (NNS years)) (PRN (: --) (S (NP (PRP you)) (ADJP (RB pretty) (RB much))))) (VP (VB guarantee) (SBAR (IN that) (S (NP (NP (DT those)) (SBAR (WHNP (WP who)) (S (VP (VBP are) (VP (VBN elected)))))) (VP (MD wo) (RB n't) (VP (VB have) (NP (NP (JJ much)) (PP (IN of) (NP (NP (DT a) (NN stake)) (PP (IN in) (NP (PRP$ their) (NNS jobs))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="even worse" type="ADJP">
          <tokens>
            <token id="11" string="even" />
            <token id="12" string="worse" />
          </tokens>
        </chunking>
        <chunking id="2" string="have much of a stake in their jobs" type="VP">
          <tokens>
            <token id="29" string="have" />
            <token id="30" string="much" />
            <token id="31" string="of" />
            <token id="32" string="a" />
            <token id="33" string="stake" />
            <token id="34" string="in" />
            <token id="35" string="their" />
            <token id="36" string="jobs" />
          </tokens>
        </chunking>
        <chunking id="3" string="are elected" type="VP">
          <tokens>
            <token id="25" string="are" />
            <token id="26" string="elected" />
          </tokens>
        </chunking>
        <chunking id="4" string="who are elected" type="SBAR">
          <tokens>
            <token id="24" string="who" />
            <token id="25" string="are" />
            <token id="26" string="elected" />
          </tokens>
        </chunking>
        <chunking id="5" string="a stake in their jobs" type="NP">
          <tokens>
            <token id="32" string="a" />
            <token id="33" string="stake" />
            <token id="34" string="in" />
            <token id="35" string="their" />
            <token id="36" string="jobs" />
          </tokens>
        </chunking>
        <chunking id="6" string="guarantee that those who are elected wo n't have much of a stake in their jobs" type="VP">
          <tokens>
            <token id="21" string="guarantee" />
            <token id="22" string="that" />
            <token id="23" string="those" />
            <token id="24" string="who" />
            <token id="25" string="are" />
            <token id="26" string="elected" />
            <token id="27" string="wo" />
            <token id="28" string="n't" />
            <token id="29" string="have" />
            <token id="30" string="much" />
            <token id="31" string="of" />
            <token id="32" string="a" />
            <token id="33" string="stake" />
            <token id="34" string="in" />
            <token id="35" string="their" />
            <token id="36" string="jobs" />
          </tokens>
        </chunking>
        <chunking id="7" string="much of a stake in their jobs" type="NP">
          <tokens>
            <token id="30" string="much" />
            <token id="31" string="of" />
            <token id="32" string="a" />
            <token id="33" string="stake" />
            <token id="34" string="in" />
            <token id="35" string="their" />
            <token id="36" string="jobs" />
          </tokens>
        </chunking>
        <chunking id="8" string="every six years -- you pretty much" type="NP">
          <tokens>
            <token id="14" string="every" />
            <token id="15" string="six" />
            <token id="16" string="years" />
            <token id="17" string="--" />
            <token id="18" string="you" />
            <token id="19" string="pretty" />
            <token id="20" string="much" />
          </tokens>
        </chunking>
        <chunking id="9" string="every six years" type="NP">
          <tokens>
            <token id="14" string="every" />
            <token id="15" string="six" />
            <token id="16" string="years" />
          </tokens>
        </chunking>
        <chunking id="10" string="their jobs" type="NP">
          <tokens>
            <token id="35" string="their" />
            <token id="36" string="jobs" />
          </tokens>
        </chunking>
        <chunking id="11" string="turning out the legislators every 12 years -- or even worse" type="VP">
          <tokens>
            <token id="2" string="turning" />
            <token id="3" string="out" />
            <token id="4" string="the" />
            <token id="5" string="legislators" />
            <token id="6" string="every" />
            <token id="7" string="12" />
            <token id="8" string="years" />
            <token id="9" string="--" />
            <token id="10" string="or" />
            <token id="11" string="even" />
            <token id="12" string="worse" />
          </tokens>
        </chunking>
        <chunking id="12" string="wo n't have much of a stake in their jobs" type="VP">
          <tokens>
            <token id="27" string="wo" />
            <token id="28" string="n't" />
            <token id="29" string="have" />
            <token id="30" string="much" />
            <token id="31" string="of" />
            <token id="32" string="a" />
            <token id="33" string="stake" />
            <token id="34" string="in" />
            <token id="35" string="their" />
            <token id="36" string="jobs" />
          </tokens>
        </chunking>
        <chunking id="13" string="12 years" type="ADJP">
          <tokens>
            <token id="7" string="12" />
            <token id="8" string="years" />
          </tokens>
        </chunking>
        <chunking id="14" string="the legislators" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="legislators" />
          </tokens>
        </chunking>
        <chunking id="15" string="elected" type="VP">
          <tokens>
            <token id="26" string="elected" />
          </tokens>
        </chunking>
        <chunking id="16" string="pretty much" type="ADJP">
          <tokens>
            <token id="19" string="pretty" />
            <token id="20" string="much" />
          </tokens>
        </chunking>
        <chunking id="17" string="those who are elected" type="NP">
          <tokens>
            <token id="23" string="those" />
            <token id="24" string="who" />
            <token id="25" string="are" />
            <token id="26" string="elected" />
          </tokens>
        </chunking>
        <chunking id="18" string="a stake" type="NP">
          <tokens>
            <token id="32" string="a" />
            <token id="33" string="stake" />
          </tokens>
        </chunking>
        <chunking id="19" string="the legislators every 12 years -- or even worse" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="legislators" />
            <token id="6" string="every" />
            <token id="7" string="12" />
            <token id="8" string="years" />
            <token id="9" string="--" />
            <token id="10" string="or" />
            <token id="11" string="even" />
            <token id="12" string="worse" />
          </tokens>
        </chunking>
        <chunking id="20" string="every 12 years -- or even worse" type="ADJP">
          <tokens>
            <token id="6" string="every" />
            <token id="7" string="12" />
            <token id="8" string="years" />
            <token id="9" string="--" />
            <token id="10" string="or" />
            <token id="11" string="even" />
            <token id="12" string="worse" />
          </tokens>
        </chunking>
        <chunking id="21" string="that those who are elected wo n't have much of a stake in their jobs" type="SBAR">
          <tokens>
            <token id="22" string="that" />
            <token id="23" string="those" />
            <token id="24" string="who" />
            <token id="25" string="are" />
            <token id="26" string="elected" />
            <token id="27" string="wo" />
            <token id="28" string="n't" />
            <token id="29" string="have" />
            <token id="30" string="much" />
            <token id="31" string="of" />
            <token id="32" string="a" />
            <token id="33" string="stake" />
            <token id="34" string="in" />
            <token id="35" string="their" />
            <token id="36" string="jobs" />
          </tokens>
        </chunking>
        <chunking id="22" string="you" type="NP">
          <tokens>
            <token id="18" string="you" />
          </tokens>
        </chunking>
        <chunking id="23" string="those" type="NP">
          <tokens>
            <token id="23" string="those" />
          </tokens>
        </chunking>
        <chunking id="24" string="much" type="NP">
          <tokens>
            <token id="30" string="much" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="2">turning</governor>
          <dependent id="1">By</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="21">guarantee</governor>
          <dependent id="2">turning</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="2">turning</governor>
          <dependent id="3">out</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">legislators</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">turning</governor>
          <dependent id="5">legislators</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="8">years</governor>
          <dependent id="6">every</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">years</governor>
          <dependent id="7">12</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">legislators</governor>
          <dependent id="8">years</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">years</governor>
          <dependent id="10">or</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">worse</governor>
          <dependent id="11">even</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">years</governor>
          <dependent id="12">worse</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">years</governor>
          <dependent id="14">every</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="16">years</governor>
          <dependent id="15">six</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">guarantee</governor>
          <dependent id="16">years</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="20">much</governor>
          <dependent id="18">you</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">much</governor>
          <dependent id="19">pretty</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="16">years</governor>
          <dependent id="20">much</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="21">guarantee</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="29">have</governor>
          <dependent id="22">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">have</governor>
          <dependent id="23">those</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="26">elected</governor>
          <dependent id="24">who</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="26">elected</governor>
          <dependent id="25">are</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="23">those</governor>
          <dependent id="26">elected</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="29">have</governor>
          <dependent id="27">wo</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="29">have</governor>
          <dependent id="28">n't</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="21">guarantee</governor>
          <dependent id="29">have</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="29">have</governor>
          <dependent id="30">much</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">stake</governor>
          <dependent id="31">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">stake</governor>
          <dependent id="32">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">much</governor>
          <dependent id="33">stake</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">jobs</governor>
          <dependent id="34">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="36">jobs</governor>
          <dependent id="35">their</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">stake</governor>
          <dependent id="36">jobs</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="every 12 years" type="SET" score="0.0">
          <tokens>
            <token id="6" string="every" />
            <token id="7" string="12" />
            <token id="8" string="years" />
          </tokens>
        </entity>
        <entity id="2" string="every six years" type="SET" score="0.0">
          <tokens>
            <token id="14" string="every" />
            <token id="15" string="six" />
            <token id="16" string="years" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>They will use them as temporary hitching posts on their way to other offices without term limitations.</content>
      <tokens>
        <token id="1" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="use" lemma="use" stem="us" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="temporary" lemma="temporary" stem="temporari" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="hitching" lemma="hitch" stem="hitch" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="posts" lemma="post" stem="post" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="way" lemma="way" stem="wai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="offices" lemma="office" stem="offic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="without" lemma="without" stem="without" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="term" lemma="term" stem="term" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="limitations" lemma="limitation" stem="limit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP They)) (VP (MD will) (VP (VB use) (NP (PRP them)) (PP (IN as) (NP (NP (JJ temporary) (VBG hitching) (NNS posts)) (PP (IN on) (NP (PRP$ their) (NN way) (S (VP (TO to) (VP (NP (JJ other) (NNS offices)) (PP (IN without) (NP (NN term) (NNS limitations)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="1" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="other offices without term limitations" type="VP">
          <tokens>
            <token id="13" string="other" />
            <token id="14" string="offices" />
            <token id="15" string="without" />
            <token id="16" string="term" />
            <token id="17" string="limitations" />
          </tokens>
        </chunking>
        <chunking id="3" string="will use them as temporary hitching posts on their way to other offices without term limitations" type="VP">
          <tokens>
            <token id="2" string="will" />
            <token id="3" string="use" />
            <token id="4" string="them" />
            <token id="5" string="as" />
            <token id="6" string="temporary" />
            <token id="7" string="hitching" />
            <token id="8" string="posts" />
            <token id="9" string="on" />
            <token id="10" string="their" />
            <token id="11" string="way" />
            <token id="12" string="to" />
            <token id="13" string="other" />
            <token id="14" string="offices" />
            <token id="15" string="without" />
            <token id="16" string="term" />
            <token id="17" string="limitations" />
          </tokens>
        </chunking>
        <chunking id="4" string="their way to other offices without term limitations" type="NP">
          <tokens>
            <token id="10" string="their" />
            <token id="11" string="way" />
            <token id="12" string="to" />
            <token id="13" string="other" />
            <token id="14" string="offices" />
            <token id="15" string="without" />
            <token id="16" string="term" />
            <token id="17" string="limitations" />
          </tokens>
        </chunking>
        <chunking id="5" string="other offices" type="NP">
          <tokens>
            <token id="13" string="other" />
            <token id="14" string="offices" />
          </tokens>
        </chunking>
        <chunking id="6" string="term limitations" type="NP">
          <tokens>
            <token id="16" string="term" />
            <token id="17" string="limitations" />
          </tokens>
        </chunking>
        <chunking id="7" string="to other offices without term limitations" type="VP">
          <tokens>
            <token id="12" string="to" />
            <token id="13" string="other" />
            <token id="14" string="offices" />
            <token id="15" string="without" />
            <token id="16" string="term" />
            <token id="17" string="limitations" />
          </tokens>
        </chunking>
        <chunking id="8" string="temporary hitching posts on their way to other offices without term limitations" type="NP">
          <tokens>
            <token id="6" string="temporary" />
            <token id="7" string="hitching" />
            <token id="8" string="posts" />
            <token id="9" string="on" />
            <token id="10" string="their" />
            <token id="11" string="way" />
            <token id="12" string="to" />
            <token id="13" string="other" />
            <token id="14" string="offices" />
            <token id="15" string="without" />
            <token id="16" string="term" />
            <token id="17" string="limitations" />
          </tokens>
        </chunking>
        <chunking id="9" string="them" type="NP">
          <tokens>
            <token id="4" string="them" />
          </tokens>
        </chunking>
        <chunking id="10" string="use them as temporary hitching posts on their way to other offices without term limitations" type="VP">
          <tokens>
            <token id="3" string="use" />
            <token id="4" string="them" />
            <token id="5" string="as" />
            <token id="6" string="temporary" />
            <token id="7" string="hitching" />
            <token id="8" string="posts" />
            <token id="9" string="on" />
            <token id="10" string="their" />
            <token id="11" string="way" />
            <token id="12" string="to" />
            <token id="13" string="other" />
            <token id="14" string="offices" />
            <token id="15" string="without" />
            <token id="16" string="term" />
            <token id="17" string="limitations" />
          </tokens>
        </chunking>
        <chunking id="11" string="temporary hitching posts" type="NP">
          <tokens>
            <token id="6" string="temporary" />
            <token id="7" string="hitching" />
            <token id="8" string="posts" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">use</governor>
          <dependent id="1">They</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">use</governor>
          <dependent id="2">will</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">use</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">use</governor>
          <dependent id="4">them</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">posts</governor>
          <dependent id="5">as</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">posts</governor>
          <dependent id="6">temporary</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">posts</governor>
          <dependent id="7">hitching</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">use</governor>
          <dependent id="8">posts</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">way</governor>
          <dependent id="9">on</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">way</governor>
          <dependent id="10">their</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">posts</governor>
          <dependent id="11">way</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">offices</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">offices</governor>
          <dependent id="13">other</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="11">way</governor>
          <dependent id="14">offices</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">limitations</governor>
          <dependent id="15">without</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">limitations</governor>
          <dependent id="16">term</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">offices</governor>
          <dependent id="17">limitations</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>Not every state lawmaker has his eye on a seat in the U.S. Senate or House of Representatives.</content>
      <tokens>
        <token id="1" string="Not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="every" lemma="every" stem="everi" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="state" lemma="state" stem="state" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="lawmaker" lemma="lawmaker" stem="lawmak" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="eye" lemma="eye" stem="ey" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="seat" lemma="seat" stem="seat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="U.S." lemma="U.S." stem="u.s." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="14" string="Senate" lemma="Senate" stem="senat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="15" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="House" lemma="House" stem="hous" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="18" string="Representatives" lemma="Representatives" stem="repres" pos="NNPS" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (RB Not) (NP (DT every) (NN state) (NN lawmaker)) (VP (VBZ has) (NP (PRP$ his) (NN eye)) (PP (IN on) (NP (NP (NP (DT a) (NN seat)) (PP (IN in) (NP (DT the) (NNP U.S.) (NNP Senate)))) (CC or) (NP (NP (NNP House)) (PP (IN of) (NP (NNPS Representatives))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="every state lawmaker" type="NP">
          <tokens>
            <token id="2" string="every" />
            <token id="3" string="state" />
            <token id="4" string="lawmaker" />
          </tokens>
        </chunking>
        <chunking id="2" string="the U.S. Senate" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="U.S." />
            <token id="14" string="Senate" />
          </tokens>
        </chunking>
        <chunking id="3" string="House" type="NP">
          <tokens>
            <token id="16" string="House" />
          </tokens>
        </chunking>
        <chunking id="4" string="House of Representatives" type="NP">
          <tokens>
            <token id="16" string="House" />
            <token id="17" string="of" />
            <token id="18" string="Representatives" />
          </tokens>
        </chunking>
        <chunking id="5" string="Representatives" type="NP">
          <tokens>
            <token id="18" string="Representatives" />
          </tokens>
        </chunking>
        <chunking id="6" string="a seat in the U.S. Senate or House of Representatives" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="seat" />
            <token id="11" string="in" />
            <token id="12" string="the" />
            <token id="13" string="U.S." />
            <token id="14" string="Senate" />
            <token id="15" string="or" />
            <token id="16" string="House" />
            <token id="17" string="of" />
            <token id="18" string="Representatives" />
          </tokens>
        </chunking>
        <chunking id="7" string="has his eye on a seat in the U.S. Senate or House of Representatives" type="VP">
          <tokens>
            <token id="5" string="has" />
            <token id="6" string="his" />
            <token id="7" string="eye" />
            <token id="8" string="on" />
            <token id="9" string="a" />
            <token id="10" string="seat" />
            <token id="11" string="in" />
            <token id="12" string="the" />
            <token id="13" string="U.S." />
            <token id="14" string="Senate" />
            <token id="15" string="or" />
            <token id="16" string="House" />
            <token id="17" string="of" />
            <token id="18" string="Representatives" />
          </tokens>
        </chunking>
        <chunking id="8" string="his eye" type="NP">
          <tokens>
            <token id="6" string="his" />
            <token id="7" string="eye" />
          </tokens>
        </chunking>
        <chunking id="9" string="a seat in the U.S. Senate" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="seat" />
            <token id="11" string="in" />
            <token id="12" string="the" />
            <token id="13" string="U.S." />
            <token id="14" string="Senate" />
          </tokens>
        </chunking>
        <chunking id="10" string="a seat" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="seat" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="neg">
          <governor id="5">has</governor>
          <dependent id="1">Not</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">lawmaker</governor>
          <dependent id="2">every</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">lawmaker</governor>
          <dependent id="3">state</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">has</governor>
          <dependent id="4">lawmaker</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">has</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">eye</governor>
          <dependent id="6">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">has</governor>
          <dependent id="7">eye</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">seat</governor>
          <dependent id="8">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">seat</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">has</governor>
          <dependent id="10">seat</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Senate</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">Senate</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Senate</governor>
          <dependent id="13">U.S.</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">seat</governor>
          <dependent id="14">Senate</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">seat</governor>
          <dependent id="15">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">seat</governor>
          <dependent id="16">House</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Representatives</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">House</governor>
          <dependent id="18">Representatives</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Senate" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="14" string="Senate" />
          </tokens>
        </entity>
        <entity id="2" string="U.S." type="LOCATION" score="0.0">
          <tokens>
            <token id="13" string="U.S." />
          </tokens>
        </entity>
        <entity id="3" string="House of Representatives" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="16" string="House" />
            <token id="17" string="of" />
            <token id="18" string="Representatives" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>But it&amp;apost;s a safe bet that more people will be using state seats to groom for higher office if they know that the law will force them out soon.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="safe" lemma="safe" stem="safe" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="bet" lemma="bet" stem="bet" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="using" lemma="use" stem="us" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="state" lemma="state" stem="state" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="seats" lemma="seat" stem="seat" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="groom" lemma="groom" stem="groom" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="higher" lemma="higher" stem="higher" pos="JJR" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="office" lemma="office" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="know" lemma="know" stem="know" pos="VBP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="law" lemma="law" stem="law" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="27" string="force" lemma="force" stem="forc" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="28" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="29" string="out" lemma="out" stem="out" pos="RB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="30" string="soon" lemma="soon" stem="soon" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (PRP it)) (VP (VBZ 's) (NP (NP (DT a) (JJ safe) (NN bet)) (SBAR (WHNP (WDT that)) (S (NP (JJR more) (NNS people)) (VP (MD will) (VP (VB be) (VP (VBG using) (NP (NN state) (NNS seats)) (PP (TO to) (NP (NN groom))) (PP (IN for) (NP (JJR higher) (NN office))) (SBAR (IN if) (S (NP (PRP they)) (VP (VBP know) (SBAR (IN that) (S (NP (DT the) (NN law)) (VP (MD will) (VP (VB force) (NP (PRP them)) (ADVP (RB out) (RB soon)))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="groom" type="NP">
          <tokens>
            <token id="16" string="groom" />
          </tokens>
        </chunking>
        <chunking id="2" string="if they know that the law will force them out soon" type="SBAR">
          <tokens>
            <token id="20" string="if" />
            <token id="21" string="they" />
            <token id="22" string="know" />
            <token id="23" string="that" />
            <token id="24" string="the" />
            <token id="25" string="law" />
            <token id="26" string="will" />
            <token id="27" string="force" />
            <token id="28" string="them" />
            <token id="29" string="out" />
            <token id="30" string="soon" />
          </tokens>
        </chunking>
        <chunking id="3" string="force them out soon" type="VP">
          <tokens>
            <token id="27" string="force" />
            <token id="28" string="them" />
            <token id="29" string="out" />
            <token id="30" string="soon" />
          </tokens>
        </chunking>
        <chunking id="4" string="be using state seats to groom for higher office if they know that the law will force them out soon" type="VP">
          <tokens>
            <token id="11" string="be" />
            <token id="12" string="using" />
            <token id="13" string="state" />
            <token id="14" string="seats" />
            <token id="15" string="to" />
            <token id="16" string="groom" />
            <token id="17" string="for" />
            <token id="18" string="higher" />
            <token id="19" string="office" />
            <token id="20" string="if" />
            <token id="21" string="they" />
            <token id="22" string="know" />
            <token id="23" string="that" />
            <token id="24" string="the" />
            <token id="25" string="law" />
            <token id="26" string="will" />
            <token id="27" string="force" />
            <token id="28" string="them" />
            <token id="29" string="out" />
            <token id="30" string="soon" />
          </tokens>
        </chunking>
        <chunking id="5" string="that the law will force them out soon" type="SBAR">
          <tokens>
            <token id="23" string="that" />
            <token id="24" string="the" />
            <token id="25" string="law" />
            <token id="26" string="will" />
            <token id="27" string="force" />
            <token id="28" string="them" />
            <token id="29" string="out" />
            <token id="30" string="soon" />
          </tokens>
        </chunking>
        <chunking id="6" string="'s a safe bet that more people will be using state seats to groom for higher office if they know that the law will force them out soon" type="VP">
          <tokens>
            <token id="3" string="'s" />
            <token id="4" string="a" />
            <token id="5" string="safe" />
            <token id="6" string="bet" />
            <token id="7" string="that" />
            <token id="8" string="more" />
            <token id="9" string="people" />
            <token id="10" string="will" />
            <token id="11" string="be" />
            <token id="12" string="using" />
            <token id="13" string="state" />
            <token id="14" string="seats" />
            <token id="15" string="to" />
            <token id="16" string="groom" />
            <token id="17" string="for" />
            <token id="18" string="higher" />
            <token id="19" string="office" />
            <token id="20" string="if" />
            <token id="21" string="they" />
            <token id="22" string="know" />
            <token id="23" string="that" />
            <token id="24" string="the" />
            <token id="25" string="law" />
            <token id="26" string="will" />
            <token id="27" string="force" />
            <token id="28" string="them" />
            <token id="29" string="out" />
            <token id="30" string="soon" />
          </tokens>
        </chunking>
        <chunking id="7" string="more people" type="NP">
          <tokens>
            <token id="8" string="more" />
            <token id="9" string="people" />
          </tokens>
        </chunking>
        <chunking id="8" string="that more people will be using state seats to groom for higher office if they know that the law will force them out soon" type="SBAR">
          <tokens>
            <token id="7" string="that" />
            <token id="8" string="more" />
            <token id="9" string="people" />
            <token id="10" string="will" />
            <token id="11" string="be" />
            <token id="12" string="using" />
            <token id="13" string="state" />
            <token id="14" string="seats" />
            <token id="15" string="to" />
            <token id="16" string="groom" />
            <token id="17" string="for" />
            <token id="18" string="higher" />
            <token id="19" string="office" />
            <token id="20" string="if" />
            <token id="21" string="they" />
            <token id="22" string="know" />
            <token id="23" string="that" />
            <token id="24" string="the" />
            <token id="25" string="law" />
            <token id="26" string="will" />
            <token id="27" string="force" />
            <token id="28" string="them" />
            <token id="29" string="out" />
            <token id="30" string="soon" />
          </tokens>
        </chunking>
        <chunking id="9" string="using state seats to groom for higher office if they know that the law will force them out soon" type="VP">
          <tokens>
            <token id="12" string="using" />
            <token id="13" string="state" />
            <token id="14" string="seats" />
            <token id="15" string="to" />
            <token id="16" string="groom" />
            <token id="17" string="for" />
            <token id="18" string="higher" />
            <token id="19" string="office" />
            <token id="20" string="if" />
            <token id="21" string="they" />
            <token id="22" string="know" />
            <token id="23" string="that" />
            <token id="24" string="the" />
            <token id="25" string="law" />
            <token id="26" string="will" />
            <token id="27" string="force" />
            <token id="28" string="them" />
            <token id="29" string="out" />
            <token id="30" string="soon" />
          </tokens>
        </chunking>
        <chunking id="10" string="it" type="NP">
          <tokens>
            <token id="2" string="it" />
          </tokens>
        </chunking>
        <chunking id="11" string="know that the law will force them out soon" type="VP">
          <tokens>
            <token id="22" string="know" />
            <token id="23" string="that" />
            <token id="24" string="the" />
            <token id="25" string="law" />
            <token id="26" string="will" />
            <token id="27" string="force" />
            <token id="28" string="them" />
            <token id="29" string="out" />
            <token id="30" string="soon" />
          </tokens>
        </chunking>
        <chunking id="12" string="them" type="NP">
          <tokens>
            <token id="28" string="them" />
          </tokens>
        </chunking>
        <chunking id="13" string="a safe bet" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="safe" />
            <token id="6" string="bet" />
          </tokens>
        </chunking>
        <chunking id="14" string="state seats" type="NP">
          <tokens>
            <token id="13" string="state" />
            <token id="14" string="seats" />
          </tokens>
        </chunking>
        <chunking id="15" string="they" type="NP">
          <tokens>
            <token id="21" string="they" />
          </tokens>
        </chunking>
        <chunking id="16" string="will force them out soon" type="VP">
          <tokens>
            <token id="26" string="will" />
            <token id="27" string="force" />
            <token id="28" string="them" />
            <token id="29" string="out" />
            <token id="30" string="soon" />
          </tokens>
        </chunking>
        <chunking id="17" string="a safe bet that more people will be using state seats to groom for higher office if they know that the law will force them out soon" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="safe" />
            <token id="6" string="bet" />
            <token id="7" string="that" />
            <token id="8" string="more" />
            <token id="9" string="people" />
            <token id="10" string="will" />
            <token id="11" string="be" />
            <token id="12" string="using" />
            <token id="13" string="state" />
            <token id="14" string="seats" />
            <token id="15" string="to" />
            <token id="16" string="groom" />
            <token id="17" string="for" />
            <token id="18" string="higher" />
            <token id="19" string="office" />
            <token id="20" string="if" />
            <token id="21" string="they" />
            <token id="22" string="know" />
            <token id="23" string="that" />
            <token id="24" string="the" />
            <token id="25" string="law" />
            <token id="26" string="will" />
            <token id="27" string="force" />
            <token id="28" string="them" />
            <token id="29" string="out" />
            <token id="30" string="soon" />
          </tokens>
        </chunking>
        <chunking id="18" string="will be using state seats to groom for higher office if they know that the law will force them out soon" type="VP">
          <tokens>
            <token id="10" string="will" />
            <token id="11" string="be" />
            <token id="12" string="using" />
            <token id="13" string="state" />
            <token id="14" string="seats" />
            <token id="15" string="to" />
            <token id="16" string="groom" />
            <token id="17" string="for" />
            <token id="18" string="higher" />
            <token id="19" string="office" />
            <token id="20" string="if" />
            <token id="21" string="they" />
            <token id="22" string="know" />
            <token id="23" string="that" />
            <token id="24" string="the" />
            <token id="25" string="law" />
            <token id="26" string="will" />
            <token id="27" string="force" />
            <token id="28" string="them" />
            <token id="29" string="out" />
            <token id="30" string="soon" />
          </tokens>
        </chunking>
        <chunking id="19" string="the law" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="law" />
          </tokens>
        </chunking>
        <chunking id="20" string="higher office" type="NP">
          <tokens>
            <token id="18" string="higher" />
            <token id="19" string="office" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="6">bet</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">bet</governor>
          <dependent id="2">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">bet</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">bet</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">bet</governor>
          <dependent id="5">safe</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">bet</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">using</governor>
          <dependent id="7">that</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">people</governor>
          <dependent id="8">more</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">using</governor>
          <dependent id="9">people</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">using</governor>
          <dependent id="10">will</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">using</governor>
          <dependent id="11">be</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="6">bet</governor>
          <dependent id="12">using</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">seats</governor>
          <dependent id="13">state</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">using</governor>
          <dependent id="14">seats</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">groom</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">using</governor>
          <dependent id="16">groom</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">office</governor>
          <dependent id="17">for</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">office</governor>
          <dependent id="18">higher</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">using</governor>
          <dependent id="19">office</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">know</governor>
          <dependent id="20">if</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">know</governor>
          <dependent id="21">they</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">using</governor>
          <dependent id="22">know</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="27">force</governor>
          <dependent id="23">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">law</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">force</governor>
          <dependent id="25">law</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="27">force</governor>
          <dependent id="26">will</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="22">know</governor>
          <dependent id="27">force</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="27">force</governor>
          <dependent id="28">them</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="30">soon</governor>
          <dependent id="29">out</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="27">force</governor>
          <dependent id="30">soon</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>Lobbyists, of course, will rejoice.</content>
      <tokens>
        <token id="1" string="Lobbyists" lemma="lobbyist" stem="lobbyist" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="course" lemma="course" stem="cours" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="rejoice" lemma="rejoice" stem="rejoic" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNS Lobbyists)) (, ,) (PP (IN of) (NP (NN course))) (, ,)) (VP (MD will) (VP (VB rejoice))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Lobbyists" type="NP">
          <tokens>
            <token id="1" string="Lobbyists" />
          </tokens>
        </chunking>
        <chunking id="2" string="course" type="NP">
          <tokens>
            <token id="4" string="course" />
          </tokens>
        </chunking>
        <chunking id="3" string="rejoice" type="VP">
          <tokens>
            <token id="7" string="rejoice" />
          </tokens>
        </chunking>
        <chunking id="4" string="Lobbyists , of course ," type="NP">
          <tokens>
            <token id="1" string="Lobbyists" />
            <token id="2" string="," />
            <token id="3" string="of" />
            <token id="4" string="course" />
            <token id="5" string="," />
          </tokens>
        </chunking>
        <chunking id="5" string="will rejoice" type="VP">
          <tokens>
            <token id="6" string="will" />
            <token id="7" string="rejoice" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="7">rejoice</governor>
          <dependent id="1">Lobbyists</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">course</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Lobbyists</governor>
          <dependent id="4">course</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">rejoice</governor>
          <dependent id="6">will</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">rejoice</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>Their influence over these legislative birds of passage will grow because they will be guaranteed a perennial crop of callow and ignorant lawmakers.</content>
      <tokens>
        <token id="1" string="Their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="influence" lemma="influence" stem="influenc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="these" lemma="these" stem="these" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="legislative" lemma="legislative" stem="legisl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="birds" lemma="bird" stem="bird" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="passage" lemma="passage" stem="passag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="grow" lemma="grow" stem="grow" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="guaranteed" lemma="guarantee" stem="guarante" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="perennial" lemma="perennial" stem="perenni" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="crop" lemma="crop" stem="crop" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="callow" lemma="callow" stem="callow" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="ignorant" lemma="ignorant" stem="ignor" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="lawmakers" lemma="lawmaker" stem="lawmak" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (PRP$ Their) (NN influence)) (PP (IN over) (NP (NP (DT these) (JJ legislative) (NNS birds)) (PP (IN of) (NP (NN passage)))))) (VP (MD will) (VP (VB grow) (SBAR (IN because) (S (NP (PRP they)) (VP (MD will) (VP (VB be) (VP (VBN guaranteed) (NP (NP (DT a) (JJ perennial) (NN crop)) (PP (IN of) (NP (NN callow) (CC and) (JJ ignorant) (NNS lawmakers))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Their influence over these legislative birds of passage" type="NP">
          <tokens>
            <token id="1" string="Their" />
            <token id="2" string="influence" />
            <token id="3" string="over" />
            <token id="4" string="these" />
            <token id="5" string="legislative" />
            <token id="6" string="birds" />
            <token id="7" string="of" />
            <token id="8" string="passage" />
          </tokens>
        </chunking>
        <chunking id="2" string="grow because they will be guaranteed a perennial crop of callow and ignorant lawmakers" type="VP">
          <tokens>
            <token id="10" string="grow" />
            <token id="11" string="because" />
            <token id="12" string="they" />
            <token id="13" string="will" />
            <token id="14" string="be" />
            <token id="15" string="guaranteed" />
            <token id="16" string="a" />
            <token id="17" string="perennial" />
            <token id="18" string="crop" />
            <token id="19" string="of" />
            <token id="20" string="callow" />
            <token id="21" string="and" />
            <token id="22" string="ignorant" />
            <token id="23" string="lawmakers" />
          </tokens>
        </chunking>
        <chunking id="3" string="guaranteed a perennial crop of callow and ignorant lawmakers" type="VP">
          <tokens>
            <token id="15" string="guaranteed" />
            <token id="16" string="a" />
            <token id="17" string="perennial" />
            <token id="18" string="crop" />
            <token id="19" string="of" />
            <token id="20" string="callow" />
            <token id="21" string="and" />
            <token id="22" string="ignorant" />
            <token id="23" string="lawmakers" />
          </tokens>
        </chunking>
        <chunking id="4" string="these legislative birds of passage" type="NP">
          <tokens>
            <token id="4" string="these" />
            <token id="5" string="legislative" />
            <token id="6" string="birds" />
            <token id="7" string="of" />
            <token id="8" string="passage" />
          </tokens>
        </chunking>
        <chunking id="5" string="passage" type="NP">
          <tokens>
            <token id="8" string="passage" />
          </tokens>
        </chunking>
        <chunking id="6" string="Their influence" type="NP">
          <tokens>
            <token id="1" string="Their" />
            <token id="2" string="influence" />
          </tokens>
        </chunking>
        <chunking id="7" string="callow and ignorant lawmakers" type="NP">
          <tokens>
            <token id="20" string="callow" />
            <token id="21" string="and" />
            <token id="22" string="ignorant" />
            <token id="23" string="lawmakers" />
          </tokens>
        </chunking>
        <chunking id="8" string="will be guaranteed a perennial crop of callow and ignorant lawmakers" type="VP">
          <tokens>
            <token id="13" string="will" />
            <token id="14" string="be" />
            <token id="15" string="guaranteed" />
            <token id="16" string="a" />
            <token id="17" string="perennial" />
            <token id="18" string="crop" />
            <token id="19" string="of" />
            <token id="20" string="callow" />
            <token id="21" string="and" />
            <token id="22" string="ignorant" />
            <token id="23" string="lawmakers" />
          </tokens>
        </chunking>
        <chunking id="9" string="these legislative birds" type="NP">
          <tokens>
            <token id="4" string="these" />
            <token id="5" string="legislative" />
            <token id="6" string="birds" />
          </tokens>
        </chunking>
        <chunking id="10" string="be guaranteed a perennial crop of callow and ignorant lawmakers" type="VP">
          <tokens>
            <token id="14" string="be" />
            <token id="15" string="guaranteed" />
            <token id="16" string="a" />
            <token id="17" string="perennial" />
            <token id="18" string="crop" />
            <token id="19" string="of" />
            <token id="20" string="callow" />
            <token id="21" string="and" />
            <token id="22" string="ignorant" />
            <token id="23" string="lawmakers" />
          </tokens>
        </chunking>
        <chunking id="11" string="a perennial crop" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="perennial" />
            <token id="18" string="crop" />
          </tokens>
        </chunking>
        <chunking id="12" string="they" type="NP">
          <tokens>
            <token id="12" string="they" />
          </tokens>
        </chunking>
        <chunking id="13" string="because they will be guaranteed a perennial crop of callow and ignorant lawmakers" type="SBAR">
          <tokens>
            <token id="11" string="because" />
            <token id="12" string="they" />
            <token id="13" string="will" />
            <token id="14" string="be" />
            <token id="15" string="guaranteed" />
            <token id="16" string="a" />
            <token id="17" string="perennial" />
            <token id="18" string="crop" />
            <token id="19" string="of" />
            <token id="20" string="callow" />
            <token id="21" string="and" />
            <token id="22" string="ignorant" />
            <token id="23" string="lawmakers" />
          </tokens>
        </chunking>
        <chunking id="14" string="will grow because they will be guaranteed a perennial crop of callow and ignorant lawmakers" type="VP">
          <tokens>
            <token id="9" string="will" />
            <token id="10" string="grow" />
            <token id="11" string="because" />
            <token id="12" string="they" />
            <token id="13" string="will" />
            <token id="14" string="be" />
            <token id="15" string="guaranteed" />
            <token id="16" string="a" />
            <token id="17" string="perennial" />
            <token id="18" string="crop" />
            <token id="19" string="of" />
            <token id="20" string="callow" />
            <token id="21" string="and" />
            <token id="22" string="ignorant" />
            <token id="23" string="lawmakers" />
          </tokens>
        </chunking>
        <chunking id="15" string="a perennial crop of callow and ignorant lawmakers" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="perennial" />
            <token id="18" string="crop" />
            <token id="19" string="of" />
            <token id="20" string="callow" />
            <token id="21" string="and" />
            <token id="22" string="ignorant" />
            <token id="23" string="lawmakers" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="2">influence</governor>
          <dependent id="1">Their</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">grow</governor>
          <dependent id="2">influence</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">birds</governor>
          <dependent id="3">over</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">birds</governor>
          <dependent id="4">these</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">birds</governor>
          <dependent id="5">legislative</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">influence</governor>
          <dependent id="6">birds</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">passage</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">birds</governor>
          <dependent id="8">passage</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">grow</governor>
          <dependent id="9">will</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">grow</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">guaranteed</governor>
          <dependent id="11">because</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="15">guaranteed</governor>
          <dependent id="12">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">guaranteed</governor>
          <dependent id="13">will</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="15">guaranteed</governor>
          <dependent id="14">be</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="10">grow</governor>
          <dependent id="15">guaranteed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">crop</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">crop</governor>
          <dependent id="17">perennial</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">guaranteed</governor>
          <dependent id="18">crop</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">lawmakers</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">lawmakers</governor>
          <dependent id="20">callow</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="20">callow</governor>
          <dependent id="21">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="20">callow</governor>
          <dependent id="22">ignorant</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">crop</governor>
          <dependent id="23">lawmakers</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>One thing that legislators now have going for them is that they can become conversant with public issues and so challenge, if they care to, the self-serving propaganda of the special interests.</content>
      <tokens>
        <token id="1" string="One" lemma="one" stem="one" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="2" string="thing" lemma="thing" stem="thing" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="legislators" lemma="legislator" stem="legisl" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="become" lemma="become" stem="becom" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="conversant" lemma="conversant" stem="convers" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="public" lemma="public" stem="public" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="issues" lemma="issue" stem="issu" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="challenge" lemma="challenge" stem="challeng" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="care" lemma="care" stem="care" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="self-serving" lemma="self-serving" stem="self-serv" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="propaganda" lemma="propaganda" stem="propaganda" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="special" lemma="special" stem="special" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="interests" lemma="interest" stem="interest" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (CD One) (NN thing) (SBAR (WHNP (WDT that)) (S (NP (NNS legislators)) (ADVP (RB now)) (VP (VBP have) (S (VP (VBG going) (PP (IN for) (NP (PRP them))))))))) (VP (VBZ is) (SBAR (IN that) (S (NP (PRP they)) (VP (MD can) (VP (VB become) (NP (JJ conversant) (UCP (PP (IN with) (NP (JJ public) (NNS issues))) (CC and) (ADVP (RB so))) (NN challenge)) (, ,) (SBAR (IN if) (S (NP (PRP they)) (VP (VBP care) (S (VP (TO to))) (, ,) (S (NP (NP (DT the) (JJ self-serving) (NN propaganda)) (PP (IN of) (NP (DT the) (JJ special) (NNS interests))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that they can become conversant with public issues and so challenge , if they care to , the self-serving propaganda of the special interests" type="SBAR">
          <tokens>
            <token id="11" string="that" />
            <token id="12" string="they" />
            <token id="13" string="can" />
            <token id="14" string="become" />
            <token id="15" string="conversant" />
            <token id="16" string="with" />
            <token id="17" string="public" />
            <token id="18" string="issues" />
            <token id="19" string="and" />
            <token id="20" string="so" />
            <token id="21" string="challenge" />
            <token id="22" string="," />
            <token id="23" string="if" />
            <token id="24" string="they" />
            <token id="25" string="care" />
            <token id="26" string="to" />
            <token id="27" string="," />
            <token id="28" string="the" />
            <token id="29" string="self-serving" />
            <token id="30" string="propaganda" />
            <token id="31" string="of" />
            <token id="32" string="the" />
            <token id="33" string="special" />
            <token id="34" string="interests" />
          </tokens>
        </chunking>
        <chunking id="2" string="public issues" type="NP">
          <tokens>
            <token id="17" string="public" />
            <token id="18" string="issues" />
          </tokens>
        </chunking>
        <chunking id="3" string="the self-serving propaganda of the special interests" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="self-serving" />
            <token id="30" string="propaganda" />
            <token id="31" string="of" />
            <token id="32" string="the" />
            <token id="33" string="special" />
            <token id="34" string="interests" />
          </tokens>
        </chunking>
        <chunking id="4" string="can become conversant with public issues and so challenge , if they care to , the self-serving propaganda of the special interests" type="VP">
          <tokens>
            <token id="13" string="can" />
            <token id="14" string="become" />
            <token id="15" string="conversant" />
            <token id="16" string="with" />
            <token id="17" string="public" />
            <token id="18" string="issues" />
            <token id="19" string="and" />
            <token id="20" string="so" />
            <token id="21" string="challenge" />
            <token id="22" string="," />
            <token id="23" string="if" />
            <token id="24" string="they" />
            <token id="25" string="care" />
            <token id="26" string="to" />
            <token id="27" string="," />
            <token id="28" string="the" />
            <token id="29" string="self-serving" />
            <token id="30" string="propaganda" />
            <token id="31" string="of" />
            <token id="32" string="the" />
            <token id="33" string="special" />
            <token id="34" string="interests" />
          </tokens>
        </chunking>
        <chunking id="5" string="is that they can become conversant with public issues and so challenge , if they care to , the self-serving propaganda of the special interests" type="VP">
          <tokens>
            <token id="10" string="is" />
            <token id="11" string="that" />
            <token id="12" string="they" />
            <token id="13" string="can" />
            <token id="14" string="become" />
            <token id="15" string="conversant" />
            <token id="16" string="with" />
            <token id="17" string="public" />
            <token id="18" string="issues" />
            <token id="19" string="and" />
            <token id="20" string="so" />
            <token id="21" string="challenge" />
            <token id="22" string="," />
            <token id="23" string="if" />
            <token id="24" string="they" />
            <token id="25" string="care" />
            <token id="26" string="to" />
            <token id="27" string="," />
            <token id="28" string="the" />
            <token id="29" string="self-serving" />
            <token id="30" string="propaganda" />
            <token id="31" string="of" />
            <token id="32" string="the" />
            <token id="33" string="special" />
            <token id="34" string="interests" />
          </tokens>
        </chunking>
        <chunking id="6" string="become conversant with public issues and so challenge , if they care to , the self-serving propaganda of the special interests" type="VP">
          <tokens>
            <token id="14" string="become" />
            <token id="15" string="conversant" />
            <token id="16" string="with" />
            <token id="17" string="public" />
            <token id="18" string="issues" />
            <token id="19" string="and" />
            <token id="20" string="so" />
            <token id="21" string="challenge" />
            <token id="22" string="," />
            <token id="23" string="if" />
            <token id="24" string="they" />
            <token id="25" string="care" />
            <token id="26" string="to" />
            <token id="27" string="," />
            <token id="28" string="the" />
            <token id="29" string="self-serving" />
            <token id="30" string="propaganda" />
            <token id="31" string="of" />
            <token id="32" string="the" />
            <token id="33" string="special" />
            <token id="34" string="interests" />
          </tokens>
        </chunking>
        <chunking id="7" string="if they care to , the self-serving propaganda of the special interests" type="SBAR">
          <tokens>
            <token id="23" string="if" />
            <token id="24" string="they" />
            <token id="25" string="care" />
            <token id="26" string="to" />
            <token id="27" string="," />
            <token id="28" string="the" />
            <token id="29" string="self-serving" />
            <token id="30" string="propaganda" />
            <token id="31" string="of" />
            <token id="32" string="the" />
            <token id="33" string="special" />
            <token id="34" string="interests" />
          </tokens>
        </chunking>
        <chunking id="8" string="have going for them" type="VP">
          <tokens>
            <token id="6" string="have" />
            <token id="7" string="going" />
            <token id="8" string="for" />
            <token id="9" string="them" />
          </tokens>
        </chunking>
        <chunking id="9" string="care to , the self-serving propaganda of the special interests" type="VP">
          <tokens>
            <token id="25" string="care" />
            <token id="26" string="to" />
            <token id="27" string="," />
            <token id="28" string="the" />
            <token id="29" string="self-serving" />
            <token id="30" string="propaganda" />
            <token id="31" string="of" />
            <token id="32" string="the" />
            <token id="33" string="special" />
            <token id="34" string="interests" />
          </tokens>
        </chunking>
        <chunking id="10" string="going for them" type="VP">
          <tokens>
            <token id="7" string="going" />
            <token id="8" string="for" />
            <token id="9" string="them" />
          </tokens>
        </chunking>
        <chunking id="11" string="them" type="NP">
          <tokens>
            <token id="9" string="them" />
          </tokens>
        </chunking>
        <chunking id="12" string="the self-serving propaganda" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="self-serving" />
            <token id="30" string="propaganda" />
          </tokens>
        </chunking>
        <chunking id="13" string="that legislators now have going for them" type="SBAR">
          <tokens>
            <token id="3" string="that" />
            <token id="4" string="legislators" />
            <token id="5" string="now" />
            <token id="6" string="have" />
            <token id="7" string="going" />
            <token id="8" string="for" />
            <token id="9" string="them" />
          </tokens>
        </chunking>
        <chunking id="14" string="they" type="NP">
          <tokens>
            <token id="12" string="they" />
          </tokens>
        </chunking>
        <chunking id="15" string="legislators" type="NP">
          <tokens>
            <token id="4" string="legislators" />
          </tokens>
        </chunking>
        <chunking id="16" string="the special interests" type="NP">
          <tokens>
            <token id="32" string="the" />
            <token id="33" string="special" />
            <token id="34" string="interests" />
          </tokens>
        </chunking>
        <chunking id="17" string="conversant with public issues and so challenge" type="NP">
          <tokens>
            <token id="15" string="conversant" />
            <token id="16" string="with" />
            <token id="17" string="public" />
            <token id="18" string="issues" />
            <token id="19" string="and" />
            <token id="20" string="so" />
            <token id="21" string="challenge" />
          </tokens>
        </chunking>
        <chunking id="18" string="One thing that legislators now have going for them" type="NP">
          <tokens>
            <token id="1" string="One" />
            <token id="2" string="thing" />
            <token id="3" string="that" />
            <token id="4" string="legislators" />
            <token id="5" string="now" />
            <token id="6" string="have" />
            <token id="7" string="going" />
            <token id="8" string="for" />
            <token id="9" string="them" />
          </tokens>
        </chunking>
        <chunking id="19" string="to" type="VP">
          <tokens>
            <token id="26" string="to" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nummod">
          <governor id="2">thing</governor>
          <dependent id="1">One</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">is</governor>
          <dependent id="2">thing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">going</governor>
          <dependent id="3">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">have</governor>
          <dependent id="4">legislators</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">have</governor>
          <dependent id="5">now</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">thing</governor>
          <dependent id="6">have</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">have</governor>
          <dependent id="7">going</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">them</governor>
          <dependent id="8">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">going</governor>
          <dependent id="9">them</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">is</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">become</governor>
          <dependent id="11">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">become</governor>
          <dependent id="12">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">become</governor>
          <dependent id="13">can</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">is</governor>
          <dependent id="14">become</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">challenge</governor>
          <dependent id="15">conversant</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">issues</governor>
          <dependent id="16">with</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">issues</governor>
          <dependent id="17">public</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">challenge</governor>
          <dependent id="18">issues</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="18">issues</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">issues</governor>
          <dependent id="20">so</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="14">become</governor>
          <dependent id="21">challenge</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="25">care</governor>
          <dependent id="23">if</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">care</governor>
          <dependent id="24">they</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="14">become</governor>
          <dependent id="25">care</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="25">care</governor>
          <dependent id="26">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">propaganda</governor>
          <dependent id="28">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="30">propaganda</governor>
          <dependent id="29">self-serving</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="25">care</governor>
          <dependent id="30">propaganda</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">interests</governor>
          <dependent id="31">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">interests</governor>
          <dependent id="32">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="34">interests</governor>
          <dependent id="33">special</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">propaganda</governor>
          <dependent id="34">interests</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="One" type="NUMBER" score="0.0">
          <tokens>
            <token id="1" string="One" />
          </tokens>
        </entity>
        <entity id="2" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="5" string="now" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>Celebrating, along with the lobbyists, will be the legislative staffs whose tenure would be unaffected.</content>
      <tokens>
        <token id="1" string="Celebrating" lemma="celebrate" stem="celebr" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="along" lemma="along" stem="along" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="lobbyists" lemma="lobbyist" stem="lobbyist" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="legislative" lemma="legislative" stem="legisl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="staffs" lemma="staff" stem="staff" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="whose" lemma="whose" stem="whose" pos="WP$" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="tenure" lemma="tenure" stem="tenur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="unaffected" lemma="unaffected" stem="unaffect" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VBG Celebrating))) (, ,) (ADVP (IN along) (PP (IN with) (NP (DT the) (NNS lobbyists)))) (, ,) (VP (MD will) (VP (VB be) (NP (NP (DT the) (JJ legislative) (NNS staffs)) (SBAR (WHNP (WP$ whose) (NN tenure)) (S (VP (MD would) (VP (VB be) (ADJP (JJ unaffected))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the legislative staffs" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="legislative" />
            <token id="12" string="staffs" />
          </tokens>
        </chunking>
        <chunking id="2" string="Celebrating" type="VP">
          <tokens>
            <token id="1" string="Celebrating" />
          </tokens>
        </chunking>
        <chunking id="3" string="the legislative staffs whose tenure would be unaffected" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="legislative" />
            <token id="12" string="staffs" />
            <token id="13" string="whose" />
            <token id="14" string="tenure" />
            <token id="15" string="would" />
            <token id="16" string="be" />
            <token id="17" string="unaffected" />
          </tokens>
        </chunking>
        <chunking id="4" string="the lobbyists" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="lobbyists" />
          </tokens>
        </chunking>
        <chunking id="5" string="be the legislative staffs whose tenure would be unaffected" type="VP">
          <tokens>
            <token id="9" string="be" />
            <token id="10" string="the" />
            <token id="11" string="legislative" />
            <token id="12" string="staffs" />
            <token id="13" string="whose" />
            <token id="14" string="tenure" />
            <token id="15" string="would" />
            <token id="16" string="be" />
            <token id="17" string="unaffected" />
          </tokens>
        </chunking>
        <chunking id="6" string="whose tenure would be unaffected" type="SBAR">
          <tokens>
            <token id="13" string="whose" />
            <token id="14" string="tenure" />
            <token id="15" string="would" />
            <token id="16" string="be" />
            <token id="17" string="unaffected" />
          </tokens>
        </chunking>
        <chunking id="7" string="would be unaffected" type="VP">
          <tokens>
            <token id="15" string="would" />
            <token id="16" string="be" />
            <token id="17" string="unaffected" />
          </tokens>
        </chunking>
        <chunking id="8" string="will be the legislative staffs whose tenure would be unaffected" type="VP">
          <tokens>
            <token id="8" string="will" />
            <token id="9" string="be" />
            <token id="10" string="the" />
            <token id="11" string="legislative" />
            <token id="12" string="staffs" />
            <token id="13" string="whose" />
            <token id="14" string="tenure" />
            <token id="15" string="would" />
            <token id="16" string="be" />
            <token id="17" string="unaffected" />
          </tokens>
        </chunking>
        <chunking id="9" string="be unaffected" type="VP">
          <tokens>
            <token id="16" string="be" />
            <token id="17" string="unaffected" />
          </tokens>
        </chunking>
        <chunking id="10" string="unaffected" type="ADJP">
          <tokens>
            <token id="17" string="unaffected" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="dep">
          <governor id="12">staffs</governor>
          <dependent id="1">Celebrating</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">staffs</governor>
          <dependent id="3">along</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">lobbyists</governor>
          <dependent id="4">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">lobbyists</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">along</governor>
          <dependent id="6">lobbyists</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">staffs</governor>
          <dependent id="8">will</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">staffs</governor>
          <dependent id="9">be</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">staffs</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">staffs</governor>
          <dependent id="11">legislative</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">staffs</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">tenure</governor>
          <dependent id="13">whose</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">unaffected</governor>
          <dependent id="14">tenure</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="17">unaffected</governor>
          <dependent id="15">would</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="17">unaffected</governor>
          <dependent id="16">be</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="12">staffs</governor>
          <dependent id="17">unaffected</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="26" has_coreference="true">
      <content>These unelected officials are permanent and beyond the reach of voters, while the very people who are in some measure accountable will be hustled out of office.</content>
      <tokens>
        <token id="1" string="These" lemma="these" stem="these" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="unelected" lemma="unelected" stem="unelect" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="officials" lemma="official" stem="offici" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="permanent" lemma="permanent" stem="perman" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="beyond" lemma="beyond" stem="beyond" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="reach" lemma="reach" stem="reach" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="voters" lemma="voter" stem="voter" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="while" lemma="while" stem="while" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="very" lemma="very" stem="veri" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="measure" lemma="measure" stem="measur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="accountable" lemma="accountable" stem="account" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="23" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="hustled" lemma="hustle" stem="hustl" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="out" lemma="out" stem="out" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="office" lemma="office" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT These) (JJ unelected) (NNS officials)) (VP (VBP are) (UCP (ADJP (JJ permanent)) (CC and) (PP (IN beyond) (NP (NP (DT the) (NN reach)) (PP (IN of) (NP (NNS voters)))))) (, ,) (SBAR (IN while) (S (NP (NP (DT the) (JJ very) (NNS people)) (SBAR (WHNP (WP who)) (S (VP (VBP are) (ADVP (IN in) (NP (DT some) (NN measure))) (ADJP (JJ accountable)))))) (VP (MD will) (VP (VB be) (VP (VBN hustled) (PRT (IN out)) (PP (IN of) (NP (NN office))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the reach of voters" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="reach" />
            <token id="10" string="of" />
            <token id="11" string="voters" />
          </tokens>
        </chunking>
        <chunking id="2" string="accountable" type="ADJP">
          <tokens>
            <token id="22" string="accountable" />
          </tokens>
        </chunking>
        <chunking id="3" string="the reach" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="reach" />
          </tokens>
        </chunking>
        <chunking id="4" string="will be hustled out of office" type="VP">
          <tokens>
            <token id="23" string="will" />
            <token id="24" string="be" />
            <token id="25" string="hustled" />
            <token id="26" string="out" />
            <token id="27" string="of" />
            <token id="28" string="office" />
          </tokens>
        </chunking>
        <chunking id="5" string="voters" type="NP">
          <tokens>
            <token id="11" string="voters" />
          </tokens>
        </chunking>
        <chunking id="6" string="while the very people who are in some measure accountable will be hustled out of office" type="SBAR">
          <tokens>
            <token id="13" string="while" />
            <token id="14" string="the" />
            <token id="15" string="very" />
            <token id="16" string="people" />
            <token id="17" string="who" />
            <token id="18" string="are" />
            <token id="19" string="in" />
            <token id="20" string="some" />
            <token id="21" string="measure" />
            <token id="22" string="accountable" />
            <token id="23" string="will" />
            <token id="24" string="be" />
            <token id="25" string="hustled" />
            <token id="26" string="out" />
            <token id="27" string="of" />
            <token id="28" string="office" />
          </tokens>
        </chunking>
        <chunking id="7" string="be hustled out of office" type="VP">
          <tokens>
            <token id="24" string="be" />
            <token id="25" string="hustled" />
            <token id="26" string="out" />
            <token id="27" string="of" />
            <token id="28" string="office" />
          </tokens>
        </chunking>
        <chunking id="8" string="the very people" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="very" />
            <token id="16" string="people" />
          </tokens>
        </chunking>
        <chunking id="9" string="office" type="NP">
          <tokens>
            <token id="28" string="office" />
          </tokens>
        </chunking>
        <chunking id="10" string="These unelected officials" type="NP">
          <tokens>
            <token id="1" string="These" />
            <token id="2" string="unelected" />
            <token id="3" string="officials" />
          </tokens>
        </chunking>
        <chunking id="11" string="are in some measure accountable" type="VP">
          <tokens>
            <token id="18" string="are" />
            <token id="19" string="in" />
            <token id="20" string="some" />
            <token id="21" string="measure" />
            <token id="22" string="accountable" />
          </tokens>
        </chunking>
        <chunking id="12" string="permanent" type="ADJP">
          <tokens>
            <token id="5" string="permanent" />
          </tokens>
        </chunking>
        <chunking id="13" string="who are in some measure accountable" type="SBAR">
          <tokens>
            <token id="17" string="who" />
            <token id="18" string="are" />
            <token id="19" string="in" />
            <token id="20" string="some" />
            <token id="21" string="measure" />
            <token id="22" string="accountable" />
          </tokens>
        </chunking>
        <chunking id="14" string="the very people who are in some measure accountable" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="very" />
            <token id="16" string="people" />
            <token id="17" string="who" />
            <token id="18" string="are" />
            <token id="19" string="in" />
            <token id="20" string="some" />
            <token id="21" string="measure" />
            <token id="22" string="accountable" />
          </tokens>
        </chunking>
        <chunking id="15" string="hustled out of office" type="VP">
          <tokens>
            <token id="25" string="hustled" />
            <token id="26" string="out" />
            <token id="27" string="of" />
            <token id="28" string="office" />
          </tokens>
        </chunking>
        <chunking id="16" string="are permanent and beyond the reach of voters , while the very people who are in some measure accountable will be hustled out of office" type="VP">
          <tokens>
            <token id="4" string="are" />
            <token id="5" string="permanent" />
            <token id="6" string="and" />
            <token id="7" string="beyond" />
            <token id="8" string="the" />
            <token id="9" string="reach" />
            <token id="10" string="of" />
            <token id="11" string="voters" />
            <token id="12" string="," />
            <token id="13" string="while" />
            <token id="14" string="the" />
            <token id="15" string="very" />
            <token id="16" string="people" />
            <token id="17" string="who" />
            <token id="18" string="are" />
            <token id="19" string="in" />
            <token id="20" string="some" />
            <token id="21" string="measure" />
            <token id="22" string="accountable" />
            <token id="23" string="will" />
            <token id="24" string="be" />
            <token id="25" string="hustled" />
            <token id="26" string="out" />
            <token id="27" string="of" />
            <token id="28" string="office" />
          </tokens>
        </chunking>
        <chunking id="17" string="some measure" type="NP">
          <tokens>
            <token id="20" string="some" />
            <token id="21" string="measure" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">officials</governor>
          <dependent id="1">These</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">officials</governor>
          <dependent id="2">unelected</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">permanent</governor>
          <dependent id="3">officials</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">permanent</governor>
          <dependent id="4">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">permanent</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">permanent</governor>
          <dependent id="6">and</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">reach</governor>
          <dependent id="7">beyond</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">reach</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">permanent</governor>
          <dependent id="9">reach</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">voters</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">reach</governor>
          <dependent id="11">voters</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="25">hustled</governor>
          <dependent id="13">while</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">people</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">people</governor>
          <dependent id="15">very</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="25">hustled</governor>
          <dependent id="16">people</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">accountable</governor>
          <dependent id="17">who</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="22">accountable</governor>
          <dependent id="18">are</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">measure</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">measure</governor>
          <dependent id="20">some</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="22">accountable</governor>
          <dependent id="21">measure</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="16">people</governor>
          <dependent id="22">accountable</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="25">hustled</governor>
          <dependent id="23">will</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="25">hustled</governor>
          <dependent id="24">be</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">permanent</governor>
          <dependent id="25">hustled</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="25">hustled</governor>
          <dependent id="26">out</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">office</governor>
          <dependent id="27">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">hustled</governor>
          <dependent id="28">office</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>Ultimately, what the term limit amounts to is an indictment of citizenship.</content>
      <tokens>
        <token id="1" string="Ultimately" lemma="ultimately" stem="ultimat" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="term" lemma="term" stem="term" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="limit" lemma="limit" stem="limit" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="amounts" lemma="amount" stem="amount" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="indictment" lemma="indictment" stem="indict" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="citizenship" lemma="citizenship" stem="citizenship" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Ultimately)) (, ,) (X (WP what)) (NP (DT the) (NN term) (NN limit)) (VP (VBZ amounts) (S (VP (TO to) (VP (VBZ is) (NP (NP (DT an) (NN indictment)) (PP (IN of) (NP (NN citizenship)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="citizenship" type="NP">
          <tokens>
            <token id="13" string="citizenship" />
          </tokens>
        </chunking>
        <chunking id="2" string="is an indictment of citizenship" type="VP">
          <tokens>
            <token id="9" string="is" />
            <token id="10" string="an" />
            <token id="11" string="indictment" />
            <token id="12" string="of" />
            <token id="13" string="citizenship" />
          </tokens>
        </chunking>
        <chunking id="3" string="an indictment of citizenship" type="NP">
          <tokens>
            <token id="10" string="an" />
            <token id="11" string="indictment" />
            <token id="12" string="of" />
            <token id="13" string="citizenship" />
          </tokens>
        </chunking>
        <chunking id="4" string="to is an indictment of citizenship" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="is" />
            <token id="10" string="an" />
            <token id="11" string="indictment" />
            <token id="12" string="of" />
            <token id="13" string="citizenship" />
          </tokens>
        </chunking>
        <chunking id="5" string="an indictment" type="NP">
          <tokens>
            <token id="10" string="an" />
            <token id="11" string="indictment" />
          </tokens>
        </chunking>
        <chunking id="6" string="the term limit" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="term" />
            <token id="6" string="limit" />
          </tokens>
        </chunking>
        <chunking id="7" string="amounts to is an indictment of citizenship" type="VP">
          <tokens>
            <token id="7" string="amounts" />
            <token id="8" string="to" />
            <token id="9" string="is" />
            <token id="10" string="an" />
            <token id="11" string="indictment" />
            <token id="12" string="of" />
            <token id="13" string="citizenship" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="7">amounts</governor>
          <dependent id="1">Ultimately</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">amounts</governor>
          <dependent id="3">what</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">limit</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">limit</governor>
          <dependent id="5">term</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">amounts</governor>
          <dependent id="6">limit</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">amounts</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">indictment</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">indictment</governor>
          <dependent id="9">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">indictment</governor>
          <dependent id="10">an</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">amounts</governor>
          <dependent id="11">indictment</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">citizenship</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">indictment</governor>
          <dependent id="13">citizenship</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="28" has_coreference="true">
      <content>It is an admission that the voters are civic imbeciles who cannot discriminate between bad lawmakers and good ones.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="admission" lemma="admission" stem="admiss" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="voters" lemma="voter" stem="voter" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="civic" lemma="civic" stem="civic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="imbeciles" lemma="imbecile" stem="imbecil" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="discriminate" lemma="discriminate" stem="discrimin" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="between" lemma="between" stem="between" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="bad" lemma="bad" stem="bad" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="lawmakers" lemma="lawmaker" stem="lawmak" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="good" lemma="good" stem="good" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="ones" lemma="one" stem="on" pos="NNS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBZ is) (NP (DT an) (NN admission)) (SBAR (IN that) (S (NP (DT the) (NNS voters)) (VP (VBP are) (NP (NP (JJ civic) (NNS imbeciles)) (SBAR (WHNP (WP who)) (S (VP (MD can) (RB not) (VP (VB discriminate) (PP (IN between) (NP (NP (JJ bad) (NNS lawmakers)) (CC and) (NP (JJ good) (NNS ones))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="civic imbeciles who can not discriminate between bad lawmakers and good ones" type="NP">
          <tokens>
            <token id="9" string="civic" />
            <token id="10" string="imbeciles" />
            <token id="11" string="who" />
            <token id="12" string="can" />
            <token id="13" string="not" />
            <token id="14" string="discriminate" />
            <token id="15" string="between" />
            <token id="16" string="bad" />
            <token id="17" string="lawmakers" />
            <token id="18" string="and" />
            <token id="19" string="good" />
            <token id="20" string="ones" />
          </tokens>
        </chunking>
        <chunking id="2" string="can not discriminate between bad lawmakers and good ones" type="VP">
          <tokens>
            <token id="12" string="can" />
            <token id="13" string="not" />
            <token id="14" string="discriminate" />
            <token id="15" string="between" />
            <token id="16" string="bad" />
            <token id="17" string="lawmakers" />
            <token id="18" string="and" />
            <token id="19" string="good" />
            <token id="20" string="ones" />
          </tokens>
        </chunking>
        <chunking id="3" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="4" string="discriminate between bad lawmakers and good ones" type="VP">
          <tokens>
            <token id="14" string="discriminate" />
            <token id="15" string="between" />
            <token id="16" string="bad" />
            <token id="17" string="lawmakers" />
            <token id="18" string="and" />
            <token id="19" string="good" />
            <token id="20" string="ones" />
          </tokens>
        </chunking>
        <chunking id="5" string="bad lawmakers and good ones" type="NP">
          <tokens>
            <token id="16" string="bad" />
            <token id="17" string="lawmakers" />
            <token id="18" string="and" />
            <token id="19" string="good" />
            <token id="20" string="ones" />
          </tokens>
        </chunking>
        <chunking id="6" string="bad lawmakers" type="NP">
          <tokens>
            <token id="16" string="bad" />
            <token id="17" string="lawmakers" />
          </tokens>
        </chunking>
        <chunking id="7" string="an admission" type="NP">
          <tokens>
            <token id="3" string="an" />
            <token id="4" string="admission" />
          </tokens>
        </chunking>
        <chunking id="8" string="civic imbeciles" type="NP">
          <tokens>
            <token id="9" string="civic" />
            <token id="10" string="imbeciles" />
          </tokens>
        </chunking>
        <chunking id="9" string="who can not discriminate between bad lawmakers and good ones" type="SBAR">
          <tokens>
            <token id="11" string="who" />
            <token id="12" string="can" />
            <token id="13" string="not" />
            <token id="14" string="discriminate" />
            <token id="15" string="between" />
            <token id="16" string="bad" />
            <token id="17" string="lawmakers" />
            <token id="18" string="and" />
            <token id="19" string="good" />
            <token id="20" string="ones" />
          </tokens>
        </chunking>
        <chunking id="10" string="good ones" type="NP">
          <tokens>
            <token id="19" string="good" />
            <token id="20" string="ones" />
          </tokens>
        </chunking>
        <chunking id="11" string="that the voters are civic imbeciles who can not discriminate between bad lawmakers and good ones" type="SBAR">
          <tokens>
            <token id="5" string="that" />
            <token id="6" string="the" />
            <token id="7" string="voters" />
            <token id="8" string="are" />
            <token id="9" string="civic" />
            <token id="10" string="imbeciles" />
            <token id="11" string="who" />
            <token id="12" string="can" />
            <token id="13" string="not" />
            <token id="14" string="discriminate" />
            <token id="15" string="between" />
            <token id="16" string="bad" />
            <token id="17" string="lawmakers" />
            <token id="18" string="and" />
            <token id="19" string="good" />
            <token id="20" string="ones" />
          </tokens>
        </chunking>
        <chunking id="12" string="the voters" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="voters" />
          </tokens>
        </chunking>
        <chunking id="13" string="are civic imbeciles who can not discriminate between bad lawmakers and good ones" type="VP">
          <tokens>
            <token id="8" string="are" />
            <token id="9" string="civic" />
            <token id="10" string="imbeciles" />
            <token id="11" string="who" />
            <token id="12" string="can" />
            <token id="13" string="not" />
            <token id="14" string="discriminate" />
            <token id="15" string="between" />
            <token id="16" string="bad" />
            <token id="17" string="lawmakers" />
            <token id="18" string="and" />
            <token id="19" string="good" />
            <token id="20" string="ones" />
          </tokens>
        </chunking>
        <chunking id="14" string="is an admission that the voters are civic imbeciles who can not discriminate between bad lawmakers and good ones" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="an" />
            <token id="4" string="admission" />
            <token id="5" string="that" />
            <token id="6" string="the" />
            <token id="7" string="voters" />
            <token id="8" string="are" />
            <token id="9" string="civic" />
            <token id="10" string="imbeciles" />
            <token id="11" string="who" />
            <token id="12" string="can" />
            <token id="13" string="not" />
            <token id="14" string="discriminate" />
            <token id="15" string="between" />
            <token id="16" string="bad" />
            <token id="17" string="lawmakers" />
            <token id="18" string="and" />
            <token id="19" string="good" />
            <token id="20" string="ones" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">admission</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">admission</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">admission</governor>
          <dependent id="3">an</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">admission</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">imbeciles</governor>
          <dependent id="5">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">voters</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">imbeciles</governor>
          <dependent id="7">voters</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="10">imbeciles</governor>
          <dependent id="8">are</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">imbeciles</governor>
          <dependent id="9">civic</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">admission</governor>
          <dependent id="10">imbeciles</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">discriminate</governor>
          <dependent id="11">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">discriminate</governor>
          <dependent id="12">can</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="14">discriminate</governor>
          <dependent id="13">not</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="10">imbeciles</governor>
          <dependent id="14">discriminate</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">lawmakers</governor>
          <dependent id="15">between</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">lawmakers</governor>
          <dependent id="16">bad</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">discriminate</governor>
          <dependent id="17">lawmakers</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">lawmakers</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">ones</governor>
          <dependent id="19">good</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">lawmakers</governor>
          <dependent id="20">ones</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="29" has_coreference="true">
      <content>Where surgical strikes are needed to eliminate the incompetent or corrupt, the term limitation uses carpet bombing in the hope that in the resulting carnage, some of the guilty will suffer along with the innocent.</content>
      <tokens>
        <token id="1" string="Where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="surgical" lemma="surgical" stem="surgic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="strikes" lemma="strike" stem="strike" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="needed" lemma="need" stem="need" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="eliminate" lemma="eliminate" stem="elimin" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="incompetent" lemma="incompetent" stem="incompet" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="corrupt" lemma="corrupt" stem="corrupt" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="term" lemma="term" stem="term" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="limitation" lemma="limitation" stem="limit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="uses" lemma="use" stem="us" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="carpet" lemma="carpet" stem="carpet" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="bombing" lemma="bombing" stem="bomb" pos="NN" type="Word" isStopWord="false" ner="CRIMINAL_CHARGE" is_referenced="false" is_refers="false" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="hope" lemma="hope" stem="hope" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="resulting" lemma="result" stem="result" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="carnage" lemma="carnage" stem="carnag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="guilty" lemma="guilty" stem="guilti" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="suffer" lemma="suffer" stem="suffer" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="along" lemma="along" stem="along" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="innocent" lemma="innocent" stem="innoc" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (WHADVP (WRB Where)) (S (NP (JJ surgical) (NNS strikes)) (VP (VBP are) (UCP (VP (VBN needed) (S (VP (TO to) (VP (VB eliminate) (NP (DT the) (JJ incompetent)))))) (CC or) (ADJP (JJ corrupt)))))) (, ,) (NP (DT the) (NN term) (NN limitation)) (VP (VBZ uses) (NP (NN carpet) (NN bombing)) (PP (IN in) (NP (DT the) (NN hope))) (SBAR (IN that) (S (PP (IN in) (NP (DT the) (VBG resulting) (NN carnage))) (, ,) (NP (NP (DT some)) (PP (IN of) (NP (DT the) (JJ guilty)))) (VP (MD will) (VP (VB suffer) (ADVP (IN along)) (PP (IN with) (NP (DT the) (JJ innocent)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="uses carpet bombing in the hope that in the resulting carnage , some of the guilty will suffer along with the innocent" type="VP">
          <tokens>
            <token id="16" string="uses" />
            <token id="17" string="carpet" />
            <token id="18" string="bombing" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="hope" />
            <token id="22" string="that" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="resulting" />
            <token id="26" string="carnage" />
            <token id="27" string="," />
            <token id="28" string="some" />
            <token id="29" string="of" />
            <token id="30" string="the" />
            <token id="31" string="guilty" />
            <token id="32" string="will" />
            <token id="33" string="suffer" />
            <token id="34" string="along" />
            <token id="35" string="with" />
            <token id="36" string="the" />
            <token id="37" string="innocent" />
          </tokens>
        </chunking>
        <chunking id="2" string="the resulting carnage" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="resulting" />
            <token id="26" string="carnage" />
          </tokens>
        </chunking>
        <chunking id="3" string="corrupt" type="ADJP">
          <tokens>
            <token id="11" string="corrupt" />
          </tokens>
        </chunking>
        <chunking id="4" string="suffer along with the innocent" type="VP">
          <tokens>
            <token id="33" string="suffer" />
            <token id="34" string="along" />
            <token id="35" string="with" />
            <token id="36" string="the" />
            <token id="37" string="innocent" />
          </tokens>
        </chunking>
        <chunking id="5" string="eliminate the incompetent" type="VP">
          <tokens>
            <token id="7" string="eliminate" />
            <token id="8" string="the" />
            <token id="9" string="incompetent" />
          </tokens>
        </chunking>
        <chunking id="6" string="some" type="NP">
          <tokens>
            <token id="28" string="some" />
          </tokens>
        </chunking>
        <chunking id="7" string="are needed to eliminate the incompetent or corrupt" type="VP">
          <tokens>
            <token id="4" string="are" />
            <token id="5" string="needed" />
            <token id="6" string="to" />
            <token id="7" string="eliminate" />
            <token id="8" string="the" />
            <token id="9" string="incompetent" />
            <token id="10" string="or" />
            <token id="11" string="corrupt" />
          </tokens>
        </chunking>
        <chunking id="8" string="the innocent" type="NP">
          <tokens>
            <token id="36" string="the" />
            <token id="37" string="innocent" />
          </tokens>
        </chunking>
        <chunking id="9" string="needed to eliminate the incompetent" type="VP">
          <tokens>
            <token id="5" string="needed" />
            <token id="6" string="to" />
            <token id="7" string="eliminate" />
            <token id="8" string="the" />
            <token id="9" string="incompetent" />
          </tokens>
        </chunking>
        <chunking id="10" string="the term limitation" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="term" />
            <token id="15" string="limitation" />
          </tokens>
        </chunking>
        <chunking id="11" string="that in the resulting carnage , some of the guilty will suffer along with the innocent" type="SBAR">
          <tokens>
            <token id="22" string="that" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="resulting" />
            <token id="26" string="carnage" />
            <token id="27" string="," />
            <token id="28" string="some" />
            <token id="29" string="of" />
            <token id="30" string="the" />
            <token id="31" string="guilty" />
            <token id="32" string="will" />
            <token id="33" string="suffer" />
            <token id="34" string="along" />
            <token id="35" string="with" />
            <token id="36" string="the" />
            <token id="37" string="innocent" />
          </tokens>
        </chunking>
        <chunking id="12" string="will suffer along with the innocent" type="VP">
          <tokens>
            <token id="32" string="will" />
            <token id="33" string="suffer" />
            <token id="34" string="along" />
            <token id="35" string="with" />
            <token id="36" string="the" />
            <token id="37" string="innocent" />
          </tokens>
        </chunking>
        <chunking id="13" string="to eliminate the incompetent" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="eliminate" />
            <token id="8" string="the" />
            <token id="9" string="incompetent" />
          </tokens>
        </chunking>
        <chunking id="14" string="Where surgical strikes are needed to eliminate the incompetent or corrupt" type="SBAR">
          <tokens>
            <token id="1" string="Where" />
            <token id="2" string="surgical" />
            <token id="3" string="strikes" />
            <token id="4" string="are" />
            <token id="5" string="needed" />
            <token id="6" string="to" />
            <token id="7" string="eliminate" />
            <token id="8" string="the" />
            <token id="9" string="incompetent" />
            <token id="10" string="or" />
            <token id="11" string="corrupt" />
          </tokens>
        </chunking>
        <chunking id="15" string="the guilty" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="guilty" />
          </tokens>
        </chunking>
        <chunking id="16" string="the incompetent" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="incompetent" />
          </tokens>
        </chunking>
        <chunking id="17" string="the hope" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="hope" />
          </tokens>
        </chunking>
        <chunking id="18" string="surgical strikes" type="NP">
          <tokens>
            <token id="2" string="surgical" />
            <token id="3" string="strikes" />
          </tokens>
        </chunking>
        <chunking id="19" string="carpet bombing" type="NP">
          <tokens>
            <token id="17" string="carpet" />
            <token id="18" string="bombing" />
          </tokens>
        </chunking>
        <chunking id="20" string="some of the guilty" type="NP">
          <tokens>
            <token id="28" string="some" />
            <token id="29" string="of" />
            <token id="30" string="the" />
            <token id="31" string="guilty" />
          </tokens>
        </chunking>
        <chunking id="21" string="Where" type="WHADVP">
          <tokens>
            <token id="1" string="Where" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="5">needed</governor>
          <dependent id="1">Where</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">strikes</governor>
          <dependent id="2">surgical</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">needed</governor>
          <dependent id="3">strikes</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">needed</governor>
          <dependent id="4">are</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="16">uses</governor>
          <dependent id="5">needed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">eliminate</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">needed</governor>
          <dependent id="7">eliminate</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">incompetent</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">eliminate</governor>
          <dependent id="9">incompetent</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">needed</governor>
          <dependent id="10">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">needed</governor>
          <dependent id="11">corrupt</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">limitation</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">limitation</governor>
          <dependent id="14">term</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">uses</governor>
          <dependent id="15">limitation</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">uses</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">bombing</governor>
          <dependent id="17">carpet</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">uses</governor>
          <dependent id="18">bombing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">hope</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">hope</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">uses</governor>
          <dependent id="21">hope</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="33">suffer</governor>
          <dependent id="22">that</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">carnage</governor>
          <dependent id="23">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">carnage</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">carnage</governor>
          <dependent id="25">resulting</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">suffer</governor>
          <dependent id="26">carnage</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="33">suffer</governor>
          <dependent id="28">some</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">guilty</governor>
          <dependent id="29">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">guilty</governor>
          <dependent id="30">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">some</governor>
          <dependent id="31">guilty</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="33">suffer</governor>
          <dependent id="32">will</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">uses</governor>
          <dependent id="33">suffer</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="33">suffer</governor>
          <dependent id="34">along</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">innocent</governor>
          <dependent id="35">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="37">innocent</governor>
          <dependent id="36">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">suffer</governor>
          <dependent id="37">innocent</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="bombing" type="CRIMINAL_CHARGE" score="0.0">
          <tokens>
            <token id="18" string="bombing" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="30" has_coreference="true">
      <content>At the most basic level, term limitation is just flat-out wrongheaded and illogical: To throw everybody out when all you want to do is throw out the rascals is like burning down your house in order to get rid of the rats.</content>
      <tokens>
        <token id="1" string="At" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="most" lemma="most" stem="most" pos="JJS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="basic" lemma="basic" stem="basic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="level" lemma="level" stem="level" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="term" lemma="term" stem="term" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="limitation" lemma="limitation" stem="limit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="flat-out" lemma="flat-out" stem="flat-out" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="wrongheaded" lemma="wrongheaded" stem="wronghead" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="illogical" lemma="illogical" stem="illog" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="To" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="throw" lemma="throw" stem="throw" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="everybody" lemma="everybody" stem="everybodi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="out" lemma="out" stem="out" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="want" lemma="want" stem="want" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="do" lemma="do" stem="do" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="throw" lemma="throw" stem="throw" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="rascals" lemma="rascal" stem="rascal" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="burning" lemma="burn" stem="burn" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="down" lemma="down" stem="down" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="your" lemma="you" stem="your" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="house" lemma="house" stem="hous" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="order" lemma="order" stem="order" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="get" lemma="get" stem="get" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="rid" lemma="rid" stem="rid" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="rats" lemma="rat" stem="rat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (PP (IN At) (NP (DT the) (JJS most) (JJ basic) (NN level))) (, ,) (NP (NN term) (NN limitation)) (VP (VBZ is) (ADVP (RB just) (JJ flat-out)) (ADJP (JJ wrongheaded) (CC and) (JJ illogical)))) (: :) (S (S (VP (TO To) (VP (VB throw) (NP (NN everybody)) (PP (IN out) (SBAR (WHADVP (WRB when)) (S (NP (NP (DT all)) (SBAR (S (NP (PRP you)) (VP (VBP want) (S (VP (TO to) (VP (VB do)))))))) (VP (VBZ is) (VP (VB throw) (PRT (RP out)) (NP (DT the) (NNS rascals)))))))))) (VP (VBZ is) (PP (IN like) (S (VP (VBG burning) (PRT (RP down)) (NP (NP (PRP$ your) (NN house)) (PP (IN in) (NP (NN order)))) (S (VP (TO to) (VP (VB get) (ADJP (JJ rid)) (PP (IN of) (NP (DT the) (NNS rats))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="all" type="NP">
          <tokens>
            <token id="21" string="all" />
          </tokens>
        </chunking>
        <chunking id="2" string="you want to do" type="SBAR">
          <tokens>
            <token id="22" string="you" />
            <token id="23" string="want" />
            <token id="24" string="to" />
            <token id="25" string="do" />
          </tokens>
        </chunking>
        <chunking id="3" string="To throw everybody out when all you want to do is throw out the rascals" type="VP">
          <tokens>
            <token id="16" string="To" />
            <token id="17" string="throw" />
            <token id="18" string="everybody" />
            <token id="19" string="out" />
            <token id="20" string="when" />
            <token id="21" string="all" />
            <token id="22" string="you" />
            <token id="23" string="want" />
            <token id="24" string="to" />
            <token id="25" string="do" />
            <token id="26" string="is" />
            <token id="27" string="throw" />
            <token id="28" string="out" />
            <token id="29" string="the" />
            <token id="30" string="rascals" />
          </tokens>
        </chunking>
        <chunking id="4" string="when all you want to do is throw out the rascals" type="SBAR">
          <tokens>
            <token id="20" string="when" />
            <token id="21" string="all" />
            <token id="22" string="you" />
            <token id="23" string="want" />
            <token id="24" string="to" />
            <token id="25" string="do" />
            <token id="26" string="is" />
            <token id="27" string="throw" />
            <token id="28" string="out" />
            <token id="29" string="the" />
            <token id="30" string="rascals" />
          </tokens>
        </chunking>
        <chunking id="5" string="want to do" type="VP">
          <tokens>
            <token id="23" string="want" />
            <token id="24" string="to" />
            <token id="25" string="do" />
          </tokens>
        </chunking>
        <chunking id="6" string="your house" type="NP">
          <tokens>
            <token id="35" string="your" />
            <token id="36" string="house" />
          </tokens>
        </chunking>
        <chunking id="7" string="is just flat-out wrongheaded and illogical" type="VP">
          <tokens>
            <token id="9" string="is" />
            <token id="10" string="just" />
            <token id="11" string="flat-out" />
            <token id="12" string="wrongheaded" />
            <token id="13" string="and" />
            <token id="14" string="illogical" />
          </tokens>
        </chunking>
        <chunking id="8" string="throw everybody out when all you want to do is throw out the rascals" type="VP">
          <tokens>
            <token id="17" string="throw" />
            <token id="18" string="everybody" />
            <token id="19" string="out" />
            <token id="20" string="when" />
            <token id="21" string="all" />
            <token id="22" string="you" />
            <token id="23" string="want" />
            <token id="24" string="to" />
            <token id="25" string="do" />
            <token id="26" string="is" />
            <token id="27" string="throw" />
            <token id="28" string="out" />
            <token id="29" string="the" />
            <token id="30" string="rascals" />
          </tokens>
        </chunking>
        <chunking id="9" string="throw out the rascals" type="VP">
          <tokens>
            <token id="27" string="throw" />
            <token id="28" string="out" />
            <token id="29" string="the" />
            <token id="30" string="rascals" />
          </tokens>
        </chunking>
        <chunking id="10" string="the rascals" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="rascals" />
          </tokens>
        </chunking>
        <chunking id="11" string="get rid of the rats" type="VP">
          <tokens>
            <token id="40" string="get" />
            <token id="41" string="rid" />
            <token id="42" string="of" />
            <token id="43" string="the" />
            <token id="44" string="rats" />
          </tokens>
        </chunking>
        <chunking id="12" string="wrongheaded and illogical" type="ADJP">
          <tokens>
            <token id="12" string="wrongheaded" />
            <token id="13" string="and" />
            <token id="14" string="illogical" />
          </tokens>
        </chunking>
        <chunking id="13" string="your house in order" type="NP">
          <tokens>
            <token id="35" string="your" />
            <token id="36" string="house" />
            <token id="37" string="in" />
            <token id="38" string="order" />
          </tokens>
        </chunking>
        <chunking id="14" string="to get rid of the rats" type="VP">
          <tokens>
            <token id="39" string="to" />
            <token id="40" string="get" />
            <token id="41" string="rid" />
            <token id="42" string="of" />
            <token id="43" string="the" />
            <token id="44" string="rats" />
          </tokens>
        </chunking>
        <chunking id="15" string="everybody" type="NP">
          <tokens>
            <token id="18" string="everybody" />
          </tokens>
        </chunking>
        <chunking id="16" string="the most basic level" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="most" />
            <token id="4" string="basic" />
            <token id="5" string="level" />
          </tokens>
        </chunking>
        <chunking id="17" string="do" type="VP">
          <tokens>
            <token id="25" string="do" />
          </tokens>
        </chunking>
        <chunking id="18" string="rid" type="ADJP">
          <tokens>
            <token id="41" string="rid" />
          </tokens>
        </chunking>
        <chunking id="19" string="when" type="WHADVP">
          <tokens>
            <token id="20" string="when" />
          </tokens>
        </chunking>
        <chunking id="20" string="is throw out the rascals" type="VP">
          <tokens>
            <token id="26" string="is" />
            <token id="27" string="throw" />
            <token id="28" string="out" />
            <token id="29" string="the" />
            <token id="30" string="rascals" />
          </tokens>
        </chunking>
        <chunking id="21" string="term limitation" type="NP">
          <tokens>
            <token id="7" string="term" />
            <token id="8" string="limitation" />
          </tokens>
        </chunking>
        <chunking id="22" string="all you want to do" type="NP">
          <tokens>
            <token id="21" string="all" />
            <token id="22" string="you" />
            <token id="23" string="want" />
            <token id="24" string="to" />
            <token id="25" string="do" />
          </tokens>
        </chunking>
        <chunking id="23" string="to do" type="VP">
          <tokens>
            <token id="24" string="to" />
            <token id="25" string="do" />
          </tokens>
        </chunking>
        <chunking id="24" string="is like burning down your house in order to get rid of the rats" type="VP">
          <tokens>
            <token id="31" string="is" />
            <token id="32" string="like" />
            <token id="33" string="burning" />
            <token id="34" string="down" />
            <token id="35" string="your" />
            <token id="36" string="house" />
            <token id="37" string="in" />
            <token id="38" string="order" />
            <token id="39" string="to" />
            <token id="40" string="get" />
            <token id="41" string="rid" />
            <token id="42" string="of" />
            <token id="43" string="the" />
            <token id="44" string="rats" />
          </tokens>
        </chunking>
        <chunking id="25" string="burning down your house in order to get rid of the rats" type="VP">
          <tokens>
            <token id="33" string="burning" />
            <token id="34" string="down" />
            <token id="35" string="your" />
            <token id="36" string="house" />
            <token id="37" string="in" />
            <token id="38" string="order" />
            <token id="39" string="to" />
            <token id="40" string="get" />
            <token id="41" string="rid" />
            <token id="42" string="of" />
            <token id="43" string="the" />
            <token id="44" string="rats" />
          </tokens>
        </chunking>
        <chunking id="26" string="order" type="NP">
          <tokens>
            <token id="38" string="order" />
          </tokens>
        </chunking>
        <chunking id="27" string="the rats" type="NP">
          <tokens>
            <token id="43" string="the" />
            <token id="44" string="rats" />
          </tokens>
        </chunking>
        <chunking id="28" string="you" type="NP">
          <tokens>
            <token id="22" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="5">level</governor>
          <dependent id="1">At</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">level</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">level</governor>
          <dependent id="3">most</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">level</governor>
          <dependent id="4">basic</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">wrongheaded</governor>
          <dependent id="5">level</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">limitation</governor>
          <dependent id="7">term</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">wrongheaded</governor>
          <dependent id="8">limitation</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">wrongheaded</governor>
          <dependent id="9">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">flat-out</governor>
          <dependent id="10">just</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">wrongheaded</governor>
          <dependent id="11">flat-out</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">wrongheaded</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">wrongheaded</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">wrongheaded</governor>
          <dependent id="14">illogical</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">throw</governor>
          <dependent id="16">To</dependent>
        </dependency>
        <dependency type="csubj">
          <governor id="33">burning</governor>
          <dependent id="17">throw</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">throw</governor>
          <dependent id="18">everybody</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="27">throw</governor>
          <dependent id="19">out</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="27">throw</governor>
          <dependent id="20">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">throw</governor>
          <dependent id="21">all</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">want</governor>
          <dependent id="22">you</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="21">all</governor>
          <dependent id="23">want</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="25">do</governor>
          <dependent id="24">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="23">want</governor>
          <dependent id="25">do</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="27">throw</governor>
          <dependent id="26">is</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="17">throw</governor>
          <dependent id="27">throw</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="27">throw</governor>
          <dependent id="28">out</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">rascals</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="27">throw</governor>
          <dependent id="30">rascals</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="33">burning</governor>
          <dependent id="31">is</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="33">burning</governor>
          <dependent id="32">like</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="12">wrongheaded</governor>
          <dependent id="33">burning</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="33">burning</governor>
          <dependent id="34">down</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="36">house</governor>
          <dependent id="35">your</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="33">burning</governor>
          <dependent id="36">house</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="36">house</governor>
          <dependent id="37">in</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="37">in</governor>
          <dependent id="38">order</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="40">get</governor>
          <dependent id="39">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="33">burning</governor>
          <dependent id="40">get</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="40">get</governor>
          <dependent id="41">rid</dependent>
        </dependency>
        <dependency type="case">
          <governor id="44">rats</governor>
          <dependent id="42">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="44">rats</governor>
          <dependent id="43">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="40">get</governor>
          <dependent id="44">rats</dependent>
        </dependency>
      </dependencies>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="2" type="NOMINAL">
      <referenced ids_tokens="11-12-13-14-15-16-17" string="the very people who scheduled the operations" id_sentence="2" />
      <mentions>
        <mention ids_tokens="14-22" string="the very people who are in some measure accountable" id_sentence="26" />
      </mentions>
    </coreference>
    <coreference id="3" type="NOMINAL">
      <referenced ids_tokens="18" string="conservatives" id_sentence="3" />
      <mentions>
        <mention ids_tokens="17" string="they" id_sentence="4" />
      </mentions>
    </coreference>
    <coreference id="4" type="PROPER">
      <referenced ids_tokens="1-2-3-4" string="The Republicans in 1951" id_sentence="4" />
      <mentions>
        <mention ids_tokens="3-44" string="Republicans , naturally enough , who seem to be the most enthusiastic puffers of term limitation , since they have the most to gain , at least in the short term , from an indiscriminate clean-out of the nation's deliberative bodies" id_sentence="13" />
        <mention ids_tokens="3" string="Republicans" id_sentence="13" />
      </mentions>
    </coreference>
    <coreference id="6" type="NOMINAL">
      <referenced ids_tokens="1-2-3-4-5-6-7-8-9-10-11" string="The latest institutional patients to be wheeled into the shock-trauma unit" id_sentence="6" />
      <mentions>
        <mention ids_tokens="7" string="them" id_sentence="7" />
      </mentions>
    </coreference>
    <coreference id="7" type="NOMINAL">
      <referenced ids_tokens="13-14-15" string="the state legislatures" id_sentence="6" />
      <mentions>
        <mention ids_tokens="12-13" string="state legislatures" id_sentence="15" />
      </mentions>
    </coreference>
    <coreference id="9" type="PROPER">
      <referenced ids_tokens="19-20" string="the Oklahoma" id_sentence="10" />
      <mentions>
        <mention ids_tokens="11" string="Oklahoma" id_sentence="8" />
        <mention ids_tokens="8" string="Oklahoma" id_sentence="9" />
        <mention ids_tokens="2" string="Oklahoma" id_sentence="11" />
      </mentions>
    </coreference>
    <coreference id="10" type="NOMINAL">
      <referenced ids_tokens="1-2-3" string="The first cut" id_sentence="8" />
      <mentions>
        <mention ids_tokens="2" string="itself" id_sentence="9" />
      </mentions>
    </coreference>
    <coreference id="11" type="NOMINAL">
      <referenced ids_tokens="11-12" string="Oklahoma voters" id_sentence="8" />
      <mentions>
        <mention ids_tokens="11" string="voters" id_sentence="26" />
        <mention ids_tokens="6-7" string="the voters" id_sentence="28" />
        <mention ids_tokens="9-20" string="civic imbeciles who can not discriminate between bad lawmakers and good ones" id_sentence="28" />
      </mentions>
    </coreference>
    <coreference id="12" type="NOMINAL">
      <referenced ids_tokens="19-20" string="state lawmakers" id_sentence="8" />
      <mentions>
        <mention ids_tokens="22-23" string="the lawmakers" id_sentence="14" />
      </mentions>
    </coreference>
    <coreference id="13" type="NOMINAL">
      <referenced ids_tokens="4-5-6-7-8" string="the term limitation in Oklahoma" id_sentence="9" />
      <mentions>
        <mention ids_tokens="17-18" string="term limitation" id_sentence="13" />
        <mention ids_tokens="3-4" string="term limitation" id_sentence="14" />
        <mention ids_tokens="13-15" string="the term limitation" id_sentence="29" />
        <mention ids_tokens="7-8" string="term limitation" id_sentence="30" />
      </mentions>
    </coreference>
    <coreference id="14" type="NOMINAL">
      <referenced ids_tokens="1-2-3" string="The Oklahoma referendum" id_sentence="11" />
      <mentions>
        <mention ids_tokens="1" string="It" id_sentence="12" />
      </mentions>
    </coreference>
    <coreference id="17" type="NOMINAL">
      <referenced ids_tokens="28-29-30" string="highly paid lobbyists" id_sentence="16" />
      <mentions>
        <mention ids_tokens="1" string="Lobbyists" id_sentence="22" />
        <mention ids_tokens="1" string="Their" id_sentence="23" />
        <mention ids_tokens="12" string="they" id_sentence="23" />
        <mention ids_tokens="5-6" string="the lobbyists" id_sentence="25" />
      </mentions>
    </coreference>
    <coreference id="18" type="NOMINAL">
      <referenced ids_tokens="4" string="legislators" id_sentence="24" />
      <mentions>
        <mention ids_tokens="4-12" string="the legislators every 12 years -- or even worse" id_sentence="18" />
        <mention ids_tokens="1" string="They" id_sentence="19" />
        <mention ids_tokens="4" string="them" id_sentence="19" />
        <mention ids_tokens="10" string="their" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="20" type="NOMINAL">
      <referenced ids_tokens="4-5-6-7-8-9-10-11-12-13-14-15-16-17-18-19-20-21-22-23-24-25-26-27-28-29-30" string="a safe bet that more people will be using state seats to groom for higher office if they know that the law will force them out soon" id_sentence="21" />
      <mentions>
        <mention ids_tokens="6-7" string="his eye" id_sentence="20" />
      </mentions>
    </coreference>
    <coreference id="22" type="NOMINAL">
      <referenced ids_tokens="4-5-6" string="the term limit" id_sentence="27" />
      <mentions>
        <mention ids_tokens="1" string="It" id_sentence="28" />
        <mention ids_tokens="3-4" string="an admission" id_sentence="28" />
      </mentions>
    </coreference>
  </coreferences>
</document>
