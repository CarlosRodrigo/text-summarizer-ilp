<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="FBIS4-45908">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>CSO It is already a multi-million pound disaster for British agriculture and now it threatens to erupt into a major political row between European governments.</content>
      <tokens>
        <token id="1" string="CSO" lemma="CSO" stem="cso" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="already" lemma="already" stem="alreadi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="multi-million" lemma="multi-million" stem="multi-million" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="pound" lemma="pound" stem="pound" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="disaster" lemma="disaster" stem="disast" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="false" />
        <token id="9" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="British" lemma="british" stem="british" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="true" is_refers="false" />
        <token id="11" string="agriculture" lemma="agriculture" stem="agricultur" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="14" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="threatens" lemma="threaten" stem="threaten" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="erupt" lemma="erupt" stem="erupt" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="major" lemma="major" stem="major" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="political" lemma="political" stem="polit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="row" lemma="row" stem="row" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="between" lemma="between" stem="between" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="European" lemma="european" stem="european" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="25" string="governments" lemma="government" stem="govern" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNP CSO) (PRP It)) (VP (VBZ is) (ADVP (RB already)) (NP (NP (DT a) (JJ multi-million) (NN pound) (NN disaster)) (PP (IN for) (NP (JJ British) (NN agriculture)))))) (CC and) (S (ADVP (RB now)) (NP (PRP it)) (VP (VBZ threatens) (S (VP (TO to) (VP (VB erupt) (PP (IN into) (NP (NP (DT a) (JJ major) (JJ political) (NN row)) (PP (IN between) (NP (JJ European) (NNS governments)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="to erupt into a major political row between European governments" type="VP">
          <tokens>
            <token id="16" string="to" />
            <token id="17" string="erupt" />
            <token id="18" string="into" />
            <token id="19" string="a" />
            <token id="20" string="major" />
            <token id="21" string="political" />
            <token id="22" string="row" />
            <token id="23" string="between" />
            <token id="24" string="European" />
            <token id="25" string="governments" />
          </tokens>
        </chunking>
        <chunking id="2" string="CSO It" type="NP">
          <tokens>
            <token id="1" string="CSO" />
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="3" string="European governments" type="NP">
          <tokens>
            <token id="24" string="European" />
            <token id="25" string="governments" />
          </tokens>
        </chunking>
        <chunking id="4" string="a multi-million pound disaster" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="multi-million" />
            <token id="7" string="pound" />
            <token id="8" string="disaster" />
          </tokens>
        </chunking>
        <chunking id="5" string="erupt into a major political row between European governments" type="VP">
          <tokens>
            <token id="17" string="erupt" />
            <token id="18" string="into" />
            <token id="19" string="a" />
            <token id="20" string="major" />
            <token id="21" string="political" />
            <token id="22" string="row" />
            <token id="23" string="between" />
            <token id="24" string="European" />
            <token id="25" string="governments" />
          </tokens>
        </chunking>
        <chunking id="6" string="is already a multi-million pound disaster for British agriculture" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="already" />
            <token id="5" string="a" />
            <token id="6" string="multi-million" />
            <token id="7" string="pound" />
            <token id="8" string="disaster" />
            <token id="9" string="for" />
            <token id="10" string="British" />
            <token id="11" string="agriculture" />
          </tokens>
        </chunking>
        <chunking id="7" string="a multi-million pound disaster for British agriculture" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="multi-million" />
            <token id="7" string="pound" />
            <token id="8" string="disaster" />
            <token id="9" string="for" />
            <token id="10" string="British" />
            <token id="11" string="agriculture" />
          </tokens>
        </chunking>
        <chunking id="8" string="a major political row" type="NP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="major" />
            <token id="21" string="political" />
            <token id="22" string="row" />
          </tokens>
        </chunking>
        <chunking id="9" string="British agriculture" type="NP">
          <tokens>
            <token id="10" string="British" />
            <token id="11" string="agriculture" />
          </tokens>
        </chunking>
        <chunking id="10" string="it" type="NP">
          <tokens>
            <token id="14" string="it" />
          </tokens>
        </chunking>
        <chunking id="11" string="threatens to erupt into a major political row between European governments" type="VP">
          <tokens>
            <token id="15" string="threatens" />
            <token id="16" string="to" />
            <token id="17" string="erupt" />
            <token id="18" string="into" />
            <token id="19" string="a" />
            <token id="20" string="major" />
            <token id="21" string="political" />
            <token id="22" string="row" />
            <token id="23" string="between" />
            <token id="24" string="European" />
            <token id="25" string="governments" />
          </tokens>
        </chunking>
        <chunking id="12" string="a major political row between European governments" type="NP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="major" />
            <token id="21" string="political" />
            <token id="22" string="row" />
            <token id="23" string="between" />
            <token id="24" string="European" />
            <token id="25" string="governments" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="8">disaster</governor>
          <dependent id="1">CSO</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="1">CSO</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">disaster</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">disaster</governor>
          <dependent id="4">already</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">disaster</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">disaster</governor>
          <dependent id="6">multi-million</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">disaster</governor>
          <dependent id="7">pound</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">disaster</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">agriculture</governor>
          <dependent id="9">for</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">agriculture</governor>
          <dependent id="10">British</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">disaster</governor>
          <dependent id="11">agriculture</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">disaster</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">threatens</governor>
          <dependent id="13">now</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">threatens</governor>
          <dependent id="14">it</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">disaster</governor>
          <dependent id="15">threatens</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">erupt</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="15">threatens</governor>
          <dependent id="17">erupt</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">row</governor>
          <dependent id="18">into</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">row</governor>
          <dependent id="19">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">row</governor>
          <dependent id="20">major</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">row</governor>
          <dependent id="21">political</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">erupt</governor>
          <dependent id="22">row</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">governments</governor>
          <dependent id="23">between</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">governments</governor>
          <dependent id="24">European</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">row</governor>
          <dependent id="25">governments</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="10" string="British" />
          </tokens>
        </entity>
        <entity id="2" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="13" string="now" />
          </tokens>
        </entity>
        <entity id="3" string="European" type="MISC" score="0.0">
          <tokens>
            <token id="24" string="European" />
          </tokens>
        </entity>
        <entity id="4" string="disaster" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="8" string="disaster" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>It is bovine spongiform encephalopathy (BSE) -- &amp;quot;mad cow&amp;quot; disease -- and few would be prepared to say exactly when and where it will end.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="bovine" lemma="bovine" stem="bovin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="spongiform" lemma="spongiform" stem="spongiform" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="encephalopathy" lemma="encephalopathy" stem="encephalopathi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="BSE" lemma="bse" stem="bse" pos="NN" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="8" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="mad" lemma="mad" stem="mad" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="cow" lemma="cow" stem="cow" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="false" />
        <token id="15" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="few" lemma="few" stem="few" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="prepared" lemma="prepare" stem="prepar" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="say" lemma="say" stem="sai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="exactly" lemma="exactly" stem="exactli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="28" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="end" lemma="end" stem="end" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP It)) (VP (VBZ is) (NP (NP (NP (JJ bovine) (NN spongiform) (NN encephalopathy)) (PRN (-LRB- -LRB-) (NP (NN BSE)) (-RRB- -RRB-))) (: --) (NP (ADJP (`` ``) (JJ mad) (NN cow) ('' '')) (NN disease)) (: --)))) (CC and) (S (NP (JJ few)) (VP (MD would) (VP (VB be) (VP (VBN prepared) (S (VP (TO to) (VP (VB say) (SBAR (WHADVP (RB exactly) (WRB when) (CC and) (WRB where)) (S (NP (PRP it)) (VP (MD will) (VP (VB end)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="bovine spongiform encephalopathy -LRB- BSE -RRB- -- `` mad cow '' disease --" type="NP">
          <tokens>
            <token id="3" string="bovine" />
            <token id="4" string="spongiform" />
            <token id="5" string="encephalopathy" />
            <token id="6" string="(" />
            <token id="7" string="BSE" />
            <token id="8" string=")" />
            <token id="9" string="--" />
            <token id="10" string="&quot;" />
            <token id="11" string="mad" />
            <token id="12" string="cow" />
            <token id="13" string="&quot;" />
            <token id="14" string="disease" />
            <token id="15" string="--" />
          </tokens>
        </chunking>
        <chunking id="2" string="would be prepared to say exactly when and where it will end" type="VP">
          <tokens>
            <token id="18" string="would" />
            <token id="19" string="be" />
            <token id="20" string="prepared" />
            <token id="21" string="to" />
            <token id="22" string="say" />
            <token id="23" string="exactly" />
            <token id="24" string="when" />
            <token id="25" string="and" />
            <token id="26" string="where" />
            <token id="27" string="it" />
            <token id="28" string="will" />
            <token id="29" string="end" />
          </tokens>
        </chunking>
        <chunking id="3" string="to say exactly when and where it will end" type="VP">
          <tokens>
            <token id="21" string="to" />
            <token id="22" string="say" />
            <token id="23" string="exactly" />
            <token id="24" string="when" />
            <token id="25" string="and" />
            <token id="26" string="where" />
            <token id="27" string="it" />
            <token id="28" string="will" />
            <token id="29" string="end" />
          </tokens>
        </chunking>
        <chunking id="4" string="bovine spongiform encephalopathy -LRB- BSE -RRB-" type="NP">
          <tokens>
            <token id="3" string="bovine" />
            <token id="4" string="spongiform" />
            <token id="5" string="encephalopathy" />
            <token id="6" string="(" />
            <token id="7" string="BSE" />
            <token id="8" string=")" />
          </tokens>
        </chunking>
        <chunking id="5" string="prepared to say exactly when and where it will end" type="VP">
          <tokens>
            <token id="20" string="prepared" />
            <token id="21" string="to" />
            <token id="22" string="say" />
            <token id="23" string="exactly" />
            <token id="24" string="when" />
            <token id="25" string="and" />
            <token id="26" string="where" />
            <token id="27" string="it" />
            <token id="28" string="will" />
            <token id="29" string="end" />
          </tokens>
        </chunking>
        <chunking id="6" string="bovine spongiform encephalopathy" type="NP">
          <tokens>
            <token id="3" string="bovine" />
            <token id="4" string="spongiform" />
            <token id="5" string="encephalopathy" />
          </tokens>
        </chunking>
        <chunking id="7" string="exactly when and where" type="WHADVP">
          <tokens>
            <token id="23" string="exactly" />
            <token id="24" string="when" />
            <token id="25" string="and" />
            <token id="26" string="where" />
          </tokens>
        </chunking>
        <chunking id="8" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="9" string="exactly when and where it will end" type="SBAR">
          <tokens>
            <token id="23" string="exactly" />
            <token id="24" string="when" />
            <token id="25" string="and" />
            <token id="26" string="where" />
            <token id="27" string="it" />
            <token id="28" string="will" />
            <token id="29" string="end" />
          </tokens>
        </chunking>
        <chunking id="10" string="it" type="NP">
          <tokens>
            <token id="27" string="it" />
          </tokens>
        </chunking>
        <chunking id="11" string="will end" type="VP">
          <tokens>
            <token id="28" string="will" />
            <token id="29" string="end" />
          </tokens>
        </chunking>
        <chunking id="12" string="`` mad cow ''" type="ADJP">
          <tokens>
            <token id="10" string="&quot;" />
            <token id="11" string="mad" />
            <token id="12" string="cow" />
            <token id="13" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="13" string="BSE" type="NP">
          <tokens>
            <token id="7" string="BSE" />
          </tokens>
        </chunking>
        <chunking id="14" string="be prepared to say exactly when and where it will end" type="VP">
          <tokens>
            <token id="19" string="be" />
            <token id="20" string="prepared" />
            <token id="21" string="to" />
            <token id="22" string="say" />
            <token id="23" string="exactly" />
            <token id="24" string="when" />
            <token id="25" string="and" />
            <token id="26" string="where" />
            <token id="27" string="it" />
            <token id="28" string="will" />
            <token id="29" string="end" />
          </tokens>
        </chunking>
        <chunking id="15" string="few" type="NP">
          <tokens>
            <token id="17" string="few" />
          </tokens>
        </chunking>
        <chunking id="16" string="say exactly when and where it will end" type="VP">
          <tokens>
            <token id="22" string="say" />
            <token id="23" string="exactly" />
            <token id="24" string="when" />
            <token id="25" string="and" />
            <token id="26" string="where" />
            <token id="27" string="it" />
            <token id="28" string="will" />
            <token id="29" string="end" />
          </tokens>
        </chunking>
        <chunking id="17" string="is bovine spongiform encephalopathy -LRB- BSE -RRB- -- `` mad cow '' disease --" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="bovine" />
            <token id="4" string="spongiform" />
            <token id="5" string="encephalopathy" />
            <token id="6" string="(" />
            <token id="7" string="BSE" />
            <token id="8" string=")" />
            <token id="9" string="--" />
            <token id="10" string="&quot;" />
            <token id="11" string="mad" />
            <token id="12" string="cow" />
            <token id="13" string="&quot;" />
            <token id="14" string="disease" />
            <token id="15" string="--" />
          </tokens>
        </chunking>
        <chunking id="18" string="end" type="VP">
          <tokens>
            <token id="29" string="end" />
          </tokens>
        </chunking>
        <chunking id="19" string="`` mad cow '' disease" type="NP">
          <tokens>
            <token id="10" string="&quot;" />
            <token id="11" string="mad" />
            <token id="12" string="cow" />
            <token id="13" string="&quot;" />
            <token id="14" string="disease" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">encephalopathy</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">encephalopathy</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">encephalopathy</governor>
          <dependent id="3">bovine</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">encephalopathy</governor>
          <dependent id="4">spongiform</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">encephalopathy</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="5">encephalopathy</governor>
          <dependent id="7">BSE</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="12">cow</governor>
          <dependent id="11">mad</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">disease</governor>
          <dependent id="12">cow</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="5">encephalopathy</governor>
          <dependent id="14">disease</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">encephalopathy</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="20">prepared</governor>
          <dependent id="17">few</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="20">prepared</governor>
          <dependent id="18">would</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="20">prepared</governor>
          <dependent id="19">be</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">encephalopathy</governor>
          <dependent id="20">prepared</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">say</governor>
          <dependent id="21">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="20">prepared</governor>
          <dependent id="22">say</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="24">when</governor>
          <dependent id="23">exactly</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="29">end</governor>
          <dependent id="24">when</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="24">when</governor>
          <dependent id="25">and</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="24">when</governor>
          <dependent id="26">where</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">end</governor>
          <dependent id="27">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="29">end</governor>
          <dependent id="28">will</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="22">say</governor>
          <dependent id="29">end</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="BSE" type="MISC" score="0.0">
          <tokens>
            <token id="7" string="BSE" />
          </tokens>
        </entity>
        <entity id="2" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="14" string="disease" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>Next week European Community health ministers will meet to discuss a German call for a ban on British beef imports to that country.</content>
      <tokens>
        <token id="1" string="Next" lemma="next" stem="next" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="2" string="week" lemma="week" stem="week" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="European" lemma="European" stem="european" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="4" string="Community" lemma="Community" stem="commun" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="5" string="health" lemma="health" stem="health" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="ministers" lemma="minister" stem="minist" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="meet" lemma="meet" stem="meet" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="discuss" lemma="discuss" stem="discuss" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="German" lemma="german" stem="german" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="13" string="call" lemma="call" stem="call" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="ban" lemma="ban" stem="ban" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="British" lemma="british" stem="british" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="19" string="beef" lemma="beef" stem="beef" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="imports" lemma="import" stem="import" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="country" lemma="country" stem="countri" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP-TMP (JJ Next) (NN week)) (NP (NNP European) (NNP Community) (NN health) (NNS ministers)) (VP (MD will) (VP (VB meet) (S (VP (TO to) (VP (VB discuss) (NP (NP (DT a) (JJ German) (NN call)) (PP (IN for) (NP (NP (DT a) (NN ban)) (PP (IN on) (NP (JJ British) (NN beef) (NNS imports)))))) (PP (TO to) (NP (DT that) (NN country)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="European Community health ministers" type="NP">
          <tokens>
            <token id="3" string="European" />
            <token id="4" string="Community" />
            <token id="5" string="health" />
            <token id="6" string="ministers" />
          </tokens>
        </chunking>
        <chunking id="2" string="to discuss a German call for a ban on British beef imports to that country" type="VP">
          <tokens>
            <token id="9" string="to" />
            <token id="10" string="discuss" />
            <token id="11" string="a" />
            <token id="12" string="German" />
            <token id="13" string="call" />
            <token id="14" string="for" />
            <token id="15" string="a" />
            <token id="16" string="ban" />
            <token id="17" string="on" />
            <token id="18" string="British" />
            <token id="19" string="beef" />
            <token id="20" string="imports" />
            <token id="21" string="to" />
            <token id="22" string="that" />
            <token id="23" string="country" />
          </tokens>
        </chunking>
        <chunking id="3" string="a German call" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="German" />
            <token id="13" string="call" />
          </tokens>
        </chunking>
        <chunking id="4" string="will meet to discuss a German call for a ban on British beef imports to that country" type="VP">
          <tokens>
            <token id="7" string="will" />
            <token id="8" string="meet" />
            <token id="9" string="to" />
            <token id="10" string="discuss" />
            <token id="11" string="a" />
            <token id="12" string="German" />
            <token id="13" string="call" />
            <token id="14" string="for" />
            <token id="15" string="a" />
            <token id="16" string="ban" />
            <token id="17" string="on" />
            <token id="18" string="British" />
            <token id="19" string="beef" />
            <token id="20" string="imports" />
            <token id="21" string="to" />
            <token id="22" string="that" />
            <token id="23" string="country" />
          </tokens>
        </chunking>
        <chunking id="5" string="that country" type="NP">
          <tokens>
            <token id="22" string="that" />
            <token id="23" string="country" />
          </tokens>
        </chunking>
        <chunking id="6" string="a ban" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="ban" />
          </tokens>
        </chunking>
        <chunking id="7" string="a ban on British beef imports" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="ban" />
            <token id="17" string="on" />
            <token id="18" string="British" />
            <token id="19" string="beef" />
            <token id="20" string="imports" />
          </tokens>
        </chunking>
        <chunking id="8" string="British beef imports" type="NP">
          <tokens>
            <token id="18" string="British" />
            <token id="19" string="beef" />
            <token id="20" string="imports" />
          </tokens>
        </chunking>
        <chunking id="9" string="a German call for a ban on British beef imports" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="German" />
            <token id="13" string="call" />
            <token id="14" string="for" />
            <token id="15" string="a" />
            <token id="16" string="ban" />
            <token id="17" string="on" />
            <token id="18" string="British" />
            <token id="19" string="beef" />
            <token id="20" string="imports" />
          </tokens>
        </chunking>
        <chunking id="10" string="meet to discuss a German call for a ban on British beef imports to that country" type="VP">
          <tokens>
            <token id="8" string="meet" />
            <token id="9" string="to" />
            <token id="10" string="discuss" />
            <token id="11" string="a" />
            <token id="12" string="German" />
            <token id="13" string="call" />
            <token id="14" string="for" />
            <token id="15" string="a" />
            <token id="16" string="ban" />
            <token id="17" string="on" />
            <token id="18" string="British" />
            <token id="19" string="beef" />
            <token id="20" string="imports" />
            <token id="21" string="to" />
            <token id="22" string="that" />
            <token id="23" string="country" />
          </tokens>
        </chunking>
        <chunking id="11" string="discuss a German call for a ban on British beef imports to that country" type="VP">
          <tokens>
            <token id="10" string="discuss" />
            <token id="11" string="a" />
            <token id="12" string="German" />
            <token id="13" string="call" />
            <token id="14" string="for" />
            <token id="15" string="a" />
            <token id="16" string="ban" />
            <token id="17" string="on" />
            <token id="18" string="British" />
            <token id="19" string="beef" />
            <token id="20" string="imports" />
            <token id="21" string="to" />
            <token id="22" string="that" />
            <token id="23" string="country" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">week</governor>
          <dependent id="1">Next</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="8">meet</governor>
          <dependent id="2">week</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">ministers</governor>
          <dependent id="3">European</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">ministers</governor>
          <dependent id="4">Community</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">ministers</governor>
          <dependent id="5">health</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">meet</governor>
          <dependent id="6">ministers</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">meet</governor>
          <dependent id="7">will</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">meet</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">discuss</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">meet</governor>
          <dependent id="10">discuss</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">call</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">call</governor>
          <dependent id="12">German</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">discuss</governor>
          <dependent id="13">call</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">ban</governor>
          <dependent id="14">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">ban</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">call</governor>
          <dependent id="16">ban</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">imports</governor>
          <dependent id="17">on</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">imports</governor>
          <dependent id="18">British</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">imports</governor>
          <dependent id="19">beef</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">ban</governor>
          <dependent id="20">imports</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">country</governor>
          <dependent id="21">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">country</governor>
          <dependent id="22">that</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">discuss</governor>
          <dependent id="23">country</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="18" string="British" />
          </tokens>
        </entity>
        <entity id="2" string="European Community" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="3" string="European" />
            <token id="4" string="Community" />
          </tokens>
        </entity>
        <entity id="3" string="Next week" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="Next" />
            <token id="2" string="week" />
          </tokens>
        </entity>
        <entity id="4" string="German" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="12" string="German" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>Some German politicians say their country should risk breaking Single Market free trade rules because the potential health risks are so grave.</content>
      <tokens>
        <token id="1" string="Some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="German" lemma="german" stem="german" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="true" is_refers="false" />
        <token id="3" string="politicians" lemma="politician" stem="politician" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="say" lemma="say" stem="sai" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="country" lemma="country" stem="countri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="should" lemma="should" stem="should" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="risk" lemma="risk" stem="risk" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="breaking" lemma="break" stem="break" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="Single" lemma="single" stem="singl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="Market" lemma="market" stem="market" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="free" lemma="free" stem="free" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="trade" lemma="trade" stem="trade" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="rules" lemma="rule" stem="rule" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="potential" lemma="potential" stem="potenti" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="health" lemma="health" stem="health" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="risks" lemma="risk" stem="risk" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="grave" lemma="grave" stem="grave" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT Some) (JJ German) (NNS politicians)) (VP (VBP say) (SBAR (S (NP (PRP$ their) (NN country)) (VP (MD should) (VP (VB risk) (S (VP (VBG breaking) (NP (JJ Single) (NN Market)))) (SBAR (NP (JJ free) (NN trade) (NNS rules)) (IN because) (S (NP (DT the) (JJ potential) (NN health) (NNS risks)) (VP (VBP are) (ADJP (RB so) (JJ grave)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Some German politicians" type="NP">
          <tokens>
            <token id="1" string="Some" />
            <token id="2" string="German" />
            <token id="3" string="politicians" />
          </tokens>
        </chunking>
        <chunking id="2" string="say their country should risk breaking Single Market free trade rules because the potential health risks are so grave" type="VP">
          <tokens>
            <token id="4" string="say" />
            <token id="5" string="their" />
            <token id="6" string="country" />
            <token id="7" string="should" />
            <token id="8" string="risk" />
            <token id="9" string="breaking" />
            <token id="10" string="Single" />
            <token id="11" string="Market" />
            <token id="12" string="free" />
            <token id="13" string="trade" />
            <token id="14" string="rules" />
            <token id="15" string="because" />
            <token id="16" string="the" />
            <token id="17" string="potential" />
            <token id="18" string="health" />
            <token id="19" string="risks" />
            <token id="20" string="are" />
            <token id="21" string="so" />
            <token id="22" string="grave" />
          </tokens>
        </chunking>
        <chunking id="3" string="Single Market" type="NP">
          <tokens>
            <token id="10" string="Single" />
            <token id="11" string="Market" />
          </tokens>
        </chunking>
        <chunking id="4" string="free trade rules" type="NP">
          <tokens>
            <token id="12" string="free" />
            <token id="13" string="trade" />
            <token id="14" string="rules" />
          </tokens>
        </chunking>
        <chunking id="5" string="the potential health risks" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="potential" />
            <token id="18" string="health" />
            <token id="19" string="risks" />
          </tokens>
        </chunking>
        <chunking id="6" string="are so grave" type="VP">
          <tokens>
            <token id="20" string="are" />
            <token id="21" string="so" />
            <token id="22" string="grave" />
          </tokens>
        </chunking>
        <chunking id="7" string="risk breaking Single Market free trade rules because the potential health risks are so grave" type="VP">
          <tokens>
            <token id="8" string="risk" />
            <token id="9" string="breaking" />
            <token id="10" string="Single" />
            <token id="11" string="Market" />
            <token id="12" string="free" />
            <token id="13" string="trade" />
            <token id="14" string="rules" />
            <token id="15" string="because" />
            <token id="16" string="the" />
            <token id="17" string="potential" />
            <token id="18" string="health" />
            <token id="19" string="risks" />
            <token id="20" string="are" />
            <token id="21" string="so" />
            <token id="22" string="grave" />
          </tokens>
        </chunking>
        <chunking id="8" string="breaking Single Market" type="VP">
          <tokens>
            <token id="9" string="breaking" />
            <token id="10" string="Single" />
            <token id="11" string="Market" />
          </tokens>
        </chunking>
        <chunking id="9" string="free trade rules because the potential health risks are so grave" type="SBAR">
          <tokens>
            <token id="12" string="free" />
            <token id="13" string="trade" />
            <token id="14" string="rules" />
            <token id="15" string="because" />
            <token id="16" string="the" />
            <token id="17" string="potential" />
            <token id="18" string="health" />
            <token id="19" string="risks" />
            <token id="20" string="are" />
            <token id="21" string="so" />
            <token id="22" string="grave" />
          </tokens>
        </chunking>
        <chunking id="10" string="their country" type="NP">
          <tokens>
            <token id="5" string="their" />
            <token id="6" string="country" />
          </tokens>
        </chunking>
        <chunking id="11" string="so grave" type="ADJP">
          <tokens>
            <token id="21" string="so" />
            <token id="22" string="grave" />
          </tokens>
        </chunking>
        <chunking id="12" string="their country should risk breaking Single Market free trade rules because the potential health risks are so grave" type="SBAR">
          <tokens>
            <token id="5" string="their" />
            <token id="6" string="country" />
            <token id="7" string="should" />
            <token id="8" string="risk" />
            <token id="9" string="breaking" />
            <token id="10" string="Single" />
            <token id="11" string="Market" />
            <token id="12" string="free" />
            <token id="13" string="trade" />
            <token id="14" string="rules" />
            <token id="15" string="because" />
            <token id="16" string="the" />
            <token id="17" string="potential" />
            <token id="18" string="health" />
            <token id="19" string="risks" />
            <token id="20" string="are" />
            <token id="21" string="so" />
            <token id="22" string="grave" />
          </tokens>
        </chunking>
        <chunking id="13" string="should risk breaking Single Market free trade rules because the potential health risks are so grave" type="VP">
          <tokens>
            <token id="7" string="should" />
            <token id="8" string="risk" />
            <token id="9" string="breaking" />
            <token id="10" string="Single" />
            <token id="11" string="Market" />
            <token id="12" string="free" />
            <token id="13" string="trade" />
            <token id="14" string="rules" />
            <token id="15" string="because" />
            <token id="16" string="the" />
            <token id="17" string="potential" />
            <token id="18" string="health" />
            <token id="19" string="risks" />
            <token id="20" string="are" />
            <token id="21" string="so" />
            <token id="22" string="grave" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">politicians</governor>
          <dependent id="1">Some</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">politicians</governor>
          <dependent id="2">German</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">say</governor>
          <dependent id="3">politicians</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">say</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">country</governor>
          <dependent id="5">their</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">risk</governor>
          <dependent id="6">country</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">risk</governor>
          <dependent id="7">should</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">say</governor>
          <dependent id="8">risk</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">risk</governor>
          <dependent id="9">breaking</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">Market</governor>
          <dependent id="10">Single</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">breaking</governor>
          <dependent id="11">Market</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">rules</governor>
          <dependent id="12">free</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">rules</governor>
          <dependent id="13">trade</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="22">grave</governor>
          <dependent id="14">rules</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">grave</governor>
          <dependent id="15">because</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">risks</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">risks</governor>
          <dependent id="17">potential</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">risks</governor>
          <dependent id="18">health</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">grave</governor>
          <dependent id="19">risks</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="22">grave</governor>
          <dependent id="20">are</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="22">grave</governor>
          <dependent id="21">so</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="8">risk</governor>
          <dependent id="22">grave</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="German" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="2" string="German" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="false">
      <content>Nonsense, say British government scientists.</content>
      <tokens>
        <token id="1" string="Nonsense" lemma="nonsense" stem="nonsens" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="say" lemma="say" stem="sai" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="British" lemma="british" stem="british" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="5" string="government" lemma="government" stem="govern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="scientists" lemma="scientist" stem="scientist" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NN Nonsense)) (, ,) (VP (VBP say) (NP (JJ British) (NN government) (NNS scientists))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="say British government scientists" type="VP">
          <tokens>
            <token id="3" string="say" />
            <token id="4" string="British" />
            <token id="5" string="government" />
            <token id="6" string="scientists" />
          </tokens>
        </chunking>
        <chunking id="2" string="Nonsense" type="NP">
          <tokens>
            <token id="1" string="Nonsense" />
          </tokens>
        </chunking>
        <chunking id="3" string="British government scientists" type="NP">
          <tokens>
            <token id="4" string="British" />
            <token id="5" string="government" />
            <token id="6" string="scientists" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">say</governor>
          <dependent id="1">Nonsense</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">say</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">scientists</governor>
          <dependent id="4">British</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">scientists</governor>
          <dependent id="5">government</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">say</governor>
          <dependent id="6">scientists</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="4" string="British" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="false">
      <content>Meanwhile, the controversy in Britain is reaching new heights.</content>
      <tokens>
        <token id="1" string="Meanwhile" lemma="meanwhile" stem="meanwhil" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="controversy" lemma="controversy" stem="controversi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Britain" lemma="Britain" stem="britain" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="7" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="reaching" lemma="reach" stem="reach" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="new" lemma="new" stem="new" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="heights" lemma="height" stem="height" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Meanwhile)) (, ,) (NP (NP (DT the) (NN controversy)) (PP (IN in) (NP (NNP Britain)))) (VP (VBZ is) (VP (VBG reaching) (NP (JJ new) (NNS heights)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is reaching new heights" type="VP">
          <tokens>
            <token id="7" string="is" />
            <token id="8" string="reaching" />
            <token id="9" string="new" />
            <token id="10" string="heights" />
          </tokens>
        </chunking>
        <chunking id="2" string="reaching new heights" type="VP">
          <tokens>
            <token id="8" string="reaching" />
            <token id="9" string="new" />
            <token id="10" string="heights" />
          </tokens>
        </chunking>
        <chunking id="3" string="new heights" type="NP">
          <tokens>
            <token id="9" string="new" />
            <token id="10" string="heights" />
          </tokens>
        </chunking>
        <chunking id="4" string="Britain" type="NP">
          <tokens>
            <token id="6" string="Britain" />
          </tokens>
        </chunking>
        <chunking id="5" string="the controversy in Britain" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="controversy" />
            <token id="5" string="in" />
            <token id="6" string="Britain" />
          </tokens>
        </chunking>
        <chunking id="6" string="the controversy" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="controversy" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="8">reaching</governor>
          <dependent id="1">Meanwhile</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">controversy</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">reaching</governor>
          <dependent id="4">controversy</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Britain</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">controversy</governor>
          <dependent id="6">Britain</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">reaching</governor>
          <dependent id="7">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">reaching</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">heights</governor>
          <dependent id="9">new</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">reaching</governor>
          <dependent id="10">heights</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Britain" type="LOCATION" score="0.0">
          <tokens>
            <token id="6" string="Britain" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="false">
      <content>Last week, the scientific journal Nature called for a start to be made on replacing the British cattle population with animals free from the infection -- which the magazine estimate would cost &amp;amp;pound;30 billion.</content>
      <tokens>
        <token id="1" string="Last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="2" string="week" lemma="week" stem="week" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="scientific" lemma="scientific" stem="scientif" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="journal" lemma="journal" stem="journal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="Nature" lemma="Nature" stem="natur" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="8" string="called" lemma="call" stem="call" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="start" lemma="start" stem="start" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="made" lemma="make" stem="made" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="replacing" lemma="replace" stem="replac" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="British" lemma="british" stem="british" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="19" string="cattle" lemma="cattle" stem="cattl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="population" lemma="population" stem="popul" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="animals" lemma="animal" stem="anim" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="free" lemma="free" stem="free" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="infection" lemma="infection" stem="infect" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="27" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="magazine" lemma="magazine" stem="magazin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="estimate" lemma="estimate" stem="estim" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="cost" lemma="cost" stem="cost" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="&amp;" lemma="&amp;" stem="&amp;" pos="CC" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="pound" lemma="pound" stem="pound" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="30" lemma="30" stem="30" pos="CD" type="Number" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="38" string="billion" lemma="billion" stem="billion" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="39" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP-TMP (JJ Last) (NN week)) (, ,) (NP (DT the) (JJ scientific) (NN journal) (NNP Nature)) (VP (VBD called) (PP (IN for) (NP (DT a) (NN start))) (S (VP (TO to) (VP (VB be) (VP (VBN made) (PP (IN on) (S (VP (VBG replacing) (NP (NP (DT the) (JJ British) (NNS cattle) (NN population)) (PP (IN with) (NP (NP (NNS animals)) (ADVP (JJ free) (PP (IN from) (NP (DT the) (NN infection)))))) (PRN (: --) (SBAR (WHNP (WDT which)) (S (NP (DT the) (NN magazine) (NN estimate)) (VP (MD would) (VP (VB cost) (NP (CC &amp;) (NN pound)))))) (: ;)) (ADJP (CD 30) (CD billion))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a start" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="start" />
          </tokens>
        </chunking>
        <chunking id="2" string="the scientific journal Nature" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="scientific" />
            <token id="6" string="journal" />
            <token id="7" string="Nature" />
          </tokens>
        </chunking>
        <chunking id="3" string="the infection" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="infection" />
          </tokens>
        </chunking>
        <chunking id="4" string="animals free from the infection" type="NP">
          <tokens>
            <token id="22" string="animals" />
            <token id="23" string="free" />
            <token id="24" string="from" />
            <token id="25" string="the" />
            <token id="26" string="infection" />
          </tokens>
        </chunking>
        <chunking id="5" string="30 billion" type="ADJP">
          <tokens>
            <token id="37" string="30" />
            <token id="38" string="billion" />
          </tokens>
        </chunking>
        <chunking id="6" string="the British cattle population with animals free from the infection -- which the magazine estimate would cost &amp; pound ; 30 billion" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="British" />
            <token id="19" string="cattle" />
            <token id="20" string="population" />
            <token id="21" string="with" />
            <token id="22" string="animals" />
            <token id="23" string="free" />
            <token id="24" string="from" />
            <token id="25" string="the" />
            <token id="26" string="infection" />
            <token id="27" string="--" />
            <token id="28" string="which" />
            <token id="29" string="the" />
            <token id="30" string="magazine" />
            <token id="31" string="estimate" />
            <token id="32" string="would" />
            <token id="33" string="cost" />
            <token id="34" string="&amp;" />
            <token id="35" string="pound" />
            <token id="36" string=";" />
            <token id="37" string="30" />
            <token id="38" string="billion" />
          </tokens>
        </chunking>
        <chunking id="7" string="be made on replacing the British cattle population with animals free from the infection -- which the magazine estimate would cost &amp; pound ; 30 billion" type="VP">
          <tokens>
            <token id="13" string="be" />
            <token id="14" string="made" />
            <token id="15" string="on" />
            <token id="16" string="replacing" />
            <token id="17" string="the" />
            <token id="18" string="British" />
            <token id="19" string="cattle" />
            <token id="20" string="population" />
            <token id="21" string="with" />
            <token id="22" string="animals" />
            <token id="23" string="free" />
            <token id="24" string="from" />
            <token id="25" string="the" />
            <token id="26" string="infection" />
            <token id="27" string="--" />
            <token id="28" string="which" />
            <token id="29" string="the" />
            <token id="30" string="magazine" />
            <token id="31" string="estimate" />
            <token id="32" string="would" />
            <token id="33" string="cost" />
            <token id="34" string="&amp;" />
            <token id="35" string="pound" />
            <token id="36" string=";" />
            <token id="37" string="30" />
            <token id="38" string="billion" />
          </tokens>
        </chunking>
        <chunking id="8" string="to be made on replacing the British cattle population with animals free from the infection -- which the magazine estimate would cost &amp; pound ; 30 billion" type="VP">
          <tokens>
            <token id="12" string="to" />
            <token id="13" string="be" />
            <token id="14" string="made" />
            <token id="15" string="on" />
            <token id="16" string="replacing" />
            <token id="17" string="the" />
            <token id="18" string="British" />
            <token id="19" string="cattle" />
            <token id="20" string="population" />
            <token id="21" string="with" />
            <token id="22" string="animals" />
            <token id="23" string="free" />
            <token id="24" string="from" />
            <token id="25" string="the" />
            <token id="26" string="infection" />
            <token id="27" string="--" />
            <token id="28" string="which" />
            <token id="29" string="the" />
            <token id="30" string="magazine" />
            <token id="31" string="estimate" />
            <token id="32" string="would" />
            <token id="33" string="cost" />
            <token id="34" string="&amp;" />
            <token id="35" string="pound" />
            <token id="36" string=";" />
            <token id="37" string="30" />
            <token id="38" string="billion" />
          </tokens>
        </chunking>
        <chunking id="9" string="which the magazine estimate would cost &amp; pound" type="SBAR">
          <tokens>
            <token id="28" string="which" />
            <token id="29" string="the" />
            <token id="30" string="magazine" />
            <token id="31" string="estimate" />
            <token id="32" string="would" />
            <token id="33" string="cost" />
            <token id="34" string="&amp;" />
            <token id="35" string="pound" />
          </tokens>
        </chunking>
        <chunking id="10" string="the magazine estimate" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="magazine" />
            <token id="31" string="estimate" />
          </tokens>
        </chunking>
        <chunking id="11" string="cost &amp; pound" type="VP">
          <tokens>
            <token id="33" string="cost" />
            <token id="34" string="&amp;" />
            <token id="35" string="pound" />
          </tokens>
        </chunking>
        <chunking id="12" string="would cost &amp; pound" type="VP">
          <tokens>
            <token id="32" string="would" />
            <token id="33" string="cost" />
            <token id="34" string="&amp;" />
            <token id="35" string="pound" />
          </tokens>
        </chunking>
        <chunking id="13" string="&amp; pound" type="NP">
          <tokens>
            <token id="34" string="&amp;" />
            <token id="35" string="pound" />
          </tokens>
        </chunking>
        <chunking id="14" string="made on replacing the British cattle population with animals free from the infection -- which the magazine estimate would cost &amp; pound ; 30 billion" type="VP">
          <tokens>
            <token id="14" string="made" />
            <token id="15" string="on" />
            <token id="16" string="replacing" />
            <token id="17" string="the" />
            <token id="18" string="British" />
            <token id="19" string="cattle" />
            <token id="20" string="population" />
            <token id="21" string="with" />
            <token id="22" string="animals" />
            <token id="23" string="free" />
            <token id="24" string="from" />
            <token id="25" string="the" />
            <token id="26" string="infection" />
            <token id="27" string="--" />
            <token id="28" string="which" />
            <token id="29" string="the" />
            <token id="30" string="magazine" />
            <token id="31" string="estimate" />
            <token id="32" string="would" />
            <token id="33" string="cost" />
            <token id="34" string="&amp;" />
            <token id="35" string="pound" />
            <token id="36" string=";" />
            <token id="37" string="30" />
            <token id="38" string="billion" />
          </tokens>
        </chunking>
        <chunking id="15" string="animals" type="NP">
          <tokens>
            <token id="22" string="animals" />
          </tokens>
        </chunking>
        <chunking id="16" string="replacing the British cattle population with animals free from the infection -- which the magazine estimate would cost &amp; pound ; 30 billion" type="VP">
          <tokens>
            <token id="16" string="replacing" />
            <token id="17" string="the" />
            <token id="18" string="British" />
            <token id="19" string="cattle" />
            <token id="20" string="population" />
            <token id="21" string="with" />
            <token id="22" string="animals" />
            <token id="23" string="free" />
            <token id="24" string="from" />
            <token id="25" string="the" />
            <token id="26" string="infection" />
            <token id="27" string="--" />
            <token id="28" string="which" />
            <token id="29" string="the" />
            <token id="30" string="magazine" />
            <token id="31" string="estimate" />
            <token id="32" string="would" />
            <token id="33" string="cost" />
            <token id="34" string="&amp;" />
            <token id="35" string="pound" />
            <token id="36" string=";" />
            <token id="37" string="30" />
            <token id="38" string="billion" />
          </tokens>
        </chunking>
        <chunking id="17" string="called for a start to be made on replacing the British cattle population with animals free from the infection -- which the magazine estimate would cost &amp; pound ; 30 billion" type="VP">
          <tokens>
            <token id="8" string="called" />
            <token id="9" string="for" />
            <token id="10" string="a" />
            <token id="11" string="start" />
            <token id="12" string="to" />
            <token id="13" string="be" />
            <token id="14" string="made" />
            <token id="15" string="on" />
            <token id="16" string="replacing" />
            <token id="17" string="the" />
            <token id="18" string="British" />
            <token id="19" string="cattle" />
            <token id="20" string="population" />
            <token id="21" string="with" />
            <token id="22" string="animals" />
            <token id="23" string="free" />
            <token id="24" string="from" />
            <token id="25" string="the" />
            <token id="26" string="infection" />
            <token id="27" string="--" />
            <token id="28" string="which" />
            <token id="29" string="the" />
            <token id="30" string="magazine" />
            <token id="31" string="estimate" />
            <token id="32" string="would" />
            <token id="33" string="cost" />
            <token id="34" string="&amp;" />
            <token id="35" string="pound" />
            <token id="36" string=";" />
            <token id="37" string="30" />
            <token id="38" string="billion" />
          </tokens>
        </chunking>
        <chunking id="18" string="the British cattle population" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="British" />
            <token id="19" string="cattle" />
            <token id="20" string="population" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">week</governor>
          <dependent id="1">Last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="8">called</governor>
          <dependent id="2">week</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">Nature</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">Nature</governor>
          <dependent id="5">scientific</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Nature</governor>
          <dependent id="6">journal</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">called</governor>
          <dependent id="7">Nature</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">called</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">start</governor>
          <dependent id="9">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">start</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">called</governor>
          <dependent id="11">start</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">made</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="14">made</governor>
          <dependent id="13">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">called</governor>
          <dependent id="14">made</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">replacing</governor>
          <dependent id="15">on</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="14">made</governor>
          <dependent id="16">replacing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">population</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">population</governor>
          <dependent id="18">British</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">population</governor>
          <dependent id="19">cattle</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">replacing</governor>
          <dependent id="20">population</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">animals</governor>
          <dependent id="21">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">population</governor>
          <dependent id="22">animals</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="22">animals</governor>
          <dependent id="23">free</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">infection</governor>
          <dependent id="24">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">infection</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">free</governor>
          <dependent id="26">infection</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="33">cost</governor>
          <dependent id="28">which</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">estimate</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">estimate</governor>
          <dependent id="30">magazine</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="33">cost</governor>
          <dependent id="31">estimate</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="33">cost</governor>
          <dependent id="32">would</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="20">population</governor>
          <dependent id="33">cost</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="35">pound</governor>
          <dependent id="34">&amp;</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="33">cost</governor>
          <dependent id="35">pound</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="38">billion</governor>
          <dependent id="37">30</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">population</governor>
          <dependent id="38">billion</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Last week" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="Last" />
            <token id="2" string="week" />
          </tokens>
        </entity>
        <entity id="2" string="Nature" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="7" string="Nature" />
          </tokens>
        </entity>
        <entity id="3" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="18" string="British" />
          </tokens>
        </entity>
        <entity id="4" string="infection" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="26" string="infection" />
          </tokens>
        </entity>
        <entity id="5" string="30 billion" type="MONEY" score="0.0">
          <tokens>
            <token id="37" string="30" />
            <token id="38" string="billion" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>Next day, one of the farming industry&amp;apost;s loudest voices, the magazine Farmers Weekly hit back at what it called &amp;quot;a diet of speculation, half-truths and downright lies&amp;quot; and denounced what it called &amp;quot;certain publicity-hungry scientists promoted by the media more interested in fiction than fact.&amp;quot;</content>
      <tokens>
        <token id="1" string="Next" lemma="next" stem="next" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="2" string="day" lemma="day" stem="dai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="farming" lemma="farm" stem="farm" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="industry" lemma="industry" stem="industri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="loudest" lemma="loudest" stem="loudest" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="voices" lemma="voice" stem="voic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="magazine" lemma="magazine" stem="magazin" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="Farmers" lemma="Farmers" stem="farmer" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="16" string="Weekly" lemma="Weekly" stem="weekli" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="17" string="hit" lemma="hit" stem="hit" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="back" lemma="back" stem="back" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="called" lemma="call" stem="call" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="diet" lemma="diet" stem="diet" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="speculation" lemma="speculation" stem="specul" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="half-truths" lemma="half-truth" stem="half-truth" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="downright" lemma="downright" stem="downright" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string="lies" lemma="lie" stem="li" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="denounced" lemma="denounce" stem="denounc" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="called" lemma="call" stem="call" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="certain" lemma="certain" stem="certain" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="publicity-hungry" lemma="publicity-hungry" stem="publicity-hungri" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="scientists" lemma="scientist" stem="scientist" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="promoted" lemma="promote" stem="promot" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="media" lemma="media" stem="media" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="47" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="48" string="interested" lemma="interested" stem="interest" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="49" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="50" string="fiction" lemma="fiction" stem="fiction" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="51" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="52" string="fact" lemma="fact" stem="fact" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="53" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="54" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP-TMP (JJ Next) (NN day)) (PRN (, ,) (S (NP (NP (CD one)) (PP (IN of) (NP (DT the)))) (VP (VBG farming) (NP (NP (NN industry) (POS 's)) (JJS loudest) (NNS voices)))) (, ,)) (NP (DT the) (NN magazine) (NNP Farmers) (NNP Weekly)) (VP (VBD hit) (ADVP (RB back)) (PP (IN at) (SBAR (WHNP (WP what)) (S (NP (PRP it)) (VP (VP (VBD called) (`` ``) (SBAR (S (NP (NP (DT a) (NN diet)) (PP (IN of) (NP (NP (NN speculation)) (, ,) (NP (NNS half-truths)) (CC and) (NP (RB downright))))) (VP (VBZ lies)))) ('' '')) (CC and) (VP (VBD denounced) (SBAR (WHNP (WP what)) (S (NP (PRP it)) (VP (VBD called) (`` ``) (S (NP (NP (JJ certain) (JJ publicity-hungry) (NNS scientists)) (VP (VBN promoted) (PP (IN by) (NP (DT the) (NNS media))))) (ADJP (RBR more) (JJ interested) (PP (IN in) (NP (NP (NN fiction)) (PP (IN than) (NP (NN fact)))))))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="farming industry 's loudest voices" type="VP">
          <tokens>
            <token id="7" string="farming" />
            <token id="8" string="industry" />
            <token id="9" string="'s" />
            <token id="10" string="loudest" />
            <token id="11" string="voices" />
          </tokens>
        </chunking>
        <chunking id="2" string="a diet of speculation , half-truths and downright lies" type="SBAR">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="diet" />
            <token id="26" string="of" />
            <token id="27" string="speculation" />
            <token id="28" string="," />
            <token id="29" string="half-truths" />
            <token id="30" string="and" />
            <token id="31" string="downright" />
            <token id="32" string="lies" />
          </tokens>
        </chunking>
        <chunking id="3" string="certain publicity-hungry scientists" type="NP">
          <tokens>
            <token id="40" string="certain" />
            <token id="41" string="publicity-hungry" />
            <token id="42" string="scientists" />
          </tokens>
        </chunking>
        <chunking id="4" string="speculation" type="NP">
          <tokens>
            <token id="27" string="speculation" />
          </tokens>
        </chunking>
        <chunking id="5" string="what it called `` certain publicity-hungry scientists promoted by the media more interested in fiction than fact" type="SBAR">
          <tokens>
            <token id="36" string="what" />
            <token id="37" string="it" />
            <token id="38" string="called" />
            <token id="39" string="&quot;" />
            <token id="40" string="certain" />
            <token id="41" string="publicity-hungry" />
            <token id="42" string="scientists" />
            <token id="43" string="promoted" />
            <token id="44" string="by" />
            <token id="45" string="the" />
            <token id="46" string="media" />
            <token id="47" string="more" />
            <token id="48" string="interested" />
            <token id="49" string="in" />
            <token id="50" string="fiction" />
            <token id="51" string="than" />
            <token id="52" string="fact" />
          </tokens>
        </chunking>
        <chunking id="6" string="one" type="NP">
          <tokens>
            <token id="4" string="one" />
          </tokens>
        </chunking>
        <chunking id="7" string="called `` certain publicity-hungry scientists promoted by the media more interested in fiction than fact" type="VP">
          <tokens>
            <token id="38" string="called" />
            <token id="39" string="&quot;" />
            <token id="40" string="certain" />
            <token id="41" string="publicity-hungry" />
            <token id="42" string="scientists" />
            <token id="43" string="promoted" />
            <token id="44" string="by" />
            <token id="45" string="the" />
            <token id="46" string="media" />
            <token id="47" string="more" />
            <token id="48" string="interested" />
            <token id="49" string="in" />
            <token id="50" string="fiction" />
            <token id="51" string="than" />
            <token id="52" string="fact" />
          </tokens>
        </chunking>
        <chunking id="8" string="denounced what it called `` certain publicity-hungry scientists promoted by the media more interested in fiction than fact" type="VP">
          <tokens>
            <token id="35" string="denounced" />
            <token id="36" string="what" />
            <token id="37" string="it" />
            <token id="38" string="called" />
            <token id="39" string="&quot;" />
            <token id="40" string="certain" />
            <token id="41" string="publicity-hungry" />
            <token id="42" string="scientists" />
            <token id="43" string="promoted" />
            <token id="44" string="by" />
            <token id="45" string="the" />
            <token id="46" string="media" />
            <token id="47" string="more" />
            <token id="48" string="interested" />
            <token id="49" string="in" />
            <token id="50" string="fiction" />
            <token id="51" string="than" />
            <token id="52" string="fact" />
          </tokens>
        </chunking>
        <chunking id="9" string="the media" type="NP">
          <tokens>
            <token id="45" string="the" />
            <token id="46" string="media" />
          </tokens>
        </chunking>
        <chunking id="10" string="downright" type="NP">
          <tokens>
            <token id="31" string="downright" />
          </tokens>
        </chunking>
        <chunking id="11" string="it" type="NP">
          <tokens>
            <token id="21" string="it" />
          </tokens>
        </chunking>
        <chunking id="12" string="a diet" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="diet" />
          </tokens>
        </chunking>
        <chunking id="13" string="industry 's" type="NP">
          <tokens>
            <token id="8" string="industry" />
            <token id="9" string="'s" />
          </tokens>
        </chunking>
        <chunking id="14" string="the" type="NP">
          <tokens>
            <token id="6" string="the" />
          </tokens>
        </chunking>
        <chunking id="15" string="what it called `` a diet of speculation , half-truths and downright lies '' and denounced what it called `` certain publicity-hungry scientists promoted by the media more interested in fiction than fact" type="SBAR">
          <tokens>
            <token id="20" string="what" />
            <token id="21" string="it" />
            <token id="22" string="called" />
            <token id="23" string="&quot;" />
            <token id="24" string="a" />
            <token id="25" string="diet" />
            <token id="26" string="of" />
            <token id="27" string="speculation" />
            <token id="28" string="," />
            <token id="29" string="half-truths" />
            <token id="30" string="and" />
            <token id="31" string="downright" />
            <token id="32" string="lies" />
            <token id="33" string="&quot;" />
            <token id="34" string="and" />
            <token id="35" string="denounced" />
            <token id="36" string="what" />
            <token id="37" string="it" />
            <token id="38" string="called" />
            <token id="39" string="&quot;" />
            <token id="40" string="certain" />
            <token id="41" string="publicity-hungry" />
            <token id="42" string="scientists" />
            <token id="43" string="promoted" />
            <token id="44" string="by" />
            <token id="45" string="the" />
            <token id="46" string="media" />
            <token id="47" string="more" />
            <token id="48" string="interested" />
            <token id="49" string="in" />
            <token id="50" string="fiction" />
            <token id="51" string="than" />
            <token id="52" string="fact" />
          </tokens>
        </chunking>
        <chunking id="16" string="half-truths" type="NP">
          <tokens>
            <token id="29" string="half-truths" />
          </tokens>
        </chunking>
        <chunking id="17" string="certain publicity-hungry scientists promoted by the media" type="NP">
          <tokens>
            <token id="40" string="certain" />
            <token id="41" string="publicity-hungry" />
            <token id="42" string="scientists" />
            <token id="43" string="promoted" />
            <token id="44" string="by" />
            <token id="45" string="the" />
            <token id="46" string="media" />
          </tokens>
        </chunking>
        <chunking id="18" string="fiction" type="NP">
          <tokens>
            <token id="50" string="fiction" />
          </tokens>
        </chunking>
        <chunking id="19" string="fact" type="NP">
          <tokens>
            <token id="52" string="fact" />
          </tokens>
        </chunking>
        <chunking id="20" string="the magazine Farmers Weekly" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="magazine" />
            <token id="15" string="Farmers" />
            <token id="16" string="Weekly" />
          </tokens>
        </chunking>
        <chunking id="21" string="hit back at what it called `` a diet of speculation , half-truths and downright lies '' and denounced what it called `` certain publicity-hungry scientists promoted by the media more interested in fiction than fact" type="VP">
          <tokens>
            <token id="17" string="hit" />
            <token id="18" string="back" />
            <token id="19" string="at" />
            <token id="20" string="what" />
            <token id="21" string="it" />
            <token id="22" string="called" />
            <token id="23" string="&quot;" />
            <token id="24" string="a" />
            <token id="25" string="diet" />
            <token id="26" string="of" />
            <token id="27" string="speculation" />
            <token id="28" string="," />
            <token id="29" string="half-truths" />
            <token id="30" string="and" />
            <token id="31" string="downright" />
            <token id="32" string="lies" />
            <token id="33" string="&quot;" />
            <token id="34" string="and" />
            <token id="35" string="denounced" />
            <token id="36" string="what" />
            <token id="37" string="it" />
            <token id="38" string="called" />
            <token id="39" string="&quot;" />
            <token id="40" string="certain" />
            <token id="41" string="publicity-hungry" />
            <token id="42" string="scientists" />
            <token id="43" string="promoted" />
            <token id="44" string="by" />
            <token id="45" string="the" />
            <token id="46" string="media" />
            <token id="47" string="more" />
            <token id="48" string="interested" />
            <token id="49" string="in" />
            <token id="50" string="fiction" />
            <token id="51" string="than" />
            <token id="52" string="fact" />
          </tokens>
        </chunking>
        <chunking id="22" string="fiction than fact" type="NP">
          <tokens>
            <token id="50" string="fiction" />
            <token id="51" string="than" />
            <token id="52" string="fact" />
          </tokens>
        </chunking>
        <chunking id="23" string="industry 's loudest voices" type="NP">
          <tokens>
            <token id="8" string="industry" />
            <token id="9" string="'s" />
            <token id="10" string="loudest" />
            <token id="11" string="voices" />
          </tokens>
        </chunking>
        <chunking id="24" string="called `` a diet of speculation , half-truths and downright lies ''" type="VP">
          <tokens>
            <token id="22" string="called" />
            <token id="23" string="&quot;" />
            <token id="24" string="a" />
            <token id="25" string="diet" />
            <token id="26" string="of" />
            <token id="27" string="speculation" />
            <token id="28" string="," />
            <token id="29" string="half-truths" />
            <token id="30" string="and" />
            <token id="31" string="downright" />
            <token id="32" string="lies" />
            <token id="33" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="25" string="one of the" type="NP">
          <tokens>
            <token id="4" string="one" />
            <token id="5" string="of" />
            <token id="6" string="the" />
          </tokens>
        </chunking>
        <chunking id="26" string="called `` a diet of speculation , half-truths and downright lies '' and denounced what it called `` certain publicity-hungry scientists promoted by the media more interested in fiction than fact" type="VP">
          <tokens>
            <token id="22" string="called" />
            <token id="23" string="&quot;" />
            <token id="24" string="a" />
            <token id="25" string="diet" />
            <token id="26" string="of" />
            <token id="27" string="speculation" />
            <token id="28" string="," />
            <token id="29" string="half-truths" />
            <token id="30" string="and" />
            <token id="31" string="downright" />
            <token id="32" string="lies" />
            <token id="33" string="&quot;" />
            <token id="34" string="and" />
            <token id="35" string="denounced" />
            <token id="36" string="what" />
            <token id="37" string="it" />
            <token id="38" string="called" />
            <token id="39" string="&quot;" />
            <token id="40" string="certain" />
            <token id="41" string="publicity-hungry" />
            <token id="42" string="scientists" />
            <token id="43" string="promoted" />
            <token id="44" string="by" />
            <token id="45" string="the" />
            <token id="46" string="media" />
            <token id="47" string="more" />
            <token id="48" string="interested" />
            <token id="49" string="in" />
            <token id="50" string="fiction" />
            <token id="51" string="than" />
            <token id="52" string="fact" />
          </tokens>
        </chunking>
        <chunking id="27" string="promoted by the media" type="VP">
          <tokens>
            <token id="43" string="promoted" />
            <token id="44" string="by" />
            <token id="45" string="the" />
            <token id="46" string="media" />
          </tokens>
        </chunking>
        <chunking id="28" string="more interested in fiction than fact" type="ADJP">
          <tokens>
            <token id="47" string="more" />
            <token id="48" string="interested" />
            <token id="49" string="in" />
            <token id="50" string="fiction" />
            <token id="51" string="than" />
            <token id="52" string="fact" />
          </tokens>
        </chunking>
        <chunking id="29" string="lies" type="VP">
          <tokens>
            <token id="32" string="lies" />
          </tokens>
        </chunking>
        <chunking id="30" string="speculation , half-truths and downright" type="NP">
          <tokens>
            <token id="27" string="speculation" />
            <token id="28" string="," />
            <token id="29" string="half-truths" />
            <token id="30" string="and" />
            <token id="31" string="downright" />
          </tokens>
        </chunking>
        <chunking id="31" string="a diet of speculation , half-truths and downright" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="diet" />
            <token id="26" string="of" />
            <token id="27" string="speculation" />
            <token id="28" string="," />
            <token id="29" string="half-truths" />
            <token id="30" string="and" />
            <token id="31" string="downright" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">day</governor>
          <dependent id="1">Next</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="17">hit</governor>
          <dependent id="2">day</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">farming</governor>
          <dependent id="4">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">the</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">one</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="17">hit</governor>
          <dependent id="7">farming</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">voices</governor>
          <dependent id="8">industry</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">industry</governor>
          <dependent id="9">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">voices</governor>
          <dependent id="10">loudest</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">farming</governor>
          <dependent id="11">voices</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">Weekly</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Weekly</governor>
          <dependent id="14">magazine</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Weekly</governor>
          <dependent id="15">Farmers</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">hit</governor>
          <dependent id="16">Weekly</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">hit</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">hit</governor>
          <dependent id="18">back</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">called</governor>
          <dependent id="19">at</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">called</governor>
          <dependent id="20">what</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">called</governor>
          <dependent id="21">it</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="17">hit</governor>
          <dependent id="22">called</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">diet</governor>
          <dependent id="24">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="32">lies</governor>
          <dependent id="25">diet</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">speculation</governor>
          <dependent id="26">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">diet</governor>
          <dependent id="27">speculation</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="27">speculation</governor>
          <dependent id="29">half-truths</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="27">speculation</governor>
          <dependent id="30">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="27">speculation</governor>
          <dependent id="31">downright</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="22">called</governor>
          <dependent id="32">lies</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="22">called</governor>
          <dependent id="34">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="22">called</governor>
          <dependent id="35">denounced</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="48">interested</governor>
          <dependent id="36">what</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="38">called</governor>
          <dependent id="37">it</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="35">denounced</governor>
          <dependent id="38">called</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="42">scientists</governor>
          <dependent id="40">certain</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="42">scientists</governor>
          <dependent id="41">publicity-hungry</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="48">interested</governor>
          <dependent id="42">scientists</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="42">scientists</governor>
          <dependent id="43">promoted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="46">media</governor>
          <dependent id="44">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="46">media</governor>
          <dependent id="45">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="43">promoted</governor>
          <dependent id="46">media</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="48">interested</governor>
          <dependent id="47">more</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="38">called</governor>
          <dependent id="48">interested</dependent>
        </dependency>
        <dependency type="case">
          <governor id="50">fiction</governor>
          <dependent id="49">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="48">interested</governor>
          <dependent id="50">fiction</dependent>
        </dependency>
        <dependency type="case">
          <governor id="52">fact</governor>
          <dependent id="51">than</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="50">fiction</governor>
          <dependent id="52">fact</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="4" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="Next day" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="Next" />
            <token id="2" string="day" />
          </tokens>
        </entity>
        <entity id="3" string="Farmers Weekly" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="15" string="Farmers" />
            <token id="16" string="Weekly" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>Calling on the Ministry of Agriculture, Fisheries and Food (MAFF) to do more to explain the disease, the magazine concluded: &amp;quot;The alternative is to exacerbate the current climate of fear and uncertainty...&amp;quot; The fear is not just that shared by farmers worried about their livelihood.</content>
      <tokens>
        <token id="1" string="Calling" lemma="call" stem="call" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Ministry" lemma="Ministry" stem="ministri" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="6" string="Agriculture" lemma="Agriculture" stem="agricultur" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Fisheries" lemma="Fisheries" stem="fisheri" pos="NNPS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Food" lemma="Food" stem="food" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="MAFF" lemma="MAFF" stem="maff" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="13" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="do" lemma="do" stem="do" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="explain" lemma="explain" stem="explain" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="true" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="magazine" lemma="magazine" stem="magazin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="concluded" lemma="conclude" stem="conclud" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="alternative" lemma="alternative" stem="altern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="exacerbate" lemma="exacerbate" stem="exacerb" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="current" lemma="current" stem="current" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="34" string="climate" lemma="climate" stem="climat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="fear" lemma="fear" stem="fear" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="uncertainty" lemma="uncertainty" stem="uncertainti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="..." lemma="..." stem="..." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="42" string="fear" lemma="fear" stem="fear" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="43" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="shared" lemma="share" stem="share" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="48" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="49" string="farmers" lemma="farmer" stem="farmer" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="50" string="worried" lemma="worry" stem="worri" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="51" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="52" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="53" string="livelihood" lemma="livelihood" stem="livelihood" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="54" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (S (VP (VBG Calling) (PP (IN on) (NP (NP (DT the) (NNP Ministry)) (PP (IN of) (NP (NP (NNP Agriculture)) (, ,) (NP (NNPS Fisheries)) (CC and) (NP (NNP Food)) (PRN (-LRB- -LRB-) (NP (NNP MAFF)) (-RRB- -RRB-)))))) (S (VP (TO to) (VP (VB do) (NP (JJR more)) (S (VP (TO to) (VP (VB explain) (NP (DT the) (NN disease)))))))))) (, ,) (NP (DT the) (NN magazine)) (VP (VBD concluded) (: :) (`` ``) (S (NP (DT The) (NN alternative)) (VP (VBZ is) (S (VP (TO to) (VP (VB exacerbate) (NP (NP (DT the) (JJ current) (NN climate)) (PP (IN of) (NP (NN fear) (CC and) (NN uncertainty))))))))))) (: ...) ('' '') (S (NP (DT The) (NN fear)) (VP (VBZ is) (RB not) (NP (NP (RB just) (DT that)) (VP (VBN shared) (PP (IN by) (NP (NP (NNS farmers)) (VP (VBN worried) (PP (IN about) (NP (PRP$ their) (NN livelihood)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="worried about their livelihood" type="VP">
          <tokens>
            <token id="50" string="worried" />
            <token id="51" string="about" />
            <token id="52" string="their" />
            <token id="53" string="livelihood" />
          </tokens>
        </chunking>
        <chunking id="2" string="fear and uncertainty" type="NP">
          <tokens>
            <token id="36" string="fear" />
            <token id="37" string="and" />
            <token id="38" string="uncertainty" />
          </tokens>
        </chunking>
        <chunking id="3" string="the Ministry" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="Ministry" />
          </tokens>
        </chunking>
        <chunking id="4" string="more" type="NP">
          <tokens>
            <token id="16" string="more" />
          </tokens>
        </chunking>
        <chunking id="5" string="do more to explain the disease" type="VP">
          <tokens>
            <token id="15" string="do" />
            <token id="16" string="more" />
            <token id="17" string="to" />
            <token id="18" string="explain" />
            <token id="19" string="the" />
            <token id="20" string="disease" />
          </tokens>
        </chunking>
        <chunking id="6" string="The fear" type="NP">
          <tokens>
            <token id="41" string="The" />
            <token id="42" string="fear" />
          </tokens>
        </chunking>
        <chunking id="7" string="Fisheries" type="NP">
          <tokens>
            <token id="8" string="Fisheries" />
          </tokens>
        </chunking>
        <chunking id="8" string="the current climate" type="NP">
          <tokens>
            <token id="32" string="the" />
            <token id="33" string="current" />
            <token id="34" string="climate" />
          </tokens>
        </chunking>
        <chunking id="9" string="Agriculture , Fisheries and Food -LRB- MAFF -RRB-" type="NP">
          <tokens>
            <token id="6" string="Agriculture" />
            <token id="7" string="," />
            <token id="8" string="Fisheries" />
            <token id="9" string="and" />
            <token id="10" string="Food" />
            <token id="11" string="(" />
            <token id="12" string="MAFF" />
            <token id="13" string=")" />
          </tokens>
        </chunking>
        <chunking id="10" string="explain the disease" type="VP">
          <tokens>
            <token id="18" string="explain" />
            <token id="19" string="the" />
            <token id="20" string="disease" />
          </tokens>
        </chunking>
        <chunking id="11" string="MAFF" type="NP">
          <tokens>
            <token id="12" string="MAFF" />
          </tokens>
        </chunking>
        <chunking id="12" string="the disease" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="disease" />
          </tokens>
        </chunking>
        <chunking id="13" string="the current climate of fear and uncertainty" type="NP">
          <tokens>
            <token id="32" string="the" />
            <token id="33" string="current" />
            <token id="34" string="climate" />
            <token id="35" string="of" />
            <token id="36" string="fear" />
            <token id="37" string="and" />
            <token id="38" string="uncertainty" />
          </tokens>
        </chunking>
        <chunking id="14" string="to exacerbate the current climate of fear and uncertainty" type="VP">
          <tokens>
            <token id="30" string="to" />
            <token id="31" string="exacerbate" />
            <token id="32" string="the" />
            <token id="33" string="current" />
            <token id="34" string="climate" />
            <token id="35" string="of" />
            <token id="36" string="fear" />
            <token id="37" string="and" />
            <token id="38" string="uncertainty" />
          </tokens>
        </chunking>
        <chunking id="15" string="exacerbate the current climate of fear and uncertainty" type="VP">
          <tokens>
            <token id="31" string="exacerbate" />
            <token id="32" string="the" />
            <token id="33" string="current" />
            <token id="34" string="climate" />
            <token id="35" string="of" />
            <token id="36" string="fear" />
            <token id="37" string="and" />
            <token id="38" string="uncertainty" />
          </tokens>
        </chunking>
        <chunking id="16" string="shared by farmers worried about their livelihood" type="VP">
          <tokens>
            <token id="47" string="shared" />
            <token id="48" string="by" />
            <token id="49" string="farmers" />
            <token id="50" string="worried" />
            <token id="51" string="about" />
            <token id="52" string="their" />
            <token id="53" string="livelihood" />
          </tokens>
        </chunking>
        <chunking id="17" string="the magazine" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="magazine" />
          </tokens>
        </chunking>
        <chunking id="18" string="farmers worried about their livelihood" type="NP">
          <tokens>
            <token id="49" string="farmers" />
            <token id="50" string="worried" />
            <token id="51" string="about" />
            <token id="52" string="their" />
            <token id="53" string="livelihood" />
          </tokens>
        </chunking>
        <chunking id="19" string="is not just that shared by farmers worried about their livelihood" type="VP">
          <tokens>
            <token id="43" string="is" />
            <token id="44" string="not" />
            <token id="45" string="just" />
            <token id="46" string="that" />
            <token id="47" string="shared" />
            <token id="48" string="by" />
            <token id="49" string="farmers" />
            <token id="50" string="worried" />
            <token id="51" string="about" />
            <token id="52" string="their" />
            <token id="53" string="livelihood" />
          </tokens>
        </chunking>
        <chunking id="20" string="to explain the disease" type="VP">
          <tokens>
            <token id="17" string="to" />
            <token id="18" string="explain" />
            <token id="19" string="the" />
            <token id="20" string="disease" />
          </tokens>
        </chunking>
        <chunking id="21" string="just that shared by farmers worried about their livelihood" type="NP">
          <tokens>
            <token id="45" string="just" />
            <token id="46" string="that" />
            <token id="47" string="shared" />
            <token id="48" string="by" />
            <token id="49" string="farmers" />
            <token id="50" string="worried" />
            <token id="51" string="about" />
            <token id="52" string="their" />
            <token id="53" string="livelihood" />
          </tokens>
        </chunking>
        <chunking id="22" string="just that" type="NP">
          <tokens>
            <token id="45" string="just" />
            <token id="46" string="that" />
          </tokens>
        </chunking>
        <chunking id="23" string="concluded : `` The alternative is to exacerbate the current climate of fear and uncertainty" type="VP">
          <tokens>
            <token id="24" string="concluded" />
            <token id="25" string=":" />
            <token id="26" string="&quot;" />
            <token id="27" string="The" />
            <token id="28" string="alternative" />
            <token id="29" string="is" />
            <token id="30" string="to" />
            <token id="31" string="exacerbate" />
            <token id="32" string="the" />
            <token id="33" string="current" />
            <token id="34" string="climate" />
            <token id="35" string="of" />
            <token id="36" string="fear" />
            <token id="37" string="and" />
            <token id="38" string="uncertainty" />
          </tokens>
        </chunking>
        <chunking id="24" string="farmers" type="NP">
          <tokens>
            <token id="49" string="farmers" />
          </tokens>
        </chunking>
        <chunking id="25" string="Calling on the Ministry of Agriculture , Fisheries and Food -LRB- MAFF -RRB- to do more to explain the disease" type="VP">
          <tokens>
            <token id="1" string="Calling" />
            <token id="2" string="on" />
            <token id="3" string="the" />
            <token id="4" string="Ministry" />
            <token id="5" string="of" />
            <token id="6" string="Agriculture" />
            <token id="7" string="," />
            <token id="8" string="Fisheries" />
            <token id="9" string="and" />
            <token id="10" string="Food" />
            <token id="11" string="(" />
            <token id="12" string="MAFF" />
            <token id="13" string=")" />
            <token id="14" string="to" />
            <token id="15" string="do" />
            <token id="16" string="more" />
            <token id="17" string="to" />
            <token id="18" string="explain" />
            <token id="19" string="the" />
            <token id="20" string="disease" />
          </tokens>
        </chunking>
        <chunking id="26" string="the Ministry of Agriculture , Fisheries and Food -LRB- MAFF -RRB-" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="Ministry" />
            <token id="5" string="of" />
            <token id="6" string="Agriculture" />
            <token id="7" string="," />
            <token id="8" string="Fisheries" />
            <token id="9" string="and" />
            <token id="10" string="Food" />
            <token id="11" string="(" />
            <token id="12" string="MAFF" />
            <token id="13" string=")" />
          </tokens>
        </chunking>
        <chunking id="27" string="their livelihood" type="NP">
          <tokens>
            <token id="52" string="their" />
            <token id="53" string="livelihood" />
          </tokens>
        </chunking>
        <chunking id="28" string="The alternative" type="NP">
          <tokens>
            <token id="27" string="The" />
            <token id="28" string="alternative" />
          </tokens>
        </chunking>
        <chunking id="29" string="to do more to explain the disease" type="VP">
          <tokens>
            <token id="14" string="to" />
            <token id="15" string="do" />
            <token id="16" string="more" />
            <token id="17" string="to" />
            <token id="18" string="explain" />
            <token id="19" string="the" />
            <token id="20" string="disease" />
          </tokens>
        </chunking>
        <chunking id="30" string="Agriculture" type="NP">
          <tokens>
            <token id="6" string="Agriculture" />
          </tokens>
        </chunking>
        <chunking id="31" string="Food" type="NP">
          <tokens>
            <token id="10" string="Food" />
          </tokens>
        </chunking>
        <chunking id="32" string="is to exacerbate the current climate of fear and uncertainty" type="VP">
          <tokens>
            <token id="29" string="is" />
            <token id="30" string="to" />
            <token id="31" string="exacerbate" />
            <token id="32" string="the" />
            <token id="33" string="current" />
            <token id="34" string="climate" />
            <token id="35" string="of" />
            <token id="36" string="fear" />
            <token id="37" string="and" />
            <token id="38" string="uncertainty" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advcl">
          <governor id="24">concluded</governor>
          <dependent id="1">Calling</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">Ministry</governor>
          <dependent id="2">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">Ministry</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Calling</governor>
          <dependent id="4">Ministry</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Agriculture</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">Ministry</governor>
          <dependent id="6">Agriculture</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">Agriculture</governor>
          <dependent id="8">Fisheries</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">Agriculture</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">Agriculture</governor>
          <dependent id="10">Food</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="6">Agriculture</governor>
          <dependent id="12">MAFF</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">do</governor>
          <dependent id="14">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="1">Calling</governor>
          <dependent id="15">do</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">do</governor>
          <dependent id="16">more</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">explain</governor>
          <dependent id="17">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="15">do</governor>
          <dependent id="18">explain</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">disease</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">explain</governor>
          <dependent id="20">disease</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">magazine</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">concluded</governor>
          <dependent id="23">magazine</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="24">concluded</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">alternative</governor>
          <dependent id="27">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">is</governor>
          <dependent id="28">alternative</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="24">concluded</governor>
          <dependent id="29">is</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="31">exacerbate</governor>
          <dependent id="30">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="29">is</governor>
          <dependent id="31">exacerbate</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">climate</governor>
          <dependent id="32">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="34">climate</governor>
          <dependent id="33">current</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="31">exacerbate</governor>
          <dependent id="34">climate</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">fear</governor>
          <dependent id="35">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="34">climate</governor>
          <dependent id="36">fear</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="36">fear</governor>
          <dependent id="37">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="36">fear</governor>
          <dependent id="38">uncertainty</dependent>
        </dependency>
        <dependency type="det">
          <governor id="42">fear</governor>
          <dependent id="41">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="46">that</governor>
          <dependent id="42">fear</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="46">that</governor>
          <dependent id="43">is</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="46">that</governor>
          <dependent id="44">not</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="46">that</governor>
          <dependent id="45">just</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="24">concluded</governor>
          <dependent id="46">that</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="46">that</governor>
          <dependent id="47">shared</dependent>
        </dependency>
        <dependency type="case">
          <governor id="49">farmers</governor>
          <dependent id="48">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="47">shared</governor>
          <dependent id="49">farmers</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="49">farmers</governor>
          <dependent id="50">worried</dependent>
        </dependency>
        <dependency type="case">
          <governor id="53">livelihood</governor>
          <dependent id="51">about</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="53">livelihood</governor>
          <dependent id="52">their</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="50">worried</governor>
          <dependent id="53">livelihood</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="MAFF" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="12" string="MAFF" />
          </tokens>
        </entity>
        <entity id="2" string="current" type="DATE" score="0.0">
          <tokens>
            <token id="33" string="current" />
          </tokens>
        </entity>
        <entity id="3" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="20" string="disease" />
          </tokens>
        </entity>
        <entity id="4" string="Ministry of Agriculture" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="4" string="Ministry" />
            <token id="5" string="of" />
            <token id="6" string="Agriculture" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>Could it transfer itself from cows to humans?</content>
      <tokens>
        <token id="1" string="Could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="transfer" lemma="transfer" stem="transfer" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="itself" lemma="itself" stem="itself" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="cows" lemma="cow" stem="cow" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="humans" lemma="human" stem="human" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SQ (MD Could) (NP (PRP it)) (VP (VB transfer) (NP (PRP itself)) (PP (IN from) (NP (NP (NNS cows)) (PP (TO to) (NP (NNS humans)))))) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="transfer itself from cows to humans" type="VP">
          <tokens>
            <token id="3" string="transfer" />
            <token id="4" string="itself" />
            <token id="5" string="from" />
            <token id="6" string="cows" />
            <token id="7" string="to" />
            <token id="8" string="humans" />
          </tokens>
        </chunking>
        <chunking id="2" string="itself" type="NP">
          <tokens>
            <token id="4" string="itself" />
          </tokens>
        </chunking>
        <chunking id="3" string="cows to humans" type="NP">
          <tokens>
            <token id="6" string="cows" />
            <token id="7" string="to" />
            <token id="8" string="humans" />
          </tokens>
        </chunking>
        <chunking id="4" string="cows" type="NP">
          <tokens>
            <token id="6" string="cows" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="2" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="humans" type="NP">
          <tokens>
            <token id="8" string="humans" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="aux">
          <governor id="3">transfer</governor>
          <dependent id="1">Could</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">transfer</governor>
          <dependent id="2">it</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">transfer</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">transfer</governor>
          <dependent id="4">itself</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">cows</governor>
          <dependent id="5">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">transfer</governor>
          <dependent id="6">cows</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">humans</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">cows</governor>
          <dependent id="8">humans</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>&amp;quot;Mad Cow&amp;quot; disease was probably first observed on a farm in Kent in 1985, when four animals were put down after they were observed drooling, staggering before collapsing.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Mad" lemma="Mad" stem="mad" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="Cow" lemma="Cow" stem="cow" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="true" />
        <token id="6" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="probably" lemma="probably" stem="probabl" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="9" string="observed" lemma="observe" stem="observ" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="farm" lemma="farm" stem="farm" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Kent" lemma="Kent" stem="kent" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="15" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="1985" lemma="1985" stem="1985" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="four" lemma="four" stem="four" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="20" string="animals" lemma="animal" stem="anim" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="put" lemma="put" stem="put" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="down" lemma="down" stem="down" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="observed" lemma="observe" stem="observ" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="drooling" lemma="drool" stem="drool" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="staggering" lemma="stagger" stem="stagger" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="collapsing" lemma="collapse" stem="collaps" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (NNP Mad) (NNP Cow) ('' '') (NN disease)) (VP (VBD was) (ADVP (RB probably)) (VP (ADVP (JJ first)) (VBN observed) (PP (IN on) (NP (NP (DT a) (NN farm)) (PP (IN in) (NP (NP (NNP Kent)) (PP (IN in) (NP (CD 1985))))))) (, ,) (SBAR (WHADVP (WRB when)) (S (NP (CD four) (NNS animals)) (VP (VBD were) (VP (VBN put) (PRT (RP down)) (SBAR (IN after) (S (NP (PRP they)) (VP (VBD were) (VP (VBN observed) (S (VP (VP (VBG drooling)) (, ,) (VP (VBG staggering) (PP (IN before) (NP (VBG collapsing)))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="first observed on a farm in Kent in 1985 , when four animals were put down after they were observed drooling , staggering before collapsing" type="VP">
          <tokens>
            <token id="8" string="first" />
            <token id="9" string="observed" />
            <token id="10" string="on" />
            <token id="11" string="a" />
            <token id="12" string="farm" />
            <token id="13" string="in" />
            <token id="14" string="Kent" />
            <token id="15" string="in" />
            <token id="16" string="1985" />
            <token id="17" string="," />
            <token id="18" string="when" />
            <token id="19" string="four" />
            <token id="20" string="animals" />
            <token id="21" string="were" />
            <token id="22" string="put" />
            <token id="23" string="down" />
            <token id="24" string="after" />
            <token id="25" string="they" />
            <token id="26" string="were" />
            <token id="27" string="observed" />
            <token id="28" string="drooling" />
            <token id="29" string="," />
            <token id="30" string="staggering" />
            <token id="31" string="before" />
            <token id="32" string="collapsing" />
          </tokens>
        </chunking>
        <chunking id="2" string="were put down after they were observed drooling , staggering before collapsing" type="VP">
          <tokens>
            <token id="21" string="were" />
            <token id="22" string="put" />
            <token id="23" string="down" />
            <token id="24" string="after" />
            <token id="25" string="they" />
            <token id="26" string="were" />
            <token id="27" string="observed" />
            <token id="28" string="drooling" />
            <token id="29" string="," />
            <token id="30" string="staggering" />
            <token id="31" string="before" />
            <token id="32" string="collapsing" />
          </tokens>
        </chunking>
        <chunking id="3" string="Kent in 1985" type="NP">
          <tokens>
            <token id="14" string="Kent" />
            <token id="15" string="in" />
            <token id="16" string="1985" />
          </tokens>
        </chunking>
        <chunking id="4" string="were observed drooling , staggering before collapsing" type="VP">
          <tokens>
            <token id="26" string="were" />
            <token id="27" string="observed" />
            <token id="28" string="drooling" />
            <token id="29" string="," />
            <token id="30" string="staggering" />
            <token id="31" string="before" />
            <token id="32" string="collapsing" />
          </tokens>
        </chunking>
        <chunking id="5" string="was probably first observed on a farm in Kent in 1985 , when four animals were put down after they were observed drooling , staggering before collapsing" type="VP">
          <tokens>
            <token id="6" string="was" />
            <token id="7" string="probably" />
            <token id="8" string="first" />
            <token id="9" string="observed" />
            <token id="10" string="on" />
            <token id="11" string="a" />
            <token id="12" string="farm" />
            <token id="13" string="in" />
            <token id="14" string="Kent" />
            <token id="15" string="in" />
            <token id="16" string="1985" />
            <token id="17" string="," />
            <token id="18" string="when" />
            <token id="19" string="four" />
            <token id="20" string="animals" />
            <token id="21" string="were" />
            <token id="22" string="put" />
            <token id="23" string="down" />
            <token id="24" string="after" />
            <token id="25" string="they" />
            <token id="26" string="were" />
            <token id="27" string="observed" />
            <token id="28" string="drooling" />
            <token id="29" string="," />
            <token id="30" string="staggering" />
            <token id="31" string="before" />
            <token id="32" string="collapsing" />
          </tokens>
        </chunking>
        <chunking id="6" string="observed drooling , staggering before collapsing" type="VP">
          <tokens>
            <token id="27" string="observed" />
            <token id="28" string="drooling" />
            <token id="29" string="," />
            <token id="30" string="staggering" />
            <token id="31" string="before" />
            <token id="32" string="collapsing" />
          </tokens>
        </chunking>
        <chunking id="7" string="a farm" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="farm" />
          </tokens>
        </chunking>
        <chunking id="8" string="Mad Cow '' disease" type="NP">
          <tokens>
            <token id="2" string="Mad" />
            <token id="3" string="Cow" />
            <token id="4" string="&quot;" />
            <token id="5" string="disease" />
          </tokens>
        </chunking>
        <chunking id="9" string="when four animals were put down after they were observed drooling , staggering before collapsing" type="SBAR">
          <tokens>
            <token id="18" string="when" />
            <token id="19" string="four" />
            <token id="20" string="animals" />
            <token id="21" string="were" />
            <token id="22" string="put" />
            <token id="23" string="down" />
            <token id="24" string="after" />
            <token id="25" string="they" />
            <token id="26" string="were" />
            <token id="27" string="observed" />
            <token id="28" string="drooling" />
            <token id="29" string="," />
            <token id="30" string="staggering" />
            <token id="31" string="before" />
            <token id="32" string="collapsing" />
          </tokens>
        </chunking>
        <chunking id="10" string="when" type="WHADVP">
          <tokens>
            <token id="18" string="when" />
          </tokens>
        </chunking>
        <chunking id="11" string="after they were observed drooling , staggering before collapsing" type="SBAR">
          <tokens>
            <token id="24" string="after" />
            <token id="25" string="they" />
            <token id="26" string="were" />
            <token id="27" string="observed" />
            <token id="28" string="drooling" />
            <token id="29" string="," />
            <token id="30" string="staggering" />
            <token id="31" string="before" />
            <token id="32" string="collapsing" />
          </tokens>
        </chunking>
        <chunking id="12" string="a farm in Kent in 1985" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="farm" />
            <token id="13" string="in" />
            <token id="14" string="Kent" />
            <token id="15" string="in" />
            <token id="16" string="1985" />
          </tokens>
        </chunking>
        <chunking id="13" string="collapsing" type="NP">
          <tokens>
            <token id="32" string="collapsing" />
          </tokens>
        </chunking>
        <chunking id="14" string="four animals" type="NP">
          <tokens>
            <token id="19" string="four" />
            <token id="20" string="animals" />
          </tokens>
        </chunking>
        <chunking id="15" string="they" type="NP">
          <tokens>
            <token id="25" string="they" />
          </tokens>
        </chunking>
        <chunking id="16" string="1985" type="NP">
          <tokens>
            <token id="16" string="1985" />
          </tokens>
        </chunking>
        <chunking id="17" string="put down after they were observed drooling , staggering before collapsing" type="VP">
          <tokens>
            <token id="22" string="put" />
            <token id="23" string="down" />
            <token id="24" string="after" />
            <token id="25" string="they" />
            <token id="26" string="were" />
            <token id="27" string="observed" />
            <token id="28" string="drooling" />
            <token id="29" string="," />
            <token id="30" string="staggering" />
            <token id="31" string="before" />
            <token id="32" string="collapsing" />
          </tokens>
        </chunking>
        <chunking id="18" string="drooling" type="VP">
          <tokens>
            <token id="28" string="drooling" />
          </tokens>
        </chunking>
        <chunking id="19" string="Kent" type="NP">
          <tokens>
            <token id="14" string="Kent" />
          </tokens>
        </chunking>
        <chunking id="20" string="drooling , staggering before collapsing" type="VP">
          <tokens>
            <token id="28" string="drooling" />
            <token id="29" string="," />
            <token id="30" string="staggering" />
            <token id="31" string="before" />
            <token id="32" string="collapsing" />
          </tokens>
        </chunking>
        <chunking id="21" string="staggering before collapsing" type="VP">
          <tokens>
            <token id="30" string="staggering" />
            <token id="31" string="before" />
            <token id="32" string="collapsing" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="5">disease</governor>
          <dependent id="2">Mad</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">disease</governor>
          <dependent id="3">Cow</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="9">observed</governor>
          <dependent id="5">disease</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="9">observed</governor>
          <dependent id="6">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">observed</governor>
          <dependent id="7">probably</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">observed</governor>
          <dependent id="8">first</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">observed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">farm</governor>
          <dependent id="10">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">farm</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">observed</governor>
          <dependent id="12">farm</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Kent</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">farm</governor>
          <dependent id="14">Kent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">1985</governor>
          <dependent id="15">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">Kent</governor>
          <dependent id="16">1985</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="22">put</governor>
          <dependent id="18">when</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="20">animals</governor>
          <dependent id="19">four</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="22">put</governor>
          <dependent id="20">animals</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="22">put</governor>
          <dependent id="21">were</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">observed</governor>
          <dependent id="22">put</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="22">put</governor>
          <dependent id="23">down</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="27">observed</governor>
          <dependent id="24">after</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="27">observed</governor>
          <dependent id="25">they</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="27">observed</governor>
          <dependent id="26">were</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="22">put</governor>
          <dependent id="27">observed</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="27">observed</governor>
          <dependent id="28">drooling</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="28">drooling</governor>
          <dependent id="30">staggering</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">collapsing</governor>
          <dependent id="31">before</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">staggering</governor>
          <dependent id="32">collapsing</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="8" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="1985" type="DATE" score="0.0">
          <tokens>
            <token id="16" string="1985" />
          </tokens>
        </entity>
        <entity id="3" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="5" string="disease" />
          </tokens>
        </entity>
        <entity id="4" string="four" type="NUMBER" score="0.0">
          <tokens>
            <token id="19" string="four" />
          </tokens>
        </entity>
        <entity id="5" string="Kent" type="LOCATION" score="0.0">
          <tokens>
            <token id="14" string="Kent" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>Scientists at the Central Veterinary Laboratory in Surrey found that the animals&amp;apost; brains had become holed and spongelike -- similar symptoms to the disease scrapie in sheep and the rare Creutzfeldt-Jakob disease (CJD), in humans.</content>
      <tokens>
        <token id="1" string="Scientists" lemma="scientist" stem="scientist" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Central" lemma="Central" stem="central" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="5" string="Veterinary" lemma="veterinary" stem="veterinari" pos="JJ" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="6" string="Laboratory" lemma="laboratory" stem="laboratori" pos="NN" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Surrey" lemma="Surrey" stem="surrei" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="9" string="found" lemma="find" stem="found" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="animals" lemma="animal" stem="anim" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="brains" lemma="brain" stem="brain" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="become" lemma="become" stem="becom" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="holed" lemma="hole" stem="hole" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="spongelike" lemma="spongelike" stem="spongelik" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="similar" lemma="similar" stem="similar" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="symptoms" lemma="symptom" stem="symptom" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="26" string="scrapie" lemma="scrapie" stem="scrapi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="sheep" lemma="sheep" stem="sheep" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="rare" lemma="rare" stem="rare" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="Creutzfeldt-Jakob" lemma="creutzfeldt-jakob" stem="creutzfeldt-jakob" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="33" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="34" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="CJD" lemma="cjd" stem="cjd" pos="NN" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="36" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="humans" lemma="human" stem="human" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNS Scientists)) (PP (IN at) (NP (NP (DT the) (NNP Central) (JJ Veterinary) (NN Laboratory)) (PP (IN in) (NP (NNP Surrey)))))) (VP (VBD found) (SBAR (IN that) (S (NP (NP (DT the) (NNS animals) (POS ')) (NNS brains)) (VP (VBD had) (VP (VBN become) (UCP (VP (VBN holed)) (CC and) (ADJP (JJ spongelike))))))) (: --) (NP (NP (JJ similar) (NNS symptoms)) (PP (TO to) (NP (NP (NP (DT the) (NN disease) (NN scrapie)) (PP (IN in) (NP (NN sheep)))) (CC and) (NP (NP (DT the) (JJ rare) (JJ Creutzfeldt-Jakob) (NN disease)) (PRN (-LRB- -LRB-) (NP (NN CJD)) (-RRB- -RRB-)) (, ,) (PP (IN in) (NP (NNS humans)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="similar symptoms to the disease scrapie in sheep and the rare Creutzfeldt-Jakob disease -LRB- CJD -RRB- , in humans" type="NP">
          <tokens>
            <token id="21" string="similar" />
            <token id="22" string="symptoms" />
            <token id="23" string="to" />
            <token id="24" string="the" />
            <token id="25" string="disease" />
            <token id="26" string="scrapie" />
            <token id="27" string="in" />
            <token id="28" string="sheep" />
            <token id="29" string="and" />
            <token id="30" string="the" />
            <token id="31" string="rare" />
            <token id="32" string="Creutzfeldt-Jakob" />
            <token id="33" string="disease" />
            <token id="34" string="(" />
            <token id="35" string="CJD" />
            <token id="36" string=")" />
            <token id="37" string="," />
            <token id="38" string="in" />
            <token id="39" string="humans" />
          </tokens>
        </chunking>
        <chunking id="2" string="become holed and spongelike" type="VP">
          <tokens>
            <token id="16" string="become" />
            <token id="17" string="holed" />
            <token id="18" string="and" />
            <token id="19" string="spongelike" />
          </tokens>
        </chunking>
        <chunking id="3" string="the rare Creutzfeldt-Jakob disease" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="rare" />
            <token id="32" string="Creutzfeldt-Jakob" />
            <token id="33" string="disease" />
          </tokens>
        </chunking>
        <chunking id="4" string="Scientists at the Central Veterinary Laboratory in Surrey" type="NP">
          <tokens>
            <token id="1" string="Scientists" />
            <token id="2" string="at" />
            <token id="3" string="the" />
            <token id="4" string="Central" />
            <token id="5" string="Veterinary" />
            <token id="6" string="Laboratory" />
            <token id="7" string="in" />
            <token id="8" string="Surrey" />
          </tokens>
        </chunking>
        <chunking id="5" string="the disease scrapie" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="disease" />
            <token id="26" string="scrapie" />
          </tokens>
        </chunking>
        <chunking id="6" string="the animals ' brains" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="animals" />
            <token id="13" string="'" />
            <token id="14" string="brains" />
          </tokens>
        </chunking>
        <chunking id="7" string="holed" type="VP">
          <tokens>
            <token id="17" string="holed" />
          </tokens>
        </chunking>
        <chunking id="8" string="the Central Veterinary Laboratory in Surrey" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="Central" />
            <token id="5" string="Veterinary" />
            <token id="6" string="Laboratory" />
            <token id="7" string="in" />
            <token id="8" string="Surrey" />
          </tokens>
        </chunking>
        <chunking id="9" string="spongelike" type="ADJP">
          <tokens>
            <token id="19" string="spongelike" />
          </tokens>
        </chunking>
        <chunking id="10" string="the animals '" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="animals" />
            <token id="13" string="'" />
          </tokens>
        </chunking>
        <chunking id="11" string="the disease scrapie in sheep" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="disease" />
            <token id="26" string="scrapie" />
            <token id="27" string="in" />
            <token id="28" string="sheep" />
          </tokens>
        </chunking>
        <chunking id="12" string="the rare Creutzfeldt-Jakob disease -LRB- CJD -RRB- , in humans" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="rare" />
            <token id="32" string="Creutzfeldt-Jakob" />
            <token id="33" string="disease" />
            <token id="34" string="(" />
            <token id="35" string="CJD" />
            <token id="36" string=")" />
            <token id="37" string="," />
            <token id="38" string="in" />
            <token id="39" string="humans" />
          </tokens>
        </chunking>
        <chunking id="13" string="had become holed and spongelike" type="VP">
          <tokens>
            <token id="15" string="had" />
            <token id="16" string="become" />
            <token id="17" string="holed" />
            <token id="18" string="and" />
            <token id="19" string="spongelike" />
          </tokens>
        </chunking>
        <chunking id="14" string="the disease scrapie in sheep and the rare Creutzfeldt-Jakob disease -LRB- CJD -RRB- , in humans" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="disease" />
            <token id="26" string="scrapie" />
            <token id="27" string="in" />
            <token id="28" string="sheep" />
            <token id="29" string="and" />
            <token id="30" string="the" />
            <token id="31" string="rare" />
            <token id="32" string="Creutzfeldt-Jakob" />
            <token id="33" string="disease" />
            <token id="34" string="(" />
            <token id="35" string="CJD" />
            <token id="36" string=")" />
            <token id="37" string="," />
            <token id="38" string="in" />
            <token id="39" string="humans" />
          </tokens>
        </chunking>
        <chunking id="15" string="similar symptoms" type="NP">
          <tokens>
            <token id="21" string="similar" />
            <token id="22" string="symptoms" />
          </tokens>
        </chunking>
        <chunking id="16" string="Scientists" type="NP">
          <tokens>
            <token id="1" string="Scientists" />
          </tokens>
        </chunking>
        <chunking id="17" string="that the animals ' brains had become holed and spongelike" type="SBAR">
          <tokens>
            <token id="10" string="that" />
            <token id="11" string="the" />
            <token id="12" string="animals" />
            <token id="13" string="'" />
            <token id="14" string="brains" />
            <token id="15" string="had" />
            <token id="16" string="become" />
            <token id="17" string="holed" />
            <token id="18" string="and" />
            <token id="19" string="spongelike" />
          </tokens>
        </chunking>
        <chunking id="18" string="found that the animals ' brains had become holed and spongelike -- similar symptoms to the disease scrapie in sheep and the rare Creutzfeldt-Jakob disease -LRB- CJD -RRB- , in humans" type="VP">
          <tokens>
            <token id="9" string="found" />
            <token id="10" string="that" />
            <token id="11" string="the" />
            <token id="12" string="animals" />
            <token id="13" string="'" />
            <token id="14" string="brains" />
            <token id="15" string="had" />
            <token id="16" string="become" />
            <token id="17" string="holed" />
            <token id="18" string="and" />
            <token id="19" string="spongelike" />
            <token id="20" string="--" />
            <token id="21" string="similar" />
            <token id="22" string="symptoms" />
            <token id="23" string="to" />
            <token id="24" string="the" />
            <token id="25" string="disease" />
            <token id="26" string="scrapie" />
            <token id="27" string="in" />
            <token id="28" string="sheep" />
            <token id="29" string="and" />
            <token id="30" string="the" />
            <token id="31" string="rare" />
            <token id="32" string="Creutzfeldt-Jakob" />
            <token id="33" string="disease" />
            <token id="34" string="(" />
            <token id="35" string="CJD" />
            <token id="36" string=")" />
            <token id="37" string="," />
            <token id="38" string="in" />
            <token id="39" string="humans" />
          </tokens>
        </chunking>
        <chunking id="19" string="the Central Veterinary Laboratory" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="Central" />
            <token id="5" string="Veterinary" />
            <token id="6" string="Laboratory" />
          </tokens>
        </chunking>
        <chunking id="20" string="Surrey" type="NP">
          <tokens>
            <token id="8" string="Surrey" />
          </tokens>
        </chunking>
        <chunking id="21" string="CJD" type="NP">
          <tokens>
            <token id="35" string="CJD" />
          </tokens>
        </chunking>
        <chunking id="22" string="humans" type="NP">
          <tokens>
            <token id="39" string="humans" />
          </tokens>
        </chunking>
        <chunking id="23" string="sheep" type="NP">
          <tokens>
            <token id="28" string="sheep" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="9">found</governor>
          <dependent id="1">Scientists</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Laboratory</governor>
          <dependent id="2">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">Laboratory</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Laboratory</governor>
          <dependent id="4">Central</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">Laboratory</governor>
          <dependent id="5">Veterinary</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Scientists</governor>
          <dependent id="6">Laboratory</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">Surrey</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">Laboratory</governor>
          <dependent id="8">Surrey</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">found</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">become</governor>
          <dependent id="10">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">animals</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">brains</governor>
          <dependent id="12">animals</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">animals</governor>
          <dependent id="13">'</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">become</governor>
          <dependent id="14">brains</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">become</governor>
          <dependent id="15">had</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">found</governor>
          <dependent id="16">become</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="16">become</governor>
          <dependent id="17">holed</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">holed</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">holed</governor>
          <dependent id="19">spongelike</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">symptoms</governor>
          <dependent id="21">similar</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">found</governor>
          <dependent id="22">symptoms</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">scrapie</governor>
          <dependent id="23">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">scrapie</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">scrapie</governor>
          <dependent id="25">disease</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">symptoms</governor>
          <dependent id="26">scrapie</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">sheep</governor>
          <dependent id="27">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">scrapie</governor>
          <dependent id="28">sheep</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="26">scrapie</governor>
          <dependent id="29">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">disease</governor>
          <dependent id="30">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="33">disease</governor>
          <dependent id="31">rare</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="33">disease</governor>
          <dependent id="32">Creutzfeldt-Jakob</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="26">scrapie</governor>
          <dependent id="33">disease</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="33">disease</governor>
          <dependent id="35">CJD</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">humans</governor>
          <dependent id="38">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">disease</governor>
          <dependent id="39">humans</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Central Veterinary Laboratory" type="LOCATION" score="0.0">
          <tokens>
            <token id="4" string="Central" />
            <token id="5" string="Veterinary" />
            <token id="6" string="Laboratory" />
          </tokens>
        </entity>
        <entity id="2" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="25" string="disease" />
          </tokens>
        </entity>
        <entity id="3" string="Creutzfeldt-Jakob" type="MISC" score="0.0">
          <tokens>
            <token id="32" string="Creutzfeldt-Jakob" />
          </tokens>
        </entity>
        <entity id="4" string="Surrey" type="LOCATION" score="0.0">
          <tokens>
            <token id="8" string="Surrey" />
          </tokens>
        </entity>
        <entity id="5" string="CJD" type="MISC" score="0.0">
          <tokens>
            <token id="35" string="CJD" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>MAFF scientists concluded that BSE had appeared in cattle given processed feed that included remains of diseased sheep.</content>
      <tokens>
        <token id="1" string="MAFF" lemma="maff" stem="maff" pos="NN" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="2" string="scientists" lemma="scientist" stem="scientist" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="concluded" lemma="conclude" stem="conclud" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="BSE" lemma="BSE" stem="bse" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="6" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="appeared" lemma="appear" stem="appear" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="cattle" lemma="cattle" stem="cattl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="given" lemma="give" stem="given" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="processed" lemma="process" stem="process" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="12" string="feed" lemma="feed" stem="feed" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="13" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="14" string="included" lemma="include" stem="includ" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="15" string="remains" lemma="remains" stem="remain" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="17" string="diseased" lemma="diseased" stem="diseas" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="18" string="sheep" lemma="sheep" stem="sheep" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NN MAFF) (NNS scientists)) (VP (VBD concluded) (SBAR (IN that) (S (NP (NNP BSE)) (VP (VBD had) (VP (VBN appeared) (PP (IN in) (NP (NP (NNS cattle)) (VP (VBN given) (NP (NP (VBN processed) (NN feed)) (SBAR (WHNP (WDT that)) (S (VP (VBD included) (NP (NP (NNS remains)) (PP (IN of) (NP (JJ diseased) (NN sheep)))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="diseased sheep" type="NP">
          <tokens>
            <token id="17" string="diseased" />
            <token id="18" string="sheep" />
          </tokens>
        </chunking>
        <chunking id="2" string="included remains of diseased sheep" type="VP">
          <tokens>
            <token id="14" string="included" />
            <token id="15" string="remains" />
            <token id="16" string="of" />
            <token id="17" string="diseased" />
            <token id="18" string="sheep" />
          </tokens>
        </chunking>
        <chunking id="3" string="that included remains of diseased sheep" type="SBAR">
          <tokens>
            <token id="13" string="that" />
            <token id="14" string="included" />
            <token id="15" string="remains" />
            <token id="16" string="of" />
            <token id="17" string="diseased" />
            <token id="18" string="sheep" />
          </tokens>
        </chunking>
        <chunking id="4" string="cattle" type="NP">
          <tokens>
            <token id="9" string="cattle" />
          </tokens>
        </chunking>
        <chunking id="5" string="processed feed" type="NP">
          <tokens>
            <token id="11" string="processed" />
            <token id="12" string="feed" />
          </tokens>
        </chunking>
        <chunking id="6" string="remains" type="NP">
          <tokens>
            <token id="15" string="remains" />
          </tokens>
        </chunking>
        <chunking id="7" string="appeared in cattle given processed feed that included remains of diseased sheep" type="VP">
          <tokens>
            <token id="7" string="appeared" />
            <token id="8" string="in" />
            <token id="9" string="cattle" />
            <token id="10" string="given" />
            <token id="11" string="processed" />
            <token id="12" string="feed" />
            <token id="13" string="that" />
            <token id="14" string="included" />
            <token id="15" string="remains" />
            <token id="16" string="of" />
            <token id="17" string="diseased" />
            <token id="18" string="sheep" />
          </tokens>
        </chunking>
        <chunking id="8" string="concluded that BSE had appeared in cattle given processed feed that included remains of diseased sheep" type="VP">
          <tokens>
            <token id="3" string="concluded" />
            <token id="4" string="that" />
            <token id="5" string="BSE" />
            <token id="6" string="had" />
            <token id="7" string="appeared" />
            <token id="8" string="in" />
            <token id="9" string="cattle" />
            <token id="10" string="given" />
            <token id="11" string="processed" />
            <token id="12" string="feed" />
            <token id="13" string="that" />
            <token id="14" string="included" />
            <token id="15" string="remains" />
            <token id="16" string="of" />
            <token id="17" string="diseased" />
            <token id="18" string="sheep" />
          </tokens>
        </chunking>
        <chunking id="9" string="BSE" type="NP">
          <tokens>
            <token id="5" string="BSE" />
          </tokens>
        </chunking>
        <chunking id="10" string="processed feed that included remains of diseased sheep" type="NP">
          <tokens>
            <token id="11" string="processed" />
            <token id="12" string="feed" />
            <token id="13" string="that" />
            <token id="14" string="included" />
            <token id="15" string="remains" />
            <token id="16" string="of" />
            <token id="17" string="diseased" />
            <token id="18" string="sheep" />
          </tokens>
        </chunking>
        <chunking id="11" string="given processed feed that included remains of diseased sheep" type="VP">
          <tokens>
            <token id="10" string="given" />
            <token id="11" string="processed" />
            <token id="12" string="feed" />
            <token id="13" string="that" />
            <token id="14" string="included" />
            <token id="15" string="remains" />
            <token id="16" string="of" />
            <token id="17" string="diseased" />
            <token id="18" string="sheep" />
          </tokens>
        </chunking>
        <chunking id="12" string="that BSE had appeared in cattle given processed feed that included remains of diseased sheep" type="SBAR">
          <tokens>
            <token id="4" string="that" />
            <token id="5" string="BSE" />
            <token id="6" string="had" />
            <token id="7" string="appeared" />
            <token id="8" string="in" />
            <token id="9" string="cattle" />
            <token id="10" string="given" />
            <token id="11" string="processed" />
            <token id="12" string="feed" />
            <token id="13" string="that" />
            <token id="14" string="included" />
            <token id="15" string="remains" />
            <token id="16" string="of" />
            <token id="17" string="diseased" />
            <token id="18" string="sheep" />
          </tokens>
        </chunking>
        <chunking id="13" string="remains of diseased sheep" type="NP">
          <tokens>
            <token id="15" string="remains" />
            <token id="16" string="of" />
            <token id="17" string="diseased" />
            <token id="18" string="sheep" />
          </tokens>
        </chunking>
        <chunking id="14" string="cattle given processed feed that included remains of diseased sheep" type="NP">
          <tokens>
            <token id="9" string="cattle" />
            <token id="10" string="given" />
            <token id="11" string="processed" />
            <token id="12" string="feed" />
            <token id="13" string="that" />
            <token id="14" string="included" />
            <token id="15" string="remains" />
            <token id="16" string="of" />
            <token id="17" string="diseased" />
            <token id="18" string="sheep" />
          </tokens>
        </chunking>
        <chunking id="15" string="MAFF scientists" type="NP">
          <tokens>
            <token id="1" string="MAFF" />
            <token id="2" string="scientists" />
          </tokens>
        </chunking>
        <chunking id="16" string="had appeared in cattle given processed feed that included remains of diseased sheep" type="VP">
          <tokens>
            <token id="6" string="had" />
            <token id="7" string="appeared" />
            <token id="8" string="in" />
            <token id="9" string="cattle" />
            <token id="10" string="given" />
            <token id="11" string="processed" />
            <token id="12" string="feed" />
            <token id="13" string="that" />
            <token id="14" string="included" />
            <token id="15" string="remains" />
            <token id="16" string="of" />
            <token id="17" string="diseased" />
            <token id="18" string="sheep" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">scientists</governor>
          <dependent id="1">MAFF</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">concluded</governor>
          <dependent id="2">scientists</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">concluded</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">appeared</governor>
          <dependent id="4">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">appeared</governor>
          <dependent id="5">BSE</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">appeared</governor>
          <dependent id="6">had</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">concluded</governor>
          <dependent id="7">appeared</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">cattle</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">appeared</governor>
          <dependent id="9">cattle</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="9">cattle</governor>
          <dependent id="10">given</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">feed</governor>
          <dependent id="11">processed</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">given</governor>
          <dependent id="12">feed</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">included</governor>
          <dependent id="13">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="12">feed</governor>
          <dependent id="14">included</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">included</governor>
          <dependent id="15">remains</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">sheep</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">sheep</governor>
          <dependent id="17">diseased</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">remains</governor>
          <dependent id="18">sheep</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="MAFF" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="1" string="MAFF" />
          </tokens>
        </entity>
        <entity id="2" string="BSE" type="MISC" score="0.0">
          <tokens>
            <token id="5" string="BSE" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>New rendering methods, reducing the temperature at which the feed was prepared, were enabling the infective agent to survive, they concluded.</content>
      <tokens>
        <token id="1" string="New" lemma="New" stem="new" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="rendering" lemma="render" stem="render" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="methods" lemma="method" stem="method" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="reducing" lemma="reduce" stem="reduc" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="temperature" lemma="temperature" stem="temperatur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="feed" lemma="feed" stem="feed" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="prepared" lemma="prepare" stem="prepar" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="enabling" lemma="enable" stem="enabl" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="infective" lemma="infective" stem="infect" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="agent" lemma="agent" stem="agent" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="survive" lemma="survive" stem="surviv" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="concluded" lemma="conclude" stem="conclud" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (NNP New)) (VP (VBG rendering) (NP (NNS methods)))) (, ,) (S (VP (VBG reducing) (NP (NP (DT the) (NN temperature)) (SBAR (WHPP (IN at) (WHNP (WDT which))) (S (NP (DT the) (NN feed)) (VP (VBD was) (VP (VBN prepared)))))))) (, ,) (VP (VBD were) (VP (VBG enabling) (NP (DT the) (JJ infective) (NN agent)) (S (VP (TO to) (VP (VB survive))))))) (, ,) (NP (PRP they)) (VP (VBD concluded)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="at which the feed was prepared" type="SBAR">
          <tokens>
            <token id="8" string="at" />
            <token id="9" string="which" />
            <token id="10" string="the" />
            <token id="11" string="feed" />
            <token id="12" string="was" />
            <token id="13" string="prepared" />
          </tokens>
        </chunking>
        <chunking id="2" string="survive" type="VP">
          <tokens>
            <token id="21" string="survive" />
          </tokens>
        </chunking>
        <chunking id="3" string="the infective agent" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="infective" />
            <token id="19" string="agent" />
          </tokens>
        </chunking>
        <chunking id="4" string="methods" type="NP">
          <tokens>
            <token id="3" string="methods" />
          </tokens>
        </chunking>
        <chunking id="5" string="to survive" type="VP">
          <tokens>
            <token id="20" string="to" />
            <token id="21" string="survive" />
          </tokens>
        </chunking>
        <chunking id="6" string="the temperature at which the feed was prepared" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="temperature" />
            <token id="8" string="at" />
            <token id="9" string="which" />
            <token id="10" string="the" />
            <token id="11" string="feed" />
            <token id="12" string="was" />
            <token id="13" string="prepared" />
          </tokens>
        </chunking>
        <chunking id="7" string="prepared" type="VP">
          <tokens>
            <token id="13" string="prepared" />
          </tokens>
        </chunking>
        <chunking id="8" string="concluded" type="VP">
          <tokens>
            <token id="24" string="concluded" />
          </tokens>
        </chunking>
        <chunking id="9" string="the feed" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="feed" />
          </tokens>
        </chunking>
        <chunking id="10" string="was prepared" type="VP">
          <tokens>
            <token id="12" string="was" />
            <token id="13" string="prepared" />
          </tokens>
        </chunking>
        <chunking id="11" string="were enabling the infective agent to survive" type="VP">
          <tokens>
            <token id="15" string="were" />
            <token id="16" string="enabling" />
            <token id="17" string="the" />
            <token id="18" string="infective" />
            <token id="19" string="agent" />
            <token id="20" string="to" />
            <token id="21" string="survive" />
          </tokens>
        </chunking>
        <chunking id="12" string="they" type="NP">
          <tokens>
            <token id="23" string="they" />
          </tokens>
        </chunking>
        <chunking id="13" string="New rendering methods" type="NP">
          <tokens>
            <token id="1" string="New" />
            <token id="2" string="rendering" />
            <token id="3" string="methods" />
          </tokens>
        </chunking>
        <chunking id="14" string="reducing the temperature at which the feed was prepared" type="VP">
          <tokens>
            <token id="5" string="reducing" />
            <token id="6" string="the" />
            <token id="7" string="temperature" />
            <token id="8" string="at" />
            <token id="9" string="which" />
            <token id="10" string="the" />
            <token id="11" string="feed" />
            <token id="12" string="was" />
            <token id="13" string="prepared" />
          </tokens>
        </chunking>
        <chunking id="15" string="rendering methods" type="VP">
          <tokens>
            <token id="2" string="rendering" />
            <token id="3" string="methods" />
          </tokens>
        </chunking>
        <chunking id="16" string="the temperature" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="temperature" />
          </tokens>
        </chunking>
        <chunking id="17" string="enabling the infective agent to survive" type="VP">
          <tokens>
            <token id="16" string="enabling" />
            <token id="17" string="the" />
            <token id="18" string="infective" />
            <token id="19" string="agent" />
            <token id="20" string="to" />
            <token id="21" string="survive" />
          </tokens>
        </chunking>
        <chunking id="18" string="New" type="NP">
          <tokens>
            <token id="1" string="New" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="16">enabling</governor>
          <dependent id="1">New</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="1">New</governor>
          <dependent id="2">rendering</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">rendering</governor>
          <dependent id="3">methods</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="16">enabling</governor>
          <dependent id="5">reducing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">temperature</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">reducing</governor>
          <dependent id="7">temperature</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">which</governor>
          <dependent id="8">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">prepared</governor>
          <dependent id="9">which</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">feed</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="13">prepared</governor>
          <dependent id="11">feed</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="13">prepared</governor>
          <dependent id="12">was</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="7">temperature</governor>
          <dependent id="13">prepared</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">enabling</governor>
          <dependent id="15">were</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="24">concluded</governor>
          <dependent id="16">enabling</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">agent</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">agent</governor>
          <dependent id="18">infective</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">enabling</governor>
          <dependent id="19">agent</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">survive</governor>
          <dependent id="20">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="16">enabling</governor>
          <dependent id="21">survive</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">concluded</governor>
          <dependent id="23">they</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="24">concluded</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="15" has_coreference="false">
      <content>Acting on this advice, in July 1988, John MacGregor, then Agriculture Minister, introduced a ban on such ruminant protein being used in feed.</content>
      <tokens>
        <token id="1" string="Acting" lemma="acting" stem="acting" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="advice" lemma="advice" stem="advic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="July" lemma="July" stem="juli" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="8" string="1988" lemma="1988" stem="1988" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="11" string="MacGregor" lemma="MacGregor" stem="macgregor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Agriculture" lemma="Agriculture" stem="agricultur" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="Minister" lemma="Minister" stem="minist" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="introduced" lemma="introduce" stem="introduc" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="ban" lemma="ban" stem="ban" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="ruminant" lemma="ruminant" stem="rumin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="protein" lemma="protein" stem="protein" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="being" lemma="be" stem="be" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="used" lemma="use" stem="us" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="feed" lemma="feed" stem="feed" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NN Acting)) (PP (IN on) (NP (DT this) (NN advice)))) (, ,) (PP (IN in) (NP (NNP July) (CD 1988))) (, ,) (NP (NP (NNP John) (NNP MacGregor)) (, ,) (RB then) (NP (NNP Agriculture) (NNP Minister)) (, ,)) (VP (VBD introduced) (NP (DT a) (NN ban)) (PP (IN on) (NP (NP (JJ such) (NN ruminant) (NN protein)) (VP (VBG being) (VP (VBN used) (PP (IN in) (NP (NN feed)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Agriculture Minister" type="NP">
          <tokens>
            <token id="14" string="Agriculture" />
            <token id="15" string="Minister" />
          </tokens>
        </chunking>
        <chunking id="2" string="such ruminant protein being used in feed" type="NP">
          <tokens>
            <token id="21" string="such" />
            <token id="22" string="ruminant" />
            <token id="23" string="protein" />
            <token id="24" string="being" />
            <token id="25" string="used" />
            <token id="26" string="in" />
            <token id="27" string="feed" />
          </tokens>
        </chunking>
        <chunking id="3" string="John MacGregor , then Agriculture Minister ," type="NP">
          <tokens>
            <token id="10" string="John" />
            <token id="11" string="MacGregor" />
            <token id="12" string="," />
            <token id="13" string="then" />
            <token id="14" string="Agriculture" />
            <token id="15" string="Minister" />
            <token id="16" string="," />
          </tokens>
        </chunking>
        <chunking id="4" string="being used in feed" type="VP">
          <tokens>
            <token id="24" string="being" />
            <token id="25" string="used" />
            <token id="26" string="in" />
            <token id="27" string="feed" />
          </tokens>
        </chunking>
        <chunking id="5" string="July 1988" type="NP">
          <tokens>
            <token id="7" string="July" />
            <token id="8" string="1988" />
          </tokens>
        </chunking>
        <chunking id="6" string="used in feed" type="VP">
          <tokens>
            <token id="25" string="used" />
            <token id="26" string="in" />
            <token id="27" string="feed" />
          </tokens>
        </chunking>
        <chunking id="7" string="a ban" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="ban" />
          </tokens>
        </chunking>
        <chunking id="8" string="this advice" type="NP">
          <tokens>
            <token id="3" string="this" />
            <token id="4" string="advice" />
          </tokens>
        </chunking>
        <chunking id="9" string="introduced a ban on such ruminant protein being used in feed" type="VP">
          <tokens>
            <token id="17" string="introduced" />
            <token id="18" string="a" />
            <token id="19" string="ban" />
            <token id="20" string="on" />
            <token id="21" string="such" />
            <token id="22" string="ruminant" />
            <token id="23" string="protein" />
            <token id="24" string="being" />
            <token id="25" string="used" />
            <token id="26" string="in" />
            <token id="27" string="feed" />
          </tokens>
        </chunking>
        <chunking id="10" string="John MacGregor" type="NP">
          <tokens>
            <token id="10" string="John" />
            <token id="11" string="MacGregor" />
          </tokens>
        </chunking>
        <chunking id="11" string="such ruminant protein" type="NP">
          <tokens>
            <token id="21" string="such" />
            <token id="22" string="ruminant" />
            <token id="23" string="protein" />
          </tokens>
        </chunking>
        <chunking id="12" string="feed" type="NP">
          <tokens>
            <token id="27" string="feed" />
          </tokens>
        </chunking>
        <chunking id="13" string="Acting on this advice" type="NP">
          <tokens>
            <token id="1" string="Acting" />
            <token id="2" string="on" />
            <token id="3" string="this" />
            <token id="4" string="advice" />
          </tokens>
        </chunking>
        <chunking id="14" string="Acting" type="NP">
          <tokens>
            <token id="1" string="Acting" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="17">introduced</governor>
          <dependent id="1">Acting</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">advice</governor>
          <dependent id="2">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">advice</governor>
          <dependent id="3">this</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Acting</governor>
          <dependent id="4">advice</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">July</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">introduced</governor>
          <dependent id="7">July</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="7">July</governor>
          <dependent id="8">1988</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">MacGregor</governor>
          <dependent id="10">John</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">introduced</governor>
          <dependent id="11">MacGregor</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">Minister</governor>
          <dependent id="13">then</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Minister</governor>
          <dependent id="14">Agriculture</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="11">MacGregor</governor>
          <dependent id="15">Minister</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">introduced</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">ban</governor>
          <dependent id="18">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">introduced</governor>
          <dependent id="19">ban</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">protein</governor>
          <dependent id="20">on</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">protein</governor>
          <dependent id="21">such</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">protein</governor>
          <dependent id="22">ruminant</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">introduced</governor>
          <dependent id="23">protein</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="25">used</governor>
          <dependent id="24">being</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="23">protein</governor>
          <dependent id="25">used</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">feed</governor>
          <dependent id="26">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">used</governor>
          <dependent id="27">feed</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="John MacGregor" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="John" />
            <token id="11" string="MacGregor" />
          </tokens>
        </entity>
        <entity id="2" string="July 1988" type="DATE" score="0.0">
          <tokens>
            <token id="7" string="July" />
            <token id="8" string="1988" />
          </tokens>
        </entity>
        <entity id="3" string="Minister" type="TITLE" score="0.0">
          <tokens>
            <token id="15" string="Minister" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>Cattle confirmed as having BSE have been put down and incinerated, with the ashes being buried.</content>
      <tokens>
        <token id="1" string="Cattle" lemma="Cattle" stem="cattl" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="confirmed" lemma="confirm" stem="confirm" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="having" lemma="have" stem="have" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="BSE" lemma="BSE" stem="bse" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="6" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="put" lemma="put" stem="put" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="down" lemma="down" stem="down" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="incinerated" lemma="incinerate" stem="inciner" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="ashes" lemma="ash" stem="ash" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="being" lemma="be" stem="be" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="buried" lemma="bury" stem="buri" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Cattle)) (VP (VP (VBD confirmed) (PP (IN as) (S (VP (VBG having) (S (NP (NNP BSE)) (VP (VBP have) (VP (VBN been) (VP (VBN put) (PRT (RP down)))))))))) (CC and) (VP (VBD incinerated)) (, ,) (PP (IN with) (NP (NP (DT the) (NNS ashes)) (VP (VBG being) (VP (VBN buried)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="confirmed as having BSE have been put down" type="VP">
          <tokens>
            <token id="2" string="confirmed" />
            <token id="3" string="as" />
            <token id="4" string="having" />
            <token id="5" string="BSE" />
            <token id="6" string="have" />
            <token id="7" string="been" />
            <token id="8" string="put" />
            <token id="9" string="down" />
          </tokens>
        </chunking>
        <chunking id="2" string="the ashes being buried" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="ashes" />
            <token id="16" string="being" />
            <token id="17" string="buried" />
          </tokens>
        </chunking>
        <chunking id="3" string="incinerated" type="VP">
          <tokens>
            <token id="11" string="incinerated" />
          </tokens>
        </chunking>
        <chunking id="4" string="buried" type="VP">
          <tokens>
            <token id="17" string="buried" />
          </tokens>
        </chunking>
        <chunking id="5" string="having BSE have been put down" type="VP">
          <tokens>
            <token id="4" string="having" />
            <token id="5" string="BSE" />
            <token id="6" string="have" />
            <token id="7" string="been" />
            <token id="8" string="put" />
            <token id="9" string="down" />
          </tokens>
        </chunking>
        <chunking id="6" string="the ashes" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="ashes" />
          </tokens>
        </chunking>
        <chunking id="7" string="being buried" type="VP">
          <tokens>
            <token id="16" string="being" />
            <token id="17" string="buried" />
          </tokens>
        </chunking>
        <chunking id="8" string="have been put down" type="VP">
          <tokens>
            <token id="6" string="have" />
            <token id="7" string="been" />
            <token id="8" string="put" />
            <token id="9" string="down" />
          </tokens>
        </chunking>
        <chunking id="9" string="been put down" type="VP">
          <tokens>
            <token id="7" string="been" />
            <token id="8" string="put" />
            <token id="9" string="down" />
          </tokens>
        </chunking>
        <chunking id="10" string="confirmed as having BSE have been put down and incinerated , with the ashes being buried" type="VP">
          <tokens>
            <token id="2" string="confirmed" />
            <token id="3" string="as" />
            <token id="4" string="having" />
            <token id="5" string="BSE" />
            <token id="6" string="have" />
            <token id="7" string="been" />
            <token id="8" string="put" />
            <token id="9" string="down" />
            <token id="10" string="and" />
            <token id="11" string="incinerated" />
            <token id="12" string="," />
            <token id="13" string="with" />
            <token id="14" string="the" />
            <token id="15" string="ashes" />
            <token id="16" string="being" />
            <token id="17" string="buried" />
          </tokens>
        </chunking>
        <chunking id="11" string="BSE" type="NP">
          <tokens>
            <token id="5" string="BSE" />
          </tokens>
        </chunking>
        <chunking id="12" string="put down" type="VP">
          <tokens>
            <token id="8" string="put" />
            <token id="9" string="down" />
          </tokens>
        </chunking>
        <chunking id="13" string="Cattle" type="NP">
          <tokens>
            <token id="1" string="Cattle" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">confirmed</governor>
          <dependent id="1">Cattle</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">confirmed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="4">having</governor>
          <dependent id="3">as</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="2">confirmed</governor>
          <dependent id="4">having</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="8">put</governor>
          <dependent id="5">BSE</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">put</governor>
          <dependent id="6">have</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="8">put</governor>
          <dependent id="7">been</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">having</governor>
          <dependent id="8">put</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="8">put</governor>
          <dependent id="9">down</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">confirmed</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">confirmed</governor>
          <dependent id="11">incinerated</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">ashes</governor>
          <dependent id="13">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">ashes</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">confirmed</governor>
          <dependent id="15">ashes</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="17">buried</governor>
          <dependent id="16">being</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="15">ashes</governor>
          <dependent id="17">buried</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="BSE" type="MISC" score="0.0">
          <tokens>
            <token id="5" string="BSE" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="false">
      <content>In 1989 a further ban was introduced, on cattle offal sold for human consumption.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="1989" lemma="1989" stem="1989" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="further" lemma="further" stem="further" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="ban" lemma="ban" stem="ban" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="introduced" lemma="introduce" stem="introduc" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="cattle" lemma="cattle" stem="cattl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="offal" lemma="offal" stem="offal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="sold" lemma="sell" stem="sold" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="human" lemma="human" stem="human" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="consumption" lemma="consumption" stem="consumpt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (CD 1989))) (NP (DT a) (JJ further) (NN ban)) (VP (VBD was) (VP (VBN introduced) (, ,) (PP (IN on) (NP (NP (NNS cattle) (NN offal)) (VP (VBN sold) (PP (IN for) (NP (JJ human) (NN consumption)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a further ban" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="further" />
            <token id="5" string="ban" />
          </tokens>
        </chunking>
        <chunking id="2" string="was introduced , on cattle offal sold for human consumption" type="VP">
          <tokens>
            <token id="6" string="was" />
            <token id="7" string="introduced" />
            <token id="8" string="," />
            <token id="9" string="on" />
            <token id="10" string="cattle" />
            <token id="11" string="offal" />
            <token id="12" string="sold" />
            <token id="13" string="for" />
            <token id="14" string="human" />
            <token id="15" string="consumption" />
          </tokens>
        </chunking>
        <chunking id="3" string="human consumption" type="NP">
          <tokens>
            <token id="14" string="human" />
            <token id="15" string="consumption" />
          </tokens>
        </chunking>
        <chunking id="4" string="sold for human consumption" type="VP">
          <tokens>
            <token id="12" string="sold" />
            <token id="13" string="for" />
            <token id="14" string="human" />
            <token id="15" string="consumption" />
          </tokens>
        </chunking>
        <chunking id="5" string="introduced , on cattle offal sold for human consumption" type="VP">
          <tokens>
            <token id="7" string="introduced" />
            <token id="8" string="," />
            <token id="9" string="on" />
            <token id="10" string="cattle" />
            <token id="11" string="offal" />
            <token id="12" string="sold" />
            <token id="13" string="for" />
            <token id="14" string="human" />
            <token id="15" string="consumption" />
          </tokens>
        </chunking>
        <chunking id="6" string="cattle offal sold for human consumption" type="NP">
          <tokens>
            <token id="10" string="cattle" />
            <token id="11" string="offal" />
            <token id="12" string="sold" />
            <token id="13" string="for" />
            <token id="14" string="human" />
            <token id="15" string="consumption" />
          </tokens>
        </chunking>
        <chunking id="7" string="1989" type="NP">
          <tokens>
            <token id="2" string="1989" />
          </tokens>
        </chunking>
        <chunking id="8" string="cattle offal" type="NP">
          <tokens>
            <token id="10" string="cattle" />
            <token id="11" string="offal" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">1989</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">introduced</governor>
          <dependent id="2">1989</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">ban</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">ban</governor>
          <dependent id="4">further</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="7">introduced</governor>
          <dependent id="5">ban</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="7">introduced</governor>
          <dependent id="6">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">introduced</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">offal</governor>
          <dependent id="9">on</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">offal</governor>
          <dependent id="10">cattle</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">introduced</governor>
          <dependent id="11">offal</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="11">offal</governor>
          <dependent id="12">sold</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">consumption</governor>
          <dependent id="13">for</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">consumption</governor>
          <dependent id="14">human</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">sold</governor>
          <dependent id="15">consumption</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1989" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="1989" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>That year it was officially predicted that 20,000 animals would be affected before the feed ban, together with the drying up of any supplies already on farms, had its effect.</content>
      <tokens>
        <token id="1" string="That" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="3" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="officially" lemma="officially" stem="offici" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="predicted" lemma="predict" stem="predict" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="20,000" lemma="20,000" stem="20,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="9" string="animals" lemma="animal" stem="anim" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="affected" lemma="affect" stem="affect" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="feed" lemma="feed" stem="feed" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="ban" lemma="ban" stem="ban" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="together" lemma="together" stem="togeth" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="drying" lemma="dry" stem="dry" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="up" lemma="up" stem="up" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="supplies" lemma="supplies" stem="suppli" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="already" lemma="already" stem="alreadi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="farms" lemma="farm" stem="farm" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="effect" lemma="effect" stem="effect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT That) (NN year)) (PRN (S (NP (PRP it)) (VP (VBD was) (ADVP (RB officially)) (VP (VBN predicted) (SBAR (IN that) (S (NP (CD 20,000) (NNS animals)) (VP (MD would) (VP (VB be) (VP (VBN affected) (PP (IN before) (NP (DT the) (NN feed) (NN ban))) (, ,) (ADVP (RB together)) (PP (IN with) (NP (NP (DT the)) (VP (VBG drying) (ADVP (RB up) (PP (IN of) (NP (DT any) (NNS supplies)) (ADVP (RB already)))) (PP (IN on) (NP (NNS farms)))))))))))))) (, ,)) (VP (VBD had) (NP (PRP$ its) (NN effect))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="20,000 animals" type="NP">
          <tokens>
            <token id="8" string="20,000" />
            <token id="9" string="animals" />
          </tokens>
        </chunking>
        <chunking id="2" string="it" type="NP">
          <tokens>
            <token id="3" string="it" />
          </tokens>
        </chunking>
        <chunking id="3" string="would be affected before the feed ban , together with the drying up of any supplies already on farms" type="VP">
          <tokens>
            <token id="10" string="would" />
            <token id="11" string="be" />
            <token id="12" string="affected" />
            <token id="13" string="before" />
            <token id="14" string="the" />
            <token id="15" string="feed" />
            <token id="16" string="ban" />
            <token id="17" string="," />
            <token id="18" string="together" />
            <token id="19" string="with" />
            <token id="20" string="the" />
            <token id="21" string="drying" />
            <token id="22" string="up" />
            <token id="23" string="of" />
            <token id="24" string="any" />
            <token id="25" string="supplies" />
            <token id="26" string="already" />
            <token id="27" string="on" />
            <token id="28" string="farms" />
          </tokens>
        </chunking>
        <chunking id="4" string="was officially predicted that 20,000 animals would be affected before the feed ban , together with the drying up of any supplies already on farms" type="VP">
          <tokens>
            <token id="4" string="was" />
            <token id="5" string="officially" />
            <token id="6" string="predicted" />
            <token id="7" string="that" />
            <token id="8" string="20,000" />
            <token id="9" string="animals" />
            <token id="10" string="would" />
            <token id="11" string="be" />
            <token id="12" string="affected" />
            <token id="13" string="before" />
            <token id="14" string="the" />
            <token id="15" string="feed" />
            <token id="16" string="ban" />
            <token id="17" string="," />
            <token id="18" string="together" />
            <token id="19" string="with" />
            <token id="20" string="the" />
            <token id="21" string="drying" />
            <token id="22" string="up" />
            <token id="23" string="of" />
            <token id="24" string="any" />
            <token id="25" string="supplies" />
            <token id="26" string="already" />
            <token id="27" string="on" />
            <token id="28" string="farms" />
          </tokens>
        </chunking>
        <chunking id="5" string="predicted that 20,000 animals would be affected before the feed ban , together with the drying up of any supplies already on farms" type="VP">
          <tokens>
            <token id="6" string="predicted" />
            <token id="7" string="that" />
            <token id="8" string="20,000" />
            <token id="9" string="animals" />
            <token id="10" string="would" />
            <token id="11" string="be" />
            <token id="12" string="affected" />
            <token id="13" string="before" />
            <token id="14" string="the" />
            <token id="15" string="feed" />
            <token id="16" string="ban" />
            <token id="17" string="," />
            <token id="18" string="together" />
            <token id="19" string="with" />
            <token id="20" string="the" />
            <token id="21" string="drying" />
            <token id="22" string="up" />
            <token id="23" string="of" />
            <token id="24" string="any" />
            <token id="25" string="supplies" />
            <token id="26" string="already" />
            <token id="27" string="on" />
            <token id="28" string="farms" />
          </tokens>
        </chunking>
        <chunking id="6" string="be affected before the feed ban , together with the drying up of any supplies already on farms" type="VP">
          <tokens>
            <token id="11" string="be" />
            <token id="12" string="affected" />
            <token id="13" string="before" />
            <token id="14" string="the" />
            <token id="15" string="feed" />
            <token id="16" string="ban" />
            <token id="17" string="," />
            <token id="18" string="together" />
            <token id="19" string="with" />
            <token id="20" string="the" />
            <token id="21" string="drying" />
            <token id="22" string="up" />
            <token id="23" string="of" />
            <token id="24" string="any" />
            <token id="25" string="supplies" />
            <token id="26" string="already" />
            <token id="27" string="on" />
            <token id="28" string="farms" />
          </tokens>
        </chunking>
        <chunking id="7" string="had its effect" type="VP">
          <tokens>
            <token id="30" string="had" />
            <token id="31" string="its" />
            <token id="32" string="effect" />
          </tokens>
        </chunking>
        <chunking id="8" string="That year" type="NP">
          <tokens>
            <token id="1" string="That" />
            <token id="2" string="year" />
          </tokens>
        </chunking>
        <chunking id="9" string="that 20,000 animals would be affected before the feed ban , together with the drying up of any supplies already on farms" type="SBAR">
          <tokens>
            <token id="7" string="that" />
            <token id="8" string="20,000" />
            <token id="9" string="animals" />
            <token id="10" string="would" />
            <token id="11" string="be" />
            <token id="12" string="affected" />
            <token id="13" string="before" />
            <token id="14" string="the" />
            <token id="15" string="feed" />
            <token id="16" string="ban" />
            <token id="17" string="," />
            <token id="18" string="together" />
            <token id="19" string="with" />
            <token id="20" string="the" />
            <token id="21" string="drying" />
            <token id="22" string="up" />
            <token id="23" string="of" />
            <token id="24" string="any" />
            <token id="25" string="supplies" />
            <token id="26" string="already" />
            <token id="27" string="on" />
            <token id="28" string="farms" />
          </tokens>
        </chunking>
        <chunking id="10" string="affected before the feed ban , together with the drying up of any supplies already on farms" type="VP">
          <tokens>
            <token id="12" string="affected" />
            <token id="13" string="before" />
            <token id="14" string="the" />
            <token id="15" string="feed" />
            <token id="16" string="ban" />
            <token id="17" string="," />
            <token id="18" string="together" />
            <token id="19" string="with" />
            <token id="20" string="the" />
            <token id="21" string="drying" />
            <token id="22" string="up" />
            <token id="23" string="of" />
            <token id="24" string="any" />
            <token id="25" string="supplies" />
            <token id="26" string="already" />
            <token id="27" string="on" />
            <token id="28" string="farms" />
          </tokens>
        </chunking>
        <chunking id="11" string="the" type="NP">
          <tokens>
            <token id="20" string="the" />
          </tokens>
        </chunking>
        <chunking id="12" string="any supplies" type="NP">
          <tokens>
            <token id="24" string="any" />
            <token id="25" string="supplies" />
          </tokens>
        </chunking>
        <chunking id="13" string="the drying up of any supplies already on farms" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="drying" />
            <token id="22" string="up" />
            <token id="23" string="of" />
            <token id="24" string="any" />
            <token id="25" string="supplies" />
            <token id="26" string="already" />
            <token id="27" string="on" />
            <token id="28" string="farms" />
          </tokens>
        </chunking>
        <chunking id="14" string="drying up of any supplies already on farms" type="VP">
          <tokens>
            <token id="21" string="drying" />
            <token id="22" string="up" />
            <token id="23" string="of" />
            <token id="24" string="any" />
            <token id="25" string="supplies" />
            <token id="26" string="already" />
            <token id="27" string="on" />
            <token id="28" string="farms" />
          </tokens>
        </chunking>
        <chunking id="15" string="farms" type="NP">
          <tokens>
            <token id="28" string="farms" />
          </tokens>
        </chunking>
        <chunking id="16" string="the feed ban" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="feed" />
            <token id="16" string="ban" />
          </tokens>
        </chunking>
        <chunking id="17" string="its effect" type="NP">
          <tokens>
            <token id="31" string="its" />
            <token id="32" string="effect" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">year</governor>
          <dependent id="1">That</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="30">had</governor>
          <dependent id="2">year</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="6">predicted</governor>
          <dependent id="3">it</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">predicted</governor>
          <dependent id="4">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">predicted</governor>
          <dependent id="5">officially</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="30">had</governor>
          <dependent id="6">predicted</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">affected</governor>
          <dependent id="7">that</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="9">animals</governor>
          <dependent id="8">20,000</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="12">affected</governor>
          <dependent id="9">animals</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">affected</governor>
          <dependent id="10">would</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="12">affected</governor>
          <dependent id="11">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">predicted</governor>
          <dependent id="12">affected</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">ban</governor>
          <dependent id="13">before</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">ban</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">ban</governor>
          <dependent id="15">feed</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">affected</governor>
          <dependent id="16">ban</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">the</governor>
          <dependent id="18">together</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="18">together</governor>
          <dependent id="19">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">affected</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="20">the</governor>
          <dependent id="21">drying</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="21">drying</governor>
          <dependent id="22">up</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">supplies</governor>
          <dependent id="23">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">supplies</governor>
          <dependent id="24">any</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">up</governor>
          <dependent id="25">supplies</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="25">supplies</governor>
          <dependent id="26">already</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">farms</governor>
          <dependent id="27">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">drying</governor>
          <dependent id="28">farms</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="30">had</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="32">effect</governor>
          <dependent id="31">its</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="30">had</governor>
          <dependent id="32">effect</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="year" type="DURATION" score="0.0">
          <tokens>
            <token id="2" string="year" />
          </tokens>
        </entity>
        <entity id="2" string="20,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="8" string="20,000" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="false">
      <content>But the spread of BSE has confounded original expectations.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="spread" lemma="spread" stem="spread" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="BSE" lemma="BSE" stem="bse" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="6" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="confounded" lemma="confound" stem="confound" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="original" lemma="original" stem="origin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="expectations" lemma="expectation" stem="expect" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (NP (DT the) (NN spread)) (PP (IN of) (NP (NNP BSE)))) (VP (VBZ has) (VP (VBN confounded) (NP (JJ original) (NNS expectations)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="confounded original expectations" type="VP">
          <tokens>
            <token id="7" string="confounded" />
            <token id="8" string="original" />
            <token id="9" string="expectations" />
          </tokens>
        </chunking>
        <chunking id="2" string="BSE" type="NP">
          <tokens>
            <token id="5" string="BSE" />
          </tokens>
        </chunking>
        <chunking id="3" string="the spread of BSE" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="spread" />
            <token id="4" string="of" />
            <token id="5" string="BSE" />
          </tokens>
        </chunking>
        <chunking id="4" string="original expectations" type="NP">
          <tokens>
            <token id="8" string="original" />
            <token id="9" string="expectations" />
          </tokens>
        </chunking>
        <chunking id="5" string="has confounded original expectations" type="VP">
          <tokens>
            <token id="6" string="has" />
            <token id="7" string="confounded" />
            <token id="8" string="original" />
            <token id="9" string="expectations" />
          </tokens>
        </chunking>
        <chunking id="6" string="the spread" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="spread" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="7">confounded</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">spread</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">confounded</governor>
          <dependent id="3">spread</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">BSE</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">spread</governor>
          <dependent id="5">BSE</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">confounded</governor>
          <dependent id="6">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">confounded</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">expectations</governor>
          <dependent id="8">original</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">confounded</governor>
          <dependent id="9">expectations</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="BSE" type="MISC" score="0.0">
          <tokens>
            <token id="5" string="BSE" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>The Ministry of Agriculture said yesterday that by the beginning of last week the total number of cattle diagnosed since November 1986 as having BSE had risen to 121,898 -- six times the original prediction.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="Ministry" lemma="Ministry" stem="ministri" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="4" string="Agriculture" lemma="Agriculture" stem="agricultur" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="5" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="yesterday" lemma="yesterday" stem="yesterdai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="7" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="10" string="beginning" lemma="beginning" stem="begin" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="12" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="13" string="week" lemma="week" stem="week" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="total" lemma="total" stem="total" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="number" lemma="number" stem="number" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="cattle" lemma="cattle" stem="cattl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="diagnosed" lemma="diagnose" stem="diagnos" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="November" lemma="November" stem="novemb" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="22" string="1986" lemma="1986" stem="1986" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="23" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="having" lemma="have" stem="have" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="BSE" lemma="BSE" stem="bse" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="26" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="risen" lemma="rise" stem="risen" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="121,898" lemma="121,898" stem="121,898" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="30" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="six" lemma="six" stem="six" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="32" string="times" lemma="time" stem="time" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="original" lemma="original" stem="origin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="prediction" lemma="prediction" stem="predict" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NNP Ministry)) (PP (IN of) (NP (NNP Agriculture)))) (VP (VBD said) (NP-TMP (NN yesterday)) (SBAR (IN that) (S (PP (IN by) (NP (NP (DT the) (NN beginning)) (PP (IN of) (NP (JJ last) (NN week))))) (NP (NP (DT the) (JJ total) (NN number)) (PP (IN of) (NP (NNS cattle)))) (VP (VBD diagnosed) (PP (IN since) (NP (NNP November) (CD 1986))) (PP (IN as) (S (VP (VBG having) (S (NP (NNP BSE)) (VP (VBD had) (VP (VBN risen) (PP (TO to) (NP (NP (CD 121,898)) (: --) (NP (NP (QP (CD six) (NNS times))) (NP (DT the) (JJ original) (NN prediction))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="having BSE had risen to 121,898 -- six times the original prediction" type="VP">
          <tokens>
            <token id="24" string="having" />
            <token id="25" string="BSE" />
            <token id="26" string="had" />
            <token id="27" string="risen" />
            <token id="28" string="to" />
            <token id="29" string="121,898" />
            <token id="30" string="--" />
            <token id="31" string="six" />
            <token id="32" string="times" />
            <token id="33" string="the" />
            <token id="34" string="original" />
            <token id="35" string="prediction" />
          </tokens>
        </chunking>
        <chunking id="2" string="the beginning" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="beginning" />
          </tokens>
        </chunking>
        <chunking id="3" string="the total number of cattle" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="total" />
            <token id="16" string="number" />
            <token id="17" string="of" />
            <token id="18" string="cattle" />
          </tokens>
        </chunking>
        <chunking id="4" string="the total number" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="total" />
            <token id="16" string="number" />
          </tokens>
        </chunking>
        <chunking id="5" string="the original prediction" type="NP">
          <tokens>
            <token id="33" string="the" />
            <token id="34" string="original" />
            <token id="35" string="prediction" />
          </tokens>
        </chunking>
        <chunking id="6" string="cattle" type="NP">
          <tokens>
            <token id="18" string="cattle" />
          </tokens>
        </chunking>
        <chunking id="7" string="The Ministry of Agriculture" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Ministry" />
            <token id="3" string="of" />
            <token id="4" string="Agriculture" />
          </tokens>
        </chunking>
        <chunking id="8" string="the beginning of last week" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="beginning" />
            <token id="11" string="of" />
            <token id="12" string="last" />
            <token id="13" string="week" />
          </tokens>
        </chunking>
        <chunking id="9" string="121,898" type="NP">
          <tokens>
            <token id="29" string="121,898" />
          </tokens>
        </chunking>
        <chunking id="10" string="diagnosed since November 1986 as having BSE had risen to 121,898 -- six times the original prediction" type="VP">
          <tokens>
            <token id="19" string="diagnosed" />
            <token id="20" string="since" />
            <token id="21" string="November" />
            <token id="22" string="1986" />
            <token id="23" string="as" />
            <token id="24" string="having" />
            <token id="25" string="BSE" />
            <token id="26" string="had" />
            <token id="27" string="risen" />
            <token id="28" string="to" />
            <token id="29" string="121,898" />
            <token id="30" string="--" />
            <token id="31" string="six" />
            <token id="32" string="times" />
            <token id="33" string="the" />
            <token id="34" string="original" />
            <token id="35" string="prediction" />
          </tokens>
        </chunking>
        <chunking id="11" string="BSE" type="NP">
          <tokens>
            <token id="25" string="BSE" />
          </tokens>
        </chunking>
        <chunking id="12" string="six times" type="NP">
          <tokens>
            <token id="31" string="six" />
            <token id="32" string="times" />
          </tokens>
        </chunking>
        <chunking id="13" string="121,898 -- six times the original prediction" type="NP">
          <tokens>
            <token id="29" string="121,898" />
            <token id="30" string="--" />
            <token id="31" string="six" />
            <token id="32" string="times" />
            <token id="33" string="the" />
            <token id="34" string="original" />
            <token id="35" string="prediction" />
          </tokens>
        </chunking>
        <chunking id="14" string="November 1986" type="NP">
          <tokens>
            <token id="21" string="November" />
            <token id="22" string="1986" />
          </tokens>
        </chunking>
        <chunking id="15" string="last week" type="NP">
          <tokens>
            <token id="12" string="last" />
            <token id="13" string="week" />
          </tokens>
        </chunking>
        <chunking id="16" string="risen to 121,898 -- six times the original prediction" type="VP">
          <tokens>
            <token id="27" string="risen" />
            <token id="28" string="to" />
            <token id="29" string="121,898" />
            <token id="30" string="--" />
            <token id="31" string="six" />
            <token id="32" string="times" />
            <token id="33" string="the" />
            <token id="34" string="original" />
            <token id="35" string="prediction" />
          </tokens>
        </chunking>
        <chunking id="17" string="six times the original prediction" type="NP">
          <tokens>
            <token id="31" string="six" />
            <token id="32" string="times" />
            <token id="33" string="the" />
            <token id="34" string="original" />
            <token id="35" string="prediction" />
          </tokens>
        </chunking>
        <chunking id="18" string="The Ministry" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Ministry" />
          </tokens>
        </chunking>
        <chunking id="19" string="that by the beginning of last week the total number of cattle diagnosed since November 1986 as having BSE had risen to 121,898 -- six times the original prediction" type="SBAR">
          <tokens>
            <token id="7" string="that" />
            <token id="8" string="by" />
            <token id="9" string="the" />
            <token id="10" string="beginning" />
            <token id="11" string="of" />
            <token id="12" string="last" />
            <token id="13" string="week" />
            <token id="14" string="the" />
            <token id="15" string="total" />
            <token id="16" string="number" />
            <token id="17" string="of" />
            <token id="18" string="cattle" />
            <token id="19" string="diagnosed" />
            <token id="20" string="since" />
            <token id="21" string="November" />
            <token id="22" string="1986" />
            <token id="23" string="as" />
            <token id="24" string="having" />
            <token id="25" string="BSE" />
            <token id="26" string="had" />
            <token id="27" string="risen" />
            <token id="28" string="to" />
            <token id="29" string="121,898" />
            <token id="30" string="--" />
            <token id="31" string="six" />
            <token id="32" string="times" />
            <token id="33" string="the" />
            <token id="34" string="original" />
            <token id="35" string="prediction" />
          </tokens>
        </chunking>
        <chunking id="20" string="Agriculture" type="NP">
          <tokens>
            <token id="4" string="Agriculture" />
          </tokens>
        </chunking>
        <chunking id="21" string="said yesterday that by the beginning of last week the total number of cattle diagnosed since November 1986 as having BSE had risen to 121,898 -- six times the original prediction" type="VP">
          <tokens>
            <token id="5" string="said" />
            <token id="6" string="yesterday" />
            <token id="7" string="that" />
            <token id="8" string="by" />
            <token id="9" string="the" />
            <token id="10" string="beginning" />
            <token id="11" string="of" />
            <token id="12" string="last" />
            <token id="13" string="week" />
            <token id="14" string="the" />
            <token id="15" string="total" />
            <token id="16" string="number" />
            <token id="17" string="of" />
            <token id="18" string="cattle" />
            <token id="19" string="diagnosed" />
            <token id="20" string="since" />
            <token id="21" string="November" />
            <token id="22" string="1986" />
            <token id="23" string="as" />
            <token id="24" string="having" />
            <token id="25" string="BSE" />
            <token id="26" string="had" />
            <token id="27" string="risen" />
            <token id="28" string="to" />
            <token id="29" string="121,898" />
            <token id="30" string="--" />
            <token id="31" string="six" />
            <token id="32" string="times" />
            <token id="33" string="the" />
            <token id="34" string="original" />
            <token id="35" string="prediction" />
          </tokens>
        </chunking>
        <chunking id="22" string="had risen to 121,898 -- six times the original prediction" type="VP">
          <tokens>
            <token id="26" string="had" />
            <token id="27" string="risen" />
            <token id="28" string="to" />
            <token id="29" string="121,898" />
            <token id="30" string="--" />
            <token id="31" string="six" />
            <token id="32" string="times" />
            <token id="33" string="the" />
            <token id="34" string="original" />
            <token id="35" string="prediction" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">Ministry</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">said</governor>
          <dependent id="2">Ministry</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">Agriculture</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">Ministry</governor>
          <dependent id="4">Agriculture</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">said</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="5">said</governor>
          <dependent id="6">yesterday</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">diagnosed</governor>
          <dependent id="7">that</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">beginning</governor>
          <dependent id="8">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">beginning</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">diagnosed</governor>
          <dependent id="10">beginning</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">week</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">week</governor>
          <dependent id="12">last</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">beginning</governor>
          <dependent id="13">week</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">number</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">number</governor>
          <dependent id="15">total</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">diagnosed</governor>
          <dependent id="16">number</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">cattle</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">number</governor>
          <dependent id="18">cattle</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">said</governor>
          <dependent id="19">diagnosed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">November</governor>
          <dependent id="20">since</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">diagnosed</governor>
          <dependent id="21">November</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="21">November</governor>
          <dependent id="22">1986</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">having</governor>
          <dependent id="23">as</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="19">diagnosed</governor>
          <dependent id="24">having</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">risen</governor>
          <dependent id="25">BSE</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="27">risen</governor>
          <dependent id="26">had</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="24">having</governor>
          <dependent id="27">risen</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">121,898</governor>
          <dependent id="28">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">risen</governor>
          <dependent id="29">121,898</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="32">times</governor>
          <dependent id="31">six</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="29">121,898</governor>
          <dependent id="32">times</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">prediction</governor>
          <dependent id="33">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="35">prediction</governor>
          <dependent id="34">original</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="32">times</governor>
          <dependent id="35">prediction</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="the beginning of last week" type="DATE" score="0.0">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="beginning" />
            <token id="11" string="of" />
            <token id="12" string="last" />
            <token id="13" string="week" />
          </tokens>
        </entity>
        <entity id="2" string="121,898" type="NUMBER" score="0.0">
          <tokens>
            <token id="29" string="121,898" />
          </tokens>
        </entity>
        <entity id="3" string="six" type="NUMBER" score="0.0">
          <tokens>
            <token id="31" string="six" />
          </tokens>
        </entity>
        <entity id="4" string="BSE" type="MISC" score="0.0">
          <tokens>
            <token id="25" string="BSE" />
          </tokens>
        </entity>
        <entity id="5" string="yesterday" type="DATE" score="0.0">
          <tokens>
            <token id="6" string="yesterday" />
          </tokens>
        </entity>
        <entity id="6" string="November 1986" type="DATE" score="0.0">
          <tokens>
            <token id="21" string="November" />
            <token id="22" string="1986" />
          </tokens>
        </entity>
        <entity id="7" string="Ministry of Agriculture" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="2" string="Ministry" />
            <token id="3" string="of" />
            <token id="4" string="Agriculture" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>The ministry believes that the reason more cattle have died is that farmers or food renderers kept using infected feed after the ban.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="ministry" lemma="ministry" stem="ministri" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="believes" lemma="believe" stem="believ" pos="VBZ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="reason" lemma="reason" stem="reason" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="cattle" lemma="cattle" stem="cattl" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="died" lemma="die" stem="di" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="farmers" lemma="farmer" stem="farmer" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="food" lemma="food" stem="food" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="renderers" lemma="renderer" stem="render" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="kept" lemma="keep" stem="kept" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="using" lemma="use" stem="us" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="infected" lemma="infected" stem="infect" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="feed" lemma="feed" stem="feed" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="ban" lemma="ban" stem="ban" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NN ministry)) (SBAR (S (VP (VBZ believes) (SBAR (IN that) (S (NP (ADVP (NP (DT the) (NN reason)) (RBR more)) (NNS cattle)) (VP (VBP have) (VP (VBN died))))))))) (VP (VBZ is) (SBAR (IN that) (S (NP (NNS farmers) (CC or) (NN food) (NNS renderers)) (VP (VBD kept) (S (VP (VBG using) (NP (JJ infected) (NN feed)) (PP (IN after) (NP (DT the) (NN ban))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="using infected feed after the ban" type="VP">
          <tokens>
            <token id="18" string="using" />
            <token id="19" string="infected" />
            <token id="20" string="feed" />
            <token id="21" string="after" />
            <token id="22" string="the" />
            <token id="23" string="ban" />
          </tokens>
        </chunking>
        <chunking id="2" string="that farmers or food renderers kept using infected feed after the ban" type="SBAR">
          <tokens>
            <token id="12" string="that" />
            <token id="13" string="farmers" />
            <token id="14" string="or" />
            <token id="15" string="food" />
            <token id="16" string="renderers" />
            <token id="17" string="kept" />
            <token id="18" string="using" />
            <token id="19" string="infected" />
            <token id="20" string="feed" />
            <token id="21" string="after" />
            <token id="22" string="the" />
            <token id="23" string="ban" />
          </tokens>
        </chunking>
        <chunking id="3" string="believes that the reason more cattle have died" type="SBAR">
          <tokens>
            <token id="3" string="believes" />
            <token id="4" string="that" />
            <token id="5" string="the" />
            <token id="6" string="reason" />
            <token id="7" string="more" />
            <token id="8" string="cattle" />
            <token id="9" string="have" />
            <token id="10" string="died" />
          </tokens>
        </chunking>
        <chunking id="4" string="the reason" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="reason" />
          </tokens>
        </chunking>
        <chunking id="5" string="died" type="VP">
          <tokens>
            <token id="10" string="died" />
          </tokens>
        </chunking>
        <chunking id="6" string="farmers or food renderers" type="NP">
          <tokens>
            <token id="13" string="farmers" />
            <token id="14" string="or" />
            <token id="15" string="food" />
            <token id="16" string="renderers" />
          </tokens>
        </chunking>
        <chunking id="7" string="The ministry believes that the reason more cattle have died" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="ministry" />
            <token id="3" string="believes" />
            <token id="4" string="that" />
            <token id="5" string="the" />
            <token id="6" string="reason" />
            <token id="7" string="more" />
            <token id="8" string="cattle" />
            <token id="9" string="have" />
            <token id="10" string="died" />
          </tokens>
        </chunking>
        <chunking id="8" string="have died" type="VP">
          <tokens>
            <token id="9" string="have" />
            <token id="10" string="died" />
          </tokens>
        </chunking>
        <chunking id="9" string="the ban" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="ban" />
          </tokens>
        </chunking>
        <chunking id="10" string="The ministry" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="ministry" />
          </tokens>
        </chunking>
        <chunking id="11" string="is that farmers or food renderers kept using infected feed after the ban" type="VP">
          <tokens>
            <token id="11" string="is" />
            <token id="12" string="that" />
            <token id="13" string="farmers" />
            <token id="14" string="or" />
            <token id="15" string="food" />
            <token id="16" string="renderers" />
            <token id="17" string="kept" />
            <token id="18" string="using" />
            <token id="19" string="infected" />
            <token id="20" string="feed" />
            <token id="21" string="after" />
            <token id="22" string="the" />
            <token id="23" string="ban" />
          </tokens>
        </chunking>
        <chunking id="12" string="kept using infected feed after the ban" type="VP">
          <tokens>
            <token id="17" string="kept" />
            <token id="18" string="using" />
            <token id="19" string="infected" />
            <token id="20" string="feed" />
            <token id="21" string="after" />
            <token id="22" string="the" />
            <token id="23" string="ban" />
          </tokens>
        </chunking>
        <chunking id="13" string="that the reason more cattle have died" type="SBAR">
          <tokens>
            <token id="4" string="that" />
            <token id="5" string="the" />
            <token id="6" string="reason" />
            <token id="7" string="more" />
            <token id="8" string="cattle" />
            <token id="9" string="have" />
            <token id="10" string="died" />
          </tokens>
        </chunking>
        <chunking id="14" string="infected feed" type="NP">
          <tokens>
            <token id="19" string="infected" />
            <token id="20" string="feed" />
          </tokens>
        </chunking>
        <chunking id="15" string="the reason more cattle" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="reason" />
            <token id="7" string="more" />
            <token id="8" string="cattle" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">ministry</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">is</governor>
          <dependent id="2">ministry</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="2">ministry</governor>
          <dependent id="3">believes</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">died</governor>
          <dependent id="4">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">reason</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="7">more</governor>
          <dependent id="6">reason</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">cattle</governor>
          <dependent id="7">more</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">died</governor>
          <dependent id="8">cattle</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">died</governor>
          <dependent id="9">have</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">believes</governor>
          <dependent id="10">died</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">is</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">kept</governor>
          <dependent id="12">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">kept</governor>
          <dependent id="13">farmers</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">farmers</governor>
          <dependent id="14">or</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">renderers</governor>
          <dependent id="15">food</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">farmers</governor>
          <dependent id="16">renderers</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">is</governor>
          <dependent id="17">kept</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="17">kept</governor>
          <dependent id="18">using</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">feed</governor>
          <dependent id="19">infected</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">using</governor>
          <dependent id="20">feed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">ban</governor>
          <dependent id="21">after</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">ban</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">using</governor>
          <dependent id="23">ban</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>Last week, MAFF said that the numbers of confirmed BSE cases in the first two months of this year showed a 20 per cent drop over the same period in 1993 -- proof, the ministry says, that the epidemic is waning.</content>
      <tokens>
        <token id="1" string="Last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="2" string="week" lemma="week" stem="week" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="MAFF" lemma="MAFF" stem="maff" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="5" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="numbers" lemma="number" stem="number" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="confirmed" lemma="confirm" stem="confirm" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="BSE" lemma="bse" stem="bse" pos="NN" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="12" string="cases" lemma="case" stem="case" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="15" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="16" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="17" string="months" lemma="month" stem="month" pos="NNS" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="18" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="19" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="20" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="21" string="showed" lemma="show" stem="show" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="20" lemma="20" stem="20" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="24" string="per" lemma="per" stem="per" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="cent" lemma="cent" stem="cent" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="drop" lemma="drop" stem="drop" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="same" lemma="same" stem="same" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="period" lemma="period" stem="period" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="1993" lemma="1993" stem="1993" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="33" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="proof" lemma="proof" stem="proof" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="37" string="ministry" lemma="ministry" stem="ministri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="38" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="42" string="epidemic" lemma="epidemic" stem="epidem" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="43" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="waning" lemma="wane" stem="wane" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP-TMP (JJ Last) (NN week)) (, ,) (NP (NNP MAFF)) (VP (VBD said) (SBAR (IN that) (S (NP (NP (DT the) (NNS numbers)) (PP (IN of) (NP (NP (VBN confirmed) (NN BSE) (NNS cases)) (PP (IN in) (NP (DT the) (JJ first) (CD two) (NNS months))) (PP (IN of) (NP (DT this) (NN year)))))) (VP (VBD showed) (NP (QP (DT a) (CD 20))) (PP (IN per) (NP (NN cent) (NN drop))) (PP (IN over) (NP (NP (NP (DT the) (JJ same) (NN period)) (PP (IN in) (NP (CD 1993)))) (: --) (NP (NN proof)))) (PRN (, ,) (S (NP (DT the) (NN ministry)) (VP (VBZ says))) (, ,)) (SBAR (IN that) (S (NP (DT the) (JJ epidemic)) (VP (VBZ is) (VP (VBG waning))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="confirmed BSE cases" type="NP">
          <tokens>
            <token id="10" string="confirmed" />
            <token id="11" string="BSE" />
            <token id="12" string="cases" />
          </tokens>
        </chunking>
        <chunking id="2" string="the numbers" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="numbers" />
          </tokens>
        </chunking>
        <chunking id="3" string="that the epidemic is waning" type="SBAR">
          <tokens>
            <token id="40" string="that" />
            <token id="41" string="the" />
            <token id="42" string="epidemic" />
            <token id="43" string="is" />
            <token id="44" string="waning" />
          </tokens>
        </chunking>
        <chunking id="4" string="waning" type="VP">
          <tokens>
            <token id="44" string="waning" />
          </tokens>
        </chunking>
        <chunking id="5" string="confirmed BSE cases in the first two months of this year" type="NP">
          <tokens>
            <token id="10" string="confirmed" />
            <token id="11" string="BSE" />
            <token id="12" string="cases" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="first" />
            <token id="16" string="two" />
            <token id="17" string="months" />
            <token id="18" string="of" />
            <token id="19" string="this" />
            <token id="20" string="year" />
          </tokens>
        </chunking>
        <chunking id="6" string="said that the numbers of confirmed BSE cases in the first two months of this year showed a 20 per cent drop over the same period in 1993 -- proof , the ministry says , that the epidemic is waning" type="VP">
          <tokens>
            <token id="5" string="said" />
            <token id="6" string="that" />
            <token id="7" string="the" />
            <token id="8" string="numbers" />
            <token id="9" string="of" />
            <token id="10" string="confirmed" />
            <token id="11" string="BSE" />
            <token id="12" string="cases" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="first" />
            <token id="16" string="two" />
            <token id="17" string="months" />
            <token id="18" string="of" />
            <token id="19" string="this" />
            <token id="20" string="year" />
            <token id="21" string="showed" />
            <token id="22" string="a" />
            <token id="23" string="20" />
            <token id="24" string="per" />
            <token id="25" string="cent" />
            <token id="26" string="drop" />
            <token id="27" string="over" />
            <token id="28" string="the" />
            <token id="29" string="same" />
            <token id="30" string="period" />
            <token id="31" string="in" />
            <token id="32" string="1993" />
            <token id="33" string="--" />
            <token id="34" string="proof" />
            <token id="35" string="," />
            <token id="36" string="the" />
            <token id="37" string="ministry" />
            <token id="38" string="says" />
            <token id="39" string="," />
            <token id="40" string="that" />
            <token id="41" string="the" />
            <token id="42" string="epidemic" />
            <token id="43" string="is" />
            <token id="44" string="waning" />
          </tokens>
        </chunking>
        <chunking id="7" string="is waning" type="VP">
          <tokens>
            <token id="43" string="is" />
            <token id="44" string="waning" />
          </tokens>
        </chunking>
        <chunking id="8" string="the numbers of confirmed BSE cases in the first two months of this year" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="numbers" />
            <token id="9" string="of" />
            <token id="10" string="confirmed" />
            <token id="11" string="BSE" />
            <token id="12" string="cases" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="first" />
            <token id="16" string="two" />
            <token id="17" string="months" />
            <token id="18" string="of" />
            <token id="19" string="this" />
            <token id="20" string="year" />
          </tokens>
        </chunking>
        <chunking id="9" string="the same period" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="same" />
            <token id="30" string="period" />
          </tokens>
        </chunking>
        <chunking id="10" string="the epidemic" type="NP">
          <tokens>
            <token id="41" string="the" />
            <token id="42" string="epidemic" />
          </tokens>
        </chunking>
        <chunking id="11" string="that the numbers of confirmed BSE cases in the first two months of this year showed a 20 per cent drop over the same period in 1993 -- proof , the ministry says , that the epidemic is waning" type="SBAR">
          <tokens>
            <token id="6" string="that" />
            <token id="7" string="the" />
            <token id="8" string="numbers" />
            <token id="9" string="of" />
            <token id="10" string="confirmed" />
            <token id="11" string="BSE" />
            <token id="12" string="cases" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="first" />
            <token id="16" string="two" />
            <token id="17" string="months" />
            <token id="18" string="of" />
            <token id="19" string="this" />
            <token id="20" string="year" />
            <token id="21" string="showed" />
            <token id="22" string="a" />
            <token id="23" string="20" />
            <token id="24" string="per" />
            <token id="25" string="cent" />
            <token id="26" string="drop" />
            <token id="27" string="over" />
            <token id="28" string="the" />
            <token id="29" string="same" />
            <token id="30" string="period" />
            <token id="31" string="in" />
            <token id="32" string="1993" />
            <token id="33" string="--" />
            <token id="34" string="proof" />
            <token id="35" string="," />
            <token id="36" string="the" />
            <token id="37" string="ministry" />
            <token id="38" string="says" />
            <token id="39" string="," />
            <token id="40" string="that" />
            <token id="41" string="the" />
            <token id="42" string="epidemic" />
            <token id="43" string="is" />
            <token id="44" string="waning" />
          </tokens>
        </chunking>
        <chunking id="12" string="the same period in 1993 -- proof" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="same" />
            <token id="30" string="period" />
            <token id="31" string="in" />
            <token id="32" string="1993" />
            <token id="33" string="--" />
            <token id="34" string="proof" />
          </tokens>
        </chunking>
        <chunking id="13" string="showed a 20 per cent drop over the same period in 1993 -- proof , the ministry says , that the epidemic is waning" type="VP">
          <tokens>
            <token id="21" string="showed" />
            <token id="22" string="a" />
            <token id="23" string="20" />
            <token id="24" string="per" />
            <token id="25" string="cent" />
            <token id="26" string="drop" />
            <token id="27" string="over" />
            <token id="28" string="the" />
            <token id="29" string="same" />
            <token id="30" string="period" />
            <token id="31" string="in" />
            <token id="32" string="1993" />
            <token id="33" string="--" />
            <token id="34" string="proof" />
            <token id="35" string="," />
            <token id="36" string="the" />
            <token id="37" string="ministry" />
            <token id="38" string="says" />
            <token id="39" string="," />
            <token id="40" string="that" />
            <token id="41" string="the" />
            <token id="42" string="epidemic" />
            <token id="43" string="is" />
            <token id="44" string="waning" />
          </tokens>
        </chunking>
        <chunking id="14" string="MAFF" type="NP">
          <tokens>
            <token id="4" string="MAFF" />
          </tokens>
        </chunking>
        <chunking id="15" string="a 20" type="NP">
          <tokens>
            <token id="22" string="a" />
            <token id="23" string="20" />
          </tokens>
        </chunking>
        <chunking id="16" string="the same period in 1993" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="same" />
            <token id="30" string="period" />
            <token id="31" string="in" />
            <token id="32" string="1993" />
          </tokens>
        </chunking>
        <chunking id="17" string="says" type="VP">
          <tokens>
            <token id="38" string="says" />
          </tokens>
        </chunking>
        <chunking id="18" string="1993" type="NP">
          <tokens>
            <token id="32" string="1993" />
          </tokens>
        </chunking>
        <chunking id="19" string="cent drop" type="NP">
          <tokens>
            <token id="25" string="cent" />
            <token id="26" string="drop" />
          </tokens>
        </chunking>
        <chunking id="20" string="the first two months" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="first" />
            <token id="16" string="two" />
            <token id="17" string="months" />
          </tokens>
        </chunking>
        <chunking id="21" string="proof" type="NP">
          <tokens>
            <token id="34" string="proof" />
          </tokens>
        </chunking>
        <chunking id="22" string="this year" type="NP">
          <tokens>
            <token id="19" string="this" />
            <token id="20" string="year" />
          </tokens>
        </chunking>
        <chunking id="23" string="the ministry" type="NP">
          <tokens>
            <token id="36" string="the" />
            <token id="37" string="ministry" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">week</governor>
          <dependent id="1">Last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="5">said</governor>
          <dependent id="2">week</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">said</governor>
          <dependent id="4">MAFF</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">said</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">showed</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">numbers</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">showed</governor>
          <dependent id="8">numbers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">cases</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">cases</governor>
          <dependent id="10">confirmed</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">cases</governor>
          <dependent id="11">BSE</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">numbers</governor>
          <dependent id="12">cases</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">months</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">months</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">months</governor>
          <dependent id="15">first</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="17">months</governor>
          <dependent id="16">two</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">cases</governor>
          <dependent id="17">months</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">year</governor>
          <dependent id="18">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">year</governor>
          <dependent id="19">this</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">cases</governor>
          <dependent id="20">year</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">said</governor>
          <dependent id="21">showed</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="23">20</governor>
          <dependent id="22">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">showed</governor>
          <dependent id="23">20</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">drop</governor>
          <dependent id="24">per</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">drop</governor>
          <dependent id="25">cent</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">showed</governor>
          <dependent id="26">drop</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">period</governor>
          <dependent id="27">over</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">period</governor>
          <dependent id="28">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="30">period</governor>
          <dependent id="29">same</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">showed</governor>
          <dependent id="30">period</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">1993</governor>
          <dependent id="31">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">period</governor>
          <dependent id="32">1993</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="30">period</governor>
          <dependent id="34">proof</dependent>
        </dependency>
        <dependency type="det">
          <governor id="37">ministry</governor>
          <dependent id="36">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="38">says</governor>
          <dependent id="37">ministry</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="21">showed</governor>
          <dependent id="38">says</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="44">waning</governor>
          <dependent id="40">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="42">epidemic</governor>
          <dependent id="41">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="44">waning</governor>
          <dependent id="42">epidemic</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="44">waning</governor>
          <dependent id="43">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="21">showed</governor>
          <dependent id="44">waning</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="MAFF" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="4" string="MAFF" />
          </tokens>
        </entity>
        <entity id="2" string="Last week" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="Last" />
            <token id="2" string="week" />
          </tokens>
        </entity>
        <entity id="3" string="BSE" type="MISC" score="0.0">
          <tokens>
            <token id="11" string="BSE" />
          </tokens>
        </entity>
        <entity id="4" string="1993" type="DATE" score="0.0">
          <tokens>
            <token id="32" string="1993" />
          </tokens>
        </entity>
        <entity id="5" string="the first two months of this year" type="DATE" score="0.0">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="first" />
            <token id="16" string="two" />
            <token id="17" string="months" />
            <token id="18" string="of" />
            <token id="19" string="this" />
            <token id="20" string="year" />
          </tokens>
        </entity>
        <entity id="6" string="20" type="NUMBER" score="0.0">
          <tokens>
            <token id="23" string="20" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="23" has_coreference="false">
      <content>Yet there is still controversy.</content>
      <tokens>
        <token id="1" string="Yet" lemma="yet" stem="yet" pos="CC" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="still" lemma="still" stem="still" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="controversy" lemma="controversy" stem="controversi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC Yet) (NP (EX there)) (VP (VBZ is) (ADVP (RB still)) (NP (NN controversy))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="there" type="NP">
          <tokens>
            <token id="2" string="there" />
          </tokens>
        </chunking>
        <chunking id="2" string="is still controversy" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="still" />
            <token id="5" string="controversy" />
          </tokens>
        </chunking>
        <chunking id="3" string="controversy" type="NP">
          <tokens>
            <token id="5" string="controversy" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="3">is</governor>
          <dependent id="1">Yet</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="3">is</governor>
          <dependent id="2">there</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">is</governor>
          <dependent id="4">still</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">is</governor>
          <dependent id="5">controversy</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="24" has_coreference="false">
      <content>Some 8,004 cattle have died from BSE despite being born after the feed ban was introduced.</content>
      <tokens>
        <token id="1" string="Some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="8,004" lemma="8,004" stem="8,004" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="3" string="cattle" lemma="cattle" stem="cattl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="died" lemma="die" stem="di" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="BSE" lemma="BSE" stem="bse" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="8" string="despite" lemma="despite" stem="despit" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="being" lemma="be" stem="be" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="born" lemma="bear" stem="born" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="feed" lemma="feed" stem="feed" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="ban" lemma="ban" stem="ban" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="introduced" lemma="introduce" stem="introduc" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT Some) (CD 8,004) (NNS cattle)) (VP (VBP have) (VP (VBN died) (PP (IN from) (NP (NNP BSE))) (PP (IN despite) (S (VP (VBG being) (VP (VBN born) (SBAR (IN after) (S (NP (DT the) (NN feed) (NN ban)) (VP (VBD was) (VP (VBN introduced))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="died from BSE despite being born after the feed ban was introduced" type="VP">
          <tokens>
            <token id="5" string="died" />
            <token id="6" string="from" />
            <token id="7" string="BSE" />
            <token id="8" string="despite" />
            <token id="9" string="being" />
            <token id="10" string="born" />
            <token id="11" string="after" />
            <token id="12" string="the" />
            <token id="13" string="feed" />
            <token id="14" string="ban" />
            <token id="15" string="was" />
            <token id="16" string="introduced" />
          </tokens>
        </chunking>
        <chunking id="2" string="BSE" type="NP">
          <tokens>
            <token id="7" string="BSE" />
          </tokens>
        </chunking>
        <chunking id="3" string="was introduced" type="VP">
          <tokens>
            <token id="15" string="was" />
            <token id="16" string="introduced" />
          </tokens>
        </chunking>
        <chunking id="4" string="after the feed ban was introduced" type="SBAR">
          <tokens>
            <token id="11" string="after" />
            <token id="12" string="the" />
            <token id="13" string="feed" />
            <token id="14" string="ban" />
            <token id="15" string="was" />
            <token id="16" string="introduced" />
          </tokens>
        </chunking>
        <chunking id="5" string="introduced" type="VP">
          <tokens>
            <token id="16" string="introduced" />
          </tokens>
        </chunking>
        <chunking id="6" string="Some 8,004 cattle" type="NP">
          <tokens>
            <token id="1" string="Some" />
            <token id="2" string="8,004" />
            <token id="3" string="cattle" />
          </tokens>
        </chunking>
        <chunking id="7" string="being born after the feed ban was introduced" type="VP">
          <tokens>
            <token id="9" string="being" />
            <token id="10" string="born" />
            <token id="11" string="after" />
            <token id="12" string="the" />
            <token id="13" string="feed" />
            <token id="14" string="ban" />
            <token id="15" string="was" />
            <token id="16" string="introduced" />
          </tokens>
        </chunking>
        <chunking id="8" string="have died from BSE despite being born after the feed ban was introduced" type="VP">
          <tokens>
            <token id="4" string="have" />
            <token id="5" string="died" />
            <token id="6" string="from" />
            <token id="7" string="BSE" />
            <token id="8" string="despite" />
            <token id="9" string="being" />
            <token id="10" string="born" />
            <token id="11" string="after" />
            <token id="12" string="the" />
            <token id="13" string="feed" />
            <token id="14" string="ban" />
            <token id="15" string="was" />
            <token id="16" string="introduced" />
          </tokens>
        </chunking>
        <chunking id="9" string="born after the feed ban was introduced" type="VP">
          <tokens>
            <token id="10" string="born" />
            <token id="11" string="after" />
            <token id="12" string="the" />
            <token id="13" string="feed" />
            <token id="14" string="ban" />
            <token id="15" string="was" />
            <token id="16" string="introduced" />
          </tokens>
        </chunking>
        <chunking id="10" string="the feed ban" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="feed" />
            <token id="14" string="ban" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">cattle</governor>
          <dependent id="1">Some</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="3">cattle</governor>
          <dependent id="2">8,004</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">died</governor>
          <dependent id="3">cattle</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">died</governor>
          <dependent id="4">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">died</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">BSE</governor>
          <dependent id="6">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">died</governor>
          <dependent id="7">BSE</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">born</governor>
          <dependent id="8">despite</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="10">born</governor>
          <dependent id="9">being</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">died</governor>
          <dependent id="10">born</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">introduced</governor>
          <dependent id="11">after</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">ban</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">ban</governor>
          <dependent id="13">feed</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="16">introduced</governor>
          <dependent id="14">ban</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="16">introduced</governor>
          <dependent id="15">was</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="10">born</governor>
          <dependent id="16">introduced</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="BSE" type="MISC" score="0.0">
          <tokens>
            <token id="7" string="BSE" />
          </tokens>
        </entity>
        <entity id="2" string="8,004" type="NUMBER" score="0.0">
          <tokens>
            <token id="2" string="8,004" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="25" has_coreference="false">
      <content>MAFF says 5,767 of these were born before the end of 1988, and were probably fed from remaining infected supplies.</content>
      <tokens>
        <token id="1" string="MAFF" lemma="MAFF" stem="maff" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="2" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="5,767" lemma="5,767" stem="5,767" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="these" lemma="these" stem="these" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="born" lemma="bear" stem="born" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="10" string="end" lemma="end" stem="end" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="12" string="1988" lemma="1988" stem="1988" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="probably" lemma="probably" stem="probabl" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="fed" lemma="feed" stem="fed" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="remaining" lemma="remain" stem="remain" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="infected" lemma="infected" stem="infect" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="supplies" lemma="supplies" stem="suppli" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP MAFF)) (VP (VP (VBZ says) (SBAR (S (NP (NP (CD 5,767)) (PP (IN of) (NP (DT these)))) (VP (VBD were) (VP (VBN born) (PP (IN before) (NP (NP (DT the) (NN end)) (PP (IN of) (NP (CD 1988)))))))))) (, ,) (CC and) (VP (VBD were) (VP (ADVP (RB probably)) (VBN fed) (PP (IN from) (NP (VBG remaining) (JJ infected) (NNS supplies)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="5,767 of these" type="NP">
          <tokens>
            <token id="3" string="5,767" />
            <token id="4" string="of" />
            <token id="5" string="these" />
          </tokens>
        </chunking>
        <chunking id="2" string="born before the end of 1988" type="VP">
          <tokens>
            <token id="7" string="born" />
            <token id="8" string="before" />
            <token id="9" string="the" />
            <token id="10" string="end" />
            <token id="11" string="of" />
            <token id="12" string="1988" />
          </tokens>
        </chunking>
        <chunking id="3" string="the end" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="end" />
          </tokens>
        </chunking>
        <chunking id="4" string="were probably fed from remaining infected supplies" type="VP">
          <tokens>
            <token id="15" string="were" />
            <token id="16" string="probably" />
            <token id="17" string="fed" />
            <token id="18" string="from" />
            <token id="19" string="remaining" />
            <token id="20" string="infected" />
            <token id="21" string="supplies" />
          </tokens>
        </chunking>
        <chunking id="5" string="remaining infected supplies" type="NP">
          <tokens>
            <token id="19" string="remaining" />
            <token id="20" string="infected" />
            <token id="21" string="supplies" />
          </tokens>
        </chunking>
        <chunking id="6" string="the end of 1988" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="end" />
            <token id="11" string="of" />
            <token id="12" string="1988" />
          </tokens>
        </chunking>
        <chunking id="7" string="MAFF" type="NP">
          <tokens>
            <token id="1" string="MAFF" />
          </tokens>
        </chunking>
        <chunking id="8" string="were born before the end of 1988" type="VP">
          <tokens>
            <token id="6" string="were" />
            <token id="7" string="born" />
            <token id="8" string="before" />
            <token id="9" string="the" />
            <token id="10" string="end" />
            <token id="11" string="of" />
            <token id="12" string="1988" />
          </tokens>
        </chunking>
        <chunking id="9" string="1988" type="NP">
          <tokens>
            <token id="12" string="1988" />
          </tokens>
        </chunking>
        <chunking id="10" string="says 5,767 of these were born before the end of 1988 , and were probably fed from remaining infected supplies" type="VP">
          <tokens>
            <token id="2" string="says" />
            <token id="3" string="5,767" />
            <token id="4" string="of" />
            <token id="5" string="these" />
            <token id="6" string="were" />
            <token id="7" string="born" />
            <token id="8" string="before" />
            <token id="9" string="the" />
            <token id="10" string="end" />
            <token id="11" string="of" />
            <token id="12" string="1988" />
            <token id="13" string="," />
            <token id="14" string="and" />
            <token id="15" string="were" />
            <token id="16" string="probably" />
            <token id="17" string="fed" />
            <token id="18" string="from" />
            <token id="19" string="remaining" />
            <token id="20" string="infected" />
            <token id="21" string="supplies" />
          </tokens>
        </chunking>
        <chunking id="11" string="these" type="NP">
          <tokens>
            <token id="5" string="these" />
          </tokens>
        </chunking>
        <chunking id="12" string="says 5,767 of these were born before the end of 1988" type="VP">
          <tokens>
            <token id="2" string="says" />
            <token id="3" string="5,767" />
            <token id="4" string="of" />
            <token id="5" string="these" />
            <token id="6" string="were" />
            <token id="7" string="born" />
            <token id="8" string="before" />
            <token id="9" string="the" />
            <token id="10" string="end" />
            <token id="11" string="of" />
            <token id="12" string="1988" />
          </tokens>
        </chunking>
        <chunking id="13" string="5,767 of these were born before the end of 1988" type="SBAR">
          <tokens>
            <token id="3" string="5,767" />
            <token id="4" string="of" />
            <token id="5" string="these" />
            <token id="6" string="were" />
            <token id="7" string="born" />
            <token id="8" string="before" />
            <token id="9" string="the" />
            <token id="10" string="end" />
            <token id="11" string="of" />
            <token id="12" string="1988" />
          </tokens>
        </chunking>
        <chunking id="14" string="probably fed from remaining infected supplies" type="VP">
          <tokens>
            <token id="16" string="probably" />
            <token id="17" string="fed" />
            <token id="18" string="from" />
            <token id="19" string="remaining" />
            <token id="20" string="infected" />
            <token id="21" string="supplies" />
          </tokens>
        </chunking>
        <chunking id="15" string="5,767" type="NP">
          <tokens>
            <token id="3" string="5,767" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">says</governor>
          <dependent id="1">MAFF</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">says</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="7">born</governor>
          <dependent id="3">5,767</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">these</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">5,767</governor>
          <dependent id="5">these</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="7">born</governor>
          <dependent id="6">were</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">says</governor>
          <dependent id="7">born</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">end</governor>
          <dependent id="8">before</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">end</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">born</governor>
          <dependent id="10">end</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">1988</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">end</governor>
          <dependent id="12">1988</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">says</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="17">fed</governor>
          <dependent id="15">were</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">fed</governor>
          <dependent id="16">probably</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">says</governor>
          <dependent id="17">fed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">supplies</governor>
          <dependent id="18">from</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">supplies</governor>
          <dependent id="19">remaining</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">supplies</governor>
          <dependent id="20">infected</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">fed</governor>
          <dependent id="21">supplies</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="MAFF" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="1" string="MAFF" />
          </tokens>
        </entity>
        <entity id="2" string="the end of 1988" type="DATE" score="0.0">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="end" />
            <token id="11" string="of" />
            <token id="12" string="1988" />
          </tokens>
        </entity>
        <entity id="3" string="5,767" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="5,767" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="26" has_coreference="true">
      <content>That theory has been assailed by critics of the ministry.</content>
      <tokens>
        <token id="1" string="That" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="theory" lemma="theory" stem="theori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="assailed" lemma="assail" stem="assail" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="critics" lemma="critic" stem="critic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="ministry" lemma="ministry" stem="ministri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT That) (NN theory)) (VP (VBZ has) (VP (VBN been) (VP (VBN assailed) (PP (IN by) (NP (NP (NNS critics)) (PP (IN of) (NP (DT the) (NN ministry)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="has been assailed by critics of the ministry" type="VP">
          <tokens>
            <token id="3" string="has" />
            <token id="4" string="been" />
            <token id="5" string="assailed" />
            <token id="6" string="by" />
            <token id="7" string="critics" />
            <token id="8" string="of" />
            <token id="9" string="the" />
            <token id="10" string="ministry" />
          </tokens>
        </chunking>
        <chunking id="2" string="critics" type="NP">
          <tokens>
            <token id="7" string="critics" />
          </tokens>
        </chunking>
        <chunking id="3" string="critics of the ministry" type="NP">
          <tokens>
            <token id="7" string="critics" />
            <token id="8" string="of" />
            <token id="9" string="the" />
            <token id="10" string="ministry" />
          </tokens>
        </chunking>
        <chunking id="4" string="That theory" type="NP">
          <tokens>
            <token id="1" string="That" />
            <token id="2" string="theory" />
          </tokens>
        </chunking>
        <chunking id="5" string="been assailed by critics of the ministry" type="VP">
          <tokens>
            <token id="4" string="been" />
            <token id="5" string="assailed" />
            <token id="6" string="by" />
            <token id="7" string="critics" />
            <token id="8" string="of" />
            <token id="9" string="the" />
            <token id="10" string="ministry" />
          </tokens>
        </chunking>
        <chunking id="6" string="assailed by critics of the ministry" type="VP">
          <tokens>
            <token id="5" string="assailed" />
            <token id="6" string="by" />
            <token id="7" string="critics" />
            <token id="8" string="of" />
            <token id="9" string="the" />
            <token id="10" string="ministry" />
          </tokens>
        </chunking>
        <chunking id="7" string="the ministry" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="ministry" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">theory</governor>
          <dependent id="1">That</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="5">assailed</governor>
          <dependent id="2">theory</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">assailed</governor>
          <dependent id="3">has</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">assailed</governor>
          <dependent id="4">been</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">assailed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">critics</governor>
          <dependent id="6">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">assailed</governor>
          <dependent id="7">critics</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">ministry</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">ministry</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">critics</governor>
          <dependent id="10">ministry</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>Mark Purdey, a Somerset farmer and independent researcher, believes that the use of organophosphate pesticides, used from the 1980s as a sheep dip and to treat warble-fly infestation in cattle, could have damaged the animals&amp;apost; immune system, exposing them to the disease.</content>
      <tokens>
        <token id="1" string="Mark" lemma="Mark" stem="mark" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Purdey" lemma="Purdey" stem="purdei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="Somerset" lemma="Somerset" stem="somerset" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="6" string="farmer" lemma="farmer" stem="farmer" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="independent" lemma="independent" stem="independ" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="true" is_refers="false" />
        <token id="9" string="researcher" lemma="researcher" stem="research" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="believes" lemma="believe" stem="believ" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="use" lemma="use" stem="us" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="organophosphate" lemma="organophosphate" stem="organophosph" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="pesticides" lemma="pesticide" stem="pesticid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="used" lemma="use" stem="us" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="22" string="1980s" lemma="1980s" stem="1980" pos="CD" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="23" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="sheep" lemma="sheep" stem="sheep" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="dip" lemma="dip" stem="dip" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="treat" lemma="treat" stem="treat" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="warble-fly" lemma="warble-fly" stem="warble-fli" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="infestation" lemma="infestation" stem="infest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="cattle" lemma="cattle" stem="cattl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="damaged" lemma="damage" stem="damag" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="39" string="animals" lemma="animal" stem="anim" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="40" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="41" string="immune" lemma="immune" stem="immun" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="system" lemma="system" stem="system" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="exposing" lemma="expose" stem="expos" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="48" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="true" />
        <token id="49" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Mark) (NNP Purdey)) (, ,) (NP (NP (DT a) (NNP Somerset) (NN farmer)) (CC and) (NP (JJ independent) (NN researcher))) (, ,)) (VP (VBZ believes) (SBAR (IN that) (S (NP (NP (DT the) (NN use)) (PP (IN of) (NP (NN organophosphate) (NNS pesticides))) (, ,) (VP (VBN used) (PP (IN from) (NP (DT the) (CD 1980s))) (PP (IN as) (NP (NP (DT a) (NN sheep) (NN dip)) (CC and) (S (VP (TO to) (VP (VB treat) (NP (JJ warble-fly) (NN infestation)) (PP (IN in) (NP (NNS cattle))))))))) (, ,)) (VP (MD could) (VP (VB have) (VP (VBN damaged) (NP (NP (DT the) (NNS animals) (POS ')) (JJ immune) (NN system)) (, ,) (S (VP (VBG exposing) (NP (PRP them)) (PP (TO to) (NP (DT the) (NN disease))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="independent researcher" type="NP">
          <tokens>
            <token id="8" string="independent" />
            <token id="9" string="researcher" />
          </tokens>
        </chunking>
        <chunking id="2" string="organophosphate pesticides" type="NP">
          <tokens>
            <token id="16" string="organophosphate" />
            <token id="17" string="pesticides" />
          </tokens>
        </chunking>
        <chunking id="3" string="a Somerset farmer and independent researcher" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="Somerset" />
            <token id="6" string="farmer" />
            <token id="7" string="and" />
            <token id="8" string="independent" />
            <token id="9" string="researcher" />
          </tokens>
        </chunking>
        <chunking id="4" string="used from the 1980s as a sheep dip and to treat warble-fly infestation in cattle" type="VP">
          <tokens>
            <token id="19" string="used" />
            <token id="20" string="from" />
            <token id="21" string="the" />
            <token id="22" string="1980s" />
            <token id="23" string="as" />
            <token id="24" string="a" />
            <token id="25" string="sheep" />
            <token id="26" string="dip" />
            <token id="27" string="and" />
            <token id="28" string="to" />
            <token id="29" string="treat" />
            <token id="30" string="warble-fly" />
            <token id="31" string="infestation" />
            <token id="32" string="in" />
            <token id="33" string="cattle" />
          </tokens>
        </chunking>
        <chunking id="5" string="warble-fly infestation" type="NP">
          <tokens>
            <token id="30" string="warble-fly" />
            <token id="31" string="infestation" />
          </tokens>
        </chunking>
        <chunking id="6" string="cattle" type="NP">
          <tokens>
            <token id="33" string="cattle" />
          </tokens>
        </chunking>
        <chunking id="7" string="could have damaged the animals ' immune system , exposing them to the disease" type="VP">
          <tokens>
            <token id="35" string="could" />
            <token id="36" string="have" />
            <token id="37" string="damaged" />
            <token id="38" string="the" />
            <token id="39" string="animals" />
            <token id="40" string="'" />
            <token id="41" string="immune" />
            <token id="42" string="system" />
            <token id="43" string="," />
            <token id="44" string="exposing" />
            <token id="45" string="them" />
            <token id="46" string="to" />
            <token id="47" string="the" />
            <token id="48" string="disease" />
          </tokens>
        </chunking>
        <chunking id="8" string="Mark Purdey , a Somerset farmer and independent researcher ," type="NP">
          <tokens>
            <token id="1" string="Mark" />
            <token id="2" string="Purdey" />
            <token id="3" string="," />
            <token id="4" string="a" />
            <token id="5" string="Somerset" />
            <token id="6" string="farmer" />
            <token id="7" string="and" />
            <token id="8" string="independent" />
            <token id="9" string="researcher" />
            <token id="10" string="," />
          </tokens>
        </chunking>
        <chunking id="9" string="them" type="NP">
          <tokens>
            <token id="45" string="them" />
          </tokens>
        </chunking>
        <chunking id="10" string="the use of organophosphate pesticides , used from the 1980s as a sheep dip and to treat warble-fly infestation in cattle ," type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="use" />
            <token id="15" string="of" />
            <token id="16" string="organophosphate" />
            <token id="17" string="pesticides" />
            <token id="18" string="," />
            <token id="19" string="used" />
            <token id="20" string="from" />
            <token id="21" string="the" />
            <token id="22" string="1980s" />
            <token id="23" string="as" />
            <token id="24" string="a" />
            <token id="25" string="sheep" />
            <token id="26" string="dip" />
            <token id="27" string="and" />
            <token id="28" string="to" />
            <token id="29" string="treat" />
            <token id="30" string="warble-fly" />
            <token id="31" string="infestation" />
            <token id="32" string="in" />
            <token id="33" string="cattle" />
            <token id="34" string="," />
          </tokens>
        </chunking>
        <chunking id="11" string="a sheep dip and to treat warble-fly infestation in cattle" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="sheep" />
            <token id="26" string="dip" />
            <token id="27" string="and" />
            <token id="28" string="to" />
            <token id="29" string="treat" />
            <token id="30" string="warble-fly" />
            <token id="31" string="infestation" />
            <token id="32" string="in" />
            <token id="33" string="cattle" />
          </tokens>
        </chunking>
        <chunking id="12" string="the disease" type="NP">
          <tokens>
            <token id="47" string="the" />
            <token id="48" string="disease" />
          </tokens>
        </chunking>
        <chunking id="13" string="a sheep dip" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="sheep" />
            <token id="26" string="dip" />
          </tokens>
        </chunking>
        <chunking id="14" string="the animals ' immune system" type="NP">
          <tokens>
            <token id="38" string="the" />
            <token id="39" string="animals" />
            <token id="40" string="'" />
            <token id="41" string="immune" />
            <token id="42" string="system" />
          </tokens>
        </chunking>
        <chunking id="15" string="that the use of organophosphate pesticides , used from the 1980s as a sheep dip and to treat warble-fly infestation in cattle , could have damaged the animals ' immune system , exposing them to the disease" type="SBAR">
          <tokens>
            <token id="12" string="that" />
            <token id="13" string="the" />
            <token id="14" string="use" />
            <token id="15" string="of" />
            <token id="16" string="organophosphate" />
            <token id="17" string="pesticides" />
            <token id="18" string="," />
            <token id="19" string="used" />
            <token id="20" string="from" />
            <token id="21" string="the" />
            <token id="22" string="1980s" />
            <token id="23" string="as" />
            <token id="24" string="a" />
            <token id="25" string="sheep" />
            <token id="26" string="dip" />
            <token id="27" string="and" />
            <token id="28" string="to" />
            <token id="29" string="treat" />
            <token id="30" string="warble-fly" />
            <token id="31" string="infestation" />
            <token id="32" string="in" />
            <token id="33" string="cattle" />
            <token id="34" string="," />
            <token id="35" string="could" />
            <token id="36" string="have" />
            <token id="37" string="damaged" />
            <token id="38" string="the" />
            <token id="39" string="animals" />
            <token id="40" string="'" />
            <token id="41" string="immune" />
            <token id="42" string="system" />
            <token id="43" string="," />
            <token id="44" string="exposing" />
            <token id="45" string="them" />
            <token id="46" string="to" />
            <token id="47" string="the" />
            <token id="48" string="disease" />
          </tokens>
        </chunking>
        <chunking id="16" string="Mark Purdey" type="NP">
          <tokens>
            <token id="1" string="Mark" />
            <token id="2" string="Purdey" />
          </tokens>
        </chunking>
        <chunking id="17" string="a Somerset farmer" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="Somerset" />
            <token id="6" string="farmer" />
          </tokens>
        </chunking>
        <chunking id="18" string="damaged the animals ' immune system , exposing them to the disease" type="VP">
          <tokens>
            <token id="37" string="damaged" />
            <token id="38" string="the" />
            <token id="39" string="animals" />
            <token id="40" string="'" />
            <token id="41" string="immune" />
            <token id="42" string="system" />
            <token id="43" string="," />
            <token id="44" string="exposing" />
            <token id="45" string="them" />
            <token id="46" string="to" />
            <token id="47" string="the" />
            <token id="48" string="disease" />
          </tokens>
        </chunking>
        <chunking id="19" string="the use" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="use" />
          </tokens>
        </chunking>
        <chunking id="20" string="to treat warble-fly infestation in cattle" type="VP">
          <tokens>
            <token id="28" string="to" />
            <token id="29" string="treat" />
            <token id="30" string="warble-fly" />
            <token id="31" string="infestation" />
            <token id="32" string="in" />
            <token id="33" string="cattle" />
          </tokens>
        </chunking>
        <chunking id="21" string="exposing them to the disease" type="VP">
          <tokens>
            <token id="44" string="exposing" />
            <token id="45" string="them" />
            <token id="46" string="to" />
            <token id="47" string="the" />
            <token id="48" string="disease" />
          </tokens>
        </chunking>
        <chunking id="22" string="believes that the use of organophosphate pesticides , used from the 1980s as a sheep dip and to treat warble-fly infestation in cattle , could have damaged the animals ' immune system , exposing them to the disease" type="VP">
          <tokens>
            <token id="11" string="believes" />
            <token id="12" string="that" />
            <token id="13" string="the" />
            <token id="14" string="use" />
            <token id="15" string="of" />
            <token id="16" string="organophosphate" />
            <token id="17" string="pesticides" />
            <token id="18" string="," />
            <token id="19" string="used" />
            <token id="20" string="from" />
            <token id="21" string="the" />
            <token id="22" string="1980s" />
            <token id="23" string="as" />
            <token id="24" string="a" />
            <token id="25" string="sheep" />
            <token id="26" string="dip" />
            <token id="27" string="and" />
            <token id="28" string="to" />
            <token id="29" string="treat" />
            <token id="30" string="warble-fly" />
            <token id="31" string="infestation" />
            <token id="32" string="in" />
            <token id="33" string="cattle" />
            <token id="34" string="," />
            <token id="35" string="could" />
            <token id="36" string="have" />
            <token id="37" string="damaged" />
            <token id="38" string="the" />
            <token id="39" string="animals" />
            <token id="40" string="'" />
            <token id="41" string="immune" />
            <token id="42" string="system" />
            <token id="43" string="," />
            <token id="44" string="exposing" />
            <token id="45" string="them" />
            <token id="46" string="to" />
            <token id="47" string="the" />
            <token id="48" string="disease" />
          </tokens>
        </chunking>
        <chunking id="23" string="treat warble-fly infestation in cattle" type="VP">
          <tokens>
            <token id="29" string="treat" />
            <token id="30" string="warble-fly" />
            <token id="31" string="infestation" />
            <token id="32" string="in" />
            <token id="33" string="cattle" />
          </tokens>
        </chunking>
        <chunking id="24" string="have damaged the animals ' immune system , exposing them to the disease" type="VP">
          <tokens>
            <token id="36" string="have" />
            <token id="37" string="damaged" />
            <token id="38" string="the" />
            <token id="39" string="animals" />
            <token id="40" string="'" />
            <token id="41" string="immune" />
            <token id="42" string="system" />
            <token id="43" string="," />
            <token id="44" string="exposing" />
            <token id="45" string="them" />
            <token id="46" string="to" />
            <token id="47" string="the" />
            <token id="48" string="disease" />
          </tokens>
        </chunking>
        <chunking id="25" string="the animals '" type="NP">
          <tokens>
            <token id="38" string="the" />
            <token id="39" string="animals" />
            <token id="40" string="'" />
          </tokens>
        </chunking>
        <chunking id="26" string="the 1980s" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="1980s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Purdey</governor>
          <dependent id="1">Mark</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">believes</governor>
          <dependent id="2">Purdey</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">farmer</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">farmer</governor>
          <dependent id="5">Somerset</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">Purdey</governor>
          <dependent id="6">farmer</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">farmer</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">researcher</governor>
          <dependent id="8">independent</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">farmer</governor>
          <dependent id="9">researcher</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">believes</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="37">damaged</governor>
          <dependent id="12">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">use</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="37">damaged</governor>
          <dependent id="14">use</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">pesticides</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">pesticides</governor>
          <dependent id="16">organophosphate</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">use</governor>
          <dependent id="17">pesticides</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="14">use</governor>
          <dependent id="19">used</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">1980s</governor>
          <dependent id="20">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">1980s</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">used</governor>
          <dependent id="22">1980s</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">dip</governor>
          <dependent id="23">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">dip</governor>
          <dependent id="24">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">dip</governor>
          <dependent id="25">sheep</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">used</governor>
          <dependent id="26">dip</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="26">dip</governor>
          <dependent id="27">and</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="29">treat</governor>
          <dependent id="28">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="26">dip</governor>
          <dependent id="29">treat</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">infestation</governor>
          <dependent id="30">warble-fly</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="29">treat</governor>
          <dependent id="31">infestation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">cattle</governor>
          <dependent id="32">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">treat</governor>
          <dependent id="33">cattle</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="37">damaged</governor>
          <dependent id="35">could</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="37">damaged</governor>
          <dependent id="36">have</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">believes</governor>
          <dependent id="37">damaged</dependent>
        </dependency>
        <dependency type="det">
          <governor id="39">animals</governor>
          <dependent id="38">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="42">system</governor>
          <dependent id="39">animals</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">animals</governor>
          <dependent id="40">'</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="42">system</governor>
          <dependent id="41">immune</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="37">damaged</governor>
          <dependent id="42">system</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="37">damaged</governor>
          <dependent id="44">exposing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="44">exposing</governor>
          <dependent id="45">them</dependent>
        </dependency>
        <dependency type="case">
          <governor id="48">disease</governor>
          <dependent id="46">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="48">disease</governor>
          <dependent id="47">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="44">exposing</governor>
          <dependent id="48">disease</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="48" string="disease" />
          </tokens>
        </entity>
        <entity id="2" string="independent" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="8" string="independent" />
          </tokens>
        </entity>
        <entity id="3" string="Mark Purdey" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Mark" />
            <token id="2" string="Purdey" />
          </tokens>
        </entity>
        <entity id="4" string="Somerset" type="LOCATION" score="0.0">
          <tokens>
            <token id="5" string="Somerset" />
          </tokens>
        </entity>
        <entity id="5" string="the 1980s" type="DATE" score="0.0">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="1980s" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="28" has_coreference="true">
      <content>Ministry scientists, originally dismissive, are now reassessing his theories.</content>
      <tokens>
        <token id="1" string="Ministry" lemma="Ministry" stem="ministri" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="scientists" lemma="scientist" stem="scientist" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="originally" lemma="originally" stem="origin" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="dismissive" lemma="dismissive" stem="dismiss" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="9" string="reassessing" lemma="reassess" stem="reassess" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="theories" lemma="theory" stem="theori" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Ministry) (NNS scientists)) (, ,) (ADJP (RB originally) (JJ dismissive)) (, ,)) (VP (VBP are) (ADVP (RB now)) (VP (VBG reassessing) (NP (PRP$ his) (NNS theories)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Ministry scientists" type="NP">
          <tokens>
            <token id="1" string="Ministry" />
            <token id="2" string="scientists" />
          </tokens>
        </chunking>
        <chunking id="2" string="reassessing his theories" type="VP">
          <tokens>
            <token id="9" string="reassessing" />
            <token id="10" string="his" />
            <token id="11" string="theories" />
          </tokens>
        </chunking>
        <chunking id="3" string="Ministry scientists , originally dismissive ," type="NP">
          <tokens>
            <token id="1" string="Ministry" />
            <token id="2" string="scientists" />
            <token id="3" string="," />
            <token id="4" string="originally" />
            <token id="5" string="dismissive" />
            <token id="6" string="," />
          </tokens>
        </chunking>
        <chunking id="4" string="originally dismissive" type="ADJP">
          <tokens>
            <token id="4" string="originally" />
            <token id="5" string="dismissive" />
          </tokens>
        </chunking>
        <chunking id="5" string="are now reassessing his theories" type="VP">
          <tokens>
            <token id="7" string="are" />
            <token id="8" string="now" />
            <token id="9" string="reassessing" />
            <token id="10" string="his" />
            <token id="11" string="theories" />
          </tokens>
        </chunking>
        <chunking id="6" string="his theories" type="NP">
          <tokens>
            <token id="10" string="his" />
            <token id="11" string="theories" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">scientists</governor>
          <dependent id="1">Ministry</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">reassessing</governor>
          <dependent id="2">scientists</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">dismissive</governor>
          <dependent id="4">originally</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="2">scientists</governor>
          <dependent id="5">dismissive</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">reassessing</governor>
          <dependent id="7">are</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">reassessing</governor>
          <dependent id="8">now</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">reassessing</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">theories</governor>
          <dependent id="10">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">reassessing</governor>
          <dependent id="11">theories</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="8" string="now" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="29" has_coreference="false">
      <content>More recently, researchers have suggested that in some cattle, BSE has been &amp;quot;vertically&amp;quot; transmitted from cow to calf.</content>
      <tokens>
        <token id="1" string="More" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="recently" lemma="recently" stem="recent" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="researchers" lemma="researcher" stem="research" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="suggested" lemma="suggest" stem="suggest" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="cattle" lemma="cattle" stem="cattl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="BSE" lemma="BSE" stem="bse" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="13" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="vertically" lemma="vertically" stem="vertic" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="transmitted" lemma="transmit" stem="transmit" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="cow" lemma="cow" stem="cow" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="calf" lemma="calf" stem="calf" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RBR More) (RB recently)) (, ,) (NP (NNS researchers)) (VP (VBP have) (VP (VBN suggested) (SBAR (IN that) (S (PP (IN in) (NP (DT some) (NNS cattle))) (, ,) (NP (NNP BSE)) (VP (VBZ has) (VP (VBN been) (VP (`` ``) (ADVP (RB vertically) ('' '')) (VBN transmitted) (PP (IN from) (NP (NP (NN cow)) (PP (TO to) (NP (NN calf)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="some cattle" type="NP">
          <tokens>
            <token id="9" string="some" />
            <token id="10" string="cattle" />
          </tokens>
        </chunking>
        <chunking id="2" string="BSE" type="NP">
          <tokens>
            <token id="12" string="BSE" />
          </tokens>
        </chunking>
        <chunking id="3" string="have suggested that in some cattle , BSE has been `` vertically '' transmitted from cow to calf" type="VP">
          <tokens>
            <token id="5" string="have" />
            <token id="6" string="suggested" />
            <token id="7" string="that" />
            <token id="8" string="in" />
            <token id="9" string="some" />
            <token id="10" string="cattle" />
            <token id="11" string="," />
            <token id="12" string="BSE" />
            <token id="13" string="has" />
            <token id="14" string="been" />
            <token id="15" string="&quot;" />
            <token id="16" string="vertically" />
            <token id="17" string="&quot;" />
            <token id="18" string="transmitted" />
            <token id="19" string="from" />
            <token id="20" string="cow" />
            <token id="21" string="to" />
            <token id="22" string="calf" />
          </tokens>
        </chunking>
        <chunking id="4" string="researchers" type="NP">
          <tokens>
            <token id="4" string="researchers" />
          </tokens>
        </chunking>
        <chunking id="5" string="`` vertically '' transmitted from cow to calf" type="VP">
          <tokens>
            <token id="15" string="&quot;" />
            <token id="16" string="vertically" />
            <token id="17" string="&quot;" />
            <token id="18" string="transmitted" />
            <token id="19" string="from" />
            <token id="20" string="cow" />
            <token id="21" string="to" />
            <token id="22" string="calf" />
          </tokens>
        </chunking>
        <chunking id="6" string="that in some cattle , BSE has been `` vertically '' transmitted from cow to calf" type="SBAR">
          <tokens>
            <token id="7" string="that" />
            <token id="8" string="in" />
            <token id="9" string="some" />
            <token id="10" string="cattle" />
            <token id="11" string="," />
            <token id="12" string="BSE" />
            <token id="13" string="has" />
            <token id="14" string="been" />
            <token id="15" string="&quot;" />
            <token id="16" string="vertically" />
            <token id="17" string="&quot;" />
            <token id="18" string="transmitted" />
            <token id="19" string="from" />
            <token id="20" string="cow" />
            <token id="21" string="to" />
            <token id="22" string="calf" />
          </tokens>
        </chunking>
        <chunking id="7" string="calf" type="NP">
          <tokens>
            <token id="22" string="calf" />
          </tokens>
        </chunking>
        <chunking id="8" string="has been `` vertically '' transmitted from cow to calf" type="VP">
          <tokens>
            <token id="13" string="has" />
            <token id="14" string="been" />
            <token id="15" string="&quot;" />
            <token id="16" string="vertically" />
            <token id="17" string="&quot;" />
            <token id="18" string="transmitted" />
            <token id="19" string="from" />
            <token id="20" string="cow" />
            <token id="21" string="to" />
            <token id="22" string="calf" />
          </tokens>
        </chunking>
        <chunking id="9" string="cow to calf" type="NP">
          <tokens>
            <token id="20" string="cow" />
            <token id="21" string="to" />
            <token id="22" string="calf" />
          </tokens>
        </chunking>
        <chunking id="10" string="cow" type="NP">
          <tokens>
            <token id="20" string="cow" />
          </tokens>
        </chunking>
        <chunking id="11" string="suggested that in some cattle , BSE has been `` vertically '' transmitted from cow to calf" type="VP">
          <tokens>
            <token id="6" string="suggested" />
            <token id="7" string="that" />
            <token id="8" string="in" />
            <token id="9" string="some" />
            <token id="10" string="cattle" />
            <token id="11" string="," />
            <token id="12" string="BSE" />
            <token id="13" string="has" />
            <token id="14" string="been" />
            <token id="15" string="&quot;" />
            <token id="16" string="vertically" />
            <token id="17" string="&quot;" />
            <token id="18" string="transmitted" />
            <token id="19" string="from" />
            <token id="20" string="cow" />
            <token id="21" string="to" />
            <token id="22" string="calf" />
          </tokens>
        </chunking>
        <chunking id="12" string="been `` vertically '' transmitted from cow to calf" type="VP">
          <tokens>
            <token id="14" string="been" />
            <token id="15" string="&quot;" />
            <token id="16" string="vertically" />
            <token id="17" string="&quot;" />
            <token id="18" string="transmitted" />
            <token id="19" string="from" />
            <token id="20" string="cow" />
            <token id="21" string="to" />
            <token id="22" string="calf" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="2">recently</governor>
          <dependent id="1">More</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">suggested</governor>
          <dependent id="2">recently</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">suggested</governor>
          <dependent id="4">researchers</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">suggested</governor>
          <dependent id="5">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">suggested</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">transmitted</governor>
          <dependent id="7">that</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">cattle</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">cattle</governor>
          <dependent id="9">some</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">transmitted</governor>
          <dependent id="10">cattle</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="18">transmitted</governor>
          <dependent id="12">BSE</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">transmitted</governor>
          <dependent id="13">has</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="18">transmitted</governor>
          <dependent id="14">been</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">transmitted</governor>
          <dependent id="16">vertically</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">suggested</governor>
          <dependent id="18">transmitted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">cow</governor>
          <dependent id="19">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">transmitted</governor>
          <dependent id="20">cow</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">calf</governor>
          <dependent id="21">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">cow</governor>
          <dependent id="22">calf</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="BSE" type="MISC" score="0.0">
          <tokens>
            <token id="12" string="BSE" />
          </tokens>
        </entity>
        <entity id="2" string="recently" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="recently" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="30" has_coreference="true">
      <content>Given a long incubation period, such a possibility could make the disease harder to eradicate.</content>
      <tokens>
        <token id="1" string="Given" lemma="give" stem="given" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="long" lemma="long" stem="long" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="incubation" lemma="incubation" stem="incub" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="period" lemma="period" stem="period" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="such" lemma="such" stem="such" pos="PDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="possibility" lemma="possibility" stem="possibl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="make" lemma="make" stem="make" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="true" />
        <token id="14" string="harder" lemma="harder" stem="harder" pos="RBR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="eradicate" lemma="eradicate" stem="erad" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (VBN Given) (NP (DT a) (JJ long) (NN incubation) (NN period))) (, ,) (NP (PDT such) (DT a) (NN possibility)) (VP (MD could) (VP (VB make) (NP (DT the) (NN disease)) (ADVP (RBR harder)) (S (VP (TO to) (VP (VB eradicate)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the disease" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="disease" />
          </tokens>
        </chunking>
        <chunking id="2" string="make the disease harder to eradicate" type="VP">
          <tokens>
            <token id="11" string="make" />
            <token id="12" string="the" />
            <token id="13" string="disease" />
            <token id="14" string="harder" />
            <token id="15" string="to" />
            <token id="16" string="eradicate" />
          </tokens>
        </chunking>
        <chunking id="3" string="to eradicate" type="VP">
          <tokens>
            <token id="15" string="to" />
            <token id="16" string="eradicate" />
          </tokens>
        </chunking>
        <chunking id="4" string="such a possibility" type="NP">
          <tokens>
            <token id="7" string="such" />
            <token id="8" string="a" />
            <token id="9" string="possibility" />
          </tokens>
        </chunking>
        <chunking id="5" string="could make the disease harder to eradicate" type="VP">
          <tokens>
            <token id="10" string="could" />
            <token id="11" string="make" />
            <token id="12" string="the" />
            <token id="13" string="disease" />
            <token id="14" string="harder" />
            <token id="15" string="to" />
            <token id="16" string="eradicate" />
          </tokens>
        </chunking>
        <chunking id="6" string="eradicate" type="VP">
          <tokens>
            <token id="16" string="eradicate" />
          </tokens>
        </chunking>
        <chunking id="7" string="a long incubation period" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="long" />
            <token id="4" string="incubation" />
            <token id="5" string="period" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="5">period</governor>
          <dependent id="1">Given</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">period</governor>
          <dependent id="2">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">period</governor>
          <dependent id="3">long</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">period</governor>
          <dependent id="4">incubation</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">make</governor>
          <dependent id="5">period</dependent>
        </dependency>
        <dependency type="det:predet">
          <governor id="9">possibility</governor>
          <dependent id="7">such</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">possibility</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">make</governor>
          <dependent id="9">possibility</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">make</governor>
          <dependent id="10">could</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">make</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">disease</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">make</governor>
          <dependent id="13">disease</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">make</governor>
          <dependent id="14">harder</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">eradicate</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">make</governor>
          <dependent id="16">eradicate</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="13" string="disease" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="31" has_coreference="true">
      <content>This month 19 cattle have died on farms where MAFF is conducting a seven-year experiment into the disease.</content>
      <tokens>
        <token id="1" string="This" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="2" string="month" lemma="month" stem="month" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="3" string="19" lemma="19" stem="19" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="4" string="cattle" lemma="cattle" stem="cattl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="died" lemma="die" stem="di" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="farms" lemma="farm" stem="farm" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="MAFF" lemma="MAFF" stem="maff" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="11" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="conducting" lemma="conduct" stem="conduct" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="seven-year" lemma="seven-year" stem="seven-year" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="true" />
        <token id="15" string="experiment" lemma="experiment" stem="experi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="true" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP-TMP (DT This) (NN month)) (NP (CD 19) (NNS cattle)) (VP (VBP have) (VP (VBN died) (PP (IN on) (NP (NP (NNS farms)) (SBAR (WHADVP (WRB where)) (S (NP (NNP MAFF)) (VP (VBZ is) (VP (VBG conducting) (NP (DT a) (JJ seven-year) (NN experiment)) (PP (IN into) (NP (DT the) (NN disease))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="MAFF" type="NP">
          <tokens>
            <token id="10" string="MAFF" />
          </tokens>
        </chunking>
        <chunking id="2" string="the disease" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="disease" />
          </tokens>
        </chunking>
        <chunking id="3" string="died on farms where MAFF is conducting a seven-year experiment into the disease" type="VP">
          <tokens>
            <token id="6" string="died" />
            <token id="7" string="on" />
            <token id="8" string="farms" />
            <token id="9" string="where" />
            <token id="10" string="MAFF" />
            <token id="11" string="is" />
            <token id="12" string="conducting" />
            <token id="13" string="a" />
            <token id="14" string="seven-year" />
            <token id="15" string="experiment" />
            <token id="16" string="into" />
            <token id="17" string="the" />
            <token id="18" string="disease" />
          </tokens>
        </chunking>
        <chunking id="4" string="a seven-year experiment" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="seven-year" />
            <token id="15" string="experiment" />
          </tokens>
        </chunking>
        <chunking id="5" string="farms where MAFF is conducting a seven-year experiment into the disease" type="NP">
          <tokens>
            <token id="8" string="farms" />
            <token id="9" string="where" />
            <token id="10" string="MAFF" />
            <token id="11" string="is" />
            <token id="12" string="conducting" />
            <token id="13" string="a" />
            <token id="14" string="seven-year" />
            <token id="15" string="experiment" />
            <token id="16" string="into" />
            <token id="17" string="the" />
            <token id="18" string="disease" />
          </tokens>
        </chunking>
        <chunking id="6" string="farms" type="NP">
          <tokens>
            <token id="8" string="farms" />
          </tokens>
        </chunking>
        <chunking id="7" string="have died on farms where MAFF is conducting a seven-year experiment into the disease" type="VP">
          <tokens>
            <token id="5" string="have" />
            <token id="6" string="died" />
            <token id="7" string="on" />
            <token id="8" string="farms" />
            <token id="9" string="where" />
            <token id="10" string="MAFF" />
            <token id="11" string="is" />
            <token id="12" string="conducting" />
            <token id="13" string="a" />
            <token id="14" string="seven-year" />
            <token id="15" string="experiment" />
            <token id="16" string="into" />
            <token id="17" string="the" />
            <token id="18" string="disease" />
          </tokens>
        </chunking>
        <chunking id="8" string="where" type="WHADVP">
          <tokens>
            <token id="9" string="where" />
          </tokens>
        </chunking>
        <chunking id="9" string="is conducting a seven-year experiment into the disease" type="VP">
          <tokens>
            <token id="11" string="is" />
            <token id="12" string="conducting" />
            <token id="13" string="a" />
            <token id="14" string="seven-year" />
            <token id="15" string="experiment" />
            <token id="16" string="into" />
            <token id="17" string="the" />
            <token id="18" string="disease" />
          </tokens>
        </chunking>
        <chunking id="10" string="19 cattle" type="NP">
          <tokens>
            <token id="3" string="19" />
            <token id="4" string="cattle" />
          </tokens>
        </chunking>
        <chunking id="11" string="conducting a seven-year experiment into the disease" type="VP">
          <tokens>
            <token id="12" string="conducting" />
            <token id="13" string="a" />
            <token id="14" string="seven-year" />
            <token id="15" string="experiment" />
            <token id="16" string="into" />
            <token id="17" string="the" />
            <token id="18" string="disease" />
          </tokens>
        </chunking>
        <chunking id="12" string="where MAFF is conducting a seven-year experiment into the disease" type="SBAR">
          <tokens>
            <token id="9" string="where" />
            <token id="10" string="MAFF" />
            <token id="11" string="is" />
            <token id="12" string="conducting" />
            <token id="13" string="a" />
            <token id="14" string="seven-year" />
            <token id="15" string="experiment" />
            <token id="16" string="into" />
            <token id="17" string="the" />
            <token id="18" string="disease" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">month</governor>
          <dependent id="1">This</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="6">died</governor>
          <dependent id="2">month</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="4">cattle</governor>
          <dependent id="3">19</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">died</governor>
          <dependent id="4">cattle</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">died</governor>
          <dependent id="5">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">died</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">farms</governor>
          <dependent id="7">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">died</governor>
          <dependent id="8">farms</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">conducting</governor>
          <dependent id="9">where</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">conducting</governor>
          <dependent id="10">MAFF</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">conducting</governor>
          <dependent id="11">is</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="8">farms</governor>
          <dependent id="12">conducting</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">experiment</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">experiment</governor>
          <dependent id="14">seven-year</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">conducting</governor>
          <dependent id="15">experiment</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">disease</governor>
          <dependent id="16">into</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">disease</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">conducting</governor>
          <dependent id="18">disease</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="This month" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="This" />
            <token id="2" string="month" />
          </tokens>
        </entity>
        <entity id="2" string="MAFF" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="10" string="MAFF" />
          </tokens>
        </entity>
        <entity id="3" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="18" string="disease" />
          </tokens>
        </entity>
        <entity id="4" string="19" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="19" />
          </tokens>
        </entity>
        <entity id="5" string="seven-year" type="DURATION" score="0.0">
          <tokens>
            <token id="14" string="seven-year" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="32" has_coreference="true">
      <content>It is a daunting possibility for the farming industry, which has responded angrily.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="daunting" lemma="daunting" stem="daunt" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="possibility" lemma="possibility" stem="possibl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="8" string="farming" lemma="farm" stem="farm" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="9" string="industry" lemma="industry" stem="industri" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="responded" lemma="respond" stem="respond" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="angrily" lemma="angrily" stem="angrili" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBZ is) (NP (NP (DT a) (JJ daunting) (NN possibility)) (PP (IN for) (NP (NP (DT the) (VBG farming) (NN industry)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ has) (VP (VBN responded) (ADVP (RB angrily)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the farming industry , which has responded angrily" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="farming" />
            <token id="9" string="industry" />
            <token id="10" string="," />
            <token id="11" string="which" />
            <token id="12" string="has" />
            <token id="13" string="responded" />
            <token id="14" string="angrily" />
          </tokens>
        </chunking>
        <chunking id="2" string="a daunting possibility for the farming industry , which has responded angrily" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="daunting" />
            <token id="5" string="possibility" />
            <token id="6" string="for" />
            <token id="7" string="the" />
            <token id="8" string="farming" />
            <token id="9" string="industry" />
            <token id="10" string="," />
            <token id="11" string="which" />
            <token id="12" string="has" />
            <token id="13" string="responded" />
            <token id="14" string="angrily" />
          </tokens>
        </chunking>
        <chunking id="3" string="is a daunting possibility for the farming industry , which has responded angrily" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="a" />
            <token id="4" string="daunting" />
            <token id="5" string="possibility" />
            <token id="6" string="for" />
            <token id="7" string="the" />
            <token id="8" string="farming" />
            <token id="9" string="industry" />
            <token id="10" string="," />
            <token id="11" string="which" />
            <token id="12" string="has" />
            <token id="13" string="responded" />
            <token id="14" string="angrily" />
          </tokens>
        </chunking>
        <chunking id="4" string="responded angrily" type="VP">
          <tokens>
            <token id="13" string="responded" />
            <token id="14" string="angrily" />
          </tokens>
        </chunking>
        <chunking id="5" string="has responded angrily" type="VP">
          <tokens>
            <token id="12" string="has" />
            <token id="13" string="responded" />
            <token id="14" string="angrily" />
          </tokens>
        </chunking>
        <chunking id="6" string="the farming industry" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="farming" />
            <token id="9" string="industry" />
          </tokens>
        </chunking>
        <chunking id="7" string="which has responded angrily" type="SBAR">
          <tokens>
            <token id="11" string="which" />
            <token id="12" string="has" />
            <token id="13" string="responded" />
            <token id="14" string="angrily" />
          </tokens>
        </chunking>
        <chunking id="8" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="9" string="a daunting possibility" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="daunting" />
            <token id="5" string="possibility" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">possibility</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">possibility</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">possibility</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">possibility</governor>
          <dependent id="4">daunting</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">possibility</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">industry</governor>
          <dependent id="6">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">industry</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">industry</governor>
          <dependent id="8">farming</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">possibility</governor>
          <dependent id="9">industry</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">responded</governor>
          <dependent id="11">which</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">responded</governor>
          <dependent id="12">has</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="9">industry</governor>
          <dependent id="13">responded</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">responded</governor>
          <dependent id="14">angrily</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="33" has_coreference="true">
      <content>&amp;quot;There is no evidence that this disturbing disease can be transferred from cow to calf,&amp;quot; Farmers Weekly insisted last week.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="evidence" lemma="evidence" stem="evid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="disturbing" lemma="disturbing" stem="disturb" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="10" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="transferred" lemma="transfer" stem="transfer" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="cow" lemma="cow" stem="cow" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="calf" lemma="calf" stem="calf" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Farmers" lemma="Farmers" stem="farmer" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="20" string="Weekly" lemma="Weekly" stem="weekli" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="21" string="insisted" lemma="insist" stem="insist" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="23" string="week" lemma="week" stem="week" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (EX There)) (VP (VBZ is) (NP (DT no) (NN evidence)) (SBAR (IN that) (S (NP (DT this) (JJ disturbing) (NN disease)) (VP (MD can) (VP (VB be) (VP (VBN transferred) (PP (IN from) (NP (NN cow))) (PP (TO to) (NP (NN calf)))))))))) (, ,) ('' '') (NP (NNP Farmers) (NNP Weekly)) (VP (VBD insisted) (NP-TMP (JJ last) (NN week))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="transferred from cow to calf" type="VP">
          <tokens>
            <token id="12" string="transferred" />
            <token id="13" string="from" />
            <token id="14" string="cow" />
            <token id="15" string="to" />
            <token id="16" string="calf" />
          </tokens>
        </chunking>
        <chunking id="2" string="that this disturbing disease can be transferred from cow to calf" type="SBAR">
          <tokens>
            <token id="6" string="that" />
            <token id="7" string="this" />
            <token id="8" string="disturbing" />
            <token id="9" string="disease" />
            <token id="10" string="can" />
            <token id="11" string="be" />
            <token id="12" string="transferred" />
            <token id="13" string="from" />
            <token id="14" string="cow" />
            <token id="15" string="to" />
            <token id="16" string="calf" />
          </tokens>
        </chunking>
        <chunking id="3" string="There" type="NP">
          <tokens>
            <token id="2" string="There" />
          </tokens>
        </chunking>
        <chunking id="4" string="can be transferred from cow to calf" type="VP">
          <tokens>
            <token id="10" string="can" />
            <token id="11" string="be" />
            <token id="12" string="transferred" />
            <token id="13" string="from" />
            <token id="14" string="cow" />
            <token id="15" string="to" />
            <token id="16" string="calf" />
          </tokens>
        </chunking>
        <chunking id="5" string="insisted last week" type="VP">
          <tokens>
            <token id="21" string="insisted" />
            <token id="22" string="last" />
            <token id="23" string="week" />
          </tokens>
        </chunking>
        <chunking id="6" string="this disturbing disease" type="NP">
          <tokens>
            <token id="7" string="this" />
            <token id="8" string="disturbing" />
            <token id="9" string="disease" />
          </tokens>
        </chunking>
        <chunking id="7" string="calf" type="NP">
          <tokens>
            <token id="16" string="calf" />
          </tokens>
        </chunking>
        <chunking id="8" string="no evidence" type="NP">
          <tokens>
            <token id="4" string="no" />
            <token id="5" string="evidence" />
          </tokens>
        </chunking>
        <chunking id="9" string="cow" type="NP">
          <tokens>
            <token id="14" string="cow" />
          </tokens>
        </chunking>
        <chunking id="10" string="be transferred from cow to calf" type="VP">
          <tokens>
            <token id="11" string="be" />
            <token id="12" string="transferred" />
            <token id="13" string="from" />
            <token id="14" string="cow" />
            <token id="15" string="to" />
            <token id="16" string="calf" />
          </tokens>
        </chunking>
        <chunking id="11" string="Farmers Weekly" type="NP">
          <tokens>
            <token id="19" string="Farmers" />
            <token id="20" string="Weekly" />
          </tokens>
        </chunking>
        <chunking id="12" string="is no evidence that this disturbing disease can be transferred from cow to calf" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="no" />
            <token id="5" string="evidence" />
            <token id="6" string="that" />
            <token id="7" string="this" />
            <token id="8" string="disturbing" />
            <token id="9" string="disease" />
            <token id="10" string="can" />
            <token id="11" string="be" />
            <token id="12" string="transferred" />
            <token id="13" string="from" />
            <token id="14" string="cow" />
            <token id="15" string="to" />
            <token id="16" string="calf" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="3">is</governor>
          <dependent id="2">There</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="21">insisted</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">evidence</governor>
          <dependent id="4">no</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">is</governor>
          <dependent id="5">evidence</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">transferred</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">disease</governor>
          <dependent id="7">this</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">disease</governor>
          <dependent id="8">disturbing</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="12">transferred</governor>
          <dependent id="9">disease</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">transferred</governor>
          <dependent id="10">can</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="12">transferred</governor>
          <dependent id="11">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">is</governor>
          <dependent id="12">transferred</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">cow</governor>
          <dependent id="13">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">transferred</governor>
          <dependent id="14">cow</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">calf</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">transferred</governor>
          <dependent id="16">calf</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Weekly</governor>
          <dependent id="19">Farmers</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">insisted</governor>
          <dependent id="20">Weekly</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="21">insisted</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">week</governor>
          <dependent id="22">last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="21">insisted</governor>
          <dependent id="23">week</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="9" string="disease" />
          </tokens>
        </entity>
        <entity id="2" string="last week" type="DATE" score="0.0">
          <tokens>
            <token id="22" string="last" />
            <token id="23" string="week" />
          </tokens>
        </entity>
        <entity id="3" string="Farmers Weekly" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="19" string="Farmers" />
            <token id="20" string="Weekly" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="34" has_coreference="true">
      <content>More cautiously, MAFF told The Sunday Telegraph: &amp;quot;We have never said we have ruled out the possibility of maternal transmission, but even if it occurs, our scientists do not believe it will do anything other than lengthen the time before the disease is eradicated.&amp;quot;</content>
      <tokens>
        <token id="1" string="More" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="cautiously" lemma="cautiously" stem="cautious" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="MAFF" lemma="MAFF" stem="maff" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="5" string="told" lemma="tell" stem="told" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="Sunday" lemma="Sunday" stem="sundai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="8" string="Telegraph" lemma="Telegraph" stem="telegraph" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="said" lemma="say" stem="said" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="ruled" lemma="rule" stem="rule" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="possibility" lemma="possibility" stem="possibl" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="maternal" lemma="maternal" stem="matern" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="transmission" lemma="transmission" stem="transmiss" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="occurs" lemma="occur" stem="occur" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="our" lemma="we" stem="our" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="32" string="scientists" lemma="scientist" stem="scientist" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="33" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="believe" lemma="believe" stem="believ" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="do" lemma="do" stem="do" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="anything" lemma="anything" stem="anyth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="lengthen" lemma="lengthen" stem="lengthen" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="47" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="true" />
        <token id="48" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="49" string="eradicated" lemma="eradicate" stem="erad" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="50" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="51" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RBR More) (RB cautiously)) (, ,) (NP (NNP MAFF)) (VP (VBD told) (NP (DT The) (NNP Sunday) (NNP Telegraph)) (: :) (`` ``) (S (S (NP (PRP We)) (VP (VBP have) (ADVP (RB never)) (VP (VBN said) (SBAR (S (NP (PRP we)) (VP (VBP have) (VP (VBN ruled) (PRT (RP out)) (NP (NP (DT the) (NN possibility)) (PP (IN of) (NP (JJ maternal) (NN transmission))))))))))) (, ,) (CC but) (S (SBAR (RB even) (IN if) (S (NP (PRP it)) (VP (VBZ occurs)))) (, ,) (NP (PRP$ our) (NNS scientists)) (VP (VBP do) (RB not) (VP (VB believe) (SBAR (S (NP (PRP it)) (VP (MD will) (VP (VP (VB do) (NP (NN anything) (JJ other))) (IN than) (VP (VB lengthen) (NP (DT the) (NN time))) (SBAR (IN before) (S (NP (DT the) (NN disease)) (VP (VBZ is) (VP (VBN eradicated)))))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="The Sunday Telegraph" type="NP">
          <tokens>
            <token id="6" string="The" />
            <token id="7" string="Sunday" />
            <token id="8" string="Telegraph" />
          </tokens>
        </chunking>
        <chunking id="2" string="have ruled out the possibility of maternal transmission" type="VP">
          <tokens>
            <token id="16" string="have" />
            <token id="17" string="ruled" />
            <token id="18" string="out" />
            <token id="19" string="the" />
            <token id="20" string="possibility" />
            <token id="21" string="of" />
            <token id="22" string="maternal" />
            <token id="23" string="transmission" />
          </tokens>
        </chunking>
        <chunking id="3" string="it" type="NP">
          <tokens>
            <token id="28" string="it" />
          </tokens>
        </chunking>
        <chunking id="4" string="it will do anything other than lengthen the time before the disease is eradicated" type="SBAR">
          <tokens>
            <token id="36" string="it" />
            <token id="37" string="will" />
            <token id="38" string="do" />
            <token id="39" string="anything" />
            <token id="40" string="other" />
            <token id="41" string="than" />
            <token id="42" string="lengthen" />
            <token id="43" string="the" />
            <token id="44" string="time" />
            <token id="45" string="before" />
            <token id="46" string="the" />
            <token id="47" string="disease" />
            <token id="48" string="is" />
            <token id="49" string="eradicated" />
          </tokens>
        </chunking>
        <chunking id="5" string="We" type="NP">
          <tokens>
            <token id="11" string="We" />
          </tokens>
        </chunking>
        <chunking id="6" string="before the disease is eradicated" type="SBAR">
          <tokens>
            <token id="45" string="before" />
            <token id="46" string="the" />
            <token id="47" string="disease" />
            <token id="48" string="is" />
            <token id="49" string="eradicated" />
          </tokens>
        </chunking>
        <chunking id="7" string="MAFF" type="NP">
          <tokens>
            <token id="4" string="MAFF" />
          </tokens>
        </chunking>
        <chunking id="8" string="the disease" type="NP">
          <tokens>
            <token id="46" string="the" />
            <token id="47" string="disease" />
          </tokens>
        </chunking>
        <chunking id="9" string="said we have ruled out the possibility of maternal transmission" type="VP">
          <tokens>
            <token id="14" string="said" />
            <token id="15" string="we" />
            <token id="16" string="have" />
            <token id="17" string="ruled" />
            <token id="18" string="out" />
            <token id="19" string="the" />
            <token id="20" string="possibility" />
            <token id="21" string="of" />
            <token id="22" string="maternal" />
            <token id="23" string="transmission" />
          </tokens>
        </chunking>
        <chunking id="10" string="we have ruled out the possibility of maternal transmission" type="SBAR">
          <tokens>
            <token id="15" string="we" />
            <token id="16" string="have" />
            <token id="17" string="ruled" />
            <token id="18" string="out" />
            <token id="19" string="the" />
            <token id="20" string="possibility" />
            <token id="21" string="of" />
            <token id="22" string="maternal" />
            <token id="23" string="transmission" />
          </tokens>
        </chunking>
        <chunking id="11" string="lengthen the time" type="VP">
          <tokens>
            <token id="42" string="lengthen" />
            <token id="43" string="the" />
            <token id="44" string="time" />
          </tokens>
        </chunking>
        <chunking id="12" string="told The Sunday Telegraph : `` We have never said we have ruled out the possibility of maternal transmission , but even if it occurs , our scientists do not believe it will do anything other than lengthen the time before the disease is eradicated" type="VP">
          <tokens>
            <token id="5" string="told" />
            <token id="6" string="The" />
            <token id="7" string="Sunday" />
            <token id="8" string="Telegraph" />
            <token id="9" string=":" />
            <token id="10" string="&quot;" />
            <token id="11" string="We" />
            <token id="12" string="have" />
            <token id="13" string="never" />
            <token id="14" string="said" />
            <token id="15" string="we" />
            <token id="16" string="have" />
            <token id="17" string="ruled" />
            <token id="18" string="out" />
            <token id="19" string="the" />
            <token id="20" string="possibility" />
            <token id="21" string="of" />
            <token id="22" string="maternal" />
            <token id="23" string="transmission" />
            <token id="24" string="," />
            <token id="25" string="but" />
            <token id="26" string="even" />
            <token id="27" string="if" />
            <token id="28" string="it" />
            <token id="29" string="occurs" />
            <token id="30" string="," />
            <token id="31" string="our" />
            <token id="32" string="scientists" />
            <token id="33" string="do" />
            <token id="34" string="not" />
            <token id="35" string="believe" />
            <token id="36" string="it" />
            <token id="37" string="will" />
            <token id="38" string="do" />
            <token id="39" string="anything" />
            <token id="40" string="other" />
            <token id="41" string="than" />
            <token id="42" string="lengthen" />
            <token id="43" string="the" />
            <token id="44" string="time" />
            <token id="45" string="before" />
            <token id="46" string="the" />
            <token id="47" string="disease" />
            <token id="48" string="is" />
            <token id="49" string="eradicated" />
          </tokens>
        </chunking>
        <chunking id="13" string="the time" type="NP">
          <tokens>
            <token id="43" string="the" />
            <token id="44" string="time" />
          </tokens>
        </chunking>
        <chunking id="14" string="eradicated" type="VP">
          <tokens>
            <token id="49" string="eradicated" />
          </tokens>
        </chunking>
        <chunking id="15" string="have never said we have ruled out the possibility of maternal transmission" type="VP">
          <tokens>
            <token id="12" string="have" />
            <token id="13" string="never" />
            <token id="14" string="said" />
            <token id="15" string="we" />
            <token id="16" string="have" />
            <token id="17" string="ruled" />
            <token id="18" string="out" />
            <token id="19" string="the" />
            <token id="20" string="possibility" />
            <token id="21" string="of" />
            <token id="22" string="maternal" />
            <token id="23" string="transmission" />
          </tokens>
        </chunking>
        <chunking id="16" string="do anything other than lengthen the time before the disease is eradicated" type="VP">
          <tokens>
            <token id="38" string="do" />
            <token id="39" string="anything" />
            <token id="40" string="other" />
            <token id="41" string="than" />
            <token id="42" string="lengthen" />
            <token id="43" string="the" />
            <token id="44" string="time" />
            <token id="45" string="before" />
            <token id="46" string="the" />
            <token id="47" string="disease" />
            <token id="48" string="is" />
            <token id="49" string="eradicated" />
          </tokens>
        </chunking>
        <chunking id="17" string="maternal transmission" type="NP">
          <tokens>
            <token id="22" string="maternal" />
            <token id="23" string="transmission" />
          </tokens>
        </chunking>
        <chunking id="18" string="our scientists" type="NP">
          <tokens>
            <token id="31" string="our" />
            <token id="32" string="scientists" />
          </tokens>
        </chunking>
        <chunking id="19" string="ruled out the possibility of maternal transmission" type="VP">
          <tokens>
            <token id="17" string="ruled" />
            <token id="18" string="out" />
            <token id="19" string="the" />
            <token id="20" string="possibility" />
            <token id="21" string="of" />
            <token id="22" string="maternal" />
            <token id="23" string="transmission" />
          </tokens>
        </chunking>
        <chunking id="20" string="do not believe it will do anything other than lengthen the time before the disease is eradicated" type="VP">
          <tokens>
            <token id="33" string="do" />
            <token id="34" string="not" />
            <token id="35" string="believe" />
            <token id="36" string="it" />
            <token id="37" string="will" />
            <token id="38" string="do" />
            <token id="39" string="anything" />
            <token id="40" string="other" />
            <token id="41" string="than" />
            <token id="42" string="lengthen" />
            <token id="43" string="the" />
            <token id="44" string="time" />
            <token id="45" string="before" />
            <token id="46" string="the" />
            <token id="47" string="disease" />
            <token id="48" string="is" />
            <token id="49" string="eradicated" />
          </tokens>
        </chunking>
        <chunking id="21" string="even if it occurs" type="SBAR">
          <tokens>
            <token id="26" string="even" />
            <token id="27" string="if" />
            <token id="28" string="it" />
            <token id="29" string="occurs" />
          </tokens>
        </chunking>
        <chunking id="22" string="do anything other" type="VP">
          <tokens>
            <token id="38" string="do" />
            <token id="39" string="anything" />
            <token id="40" string="other" />
          </tokens>
        </chunking>
        <chunking id="23" string="we" type="NP">
          <tokens>
            <token id="15" string="we" />
          </tokens>
        </chunking>
        <chunking id="24" string="occurs" type="VP">
          <tokens>
            <token id="29" string="occurs" />
          </tokens>
        </chunking>
        <chunking id="25" string="will do anything other than lengthen the time before the disease is eradicated" type="VP">
          <tokens>
            <token id="37" string="will" />
            <token id="38" string="do" />
            <token id="39" string="anything" />
            <token id="40" string="other" />
            <token id="41" string="than" />
            <token id="42" string="lengthen" />
            <token id="43" string="the" />
            <token id="44" string="time" />
            <token id="45" string="before" />
            <token id="46" string="the" />
            <token id="47" string="disease" />
            <token id="48" string="is" />
            <token id="49" string="eradicated" />
          </tokens>
        </chunking>
        <chunking id="26" string="believe it will do anything other than lengthen the time before the disease is eradicated" type="VP">
          <tokens>
            <token id="35" string="believe" />
            <token id="36" string="it" />
            <token id="37" string="will" />
            <token id="38" string="do" />
            <token id="39" string="anything" />
            <token id="40" string="other" />
            <token id="41" string="than" />
            <token id="42" string="lengthen" />
            <token id="43" string="the" />
            <token id="44" string="time" />
            <token id="45" string="before" />
            <token id="46" string="the" />
            <token id="47" string="disease" />
            <token id="48" string="is" />
            <token id="49" string="eradicated" />
          </tokens>
        </chunking>
        <chunking id="27" string="is eradicated" type="VP">
          <tokens>
            <token id="48" string="is" />
            <token id="49" string="eradicated" />
          </tokens>
        </chunking>
        <chunking id="28" string="the possibility of maternal transmission" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="possibility" />
            <token id="21" string="of" />
            <token id="22" string="maternal" />
            <token id="23" string="transmission" />
          </tokens>
        </chunking>
        <chunking id="29" string="anything other" type="NP">
          <tokens>
            <token id="39" string="anything" />
            <token id="40" string="other" />
          </tokens>
        </chunking>
        <chunking id="30" string="the possibility" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="possibility" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="2">cautiously</governor>
          <dependent id="1">More</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">told</governor>
          <dependent id="2">cautiously</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">told</governor>
          <dependent id="4">MAFF</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">told</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">Telegraph</governor>
          <dependent id="6">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Telegraph</governor>
          <dependent id="7">Sunday</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">told</governor>
          <dependent id="8">Telegraph</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">said</governor>
          <dependent id="11">We</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">said</governor>
          <dependent id="12">have</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="14">said</governor>
          <dependent id="13">never</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">told</governor>
          <dependent id="14">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">ruled</governor>
          <dependent id="15">we</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="17">ruled</governor>
          <dependent id="16">have</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">said</governor>
          <dependent id="17">ruled</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="17">ruled</governor>
          <dependent id="18">out</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">possibility</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">ruled</governor>
          <dependent id="20">possibility</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">transmission</governor>
          <dependent id="21">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">transmission</governor>
          <dependent id="22">maternal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">possibility</governor>
          <dependent id="23">transmission</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">said</governor>
          <dependent id="25">but</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="29">occurs</governor>
          <dependent id="26">even</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="29">occurs</governor>
          <dependent id="27">if</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">occurs</governor>
          <dependent id="28">it</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="35">believe</governor>
          <dependent id="29">occurs</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="32">scientists</governor>
          <dependent id="31">our</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="35">believe</governor>
          <dependent id="32">scientists</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="35">believe</governor>
          <dependent id="33">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="35">believe</governor>
          <dependent id="34">not</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">said</governor>
          <dependent id="35">believe</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="38">do</governor>
          <dependent id="36">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="38">do</governor>
          <dependent id="37">will</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="35">believe</governor>
          <dependent id="38">do</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="38">do</governor>
          <dependent id="39">anything</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="39">anything</governor>
          <dependent id="40">other</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="38">do</governor>
          <dependent id="41">than</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="38">do</governor>
          <dependent id="42">lengthen</dependent>
        </dependency>
        <dependency type="det">
          <governor id="44">time</governor>
          <dependent id="43">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="42">lengthen</governor>
          <dependent id="44">time</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="49">eradicated</governor>
          <dependent id="45">before</dependent>
        </dependency>
        <dependency type="det">
          <governor id="47">disease</governor>
          <dependent id="46">the</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="49">eradicated</governor>
          <dependent id="47">disease</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="49">eradicated</governor>
          <dependent id="48">is</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="38">do</governor>
          <dependent id="49">eradicated</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="MAFF" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="4" string="MAFF" />
          </tokens>
        </entity>
        <entity id="2" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="47" string="disease" />
          </tokens>
        </entity>
        <entity id="3" string="Sunday" type="DATE" score="0.0">
          <tokens>
            <token id="7" string="Sunday" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="35" has_coreference="true">
      <content>So how long will it be before the epidemic is ended?</content>
      <tokens>
        <token id="1" string="So" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="how" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="long" lemma="long" stem="long" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="epidemic" lemma="epidemic" stem="epidem" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="ended" lemma="end" stem="end" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SBARQ (RB So) (WHADVP (WRB how) (RB long)) (SQ (MD will) (NP (PRP it)) (VP (VB be) (SBAR (IN before) (S (NP (DT the) (JJ epidemic)) (VP (VBZ is) (VP (VBN ended))))))) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="before the epidemic is ended" type="SBAR">
          <tokens>
            <token id="7" string="before" />
            <token id="8" string="the" />
            <token id="9" string="epidemic" />
            <token id="10" string="is" />
            <token id="11" string="ended" />
          </tokens>
        </chunking>
        <chunking id="2" string="is ended" type="VP">
          <tokens>
            <token id="10" string="is" />
            <token id="11" string="ended" />
          </tokens>
        </chunking>
        <chunking id="3" string="it" type="NP">
          <tokens>
            <token id="5" string="it" />
          </tokens>
        </chunking>
        <chunking id="4" string="be before the epidemic is ended" type="VP">
          <tokens>
            <token id="6" string="be" />
            <token id="7" string="before" />
            <token id="8" string="the" />
            <token id="9" string="epidemic" />
            <token id="10" string="is" />
            <token id="11" string="ended" />
          </tokens>
        </chunking>
        <chunking id="5" string="the epidemic" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="epidemic" />
          </tokens>
        </chunking>
        <chunking id="6" string="ended" type="VP">
          <tokens>
            <token id="11" string="ended" />
          </tokens>
        </chunking>
        <chunking id="7" string="how long" type="WHADVP">
          <tokens>
            <token id="2" string="how" />
            <token id="3" string="long" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="6">be</governor>
          <dependent id="1">So</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">long</governor>
          <dependent id="2">how</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">be</governor>
          <dependent id="3">long</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">be</governor>
          <dependent id="4">will</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">be</governor>
          <dependent id="5">it</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">be</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">ended</governor>
          <dependent id="7">before</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">epidemic</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="11">ended</governor>
          <dependent id="9">epidemic</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="11">ended</governor>
          <dependent id="10">is</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="6">be</governor>
          <dependent id="11">ended</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="36" has_coreference="true">
      <content>Richard North, a former environmental health officer turned consultant, and a contributor to The Sunday Telegraph, believes that MAFF&amp;apost;s statistics are being skewed to produce more optimistic figures -- claims not surprisingly rejected by the ministry.</content>
      <tokens>
        <token id="1" string="Richard" lemma="Richard" stem="richard" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="North" lemma="North" stem="north" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="former" lemma="former" stem="former" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="environmental" lemma="environmental" stem="environment" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="health" lemma="health" stem="health" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="turned" lemma="turn" stem="turn" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="consultant" lemma="consultant" stem="consult" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="contributor" lemma="contributor" stem="contributor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Sunday" lemma="Sunday" stem="sundai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="18" string="Telegraph" lemma="Telegraph" stem="telegraph" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="believes" lemma="believe" stem="believ" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="MAFF" lemma="MAFF" stem="maff" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="23" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="statistics" lemma="statistics" stem="statist" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="being" lemma="be" stem="be" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="skewed" lemma="skew" stem="skew" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="produce" lemma="produce" stem="produc" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="optimistic" lemma="optimistic" stem="optimist" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="figures" lemma="figure" stem="figur" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="claims" lemma="claim" stem="claim" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="surprisingly" lemma="surprisingly" stem="surprisingli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="rejected" lemma="reject" stem="reject" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="40" string="ministry" lemma="ministry" stem="ministri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="41" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (NNP Richard) (NNP North)) (, ,) (NP (DT a) (JJ former) (NX (JJ environmental) (NN health) (NN officer)))) (VP (VBD turned) (NP (NN consultant)))) (, ,) (CC and) (S (NP (NP (DT a) (NN contributor)) (PP (TO to) (NP (DT The) (NNP Sunday) (NNP Telegraph))) (, ,) (VP (VBZ believes) (SBAR (IN that) (S (NP (NP (NNP MAFF) (POS 's)) (NNS statistics)) (VP (VBP are) (VP (VBG being) (VP (VBN skewed) (S (VP (TO to) (VP (VB produce) (NP (ADJP (RBR more) (JJ optimistic)) (NNS figures))))))))))) (: --)) (VP (VBZ claims) (RB not) (ADVP (RB surprisingly)) (VP (VBN rejected) (PP (IN by) (NP (DT the) (NN ministry)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="are being skewed to produce more optimistic figures" type="VP">
          <tokens>
            <token id="25" string="are" />
            <token id="26" string="being" />
            <token id="27" string="skewed" />
            <token id="28" string="to" />
            <token id="29" string="produce" />
            <token id="30" string="more" />
            <token id="31" string="optimistic" />
            <token id="32" string="figures" />
          </tokens>
        </chunking>
        <chunking id="2" string="produce more optimistic figures" type="VP">
          <tokens>
            <token id="29" string="produce" />
            <token id="30" string="more" />
            <token id="31" string="optimistic" />
            <token id="32" string="figures" />
          </tokens>
        </chunking>
        <chunking id="3" string="Richard North" type="NP">
          <tokens>
            <token id="1" string="Richard" />
            <token id="2" string="North" />
          </tokens>
        </chunking>
        <chunking id="4" string="that MAFF 's statistics are being skewed to produce more optimistic figures" type="SBAR">
          <tokens>
            <token id="21" string="that" />
            <token id="22" string="MAFF" />
            <token id="23" string="'s" />
            <token id="24" string="statistics" />
            <token id="25" string="are" />
            <token id="26" string="being" />
            <token id="27" string="skewed" />
            <token id="28" string="to" />
            <token id="29" string="produce" />
            <token id="30" string="more" />
            <token id="31" string="optimistic" />
            <token id="32" string="figures" />
          </tokens>
        </chunking>
        <chunking id="5" string="a former environmental health officer" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="former" />
            <token id="6" string="environmental" />
            <token id="7" string="health" />
            <token id="8" string="officer" />
          </tokens>
        </chunking>
        <chunking id="6" string="The Sunday Telegraph" type="NP">
          <tokens>
            <token id="16" string="The" />
            <token id="17" string="Sunday" />
            <token id="18" string="Telegraph" />
          </tokens>
        </chunking>
        <chunking id="7" string="skewed to produce more optimistic figures" type="VP">
          <tokens>
            <token id="27" string="skewed" />
            <token id="28" string="to" />
            <token id="29" string="produce" />
            <token id="30" string="more" />
            <token id="31" string="optimistic" />
            <token id="32" string="figures" />
          </tokens>
        </chunking>
        <chunking id="8" string="claims not surprisingly rejected by the ministry" type="VP">
          <tokens>
            <token id="34" string="claims" />
            <token id="35" string="not" />
            <token id="36" string="surprisingly" />
            <token id="37" string="rejected" />
            <token id="38" string="by" />
            <token id="39" string="the" />
            <token id="40" string="ministry" />
          </tokens>
        </chunking>
        <chunking id="9" string="a contributor to The Sunday Telegraph , believes that MAFF 's statistics are being skewed to produce more optimistic figures --" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="contributor" />
            <token id="15" string="to" />
            <token id="16" string="The" />
            <token id="17" string="Sunday" />
            <token id="18" string="Telegraph" />
            <token id="19" string="," />
            <token id="20" string="believes" />
            <token id="21" string="that" />
            <token id="22" string="MAFF" />
            <token id="23" string="'s" />
            <token id="24" string="statistics" />
            <token id="25" string="are" />
            <token id="26" string="being" />
            <token id="27" string="skewed" />
            <token id="28" string="to" />
            <token id="29" string="produce" />
            <token id="30" string="more" />
            <token id="31" string="optimistic" />
            <token id="32" string="figures" />
            <token id="33" string="--" />
          </tokens>
        </chunking>
        <chunking id="10" string="more optimistic figures" type="NP">
          <tokens>
            <token id="30" string="more" />
            <token id="31" string="optimistic" />
            <token id="32" string="figures" />
          </tokens>
        </chunking>
        <chunking id="11" string="more optimistic" type="ADJP">
          <tokens>
            <token id="30" string="more" />
            <token id="31" string="optimistic" />
          </tokens>
        </chunking>
        <chunking id="12" string="MAFF 's" type="NP">
          <tokens>
            <token id="22" string="MAFF" />
            <token id="23" string="'s" />
          </tokens>
        </chunking>
        <chunking id="13" string="consultant" type="NP">
          <tokens>
            <token id="10" string="consultant" />
          </tokens>
        </chunking>
        <chunking id="14" string="believes that MAFF 's statistics are being skewed to produce more optimistic figures" type="VP">
          <tokens>
            <token id="20" string="believes" />
            <token id="21" string="that" />
            <token id="22" string="MAFF" />
            <token id="23" string="'s" />
            <token id="24" string="statistics" />
            <token id="25" string="are" />
            <token id="26" string="being" />
            <token id="27" string="skewed" />
            <token id="28" string="to" />
            <token id="29" string="produce" />
            <token id="30" string="more" />
            <token id="31" string="optimistic" />
            <token id="32" string="figures" />
          </tokens>
        </chunking>
        <chunking id="15" string="a contributor" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="contributor" />
          </tokens>
        </chunking>
        <chunking id="16" string="MAFF 's statistics" type="NP">
          <tokens>
            <token id="22" string="MAFF" />
            <token id="23" string="'s" />
            <token id="24" string="statistics" />
          </tokens>
        </chunking>
        <chunking id="17" string="rejected by the ministry" type="VP">
          <tokens>
            <token id="37" string="rejected" />
            <token id="38" string="by" />
            <token id="39" string="the" />
            <token id="40" string="ministry" />
          </tokens>
        </chunking>
        <chunking id="18" string="being skewed to produce more optimistic figures" type="VP">
          <tokens>
            <token id="26" string="being" />
            <token id="27" string="skewed" />
            <token id="28" string="to" />
            <token id="29" string="produce" />
            <token id="30" string="more" />
            <token id="31" string="optimistic" />
            <token id="32" string="figures" />
          </tokens>
        </chunking>
        <chunking id="19" string="the ministry" type="NP">
          <tokens>
            <token id="39" string="the" />
            <token id="40" string="ministry" />
          </tokens>
        </chunking>
        <chunking id="20" string="Richard North , a former environmental health officer" type="NP">
          <tokens>
            <token id="1" string="Richard" />
            <token id="2" string="North" />
            <token id="3" string="," />
            <token id="4" string="a" />
            <token id="5" string="former" />
            <token id="6" string="environmental" />
            <token id="7" string="health" />
            <token id="8" string="officer" />
          </tokens>
        </chunking>
        <chunking id="21" string="turned consultant" type="VP">
          <tokens>
            <token id="9" string="turned" />
            <token id="10" string="consultant" />
          </tokens>
        </chunking>
        <chunking id="22" string="to produce more optimistic figures" type="VP">
          <tokens>
            <token id="28" string="to" />
            <token id="29" string="produce" />
            <token id="30" string="more" />
            <token id="31" string="optimistic" />
            <token id="32" string="figures" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">North</governor>
          <dependent id="1">Richard</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">turned</governor>
          <dependent id="2">North</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">officer</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">officer</governor>
          <dependent id="5">former</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">officer</governor>
          <dependent id="6">environmental</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">officer</governor>
          <dependent id="7">health</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">North</governor>
          <dependent id="8">officer</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">turned</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">turned</governor>
          <dependent id="10">consultant</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">turned</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">contributor</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="34">claims</governor>
          <dependent id="14">contributor</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Telegraph</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">Telegraph</governor>
          <dependent id="16">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Telegraph</governor>
          <dependent id="17">Sunday</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">contributor</governor>
          <dependent id="18">Telegraph</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="14">contributor</governor>
          <dependent id="20">believes</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="27">skewed</governor>
          <dependent id="21">that</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="24">statistics</governor>
          <dependent id="22">MAFF</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">MAFF</governor>
          <dependent id="23">'s</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="27">skewed</governor>
          <dependent id="24">statistics</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="27">skewed</governor>
          <dependent id="25">are</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="27">skewed</governor>
          <dependent id="26">being</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="20">believes</governor>
          <dependent id="27">skewed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="29">produce</governor>
          <dependent id="28">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="27">skewed</governor>
          <dependent id="29">produce</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="31">optimistic</governor>
          <dependent id="30">more</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="32">figures</governor>
          <dependent id="31">optimistic</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="29">produce</governor>
          <dependent id="32">figures</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">turned</governor>
          <dependent id="34">claims</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="34">claims</governor>
          <dependent id="35">not</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="34">claims</governor>
          <dependent id="36">surprisingly</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="34">claims</governor>
          <dependent id="37">rejected</dependent>
        </dependency>
        <dependency type="case">
          <governor id="40">ministry</governor>
          <dependent id="38">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="40">ministry</governor>
          <dependent id="39">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="37">rejected</governor>
          <dependent id="40">ministry</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="MAFF" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="22" string="MAFF" />
          </tokens>
        </entity>
        <entity id="2" string="Richard North" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Richard" />
            <token id="2" string="North" />
          </tokens>
        </entity>
        <entity id="3" string="Sunday" type="DATE" score="0.0">
          <tokens>
            <token id="17" string="Sunday" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="37" has_coreference="false">
      <content>Mr North said: &amp;quot;We have more than 8,000 cattle born after the feed ban that have subsequently contracted BSE.</content>
      <tokens>
        <token id="1" string="Mr" lemma="Mr" stem="mr" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="2" string="North" lemma="North" stem="north" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="3" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="8,000" lemma="8,000" stem="8,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="11" string="cattle" lemma="cattle" stem="cattl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="born" lemma="bear" stem="born" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="feed" lemma="feed" stem="feed" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="ban" lemma="ban" stem="ban" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="subsequently" lemma="subsequently" stem="subsequ" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="contracted" lemma="contract" stem="contract" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="BSE" lemma="BSE" stem="bse" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Mr) (NNP North)) (VP (VBD said) (: :) (`` ``) (S (NP (PRP We)) (VP (VBP have) (NP (NP (QP (JJR more) (IN than) (CD 8,000)) (NNS cattle)) (VP (VBN born) (PP (IN after) (NP (DT the) (NN feed) (NN ban)))) (SBAR (WHNP (WDT that)) (S (VP (VBP have) (ADVP (RB subsequently)) (VP (VBN contracted) (NP (NNP BSE)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="born after the feed ban" type="VP">
          <tokens>
            <token id="12" string="born" />
            <token id="13" string="after" />
            <token id="14" string="the" />
            <token id="15" string="feed" />
            <token id="16" string="ban" />
          </tokens>
        </chunking>
        <chunking id="2" string="that have subsequently contracted BSE" type="SBAR">
          <tokens>
            <token id="17" string="that" />
            <token id="18" string="have" />
            <token id="19" string="subsequently" />
            <token id="20" string="contracted" />
            <token id="21" string="BSE" />
          </tokens>
        </chunking>
        <chunking id="3" string="have more than 8,000 cattle born after the feed ban that have subsequently contracted BSE" type="VP">
          <tokens>
            <token id="7" string="have" />
            <token id="8" string="more" />
            <token id="9" string="than" />
            <token id="10" string="8,000" />
            <token id="11" string="cattle" />
            <token id="12" string="born" />
            <token id="13" string="after" />
            <token id="14" string="the" />
            <token id="15" string="feed" />
            <token id="16" string="ban" />
            <token id="17" string="that" />
            <token id="18" string="have" />
            <token id="19" string="subsequently" />
            <token id="20" string="contracted" />
            <token id="21" string="BSE" />
          </tokens>
        </chunking>
        <chunking id="4" string="have subsequently contracted BSE" type="VP">
          <tokens>
            <token id="18" string="have" />
            <token id="19" string="subsequently" />
            <token id="20" string="contracted" />
            <token id="21" string="BSE" />
          </tokens>
        </chunking>
        <chunking id="5" string="Mr North" type="NP">
          <tokens>
            <token id="1" string="Mr" />
            <token id="2" string="North" />
          </tokens>
        </chunking>
        <chunking id="6" string="BSE" type="NP">
          <tokens>
            <token id="21" string="BSE" />
          </tokens>
        </chunking>
        <chunking id="7" string="said : `` We have more than 8,000 cattle born after the feed ban that have subsequently contracted BSE" type="VP">
          <tokens>
            <token id="3" string="said" />
            <token id="4" string=":" />
            <token id="5" string="&quot;" />
            <token id="6" string="We" />
            <token id="7" string="have" />
            <token id="8" string="more" />
            <token id="9" string="than" />
            <token id="10" string="8,000" />
            <token id="11" string="cattle" />
            <token id="12" string="born" />
            <token id="13" string="after" />
            <token id="14" string="the" />
            <token id="15" string="feed" />
            <token id="16" string="ban" />
            <token id="17" string="that" />
            <token id="18" string="have" />
            <token id="19" string="subsequently" />
            <token id="20" string="contracted" />
            <token id="21" string="BSE" />
          </tokens>
        </chunking>
        <chunking id="8" string="more than 8,000 cattle" type="NP">
          <tokens>
            <token id="8" string="more" />
            <token id="9" string="than" />
            <token id="10" string="8,000" />
            <token id="11" string="cattle" />
          </tokens>
        </chunking>
        <chunking id="9" string="contracted BSE" type="VP">
          <tokens>
            <token id="20" string="contracted" />
            <token id="21" string="BSE" />
          </tokens>
        </chunking>
        <chunking id="10" string="We" type="NP">
          <tokens>
            <token id="6" string="We" />
          </tokens>
        </chunking>
        <chunking id="11" string="the feed ban" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="feed" />
            <token id="16" string="ban" />
          </tokens>
        </chunking>
        <chunking id="12" string="more than 8,000 cattle born after the feed ban that have subsequently contracted BSE" type="NP">
          <tokens>
            <token id="8" string="more" />
            <token id="9" string="than" />
            <token id="10" string="8,000" />
            <token id="11" string="cattle" />
            <token id="12" string="born" />
            <token id="13" string="after" />
            <token id="14" string="the" />
            <token id="15" string="feed" />
            <token id="16" string="ban" />
            <token id="17" string="that" />
            <token id="18" string="have" />
            <token id="19" string="subsequently" />
            <token id="20" string="contracted" />
            <token id="21" string="BSE" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">North</governor>
          <dependent id="1">Mr</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">said</governor>
          <dependent id="2">North</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">have</governor>
          <dependent id="6">We</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">said</governor>
          <dependent id="7">have</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">8,000</governor>
          <dependent id="8">more</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="8">more</governor>
          <dependent id="9">than</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="11">cattle</governor>
          <dependent id="10">8,000</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">have</governor>
          <dependent id="11">cattle</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="11">cattle</governor>
          <dependent id="12">born</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">ban</governor>
          <dependent id="13">after</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">ban</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">ban</governor>
          <dependent id="15">feed</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">born</governor>
          <dependent id="16">ban</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">contracted</governor>
          <dependent id="17">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="20">contracted</governor>
          <dependent id="18">have</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">contracted</governor>
          <dependent id="19">subsequently</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="11">cattle</governor>
          <dependent id="20">contracted</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">contracted</governor>
          <dependent id="21">BSE</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Mr North" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Mr" />
            <token id="2" string="North" />
          </tokens>
        </entity>
        <entity id="2" string="8,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="10" string="8,000" />
          </tokens>
        </entity>
        <entity id="3" string="BSE" type="MISC" score="0.0">
          <tokens>
            <token id="21" string="BSE" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="38" has_coreference="false">
      <content>The claim that all of these are affected by illegally retained infected feed gets less credible by the hour.&amp;quot;</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="claim" lemma="claim" stem="claim" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="these" lemma="these" stem="these" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="affected" lemma="affect" stem="affect" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="illegally" lemma="illegally" stem="illeg" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="retained" lemma="retain" stem="retain" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="infected" lemma="infected" stem="infect" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="feed" lemma="feed" stem="feed" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="gets" lemma="get" stem="get" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="less" lemma="less" stem="less" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="credible" lemma="credible" stem="credibl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="19" string="hour" lemma="hour" stem="hour" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NN claim)) (SBAR (IN that) (S (NP (NP (DT all)) (PP (IN of) (NP (DT these)))) (VP (VBP are) (VP (VBN affected) (PP (IN by) (S (VP (ADVP (RB illegally)) (VBN retained) (NP (JJ infected) (NN feed)))))))))) (VP (VBZ gets) (ADJP (ADJP (JJR less) (JJ credible)) (PP (IN by) (NP (DT the) (NN hour))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="all" type="NP">
          <tokens>
            <token id="4" string="all" />
          </tokens>
        </chunking>
        <chunking id="2" string="gets less credible by the hour" type="VP">
          <tokens>
            <token id="14" string="gets" />
            <token id="15" string="less" />
            <token id="16" string="credible" />
            <token id="17" string="by" />
            <token id="18" string="the" />
            <token id="19" string="hour" />
          </tokens>
        </chunking>
        <chunking id="3" string="The claim" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="claim" />
          </tokens>
        </chunking>
        <chunking id="4" string="affected by illegally retained infected feed" type="VP">
          <tokens>
            <token id="8" string="affected" />
            <token id="9" string="by" />
            <token id="10" string="illegally" />
            <token id="11" string="retained" />
            <token id="12" string="infected" />
            <token id="13" string="feed" />
          </tokens>
        </chunking>
        <chunking id="5" string="that all of these are affected by illegally retained infected feed" type="SBAR">
          <tokens>
            <token id="3" string="that" />
            <token id="4" string="all" />
            <token id="5" string="of" />
            <token id="6" string="these" />
            <token id="7" string="are" />
            <token id="8" string="affected" />
            <token id="9" string="by" />
            <token id="10" string="illegally" />
            <token id="11" string="retained" />
            <token id="12" string="infected" />
            <token id="13" string="feed" />
          </tokens>
        </chunking>
        <chunking id="6" string="less credible by the hour" type="ADJP">
          <tokens>
            <token id="15" string="less" />
            <token id="16" string="credible" />
            <token id="17" string="by" />
            <token id="18" string="the" />
            <token id="19" string="hour" />
          </tokens>
        </chunking>
        <chunking id="7" string="less credible" type="ADJP">
          <tokens>
            <token id="15" string="less" />
            <token id="16" string="credible" />
          </tokens>
        </chunking>
        <chunking id="8" string="are affected by illegally retained infected feed" type="VP">
          <tokens>
            <token id="7" string="are" />
            <token id="8" string="affected" />
            <token id="9" string="by" />
            <token id="10" string="illegally" />
            <token id="11" string="retained" />
            <token id="12" string="infected" />
            <token id="13" string="feed" />
          </tokens>
        </chunking>
        <chunking id="9" string="the hour" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="hour" />
          </tokens>
        </chunking>
        <chunking id="10" string="these" type="NP">
          <tokens>
            <token id="6" string="these" />
          </tokens>
        </chunking>
        <chunking id="11" string="The claim that all of these are affected by illegally retained infected feed" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="claim" />
            <token id="3" string="that" />
            <token id="4" string="all" />
            <token id="5" string="of" />
            <token id="6" string="these" />
            <token id="7" string="are" />
            <token id="8" string="affected" />
            <token id="9" string="by" />
            <token id="10" string="illegally" />
            <token id="11" string="retained" />
            <token id="12" string="infected" />
            <token id="13" string="feed" />
          </tokens>
        </chunking>
        <chunking id="12" string="illegally retained infected feed" type="VP">
          <tokens>
            <token id="10" string="illegally" />
            <token id="11" string="retained" />
            <token id="12" string="infected" />
            <token id="13" string="feed" />
          </tokens>
        </chunking>
        <chunking id="13" string="all of these" type="NP">
          <tokens>
            <token id="4" string="all" />
            <token id="5" string="of" />
            <token id="6" string="these" />
          </tokens>
        </chunking>
        <chunking id="14" string="infected feed" type="NP">
          <tokens>
            <token id="12" string="infected" />
            <token id="13" string="feed" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">claim</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">gets</governor>
          <dependent id="2">claim</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">affected</governor>
          <dependent id="3">that</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="8">affected</governor>
          <dependent id="4">all</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">these</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">all</governor>
          <dependent id="6">these</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="8">affected</governor>
          <dependent id="7">are</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="2">claim</governor>
          <dependent id="8">affected</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">retained</governor>
          <dependent id="9">by</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">retained</governor>
          <dependent id="10">illegally</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="8">affected</governor>
          <dependent id="11">retained</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">feed</governor>
          <dependent id="12">infected</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">retained</governor>
          <dependent id="13">feed</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">gets</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="16">credible</governor>
          <dependent id="15">less</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="14">gets</governor>
          <dependent id="16">credible</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">hour</governor>
          <dependent id="17">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">hour</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">credible</governor>
          <dependent id="19">hour</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="the hour" type="DATE" score="0.0">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="hour" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="39" has_coreference="false">
      <content>One question -- perhaps the most important -- remains.</content>
      <tokens>
        <token id="1" string="One" lemma="one" stem="one" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="2" string="question" lemma="question" stem="question" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="perhaps" lemma="perhaps" stem="perhap" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="most" lemma="most" stem="most" pos="RBS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="important" lemma="important" stem="import" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="remains" lemma="remain" stem="remain" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (CD One) (NN question)) (PRN (: --) (ADVP (RB perhaps)) (NP (DT the) (ADJP (RBS most) (JJ important))) (: --))) (VP (VBZ remains)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="One question -- perhaps the most important --" type="NP">
          <tokens>
            <token id="1" string="One" />
            <token id="2" string="question" />
            <token id="3" string="--" />
            <token id="4" string="perhaps" />
            <token id="5" string="the" />
            <token id="6" string="most" />
            <token id="7" string="important" />
            <token id="8" string="--" />
          </tokens>
        </chunking>
        <chunking id="2" string="the most important" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="most" />
            <token id="7" string="important" />
          </tokens>
        </chunking>
        <chunking id="3" string="most important" type="ADJP">
          <tokens>
            <token id="6" string="most" />
            <token id="7" string="important" />
          </tokens>
        </chunking>
        <chunking id="4" string="remains" type="VP">
          <tokens>
            <token id="9" string="remains" />
          </tokens>
        </chunking>
        <chunking id="5" string="One question" type="NP">
          <tokens>
            <token id="1" string="One" />
            <token id="2" string="question" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nummod">
          <governor id="2">question</governor>
          <dependent id="1">One</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">remains</governor>
          <dependent id="2">question</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">important</governor>
          <dependent id="4">perhaps</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">important</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">important</governor>
          <dependent id="6">most</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="2">question</governor>
          <dependent id="7">important</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">remains</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="One" type="NUMBER" score="0.0">
          <tokens>
            <token id="1" string="One" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="40" has_coreference="true">
      <content>If the disease has jumped from sheep to cattle -- and cases have also been reported in kudu antelope at London Zoo -- could it affect humans?</content>
      <tokens>
        <token id="1" string="If" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="true" />
        <token id="4" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="jumped" lemma="jump" stem="jump" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="sheep" lemma="sheep" stem="sheep" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="cattle" lemma="cattle" stem="cattl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="cases" lemma="case" stem="case" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="reported" lemma="report" stem="report" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="kudu" lemma="kudu" stem="kudu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="antelope" lemma="antelope" stem="antelop" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="London" lemma="London" stem="london" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="22" string="Zoo" lemma="Zoo" stem="zoo" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="affect" lemma="affect" stem="affect" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="humans" lemma="human" stem="human" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN If) (S (NP (DT the) (NN disease)) (VP (VBZ has) (VP (VBN jumped) (PP (IN from) (NP (NN sheep))) (PP (TO to) (NP (NNS cattle))))))) (PRN (: --) (CC and) (S (NP (NNS cases)) (VP (VBP have) (ADVP (RB also)) (VP (VBN been) (VP (VBN reported) (PP (IN in) (NP (NN kudu) (NNS antelope))) (PP (IN at) (NP (NNP London) (NNP Zoo))))))) (: --)) (VP (MD could) (NP (PRP it)) (S (VP (VB affect) (NP (NNS humans))))) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="jumped from sheep to cattle" type="VP">
          <tokens>
            <token id="5" string="jumped" />
            <token id="6" string="from" />
            <token id="7" string="sheep" />
            <token id="8" string="to" />
            <token id="9" string="cattle" />
          </tokens>
        </chunking>
        <chunking id="2" string="been reported in kudu antelope at London Zoo" type="VP">
          <tokens>
            <token id="15" string="been" />
            <token id="16" string="reported" />
            <token id="17" string="in" />
            <token id="18" string="kudu" />
            <token id="19" string="antelope" />
            <token id="20" string="at" />
            <token id="21" string="London" />
            <token id="22" string="Zoo" />
          </tokens>
        </chunking>
        <chunking id="3" string="could it affect humans" type="VP">
          <tokens>
            <token id="24" string="could" />
            <token id="25" string="it" />
            <token id="26" string="affect" />
            <token id="27" string="humans" />
          </tokens>
        </chunking>
        <chunking id="4" string="cases" type="NP">
          <tokens>
            <token id="12" string="cases" />
          </tokens>
        </chunking>
        <chunking id="5" string="have also been reported in kudu antelope at London Zoo" type="VP">
          <tokens>
            <token id="13" string="have" />
            <token id="14" string="also" />
            <token id="15" string="been" />
            <token id="16" string="reported" />
            <token id="17" string="in" />
            <token id="18" string="kudu" />
            <token id="19" string="antelope" />
            <token id="20" string="at" />
            <token id="21" string="London" />
            <token id="22" string="Zoo" />
          </tokens>
        </chunking>
        <chunking id="6" string="London Zoo" type="NP">
          <tokens>
            <token id="21" string="London" />
            <token id="22" string="Zoo" />
          </tokens>
        </chunking>
        <chunking id="7" string="kudu antelope" type="NP">
          <tokens>
            <token id="18" string="kudu" />
            <token id="19" string="antelope" />
          </tokens>
        </chunking>
        <chunking id="8" string="If the disease has jumped from sheep to cattle" type="SBAR">
          <tokens>
            <token id="1" string="If" />
            <token id="2" string="the" />
            <token id="3" string="disease" />
            <token id="4" string="has" />
            <token id="5" string="jumped" />
            <token id="6" string="from" />
            <token id="7" string="sheep" />
            <token id="8" string="to" />
            <token id="9" string="cattle" />
          </tokens>
        </chunking>
        <chunking id="9" string="it" type="NP">
          <tokens>
            <token id="25" string="it" />
          </tokens>
        </chunking>
        <chunking id="10" string="cattle" type="NP">
          <tokens>
            <token id="9" string="cattle" />
          </tokens>
        </chunking>
        <chunking id="11" string="reported in kudu antelope at London Zoo" type="VP">
          <tokens>
            <token id="16" string="reported" />
            <token id="17" string="in" />
            <token id="18" string="kudu" />
            <token id="19" string="antelope" />
            <token id="20" string="at" />
            <token id="21" string="London" />
            <token id="22" string="Zoo" />
          </tokens>
        </chunking>
        <chunking id="12" string="the disease" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="disease" />
          </tokens>
        </chunking>
        <chunking id="13" string="affect humans" type="VP">
          <tokens>
            <token id="26" string="affect" />
            <token id="27" string="humans" />
          </tokens>
        </chunking>
        <chunking id="14" string="has jumped from sheep to cattle" type="VP">
          <tokens>
            <token id="4" string="has" />
            <token id="5" string="jumped" />
            <token id="6" string="from" />
            <token id="7" string="sheep" />
            <token id="8" string="to" />
            <token id="9" string="cattle" />
          </tokens>
        </chunking>
        <chunking id="15" string="humans" type="NP">
          <tokens>
            <token id="27" string="humans" />
          </tokens>
        </chunking>
        <chunking id="16" string="sheep" type="NP">
          <tokens>
            <token id="7" string="sheep" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="5">jumped</governor>
          <dependent id="1">If</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">disease</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">jumped</governor>
          <dependent id="3">disease</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">jumped</governor>
          <dependent id="4">has</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="24">could</governor>
          <dependent id="5">jumped</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">sheep</governor>
          <dependent id="6">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">jumped</governor>
          <dependent id="7">sheep</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">cattle</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">jumped</governor>
          <dependent id="9">cattle</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">reported</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="16">reported</governor>
          <dependent id="12">cases</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">reported</governor>
          <dependent id="13">have</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">reported</governor>
          <dependent id="14">also</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="16">reported</governor>
          <dependent id="15">been</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="24">could</governor>
          <dependent id="16">reported</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">antelope</governor>
          <dependent id="17">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">antelope</governor>
          <dependent id="18">kudu</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">reported</governor>
          <dependent id="19">antelope</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">Zoo</governor>
          <dependent id="20">at</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Zoo</governor>
          <dependent id="21">London</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">reported</governor>
          <dependent id="22">Zoo</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="24">could</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">could</governor>
          <dependent id="25">it</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="24">could</governor>
          <dependent id="26">affect</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="26">affect</governor>
          <dependent id="27">humans</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="3" string="disease" />
          </tokens>
        </entity>
        <entity id="2" string="London" type="LOCATION" score="0.0">
          <tokens>
            <token id="21" string="London" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="41" has_coreference="true">
      <content>That prospect, discounted by most scientists -- including MAFF critics such as Mr Purdey -- is considered a possibility by Richard Lacey, a Leeds University microbiologist who has been studying cases of CJD, a disease with a long incubation period.</content>
      <tokens>
        <token id="1" string="That" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="prospect" lemma="prospect" stem="prospect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="discounted" lemma="discount" stem="discount" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="most" lemma="most" stem="most" pos="JJS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="scientists" lemma="scientist" stem="scientist" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="including" lemma="include" stem="includ" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="MAFF" lemma="MAFF" stem="maff" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="11" string="critics" lemma="critic" stem="critic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Mr" lemma="Mr" stem="mr" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="Purdey" lemma="Purdey" stem="purdei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="16" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="considered" lemma="consider" stem="consid" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="possibility" lemma="possibility" stem="possibl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="Richard" lemma="Richard" stem="richard" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="23" string="Lacey" lemma="Lacey" stem="lacei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="Leeds" lemma="Leeds" stem="leed" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="27" string="University" lemma="University" stem="univers" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="28" string="microbiologist" lemma="microbiologist" stem="microbiologist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="studying" lemma="study" stem="studi" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="cases" lemma="case" stem="case" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="34" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="35" string="CJD" lemma="CJD" stem="cjd" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="36" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="37" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="38" string="disease" lemma="disease" stem="diseas" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="false" />
        <token id="39" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="40" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="41" string="long" lemma="long" stem="long" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="42" string="incubation" lemma="incubation" stem="incub" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="43" string="period" lemma="period" stem="period" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="44" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT That) (NN prospect)) (, ,) (VP (VBN discounted) (PP (IN by) (NP (JJS most) (NNS scientists))))) (PRN (: --) (PP (VBG including) (NP (NP (NNP MAFF) (NNS critics)) (PP (JJ such) (IN as) (NP (NNP Mr) (NNP Purdey))))) (: --)) (VP (VBZ is) (VP (VBN considered) (NP (DT a) (NN possibility)) (PP (IN by) (NP (NP (NNP Richard) (NNP Lacey)) (, ,) (NP (NP (DT a) (NNP Leeds) (NNP University) (NN microbiologist)) (SBAR (WHNP (WP who)) (S (VP (VBZ has) (VP (VBN been) (VP (VBG studying) (NP (NP (NNS cases)) (PP (IN of) (NP (NP (NNP CJD)) (, ,) (NP (NP (DT a) (NN disease)) (PP (IN with) (NP (DT a) (JJ long) (NN incubation) (NN period))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="most scientists" type="NP">
          <tokens>
            <token id="6" string="most" />
            <token id="7" string="scientists" />
          </tokens>
        </chunking>
        <chunking id="2" string="studying cases of CJD , a disease with a long incubation period" type="VP">
          <tokens>
            <token id="32" string="studying" />
            <token id="33" string="cases" />
            <token id="34" string="of" />
            <token id="35" string="CJD" />
            <token id="36" string="," />
            <token id="37" string="a" />
            <token id="38" string="disease" />
            <token id="39" string="with" />
            <token id="40" string="a" />
            <token id="41" string="long" />
            <token id="42" string="incubation" />
            <token id="43" string="period" />
          </tokens>
        </chunking>
        <chunking id="3" string="cases" type="NP">
          <tokens>
            <token id="33" string="cases" />
          </tokens>
        </chunking>
        <chunking id="4" string="discounted by most scientists" type="VP">
          <tokens>
            <token id="4" string="discounted" />
            <token id="5" string="by" />
            <token id="6" string="most" />
            <token id="7" string="scientists" />
          </tokens>
        </chunking>
        <chunking id="5" string="That prospect" type="NP">
          <tokens>
            <token id="1" string="That" />
            <token id="2" string="prospect" />
          </tokens>
        </chunking>
        <chunking id="6" string="who has been studying cases of CJD , a disease with a long incubation period" type="SBAR">
          <tokens>
            <token id="29" string="who" />
            <token id="30" string="has" />
            <token id="31" string="been" />
            <token id="32" string="studying" />
            <token id="33" string="cases" />
            <token id="34" string="of" />
            <token id="35" string="CJD" />
            <token id="36" string="," />
            <token id="37" string="a" />
            <token id="38" string="disease" />
            <token id="39" string="with" />
            <token id="40" string="a" />
            <token id="41" string="long" />
            <token id="42" string="incubation" />
            <token id="43" string="period" />
          </tokens>
        </chunking>
        <chunking id="7" string="Richard Lacey" type="NP">
          <tokens>
            <token id="22" string="Richard" />
            <token id="23" string="Lacey" />
          </tokens>
        </chunking>
        <chunking id="8" string="MAFF critics" type="NP">
          <tokens>
            <token id="10" string="MAFF" />
            <token id="11" string="critics" />
          </tokens>
        </chunking>
        <chunking id="9" string="has been studying cases of CJD , a disease with a long incubation period" type="VP">
          <tokens>
            <token id="30" string="has" />
            <token id="31" string="been" />
            <token id="32" string="studying" />
            <token id="33" string="cases" />
            <token id="34" string="of" />
            <token id="35" string="CJD" />
            <token id="36" string="," />
            <token id="37" string="a" />
            <token id="38" string="disease" />
            <token id="39" string="with" />
            <token id="40" string="a" />
            <token id="41" string="long" />
            <token id="42" string="incubation" />
            <token id="43" string="period" />
          </tokens>
        </chunking>
        <chunking id="10" string="considered a possibility by Richard Lacey , a Leeds University microbiologist who has been studying cases of CJD , a disease with a long incubation period" type="VP">
          <tokens>
            <token id="18" string="considered" />
            <token id="19" string="a" />
            <token id="20" string="possibility" />
            <token id="21" string="by" />
            <token id="22" string="Richard" />
            <token id="23" string="Lacey" />
            <token id="24" string="," />
            <token id="25" string="a" />
            <token id="26" string="Leeds" />
            <token id="27" string="University" />
            <token id="28" string="microbiologist" />
            <token id="29" string="who" />
            <token id="30" string="has" />
            <token id="31" string="been" />
            <token id="32" string="studying" />
            <token id="33" string="cases" />
            <token id="34" string="of" />
            <token id="35" string="CJD" />
            <token id="36" string="," />
            <token id="37" string="a" />
            <token id="38" string="disease" />
            <token id="39" string="with" />
            <token id="40" string="a" />
            <token id="41" string="long" />
            <token id="42" string="incubation" />
            <token id="43" string="period" />
          </tokens>
        </chunking>
        <chunking id="11" string="is considered a possibility by Richard Lacey , a Leeds University microbiologist who has been studying cases of CJD , a disease with a long incubation period" type="VP">
          <tokens>
            <token id="17" string="is" />
            <token id="18" string="considered" />
            <token id="19" string="a" />
            <token id="20" string="possibility" />
            <token id="21" string="by" />
            <token id="22" string="Richard" />
            <token id="23" string="Lacey" />
            <token id="24" string="," />
            <token id="25" string="a" />
            <token id="26" string="Leeds" />
            <token id="27" string="University" />
            <token id="28" string="microbiologist" />
            <token id="29" string="who" />
            <token id="30" string="has" />
            <token id="31" string="been" />
            <token id="32" string="studying" />
            <token id="33" string="cases" />
            <token id="34" string="of" />
            <token id="35" string="CJD" />
            <token id="36" string="," />
            <token id="37" string="a" />
            <token id="38" string="disease" />
            <token id="39" string="with" />
            <token id="40" string="a" />
            <token id="41" string="long" />
            <token id="42" string="incubation" />
            <token id="43" string="period" />
          </tokens>
        </chunking>
        <chunking id="12" string="cases of CJD , a disease with a long incubation period" type="NP">
          <tokens>
            <token id="33" string="cases" />
            <token id="34" string="of" />
            <token id="35" string="CJD" />
            <token id="36" string="," />
            <token id="37" string="a" />
            <token id="38" string="disease" />
            <token id="39" string="with" />
            <token id="40" string="a" />
            <token id="41" string="long" />
            <token id="42" string="incubation" />
            <token id="43" string="period" />
          </tokens>
        </chunking>
        <chunking id="13" string="a possibility" type="NP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="possibility" />
          </tokens>
        </chunking>
        <chunking id="14" string="Richard Lacey , a Leeds University microbiologist who has been studying cases of CJD , a disease with a long incubation period" type="NP">
          <tokens>
            <token id="22" string="Richard" />
            <token id="23" string="Lacey" />
            <token id="24" string="," />
            <token id="25" string="a" />
            <token id="26" string="Leeds" />
            <token id="27" string="University" />
            <token id="28" string="microbiologist" />
            <token id="29" string="who" />
            <token id="30" string="has" />
            <token id="31" string="been" />
            <token id="32" string="studying" />
            <token id="33" string="cases" />
            <token id="34" string="of" />
            <token id="35" string="CJD" />
            <token id="36" string="," />
            <token id="37" string="a" />
            <token id="38" string="disease" />
            <token id="39" string="with" />
            <token id="40" string="a" />
            <token id="41" string="long" />
            <token id="42" string="incubation" />
            <token id="43" string="period" />
          </tokens>
        </chunking>
        <chunking id="15" string="CJD" type="NP">
          <tokens>
            <token id="35" string="CJD" />
          </tokens>
        </chunking>
        <chunking id="16" string="a disease with a long incubation period" type="NP">
          <tokens>
            <token id="37" string="a" />
            <token id="38" string="disease" />
            <token id="39" string="with" />
            <token id="40" string="a" />
            <token id="41" string="long" />
            <token id="42" string="incubation" />
            <token id="43" string="period" />
          </tokens>
        </chunking>
        <chunking id="17" string="Mr Purdey" type="NP">
          <tokens>
            <token id="14" string="Mr" />
            <token id="15" string="Purdey" />
          </tokens>
        </chunking>
        <chunking id="18" string="a Leeds University microbiologist who has been studying cases of CJD , a disease with a long incubation period" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="Leeds" />
            <token id="27" string="University" />
            <token id="28" string="microbiologist" />
            <token id="29" string="who" />
            <token id="30" string="has" />
            <token id="31" string="been" />
            <token id="32" string="studying" />
            <token id="33" string="cases" />
            <token id="34" string="of" />
            <token id="35" string="CJD" />
            <token id="36" string="," />
            <token id="37" string="a" />
            <token id="38" string="disease" />
            <token id="39" string="with" />
            <token id="40" string="a" />
            <token id="41" string="long" />
            <token id="42" string="incubation" />
            <token id="43" string="period" />
          </tokens>
        </chunking>
        <chunking id="19" string="a Leeds University microbiologist" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="Leeds" />
            <token id="27" string="University" />
            <token id="28" string="microbiologist" />
          </tokens>
        </chunking>
        <chunking id="20" string="That prospect , discounted by most scientists" type="NP">
          <tokens>
            <token id="1" string="That" />
            <token id="2" string="prospect" />
            <token id="3" string="," />
            <token id="4" string="discounted" />
            <token id="5" string="by" />
            <token id="6" string="most" />
            <token id="7" string="scientists" />
          </tokens>
        </chunking>
        <chunking id="21" string="a long incubation period" type="NP">
          <tokens>
            <token id="40" string="a" />
            <token id="41" string="long" />
            <token id="42" string="incubation" />
            <token id="43" string="period" />
          </tokens>
        </chunking>
        <chunking id="22" string="a disease" type="NP">
          <tokens>
            <token id="37" string="a" />
            <token id="38" string="disease" />
          </tokens>
        </chunking>
        <chunking id="23" string="MAFF critics such as Mr Purdey" type="NP">
          <tokens>
            <token id="10" string="MAFF" />
            <token id="11" string="critics" />
            <token id="12" string="such" />
            <token id="13" string="as" />
            <token id="14" string="Mr" />
            <token id="15" string="Purdey" />
          </tokens>
        </chunking>
        <chunking id="24" string="CJD , a disease with a long incubation period" type="NP">
          <tokens>
            <token id="35" string="CJD" />
            <token id="36" string="," />
            <token id="37" string="a" />
            <token id="38" string="disease" />
            <token id="39" string="with" />
            <token id="40" string="a" />
            <token id="41" string="long" />
            <token id="42" string="incubation" />
            <token id="43" string="period" />
          </tokens>
        </chunking>
        <chunking id="25" string="been studying cases of CJD , a disease with a long incubation period" type="VP">
          <tokens>
            <token id="31" string="been" />
            <token id="32" string="studying" />
            <token id="33" string="cases" />
            <token id="34" string="of" />
            <token id="35" string="CJD" />
            <token id="36" string="," />
            <token id="37" string="a" />
            <token id="38" string="disease" />
            <token id="39" string="with" />
            <token id="40" string="a" />
            <token id="41" string="long" />
            <token id="42" string="incubation" />
            <token id="43" string="period" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">prospect</governor>
          <dependent id="1">That</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="18">considered</governor>
          <dependent id="2">prospect</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="2">prospect</governor>
          <dependent id="4">discounted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">scientists</governor>
          <dependent id="5">by</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">scientists</governor>
          <dependent id="6">most</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">discounted</governor>
          <dependent id="7">scientists</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">critics</governor>
          <dependent id="9">including</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">critics</governor>
          <dependent id="10">MAFF</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="18">considered</governor>
          <dependent id="11">critics</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">Purdey</governor>
          <dependent id="12">such</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="12">such</governor>
          <dependent id="13">as</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Purdey</governor>
          <dependent id="14">Mr</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">critics</governor>
          <dependent id="15">Purdey</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="18">considered</governor>
          <dependent id="17">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">considered</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">possibility</governor>
          <dependent id="19">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">considered</governor>
          <dependent id="20">possibility</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">Lacey</governor>
          <dependent id="21">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">Lacey</governor>
          <dependent id="22">Richard</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">considered</governor>
          <dependent id="23">Lacey</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">microbiologist</governor>
          <dependent id="25">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">microbiologist</governor>
          <dependent id="26">Leeds</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">microbiologist</governor>
          <dependent id="27">University</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="23">Lacey</governor>
          <dependent id="28">microbiologist</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="32">studying</governor>
          <dependent id="29">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="32">studying</governor>
          <dependent id="30">has</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="32">studying</governor>
          <dependent id="31">been</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="28">microbiologist</governor>
          <dependent id="32">studying</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="32">studying</governor>
          <dependent id="33">cases</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">CJD</governor>
          <dependent id="34">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">cases</governor>
          <dependent id="35">CJD</dependent>
        </dependency>
        <dependency type="det">
          <governor id="38">disease</governor>
          <dependent id="37">a</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="35">CJD</governor>
          <dependent id="38">disease</dependent>
        </dependency>
        <dependency type="case">
          <governor id="43">period</governor>
          <dependent id="39">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="43">period</governor>
          <dependent id="40">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="43">period</governor>
          <dependent id="41">long</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="43">period</governor>
          <dependent id="42">incubation</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="38">disease</governor>
          <dependent id="43">period</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="MAFF" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="10" string="MAFF" />
          </tokens>
        </entity>
        <entity id="2" string="Purdey" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="Purdey" />
          </tokens>
        </entity>
        <entity id="3" string="disease" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="38" string="disease" />
          </tokens>
        </entity>
        <entity id="4" string="CJD" type="MISC" score="0.0">
          <tokens>
            <token id="35" string="CJD" />
          </tokens>
        </entity>
        <entity id="5" string="Richard Lacey" type="PERSON" score="0.0">
          <tokens>
            <token id="22" string="Richard" />
            <token id="23" string="Lacey" />
          </tokens>
        </entity>
        <entity id="6" string="Leeds University" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="26" string="Leeds" />
            <token id="27" string="University" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="42" has_coreference="true">
      <content>Reviled by the farming industry and privately disparaged by MAFF, he nevertheless insists that there may be a threat.</content>
      <tokens>
        <token id="1" string="Reviled" lemma="revile" stem="revil" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="farming" lemma="farm" stem="farm" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="industry" lemma="industry" stem="industri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="privately" lemma="privately" stem="privat" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="disparaged" lemma="disparaged" stem="disparag" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="MAFF" lemma="MAFF" stem="maff" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="nevertheless" lemma="nevertheless" stem="nevertheless" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="insists" lemma="insist" stem="insist" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="threat" lemma="threat" stem="threat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VP (VBN Reviled) (PP (IN by) (NP (DT the) (VBG farming) (NN industry)))) (CC and) (VP (ADJP (RB privately) (JJ disparaged)) (PP (IN by) (NP (NNP MAFF)))))) (, ,) (NP (PRP he)) (ADVP (RB nevertheless)) (VP (VBZ insists) (SBAR (IN that) (S (NP (EX there)) (VP (MD may) (VP (VB be) (NP (DT a) (NN threat))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that there may be a threat" type="SBAR">
          <tokens>
            <token id="15" string="that" />
            <token id="16" string="there" />
            <token id="17" string="may" />
            <token id="18" string="be" />
            <token id="19" string="a" />
            <token id="20" string="threat" />
          </tokens>
        </chunking>
        <chunking id="2" string="a threat" type="NP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="threat" />
          </tokens>
        </chunking>
        <chunking id="3" string="Reviled by the farming industry" type="VP">
          <tokens>
            <token id="1" string="Reviled" />
            <token id="2" string="by" />
            <token id="3" string="the" />
            <token id="4" string="farming" />
            <token id="5" string="industry" />
          </tokens>
        </chunking>
        <chunking id="4" string="MAFF" type="NP">
          <tokens>
            <token id="10" string="MAFF" />
          </tokens>
        </chunking>
        <chunking id="5" string="there" type="NP">
          <tokens>
            <token id="16" string="there" />
          </tokens>
        </chunking>
        <chunking id="6" string="Reviled by the farming industry and privately disparaged by MAFF" type="VP">
          <tokens>
            <token id="1" string="Reviled" />
            <token id="2" string="by" />
            <token id="3" string="the" />
            <token id="4" string="farming" />
            <token id="5" string="industry" />
            <token id="6" string="and" />
            <token id="7" string="privately" />
            <token id="8" string="disparaged" />
            <token id="9" string="by" />
            <token id="10" string="MAFF" />
          </tokens>
        </chunking>
        <chunking id="7" string="privately disparaged" type="ADJP">
          <tokens>
            <token id="7" string="privately" />
            <token id="8" string="disparaged" />
          </tokens>
        </chunking>
        <chunking id="8" string="the farming industry" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="farming" />
            <token id="5" string="industry" />
          </tokens>
        </chunking>
        <chunking id="9" string="be a threat" type="VP">
          <tokens>
            <token id="18" string="be" />
            <token id="19" string="a" />
            <token id="20" string="threat" />
          </tokens>
        </chunking>
        <chunking id="10" string="he" type="NP">
          <tokens>
            <token id="12" string="he" />
          </tokens>
        </chunking>
        <chunking id="11" string="may be a threat" type="VP">
          <tokens>
            <token id="17" string="may" />
            <token id="18" string="be" />
            <token id="19" string="a" />
            <token id="20" string="threat" />
          </tokens>
        </chunking>
        <chunking id="12" string="insists that there may be a threat" type="VP">
          <tokens>
            <token id="14" string="insists" />
            <token id="15" string="that" />
            <token id="16" string="there" />
            <token id="17" string="may" />
            <token id="18" string="be" />
            <token id="19" string="a" />
            <token id="20" string="threat" />
          </tokens>
        </chunking>
        <chunking id="13" string="privately disparaged by MAFF" type="VP">
          <tokens>
            <token id="7" string="privately" />
            <token id="8" string="disparaged" />
            <token id="9" string="by" />
            <token id="10" string="MAFF" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advcl">
          <governor id="14">insists</governor>
          <dependent id="1">Reviled</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">industry</governor>
          <dependent id="2">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">industry</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">industry</governor>
          <dependent id="4">farming</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Reviled</governor>
          <dependent id="5">industry</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="1">Reviled</governor>
          <dependent id="6">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">disparaged</governor>
          <dependent id="7">privately</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="1">Reviled</governor>
          <dependent id="8">disparaged</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">MAFF</governor>
          <dependent id="9">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">disparaged</governor>
          <dependent id="10">MAFF</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">insists</governor>
          <dependent id="12">he</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">insists</governor>
          <dependent id="13">nevertheless</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">insists</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">threat</governor>
          <dependent id="15">that</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="20">threat</governor>
          <dependent id="16">there</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="20">threat</governor>
          <dependent id="17">may</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="20">threat</governor>
          <dependent id="18">be</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">threat</governor>
          <dependent id="19">a</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">insists</governor>
          <dependent id="20">threat</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="MAFF" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="10" string="MAFF" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="43" has_coreference="true">
      <content>&amp;quot;I&amp;apost;d expect an increase in cases of CJD by the early years of the next century,&amp;quot; he says.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'d" lemma="would" stem="'d" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="expect" lemma="expect" stem="expect" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="increase" lemma="increase" stem="increas" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="cases" lemma="case" stem="case" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="CJD" lemma="cjd" stem="cjd" pos="NN" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="11" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="13" string="early" lemma="early" stem="earli" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="14" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="17" string="next" lemma="next" stem="next" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="18" string="century" lemma="century" stem="centuri" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP I)) (VP (MD 'd) (VP (VB expect) (NP (NP (DT an) (NN increase)) (PP (IN in) (NP (NP (NNS cases)) (PP (IN of) (NP (NN CJD)))))) (PP (IN by) (NP (NP (DT the) (JJ early) (NNS years)) (PP (IN of) (NP (DT the) (JJ next) (NN century)))))))) (, ,) ('' '') (NP (PRP he)) (VP (VBZ says)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="cases" type="NP">
          <tokens>
            <token id="8" string="cases" />
          </tokens>
        </chunking>
        <chunking id="2" string="expect an increase in cases of CJD by the early years of the next century" type="VP">
          <tokens>
            <token id="4" string="expect" />
            <token id="5" string="an" />
            <token id="6" string="increase" />
            <token id="7" string="in" />
            <token id="8" string="cases" />
            <token id="9" string="of" />
            <token id="10" string="CJD" />
            <token id="11" string="by" />
            <token id="12" string="the" />
            <token id="13" string="early" />
            <token id="14" string="years" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="next" />
            <token id="18" string="century" />
          </tokens>
        </chunking>
        <chunking id="3" string="an increase in cases of CJD" type="NP">
          <tokens>
            <token id="5" string="an" />
            <token id="6" string="increase" />
            <token id="7" string="in" />
            <token id="8" string="cases" />
            <token id="9" string="of" />
            <token id="10" string="CJD" />
          </tokens>
        </chunking>
        <chunking id="4" string="an increase" type="NP">
          <tokens>
            <token id="5" string="an" />
            <token id="6" string="increase" />
          </tokens>
        </chunking>
        <chunking id="5" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="cases of CJD" type="NP">
          <tokens>
            <token id="8" string="cases" />
            <token id="9" string="of" />
            <token id="10" string="CJD" />
          </tokens>
        </chunking>
        <chunking id="7" string="the early years of the next century" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="early" />
            <token id="14" string="years" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="next" />
            <token id="18" string="century" />
          </tokens>
        </chunking>
        <chunking id="8" string="the early years" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="early" />
            <token id="14" string="years" />
          </tokens>
        </chunking>
        <chunking id="9" string="says" type="VP">
          <tokens>
            <token id="22" string="says" />
          </tokens>
        </chunking>
        <chunking id="10" string="'d expect an increase in cases of CJD by the early years of the next century" type="VP">
          <tokens>
            <token id="3" string="'d" />
            <token id="4" string="expect" />
            <token id="5" string="an" />
            <token id="6" string="increase" />
            <token id="7" string="in" />
            <token id="8" string="cases" />
            <token id="9" string="of" />
            <token id="10" string="CJD" />
            <token id="11" string="by" />
            <token id="12" string="the" />
            <token id="13" string="early" />
            <token id="14" string="years" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="next" />
            <token id="18" string="century" />
          </tokens>
        </chunking>
        <chunking id="11" string="he" type="NP">
          <tokens>
            <token id="21" string="he" />
          </tokens>
        </chunking>
        <chunking id="12" string="CJD" type="NP">
          <tokens>
            <token id="10" string="CJD" />
          </tokens>
        </chunking>
        <chunking id="13" string="the next century" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="next" />
            <token id="18" string="century" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">expect</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">expect</governor>
          <dependent id="3">'d</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="22">says</governor>
          <dependent id="4">expect</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">increase</governor>
          <dependent id="5">an</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">expect</governor>
          <dependent id="6">increase</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">cases</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">increase</governor>
          <dependent id="8">cases</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">CJD</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">cases</governor>
          <dependent id="10">CJD</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">years</governor>
          <dependent id="11">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">years</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">years</governor>
          <dependent id="13">early</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">expect</governor>
          <dependent id="14">years</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">century</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">century</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">century</governor>
          <dependent id="17">next</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">years</governor>
          <dependent id="18">century</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">says</governor>
          <dependent id="21">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="22">says</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="CJD" type="MISC" score="0.0">
          <tokens>
            <token id="10" string="CJD" />
          </tokens>
        </entity>
        <entity id="2" string="the early years of the next century" type="DATE" score="0.0">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="early" />
            <token id="14" string="years" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="next" />
            <token id="18" string="century" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="44" has_coreference="true">
      <content>&amp;quot;The bottom line is we just don&amp;apost;t know what risks we may be running.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="bottom" lemma="bottom" stem="bottom" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="line" lemma="line" stem="line" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="know" lemma="know" stem="know" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="risks" lemma="risk" stem="risk" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="running" lemma="run" stem="run" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (DT The) (JJ bottom) (NN line)) (VP (VBZ is) (SBAR (S (NP (PRP we)) (ADVP (RB just)) (VP (VBP do) (RB n't) (VP (VB know) (NP (WP what)) (NP-TMP (NP (NNS risks)) (SBAR (S (NP (PRP we)) (VP (MD may) (VP (VB be) (VP (VBG running)))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="be running" type="VP">
          <tokens>
            <token id="15" string="be" />
            <token id="16" string="running" />
          </tokens>
        </chunking>
        <chunking id="2" string="running" type="VP">
          <tokens>
            <token id="16" string="running" />
          </tokens>
        </chunking>
        <chunking id="3" string="what" type="NP">
          <tokens>
            <token id="11" string="what" />
          </tokens>
        </chunking>
        <chunking id="4" string="risks" type="NP">
          <tokens>
            <token id="12" string="risks" />
          </tokens>
        </chunking>
        <chunking id="5" string="we just do n't know what risks we may be running" type="SBAR">
          <tokens>
            <token id="6" string="we" />
            <token id="7" string="just" />
            <token id="8" string="do" />
            <token id="9" string="n't" />
            <token id="10" string="know" />
            <token id="11" string="what" />
            <token id="12" string="risks" />
            <token id="13" string="we" />
            <token id="14" string="may" />
            <token id="15" string="be" />
            <token id="16" string="running" />
          </tokens>
        </chunking>
        <chunking id="6" string="is we just do n't know what risks we may be running" type="VP">
          <tokens>
            <token id="5" string="is" />
            <token id="6" string="we" />
            <token id="7" string="just" />
            <token id="8" string="do" />
            <token id="9" string="n't" />
            <token id="10" string="know" />
            <token id="11" string="what" />
            <token id="12" string="risks" />
            <token id="13" string="we" />
            <token id="14" string="may" />
            <token id="15" string="be" />
            <token id="16" string="running" />
          </tokens>
        </chunking>
        <chunking id="7" string="know what risks we may be running" type="VP">
          <tokens>
            <token id="10" string="know" />
            <token id="11" string="what" />
            <token id="12" string="risks" />
            <token id="13" string="we" />
            <token id="14" string="may" />
            <token id="15" string="be" />
            <token id="16" string="running" />
          </tokens>
        </chunking>
        <chunking id="8" string="we" type="NP">
          <tokens>
            <token id="6" string="we" />
          </tokens>
        </chunking>
        <chunking id="9" string="we may be running" type="SBAR">
          <tokens>
            <token id="13" string="we" />
            <token id="14" string="may" />
            <token id="15" string="be" />
            <token id="16" string="running" />
          </tokens>
        </chunking>
        <chunking id="10" string="The bottom line" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="bottom" />
            <token id="4" string="line" />
          </tokens>
        </chunking>
        <chunking id="11" string="do n't know what risks we may be running" type="VP">
          <tokens>
            <token id="8" string="do" />
            <token id="9" string="n't" />
            <token id="10" string="know" />
            <token id="11" string="what" />
            <token id="12" string="risks" />
            <token id="13" string="we" />
            <token id="14" string="may" />
            <token id="15" string="be" />
            <token id="16" string="running" />
          </tokens>
        </chunking>
        <chunking id="12" string="may be running" type="VP">
          <tokens>
            <token id="14" string="may" />
            <token id="15" string="be" />
            <token id="16" string="running" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">line</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">line</governor>
          <dependent id="3">bottom</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">is</governor>
          <dependent id="4">line</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">is</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">know</governor>
          <dependent id="6">we</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">know</governor>
          <dependent id="7">just</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">know</governor>
          <dependent id="8">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="10">know</governor>
          <dependent id="9">n't</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">is</governor>
          <dependent id="10">know</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">know</governor>
          <dependent id="11">what</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="10">know</governor>
          <dependent id="12">risks</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">running</governor>
          <dependent id="13">we</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">running</governor>
          <dependent id="14">may</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">running</governor>
          <dependent id="15">be</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="12">risks</governor>
          <dependent id="16">running</dependent>
        </dependency>
      </dependencies>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="5-6-7-8-9-10-11" string="a multi-million pound disaster for British agriculture" id_sentence="1" />
      <mentions>
        <mention ids_tokens="1" string="It" id_sentence="2" />
        <mention ids_tokens="27" string="it" id_sentence="2" />
      </mentions>
    </coreference>
    <coreference id="2" type="PROPER">
      <referenced ids_tokens="10-11-12-13-14" string="&quot; mad cow &quot; disease" id_sentence="2" />
      <mentions>
        <mention ids_tokens="19-20" string="the disease" id_sentence="9" />
        <mention ids_tokens="2-5" string="Mad Cow &quot; disease" id_sentence="11" />
        <mention ids_tokens="47-48" string="the disease" id_sentence="27" />
        <mention ids_tokens="12-13" string="the disease" id_sentence="30" />
        <mention ids_tokens="17-18" string="the disease" id_sentence="31" />
        <mention ids_tokens="46-47" string="the disease" id_sentence="34" />
        <mention ids_tokens="2-3" string="the disease" id_sentence="40" />
        <mention ids_tokens="25" string="it" id_sentence="40" />
      </mentions>
    </coreference>
    <coreference id="3" type="NOMINAL">
      <referenced ids_tokens="22-23" string="that country" id_sentence="3" />
      <mentions>
        <mention ids_tokens="5-6" string="their country" id_sentence="4" />
      </mentions>
    </coreference>
    <coreference id="7" type="PROPER">
      <referenced ids_tokens="13-14-15-16" string="the magazine Farmers Weekly" id_sentence="8" />
      <mentions>
        <mention ids_tokens="19-20" string="Farmers Weekly" id_sentence="33" />
      </mentions>
    </coreference>
    <coreference id="8" type="NOMINAL">
      <referenced ids_tokens="31" string="downright" id_sentence="8" />
      <mentions>
        <mention ids_tokens="52" string="their" id_sentence="9" />
      </mentions>
    </coreference>
    <coreference id="9" type="PROPER">
      <referenced ids_tokens="1-2-3-4" string="The Ministry of Agriculture" id_sentence="20" />
      <mentions>
        <mention ids_tokens="4-6" string="Ministry of Agriculture" id_sentence="9" />
        <mention ids_tokens="2" string="it" id_sentence="10" />
        <mention ids_tokens="4" string="itself" id_sentence="10" />
      </mentions>
    </coreference>
    <coreference id="10" type="PROPER">
      <referenced ids_tokens="12" string="MAFF" id_sentence="9" />
      <mentions>
        <mention ids_tokens="5" string="it" id_sentence="35" />
        <mention ids_tokens="22-23" string="MAFF's" id_sentence="36" />
      </mentions>
    </coreference>
    <coreference id="12" type="NOMINAL">
      <referenced ids_tokens="8" string="humans" id_sentence="10" />
      <mentions>
        <mention ids_tokens="25" string="they" id_sentence="11" />
      </mentions>
    </coreference>
    <coreference id="13" type="NOMINAL">
      <referenced ids_tokens="19-20" string="four animals" id_sentence="11" />
      <mentions>
        <mention ids_tokens="11-13" string="the animals'" id_sentence="12" />
        <mention ids_tokens="38-40" string="the animals'" id_sentence="27" />
      </mentions>
    </coreference>
    <coreference id="15" type="NOMINAL">
      <referenced ids_tokens="1-2" string="MAFF scientists" id_sentence="13" />
      <mentions>
        <mention ids_tokens="23" string="they" id_sentence="14" />
      </mentions>
    </coreference>
    <coreference id="16" type="PROPER">
      <referenced ids_tokens="1" string="Cattle" id_sentence="16" />
      <mentions>
        <mention ids_tokens="9-18" string="cattle given processed feed that included remains of diseased sheep" id_sentence="13" />
      </mentions>
    </coreference>
    <coreference id="17" type="NOMINAL">
      <referenced ids_tokens="11-12-13-14-15-16-17-18" string="processed feed that included remains of diseased sheep" id_sentence="13" />
      <mentions>
        <mention ids_tokens="10-11" string="the feed" id_sentence="14" />
      </mentions>
    </coreference>
    <coreference id="18" type="PROPER">
      <referenced ids_tokens="1-2" string="That year" id_sentence="18" />
      <mentions>
        <mention ids_tokens="19-20" string="this year" id_sentence="22" />
      </mentions>
    </coreference>
    <coreference id="19" type="NOMINAL">
      <referenced ids_tokens="14-15-16" string="the feed ban" id_sentence="18" />
      <mentions>
        <mention ids_tokens="22-23" string="the ban" id_sentence="21" />
      </mentions>
    </coreference>
    <coreference id="20" type="NOMINAL">
      <referenced ids_tokens="28" string="farms" id_sentence="18" />
      <mentions>
        <mention ids_tokens="8-18" string="farms where MAFF is conducting a seven-year experiment into the disease" id_sentence="31" />
      </mentions>
    </coreference>
    <coreference id="21" type="NOMINAL">
      <referenced ids_tokens="1-2-3-4-5-6-7-8-9-10" string="The ministry believes that the reason more cattle have died" id_sentence="21" />
      <mentions>
        <mention ids_tokens="36-37" string="the ministry" id_sentence="22" />
        <mention ids_tokens="9-10" string="the ministry" id_sentence="26" />
        <mention ids_tokens="39-40" string="the ministry" id_sentence="36" />
      </mentions>
    </coreference>
    <coreference id="23" type="PROPER">
      <referenced ids_tokens="1-2" string="Mark Purdey" id_sentence="27" />
      <mentions>
        <mention ids_tokens="10" string="his" id_sentence="28" />
      </mentions>
    </coreference>
    <coreference id="25" type="NOMINAL">
      <referenced ids_tokens="1-2" string="Ministry scientists" id_sentence="28" />
      <mentions>
        <mention ids_tokens="31-32" string="our scientists" id_sentence="34" />
      </mentions>
    </coreference>
    <coreference id="27" type="PROPER">
      <referenced ids_tokens="1-2" string="This month" id_sentence="31" />
      <mentions>
        <mention ids_tokens="1" string="It" id_sentence="32" />
        <mention ids_tokens="3-14" string="a daunting possibility for the farming industry , which has responded angrily" id_sentence="32" />
      </mentions>
    </coreference>
    <coreference id="34" type="NOMINAL">
      <referenced ids_tokens="6-7" string="most scientists" id_sentence="41" />
      <mentions>
        <mention ids_tokens="6" string="we" id_sentence="44" />
        <mention ids_tokens="13" string="we" id_sentence="44" />
      </mentions>
    </coreference>
    <coreference id="35" type="PROPER">
      <referenced ids_tokens="14-15" string="Mr Purdey" id_sentence="41" />
      <mentions>
        <mention ids_tokens="12" string="he" id_sentence="42" />
        <mention ids_tokens="21" string="he" id_sentence="43" />
      </mentions>
    </coreference>
    <coreference id="36" type="NOMINAL">
      <referenced ids_tokens="33-34-35-36-37-38-39-40-41-42-43" string="cases of CJD , a disease with a long incubation period" id_sentence="41" />
      <mentions>
        <mention ids_tokens="8-10" string="cases of CJD" id_sentence="43" />
      </mentions>
    </coreference>
    <coreference id="37" type="NOMINAL">
      <referenced ids_tokens="2-3-4" string="The bottom line" id_sentence="44" />
      <mentions>
        <mention ids_tokens="2" string="I" id_sentence="43" />
      </mentions>
    </coreference>
  </coreferences>
</document>
